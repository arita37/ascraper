 
all -  [ [Student] Sent over 200+ SWE internships applications, but barley getting interviews ](https://www.reddit.com/r/EngineeringResumes/comments/1fbh3l4/student_sent_over_200_swe_internships/) , 2024-09-08-0913
```
https://preview.redd.it/zzo8ftb5bgnd1.png?width=5100&format=png&auto=webp&s=365d22e834c98eac1bafea5779a97b38c9227cdf

I'
m trying to figure out what is wrong with my resume because it looks fine to me. I am targeting entry-level software eng
ineering internships at small companies or big tech companies. I have a premium subscription to ResumeWord AI, and despi
te a score of over 95 in my resume, it didn't really have an impact. I have a niche in AI and RAG and try to sneak in so
ft skills in a technical way. I had previous internships due to connections and networking(I mass applied and got nothin
g last year) and never actually went through a full interview process. Also, a slightly smaller question is having a bro
ader skillset more important or specialization. And yes, I have following 90% of the guidelines mentioned on the Wiki of
 this subreddit. Any harsh criticism would be greatly appreciated.
```
---

     
 
all -  [ Langchain Structured Output vs OpenAI Structured Outputs ](https://www.reddit.com/r/LangChain/comments/1fbfrcn/langchain_structured_output_vs_openai_structured/) , 2024-09-08-0913
```
Hello. As you know, openai recently announced the 'Structured Outputs' feature. They used to support json response befor
e, but this new feature offers 100% guarantee and provides much more stable usage. I also need an LLM that can provide 1
00% guaranteed and high-performance JSON response. But I also need to use the langchain library for some of its features
 (such as prompt template, ai agent tools) and multiple llm support. At this point, I have 2 questions:



1) What is th
e difference between the langchain structured outputs feature and the new openai structured outputs feature? Can langcha
in provide 100% guaranteed and high-performance JSON response like openai?

2) If not, is there a way to use the new ope
nai feature via langchain?



I am new to langchain and llms in general. I would be very happy if you could help me, tha
nk you.
```
---

     
 
all -  [ LangChain's Repository ](https://github.com/langchain-ai/langchain) , 2024-09-08-0913
```

```
---

     
 
all -  [ I wrote my first Medium blog on Multi-Agent Systems Discussion ](https://www.reddit.com/r/LangChain/comments/1fb47oz/i_wrote_my_first_medium_blog_on_multiagent/) , 2024-09-08-0913
```
For a few months, I have been a part of this sub and working on multi-agent systems for several use-cases. 
I recently w
rote an article on Medium on the same and I would really appreciate your feedback. I wanted to mostly present my finding
s about what works and what doesn't in the industry along with giving an introduction to the topic. 

Here's the link: [
Medium](https://medium.com/@yashbhardwaj.1912/the-power-of-collaboration-llm-agents-in-multi-agent-systems-8c0441157f14)
! 
```
---

     
 
all -  [ Review and suggest ideas for my RAG chatbot ](https://www.reddit.com/r/LocalLLaMA/comments/1fb2osi/review_and_suggest_ideas_for_my_rag_chatbot/) , 2024-09-08-0913
```
Ok, so I am currently trying to build support chatbot with following technicalities 
1. FastAPI for web server(Need to m
ake it faster)
2. Qdrant as Vector Data Base(Found it to be the fastest amongst Chromadb, Elastic Search and Milvus)
3. 
MongoDB for storing all the data and feedback.
4. Semantic chunking with max token limit of 512.
5. granite-13b-chat-v2 
as the LLM(I know it's not good but I have limited options available)
6. The data is structured as well as unstructured.
 Thinking of having involving GraphRAG with current architecture.
7. Multiple data sources stored in multiple collection
s of vector database because I have implemented an access control.
8. Using mongoengine currently as a ORM. If you know 
something better please suggest.
9. Using all-miniLM-l6-v2 as vector embedding currently but planning to use stella_en_4
00M_v5.
10. Using cosine similarity to retrieve the documents.
11. Using BLEU, F1 and BERT score for automated evaluatio
n based on golden answer.
12. Using top_k as 3.
13. Currently using basic question answering prompt but want to improve 
it. Any tips? Also heard about Automatic Prompt Evaluation.
14. Currently using custom code for everything. Looking to u
se Llamaindex or Langchain for this. 
15. Right now I am not using any AI Agent, but I want to know your opinions. 
16. 
It's a simple RAG framework and I am working on improving it.
17. I haven't included reranker but I am planning to do so
 too.

I think I mentioned pretty much everything I am using for my project. So please share your suggestions, comments 
and reviews for the same. Thank you!!
```
---

     
 
all -  [ GraphRAG practical issues  ](https://www.reddit.com/r/learnmachinelearning/comments/1fb2ekl/graphrag_practical_issues/) , 2024-09-08-0913
```
I tried GraphRAG using LangChain and figured out some problems and issues it can't handle. Check out GraphRAG problems d
emonstrated here : https://youtu.be/z5ldGLU7NwU?si=o0KQ6riVkLKpyRHF
```
---

     
 
all -  [ Has anyone tried this tool? ](https://www.reddit.com/r/PromptEngineering/comments/1faurye/has_anyone_tried_this_tool/) , 2024-09-08-0913
```
Just wondering if this is worth a look vs just langchain, or what is special about it?

[https://venturebeat.com/ai/how-
few-shot-learning-with-googles-prompt-poet-can-supercharge-your-llms/](https://venturebeat.com/ai/how-few-shot-learning-
with-googles-prompt-poet-can-supercharge-your-llms/)


```
---

     
 
all -  [ What does your LLM stack look like these days? ](https://www.reddit.com/r/LangChain/comments/1fanhgm/what_does_your_llm_stack_look_like_these_days/) , 2024-09-08-0913
```
I am starting to use more of CrewAI, DSPy, Claude sonnet, chromadb and Langtrace. 
```
---

     
 
all -  [ has anyone checked this Decomposed Automation Correction for Text-to-SQL?  ](https://www.reddit.com/r/LangChain/comments/1fan5am/has_anyone_checked_this_decomposed_automation/) , 2024-09-08-0913
```
[https://github.com/zirui-HIT/DAC/tree/main](https://github.com/zirui-HIT/DAC/tree/main)

[https://arxiv.org/pdf/2408.08
779v2](https://arxiv.org/pdf/2408.08779v2)
```
---

     
 
all -  [ Does Microsoft Ever Make Anything Easy? Azure + Langchain help ](https://www.reddit.com/r/LangChain/comments/1faknzu/does_microsoft_ever_make_anything_easy_azure/) , 2024-09-08-0913
```
I am trying to setup, a working Langchain script to chat with AI to my Azure instance. Below is what I had before in def
ining the llm.

```javascript
import { ChatOpenAI } from 'langchain/chat_models/openai'

let llm = new ChatOpenAI({
  op
enAIApiKey,
  streaming: true,
  callbacks: [
    {
      handleLLMStart: async () => {
        id = setTimeout(() => {

          chat.setMessage(-1, md(`### Sorry, the AI is taking a long time to respond.`))
          setLoading(true)
    
    }, 3000)
        log(JSON.stringify({ event: 'handleLLMStart' }))
        currentMessage = ``
        chat.addMessag
e('')
      },
      handleLLMNewToken: async token => {
        clearTimeout(id)
        setLoading(false)
        if (
!token) return
        currentMessage += token
        let htmlMessage = md(currentMessage)
        chat.setMessage(-1, 
htmlMessage)
      },
      handleLLMError: async err => {
        warn(JSON.stringify({ event: 'handleLLMError', error:
 err }))
        running = false
        await appendToLogFile(JSON.stringify({ type: 'Error', message: err.message }) +
 ',\n')
      },
      handleLLMEnd: async () => {
        running = false
        log(JSON.stringify({ event: 'handleLL
MEnd' }))
        if (currentMessage) {
          await appendToLogFile(JSON.stringify({ type: 'AI', message: currentMes
sage }) + ',\n')
        }
        currentMessage = ``
      },
    },
  ],
})
```

I know that import above is deprecat
ed, I am trying to switch to using `AzureChatOpenAI` and this is the code I have, which aligns with the new 0.2 docs

``
`javascript
import { AzureChatOpenAI } from '@langchain/openai';

let llm = new AzureChatOpenAI({
  azureOpenAIApiKey: p
rocess.env.AZURE_OPENAI_API_KEY,
  azureOpenAIApiInstanceName: process.env.AZURE_OPENAI_API_INSTANCE_NAME,
  azureOpenAI
ApiDeploymentName: process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME,
  azureOpenAIApiVersion: process.env.AZURE_OPENAI_API_V
ERSION,
  callbacks: [
    {
      handleLLMStart: async () => {
        id = setTimeout(() => {
          chat.setMessa
ge(-1, md(`### Sorry, the AI is taking a long time to respond.`))
          setLoading(true)
        }, 3000)
        lo
g(JSON.stringify({ event: 'handleLLMStart' }))
        currentMessage = ``
        chat.addMessage('')
      },
      ha
ndleLLMNewToken: async token => {
        clearTimeout(id)
        setLoading(false)
        if (!token) return
        
currentMessage += token
        let htmlMessage = md(currentMessage)
        chat.setMessage(-1, htmlMessage)
      },
 
     handleLLMError: async err => {
        warn(JSON.stringify({ event: 'handleLLMError', error: err }))
        runnin
g = false
        await appendToLogFile(JSON.stringify({ type: 'Error', message: err.message }) + ',\n')
      },
      
handleLLMEnd: async () => {
        running = false
        log(JSON.stringify({ event: 'handleLLMEnd' }))
        if (c
urrentMessage) {
          await appendToLogFile(JSON.stringify({ type: 'AI', message: currentMessage }) + ',\n')
      
  }
        currentMessage = ``
      },
    },
  ],
})
```

I get a 404 error, which is not very helpful. I know for a 
fact my values are correct becuase I have a non langchain script that uses `const { AzureOpenAI } = require('openai');` 
and it works fine.

Also, I have noticed there might be an API Version that is for a particular deployment on Azure, as 
well as an API version for the entire instance. 

If anyone can provide insight on setting up Azure with Langchain and N
odeJS, I would be very greatful.

Thanks and happy coding.
```
---

     
 
all -  [ Free Generative AI Web App Course: Learn LangChain, NLP & Streamlit ](https://www.reddit.com/r/myHeadstarter/comments/1fak4vf/free_generative_ai_web_app_course_learn_langchain/) , 2024-09-08-0913
```
Here’s the link: [Free Course](https://www.udemy.com/course/building-generative-ai-web-apps-with-streamlit-langchain/) 🚀


My team at **ViSTEM** just launched an **exciting, FREE** course to teach you how to build AI-powered web apps using *
*Streamlit** and **LangChain**! Perfect for anyone wanting to dive into generative AI and web development. Whether you'r
e a beginner with some Python knowledge or an experienced developer, this course is a game-changer. Plus, you can even e
arn a **certificate** from us at ViSTEM—just send proof of completion! 🏆

**Course Highlights:**

* **Streamlit:** Build
 dynamic web apps
* **LangChain:** Master state-of-the-art AI frameworks
* **Text Summarization with NLP**
* **arXiv API
 Setup** for research paper handling

Get hands-on experience with **real-world projects** and build your own AI-powered
 research app! 🌟
```
---

     
 
all -  [ What is optimal for Langflow: Loop or multi-api call? or Tasks? ](https://www.reddit.com/r/LangChain/comments/1faiz56/what_is_optimal_for_langflow_loop_or_multiapi/) , 2024-09-08-0913
```
I'm in the midst of a fun side project to get good MTG ruling. My stopping point is getting LangChain/LangFlow to iterat
e over a list of \[words in brackets\] in a prompt, and then take those \[words in brackets\] from the user and put each
 set into an API request. Is there an easy way to do that? 
```
---

     
 
all -  [ Claude, Projects and RAG ](https://www.reddit.com/r/LangChain/comments/1faenrt/claude_projects_and_rag/) , 2024-09-08-0913
```
My understanding is that the Projects feature of Claude Soinnet 3.5 works a little like a RAG feature.  
The documents i
n the knowledge are indexed and then the prompt is augmented by information located within the documents located in the 
knowledge.  
The difference with RAG is that the documents in knowledge are uploaded  and not retrieved as in A RAG syst
em. Is this understanding correct?
```
---

     
 
all -  [ LangGraph.js Fundamentals: Nodes, Edges, Conditional Edges, and Graphs ](https://www.reddit.com/r/LangChain/comments/1faeh4h/langgraphjs_fundamentals_nodes_edges_conditional/) , 2024-09-08-0913
```
Hey folks! I've made this intro tutorial for LangGraph.js. 

[https://www.js-craft.io/blog/langgraph-js-conditional-edge
s-graphs/](https://www.js-craft.io/blog/langgraph-js-conditional-edges-graphs/)

Any feedback is welcomed! 
```
---

     
 
all -  [ Text2SQL using HuggingFace Llama3 ](https://www.reddit.com/r/LangChain/comments/1fae122/text2sql_using_huggingface_llama3/) , 2024-09-08-0913
```
Has anyone used HuggingFace to access Llama3 for Text2SQL problems? I can get results with Gemma using HuggingFace but w
hen I load Llama3 it says it's 16GB so I can't load directly. I can't find resources for Text2SQL using HuggingFace, but
 it's available for OpenAI, Groq. Below is the code with the Gemma model. 

    load_dotenv()
    
    POSTGRESQL_HOST =
 os.getenv('POSTGRESQL_HOST')
    POSTGRESQL_USER = os.getenv('POSTGRESQL_USER')
    POSTGRESQL_PASS = os.getenv('POSTGR
ESQL_PASS')
    POSTGRESQL_DB = os.getenv('POSTGRESQL_DB')
    POSTGRESQL_URI = f'postgresql://{POSTGRESQL_USER}:{POSTGR
ESQL_PASS}@{POSTGRESQL_HOST}:5432/{POSTGRESQL_DB}'
    
    HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOK
EN')
    
    hf = HuggingFaceEndpoint(repo_id = 'google/gemma-2b', temperature = 0.1, huggingfacehub_api_token = HUGGIN
GFACEHUB_API_TOKEN)
    
    def configure_db(db_uri):
        return SQLDatabase(create_engine(db_uri))
    
    db = c
onfigure_db(POSTGRESQL_URI)
    
    db_chain = SQLDatabaseChain.from_llm(hf, db, verbose=True)
    
    user_query = 'W
hich control governs incident response planning under NIS2?'
    response = db_chain.invoke(user_query)
    print(respon
se)
    
```
---

     
 
all -  [ LLM uses fake documents from examples as context ](https://www.reddit.com/r/LangChain/comments/1faatl2/llm_uses_fake_documents_from_examples_as_context/) , 2024-09-08-0913
```
Hello!

I have been working on an internal AI assistant for my company, and have set up a RAG pipeline.

Unfortunately, 
given the right query, the model uses the fake documents provided through examples to generate his answer, which is quit
e jarring. Is there any best practice here? A way to clearly indicate that information given as examples should not be c
onsidered?

If that makes a difference, my team has been toying with [Prompty ](https://prompty.ai/)for the prompt templ
ating, and its langchain integration, [langchain\_prompty](https://api.python.langchain.com/en/latest/prompty_api_refere
nce.html). I'll gladly switch to something else if needed.

As for why examples are needed here, I am using structured o
utput to generate the answer chunk by chunk, with each chunk associated to a list of IDs, linking to the documents used 
for this chunk. Examples have a substantial impact on how well the model follows guidelines (not naming the documents in
 the body of the answer for example).

Thanks!
```
---

     
 
all -  [ Dev partner for Medium com scraper ](https://www.reddit.com/r/LangChain/comments/1faa4dk/dev_partner_for_medium_com_scraper/) , 2024-09-08-0913
```
I'm working on developing a Medium.com scraper that collects article data (titles, subtitles, authors, dates, etc.), and
 I'm looking for someone to join me in building it quickly and efficiently. If you have experience with Python, Selenium
, BeautifulSoup, or any web scraping tools and want to collaborate on this, let's connect!I'm open to new ideas and appr
oaches to make the scraper more powerful. DM me if you're interested, and let's get this rolling!
```
---

     
 
all -  [ is Langchian production ready? ](https://www.reddit.com/r/LangChain/comments/1fa9y8l/is_langchian_production_ready/) , 2024-09-08-0913
```
I am working on a startup project and almost finished. I have used langchain. Seen somewhere on youtube that langchain a
nd llamaindex or not prod ready? is it true?
```
---

     
 
all -  [ Evaluate your RAG pipeline with Ragas, agnostic of LLM ](https://www.reddit.com/r/LangChain/comments/1fa9953/evaluate_your_rag_pipeline_with_ragas_agnostic_of/) , 2024-09-08-0913
```
Another update from RAG Me Up! We have added some rudimentary evaluation metrics using Ragas so you can now start tweaki
ng your RAG pipeline objectively. Best thing is that it doesn't matter if you use ChatGPT, Gemini, Claude, Ollama, LLaMa
 3.1 or any other LLM, they are all supported.

By the way - we also added Re2 to have the LLM re-read your question, im
proving performance.

  
[https://github.com/AI-Commandos/RAGMeUp](https://github.com/AI-Commandos/RAGMeUp)
```
---

     
 
all -  [ Live context and fact checks using RAG and whisper  ](https://www.reddit.com/r/LangChain/comments/1fa8ov2/live_context_and_fact_checks_using_rag_and_whisper/) , 2024-09-08-0913
```
I have a need for a tool that could be connected to a zoom call or similar and could in realtime pull up and summarise r
elevant information and perhaps also fact check.

E.g on a call person X says “the total cost of the project will be £65
 and take 2 years”

In realtime, something could pop up that says
 “
- the initial proposal stated the total cost would 
be £55
- in an email on 6th September Bob told Mary that the project was still within budget” etc.

And ideally it would
 be linked to the sources.

I remember seeing someone’s project for doing job interviews and I’ve seen some fact check p
rojects but can’t find these again.

Are there any repos or libraries that would get me a good chunk of the way there?


I’m assuming it will use OpenAI GPT, whisper, langchain but perhaps there is something that brings it all together?
```
---

     
 
all -  [ Do I need finetuning or a better RAG? ](https://www.reddit.com/r/LangChain/comments/1fa8ilr/do_i_need_finetuning_or_a_better_rag/) , 2024-09-08-0913
```
Hi everyone,  
I created a RAG model for question answering. My document is having too much details and many subheadings
 too. I have set my chunk size as 1024. I noticed RAG is not retrieving related context, as subheadings not having the t
opic name most of the times.

Currently thinking about finetuning by creating question answer pairs from my dataset. But
 I believe it can lead to more hallucination. I read articles saying finetuning can not be used to provide model with ne
w knowledge. Correct me if I am wrong. Else I think I need to pre process my docs better. Have anyone tried finetuning f
or question answering with custom data? Please share your experiences.
```
---

     
 
all -  [ Tavily vs. Exa for RAG with LangChain - Any Recommendations? ](https://www.reddit.com/r/Rag/comments/1fa73cn/tavily_vs_exa_for_rag_with_langchain_any/) , 2024-09-08-0913
```
I'm starting to build a RAG workflow using LangChain, and I'm at the stage where I need to pick a search tool. I'm looki
ng at Tavily and Exa, but I'm not sure which one would be the better choice.   
What are the key difference between them
?
```
---

     
 
all -  [ Langrunner Simplifies Remote Execution in Generative AI Workflows ](https://www.reddit.com/r/Langchaindev/comments/1fa6tk5/langrunner_simplifies_remote_execution_in/) , 2024-09-08-0913
```
When using Langchain and LlamaIndex to develop Generative AI applications, dealing with compute-intensive tasks (like fi
ne-tuning with GPUs) can be a hassle. To solve this, we created the **Langrunner** tool which offers an inline API that 
lets you execute specific blocks of code remotely without wrapping the entire codebase. It integrates directly into your
 existing workflow, scheduling tasks on clusters optimized with the necessary resources (AWS, GCP, Azure, or Kubernetes)
 and pulling results back into your local environment.

No more manual containerization or artifact transfers—just strea
mlined development from within your notebook!

Check it out here: [https://github.com/dkubeai/langrunner](https://github
.com/dkubeai/langrunner)
```
---

     
 
all -  [ Langrunner: Simplifying Remote Execution in Generative AI Workflows ](https://www.reddit.com/r/LLMDevs/comments/1fa6bf1/langrunner_simplifying_remote_execution_in/) , 2024-09-08-0913
```
When using LlamaIndex and Langchain to develop Generative AI applications, dealing with compute-intensive tasks (like fi
ne-tuning with GPUs) can be a hassle. Langrunner lets you easily execute code blocks remotely (on AWS, GCP, Azure, or Ku
bernetes) without the hassle of wrapping your entire codebase. Results flow right back into your local environment—no ma
nual containerization needed.

Level up your AI dev experience and check it out here: [https://github.com/dkubeai/langru
nner](https://github.com/dkubeai/langrunner)
```
---

     
 
all -  [ What is the best way to minimalize html code for llm.  ](https://www.reddit.com/r/LangChain/comments/1fa156y/what_is_the_best_way_to_minimalize_html_code_for/) , 2024-09-08-0913
```
I want to minimalize token count of a html file. I just want to make the llm see the web page with that html or any thin
g with lower token size. 
```
---

     
 
all -  [ Trabalhar com front tendo experiência apenas com back ](https://www.reddit.com/r/brdev/comments/1f9zjvc/trabalhar_com_front_tendo_experiência_apenas_com/) , 2024-09-08-0913
```
Contexto: trabalhava como dev backend jr em uma consultoria pequena da minha cidade, mas troquei de emprego como fullsta
ck jr e agora trabalho remoto pra uma empresa grande de SP que vende ERP pro Brasil todo. Esse trampo eu consegui por in
dicação, e apesar do foco da vaga ser backend com uso de IA (GenAI na AWS com Python e Langchain, mais especificamente) 
também querem que eu toque algumas coisas de Vue.js.

Acontece que eu não sei quase NADA de frontend, fiz uma coisa aqui
 ou ali na faculdade, mas não tenho nenhuma experiência profissional com HTML, CSS e Javascript. A sorte é que meu super
ior disse que não cobraria que eu soubesse essas coisas logo de cara. 

Mas queria saber de vocês se já aconteceram de t
er que tocar front sendo backend, ou vice-versa? Como foi isso? 


```
---

     
 
all -  [ LangChain's ConversationBufferMemory vs OpenAI API's message history ](https://www.reddit.com/r/LangChain/comments/1f9x1g0/langchains_conversationbuffermemory_vs_openai/) , 2024-09-08-0913
```
This is a question particularly relevant to using LangChain with OpenAI APIs. From my understanding, which might be wron
g, LangChain's ConversationBufferMemory injects the entire conversation history into each prompt being passed to the LLM
. While this doesn't lead to much of a problem with the context window, it seems needlessly expensive to call the API wi
th the entire conversation history when it already has a message history that it stores. The API charges for the number 
of tokens for each input.

Wouldn't the ConversationBufferMemory method be inefficient and expensive, or am I missing so
mething here?
```
---

     
 
all -  [ [P] Lessons from Retrieval Augmented Generation ](https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/) , 2024-09-08-0913
```
I implemented Rag in my organization and just wrote a blog about what we learned here:   
[https://www.b-yond.com/post/t
ransforming-telco-troubleshooting-our-journey-building-telcogpt-with-rag](https://www.b-yond.com/post/transforming-telco
-troubleshooting-our-journey-building-telcogpt-with-rag)

Hoping it would be helpful for those in this area. Covers rag 
evaluation (ragas), sql db, langchain agents vs chains, weaviate vector db, hybrid search, reranking, and more.

Some ad
ditional insights on ranking and hybrid search here:

[https://www.linkedin.com/posts/drzohaib\_transforming-telco-troub
leshooting-our-journey-activity-7232072089837486081--Le1?utm\_source=share&utm\_medium=member\_android](https://www.link
edin.com/posts/drzohaib_transforming-telco-troubleshooting-our-journey-activity-7232072089837486081--Le1?utm_source=shar
e&utm_medium=member_android)
```
---

     
 
all -  [ How to incorporate Agents into a RAG model ](https://www.reddit.com/r/LangChain/comments/1f9t31s/how_to_incorporate_agents_into_a_rag_model/) , 2024-09-08-0913
```
I'm new to langchain, and I'm currently creating an LLM application to answer questions from custom data (here, data scr
aped from websites). When I prompt a query, the answer sometimes turns out to be, 'I could not find an answer to that fr
om the provided data.' 

I was thinking of employing agents to retrieve extra information from external websites. Basica
lly, is there any way that I can create a hybrid model that combines the strength of both my internal vector database an
d external web search through agents? If so, please guide me on how to do so. I would appreciate it if you share require
d resources as well!
```
---

     
 
all -  [ Best way to add Rewoo (Planner arch) to a chat flow in Langgraph? ](https://www.reddit.com/r/LangChain/comments/1f9rqp8/best_way_to_add_rewoo_planner_arch_to_a_chat_flow/) , 2024-09-08-0913
```
Hey everyone,

I started using a graph based on *supervisor architecture* to build a conversational agent. I had better 
results using a graph based on *Router Agent*, but when dealing with more complex tasks that require multiple steps, thi
ngs haven’t worked as well as I'd hoped. So, I’m thinking about adding the Rewoo-based planner architecture (from the do
cs) into the flow.

The challenge is that in the example, the graph receives a 'Task' as input, but in a conversational 
agent, the user doesn’t always send a clear task—they just keep chatting.

Here are a couple of approaches I’m thinking 
of testing:

1. **Generate a Task from the conversation**: Take the list of messages between the user and the final AI r
esponse, and use that to write a Task that the graph can process.
2. **Feed the message history directly to the Planning
 Agent**: Instead of passing a Task, just pass the message history, and let the agent figure out the planning from that.


**Another option**: Send the message history to the planning node, but then in a parallel execution, pass a Task writt
en based on the messages directly to the solver node.

Any other ideas or suggestions?
```
---

     
 
all -  [ How perplexity handles web scraping ](https://www.reddit.com/r/LangChain/comments/1f9rpq1/how_perplexity_handles_web_scraping/) , 2024-09-08-0913
```
Hi folks,   
We recently have tried to implement some search function for open web results but one thing we found very f
rustrating is scraping time. Does any of you know or can guess how service like Perplexity or  GPT search can have such 
fast response? May I know if the speed is driven by 1) cached parsed website result or 2) underlying architecture(unlike
 current common web loader connector) or 3) simply more dedicated compute resources?   
And if possible, may I know if a
nyone can share how you improve the web searching + parsing speed in your project?  Our current speed with scraping prov
ider is just unacceptably slow... 

Thanks so much for help!
```
---

     
 
all -  [ Help! I got the hint of firing in my current job. Seeking for guidance ](https://www.reddit.com/r/LangChain/comments/1f9pxgk/help_i_got_the_hint_of_firing_in_my_current_job/) , 2024-09-08-0913
```
Help! I got the hint of firing in my current job. Seeking for guidance

Currently working in nontechnical work as a proj
ect architect junior. Finished Mtech in Data Science & due to a bad marker I ended up here. I just want to get into AI f
ield. Please share tips please. I don't know-how much time I have in this company.
```
---

     
 
all -  [ I Built an App with Lyzr Agent API That Auto-Writes & Posts Tweets! 🧠✨ Check It Out! ](https://www.reddit.com/r/LangChain/comments/1f9oep3/i_built_an_app_with_lyzr_agent_api_that/) , 2024-09-08-0913
```
[Auto Write and Post Tweets](https://reddit.com/link/1f9oep3/video/ii5kymv880nd1/player)

**Hey Reddit!**

I'm thrilled 
to share something I've been working on – an app that uses the Lyzr Agent API to automatically write and post tweets for
 you! Whether you're a social media manager, a content creator, or just someone who struggles with writer's block, this 
app takes care of everything.

**What does it do?**

* Generates AI-powered tweets based on your prompts
* Posts them di
rectly to your Twitter account
* Saves time and helps boost engagement with fresh ideas

If you're tired of coming up wi
th tweets or want to automate your posting, give it a try. Would love to hear your feedback or any features you'd like t
o see added!

#AI #Automation #Twitter #Productivity
```
---

     
 
all -  [ The propositions method for RAG - new way of data ingestion ](https://medium.com/@nirdiamant21/the-propositions-method-enhancing-information-retrieval-for-ai-systems-c5ed6e5a4d2e) , 2024-09-08-0913
```
I've just published a detailed article on Medium about the Propositions Method for AI Information Retrieval. If you're i
nterested in Natural Language Processing, information retrieval, or AI in general, I think you'll find this pretty fasci
nating.

What's the Propositions Method?
In short, it's a technique for breaking down complex information into simple, a
tomic facts. This allows AI systems to understand and retrieve information more accurately and efficiently.
In the artic
le, I cover:

- What exactly the Propositions Method is
- Why it's becoming increasingly important in AI
- How it works 
(with examples)
- The potential benefits and applications
- Some challenges and future directions

We'll soon be adding 
an implementation of the Propositions Method to our extensive collection of RAG (Retrieval-Augmented Generation) tutoria
ls. Our GitHub repository (5.5K ⭐) currently covers 25 different RAG techniques, and this will be a valuable addition. C
heck it out here: https://github.com/NirDiamant/RAG_Techniques
```
---

     
 
all -  [ Episode 0: Open Interpreter Obsidian & Convert Anything ](https://www.reddit.com/r/ToolUse/comments/1f9mr14/episode_0_open_interpreter_obsidian_convert/) , 2024-09-08-0913
```
We pay homage to Open Interpreter, where we met working together, by building a couple of very cool tools that have Open
 Interpreter at the core.

[https://www.youtube.com/watch?v=HjcPRoPfri](https://www.youtube.com/watch?v=HjcPRoPfri)

Ope
n Interpreter Obsidian Plugin - Use Open Interpreter to control your Obsidian vault!

CV - Convert anything to anything 
using the power of Open Interpreter

Friend and Open Glass merge forces

LangChain ambient AI agents UX

Next week, web 
scraping

Code  
[https://github.com/MikeBirdTech/obsidian-open-interpreter](https://github.com/MikeBirdTech/obsidian-op
en-interpreter)  
[https://github.com/tyfiero](https://www.youtube.com/redirect?event=video_description&redir_token=QUFF
LUhqbTl0WHBRUnUxcU1vMUpEZ3VKdUpsRGlvOHJvUXxBQ3Jtc0ttNF9QdGx5VHZxRmlsVjd4TUFjXy0ydS1OWXJNdlMwc3ZRR29yN2g0dUU2Z0NFU0xDNVB0
aHp5VzJMWk95NFVuNHE3U25pVnZRRmxZVUkyc2p5YlJlX0VTQzNiOFEtbG9yLV9xUUFvbzM3T3VDd09wOA&q=https%3A%2F%2Fgithub.com%2Ftyfiero&
v=HjcPRoPfri0)

[https://x.com/tooluseai](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqb
Hh2azBHbjNhdjh2bHNHaW1YVXdSVVhQai1MZ3xBQ3Jtc0tsM0lKMmdYeXB6NUxKR0dHUlJKUmY3UFFteVBLeDZnUkdyOUpqa3BjWFhXdGFyNER6dl9IWUFEU
GlWNnMyak4yWFBXdEs1dGg3RmowNXF5RVd1dzdtUHpkUkVHQVR1RGdrYnVfTTB6bTc3V1BnTGhuaw&q=https%3A%2F%2Fx.com%2Ftooluseai&v=HjcPRo
Pfri0)  
[https://x.com/MikeBirdTech](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbDFTT
1Jta3d1NHcwamZBSW9fRjZKMHZoSTM0UXxBQ3Jtc0tsc0E2YmlXR0xYa0FmQVFuMXJSNGg0eEF1QTNTVERiVHR6bW8za3N3UWJRcTE2RlJPS01ta285MjV0W
GZUWUpOazQ2WmpxNVNfMGpxVXN1c21aRnpESHA5ZVJfX1c1UFhDc0RDSzZHRkZmTU5GcC00OA&q=https%3A%2F%2Fx.com%2FMikeBirdTech&v=HjcPRoP
fri0)  
[https://x.com/FieroTy](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjdyd0Z2VFZ
TTmZ5NzE5V05WZW8xYUc0dlUyUXxBQ3Jtc0tsM2RWeWZOeEFTQzZsWTIzQkVIVHE0Yl9QNkgwVUxPSDBOYmlHOVZsQlZQV3d2VVZjM2hiZTFfZG0wdzcydFZ
ISDFNcFBTbGFzT0xTLU43ZEItQ2J4RUp6TTRGaURyaGZhTEZJbjlld0xzbnlsZlIxNA&q=https%3A%2F%2Fx.com%2FFieroTy&v=HjcPRoPfri0)

# 
```
---

     
 
all -  [ Trouble chunking mixed text documents  ](https://www.reddit.com/r/LangChain/comments/1f9mdt4/trouble_chunking_mixed_text_documents/) , 2024-09-08-0913
```
I'm working on a project where I need to translate (using llm api) long documents stored as text in a PostgreSQL databas
e. These documents contain a mix of regular text and large tables. My main challenge is to preserve the table structure 
during translation and processing, but I'm running into issues with chunking the text, as it often ruins the format of t
he tables. The tables aren’t in a standard format (markdown latex etc) but are just text which an llm can tell is struct
ured from the spacing. However I’m struggling to automate it via spacing as the rest of the doc has lots of formatting t
oo! And I can’t use an llm to chunk it as it’s too long. 

Unsure of this makes any sense!
```
---

     
 
MachineLearning -  [ [P] using GPT4o with langchain/chroma for sports analysis  ](https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/) , 2024-09-08-0913
```
Hi all, I'm working on a side project that helps with sports analysis for historical games, which in turn will help with
 sports betting. Currently I've been only focused on MLB because I wanted to see how the use case would pan out.

My fir
st attempt at this was to use the openai endpoint and load all the relevant JSON objects and send a prompt along with th
em to GPT and see what I get back. Eventually, the context size was getting way too big and the problem I was running in
to was that it was expensive. Although, the prompts back were actually pretty decent and relevant to the data.

My secon
d attempt was to setup a RAG using Chroma/LangChain/GPT4o. I got it to work but the answers all seem very off and super 
vague. None of the data I have was shown in any of the prompts i asked, or any of the players that were playing in a gam
e were mentioned at all in the prompt back, plus it kept mentioning wrong games/teams whe asking it specific games. I’m 
assuming I might need to adjust the vector store a bit but not sure how I can do that with chroma.

My question is what 
might be the best way to setup some sort of process? My end result, I would like a response back using the historical da
ta I've provided to make assumptions on what a game could be like based off all the stats given, with some room for GPT 
to also make some inference as well.

I am a super new at this so it's been a learning process so far; please bear with 
me.
```
---

     
 
deeplearning -  [ Month of August in AI ](https://www.reddit.com/r/deeplearning/comments/1f6zfz0/month_of_august_in_ai/) , 2024-09-08-0913
```
🔍 I**nside this Issue:**

* 🤖 La*test Breakthroughs: *This month it’s all about A*gents, LangChain RAG, and LLMs evaluat
ion challenges.*
* 🌐 AI Monthly News: Discover how these stories are revolutionizing industries and impacting everyday l
ife: E*U AI Act, California’s Controversial SB1047 AI regulation act, Drama at OpenAI, and possible funding at OpenAI by
 Nvidia and Apple.*
* 📚 Editor’s Special: This covers the interesting talks, lectures, and articles we came across recen
tly.

Follow me on Twitter and LinkedIn at [**RealAIGuys**](https://twitter.com/RealAIGuys) and [**AIGuysEditor**](https
://www.linkedin.com/in/vishal-rajput-999164122/) to get insight on new AI developments.

>**Please don't forget to subsc
ribe to our Newsletter:** [**https://medium.com/aiguys/newsletter**](https://medium.com/aiguys/newsletter)

# Latest Bre
akthroughs

Are Agents just simple rules? Are Agents just enhanced reasoning? The answer is yes and no. Yes, in the sens
e that agents have simple rules and can sometimes enhance reasoning capabilities compared to a single prompt. But No in 
the sense that agents can have a much more diverse functionality like using specific tools, summarizing, or even followi
ng a particular style. In this blog, we look into how to set up these agents in a hierarchal manner just like running a 
small team of Authors, researchers, and supervisors.

[**How To Build Hierarchical Multi-Agent Systems?**](https://mediu
m.com/aiguys/how-to-build-hierarchical-multi-agent-systems-dc26b19201d2?sk=90958e39e1a28f5030872a90f8e3f3da)

**TextGrad
**. It is a powerful framework performing automatic “differentiation” via text. **It backpropagates textual feedback pro
vided by LLMs to improve individual components of a compound AI system.** In this framework, LLMs provide rich, general,
 natural language suggestions to optimize variables in computation graphs, ranging from code snippets to molecular struc
tures. TextGrad showed effectiveness and generality across various applications, from question-answering and molecule op
timization to radiotherapy treatment planning.

[**TextGrad: Improving Prompting Using AutoGrad**](https://medium.com/ai
guys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10?sk=3633a9aa63b884c97469bce659265921)

The addition of RAG t
o LLMs was an excellent idea. It helped the LLMs to become more specific and individualized. Adding new components to an
y system leads to more interactions and its own sets of problems. Adding RAG to LLMs leads to several problems such as h
ow to retrieve the best content, what type of prompt to write, and many more.

In this blog, we are going to combine the
 **LangChain RAG with DSPy**. We deep dive into how to evaluate the RAG pipeline quantitatively using **RAGAs** and how 
to create a system where instead of manually tweaking prompts, we let the system figure out the best prompt.

[**How To 
Build LangChain RAG With DSPy?**](https://medium.com/aiguys/how-to-build-langchain-rag-with-dspy-ce9154fbafaa?sk=b41d104
05f84c767cf9cd6a58d1ebac0)

As the field of natural language processing (NLP) advances, the evaluation of large language
 models (LLMs) like GPT-4 becomes increasingly important and complex. Traditional metrics such as accuracy are often ina
dequate for assessing these models’ performance because they fail to capture the nuances of human language. In this arti
cle, we will explore why evaluating LLMs is challenging and discuss effective methods like BLEU and ROUGE for a more com
prehensive evaluation.

[**The Challenges of Evaluating Large Language Models**](https://medium.com/aiguys/the-challenge
s-of-evaluating-large-language-models-ec2eb834a349)

# AI Monthly News

# AI Act enters into force

On 1 August 2024, th
e European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelli
gence development and deployment in the EU. The AI Act introduces a uniform framework across all EU countries, based on 
a forward-looking definition of AI and a risk-based approach:

* **Minimal risk:** most AI systems such as spam filters 
and AI-enabled video games face no obligation under the AI Act, but companies can voluntarily adopt additional codes of 
conduct.
* **Specific transparency risk:** systems like chatbots must clearly inform users that they are interacting wit
h a machine, while certain AI-generated content must be labelled as such.
* **High risk:** high-risk AI systems such as 
AI-based medical software or AI systems used for recruitment must comply with strict requirements, including risk-mitiga
tion systems, high-quality of data sets, clear user information, human oversight, etc.
* **Unacceptable risk:** for exam
ple, AI systems that allow “social scoring” by governments or companies are considered a clear threat to people’s fundam
ental rights and are therefore banned.

**EU announcement:** [**Click here**](https://commission.europa.eu/news/ai-act-e
nters-force-2024-08-01_en)

https://preview.redd.it/nwyzfzgm4cmd1.png?width=828&format=png&auto=webp&s=c873db37ca0dadd5b
510bea70ac9f633b96aaea4

# California AI bill SB-1047 sparks fierce debate, Senator likens it to ‘Jets vs. Sharks’ feud


**Key Aspects of SB-1047:**

* Regulation Scope: Targets “frontier” AI models, defined by their immense computational t
raining requirements (over 10²⁶ operations) or significant financial investment (>$100 million).
* Compliance Requiremen
ts: Developers must implement safety protocols, including the ability to immediately shut down, cybersecurity measures, 
and risk assessments, before model deployment.
* Whistleblower Protections: Encourages reporting of non-compliance or ri
sks by offering protection against retaliation.
* Safety Incident Reporting: Mandates reporting AI safety incidents with
in 72 hours to a newly established Frontier Model Division.
* Certification: Developers need to certify compliance, pote
ntially under penalty of perjury in earlier drafts, though amendments might have altered this.

**Pros:**

* Safety Firs
t: Prioritizes the prevention of catastrophic harms by enforcing rigorous safety standards, potentially safeguarding aga
inst AI misuse or malfunction.
* Incentivizes Responsible Development: By setting high standards for AI model training, 
the company encourages developers to think critically about the implications of their creations.
* Public Trust: Enhance
s public confidence in AI by ensuring transparency and accountability in the development process.

**Cons:**

* Innovati
on Stagnation: Critics argue it might stifle innovation, especially in open-source AI, due to the high costs and regulat
ory burdens of compliance.
* Ambiguity: Some definitions and requirements might be too specific or broad, leading to leg
al challenges or unintended consequences.
* Global Competitiveness: There’s concern that such regulations could push AI 
development outside California or the U.S., benefiting other nations without similar restrictions.
* Implementation Chal
lenges: The practicalities of enforcing such regulations, especially the “positive safety determination,” could be compl
ex and contentious.

**News Article:** [**Click here**](https://www.thenation.com/article/society/sb-1047-ai-big-tech-fi
ght/)

**Open Letter:** [**Click here**](https://safesecureai.org/open-letter)

https://preview.redd.it/ib96d7nk4cmd1.pn
g?width=828&format=png&auto=webp&s=0ed5913b5dae72e203c8592393e469d9130ed689

# MORE OpenAI drama

OpenAI co-founder John
 Schulman has left the company to join rival AI startup Anthropic, while OpenAI president and co-founder Greg Brockman i
s taking an extended leave until the end of the year. Schulman, who played a key role in creating the AI-powered chatbot
 platform ChatGPT and led OpenAI’s alignment science efforts, stated his move was driven by a desire to focus more on AI
 alignment and hands-on technical work. Peter Deng, a product manager who joined OpenAI last year, has also left the com
pany. With these departures, only three of OpenAI’s original 11 founders remain: CEO Sam Altman, Brockman, and Wojciech 
Zaremba, lead of language and code generation.

**News Article:** [**Click here**](https://techcrunch.com/2024/08/05/ope
nai-co-founder-leaves-for-anthropic/)

https://preview.redd.it/0vdjc18j4cmd1.png?width=828&format=png&auto=webp&s=e9de60
4c26aed3e47b50df3bdf114ef61f967080

# Apple and Nvidia may invest in OpenAI

Apple, which is planning to integrate ChatG
PT into iOS, is in talks to invest. Soon after, [*Bloomberg* also](https://www.bloomberg.com/news/articles/2024-08-29/nv
idia-has-held-discussions-about-joining-openai-s-funding-round?srnd=homepage-americas) reported that Apple is in talks b
ut added that Nvidia “has discussed” joining the funding round as well. The round is reportedly being led by Thrive Capi
tal and would value OpenAI at more than $100 billion.

**News Article:** [**Click here**](https://www.theverge.com/2024/
8/29/24231626/apple-nvidia-openai-invest-microsoft)

https://preview.redd.it/ude6jguh4cmd1.png?width=828&format=png&auto
=webp&s=3603cbca0dbb1be3e6d0efcf06c3a698428bbdd6

# Editor’s Special

* The AI Bubble: Will It Burst, and What Comes Aft
er?: [**Click here**](https://www.youtube.com/watch?v=91SK90SahHc&t=317s)
* Eric Schmidt Full Controversial Interview on
 AI Revolution (Former Google CEO): [**Click here**](https://www.youtube.com/watch?v=mKVFNg3DEng)
* AI isn’t gonna keep 
improving [**Click here**](https://www.youtube.com/watch?v=Y8Ym7hMR100)
* General Intelligence: Define it, measure it, b
uild it: [**Click here**](https://www.youtube.com/watch?v=nL9jEy99Nh0)
```
---

     
 
deeplearning -  [ Creating a project on NLP ](https://www.reddit.com/r/deeplearning/comments/1ey2e85/creating_a_project_on_nlp/) , 2024-09-08-0913
```
So me and my friend completed the ML and DL specialization by AndrewNg, and were just gonna get started on a project. We
 decided to make a academic assistant. So basically what this does is a user can upload a PDF,text file or any other sup
ported media and the can ask questions related to it's contents. The main objective being making learning quick given la
rger documents.

The pipeline we decided is pretty standard for such a project.

1. Split the text into chunks
2. Genera
te embeddings of the chunks
3. Store the chunks in a vector DB
4. Find the top K similar chunks to the query 
5. Retriev
e context and feed it into a LLM for an answer.

So I looked up for a library and framework to use and decided on langch
ain. We haven't decided on an LLM yet but want to run it locally so no OpenAI please. 

Since this is gonna be out first
 AI project confidence is low. I would really appreciate any heads up on the issues we may face, any suggestions on libr
aries,frameworks or models will be really helpful as well. 

Appreciate any resourceful comment 😊
```
---

     
