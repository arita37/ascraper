 
all -  [ Token Limits, Consistency, & LLM in Code ](https://www.reddit.com/r/ChatGPTPro/comments/1cnhxqt/token_limits_consistency_llm_in_code/) , 2024-05-09-0910
```
**If you don’t want to read:**

* How do I address token limits without reducing tokens? Also, can someone explain top p
?
* How to improve custom GPT consistency and quantitatively measure it? I heard about temperature but what else?
* Wher
e to start for implementing LLM in code? 

**Context**

TOKEN LIMITS - I need to input over hundreds of thousands or eve
n millions of tokens in a single run (via excel/csv file). Maximum split it up into like 5-10 runs. Despite higher token
 limits, it gets lazy, gives errors, etc. 

CONSISTENCY - Custom GPT outputs are inconsistent and I need more consistenc
y. I heard about temperature and gave GPT an examples set but its still fairly inconsistent and I want to know how to me
asure this more rigorously.

LLM in PYTHON - I have experience with Python but not LLM in python. Should I start with La
ngChain and what resources should I follow? I want to experiment with this although my main concern later on is my team 
doesn’t code so I don’t know how sustainable a 'code built model' would be in the long term.

...... 

THANK YOU!
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses ](https://www.reddit.com/r/udemyfreebies/comments/1cnhul6/list_of_free_and_best_selling_discounted_courses/) , 2024-05-09-0910
```
## Udemy Free Courses for 09 May 2024

*Note : Coupons might expire anytime, so enroll as soon as possible to get the co
urses for FREE.*

* Crea sistemas Ecommerce con PHP y MySQL V2.0[REDEEM OFFER](https://idownloadcoupon.com/udemy/4790/)

* Curso Google Sites 2024: Cómo Crear Páginas Web Desde Cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/4789/)
* Cu
rso de Wix 2024: Cómo Crear una Página Web Desde Cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/4788/)
* Wealth Ma
nagement, Private Banking & Compliance Introduction[REDEEM OFFER](https://idownloadcoupon.com/udemy/4787/)
* Information
 Security Fundamentals[REDEEM OFFER](https://idownloadcoupon.com/udemy/4786/)
* Professional Diploma of Product & Servic
e Business Analyst[REDEEM OFFER](https://idownloadcoupon.com/udemy/4785/)
* Arduino Practice Test: Get Certified and Tes
t Your Skills[REDEEM OFFER](https://idownloadcoupon.com/udemy/4784/)
* Automatic Irrigation System with Arduino[REDEEM O
FFER](https://idownloadcoupon.com/udemy/4783/)
* Sales: Your First 90 Days as a New Sales Representative[REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/4782/)
* The Art of Building and Sustaining Meaningful Relationships[REDEEM OFFER](http
s://idownloadcoupon.com/udemy/4781/)
* Skills Economy: Transforming to a Skills-based Organization[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/4780/)
* Body Language / Non-Verbal Communication for Business[REDEEM OFFER](https://idownloa
dcoupon.com/udemy/4779/)
* Agile Ways of Working Workshop – Practical Guide[REDEEM OFFER](https://idownloadcoupon.com/ud
emy/4777/)
* Immigrants Guide to a Successful Career in Corporate America[REDEEM OFFER](https://idownloadcoupon.com/udem
y/4776/)
* Professional Diploma of Real Estate Business Expert[REDEEM OFFER](https://idownloadcoupon.com/udemy/4775/)
* 
Masters in Structural Engineering & Drawing Reading – Etabs[REDEEM OFFER](https://idownloadcoupon.com/udemy/4774/)
* Bec
oming an Agile Leader: Drive Outcomes and Bring Impact[REDEEM OFFER](https://idownloadcoupon.com/udemy/4773/)
* Agile Tr
ansformation A to Z | How To Make Any Company Agile[REDEEM OFFER](https://idownloadcoupon.com/udemy/4772/)
* Ultimate Mi
ro Guide: Enhance Team Productivity & Agility[REDEEM OFFER](https://idownloadcoupon.com/udemy/4771/)
* Professional Dipl
oma in Procurement, Sourcing, Supply Chains[REDEEM OFFER](https://idownloadcoupon.com/udemy/4770/)
* Google Search Maste
ry Course : Find Answers 10X Times Faster[REDEEM OFFER](https://idownloadcoupon.com/udemy/4769/)
* Mastering LangChain a
nd AWS: A Guide to Economic Analysis[REDEEM OFFER](https://idownloadcoupon.com/udemy/4768/)
* Full Paid Ads Course – Goo
gle, Meta, Microsoft, LinkedIn[REDEEM OFFER](https://idownloadcoupon.com/udemy/4767/)
* Microsoft Ads MasterClass – All 
Campaigns & Features[REDEEM OFFER](https://idownloadcoupon.com/udemy/4766/)
* Google Ads Crash Course – Campaign Creatio
ns[REDEEM OFFER](https://idownloadcoupon.com/udemy/4765/)
* Professional Diploma of Virtual Executive Assistant[REDEEM O
FFER](https://idownloadcoupon.com/udemy/4764/)
* Professional Diploma in M&A Business Mergers & Acquisitions[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/4763/)
* Applied Generative AI and Natural Language Processing[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/4762/)
* A Crash Course in Writing Well[REDEEM OFFER](https://idownloadcoupon.com/udemy/4761
/)
* Ethical Hacking: Windows Exploitation Basics[REDEEM OFFER](https://idownloadcoupon.com/udemy/4760/)
* Ethical Hacki
ng: Reverse Shells[REDEEM OFFER](https://idownloadcoupon.com/udemy/4759/)
* Linux Terminal for beginners[REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/4758/)
```
---

     
 
all -  [ Using Airtable data as a vector database for Chatbot Knowledge Base ](https://www.reddit.com/r/LangChain/comments/1cnhb5a/using_airtable_data_as_a_vector_database_for/) , 2024-05-09-0910
```
Hello AI peeps, I need some help/advice. I’m building a fairly comprehensive chatbot which includes a RAG QnA component.
 All knowledge base data is in an Airtable, where each row/record is another piece of knowledge. 

The plan is to vector
ize the knowledge base to Pinecone via Flowise Upsert and then retrieve with OpenAI Embeddings. 

The main issue is that
 I can’t figure out how to use the columns as seperate metadata keys instead of all being vectorized in 1 piece. Is ther
e an easy solution to accomplish this? Is there a better approach overall to convert the data from Airtable into a RAG k
nowledge base? Any help would be appreciated! I mentioned Flowise because it’s the simplest way to use Langchain.
```
---

     
 
all -  [ Mastering LangChain and AWS: A Guide to Economic Analysis ](https://www.reddit.com/r/udemyfreebies/comments/1cnh8wm/mastering_langchain_and_aws_a_guide_to_economic/) , 2024-05-09-0910
```
Mastering LangChain and AWS: A Guide to Economic Analysis

https://idownloadcoupon.com/udemy/4768/
```
---

     
 
all -  [ create a 'default' or 'else' tool for ReAct agent ](https://www.reddit.com/r/LangChain/comments/1cngb56/create_a_default_or_else_tool_for_react_agent/) , 2024-05-09-0910
```
I am working on a ReAct agent that will have a couple of pre-defined tools to perform specific actions BUT we need to ha
ve some kind of 'default' or 'else' tool, what I mean is: if non of the pre-defined tools is selected by the agent then 
it will try to answer the user query using the 'else' tool, the idea is that there are some pre-defined and well known a
ctions that will be executed by the agent when tue user query matches those fine, but if there is not  a good match we s
till want the agent to be able to come up with the best answer possible(inbstead of something like: I cannot answer this
 question because I don't have a tool for it). Any ideas? I'm thinking on something as a   
`GeneralHandlerTool(BaseTool
):`  
`def _run():`  
   `....`
```
---

     
 
all -  [ RAG (evaluate intermediate steps) | LangSmith Evaluations - Part 16 ](https://www.youtube.com/watch?v=yx3JMAaNggQ) , 2024-05-09-0910
```

```
---

     
 
all -  [ Master New Skills: Access 100+ Free Udemy and Coursera Courses with Certificates ](https://www.reddit.com/r/Udemy/comments/1cnesdo/master_new_skills_access_100_free_udemy_and/) , 2024-05-09-0910
```
Microsoft Ads MasterClass – All Campaigns & Features

[https://courze.org/microsoft-ads-masterclass-2024-all-campaigns-f
eatures/](https://courze.org/microsoft-ads-masterclass-2024-all-campaigns-features/)

&#x200B;

Full Paid Ads Course – G
oogle, Meta, Microsoft, LinkedIn

[https://courze.org/full-paid-ads-course-google-facebook-microsoft-linkedin/](https://
courze.org/full-paid-ads-course-google-facebook-microsoft-linkedin/)

&#x200B;

Google Search Mastery Course : Find Answ
ers 10X Times Faster

[https://courze.org/google-search-mastery-course-find-answers-10x-times-faster/](https://courze.or
g/google-search-mastery-course-find-answers-10x-times-faster/)

&#x200B;

Mastering LangChain and AWS: A Guide to Econom
ic Analysis

[https://courze.org/mastering-langchain-and-aws-a-guide-to-economic-analysis/](https://courze.org/mastering
-langchain-and-aws-a-guide-to-economic-analysis/)

&#x200B;

React: All You Need to Know with Practical Project

[https:
//courze.org/react-all-you-need-to-know-with-practical-project/](https://courze.org/react-all-you-need-to-know-with-prac
tical-project/)

&#x200B;

PyTorch Ultimate 2024: From Basics to Cutting-Edge

[https://courze.org/pytorch-ultimate-2024
-from-basics-to-cutting-edge/](https://courze.org/pytorch-ultimate-2024-from-basics-to-cutting-edge/)

&#x200B;

Google 
Ads Crash Course – Campaign Creations

[https://courze.org/google-ads-crash-course-campaign-creations/](https://courze.o
rg/google-ads-crash-course-campaign-creations/)

&#x200B;

A Crash Course in Writing Well

[https://courze.org/a-crash-c
ourse-in-writing-well/](https://courze.org/a-crash-course-in-writing-well/)

&#x200B;

Applied Generative AI and Natural
 Language Processing

[https://courze.org/applied-generative-ai-and-natural-language-processing/](https://courze.org/app
lied-generative-ai-and-natural-language-processing/)

&#x200B;

Professional Diploma in Procurement, Sourcing, Supply Ch
ains

[https://courze.org/professional-diploma-in-procurement-sourcing-supply-chains/](https://courze.org/professional-d
iploma-in-procurement-sourcing-supply-chains/)

&#x200B;

Professional Diploma of Real Estate Business Expert

[https://
courze.org/professional-diploma-of-real-estate-business-expert/](https://courze.org/professional-diploma-of-real-estate-
business-expert/)

&#x200B;

Masters in Structural Engineering & Drawing Reading – Etabs

[https://courze.org/diploma-in
-structural-drawing-reading-like-expert-etabs/](https://courze.org/diploma-in-structural-drawing-reading-like-expert-eta
bs/)

&#x200B;

Information Security Fundamentals

[https://courze.org/information-security-fundamentals/](https://courz
e.org/information-security-fundamentals/)

&#x200B;

Ultimate Miro Guide: Enhance Team Productivity & Agility

[https://
courze.org/ultimate-miro-guide-enhance-team-productivity-agility/](https://courze.org/ultimate-miro-guide-enhance-team-p
roductivity-agility/)

&#x200B;

Becoming an Agile Leader: Drive Outcomes and Bring Impact

[https://courze.org/becoming
-an-agile-leader-drive-outcomes-and-bring-impact/](https://courze.org/becoming-an-agile-leader-drive-outcomes-and-bring-
impact/)

&#x200B;

Overcoming Obstacles & Building Resilience as a Team

[https://courze.org/overcoming-obstacles-build
ing-resilience-as-a-team/](https://courze.org/overcoming-obstacles-building-resilience-as-a-team/)

&#x200B;

Agile Ways
 of Working Workshop – Practical Guide

[https://courze.org/agile-ways-of-working-workshop-practical-guide/](https://cou
rze.org/agile-ways-of-working-workshop-practical-guide/)

&#x200B;

Agile Transformation A to Z | How To Make Any Compan
y Agile

[https://courze.org/agile-transformation-a-to-z-how-to-make-any-company-agile/](https://courze.org/agile-transf
ormation-a-to-z-how-to-make-any-company-agile/)

&#x200B;

The Complete Jenkins DevOps CI/CD Pipeline Bootcamp – 2024

[
https://courze.org/the-complete-jenkins-devops-ci-cd-pipeline-bootcamp-2023/](https://courze.org/the-complete-jenkins-de
vops-ci-cd-pipeline-bootcamp-2023/)

&#x200B;

Body Language / Non-Verbal Communication for Business

[https://courze.or
g/body-language-non-verbal-communication-for-business/](https://courze.org/body-language-non-verbal-communication-for-bu
siness/)

&#x200B;

Sales: Your First 90 Days as a New Sales Representative

[https://courze.org/sales-your-first-90-day
s-as-a-new-sales-representative/](https://courze.org/sales-your-first-90-days-as-a-new-sales-representative/)

&#x200B;


Defining Project Scope and Managing Resources for Project

[https://courze.org/defining-project-scope-and-managing-reso
urces-for-project-2/](https://courze.org/defining-project-scope-and-managing-resources-for-project-2/)

&#x200B;

Defini
ng Project Scope and Managing Resources for Project

[https://courze.org/defining-project-scope-and-managing-resources-f
or-project/](https://courze.org/defining-project-scope-and-managing-resources-for-project/)

&#x200B;

Crea paginas de v
entas para vender productos digi en Hotmart

[https://courze.org/crea-paginas-de-ventas-para-vender-productos-digi-en-ho
tmart/](https://courze.org/crea-paginas-de-ventas-para-vender-productos-digi-en-hotmart/)

&#x200B;

Wealth Management, 
Private Banking & Compliance Introduction

[https://courze.org/wealth-management-private-banking-compliance-introduction
/](https://courze.org/wealth-management-private-banking-compliance-introduction/)

&#x200B;

Professional Diploma in Dig
ital Business Development

[https://courze.org/professional-diploma-in-digital-business-development/](https://courze.org
/professional-diploma-in-digital-business-development/)

&#x200B;

Cómo Crear una Academia Online con WordPress y Tutor 
LMS

[https://courze.org/como-crear-una-academia-online-con-wordpress-y-tutor-lms/](https://courze.org/como-crear-una-ac
ademia-online-con-wordpress-y-tutor-lms/)

&#x200B;

Máster en Diseño Web con Inteligencia Artificial 2024

[https://cou
rze.org/master-en-diseno-web-con-inteligencia-artificial-2024/](https://courze.org/master-en-diseno-web-con-inteligencia
-artificial-2024/)

&#x200B;

Máster en Comercio Electrónico con WordPress 2024

[https://courze.org/master-en-comercio-
electronico-con-wordpress/](https://courze.org/master-en-comercio-electronico-con-wordpress/)

&#x200B;

Cómo Crear un B
log con WordPress Para Principiantes 2024

[https://courze.org/como-crear-un-blog-con-wordpress-para-principiantes-2023/
](https://courze.org/como-crear-un-blog-con-wordpress-para-principiantes-2023/)

&#x200B;

Revolutionize PCB Design with
 Generative AI: Future of PCB

[https://courze.org/revolutionize-pcb-design-with-generative-ai-future-of-pcb/](https://c
ourze.org/revolutionize-pcb-design-with-generative-ai-future-of-pcb/)

&#x200B;

Autonomous Mastery: Steering the Future
 of Self-Driving Cars

[https://courze.org/autonomous-mastery-steering-the-future-of-self-driving-cars/](https://courze.
org/autonomous-mastery-steering-the-future-of-self-driving-cars/)

&#x200B;

Professional Diploma of Product & Service B
usiness Analyst

[https://courze.org/professional-diploma-of-product-service-business-analyst/](https://courze.org/profe
ssional-diploma-of-product-service-business-analyst/)

&#x200B;

CSS, Bootstrap, JavaScript And PHP Stack Complete Cours
e

[https://courze.org/css-bootstrap-javascript-and-php-stack-complete-course/](https://courze.org/css-bootstrap-javascr
ipt-and-php-stack-complete-course/)

&#x200B;

Elementor Kits: Crea una Página Web con Elementor Pro

[https://courze.or
g/elementor-kits-crea-una-pagina-web-con-elementor-pro/](https://courze.org/elementor-kits-crea-una-pagina-web-con-eleme
ntor-pro/)

&#x200B;

OEE-Management (English)

[https://courze.org/oee-management-english/](https://courze.org/oee-mana
gement-english/)

&#x200B;

Online Marketing mit ChatGPT

[https://courze.org/online-marketing-mit-chatgpt/](https://cou
rze.org/online-marketing-mit-chatgpt/)

&#x200B;

Master Course : Carbon Accounting for ESG Professionals 101

[https://
courze.org/master-course-carbon-accounting-for-esg-professionals-101/](https://courze.org/master-course-carbon-accountin
g-for-esg-professionals-101/)

&#x200B;

Master Course in Cargo, Truck and Warehouse Management 2.0

[https://courze.org
/master-course-in-cargo-truck-and-warehouse-management-2-0/](https://courze.org/master-course-in-cargo-truck-and-warehou
se-management-2-0/)

&#x200B;

CDPO Course 101 : Certified Data Protection Officer

[https://courze.org/cdpo-course-101-
certified-data-protection-officer/](https://courze.org/cdpo-course-101-certified-data-protection-officer/)

&#x200B;

&#
x200B;
```
---

     
 
all -  [ How to make Chat Prompt Template use data from JSON file?  ](https://www.reddit.com/r/flowise/comments/1cnd8el/how_to_make_chat_prompt_template_use_data_from/) , 2024-05-09-0910
```
I have the following setup. Desired result is having the chat respond based on the prompt (to be added in Human message)
, where I'll specify how characters from gameconfig.json should interact based on values from the same JSON. 

https://p
review.redd.it/sy974lxp89zc1.png?width=1950&format=png&auto=webp&s=02f5a7c44fdfcd827573bd6cec081a1a0b694e8a


```
---

     
 
all -  [ How can I access the output while the code is running? ](https://www.reddit.com/r/LangChain/comments/1cncubh/how_can_i_access_the_output_while_the_code_is/) , 2024-05-09-0910
```
During runtime, I can see, what chain is being executed. I need that information being displayed for further steps. Do y
ou know how can I access the output text while the code is being executed?
```
---

     
 
all -  [ Agent unable to access the internet ](https://www.reddit.com/r/AI_Agents/comments/1cn8ohe/agent_unable_to_access_the_internet/) , 2024-05-09-0910
```
Hey everybody ,

  
I've  built a search internet tool with EXA and although the API key seems to  work , my agent indic
ates  that he can't use it. 

Any help would be appreciated as I am beginner when it comes to coding. 

Here are the cod
es that I've used for the search tools and the agents using crewAI. 

Thank you in advance for your help : 

    import 
os
    from exa_py import Exa
    from langchain.agents import tool
    from dotenv import load_dotenv
    load_dotenv()

    
    class ExasearchToolSet():
        def _exa(self):
            return Exa(api_key=os.environ.get('EXA_API_KEY')
)
        @tool
        def search(self,query:str):
            '''Useful to search the internet about a a given topic a
nd return relevant results'''
            return self._exa().search(f'{query}',
                    use_autoprompt=True,
num_results=3)
        @tool
        def find_similar(self,url: str):
            '''Search for websites similar to url.

            the url passed in should be a URL returned from 'search''''
            return self._exa().find_similar(url
,num_results=3)
        @tool
        def get_contents(self,ids: str):
            '''gets content from website.
       
        the ids should be passed as a list,a list of ids returned from 'search''''
            ids=eval(ids)
           
 contents=str(self._exa().get_contents(ids))
            contents=contents.split('URL:')
            contents=[content[:
1000] for content in contents]
            return '\n\n'.join(contents)
    

    
    class TravelAgents:
    
        
def __init__(self):
            self.OpenAIGPT35 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7)
            

            
    
        def expert_travel_agent(self):
            return Agent(
                role='Expert travel a
gent',
                backstory=dedent(f'''I am an Expert in travel planning and logistics, 
                          
      I have decades experiences making travel itineraries,
                                I easily identify good deals
,
                                My purpose is to help the user to profit from a marvelous trip at a low cost'''),
    
            goal=dedent(f'''Create a 7-days travel itinerary with detailed per-day plans,
                              
  Include budget , packing suggestions and safety tips'''),
                tools=[ExasearchToolSet.search,ExasearchTool
Set.get_contents,ExasearchToolSet.find_similar,perform_calculation],
                allow_delegation=True,
            
    verbose=True,llm=self.OpenAIGPT35,
                )
            
    
        def city_selection_expert(self):
    
        return Agent(
                role='City selection expert',
                backstory=dedent(f'''I am a city sel
ection expert,
                                I have traveled across the world and gained decades of experience.
      
                          I am able to suggest the ideal destination based on the user's interests, 
                   
             weather preferences and budget'''),
                goal=dedent(f'''Select the best cities based on weather
, price and user's interests'''),
                tools=[ExasearchToolSet.search,ExasearchToolSet.get_contents,Exasearch
ToolSet.find_similar,perform_calculation]
                       ,
                allow_delegation=True,
              
  verbose=True,
                llm=self.OpenAIGPT35,
            )
        def local_tour_guide(self):
            retu
rn Agent(
                role='Local tour guide',
                backstory=dedent(f''' I am the best when it comes to 
provide the best insights about a city and 
                                suggest to the user the best activities base
d on their personal interest 
                                 '''),
                goal=dedent(f'''Give the best insig
hts about the selected city
                            '''),
                tools=[ExasearchToolSet.search,ExasearchTo
olSet.get_contents,ExasearchToolSet.find_similar,perform_calculation]
                       ,
                allow_del
egation=False,
                verbose=True,
                llm=self.OpenAIGPT35,
            )
    

    
    
    
```
---

     
 
all -  [ changing state attributes in langgraph conditional edge? ](https://www.reddit.com/r/LangChain/comments/1cn7cjy/changing_state_attributes_in_langgraph/) , 2024-05-09-0910
```
Hey all

Im fairly new to langchain and langgraph and have a question about changing state attributes in conditional edg
e nodes  


i have this code, where im deciding if i like the answer, if i dont, i would like to return the state to ret
urn to, but also manipulate a state attribute

 

def decide\_if\_answer\_acceptable\_node(state: GraphState):  
 '''  

Determines if answer is acceptable  
   
Args  
state (dict): The current state of the graph  
   
Returns:  
str: Binar
y decision for the next node to call  
'''  
   
 if state\['answerok'\] == False or state\['answerok'\] == 'False':  
s
tate\['answer'\] = 'not OK' # <--- can i alter state attributes here?  
return 'noanswer'   
 else:  
return 'answer'   



And its linked like so:  


workflow.add\_conditional\_edges(  
 'answer\_grader\_llm\_node',  
 decide\_if\_answer\_
acceptable\_node,  
{  
 'noanswer': END,  
 'answer': END  
},  
)  


  
I understand i could blank the answer in the 
'noanswer' node, but i would like to understand if its possible to set this in the conditional edge function so i can ke
ep my code more compact?

&#x200B;

Thanks! 

&#x200B;

&#x200B;

&#x200B;
```
---

     
 
all -  [ Evaluation for RAG for extraction and restricted responses ](https://www.reddit.com/r/LangChain/comments/1cn6lau/evaluation_for_rag_for_extraction_and_restricted/) , 2024-05-09-0910
```
So, I made an information extraction system where basically, when I upload a technical data sheet of a construction mate
rial through streamlit, the LLM generates a text string in .csv format containing the attributes of the material that I 
defined to extract through the prompts (which are already embedded so it's not a Q&A system). And I linked the response 
with Gspread so that the string is automatically exported to google sheets in correct order. 

I tested and the prototyp
e is working as intended but the problem is with the evaluation of the system. Since it's part of a thesis project, I ha
ve to demonstrate how well the proposed system is performing based on certain metrics, but I am finding difficulty in lo
oking for a quantitively evaluated method that suits this use case scenario. What I want to do is to compare the perform
ances of different LLMs that are being used for the generation as well as assessing the retrieval portion of the system.


Obviously, I'm not well-versed in this area so any help is appreciated. 
```
---

     
 
all -  [ In you opinion what is the best way to interact with Anthropic models in Go? ](https://www.reddit.com/r/golang/comments/1cn5nvn/in_you_opinion_what_is_the_best_way_to_interact/) , 2024-05-09-0910
```
Hi everyone!  
I am creating a new SaaS in Go ( and it has been a pleasure, I love it so much ) and right now I need to 
interact with Opus model from Anthropic.

If you already have used, what is a good way to start?  
Simple HTTP requests 
/ some library like [https://github.com/liushuangls/go-anthropic](https://github.com/liushuangls/go-anthropic) or just u
se Langchain ( used in Python - it was a huge mess with what was happening behind the scenes ) ?

thanks!!
```
---

     
 
all -  [ How to make LLM answers more creative and find answers from the internet ](https://www.reddit.com/r/LangChain/comments/1cn3d2x/how_to_make_llm_answers_more_creative_and_find/) , 2024-05-09-0910
```
I am using Langchain to load PDF files and ask questions using RetrievalQA but when I ask to generate a solution or be c
reative it does not .It looks like it is limited to the content of the provided files only. Is there a limitation for Re
rtievalQA or just an issue with my prompts ?


```
---

     
 
all -  [ Any LangFlow update planned for LangGraph? ](https://www.reddit.com/r/LangChain/comments/1cn21xp/any_langflow_update_planned_for_langgraph/) , 2024-05-09-0910
```
Current LangGraph is just libraries for multiple Agents functionality built on Langchain but it can be more useful to ha
ve GUI within LangFlow. Any attempt to expand LangFlow with LangGraph? 
```
---

     
 
all -  [ Extract tables from PDF for RAG ](https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/) , 2024-05-09-0910
```
To my fellow experts, I am having trouble to extract tables from PDF. I know there are some packages out there that clai
m to do the job, but I can’t seem to get good results from it. Moreover, my work laptop kinda restrict on installation o
f softwares and the most I can do is download open source library package.  Wondering if there are any straightforward w
ays on how to do that ? Or I have to a rite the code from scratch to process the tables but there seem to be many types 
of tables I need to consider. 

Here are the packages I tried and the reasons why they didn’t work. 

1. Pymupdf- messy 
table formatting, can misinterpret title of the page as column headers
2. Tabula/pdfminer- same performance as Pymupdf 

3. Camelot- I can’t seem to get it to work given that it needs to download Ghostscript and tkinter, which require admin 
privilege which is blocked in my work laptop. 
4. Unstructured- complicated setup as require a lot of dependencies and t
hey are hard to set up 
5. Llamaparse from llama: need cloud api key which is blocked 

I tried converting pdf to html b
ut can’t seem to identify the tables very well. 

Please help a beginner 🥺



 
```
---

     
 
all -  [ Choosing Between LLama CPP and Ctransformers for GPU-based LLama2/LLama3 Model Execution ](https://www.reddit.com/r/LangChain/comments/1cn08m1/choosing_between_llama_cpp_and_ctransformers_for/) , 2024-05-09-0910
```
If we are using a GPU for running the LLama2/LLama3 model, which library should I use? LLama CPP or Ctransformers? I'm a
 bit confused about both of these libraries. Can anyone please clear my doubt?
```
---

     
 
all -  [ Deep Dive: Building Affiliate.ai, a GenAI-Powered Affiliate Marketing Analytics Tool ](https://www.reddit.com/r/LangChain/comments/1cn04dj/deep_dive_building_affiliateai_a_genaipowered/) , 2024-05-09-0910
```
Hey everyone! I recently wrote a blog post about [Affiliate.ai](http://affiliate.ai/), a chat-based affiliate marketing 
analytics tool we've been working on. It simplifies the analytics process, letting you ask natural language questions an
d get insights, reports, and even spreadsheets delivered right within Microsoft Teams or Slack.

But the interesting par
t (for this audience, at least) is how it works under the hood. Here's a breakdown of some key elements:

* **Intent Dis
cernment with Function Calling:** We use simple function calling to quickly determine whether a user wants data or is ju
st chatting, ensuring the bot stays focused.
* **LLM-Powered Named Entity Recognition:** Instead of complex pipelines, w
e feed the LLM a list of advertisers and let it figure out the matches– surprisingly effective!
* **Query Reconstruction
 for Context:** Understanding context is tricky. We use a dedicated module to rewrite queries based on chat history.
* *
*Parallelization for Speed:** We run multiple potential routes simultaneously, speeding up response times dramatically.


Interested in the specifics? The full blog post has more details (link below). If you're building similar GenAI apps, I
'd love to hear about your approaches and techniques!

[https://www.affiliate.ai/post/a-technical-deepdive-into-affiliat
e-ai](https://www.affiliate.ai/post/a-technical-deepdive-into-affiliate-ai)
```
---

     
 
all -  [ LangChain with OpenAI not return full products in RAG QnA ](https://www.reddit.com/r/LangChain/comments/1cmzazp/langchain_with_openai_not_return_full_products_in/) , 2024-05-09-0910
```
0

I used the Python LangChain UnstructuredURLLoader to retrieve all our products on the company website for RAG purpose
s. The products were on different pages in the company website.

UnstructuredURLLoader was able to retrieve the products
 in multiple Document objects before they were chunked, embedded and stored in the vector database.

With the OpenAI LLM
 and RAG module, I asked the AI, **'How many products in the company A?' AI replied 'There are 11 products. You should c
heck the company A website for more info...'**

If I asked 'Please list all the products in the company A', AI replied t
he list of the 11 products only.

The problem is, there are more than 11 products. Why can't LLM read and aggregate the 
products in the Documents to count and to return all of the products?

Is there any context hint or prompt to tell LLM t
o read and return all products? Is it because of the chunking process?
```
---

     
 
all -  [ Node JS Support  ](https://www.reddit.com/r/LangChain/comments/1cmz6uh/node_js_support/) , 2024-05-09-0910
```
I am working on a Nextjs demo app that needs to use inference on a custom LLM I will train. When I deploy it, I’m planni
ng on using Baseten but for local development I am now considering  using Lanchain in Node (as opposed to setting up a F
lask server to handle inference and stream the responses back). Has anyone used it before? Is it a total disaster? know 
it’s not going to be as good as the Python version but maybe it’s good enough for my situation. 
```
---

     
 
all -  [ Discussion: Declaratively orchestrate your code instead of using LCEL  ](https://www.reddit.com/r/LangChain/comments/1cmyi9k/discussion_declaratively_orchestrate_your_code/) , 2024-05-09-0910
```
Hi All,

I'd be curious to discuss what peoples' thoughts would be on the following API to express their LLM workflows i
n place of LCEL. LangChain has the kitchen sink of things, so useful for that, but I haven't been fond of LCEL...

**LCE
L** - it's terse, but it pains me to come back to the code each time to figure out what it's going on. Then if I want to
 do anything complex it gets worse. Simple example from the docs:

    from langchain_core.output_parsers import StrOutp
utParser
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.runnables import RunnablePass
through
    from langchain_openai import ChatOpenAI
    
    prompt = ChatPromptTemplate.from_template(
        'Tell me
 a short joke about {topic}')
    output_parser = StrOutputParser()
    model = ChatOpenAI(model='gpt-3.5-turbo')
    ch
ain = (
        {'topic': RunnablePassthrough()}
        | prompt
        | model
        | output_parser
    )
    if _
_name__ == '__main__':
        print(chain.invoke('ice cream'))

What about this **declarative API**, using a framework 
called [Hamilton](https://github.com/dagworks-inc/hamilton/) (note: I'm one of the authors)- it's more verbose, but I ca
n always clearly see how things connect and make modifications --  Hamilton knows which function to call when stitching 
things together based on the  function name and function input arguments -- as you write functions you 'declare' what th
ey are and what they require.

    # hamilton_invoke.py
    from typing import List
    
    import openai
    
    
   
 def llm_client() -> openai.OpenAI:
        return openai.OpenAI()
    
    
    def joke_prompt(topic: str) -> str:
   
     return f'Tell me a short joke about {topic}'
    
    
    def joke_messages(joke_prompt: str) -> List[dict]:
     
   return [{'role': 'user', 'content': joke_prompt}]
    
    
    def joke_response(llm_client: openai.OpenAI,
        
              joke_messages: List[dict]) -> str:
        response = llm_client.chat.completions.create(
            mode
l='gpt-3.5-turbo',
            messages=joke_messages,
        )
        return response.choices[0].message.content
    

    
    if __name__ == '__main__':
        import hamilton_invoke
    
        from hamilton import driver
    
      
  dr = (
            driver.Builder()
            .with_modules(hamilton_invoke)
            .build()
        )
        
dr.display_all_functions('hamilton-invoke.png')  # see image below
        print(dr.execute(['joke_response'],
         
                inputs={'topic': 'ice cream'}))

This image (generated by Hamilton) represents how Hamilton stitches tog
ether the code to then run it

[Result of dr.display\_all\_functions\(\\'hamilton-invoke.png\\'\)](https://preview.redd.
it/tq5ms3ltj5zc1.png?width=702&format=png&auto=webp&s=048f54f953ab50996e459b93d034771d9a943c7c)

To see more comparisons
 (e.g. conditionally swapping anthropic for openai) [click here](https://hamilton.dagworks.io/en/latest/code-comparisons
/langchain/). For code that is both Hamilton & LangChain [see this example](https://hub.dagworks.io/docs/DAGWorks/conver
sational_rag/).

Now I wouldn't use Hamilton for a simple function call -- much like I wouldn't use LangChain for that e
ither.

I'm interested in discussing thoughts and opinions to see if there's (a) appetite for this style of API, and (b)
 therefore should we integrate more closely with LangChain.  Cheers!
```
---

     
 
all -  [ If you're wondering how to make RAG with Llama 3 here is an easy starter kit ](https://www.reddit.com/r/IMadeASaaS/comments/1cmvmxl/if_youre_wondering_how_to_make_rag_with_llama_3/) , 2024-05-09-0910
```
[https://github.com/langchain-ai/langchain-nextjs-template](https://github.com/langchain-ai/langchain-nextjs-template)


&#x200B;
```
---

     
 
all -  [ Why specialized vector databases are not the future? ](https://www.reddit.com/r/LangChain/comments/1cmqx7z/why_specialized_vector_databases_are_not_the/) , 2024-05-09-0910
```
I'm thinking about writing a blog on this topic 'Why specialized vector databases are not the future?'

In this blog, I'
ll try to explain why you need Integrated vector databases rather than a specialised vector database. 

Do you have any 
arguments that support or refute this narrative?
```
---

     
 
all -  [ Using LangChain agents to create a multi-agent platform that creates robot softwares ](https://www.reddit.com/r/LangChain/comments/1cmquwv/using_langchain_agents_to_create_a_multiagent/) , 2024-05-09-0910
```
When using LLMs for your generative AI needs, it's best to think of the LLM as a person rather than as a traditional AI 
engine. You can train and tune an LLM and give it memory to create an agent. The LLM-agent can act like a domain-expert 
for whatever domain you've trained and equipped it for. Using one agent to solve a complex problem is not the optimum so
lution. Much like how a project manager breaks a complex project into different tasks and assigns different individuals 
with different skills and trainings to manage each task, a multi-agent solution, where each agent has different capabili
ties and  trainings, can be applied to a complex problem.                                                    

In our ca
se, we want to automatically generate the entire robot software (for any given robot description) in ROS (Robot Operatin
g System);  In order to do so, first, we need to understand the overall design of the robot (a.k.a the ROS graph) and th
en for each ROS node we need to know if the LLM should generate the code, or if the LLM can fetch a suitable code from o
nline open-source repositories (a.k.a. RAG: Retrieval Augmented Generation). Each of these steps can be handled by diffe
rent agents which have different sets of tools at their disposal. The following figure shows how we are doing this:

[Ro
bot software generation using four collaborating agents each responsible for a different part of the problem, each equip
ped with different toolsets.](https://preview.redd.it/qcvb8y98c3zc1.png?width=1570&format=png&auto=webp&s=5f4072288e470f
d9e2d946e471f35e4c2dff1f94)

This is a free and open-source tool that we have released. We named it [ROScribe](https://g
ithub.com/RoboCoachTechnologies/ROScribe). Please checkout our [repository](https://github.com/RoboCoachTechnologies/ROS
cribe) for more information and give us a star if you like what you see. :) 
```
---

     
 
all -  [ Ingesting hundreds of csv files, loading them into a knowledge graph (RAG) then use LLM chatbot to q ](https://www.reddit.com/r/LangChain/comments/1cmpkyl/ingesting_hundreds_of_csv_files_loading_them_into/) , 2024-05-09-0910
```
I want to ingest hundreds of csv files, all the column data is   
different except for them sharing a similar column rel
ated to state. So I  
 am able to capture the location of the data observations and relate   
them to other data. The da
ta is mostly pertaining to demographics like   
economics, age, race, income, education, and health related outcomes. I 
  
need a general way to ingest all these csv files and load them into a   
knowledge graph, then use OpenAI to send a c
ypher query to the knowledge  
 graph to gain context of the user's question and then return an answer.  
 A question mi
ght be 'What is the highest mortality rate in the country   
and what might be causing this?' or 'Tell me counties with 
the lowest   
morbidity rates and why they might be lower than average'. I was   
thinking I could use vector embeddings
 as well for matching columns   
together and clustering the data. Im just wondering what the best way to  
 construct t
he graph will be so that the LLM can easily traverse it and   
get the correct information back to the user. What is the
 best way to   
set all this up? Does it make sense to construct a knowledge graph here   
so that LLM has context.  
  
  
Could use advice on how to set something up like this.  
    
Thanks  
  
  
    
  
  
  
  
```
---

     
 
all -  [ [1.5 YoE] Recent Master's Graduate in Computer Science Seeking Full-Time SDE or Data Science/ML role ](https://www.reddit.com/r/EngineeringResumes/comments/1cmp18k/15_yoe_recent_masters_graduate_in_computer/) , 2024-05-09-0910
```
So i have 1.5 years of experience as a full time software developer in .Net, C#, C++ techstack, I recently graduated fro
m masters in computer science , during my tenure as a student, i worked as a Graduate Student Assistant and my role chan
ged from Software developer in the first year to a data science role in the second year of my masters and so i keep chan
ging the first part of the experience section between Software developer and data science role and its part time job i.e
 the work at my university.

I have applied to over 1200 jobs and still didnt get any call backs. I am completely depres
sed and dont understand whats wrong with my resume. I need help

https://preview.redd.it/6yvelif313zc1.png?width=4961&fo
rmat=png&auto=webp&s=c6d6a4dfa54998b71521fb7c6d502051b2b0684d


```
---

     
 
all -  [ Langchain is legacy in Vercel AI SDK, how to still use Langchain in a stable and futureproof way? ](https://www.reddit.com/r/nextjs/comments/1cmkd6r/langchain_is_legacy_in_vercel_ai_sdk_how_to_still/) , 2024-05-09-0910
```
I just saw that Langchain is now a legacy provider. How can i still use Langchain with the Vercel AI SDK for my NextJS a
pps in a futureproof way. On the website it says, that the legacy providers are not recommended for new projects.
```
---

     
 
all -  [ Langtrace - Added support for Prompt Playground ](https://www.reddit.com/r/LangChain/comments/1cmk0dn/langtrace_added_support_for_prompt_playground/) , 2024-05-09-0910
```
Hey all,

  
We just added support for prompt playground. The goal of this feature is to help you test and iterate on yo
ur prompts from a single view across different combinations of models and model settings. 

- Support for OpenAI, Anthro
pic, Cohere and Groq

- Side by side comparison view.

- Comprehensive API settings tab to tweak and iterate on your pro
mpts with different combinations of settings and models. 

  
Please check it out and let me know if you have any feedba
ck.

[https://langtrace.ai/](https://langtrace.ai/)

[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale
3-Labs/langtrace)

https://reddit.com/link/1cmk0dn/video/y0tve9hb02zc1/player

  

```
---

     
 
all -  [ Torn between Data Science and Game Dev ](https://www.reddit.com/r/gamedev/comments/1cmjfpe/torn_between_data_science_and_game_dev/) , 2024-05-09-0910
```
Im really torn between either pursuing game dev or Data Science (Modeling and Analysis). My interest in coding and devel
oping started with game dev a few years ago but I switched to DS when it came to my formal education. 

I have experienc
e in both fields and I'm fairly decent in both. However, my main motivation for going into DS was how brutal the game de
v industry was a few years ago (I was young and naiive, thought ds is better but it's really all the same). 

Another ke
y factor that I took into account is that my country isn't the best for either fields so I'm mostly tied to remote work 
and DS seemed the better option there.

Do you guys suggest I stick with Data Science (am diving into LangChain and gene
rative Ai rn as well) or slowly transition back to Game Dev?

P. S: I did look into combining my game dev experience wit
h ds expertise for Game related analyst work but again, remotely working in a position like that seems improbable. 
```
---

     
 
all -  [ Why Should We Keep an Eye Out for YC Batches?
 ](https://www.reddit.com/r/LangChain/comments/1cmiclo/why_should_we_keep_an_eye_out_for_yc_batches/) , 2024-05-09-0910
```
Just to clarify, if you want to be the first to know about trends in the startup world, you have to keep an eye on what'
s going on inside Y Combinator. This incubator has extensive experience with startups. You may know Stripe, Airbnb, Drop
box, Reddit, and Twitch among its alumni. And I'm sure YC won't slow down.

According to Garry Tan (President and CEO of
 YC), **the 260 companies** in the W24 cohort were selected from over **27,000** applications. The acceptance rate for s
tartups was less than **1%**! And AI was the biggest topic, with over **85 companies** calling themselves 'AI Startups' 
and over **180 mentioning** machine learning in their demos.
```
---

     
 
all -  [ Python library to deploy LLM chat bots fast?
 ](https://www.reddit.com/r/LangChain/comments/1cmdxyi/python_library_to_deploy_llm_chat_bots_fast/) , 2024-05-09-0910
```
Here is a simple code snippet on how to use the Cycls chatbot library

    main.py
    from cycls import App
    
    ap
p = App(secret='sk-secret',
              handler='@handler-name')
    
    @app
    def entry_point(context):
        #
 Capture the received message
        received_message = context.message.content.text
        # Reply back with a simple
 message
        context.send.text(f'Received message: {received_message}')
    
    app.publish()

This is a simplified
 example but when you run [main.py](http://main.py), the chatbot immediately gets deployed with a public url and a chat 
interface. This has helped me a huge deal with testing while developing chatbots.   
Here are the docs: [https://docs.cy
cls.com/getting-started](https://docs.cycls.com/getting-started) [ ](https://docs.cycls.com/getting-started)
```
---

     
 
all -  [ Passing the output of function calling to RedisChatHistory in LCEL ](https://www.reddit.com/r/LangChain/comments/1cmdvls/passing_the_output_of_function_calling_to/) , 2024-05-09-0910
```
HI 

I have a RunnableWithMessageHistory and agent\_executor to create a chatbot agent with tools to fetch data from an 
API and then Redis to story chat history. 

I see that the RunnableWithMessageHistory is not recording the raw response 
of the function calling to the chat history. How do I solve for this?

I have been reading the API docs but couldn't fin
d anything. 
```
---

     
 
all -  [ ARC - A nimble framework for ai agent creation! ](https://www.reddit.com/r/Kotlin/comments/1cmdqfe/arc_a_nimble_framework_for_ai_agent_creation/) , 2024-05-09-0910
```
Hello r/Kotlin

I'm thrilled to introduce ARC, a new Kotlin framework for building AI Agents which takes the overhead of
f AI Agent creation. ARC is designed with simplicity and minimalism at its core.

It’s been a very tough journey braving
 so many questions from doubters on why not langchain or python etc.  u/Pat_Wlan has so many scars to show as he led thi
s module and is the core committer 🔥❤️🔥. This has been the result of our learnings from developing multi-agent systems t
hat are deployed in production at Deutsche Telekom.

**What sets ARC apart?**

* **Minimal Dependencies:** We've kept AR
C lean, ensuring that you only bring into your project what you truly need. No more bloat or extraneous libraries that h
og resources and complicate your builds!
* **Focused on Kotlin's Strengths:** ARC is built to maximize Kotlin's features
 such as DSL.
* **Interoperable by Design:** While ARC doesn't use langchain or springAI, it's designed to play well wit
h them. You're free to integrate AI functionalities or other libraries as you see fit, making ARC a flexible choice for 
a wide array of projects.
* **Community-Centered:** ARC is open-source and community-driven, with the aim of evolving th
rough your insights and contributions. We believe in the power of collective intelligence and are excited to see how the
 framework grows with your input.
* **Flexible** ARC is meant to be architecture agnostic. It doesn’t matter whether you
 are building microservices, a CLI or something else altogether.

We would like to get your feedback on this small endea
vor we took, braving so many questions internally on why not langchain or python etc .   
Would be great if you could ch
eck it out and help us make it 🚀🔥🚀.

Using the [arc-spring-init](https://github.com/lmos-ai/arc-spring-init) repository 
combined with your OpenAI-API Key you can create agents within seconds!

Project: [ARC](https://github.com/lmos-ai/arc),
 dive into the [docs](https://lmos-ai.github.io/arc/) 📖

We're looking forward to your valuable feedback.

Thanks ❤️!
```
---

     
 
all -  [ Langchain for Q&A + RAG? ](https://www.reddit.com/r/LocalLLaMA/comments/1cmafor/langchain_for_qa_rag/) , 2024-05-09-0910
```
I want to make a Q&A + RAG application.
Is langchain still a good choice?

I have never worked with it but it seems a bi
t bloated? And it seems to abstract a lot of details away such that it’s difficult to really understand what’s going on 
under the hood?

I could be completely wrong though. 

What’s your recommended stack for Q&A + RAG chatbot applications?


```
---

     
 
all -  [ Is llama2 multimodal? ](https://www.reddit.com/r/LangChain/comments/1cm9e3l/is_llama2_multimodal/) , 2024-05-09-0910
```
How can we pass images or base64 to llama2 and ask certain questions like describe this image??
```
---

     
 
all -  [ Combined Embeddings  ](https://www.reddit.com/r/LangChain/comments/1cm8oek/combined_embeddings/) , 2024-05-09-0910
```
I am developing my own Rag.
Using the text_splitter there is a performance tradeoff for the chunk size and chunk overlap
 parameters. Short chunks may not include all desired context, long chunks may hallucinate or cause info loss. Has anyon
e tried to embed twice the same document with multiple and different splitters? 
Are there noticeable advantages / disad
vantages?

```
---

     
 
all -  [ Yet Another RAG Tutorial ](https://www.reddit.com/r/webdev/comments/1cm7nuw/yet_another_rag_tutorial/) , 2024-05-09-0910
```
I was itching for a hands-on project, something I could build in just a few hours. So, I decided to experiment with Lang
Chain and vector databases to create a RAG conversation application.

Figured I'd share my experience with you. Check it
 out and lemme know what you think:

[https://genezio.com/blog/langchain-genezio-project](https://genezio.com/blog/langc
hain-genezio-project)
```
---

     
 
all -  [ Kernel crashing when using Langsmith Evaluation ](https://www.reddit.com/r/LangChain/comments/1cm7lbr/kernel_crashing_when_using_langsmith_evaluation/) , 2024-05-09-0910
```
Hello, could you assist me? I'm encountering difficulties with Langsmith's evaluation process. I'm able to evaluate my c
ontext using 'cont\_qa', but when I attempt to incorporate additional evaluators such as 'accuracy', my kernel crashes i
f there's more than one element in my dataset. Interestingly, when there's only one element, it works perfectly. I'm see
king guidance on how to address this issue. Below is the code I'm using

    import langsmith
    from langchain import 
chat_models, prompts, smith
    from langchain.schema import output_parser
    
    
    # Define your runnable or chain
 below.
    prompt = prompts.ChatPromptTemplate.from_messages(
      [
        ('system', 'You are a helpful AI assistan
t.'),
        ('human', '{question}')
      ]
    )
    
    
    # Define the evaluators to apply
    eval_config = smi
th.RunEvalConfig(
        evaluators=[
            'cot_qa',
            smith.RunEvalConfig.LabeledCriteria('harmfulnes
s'),
            smith.RunEvalConfig.LabeledCriteria('relevance'),
            smith.RunEvalConfig.LabeledCriteria('help
fulness')
        ],
        custom_evaluators=[],
        eval_llm=chat_models.ChatOpenAI(model='gpt-4', temperature=0)

    )
    
    client = langsmith.Client()
    chain_results = client.run_on_dataset(
        dataset_name=dataset_name
,
        llm_or_chain_factory=open_ai_rag,
        evaluation=eval_config,
        concurrency_level=5,
        verbose
=True,
    )
```
---

     
 
all -  [ Create a real world RAG chat app with Langchain LCEL ](https://www.reddit.com/r/LangChain/comments/1cm5ktx/create_a_real_world_rag_chat_app_with_langchain/) , 2024-05-09-0910
```
Hello everyone,

Just finished writing a post on how to create real world application using Langchain.  
I talk about :


* Langchain LCEL
* How to create composition of multiple chains.
* How to integrate user parameters like output type or
 specified vector store in chains.
* How to use configuration to change the prompt and the retriever at run time.

Check
 it out: [Link](https://www.metadocs.co/2024/05/07/create-a-complex-rag-chat-app-with-langchain-lcel/).

Thanks!
```
---

     
 
all -  [ Error Following Langchain/Vertex AI Reasoning Engine Docs ](https://www.reddit.com/r/LangChain/comments/1cm2lvb/error_following_langchainvertex_ai_reasoning/) , 2024-05-09-0910
```
Hello everyone, I'm trying to follow this example I found in the Vertex AI documentation.

[https://cloud.google.com/ver
tex-ai/generative-ai/docs/reasoning-engine/develop](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engi
ne/develop)

I'm following the steps carefully, but when I try:

    response = agent.query(

input='What is the exchang
e rate from US dollars to Swedish currency?' )

I receive the following error:

    {
    	'name': 'KeyError',
    	'mes
sage': ''agent'',
    	'stack': '---------------------------------------------------------------------------
    KeyErro
r                                  Traceback (most recent call last)
    Cell In[92], line 1
    ----> 1 response = agen
t.query(
          2     input=\'What is the exchange rate from US dollars to Swedish currency?\'
          3 )
    
   
 File /opt/homebrew/lib/python3.11/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py:439, in Langc
hainAgent.query(self, input, config, **kwargs)
        437     input = {\'input\': input}
        438 if not self._runna
ble:
    --> 439     self.set_up()
        440 return langchain_load_dump.dumpd(
        441     self._runnable.invoke(i
nput=input, config=config, **kwargs)
        442 )
    
    File /opt/homebrew/lib/python3.11/site-packages/vertexai/pre
view/reasoning_engines/templates/langchain.py:400, in LangchainAgent.set_up(self)
        398     self._llm = self._llm.
bind(functions=self._tools)
        399 self._agent = self._prompt | self._llm | self._output_parser
    --> 400 self._a
gent_executor = AgentExecutor(
        401     agent=self._agent,
        402     tools=self._tools,
        403     **s
elf._agent_executor_kwargs,
        404 )
        405 runnable = self._agent_executor
        406 if has_history:
    
 
   File /opt/homebrew/lib/python3.11/site-packages/langchain/load/serializable.py:97, in Serializable.__init__(self, **k
wargs)
         96 def __init__(self, **kwargs: Any) -> None:
    ---> 97     super().__init__(**kwargs)
         98    
 self._lc_kwargs = kwargs
    
    File /opt/homebrew/lib/python3.11/site-packages/pydantic/v1/main.py:339, in BaseModel
.__init__(__pydantic_self__, **data)
        333 \'\'\'
        334 Create a new model by parsing and validating input d
ata from keyword arguments.
        335 
        336 Raises ValidationError if the input data cannot be parsed to form a
 valid model.
        337 \'\'\'
        338 # Uses something other than `self` the first arg to allow \'self\' as a set
table attribute
    --> 339 values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)
   
     340 if validation_error:
        341     raise validation_error
    
    File /opt/homebrew/lib/python3.11/site-pac
kages/pydantic/v1/main.py:1102, in validate_model(model, input_data, cls)
       1100     continue
       1101 try:
    
-> 1102     values = validator(cls_, values)
       1103 except (ValueError, TypeError, AssertionError) as exc:
       1
104     errors.append(ErrorWrapper(exc, loc=ROOT_KEY))
    
    File /opt/homebrew/lib/python3.11/site-packages/langchai
n/agents/agent.py:881, in AgentExecutor.validate_tools(cls, values)
        878 ()
        879 def validate_tools(cls, v
alues: Dict) -> Dict:
        880     \'\'\'Validate that tools are compatible with agent.\'\'\'
    --> 881     agent =
 values[\'agent\']
        882     tools = values[\'tools\']
        883     allowed_tools = agent.get_allowed_tools()
 
   
    KeyError: 'agent''
    }

Has anyone else encountered this error while working with Vertex AI? If so, how did yo
u resolve it? Any tips or tricks would be greatly appreciated!

UPDATE:

I fix it downgrading the langchain-core version
 from  0.1.51 to 0.1.50!!!
```
---

     
 
all -  [ Smart AI voice assistant + connect to the internet ](https://www.reddit.com/r/ArtificialInteligence/comments/1clxtb8/smart_ai_voice_assistant_connect_to_the_internet/) , 2024-05-09-0910
```
I continue my experiment building a smart AI voice assistant. This time I'm adding an ability to google for an answer. 


I'm using OpenAI function calling + AI assistants combined with SerpApi Google Search API. This way the AI can google f
or real-time data like, current weather, stock, etc.

Here is the full step-by-step tutorial: [https://serpapi.com/blog/
build-a-smart-ai-voice-assistant-connect-to-the-internet/](https://serpapi.com/blog/build-a-smart-ai-voice-assistant-con
nect-to-the-internet/)

\*I still wonder if I can replace OpenAI AI assistants with something else for the chat conversa
tion history. Currently exploring LangChain ecosystem.
```
---

     
 
all -  [ Enhancing Local LLM's Understanding of Technical Documents ](https://www.reddit.com/r/LangChain/comments/1clui48/enhancing_local_llms_understanding_of_technical/) , 2024-05-09-0910
```
Hi

I'm currently using a code that processes a series of reports (PDF files), posing the same set of questions to every
 report. The output is a dataframe containing the responses to each question for every report. For instance, the questio
n 'Does the report explains why the amount of X decreased?' will be answered in a column of my output dataframe. So ever
y line of this column will consist of the answer for a specific report. My setup includes the use of [https://huggingfac
e.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) and a locall
y downloaded LLM from Hugging Face. Although the code is functional, the reports are highly technical and complex, and t
he local LLM lacks the necessary understanding of the content (I notice that when I read the answers).

I'm looking to e
nhance the LLM's comprehension by training it on additional technical documents of the same nature, hoping this will imp
rove its ability to accurately answer queries from my reports. If I've understood correctly, one approach might be to ut
ilize a RAG on the technical documents, but I'm unsure of the exact steps to implement this effectively. I've attempted 
to merge the embeddings from the downloaded 'all-MiniLM-L6-v2' model with those I generated from the technical documents
, as described here: [https://python.langchain.com/docs/integrations/retrievers/merger\_retriever/](https://python.langc
hain.com/docs/integrations/retrievers/merger_retriever/), but without success.

Could you suggest a viable strategy for 
this? Should I discard the 'all-MiniLM-L6-v2' and focus solely on embeddings derived from my technical documents? This a
pproach seems to require an extensive collection of documents, which I currently don't have.

 I've tried various other 
local LLMs (Mistral, Phi, Llama, Orca), but I encounter the same issue each time. 'Large' LLMs (Mistral e.g.) tend to ha
llucinate, while 'smaller' (Orca e.g.) LLMs often respond that they do not know.

  
Thanks
```
---

     
 
MachineLearning -  [ [D] Self-optimizing deterministic LLM memory using dspy, neo4j and vector databases. Need your input ](https://www.reddit.com/r/MachineLearning/comments/1cakjaf/d_selfoptimizing_deterministic_llm_memory_using/) , 2024-05-09-0910
```
Hey there, Redditors!

I'm back with the latest installment on creating deterministic LLM memory.

If you've been follow
ing along, you know I'm on a mission to move beyond the '[thin OpenAI wrapper](https://topoteretes.github.io/cognee/blog
/2023/10/05/going-beyond-langchain--weaviate-and-towards-a-production-ready-modern-data-platform/)' trend and tackle the
 challenges of building robust LLM memory.

  
That's why we built cognee, a python library to process documents and bui
ld knowledge graphs on top of them.

After a few weeks of work, we integrated DSPy and extended cognee.

Here is brief o
verview of the logic: 

[Architecture overview](https://preview.redd.it/fcs3lifx53wc1.png?width=1380&format=png&auto=web
p&s=9316cba52147a5b764565b8438f3f143d8e7ac84)

We aim to understand:

1. Have you tried building knowledge graphs with o
ther tools before?

2. If so, what were the biggest obstacles?

3. How would you approach semantic linking of documents 
without knowledge graphs?

*Remember to give this post an upvote if you found it insightful!*  
*And also star our* [Git
hub repo](https://github.com/topoteretes/cognee)
```
---

     
 
deeplearning -  [ Seeking Advice: Solving Data Challenges with Large Language Models (LLMs) ](https://www.reddit.com/r/deeplearning/comments/1ca4nc1/seeking_advice_solving_data_challenges_with_large/) , 2024-05-09-0910
```
Hi all

I am presented with a problem that I need to solve using LLM to get the right data from text that has only \~20%
 structure to it. Here's a sample data

XXXXX

AA          BB

CCCC:  (optional DDDD)

C1......(A1) (B1)

C2......(A2) (
B2)

C3.....(A3) (B3)

I am required to anwer with either of these results from A1/B1 till A3/B3 pairs but in order to d
o that I need to go back and ask the user which one of the options C1 to C3 applies to him?

The above is not the most c
omplex structure, it increases in complexity from here so a lot of chatting with user is required to get to the right da
ta that will always exist in the chunk like above.

In the most simplist case the data structure will look like below

X
XXXX

AA          BB

CCCC: ......(A1) (B1)



How would you build a system like this? I am looking at multi-agent syste
ms with Langchain, what about prompt chaining?
```
---

     
 
deeplearning -  [ Share the Coolest Out of The Box LLM Applications That Made You Say 'Wow that was smart' ](https://www.reddit.com/r/deeplearning/comments/1c9e6dj/share_the_coolest_out_of_the_box_llm_applications/) , 2024-05-09-0910
```
Hi, I'm looking at some LLM applications today but apart from guys doing big rags with langchain I don't see too many us
es that are out of the box or that make me say 'wow that was smart to use an LLM here'. Have you seen any cool stuff usi
ng LLMs recently that made you say 'wow, that was smart'?
```
---

     
