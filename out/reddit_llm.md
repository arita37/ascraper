 
all -  [ Good RAG implementation ](https://www.reddit.com/r/LangChain/comments/16m9cem/good_rag_implementation/) , 2023-09-19-0910
```
Hi there, I am new with LLMs and I'm working on a personal project. I am looking for a good RAG implementation (with LLM
 support) that does not take forever to run to be able to retrieve information over multiple time periods, over a large 
number of files and where the text can be longer than a chunk. Anyone got a good idea of an architecture or a good repos
itory to start from ?
```
---

     
 
all -  [ How to Optimize Text Chunking for Improved Embedding Vectorization? ](https://www.reddit.com/r/LangChain/comments/16m73j4/how_to_optimize_text_chunking_for_improved/) , 2023-09-19-0910
```
 I'm currently using Langchain to split my texts into chunks, but I believe it may not always yield the most optimal vec
tors. My source material consists of lengthy articles, which often contain contextual information distributed across the
 entire article. When I break these articles into smaller chunks, I run the risk of losing important contextual informat
ion.

Does anyone have any suggestions on how to enhance this process? I've been contemplating the idea of introducing a
 pre-vectorization step where I could transform all the articles into a 'question and answer' format through an OpenAI r
equest. However, I'm concerned that this approach might be costly, or perhaps there are more effective alternatives avai
lable. Any insights would be greatly appreciated.
```
---

     
 
all -  [ Which one is the best embedding for Langchain ReAct agents? ](https://www.reddit.com/r/LangChain/comments/16m37g7/which_one_is_the_best_embedding_for_langchain/) , 2023-09-19-0910
```
Working on a prototype and am not sure which one to choose. 

Free is best. Any open source alternatives?
```
---

     
 
all -  [ Not being able to use HuggingFaceEmbedding from Langchain ](https://www.reddit.com/r/LangChain/comments/16m1nee/not_being_able_to_use_huggingfaceembedding_from/) , 2023-09-19-0910
```
Hi, everyone! I'm quite new to LangChain and LLM's, and I'm currently trying to use LangChain + LLama 2 to extract infor
mation from PDF documents. My attempts with LLamaCcp weren't very successful, so I'm now giving a try with HuggingFace's
 embeddings and pipeline, but I can't figure out why I can't get past this one error.  I do have a working pipeline work
ing with langchain + huggingface, so I can edit the tokenizer in this case, but I have no idea what can I do now with th
e embedding model. Any help and/or tips are welcome! =)

My embedding model's instantiation works normally, the error is
 thrown at the attempt of embedding documents

&#x200B;

`hf = HuggingFaceBgeEmbeddings(`

`model_name=model_name,`

`mo
del_kwargs=model_kwargs,`

`encode_kwargs=encode_kwargs`

`)`

&#x200B;

`Please update jupyter and ipywidgets. See` [`h
ttps://ipywidgets.readthedocs.io/en/stable/user_install.html`](https://ipywidgets.readthedocs.io/en/stable/user_install.
html) `from .autonotebook import tqdm as notebook_tqdm`

`No sentence-transformers model found with name ../llama-2-7b-h
f. Creating a new one with MEAN pooling.`

`Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00, 1.49s/it]`

&#
x200B;

`embeddings = hf.embed_documents(['This is a test document.'])`

&#x200B;

`ValueError: Asking to pad but the to
kenizer does not have a padding token. Please select a token to use as \`pad\_token (tokenizer.pad\_token = tokenizer.eo
s\_token e.g.) or add a new pad token via tokenizer.add\_special\_tokens({'pad\_token': '\[PAD\]'})\`.\`

&#x200B;
```
---

     
 
all -  [ Master LangChain with No-Code tools: Flowise and LangFlow ](https://idownloadcoupon.com/udemy/3640/) , 2023-09-19-0910
```

```
---

     
 
all -  [ GenAI controller is quite limited, any thoughts on SN platform for broader GenAI orchestration? ](https://www.reddit.com/r/servicenow/comments/16lv5ej/genai_controller_is_quite_limited_any_thoughts_on/) , 2023-09-19-0910
```
SN GenAI Controller is just an API to OpenAI models.  Has anyone tried to use ServiceNow for GenAI orchestration, may be
 with  LangChain or other frameworks? 

For example combine CMDB, Workslows with LLM orchestration tools like prompt des
ign, conversation memory, embedded company data (txt, ppt, slack), API's to multiple LLMs and tools (eg calendar), verif
ication, logging, etc
```
---

     
 
all -  [ Do people not use sci-kit learn / other traditional libraries anymore? ](https://www.reddit.com/r/datascience/comments/16lu9ni/do_people_not_use_scikit_learn_other_traditional/) , 2023-09-19-0910
```
Recently saw a tweet which got quite some traction talking about how many people haven't used sci-kit learn in months as
 data scientists.

This has been replaced with PyTorch, HuggingFace, langchain, supergradients etc.

This didn't really 
make sense to me as the tooling mentioned isn't really comparable to sci-kit learn but I'm curious and slightly worried 
I might be falling behind and not up to date with things so just asking if I'm just behind the curve or what you guys th
ink/ do.
```
---

     
 
all -  [ What python packages are you using for your local builds? ](https://www.reddit.com/r/LocalLLaMA/comments/16ltbhs/what_python_packages_are_you_using_for_your_local/) , 2023-09-19-0910
```
Just wondering what packages ya’ll are using with your different local builds? 

One of my builds uses langchain and fai
ss to read local docs and create an embedding database, then feed the results from similarity search into my llm prompt


Another built just using open-interpreter with a local llama model

What packages have you come across that work good f
or local llm builds? Everything I’m building must be completely offline without using any API keys since I’m building fo
r my work so I’m curious how others work around that

Running on an M1 max with 32GB memory right now, in the process of
 upgrading to an M2 128GB

Thanks!
```
---

     
 
all -  [ + 100 Free Courses for Monday, September 18, 2023 ](https://www.reddit.com/r/udemyfreeebies/comments/16lt21x/100_free_courses_for_monday_september_18_2023/) , 2023-09-19-0910
```
**Courses for 18 September 2023**  
 

Note : Coupons might expire anytime, so enroll as soon as possible to get the cou
rses for FREE.

* DBMS Module – 5[REDEEM OFFER](https://idownloadcoupon.com/udemy/3643/)
* Contact Center Manager Profes
sional Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/3642/)
* Facebook Ads: Run Your First Ad Campaign[R
EDEEM OFFER](https://idownloadcoupon.com/udemy/3641/)
* Master LangChain with No-Code tools: Flowise and LangFlow[REDEEM
 OFFER](https://idownloadcoupon.com/udemy/3640/)
* LEVEL 1 MODULE: BECOME A WEALTH MAGNET FOR LIFE: PART 4 OF 5[REDEEM O
FFER](https://idownloadcoupon.com/udemy/3639/)
* Search Engine Optimization (SEO) For Beginners Practise Test[REDEEM OFF
ER](https://idownloadcoupon.com/udemy/3638/)
* Content Marketing For Intermediate Practise Test 2023[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3637/)
* Boost Digital Marketing Effectiveness via Behavioral Science[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/3636/)
* Python Development Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/3635/)

* Leadership & Team Building Mastery[REDEEM OFFER](https://idownloadcoupon.com/udemy/3634/)
* Adobe Photoshop Projects[
REDEEM OFFER](https://idownloadcoupon.com/udemy/3633/)
* Pubslic Speaking Trainer: Enter the Presentation Training Biz[R
EDEEM OFFER](https://idownloadcoupon.com/udemy/3631/)
* Storytelling: You Can learn to Tell Stories Effectively[REDEEM O
FFER](https://idownloadcoupon.com/udemy/3630/)
* Public Speaking for People Who Hate Public Speaking[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3629/)
* Podcasting: How to Speak Effectively on Your Own Podcast[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3628/)
* Presentation Skills: Give Great Skype Video Presentations[REDEEM OFFER](https://idownloa
dcoupon.com/udemy/3627/)
* Conference Calls-You Can Present Well On Any Conference Call[REDEEM OFFER](https://idownloadc
oupon.com/udemy/3624/)
* Media Training for Print/Online Interviews-Get Great Quotes[REDEEM OFFER](https://idownloadcoup
on.com/udemy/3623/)
* Speaking on the Telephone: Confidently Speak on the Phone[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/3622/)
* Interviewing Skills: Conducting Job Interviews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3621/)
*
 Marketing Strategy: Communicating Your Message[REDEEM OFFER](https://idownloadcoupon.com/udemy/3620/)
* Personal Presen
tation Training[REDEEM OFFER](https://idownloadcoupon.com/udemy/3619/)
* Public Speaking Emergency! Ace the Speech With 
Little Prep[REDEEM OFFER](https://idownloadcoupon.com/udemy/3618/)
* Emergency Media Training: You Can Face a Reporter I
n 2 Hours[REDEEM OFFER](https://idownloadcoupon.com/udemy/3617/)
* Media Training for Beginners: Ace Your First News Int
erviews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3616/)
* Recon For Bug Bounty, Penetration Testers & Ethical Hac
kers[REDEEM OFFER](https://idownloadcoupon.com/udemy/3615/)
* Python – Data Analytics – Real World Hands-on Projects[RED
EEM OFFER](https://idownloadcoupon.com/udemy/3614/)
* QuickBooks Online vs. Excel 2023[REDEEM OFFER](https://idownloadco
upon.com/udemy/3613/)
* QuickBooks Desktop vs. Excel[REDEEM OFFER](https://idownloadcoupon.com/udemy/3612/)
* QuickBooks
 Online vs. QuickBooks Desktop vs. Excel[REDEEM OFFER](https://idownloadcoupon.com/udemy/3611/)
* Two QuickBooks File-Bu
siness & Personal vs One File For Both[REDEEM OFFER](https://idownloadcoupon.com/udemy/3610/)
* QuicksBooks Pro-Business
 & Personal-One QuickBooks File[REDEEM OFFER](https://idownloadcoupon.com/udemy/3609/)
* QuickBooks Online vs Xero Accou
nting Software[REDEEM OFFER](https://idownloadcoupon.com/udemy/3608/)
* QuickBooks Desktop vs QBO Multiple Currencies[RE
DEEM OFFER](https://idownloadcoupon.com/udemy/3607/)
* Fast track French for beginners[REDEEM OFFER](https://idownloadco
upon.com/udemy/3606/)
* Sales management – streams, frameworks and processes[REDEEM OFFER](https://idownloadcoupon.com/u
demy/3605/)
* Corporate Finance #15 Dividend Policy[REDEEM OFFER](https://idownloadcoupon.com/udemy/3604/)
* Corporate F
inance #16 Convertible Bonds & Warrants[REDEEM OFFER](https://idownloadcoupon.com/udemy/3603/)
* Corp. Finance #14 Finan
cing-Commons Stock & Preferred Stock[REDEEM OFFER](https://idownloadcoupon.com/udemy/3602/)
* Proceso CRUD (C Sharp y Mi
crosoft SQL Server)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3601/)
* SQL Bootcamp – SQLite – Hands-On Exercises[
REDEEM OFFER](https://idownloadcoupon.com/udemy/3600/)
* AWS Certified Data Analytics Specialty DAS-C01 – Mock Exams[RED
EEM OFFER](https://idownloadcoupon.com/udemy/3599/)
* SQL Developer Certification: Test Your Skills with Tests[REDEEM OF
FER](https://idownloadcoupon.com/udemy/3598/)
* Google Professional Cloud Security Engineer – Practice Exams[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/3597/)
* Recursion and Backtracking Algorithms in Java[REDEEM OFFER](https://idownl
oadcoupon.com/udemy/3596/)
* Python for Intermediate Learners (2023)[REDEEM OFFER](https://idownloadcoupon.com/udemy/359
5/)
* Mastering HTML5: From Beginner to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/3594/)
* Graph Theory A
lgorithms in Java[REDEEM OFFER](https://idownloadcoupon.com/udemy/3593/)
* Dynamic Programming Algorithms for Coding Int
erviews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3592/)
* Curso de Base de Datos SQLite[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3591/)
* Curso de Java – Nivel Básico[REDEEM OFFER](https://idownloadcoupon.com/udemy/3590/)
* Rú
bricas para la evaluación de desempeño de los aprendizajes[REDEEM OFFER](https://idownloadcoupon.com/udemy/3589/)
* Curs
o de Base de Datos Oracle Database[REDEEM OFFER](https://idownloadcoupon.com/udemy/3588/)
* Curso de Base de Datos Fireb
ird[REDEEM OFFER](https://idownloadcoupon.com/udemy/3587/)
* Desarrollando Sistema de Ventas (C# y MySQL Server)[REDEEM 
OFFER](https://idownloadcoupon.com/udemy/3586/)
* Job Cost QuickBooks Online vs QuickBooks Desktop–Contractor[REDEEM OFF
ER](https://idownloadcoupon.com/udemy/3585/)
* Corp Finance #12 Capital Budgeting & Investment Risk Tools[REDEEM OFFER](
https://idownloadcoupon.com/udemy/3584/)
* Corporate Finance #13 Investment Banking & Long-Term Debt[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3583/)
* LeetCode in Java: Algorithms Coding Interview Questions[REDEEM OFFER](https://idow
nloadcoupon.com/udemy/3582/)
* The Complete C Programming Course for Beginners[REDEEM OFFER](https://idownloadcoupon.com
/udemy/3581/)
* Bank Feeds-QuickBooks Online, Xero, Sage, Wave (Comparison)[REDEEM OFFER](https://idownloadcoupon.com/ud
emy/3580/)
* Corp Finance #10 Cost of Capital–Debt & Equity Financing[REDEEM OFFER](https://idownloadcoupon.com/udemy/35
79/)
* Corporate Finance #9 Valuation-Bond, Common /Preferred Stock[REDEEM OFFER](https://idownloadcoupon.com/udemy/3578
/)
* The Complete Data Structures and Algorithms Course in Java[REDEEM OFFER](https://idownloadcoupon.com/udemy/3577/)
*
 Corporate Finance #8 Time Value of Money (PV & FV)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3576/)
* Corporate F
inance #7 Short Term Financing[REDEEM OFFER](https://idownloadcoupon.com/udemy/3575/)
* Corporate Finance #4 Leverage & 
Break-Even Analysis[REDEEM OFFER](https://idownloadcoupon.com/udemy/3574/)
* Corporate Finance #5 Financing Decisions[RE
DEEM OFFER](https://idownloadcoupon.com/udemy/3573/)
* Corporate Finance #6 Management of Current Assets[REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/3572/)
* Corporate Finance #1 Introduction & Financial Statements[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/3571/)
* Corporate Finance #3 Forecasting & Budgeting[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/3570/)
* Corporate Finance #2 Financial Ratios[REDEEM OFFER](https://idownloadcoupon.com/udemy/3569/)
* Automat
ed Machine Learning for Beginners (Google & Apple)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3568/)
* Partnership 
Accounting – Financial Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3567/)
* Financial Accounting – Closin
g Process[REDEEM OFFER](https://idownloadcoupon.com/udemy/3566/)
* Bank Reconciliations & Cash Internal Controls[REDEEM 
OFFER](https://idownloadcoupon.com/udemy/3565/)
* Financial Accounting – Closing Process[REDEEM OFFER](https://idownload
coupon.com/udemy/3564/)
* Financial Accounting – Subsidiary Ledgers & Special Journals[REDEEM OFFER](https://idownloadco
upon.com/udemy/3563/)
* Financial Accounting–Inventory & Merchandising Transactions[REDEEM OFFER](https://idownloadcoupo
n.com/udemy/3562/)
* Financial Accounting – Inventory Costs[REDEEM OFFER](https://idownloadcoupon.com/udemy/3561/)
* Tim
e Value of Money & Capital Budgeting – Present Value[REDEEM OFFER](https://idownloadcoupon.com/udemy/3560/)
* Financial 
Accounting-Adjusting Entries & Financial Statement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3559/)
* Financial Ac
counting-Debits & Credits-Accounting Transaction[REDEEM OFFER](https://idownloadcoupon.com/udemy/3558/)
* Receivables & 
The Allowance vs The Direct Write Off Methods[REDEEM OFFER](https://idownloadcoupon.com/udemy/3557/)
* Accounting for Co
rporations – Financial Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3556/)
* Accounting-Statement of Cash 
Flows[REDEEM OFFER](https://idownloadcoupon.com/udemy/3555/)
* Job Order Costing System – Managerial Accounting[REDEEM O
FFER](https://idownloadcoupon.com/udemy/3554/)
* Advanced Microsoft Word With Job Success[REDEEM OFFER](https://idownloa
dcoupon.com/udemy/3553/)
* Financial Accounting-Depreciation Calculation & Fixed Assets[REDEEM OFFER](https://idownloadc
oupon.com/udemy/3552/)
* Payroll Calculations Training for Financial Accounting[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/3551/)
* Process Costing System-Cost Accounting-Managerial Accounting[REDEEM OFFER](https://idownloadcoupon.com/
udemy/3550/)
* Responsibility Accounting & Performance Measurement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3549/
)
* Complete PYTHON Programming for Beginners – 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/3548/)
* Relevant C
osts – Managerial Accounting Decisions & Scenarios[REDEEM OFFER](https://idownloadcoupon.com/udemy/3547/)
* Master Budge
ts – Managerial Accounting/Cost Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3546/)
* C++ Assessment Toolk
it: Diverse Practice Tests for All Level[REDEEM OFFER](https://idownloadcoupon.com/udemy/3545/)
* Practice Tests: Crack 
the Python PCEP Certification Exam[REDEEM OFFER](https://idownloadcoupon.com/udemy/3544/)
* Ace the Python Challenge: 60
 Realistic Practice Questions[REDEEM OFFER](https://idownloadcoupon.com/udemy/3543/)
* C++ Practice Intensives: Sharpen 
Skills with 4 Rigorous Test[REDEEM OFFER](https://idownloadcoupon.com/udemy/3542/)
* Wondershare Filmora 11 Video Editin
g Course in Hindi[REDEEM OFFER](https://idownloadcoupon.com/udemy/3541/)
* Excellence in Interpersonal Skills (People & 
Social Skills)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3540/)
* iOS 16 Swift & SwiftUI – Complete iOS App Develo
pment[REDEEM OFFER](https://idownloadcoupon.com/udemy/3539/)
* Python for Intermediate Learners (2023)[REDEEM OFFER](htt
ps://idownloadcoupon.com/udemy/3538/)
* Consumer behavior, Consumer Intention & Consumer Attitude[REDEEM OFFER](https://
idownloadcoupon.com/udemy/3537/)
* Excel – Formulas & Functions Beginner to Expert Course 2023[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3536/)
* Excellence in Problem Solving Skills & Strategies[REDEEM OFFER](https://idownloadcoupon.
com/udemy/3535/)
* Rank Your Blog Website in Google: SEO For Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/ud
emy/3534/)
* Python Complete Course For Python Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/3533/)
* Javasc
ript Build a Calculator using HTML, CSS and Javascript[REDEEM OFFER](https://idownloadcoupon.com/udemy/3532/)
* 23.8″ Мо
нитор Philips 243V7QDAB, 1920×1080, 75 Гц, IPS[REDEEM OFFER](https://idownloadcoupon.com/udemy/3531/)
* Python & Django 
REST API Bootcamp – Build A Python Web API[REDEEM OFFER](https://idownloadcoupon.com/udemy/3530/)
* Flutter REST Movie A
pp: Master Flutter REST API Development[REDEEM OFFER](https://idownloadcoupon.com/udemy/3529/)
* Flutter UI Bootcamp | B
uild Beautiful Apps using Flutter[REDEEM OFFER](https://idownloadcoupon.com/udemy/3528/)
* Build A Chat Application With
 Firebase, Flutter and Provider[REDEEM OFFER](https://idownloadcoupon.com/udemy/3527/)
* C++ Mastery through 4 Logical P
ractice Tests[REDEEM OFFER](https://idownloadcoupon.com/udemy/3526/)
* C++ Challenge: 4 Intensive Practice Exams[REDEEM 
OFFER](https://idownloadcoupon.com/udemy/3525/)
* Python Practice Exams: Elevate Your Programming Skills[REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/3524/)
* Master Python Web Scraping & Automation using BS4 & Selenium[REDEEM OFFER](htt
ps://idownloadcoupon.com/udemy/3523/)
* Python Quest: 60 Challenging Question to Enhance Your Skill[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/3522/)
* Sharpen Your C++ Skills with 4 Challenging Practice Tests[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3521/)
* CSS, Bootstrap ,JavaScript, Web Development Course[REDEEM OFFER](https://idownloadcoupon
.com/udemy/3520/)
* Continuous Improvement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3519/)
* Business Improvement
 Plan[REDEEM OFFER](https://idownloadcoupon.com/udemy/3518/)
* Process Mapping: Toolkit[REDEEM OFFER](https://idownloadc
oupon.com/udemy/3517/)
* Learn Japanese For Beginners With Natsuko[REDEEM OFFER](https://idownloadcoupon.com/udemy/3516/
)
* Deep Learning MasterClass[REDEEM OFFER](https://idownloadcoupon.com/udemy/3515/)
* Root Cause Analysis: Fishbone Dia
gram[REDEEM OFFER](https://idownloadcoupon.com/udemy/3514/)
* Lean Six Sigma Yellow Belt: Certification[REDEEM OFFER](ht
tps://idownloadcoupon.com/udemy/3513/)
* Lean Six Sigma Yellow Belt: Certification[REDEEM OFFER](https://idownloadcoupon
.com/udemy/3513/)
* FMEA: Failure, Modes, Effects, Analysis[REDEEM OFFER](https://idownloadcoupon.com/udemy/3512/)
* Org
anizational Culture Change[REDEEM OFFER](https://idownloadcoupon.com/udemy/3511/)
* Lean Management: Course & certificat
ion[REDEEM OFFER](https://idownloadcoupon.com/udemy/3510/)
* Root Cause Analysis: Drill Down Tool[REDEEM OFFER](https://
idownloadcoupon.com/udemy/3509/)
* SIPOC – Supplier, Input, Process, Output, Customer[REDEEM OFFER](https://idownloadcou
pon.com/udemy/3508/)
* Mastery of IT Project Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/3507/)
* The Web
site Blueprint – Planning for a web design project[REDEEM OFFER](https://idownloadcoupon.com/udemy/3506/)
* Mastering th
e Art of Leadership[REDEEM OFFER](https://idownloadcoupon.com/udemy/3505/)
* How to Draw Hair Better Than Anyone Else[RE
DEEM OFFER](https://idownloadcoupon.com/udemy/3504/)
* Options Trading for Beginners – Intro Session[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3503/)
* Building Rapport: Confident Conversations Without Small Talk[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/3502/)
* FFmpeg | Batch Modify Thousands of Videos Quickly and Easily[REDEEM OFFER](https://i
downloadcoupon.com/udemy/3501/)
* Introduction to the language of criminal law[REDEEM OFFER](https://idownloadcoupon.com
/udemy/3500/)
* 5 Calendar Trades – Detailed Walk through[REDEEM OFFER](https://idownloadcoupon.com/udemy/3499/)
* Finan
cial Statements for Beginners in 1 Hour or Less[REDEEM OFFER](https://idownloadcoupon.com/udemy/3498/)
```
---

     
 
all -  [ + 100 Free Courses for Monday, September 18, 2023 ](https://www.reddit.com/r/udemyfreebies/comments/16lt1zs/100_free_courses_for_monday_september_18_2023/) , 2023-09-19-0910
```
**Courses for 18 September 2023**

Note : Coupons might expire anytime, so enroll as soon as possible to get the courses
 for FREE.

* DBMS Module – 5[REDEEM OFFER](https://idownloadcoupon.com/udemy/3643/)
* Contact Center Manager Profession
al Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/3642/)
* Facebook Ads: Run Your First Ad Campaign[REDEE
M OFFER](https://idownloadcoupon.com/udemy/3641/)
* Master LangChain with No-Code tools: Flowise and LangFlow[REDEEM OFF
ER](https://idownloadcoupon.com/udemy/3640/)
* LEVEL 1 MODULE: BECOME A WEALTH MAGNET FOR LIFE: PART 4 OF 5[REDEEM OFFER
](https://idownloadcoupon.com/udemy/3639/)
* Search Engine Optimization (SEO) For Beginners Practise Test[REDEEM OFFER](
https://idownloadcoupon.com/udemy/3638/)
* Content Marketing For Intermediate Practise Test 2023[REDEEM OFFER](https://i
downloadcoupon.com/udemy/3637/)
* Boost Digital Marketing Effectiveness via Behavioral Science[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3636/)
* Python Development Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/3635/)
* L
eadership & Team Building Mastery[REDEEM OFFER](https://idownloadcoupon.com/udemy/3634/)
* Adobe Photoshop Projects[REDE
EM OFFER](https://idownloadcoupon.com/udemy/3633/)
* Pubslic Speaking Trainer: Enter the Presentation Training Biz[REDEE
M OFFER](https://idownloadcoupon.com/udemy/3631/)
* Storytelling: You Can learn to Tell Stories Effectively[REDEEM OFFER
](https://idownloadcoupon.com/udemy/3630/)
* Public Speaking for People Who Hate Public Speaking[REDEEM OFFER](https://i
downloadcoupon.com/udemy/3629/)
* Podcasting: How to Speak Effectively on Your Own Podcast[REDEEM OFFER](https://idownlo
adcoupon.com/udemy/3628/)
* Presentation Skills: Give Great Skype Video Presentations[REDEEM OFFER](https://idownloadcou
pon.com/udemy/3627/)
* Conference Calls-You Can Present Well On Any Conference Call[REDEEM OFFER](https://idownloadcoupo
n.com/udemy/3624/)
* Media Training for Print/Online Interviews-Get Great Quotes[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/3623/)
* Speaking on the Telephone: Confidently Speak on the Phone[REDEEM OFFER](https://idownloadcoupon.com/ud
emy/3622/)
* Interviewing Skills: Conducting Job Interviews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3621/)
* Mar
keting Strategy: Communicating Your Message[REDEEM OFFER](https://idownloadcoupon.com/udemy/3620/)
* Personal Presentati
on Training[REDEEM OFFER](https://idownloadcoupon.com/udemy/3619/)
* Public Speaking Emergency! Ace the Speech With Litt
le Prep[REDEEM OFFER](https://idownloadcoupon.com/udemy/3618/)
* Emergency Media Training: You Can Face a Reporter In 2 
Hours[REDEEM OFFER](https://idownloadcoupon.com/udemy/3617/)
* Media Training for Beginners: Ace Your First News Intervi
ews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3616/)
* Recon For Bug Bounty, Penetration Testers & Ethical Hackers
[REDEEM OFFER](https://idownloadcoupon.com/udemy/3615/)
* Python – Data Analytics – Real World Hands-on Projects[REDEEM 
OFFER](https://idownloadcoupon.com/udemy/3614/)
* QuickBooks Online vs. Excel 2023[REDEEM OFFER](https://idownloadcoupon
.com/udemy/3613/)
* QuickBooks Desktop vs. Excel[REDEEM OFFER](https://idownloadcoupon.com/udemy/3612/)
* QuickBooks Onl
ine vs. QuickBooks Desktop vs. Excel[REDEEM OFFER](https://idownloadcoupon.com/udemy/3611/)
* Two QuickBooks File-Busine
ss & Personal vs One File For Both[REDEEM OFFER](https://idownloadcoupon.com/udemy/3610/)
* QuicksBooks Pro-Business & P
ersonal-One QuickBooks File[REDEEM OFFER](https://idownloadcoupon.com/udemy/3609/)
* QuickBooks Online vs Xero Accountin
g Software[REDEEM OFFER](https://idownloadcoupon.com/udemy/3608/)
* QuickBooks Desktop vs QBO Multiple Currencies[REDEEM
 OFFER](https://idownloadcoupon.com/udemy/3607/)
* Fast track French for beginners[REDEEM OFFER](https://idownloadcoupon
.com/udemy/3606/)
* Sales management – streams, frameworks and processes[REDEEM OFFER](https://idownloadcoupon.com/udemy
/3605/)
* Corporate Finance #15 Dividend Policy[REDEEM OFFER](https://idownloadcoupon.com/udemy/3604/)
* Corporate Finan
ce #16 Convertible Bonds & Warrants[REDEEM OFFER](https://idownloadcoupon.com/udemy/3603/)
* Corp. Finance #14 Financing
-Commons Stock & Preferred Stock[REDEEM OFFER](https://idownloadcoupon.com/udemy/3602/)
* Proceso CRUD (C Sharp y Micros
oft SQL Server)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3601/)
* SQL Bootcamp – SQLite – Hands-On Exercises[REDE
EM OFFER](https://idownloadcoupon.com/udemy/3600/)
* AWS Certified Data Analytics Specialty DAS-C01 – Mock Exams[REDEEM 
OFFER](https://idownloadcoupon.com/udemy/3599/)
* SQL Developer Certification: Test Your Skills with Tests[REDEEM OFFER]
(https://idownloadcoupon.com/udemy/3598/)
* Google Professional Cloud Security Engineer – Practice Exams[REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/3597/)
* Recursion and Backtracking Algorithms in Java[REDEEM OFFER](https://idownloadc
oupon.com/udemy/3596/)
* Python for Intermediate Learners (2023)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3595/)

* Mastering HTML5: From Beginner to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/3594/)
* Graph Theory Algor
ithms in Java[REDEEM OFFER](https://idownloadcoupon.com/udemy/3593/)
* Dynamic Programming Algorithms for Coding Intervi
ews[REDEEM OFFER](https://idownloadcoupon.com/udemy/3592/)
* Curso de Base de Datos SQLite[REDEEM OFFER](https://idownlo
adcoupon.com/udemy/3591/)
* Curso de Java – Nivel Básico[REDEEM OFFER](https://idownloadcoupon.com/udemy/3590/)
* Rúbric
as para la evaluación de desempeño de los aprendizajes[REDEEM OFFER](https://idownloadcoupon.com/udemy/3589/)
* Curso de
 Base de Datos Oracle Database[REDEEM OFFER](https://idownloadcoupon.com/udemy/3588/)
* Curso de Base de Datos Firebird[
REDEEM OFFER](https://idownloadcoupon.com/udemy/3587/)
* Desarrollando Sistema de Ventas (C# y MySQL Server)[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/3586/)
* Job Cost QuickBooks Online vs QuickBooks Desktop–Contractor[REDEEM OFFER](
https://idownloadcoupon.com/udemy/3585/)
* Corp Finance #12 Capital Budgeting & Investment Risk Tools[REDEEM OFFER](http
s://idownloadcoupon.com/udemy/3584/)
* Corporate Finance #13 Investment Banking & Long-Term Debt[REDEEM OFFER](https://i
downloadcoupon.com/udemy/3583/)
* LeetCode in Java: Algorithms Coding Interview Questions[REDEEM OFFER](https://idownloa
dcoupon.com/udemy/3582/)
* The Complete C Programming Course for Beginners[REDEEM OFFER](https://idownloadcoupon.com/ude
my/3581/)
* Bank Feeds-QuickBooks Online, Xero, Sage, Wave (Comparison)[REDEEM OFFER](https://idownloadcoupon.com/udemy/
3580/)
* Corp Finance #10 Cost of Capital–Debt & Equity Financing[REDEEM OFFER](https://idownloadcoupon.com/udemy/3579/)

* Corporate Finance #9 Valuation-Bond, Common /Preferred Stock[REDEEM OFFER](https://idownloadcoupon.com/udemy/3578/)
*
 The Complete Data Structures and Algorithms Course in Java[REDEEM OFFER](https://idownloadcoupon.com/udemy/3577/)
* Cor
porate Finance #8 Time Value of Money (PV & FV)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3576/)
* Corporate Finan
ce #7 Short Term Financing[REDEEM OFFER](https://idownloadcoupon.com/udemy/3575/)
* Corporate Finance #4 Leverage & Brea
k-Even Analysis[REDEEM OFFER](https://idownloadcoupon.com/udemy/3574/)
* Corporate Finance #5 Financing Decisions[REDEEM
 OFFER](https://idownloadcoupon.com/udemy/3573/)
* Corporate Finance #6 Management of Current Assets[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3572/)
* Corporate Finance #1 Introduction & Financial Statements[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3571/)
* Corporate Finance #3 Forecasting & Budgeting[REDEEM OFFER](https://idownloadcoupon.com/u
demy/3570/)
* Corporate Finance #2 Financial Ratios[REDEEM OFFER](https://idownloadcoupon.com/udemy/3569/)
* Automated M
achine Learning for Beginners (Google & Apple)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3568/)
* Partnership Acco
unting – Financial Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3567/)
* Financial Accounting – Closing Pr
ocess[REDEEM OFFER](https://idownloadcoupon.com/udemy/3566/)
* Bank Reconciliations & Cash Internal Controls[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/3565/)
* Financial Accounting – Closing Process[REDEEM OFFER](https://idownloadcoup
on.com/udemy/3564/)
* Financial Accounting – Subsidiary Ledgers & Special Journals[REDEEM OFFER](https://idownloadcoupon
.com/udemy/3563/)
* Financial Accounting–Inventory & Merchandising Transactions[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/3562/)
* Financial Accounting – Inventory Costs[REDEEM OFFER](https://idownloadcoupon.com/udemy/3561/)
* Time Va
lue of Money & Capital Budgeting – Present Value[REDEEM OFFER](https://idownloadcoupon.com/udemy/3560/)
* Financial Acco
unting-Adjusting Entries & Financial Statement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3559/)
* Financial Accoun
ting-Debits & Credits-Accounting Transaction[REDEEM OFFER](https://idownloadcoupon.com/udemy/3558/)
* Receivables & The 
Allowance vs The Direct Write Off Methods[REDEEM OFFER](https://idownloadcoupon.com/udemy/3557/)
* Accounting for Corpor
ations – Financial Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3556/)
* Accounting-Statement of Cash Flow
s[REDEEM OFFER](https://idownloadcoupon.com/udemy/3555/)
* Job Order Costing System – Managerial Accounting[REDEEM OFFER
](https://idownloadcoupon.com/udemy/3554/)
* Advanced Microsoft Word With Job Success[REDEEM OFFER](https://idownloadcou
pon.com/udemy/3553/)
* Financial Accounting-Depreciation Calculation & Fixed Assets[REDEEM OFFER](https://idownloadcoupo
n.com/udemy/3552/)
* Payroll Calculations Training for Financial Accounting[REDEEM OFFER](https://idownloadcoupon.com/ud
emy/3551/)
* Process Costing System-Cost Accounting-Managerial Accounting[REDEEM OFFER](https://idownloadcoupon.com/udem
y/3550/)
* Responsibility Accounting & Performance Measurement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3549/)
* 
Complete PYTHON Programming for Beginners – 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/3548/)
* Relevant Costs
 – Managerial Accounting Decisions & Scenarios[REDEEM OFFER](https://idownloadcoupon.com/udemy/3547/)
* Master Budgets –
 Managerial Accounting/Cost Accounting[REDEEM OFFER](https://idownloadcoupon.com/udemy/3546/)
* C++ Assessment Toolkit: 
Diverse Practice Tests for All Level[REDEEM OFFER](https://idownloadcoupon.com/udemy/3545/)
* Practice Tests: Crack the 
Python PCEP Certification Exam[REDEEM OFFER](https://idownloadcoupon.com/udemy/3544/)
* Ace the Python Challenge: 60 Rea
listic Practice Questions[REDEEM OFFER](https://idownloadcoupon.com/udemy/3543/)
* C++ Practice Intensives: Sharpen Skil
ls with 4 Rigorous Test[REDEEM OFFER](https://idownloadcoupon.com/udemy/3542/)
* Wondershare Filmora 11 Video Editing Co
urse in Hindi[REDEEM OFFER](https://idownloadcoupon.com/udemy/3541/)
* Excellence in Interpersonal Skills (People & Soci
al Skills)[REDEEM OFFER](https://idownloadcoupon.com/udemy/3540/)
* iOS 16 Swift & SwiftUI – Complete iOS App Developmen
t[REDEEM OFFER](https://idownloadcoupon.com/udemy/3539/)
* Python for Intermediate Learners (2023)[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/3538/)
* Consumer behavior, Consumer Intention & Consumer Attitude[REDEEM OFFER](https://idow
nloadcoupon.com/udemy/3537/)
* Excel – Formulas & Functions Beginner to Expert Course 2023[REDEEM OFFER](https://idownlo
adcoupon.com/udemy/3536/)
* Excellence in Problem Solving Skills & Strategies[REDEEM OFFER](https://idownloadcoupon.com/
udemy/3535/)
* Rank Your Blog Website in Google: SEO For Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/
3534/)
* Python Complete Course For Python Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/3533/)
* Javascript
 Build a Calculator using HTML, CSS and Javascript[REDEEM OFFER](https://idownloadcoupon.com/udemy/3532/)
* 23.8″ Монито
р Philips 243V7QDAB, 1920×1080, 75 Гц, IPS[REDEEM OFFER](https://idownloadcoupon.com/udemy/3531/)
* Python & Django REST
 API Bootcamp – Build A Python Web API[REDEEM OFFER](https://idownloadcoupon.com/udemy/3530/)
* Flutter REST Movie App: 
Master Flutter REST API Development[REDEEM OFFER](https://idownloadcoupon.com/udemy/3529/)
* Flutter UI Bootcamp | Build
 Beautiful Apps using Flutter[REDEEM OFFER](https://idownloadcoupon.com/udemy/3528/)
* Build A Chat Application With Fir
ebase, Flutter and Provider[REDEEM OFFER](https://idownloadcoupon.com/udemy/3527/)
* C++ Mastery through 4 Logical Pract
ice Tests[REDEEM OFFER](https://idownloadcoupon.com/udemy/3526/)
* C++ Challenge: 4 Intensive Practice Exams[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/3525/)
* Python Practice Exams: Elevate Your Programming Skills[REDEEM OFFER](https
://idownloadcoupon.com/udemy/3524/)
* Master Python Web Scraping & Automation using BS4 & Selenium[REDEEM OFFER](https:/
/idownloadcoupon.com/udemy/3523/)
* Python Quest: 60 Challenging Question to Enhance Your Skill[REDEEM OFFER](https://id
ownloadcoupon.com/udemy/3522/)
* Sharpen Your C++ Skills with 4 Challenging Practice Tests[REDEEM OFFER](https://idownlo
adcoupon.com/udemy/3521/)
* CSS, Bootstrap ,JavaScript, Web Development Course[REDEEM OFFER](https://idownloadcoupon.com
/udemy/3520/)
* Continuous Improvement[REDEEM OFFER](https://idownloadcoupon.com/udemy/3519/)
* Business Improvement Pla
n[REDEEM OFFER](https://idownloadcoupon.com/udemy/3518/)
* Process Mapping: Toolkit[REDEEM OFFER](https://idownloadcoupo
n.com/udemy/3517/)
* Learn Japanese For Beginners With Natsuko[REDEEM OFFER](https://idownloadcoupon.com/udemy/3516/)
* 
Deep Learning MasterClass[REDEEM OFFER](https://idownloadcoupon.com/udemy/3515/)
* Root Cause Analysis: Fishbone Diagram
[REDEEM OFFER](https://idownloadcoupon.com/udemy/3514/)
* Lean Six Sigma Yellow Belt: Certification[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/3513/)
* Lean Six Sigma Yellow Belt: Certification[REDEEM OFFER](https://idownloadcoupon.com
/udemy/3513/)
* FMEA: Failure, Modes, Effects, Analysis[REDEEM OFFER](https://idownloadcoupon.com/udemy/3512/)
* Organiz
ational Culture Change[REDEEM OFFER](https://idownloadcoupon.com/udemy/3511/)
* Lean Management: Course & certification[
REDEEM OFFER](https://idownloadcoupon.com/udemy/3510/)
* Root Cause Analysis: Drill Down Tool[REDEEM OFFER](https://idow
nloadcoupon.com/udemy/3509/)
* SIPOC – Supplier, Input, Process, Output, Customer[REDEEM OFFER](https://idownloadcoupon.
com/udemy/3508/)
* Mastery of IT Project Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/3507/)
* The Website
 Blueprint – Planning for a web design project[REDEEM OFFER](https://idownloadcoupon.com/udemy/3506/)
* Mastering the Ar
t of Leadership[REDEEM OFFER](https://idownloadcoupon.com/udemy/3505/)
* How to Draw Hair Better Than Anyone Else[REDEEM
 OFFER](https://idownloadcoupon.com/udemy/3504/)
* Options Trading for Beginners – Intro Session[REDEEM OFFER](https://i
downloadcoupon.com/udemy/3503/)
* Building Rapport: Confident Conversations Without Small Talk[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/3502/)
* FFmpeg | Batch Modify Thousands of Videos Quickly and Easily[REDEEM OFFER](https://idown
loadcoupon.com/udemy/3501/)
* Introduction to the language of criminal law[REDEEM OFFER](https://idownloadcoupon.com/ude
my/3500/)
* 5 Calendar Trades – Detailed Walk through[REDEEM OFFER](https://idownloadcoupon.com/udemy/3499/)
* Financial
 Statements for Beginners in 1 Hour or Less[REDEEM OFFER](https://idownloadcoupon.com/udemy/3498/)

GET MORE FREE ONLINE
 COURSES WITH CERTIFICATE – [CLICK HERE](https://www.reddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ Recommend platform for openai response and request ](https://www.reddit.com/r/LangChain/comments/16lq7o8/recommend_platform_for_openai_response_and_request/) , 2023-09-19-0910
```
I am looking for a platoform/dashboard which can be used to track openai response and requests. some thing like vellum o
r promptlayer
```
---

     
 
all -  [ Has anyone already got a template for RAG and Oobabooga API ](https://www.reddit.com/r/LocalLLaMA/comments/16lq5b7/has_anyone_already_got_a_template_for_rag_and/) , 2023-09-19-0910
```
E.g. Using langchain, llamaindex or their own python
```
---

     
 
all -  [ TypeError: '<' not supported between instances of 'int' and 'str' ](https://www.reddit.com/r/LangChain/comments/16lkf4b/typeerror_not_supported_between_instances_of_int/) , 2023-09-19-0910
```
 from langchain.document\_loaders import WikipediaLoader  
from langchain.text\_splitter import RecursiveCharacterTextSp
litter  
from langchain.vectorstores import Chroma  
from langchain.embeddings import HuggingFaceEmbeddings  
from langc
hain.chains import RetrievalQA  
from langchain.prompts import PromptTemplate  
from set\_llm import set\_llm  
llm = se
t\_llm(0) #llm initialization  
embeddings = HuggingFaceEmbeddings(model\_name='sentence-transformers/all-MiniLM-L6-v2')
  
docs = WikipediaLoader('Epic (2013 film)', load\_max\_docs=1).load()  
text\_splitter = RecursiveCharacterTextSplitte
r(  
 chunk\_size='1000',  
 chunk\_overlap='100',  
 length\_function=len,  
 is\_separator\_regex=False  
)  
data = t
ext\_splitter.split\_documents(docs)  
db = Chroma.from\_documents(  
 data=data,  
 embedding=embeddings,  
 ids=\[f'{i
tem.metadata\['source'\]}-{index}' for index, item in enumerate(data)\],  
 collection\_name='Epic 2013\_db',  
 persist
\_directory='VectorDB'  
)  
template = '''You are a bot who can answer questions using only the context provided.  
If 
you don't know the answer, simply say that you don't know  
{context}  
Question: {question}  
'''  
PROMPT = PromptTemp
late(  
 template=template, input\_variables=\['context', 'question'\]  
)  
qa\_with\_source = RetrievalQA.from\_chain\
_type(  
 llm=llm,  
 chain\_type='stuff',  
 retriever = db.as\_retriever(),  
 chain\_type\_kwargs={'prompt': PROMPT},
  
 return\_source\_documents=True  
)  
query = input('Your question: ')  
print(qa\_with\_source(query))  


I was fol
lowing a youtube video and wrote the above code. Am getting 'TypeError: '<' not supported between instances of 'int' and
 'str' ' at data = text\_splitter.split\_documents(docs)  


Can anyone let me know what's the problem with the code?  


```
---

     
 
all -  [ Share you success and horror LangChain in Production stories ](https://www.reddit.com/r/LangChain/comments/16lfju8/share_you_success_and_horror_langchain_in/) , 2023-09-19-0910
```
Been working on a recommender PoC that’s customer facing for large org. Evaluating whether to stick with LangChain going
 forward and would love to hear your success and horror stories of LangChain in production serving high volume requests.
 Stick with LangChain, another framework, or roll your own?
```
---

     
 
all -  [ What are people using the OpenAI APIs for? ](https://www.reddit.com/r/OpenAI/comments/16le9sb/what_are_people_using_the_openai_apis_for/) , 2023-09-19-0910
```
It seems everyone is head down coding on open-ended tools / infra like langchain, vector DBs, or even ChatGPT itself.

I
’m curious, how are businesses using LLMs? It seems for 99% of use cases building a smaller, focused model would be the 
best way to solve a real business problem.
```
---

     
 
all -  [ Can I get a LangSmith Invite Code ](https://www.reddit.com/r/LangChain/comments/16l9npt/can_i_get_a_langsmith_invite_code/) , 2023-09-19-0910
```
Guys I am terribly lost in the logs of my Custom Agent and I need to try this Langchain at least to see how bad the situ
ation is. Is it possible to send me an invite code? Been on the waitlist for ages :/
```
---

     
 
all -  [ Question about creating embeddings using a database ](https://www.reddit.com/r/LangChain/comments/16l4pbk/question_about_creating_embeddings_using_a/) , 2023-09-19-0910
```
Hello,

I am using postgres and have two tables I would like to use:  
1. places table - e.g. attractions around the wor
ld  
2. large reviews table (millions) - what people say about those attractions (with relation to a place using an ID)


I would like AI to be able to answer questions about those attractions, as well as possibly provide recommendations. I 
thought to use pgvector as I am using postgres (but open for alternatives). I would like to know what is the best way to
 approach it.

Should I create embeddings per review (e.g. a vector field per review)? Do you maybe have an example? Las
tly, since the data is not required to be 'live' (but I would like to get answers quickly) would it be better to train t
he AI instead of context injections? Any tops are welcome.

Thanks
```
---

     
 
all -  [ From API batch to streaming changes the pipeline, how to handle? ](https://www.reddit.com/r/LangChain/comments/16l34xd/from_api_batch_to_streaming_changes_the_pipeline/) , 2023-09-19-0910
```
Hey,

Working on using an LLM for a recommendation use case, let's say it's to list top n cars according to some custome
r criteria.

&#x200B;

The pipeline is simple - prompt with some input variables (customer requirements) and constraints
 (e.g. only from certain brands), with an output parser for text to JSON.

&#x200B;

Using FastAPI as the backend, withi
n which Langchain is used to orchestrate, the full completion where OpenAI gpt-3.5-turbo in streaming=False mode, was ta
king around 20 seconds to complete. When complete, I render the top cars, each as a card, on the UI.  The high latency i
s not a great user experience.

&#x200B;

I've updated FastAPI and model to work in streaming mode, but this now present
s me with a dilemma. In batch mode the chain was working as follows: 1) prompt asking the model to generate the complete
 top n list of cars, then 2) output parsing (pydantic model of car card). As I want to start feeding recommended cars ba
ck to the UI as soon as they become available, I'm wondering how best to re-engineer, i.e. as soon as I get a recommenda
tion, parse text of car description including model and brand to JSON, and serve to UI. 

&#x200B;

Ideally I wanted the
 FastAPI layer to handle everything (recommendation and output parsing), and not fall back to the FastAPI only getting t
he recommendation and the UI having to transform the text stream to JSON-based car cards as the text comes in. 

&#x200B
;

Hope I've explained the challenge OK. Any thoughts & ideas very much welcome, thanks!
```
---

     
 
all -  [ To deep dive and be good with LLMs you need a complex Langchain project behind you...... ](https://www.reddit.com/r/LangChain/comments/16l2u62/to_deep_dive_and_be_good_with_llms_you_need_a/) , 2023-09-19-0910
```
Hey,

As per title, I read a post sometime ago that stated to be good with, and deep dive into LLMs, you need to have ta
ckled a 'complex' Langchain project.  Which of course got me thinking about the definition of complex.

Would love to ha
ve some thoughts on what that means to you? Would it require a combination of multi-modal / multi-lingual / chunking / f
ine-tuning / vector db / agents & tools / short and long term memory management?

Intrigued about the perspectives on th
is from the community, thanks.
```
---

     
 
all -  [ Langchain Chatgpt Interactive survey. ](https://www.reddit.com/r/LangChain/comments/16l271i/langchain_chatgpt_interactive_survey/) , 2023-09-19-0910
```
Basically, I am trying to build the multiuser langchain chatbot. I am using pgvector to store embeddings. With page_cont
ent i have a json object stored in metadata ( basically a survey) that i  want a user to fill out interactively. For exa
mple my user asks some question and answer is provided with suggestion that there is a survey linked to this content wou
ld you like to fill this survey? And if user agrees it would start asking questions one by one and in the end it generat
es json object of the filled survey.
```
---

     
 
all -  [ Exe files created using pyinstaller are always larger than I expected, what am I doing wrong? ](https://www.reddit.com/r/learnpython/comments/16kxnga/exe_files_created_using_pyinstaller_are_always/) , 2023-09-19-0910
```
Whenever I use pyinstaller to create a portable exe, using pyinstaller --onefile -script.py nothing fancy, the result is
 always bigger than I expected. A simple web scraping script using Selenium can be as large as 80mb. 

Recently I made a
 portable program for PrivateGPT, a private LLMs, and the program alone is 1.5GB. This is not including the actual LLM i
tself. I investigated and it seems like pyinstaller decide that I need the whole torch library (800MB) to run the script
. I'm skeptical of that. I don't even use torch in my script. Seems like some part of torch is needed to support langcha
in library but I'm not sure about the whole thing. 

All in all, I wonder if just using  'pyinstaller --onefile' is fine
 or not? What are some common tricks/options to use with pyinstaller?
```
---

     
 
all -  [ Recommendations for open-source LLM models ](https://www.reddit.com/r/LangChain/comments/16kjre0/recommendations_for_opensource_llm_models/) , 2023-09-19-0910
```
Hello everyone, I've always used OpenAI models, but I'd like to start exploring the open-source world, and indeed, for c
ertain tasks, there are some strong competitors. In your experience, what are the best models for:

1. Embedding
2. Zero
-shot classification
3. Question answering (extraction)

Thank you.
```
---

     
 
all -  [ LangChain Archeticture to simulate ChatDev. ](https://www.reddit.com/r/LangChain/comments/16k765e/langchain_archeticture_to_simulate_chatdev/) , 2023-09-19-0910
```
I have been intrigued with the ChatDev, but want to use it in a local environment   and use different models for differe
nt characters. Has anyone taken a stab as mixing them up? What similar types of software accomplish the same objectives,
 but don't require an open AI key?
```
---

     
 
all -  [ Best Program and Model to read local pdf or epub with GPTQ model ](https://www.reddit.com/r/LangChain/comments/16k6dbg/best_program_and_model_to_read_local_pdf_or_epub/) , 2023-09-19-0910
```
hi, i want to read, search and resume my personnal pdf, docx or epub document localy on my computer.

**what model and p
rogram do you advice ?**

for the moment i test :  
Programm : H2oGPT, chatdocs and privategpt  
Models : vicuna uncenso
red, Nous-Yarn-Llama-2-13b-128k 	

thanks  

```
---

     
 
all -  [ Horde-Client v1.0.2 is out today! ](https://www.reddit.com/r/LocalLLaMA/comments/16k1j31/hordeclient_v102_is_out_today/) , 2023-09-19-0910
```
Few days back, I shared my project [horde-client](https://pypi.org/project/horde-client/). For those who missed the post
, this is a Python Client library for KoboldAI project that lets you remotely interact with crowdsourced/private LLM ser
vices. 

I got some great feedback in the last post and have incorporated majority of them in the new release. 

So toda
y, I am announcing v1.0.2  version of project with cool new features:

1. Horde-Client now supports [LangChain](https://
horde-client.readthedocs.io/en/latest/02_langchain.html) integration. You can easily swap out LLMs from your LangChain p
ipeline and use Horde-Client's LLM.
2. Official Documentation is now available at [https://horde-client.readthedocs.io/]
(https://horde-client.readthedocs.io/)
3. [Async](https://horde-client.readthedocs.io/en/latest/03_asyncclient.html) sup
port is now available for Horde-Client.

You can head over to [Quickstart](https://horde-client.readthedocs.io/en/latest
/01_quickstart.html) to start using Horde-Client for your projects.

Feel free to share any feedbacks, this will help im
prove the project for the community.
```
---

     
 
all -  [ GPTQ models with Langchain ](https://www.reddit.com/r/LangChain/comments/16jzm6r/gptq_models_with_langchain/) , 2023-09-19-0910
```
I am trying to use GPTQ models via Langchain. I am creating a huggingface pipeline object and passing that as the LLM in
stead of OpenAI. 

However, when I try to query CSV/dataframes with this, the speed is abysmally slow and the code gets 
stuck. The same model works fine when I use it for normal text generation outside Langchain. 

What is the best way to i
nteract with CSVs/Dataframes with my own model? If anyone has experience debugging, what is the best way to proceed next
?
```
---

     
 
all -  [ LLM for textbooks, feasible ? ](https://www.reddit.com/r/learnmachinelearning/comments/16jlt3n/llm_for_textbooks_feasible/) , 2023-09-19-0910
```
I want to build a webapp SAAS that allows you to chat with an AI tutor about  specific textbook. Some of these textbooks
 are in English and others are Arabic, conceptual , no equations or anything.
I couldn't find anything like this. Im a t
otal noob with AI. but I think it can be made using langchain and openai api , can it ?
```
---

     
 
all -  [ Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/LocalLLaMA/comments/16jl53m/agents_an_opensource_framework_for_autonomous/) , 2023-09-19-0910
```
I hope this paper is also interesting this community!

Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2
309.07870) 

Github: [https://github.com/aiwaves-cn/agents](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent a
dvances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can a
utomatically solve various tasks and **interact with environments, humans, and other agents** using natural language int
erfaces. **We consider language agents as a promising direction towards artificial general intelligence** and release Ag
ents, an **open-source library** with the goal of opening up these advances to a wider non-specialist audience. Agents i
s carefully engineered to support important **features including planning, memory,  tool usage, multi-agent communicatio
n, and fine-grained symbolic  control.** Agents is **user-friendly** as it **enables non-specialists** to build, customi
ze, test, tune, and deploy state-of-the-art **autonomous language agents without much coding**. The **library** is also 
**research-friendly as its modularized design** makes it **easily extensible for researchers.** 

https://preview.redd.i
t/ne8fsj05rgob1.jpg?width=1131&format=pjpg&auto=webp&s=076a3551bddb817351d9865809923a6bdf840cb1

https://preview.redd.it
/u4x4hm05rgob1.jpg?width=1656&format=pjpg&auto=webp&s=2ca813790719b1f6f285e67ca92834e02d12c40c

&#x200B;

&#x200B;
```
---

     
 
all -  [ Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/agi/comments/16jl4rw/agents_an_opensource_framework_for_autonomous/) , 2023-09-19-0910
```
Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2309.07870) 

Github: [https://github.com/aiwaves-cn/age
nts](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent advances on large language models (LLMs) enable research
ers and developers to build autonomous language agents that can automatically solve various tasks and **interact with en
vironments, humans, and other agents** using natural language interfaces. **We consider language agents as a promising d
irection towards artificial general intelligence** and release Agents, an **open-source library** with the goal of openi
ng up these advances to a wider non-specialist audience. Agents is carefully engineered to support important **features 
including planning, memory,  tool usage, multi-agent communication, and fine-grained symbolic  control.** Agents is **us
er-friendly** as it **enables non-specialists** to build, customize, test, tune, and deploy state-of-the-art **autonomou
s language agents without much coding**. The **library** is also **research-friendly as its modularized design** makes i
t **easily extensible for researchers.** 

https://preview.redd.it/impiu2f5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=
032644106e6ccebda499680560c2e8016485e1b1

https://preview.redd.it/2w5i64f5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=0
3a9f64546c4240654837fd3bbf577b13632f31f

&#x200B;
```
---

     
 
all -  [ [R] Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/) , 2023-09-19-0910
```
Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2309.07870) 

Github: [https://github.com/aiwaves-cn/age
nts](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent advances on large language models (LLMs) enable research
ers and developers to build autonomous language agents that can automatically solve various tasks and **interact with en
vironments, humans, and other agents** using natural language interfaces. **We consider language agents as a promising d
irection towards artificial general intelligence** and release Agents, an **open-source library** with the goal of openi
ng up these advances to a wider non-specialist audience. Agents is carefully engineered to support important **features 
including planning, memory,  tool usage, multi-agent communication, and fine-grained symbolic  control.** Agents is **us
er-friendly** as it **enables non-specialists** to build, customize, test, tune, and deploy state-of-the-art **autonomou
s language agents without much coding**. The **library** is also **research-friendly as its modularized design** makes i
t **easily extensible for researchers.** 

https://preview.redd.it/3bdi71r5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=
760942c19be6ecda791414c812a77e72751c526d

https://preview.redd.it/howf64r5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=6
36744fccab7a1c2bafb902bad5dbb647440fff5

&#x200B;
```
---

     
 
all -  [ Easiest way to launch & experiment with a langchain powered Python app via chat interface ](https://www.reddit.com/r/LangChain/comments/16jhi3e/easiest_way_to_launch_experiment_with_a_langchain/) , 2023-09-19-0910
```
I'm building an agent and I want to be able to interact with it easily. I've been thinking WhatsApp or Jupyter notebooks
 are the easiest way to start, but feels like there's probably some canonical solution folks are using?  


All I'm look
ing for is some experience where I can provide a chat API and it'll handle frontend chat experience for interaction.
```
---

     
 
all -  [ How much preprocessing are you doing for RAG QA chatbots w/ documents? ](https://www.reddit.com/r/LocalLLaMA/comments/16jde4z/how_much_preprocessing_are_you_doing_for_rag_qa/) , 2023-09-19-0910
```
I know there is a ton of interest in document QA systems, which makes sense since it has good business values to most or
ganizations.

I'm wondering for those of you who found the answers from you QA systems to be good, did you guys just dro
p the PDF / Word / etc... into the program and let the RecursiveCharacterSplitter in langchain do the work, or did you g
uys do some preprocessing before you chunked it up and loaded into the vector db.  
I am trying to do QA on a PDF of a t
extbook. I wrote some scripts to 'chunk' the textbook so each chunk also contains it's associated Title and Subheading. 


&#x200B;

Let's say we are in Chapter: Carbon-Carbon Bonds. Below is an example passage:  


Grignard Reaction:

The g
rignard reaction is very lit. Only the most based can perform it. Blah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah 
BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBl
ah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah  


I would then crea
te chunks from this passage like this:

&#x200B;

Carbon-Carbon Bonds

Grignard Reaction

The grignard reaction is very 
lit. Only the most based can perform it. Blah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Bl
ah BlahBlah Blah Blah

\-------------------------------------------------------

Carbon-Carbon Bonds

Grignard Reaction


Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah

Blah Blah BlahBlah Blah BlahBlah 
Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah  


Then I embed the chunks. The idea is that including the title an
d header will make have a higher similarity score.

Has anyone found it necessary to perform this type of chunking? Anyo
ne getting great results with easier methods?  


  


  


&#x200B;

&#x200B;

&#x200B;

&#x200B;
```
---

     
 
all -  [ Leveraging code generation tools for LangChain based project ](https://www.reddit.com/r/LangChain/comments/16jarl3/leveraging_code_generation_tools_for_langchain/) , 2023-09-19-0910
```
Hi !

I am looking to leverage the code generation features of LLM to create up-to-date apps. Currently, if I try to dev
elop a minor script utilizing the LangChain library through ChatGPT, it is unfeasible given its existing knowledge base 
(Sep 21).

How would you go about ensuring that the generated code using any library aligns with the most recent documen
tation? Someone was mentioning Claude, and to feed him with the documentation. 

Any other suggestions? Especially for d
evelopers in Europe ;)

Thanks !
```
---

     
 
all -  [ Need help for Langchain Agents with memories ](https://www.reddit.com/r/LangChain/comments/16j7w5w/need_help_for_langchain_agents_with_memories/) , 2023-09-19-0910
```
Here is the detailed description of my issue, can anyone help me.

https://github.com/langchain-ai/langchain/discussions
/10568
```
---

     
 
all -  [ Laptop freezing on running embedding and vectorstore ](https://www.reddit.com/r/LangChain/comments/16j75vv/laptop_freezing_on_running_embedding_and/) , 2023-09-19-0910
```
My laptop has i7 16 core processor and yet it freezes midway between running the program i'm following. Also the vectors
tore never loads. I have tried FAISS and Chroma

Here's the code below:

 

import streamlit as st  
from dotenv import 
load\_dotenv  
from PyPDF2 import PdfReader  
from langchain.text\_splitter import CharacterTextSplitter  
from langchai
n.embeddings import HuggingFaceInstructEmbeddings  
from langchain.vectorstores import FAISS  
from langchain.chat\_mode
ls import ChatOpenAI  
from langchain.memory import ConversationBufferMemory  
from langchain.chains import Conversation
alRetrievalChain  
from htmlTemplates import css, bot\_template, user\_template  
from langchain.llms import HuggingFace
Hub  


def get\_pdf\_text(pdf\_docs):  
 text = ''  
 for pdf in pdf\_docs:  
 pdf\_reader = PdfReader(pdf)  
 for page
 in pdf\_reader.pages:  
 text += page.extract\_text()  
 return text  


def get\_text\_chunks(text):  
 text\_splitter
 = CharacterTextSplitter(  
 separator='\\n',  
 chunk\_size=1000,  
 chunk\_overlap=200,  
 length\_function=len  
)  

 chunks = text\_splitter.split\_text(text)  
 return chunks  
def get\_vectorstore(text\_chunks):  
 embeddings = Huggin
gFaceInstructEmbeddings(model\_name='hkunlp/instructor-xl')  
 vectorstore = FAISS.from\_texts(texts=text\_chunks, embed
ding=embeddings)  
 st.write('3')  
 return vectorstore  


def main():  
 load\_dotenv()  
 st.set\_page\_config(page\_
title='Chat with your documents', page\_icon=':books:')  
 st.header('Chat with your documents :books:')  
 st.text\_inp
ut('Ask a question about your documents:')  
 with st.sidebar:  
 st.subheader('Your documents')  
 pdf\_docs=st.file\_u
ploader('Upload your PDFs here and click on 'Process'', accept\_multiple\_files=True)  
 if st.button('Process'):  
 wit
h st.spinner('Processing'):  
 \#get info from pdfs  
 raw\_text=get\_pdf\_text(pdf\_docs)  
   
 \#get text chunks  
 t
ext\_chunks = get\_text\_chunks(raw\_text)  
 st.write('workin')  
 \#create vector database  
 vectorstore = get\_vecto
rstore(text\_chunks)  
 st.write('4')  
   


if \_\_name\_\_ == '\_\_main\_\_':  
 main()

&#x200B;

I have been follow
ing this tutorial: [https://www.youtube.com/watch?v=dXxQ0LR-3Hg&t=8s](https://www.youtube.com/watch?v=dXxQ0LR-3Hg&t=8s)
```
---

     
 
all -  [ Some questions of implementing LLM to generate Q/A pairs based on local documents ](https://www.reddit.com/r/LocalLLaMA/comments/16j624z/some_questions_of_implementing_llm_to_generate_qa/) , 2023-09-19-0910
```
Recently, I have been paying around about how to implement chat-based Q/A using the LLM model based on a local knowledge
 base. 

I have experimented with the following two open-source frameworks. 

[Llama\_index](https://github.com/jerryjli
u/llama_index)

[Langchain-chatchat](https://github.com/chatchat-space/Langchain-Chatchat)

  
I believe these 2 framewo
rks are built upon what everyone refers to as the RAG (Retrieval-Augmented Generation) approach. Without altering the em
beddings and LLM, it allows for generating responses based on one's own knowledge base. 

Thanks for the author's excell
ent work, I have indeed been able to achieve my requirements to some extent. However, the output results still seem to h
ave some deviations and even mistakes. 

&#x200B;

[the work flow of chatchat](https://preview.redd.it/2mud4ayp5dob1.png
?width=834&format=png&auto=webp&s=cc598844a4d4462a8fc80383a1ce0e946828e157)

Is there a way to make the output results m
ore accurate? 

For example,  I have a user manual for the hairdryer in knowledge base showing the hair dryer is working
 under rated voltage of 110V,  when I use the LLM model with a relatively low sample size I may get a wrong answer. 

If
 I ask, 'Can I use the xxx hair dryer directly in a country with a rated voltage of 220V?' 

Llama2-7B may answers 'yes,
 you can.' 

while Llama2-13B may answer me 'no, unless you use a power adapter'. 

And GPT is capable of providing more
 excellent answers. 

I believe that if I want to achieve better output results, I may need to fine-tune the LLM or embe
ddings. 

But I've noticed that many people use Q/A pairs for fine-tuning, and I'm not sure why they do this or whether 
these operations involve fine-tuning embeddings or the LLM. In my understanding, we don't have sufficient resources for 
fine-tuning the LLM, and fine-tuning embeddings seems to only help in improving how embeddings convert human language in
to higher relevance vectors. Does this mean that when fine-tuning embeddings, there's actually no need for question-answ
er pairs? 

If I must fine-tune, should I separately fine-tune two embeddings: one fine-tuned based on question-answer p
airs for extracting vectors from documents and another fine-tuned based on question similarity for extracting vectors fr
om questions? 

&#x200B;
```
---

     
 
all -  [ Generative AI product called Needle ](https://www.reddit.com/r/LangChain/comments/16j3ppz/generative_ai_product_called_needle/) , 2023-09-19-0910
```
Hey Guys,
I am working in a product name Needle. Here are some features of it:
1. Q&A on documents (pdf, word, text, ppt
 etc.)
2. Q&A on MS Sql database (based on schema, prepare sql statement and execute it)
3. Integration with AirByte to 
support other thousands of connectors
3. Integration in your application directly: Embed as chat, API Integration
4. Cho
ose your LLM (openai, azure openai etc)
5. Host it privately and securely (export docker to your repository)

I am using
 Langchain as base framework and above things doesn’t need prompt modification or fine tuning.

How should i expand this
 product, ranging from feature expansion, marketing, reaching out to potential customers?
```
---

     
 
all -  [ Multi-Text Summarization/Question Answering ](https://www.reddit.com/r/LangChain/comments/16j2evy/multitext_summarizationquestion_answering/) , 2023-09-19-0910
```
I have a use case that uses meeting notes stored in SalesForce. I've written a function that produces a text block for e
ach meeting, which contains the meeting metadata and the meeting notes. I'd like to be able to send batches of these (co
uld be up to \~50) to an an open-source LLM (thinking LLaMa2) and prompt it to get summarizations/insights across them, 
for example:

* What were the main 5 topics that were discussed in the meetings this month?
* What questions were we ask
ed in the meetings?

What would be the best way to approach such a task? The batch of notes would be larger than the all
owable context window for most LLMs, and RAG seems more like fetching data rather than synthesizing across multiple diff
erent documents.

Somewhat new to all this, appreciate any insights!
```
---

     
 
all -  [ How to improve Chat with your own data application answer quality? ](https://www.reddit.com/r/ChatGPTCoding/comments/16j1x4c/how_to_improve_chat_with_your_own_data/) , 2023-09-19-0910
```
Hi, I have been working on my chat with your own data application for a while. I have seen most of the chat with your ow
n data tutorials on youtube, and medium articles on this topic. Majority of them just teaches you the basic mechanics of
 how to get a basic skeleton of such application working: 

1. using some form of langchain to ingest your data to a vec
tor db
2. using similarity search the vector db to return relevant documents to the question the user asks
3. set the re
turned docs from the previous step as context to the prompt you send to chatgpt api, get your answer and display the res
ult in your frontend.

Different tutorials may have a different focus on the approach, e.g. not using langchain, using l
angchain directly, using no-code UI built on top of langchain, using no-code UI built on framework similar to or modifie
d versions of langchain...

But the matter of fact is, while the output of following these tutorial kind of work, but th
ey don't live up to closer inspection. Especially if you try to put them to real world use cases, where you really try t
o use it to chat with a document or code base you really try to understand. The answers on these real world documents re
ally fall short of what you hope the AI can do. 

Anyone here have similar experience want to discuss on what can be don
e to improve on the quality of answers produced by these LLM Q&A applications? 

Looking forward to hearing your thought
s on this problem.

Thanks
```
---

     
 
all -  [ Need help processing your data before embedding it? ](https://www.reddit.com/r/LangChain/comments/16iv7v9/need_help_processing_your_data_before_embedding_it/) , 2023-09-19-0910
```
Hey,  


We just published a playground to help developers test out different pre-processing configurations for their da
ta. This includes loaders, selectors and splitters. It uses parts of Langchain as well as some custom loaders and splitt
ers built by Neum AI. (All open source) Feel free to try it out here: [https://neumai-playground.streamlit.app/](https:/
/neumai-playground.streamlit.app/)

If you want to see an overview, check out this video: [https://www.youtube.com/watch
?v=n3L680vmGJo&t=5s](https://www.youtube.com/watch?v=n3L680vmGJo&t=5s)  


Repo:  [NeumTry/pre-processing-playground (gi
thub.com)](https://github.com/NeumTry/pre-processing-playground)   


What else would you like to be able to do in the p
layground?   

```
---

     
 
all -  [ Using LangChain to generate ROS (Robotic Operating System) ](https://www.reddit.com/r/LangChain/comments/16iv2j1/using_langchain_to_generate_ros_robotic_operating/) , 2023-09-19-0910
```
Me and my team at RoboCoach Inc. have used LangChain and GPT3.5 to capture the details of a robotic design and to automa
tically implement all ROS (Robot Operating System) packages for the robotic project. This is the tool:

[https://github.
com/RoboCoachTechnologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

Demo: [https://www.youtube.com/w
atch?v=H2QaeelkReU](https://www.youtube.com/watch?v=H2QaeelkReU)

ROScribe is an open source project and we welcome all 
of you to use it and be part of this community. If you liked the tool, you can send us a video recording of your use-cas
e and we will put it on our github. We will credit all contributors at every release.
```
---

     
 
MachineLearning -  [ [P] Ways to speed up llama-2 summarization on sagemaker? ](https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/) , 2023-09-19-0910
```
I'm currently working on a project to give a quick summary of long articles/conversations.

I'm running llama-2-7b-chat-
hf with 4bit quantization on a g5.2xlarge instance on sagemaker.

The method I'm using is map\_reduce (option 2)from thi
s webpage [https://python.langchain.com/docs/use\_cases/summarization](https://python.langchain.com/docs/use_cases/summa
rization))

Of everything I've tried this is the only one that's been able to do decent summaries in a reasonable amount
 of time. However with really long articles (10,000+ words) it takes \~6 minutes before giving an output.

I tried runni
ng this same thing on a g5.12xlarge instance which has 4 A10G gpus but it hasn't reduced the time by any noticeable amou
nt.

Is there anything else I could be doing to speed this up?

&#x200B;

For reference here is the code I'm running in 
Sagemaker notebook

[https://gist.github.com/phwang4/1ab4d772228b6fff8616c28ac054c229](https://gist.github.com/phwang4/1
ab4d772228b6fff8616c28ac054c229)
```
---

     
 
MachineLearning -  [ [P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with ](https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/) , 2023-09-19-0910
```
Hey all, we just released our new project/paper and we thought you all might find it useful!

Our project (Kani) is a su
per lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in c
allable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one li
ne (the `@ai_function()` decorator) to turn any function into an AI-callable function!

Kani works with any model and ha
s built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt e
ngineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly custo
mizable.

Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. [https://colab
.research.google.com/github/zhudotexe/kani/blob/main/examples/colab\_examples.ipynb](https://colab.research.google.com/g
ithub/zhudotexe/kani/blob/main/examples/colab_examples.ipynb)  

If you're interested in learning more check out our lin
ks below!  
Paper: [https://arxiv.org/abs/2309.05542](https://arxiv.org/abs/2309.05542)  
GitHub: [https://github.com/zh
udotexe/kani](https://github.com/zhudotexe/kani)  
Docs: [https://kani.readthedocs.io/](https://kani.readthedocs.io/)
```
---

     
 
MachineLearning -  [ [D] Data Extraction using fine-tuned LLM? ](https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/) , 2023-09-19-0910
```
Hey Reddit,

I'm working on a tool to pull data from highly irregular Excel files. I've gotten reasonable results which 
is extremely fast with standard Python coding, but it's far from perfect due to the lack of standardized templates. 

In
terestingly, when I tested ChatGPT-4 on a sample table, it did a decent job at data extraction. However, relying solely 
on GPT-4 has its downsides like token limits and slow processing speed (and data privacy issues). Plus, splitting the Ex
cel sheet to fit within these limits results in loss of context and data.

I'm considering fine-tuning a language model 
to post-process data that was in a Pandas DataFrame (perhaps converted to JSON). Has anyone had success with this approa
ch or have alternative recommendations? I've tried Langchain, but it wasn't helpful.

I have figured out to extract the 
relevant columns, but the post-processing part is where I am considering using an LLM which understands the domain and w
hat needs to be extracted based on the examples I feed it.

Looking forward to your thoughts! And would be happy to answ
er any additional questions.
```
---

     
 
MachineLearning -  [ [D] Chains and Agents ](https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/) , 2023-09-19-0910
```
I think there's a lot of confusion around AI agents today and it's mainly because of lack of definition and using the wr
ong terminology.

We've been talking to many companies who are claiming they're working on agents but when you look unde
r the hood, they are really just chains.

I just listened to the Latent Space pod with Harrison Chase (Founder of Langch
ain) and I really liked how he thinks about chains vs agents.

Chains: sequence of tasks in a more rigid order, where yo
u have more control, more predictability.  
Agents: handling the edge-cases, the long-tail of things that can happen.

A
nd the most important thing is that it's not an OR question but an AND one: you can use them in the same application by 
starting with chains -> figuring our the edge-cases -> using agents to deal with them.

https://preview.redd.it/l59sc4sr
i0nb1.png?width=3127&format=png&auto=webp&s=1f3f8730c48687eaabf1f554deb181cf35b96036
```
---

     
 
MachineLearning -  [ [P] FalkorDB - a fast Graph Database - Knowledge Graph as RAG ](https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/) , 2023-09-19-0910
```
We're building a fast low latency Graph Database called FalkorDB that will also support Vector search.  
It's based on R
edis and can be used both as a stand alone database or a module for existing Redis.  
It feels like that is going to be 
the most optimized way to serve Knowledge as RAG, would love to get your feedback.  
[https://github.com/FalkorDB/falkor
db](https://github.com/FalkorDB/falkordb)  


It already supports LlamIndex and Langchain:  
[https://python.langchain.c
om/docs/use\_cases/more/graph/graph\_falkordb\_qa](https://python.langchain.com/docs/use_cases/more/graph/graph_falkordb
_qa)  
[https://gpt-index.readthedocs.io/en/latest/examples/index\_structs/knowledge\_graph/FalkorDBGraphDemo.html](http
s://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/FalkorDBGraphDemo.html)

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Is there anything LangChain can do better than using LLMs directly (either through a website or  ](https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/) , 2023-09-19-0910
```
I haven't used ChatGPT a lot or any other LLMs, I've been reading about  Langchain and its use cases, and I'm having tro
uble wrapping my head  around exactly what it does. From what I understand, its an alternative  interface for LLMs, allo
wing for easy switching between them, and makes  some work for specific use cases easier. If I wanted to write an app or
  script to interact with LLMs and do other tasks, how would LangChain be  better than just making API call(s) to an LLM
, getting back the result  as a string, and doing whatever with it?
```
---

     
 
MachineLearning -  [ Apache Airflow vs. LangChain and LlamaHub for LLM data pipeline [D] ](https://www.reddit.com/r/MachineLearning/comments/160lexg/apache_airflow_vs_langchain_and_llamahub_for_llm/) , 2023-09-19-0910
```
I’m looking for recommendations, suggestions, and/or good documentation that outlines which data pipeline would be best 
to ingest my private data (which will then be split into chunks/nodes for vector embeddings and so forth). Thank you in 
advance!
```
---

     
 
MachineLearning -  [ [P] LLM Apps Are Mostly Data Pipelines ](https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/) , 2023-09-19-0910
```
My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster
](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.

It contains a complete 
implementation

* with scraping context data from a docs website
* chunking it, getting embeddings via the openAI API
* 
loading it into pinecone
* and finally a simple Q&A interface with streamlit on top of it

**Here's a quick summary:**


* LangChain and LlamaIndex are great tools for quick exploration
* But aren't perfect for production-grade use
* I think
 we all know the 'LangChain is pointless' debate, but there's a lot of real meat to it, and Pat describes a few of them 
(a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)
* LLM applications are all about movin
g data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps
* A bunch of dat
a engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.
* Meltan
o is one such tool and Pat implemented the above described pipeline with it

**FWIW**: The GitHub project that comes wit
h the post is super easy to run and super modular. I just tested it and was able to modify everything for my own applica
tion within 30 mins.
```
---

     
 
deeplearning -  [ TheBloke/Llama-2-7b does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt  ](https://www.reddit.com/r/deeplearning/comments/16ihzn8/theblokellama27b_does_not_appear_to_have_a_file/) , 2023-09-19-0910
```
Hey everyone!

As you can guess from the title, this is the error I get. I only changed the model in AutoModelForCausalL
M, Older version was 

&#x200B;

&#x200B;

`'''`

`model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-c
hat-hf',`

`device_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

`'''`

&#x200B;

However, si
nce my GPU is NVIDIA GeForce RTX 2080 TI, it answers a simple question in 20 mins. Then I changed it to: 

`model = Auto
ModelForCausalLM.from_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',`

`model_file = 'llama-2-7b-chat.q4_K_M.gguf',`

`devi
ce_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

&#x200B;

However, this is not working, and 
giving the error. Below is the full code, if it is needed to solve.

&#x200B;

&#x200B;

from langchain.document\_loader
s import JSONLoader

from langchain.text\_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTe
xtSplitter

from langchain.embeddings import HuggingFaceEmbeddings

from langchain.vectorstores import Chroma

from lang
chain import HuggingFacePipeline

from langchain.chains import ConversationalRetrievalChain

from langchain.memory impor
t ConversationBufferMemory

from langchain.embeddings.openai import OpenAIEmbeddings

from langchain.embeddings.huggingf
ace import HuggingFaceEmbeddings

from langchain.chat\_models import ChatOpenAI

import os

import sys

import huggingfa
ce\_hub

from huggingface\_hub import notebook\_login

import torch

import transformers

from transformers import AutoT
okenizer, AutoModelForCausalLM, pipeline

from torch import cuda, bfloat16

import chromadb

from pathlib import Path

f
rom pprint import pprint

import json

from loader import JSONLoader

from [langchain.prompts.chat](https://langchain.pr
ompts.chat) import PromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate

import j
son

from langchain.docstore.document import Document

&#x200B;

def parse\_json(json\_data):

'''Parse JSON data into a
 Python dictionary.'''

return json.loads(json\_data)

&#x200B;

def create\_doc(json\_data):

'''Create a Document obje
ct from JSON data.'''

data = parse\_json(json\_data)

content\_value = ''

&#x200B;

\# Collect values of keys that con
tain 'item' in their name

for key, value in data.items():

if 'item' in key.lower():

content\_value += value + '\\n' 




&#x200B;

return Document(page\_content=content\_value, metadata={'company': data\['company'\]})

&#x200B;

&#x200B;


\##embed\_model\_id = 'BAAI/bge-base-en' ## CHANGE

&#x200B;

embed\_model\_id = 'sentence-transformers/all-mpnet-base-
v2'

&#x200B;

&#x200B;

&#x200B;

device = f'cuda:{cuda.current\_device()}' if cuda.is\_available() else 'cpu' ## NVIDI
A GeForce RTX 2080 TI

&#x200B;

embed\_model = HuggingFaceEmbeddings(

model\_name=embed\_model\_id,

model\_kwargs={'d
evice': device},

encode\_kwargs={'device': device, 'batch\_size': 32}

)

&#x200B;

docs = \[\]

&#x200B;

&#x200B;

fo
r file in os.listdir('lessdata'):

if file.endswith('.json'):

file\_path = './lessdata/'+file

with open(file\_path) as
 file:

json\_data = [file.read](https://file.read)()

document = create\_doc(json\_data)

docs.append(document)

&#x200
B;

&#x200B;

document\_splitter = RecursiveCharacterTextSplitter(separators=\['\\n'\], chunk\_size = 500, chunk\_overla
p = 100)

document\_chunks = document\_splitter.split\_documents(docs)

&#x200B;

&#x200B;

vectordb = Chroma.from\_docu
ments(document\_chunks,embedding=embed\_model, persist\_directory='./database')

&#x200B;

\##vectordb.persist()

'''

v
ectordb = Chroma.from\_documents(document\_chunks,embedding=embed\_model, persist\_directory='./database')

vectordb.per
sist('./database')

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;

\### PLEASE DO NOT TOUCH THE VSCODE

&#x200B;


&#x200B;

tokenizer = AutoTokenizer.from\_pretrained('meta-llama/Llama-2-7b-chat-hf', use\_auth\_token = True,)

&#x20
0B;

&#x200B;

model = AutoModelForCausalLM.from\_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',

model\_file = 'llama-2-7b
-chat.q4\_K\_M.gguf',

device\_map ='auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;


&#x200B;

&#x200B;

'''

model = AutoModelForCausalLM.from\_pretrained('meta-llama/Llama-2-7b-chat-hf',

device\_map =
'auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;


pipe = pipeline('text-generation',

model = model,

tokenizer = tokenizer,

device\_map='auto',

max\_new\_tokens = 512
,

min\_new\_tokens = 1,

top\_k = 5) ##see it 

&#x200B;

\## In vectorstore, take top 5 closest vectors-inputs-context
s, whatever you wanna call.

&#x200B;

llm = HuggingFacePipeline(pipeline=pipe, model\_kwargs= {'temperature':0.7})

&#x
200B;

memory = ConversationBufferMemory(memory\_key='chat\_history', input\_key='question', output\_key='answer', retur
n\_messages=True)

&#x200B;

system\_template = r''' 

Given a context, use your knowledge and answer the question. Be f
lexible, and try everything to answer in the format asked by query.

 \----

{context}

\----

'''

&#x200B;

&#x200B;


user\_template = 'Question:\`\`\`{question}\`\`\`'

&#x200B;

messages = \[

SystemMessagePromptTemplate.from\_template(
system\_template),

HumanMessagePromptTemplate.from\_template(user\_template)

\]

&#x200B;

&#x200B;

qa\_prompt = Chat
PromptTemplate.from\_messages(messages)

&#x200B;

&#x200B;

&#x200B;

jsonExpert = ConversationalRetrievalChain.from\_l
lm(llm = llm, 

retriever=vectordb.as\_retriever(search\_kwargs = {'k': 1}), ## whats it

verbose = True, memory = memor
y, combine\_docs\_chain\_kwargs={'prompt': qa\_prompt},

return\_source\_documents = True

)

&#x200B;

\##retriever ret
urns 1 output object.

&#x200B;

chat\_history = \[\]

query = 'Consider the financials and progress of companies who is
 in the tech business.'

result = jsonExpert({'question': query}, {'chat\_history': chat\_history})

\#result = jsonExpe
rt({'question': query})

&#x200B;

&#x200B;

sources = result\['source\_documents'\]\[0\]

print(result\['answer'\])

pp
rint(sources)

pprint(memory)
```
---

     
 
deeplearning -  [ How to find 'custom' datasets for LLM ](https://www.reddit.com/r/deeplearning/comments/16bj3hg/how_to_find_custom_datasets_for_llm/) , 2023-09-19-0910
```
Hey folks,

I've been digging everywhere, including here, for LLMs and custom applications. So, I read many things, lear
ned from ppl here. Its time to try something. I will try implement Llama v2 - Langchain - Chroma combination. But also I
 want to upload a dataset so that I can try my model on that. 

I find some datasets big enough (for now, 2-5 gb is ok) 
however they are table-style. I want something more texty, I mean I could use 'American Stories' or 'Arxiv' however I be
lieve that they are already used by Llama to train. 

&#x200B;

Is there any suggestions or sources that you can provide
 ? Thanks!
```
---

     
