 
all -  [ Creating demo conversational AI for Client ](https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/) , 2024-01-24-0910
```
I'm creating a demo for a client - it will involve a web ui, a conversational component and some knowledge retrieval. An
y insight into what is the best way to set this up? Whether for an MVP or Production grade software? 

I really do like 
Langchain for its flexibility (no vendor lock-in) but am also open to Assistants API. I'm wondering specifically what is
 the best 'front end' chat interface (Botpress ,Voiceflow, custom JS) and how others are setting up a seamless experienc
e while having chatGPT like power. 

Just looking to think about tradeoffs as I plan to design the service.
```
---

     
 
all -  [ Can we use Conversation History in rag chain? ](https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/) , 2024-01-24-0910
```
Currently, my chatbot can generate answers for current questions using the context (acc to prompt). Now I want to use th
e conversational part i.e., the chat history part to make it more sensible. How is that possible?
```
---

     
 
all -  [ Updated Pinecone client issue with Langchain vectorstore ](https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/) , 2024-01-24-0910
```
I have had to upgrade pinecone-client and dependencies in conjunction with langchain for vectorstores.  In doing so ran 
into a conflict with the imports for pinecone import Pinecone and langchain_community.vectorstores import Pinecone 

whe
re the class config appears incompatible now and errors with api_key unexpected on Pinecone client creation unless I rem
ove the langchain import line which of course causes the vectorstore setup to fail.  

Running the following versions:
P
inecone-client 3.0.1
Langchain 0.1.3
Langchain-community 0.0.14
Langchain-core 0.1.15

Any input greatly appreciated - t
his update made current chatbot inoperable 

Thanks
```
---

     
 
all -  [ How to create a project using Langchain which will utilise OpenAI api ](https://www.reddit.com/r/deeplearning/comments/19dxhp4/how_to_create_a_project_using_langchain_which/) , 2024-01-24-0910
```

```
---

     
 
all -  [ The real purpose of AI is to let it be the jerk for me. ](https://www.reddit.com/r/ChatGPT/comments/19dxdhw/the_real_purpose_of_ai_is_to_let_it_be_the_jerk/) , 2024-01-24-0910
```
Kinda serious, kinda joking, but curious who else is using AI to save themselves from explaining trivial engineering pri
nciples and decisions to non-technical people. For example, it must save me hours every week to just put in the naive qu
estions I get asked in business calls ( or the bad decisions that I need to shut down ) and ask the AI to explain why it
 is/isn't a good idea to do/not do this thing. The great part is at the end of the conversation I get to say, 'Look ladi
es and gentlemen, I am always open to discussion and improvement of ideas but AI is the one arguing against you not me. 
I am just relaying information.' Basically I am using AI as my bad cop in my good cop bad cop routine. Anyone else doing
 this?

After writing this I just realized some one needs to create an AI startup that just has it constantly listen to 
calls and be the jerk to shut down stupid stuff in real time. I am too lazy. Please build me this tool open source using
 Langchain. Should be super easy but not cost effective unless using local models.
```
---

     
 
all -  [ Live HowTo for building your 1st RAG App! ](https://www.reddit.com/r/LlamaIndex/comments/19dwheq/live_howto_for_building_your_1st_rag_app/) , 2024-01-24-0910
```
I'm so excited for tomorrows live how to that DataStax and LangChain are putting together that I had to share this! In m
y opinion, here's an easy way for how to develop your 1st RAG app \~ [https://www.crowdcast.io/c/5z80anwt7e13?utm\_mediu
m=social\_organic&utm\_source=socialstax&utm\_campaign=putv&utm\_content=](https://www.crowdcast.io/c/5z80anwt7e13?utm_m
edium=social_organic&utm_source=socialstax&utm_campaign=putv&utm_content=)
```
---

     
 
all -  [ Webinar - LangChain JS, Vercel, Astra with Wikipedia data ](https://www.reddit.com/r/generativeAI/comments/19dw79o/webinar_langchain_js_vercel_astra_with_wikipedia/) , 2024-01-24-0910
```
Just stumbled upon this amazing webinar that's all set for tomorrow! It's about crafting a real-time RAG app using LangC
hain.js, Vercel, and Astra DB, leveraging Wikipedia. It looks really cool: [https://dtsx.io/498383Z](https://dtsx.io/498
383Z) 
```
---

     
 
all -  [ WikiChat ](https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/) , 2024-01-24-0910
```
Saw this webinar that is around building a real-time RAG app on Wikipedia with LangChain.js, Vercel, and Astra DB. Looks
 interesting and is set to go tomorrow: [https://dtsx.io/498383Z](https://dtsx.io/498383Z)
```
---

     
 
all -  [ Become an AI Developer (Free 9-Part Series) ](https://www.reddit.com/r/computervision/comments/19dvemg/become_an_ai_developer_free_9part_series/) , 2024-01-24-0910
```
Just sharing a free series I stumbled across on Linkedin - DataCamp's 9-part AI code-along series.

This specific sessio
n linked below is 'Building Chatbots with OpenAI API and Pinecone' but there are 8 others to have a look at and code alo
ng to.

*Start from basics to build on skills with GPT, Pinecone and LangChain to create a chatbot that answers question
s about research papers. Make use of retrieval augmented generation, and learn how to combine this with conversational m
emory to hold a conversation with the chatbot. Code Along on DataCamp Workspace:* [*https://www.datacamp.com/code-along/
building-chatbots-openai-api-pinecone*](https://www.datacamp.com/code-along/building-chatbots-openai-api-pinecone)

Find
 all of the sessions at: [https://www.datacamp.com/ai-code-alongs](https://www.datacamp.com/ai-code-alongs)
```
---

     
 
all -  [ Become an AI Developer (Free 9-Part Series) ](https://www.reddit.com/r/WebDevBuddies/comments/19dvbyl/become_an_ai_developer_free_9part_series/) , 2024-01-24-0910
```
Just sharing a free series I stumbled across on Linkedin - DataCamp's 9-part AI code-along series.  
This specific sessi
on linked below is 'Building Chatbots with OpenAI API and Pinecone' but there are 8 others to have a look at and code al
ong to.  
*Start from basics to build on skills with GPT, Pinecone and LangChain to create a chatbot that answers questi
ons about research papers. Make use of retrieval augmented generation, and learn how to combine this with conversational
 memory to hold a conversation with the chatbot. Code Along on DataCamp Workspace: https://www.datacamp.com/code-along/b
uilding-chatbots-openai-api-pinecone*  
Find all of the sessions at: https://www.datacamp.com/ai-code-alongs
```
---

     
 
all -  [ Re-ranking and pagination ](https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/) , 2024-01-24-0910
```
Hi, I'm using Elasticsearch to maintain a set of documents. When a user types in a query, I perform a lexical (+semantic
) search and output the results. So far I've had good success with this approach. However, I now want to perform a post-
retrieval re-ranking using Cohere. I'm curious as to how should I paginate the results, or if it's even possible in the 
first-place?  
Thanks!
```
---

     
 
all -  [ [HELP] Can't save the chromadb vector store ](https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/) , 2024-01-24-0910
```
I'm working on embedding some documents (lots of it) and I was debugging my code, running it to check if the AzureOpenEm
beddingAPI works, here's the code:

        loader = DataFrameLoader(df, page_content_column='desc_cleaned')
    
      
  splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200
        )
        splits = s
plitter.split_documents(loader.load())
        vectorstore = Chroma.from_documents(documents=splits, embedding=AzureOpen
AIEmbeddings(show_progress_bar=True))

So now I got my debugger on, and I'm trying to save the vector store so that I do
n't have to sit through the whole thing again, but doing \`vectorstore.persist()\` does not seem to work, and it does no
t throw an error either.

Do you guys have an idea on how I could save the store locally?
```
---

     
 
all -  [ Memory handling in LCEL. ](https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/) , 2024-01-24-0910
```
How can I build a custom retrieval chatbot chain using the LCEL and not the available default langchain chains?
```
---

     
 
all -  [ Qdrant Similarity Search Metric ](https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/) , 2024-01-24-0910
```
Hello all, May I know what is the metric used to compute similarity for QDrant Retriever, with a search_type=similarity 
? Would it be cosine similarity? L2?
```
---

     
 
all -  [ Langchain UnstructuredFileLoader: Load PDFs ](https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/) , 2024-01-24-0910
```
Hi, 

I wanted to find a more clean way to load my PDFs than PyPDF loader and came across [Unstructured.io](https://Unst
ructured.io) wit Langchain. I am loading my PDF like this: 

`# UnstructuredIO Test`  
`from langchain_community.documen
t_loaders import UnstructuredFileLoader`  
`loader = UnstructuredFileLoader(`  
 `'my.pdf', mode='elements'`  
`)`  
`do
cs = loader.load()`  
`docs[:5]`

Now I figured out that this loads every line of the PDF into a list entry (PDF with 22
 pages ended up with 580 entries). But how can I extract the text of whole pages to be able to further use it for RAG?


With only reading on one line each, I think context gets lost.
```
---

     
 
all -  [ RAG with PDFs: Why chunking and not using whole page ](https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/) , 2024-01-24-0910
```
Hi,

I understand that Chunking for RAG is very important for longer texts. But I was wondering why it is common that PD
Fs also get chunked. 

For example, many PDF pages in my use case have less than 2000 characters. When reading in the PD
F, the context over pages gets lost anyways, because PyPDFLoader for example stores every page separately.  As 2000 char
s isn't that much and I want to get as many context as possible (so maximum 1 page), why should I consider chunking?
```
---

     
 
all -  [ How to Stop Document Retrieval in a RAG chatbot for Greeting input from user Like Hi, Hello, Good Mo ](https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/) , 2024-01-24-0910
```
I have built RAG chatbot entirely from scratch NO langchain involved. The docs are retrieved for every query, I want to 
Stop docs Retrieval for Greeting messenges.

I have tried conditional check by storing all Greeting messages in a list w
hich worked fine
But what if user enters different greeting message that's not in list,  what if he enters with spelling
 mistakes. This will definitely fail.

How to handle this?
```
---

     
 
all -  [ LLM based ChatBots with Memory ](https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/) , 2024-01-24-0910
```
I am building a chatbot using Azure OpenAI API. Is there a way I can integrate the memory module of the Langchain framew
ork into my chat application? Currently, I am using summarization to implement the short-term memory but I would like to
 expand the memory implications to a long-term memory and also manage the summarization using the buffer memory methods 
in Langchain. My conversations are currently stored in a Redis cache.
```
---

     
 
all -  [ Developing an app using open source LLMs ](https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/) , 2024-01-24-0910
```
Hi folks

I'm currently trying to build an app (python) using local llms 
I tried Mistral 7b instruct. 
I have tried few
 prompts asking the model to generate code snippets and functions. But now i have to test the model if it can give sourc
e code to build an app (let's say a chatbot for instance). 
Basically the input would be a use case in natural language


For example: Build an end to end chatbot that can answer customer's queries and help with the issues.

What should be m
y approach ? How to get this done ? Please provide suggestions since I'm really new to LLMs. If possible provide any tut
orials or guides.
```
---

     
 
all -  [ vec2word ](https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/) , 2024-01-24-0910
```
I want to embed a prompt, invert the sign of each embedding, then turn that new embedding back into text.

I am getting 
stuck on getting the embedding transformed back into words...

how do you do that?
```
---

     
 
all -  [ Create full RAG solution tutorial ](https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/) , 2024-01-24-0910
```
I am trying to build rag solution for a user guide
I have worked with chromadb and OpenAI but I want to build something 
robust step by step 
Can you suggest something for me 
Thanks
```
---

     
 
all -  [ wht chat_histrory ](https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/) , 2024-01-24-0910
```
I know this is not related langchain. somehow i am unable to post in python group. why the hell this is showing error. c
hat\_history I declared at  99. why its showingerror at 106 but not at 108

&#x200B;

&#x200B;

https://preview.redd.it/
4e8lqlgolzdc1.png?width=1324&format=png&auto=webp&s=277c36af1e06d189b047d50ada64a7b07001ed8c
```
---

     
 
all -  [ FAISS as Retriever: Score Treshold not working ](https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/) , 2024-01-24-0910
```
Hi,

in a RAG application, I am using FAISS as retriever:

`retriever = vectorstore.as_retriever(search_kwargs={'k': 3, 
'score_treshold': 0.9}, search_type='similarity')`

`retriever.get_relevant_documents('- I am Karl and I play soccer')`


However when changing the Score-Treshold I am still getting back the same documents. So there is no difference if I set
 it to 0.1 or 0.9.

In my understanding it should work as follows:

\- Search the top 3 docs that have a similarity scor
e of 0.9 or higher.

\- If for example only one doc has a higher similarity than 0.9, only retrieve one doc.

\- But: it
 is always retrieving 3 Docs, even if they are not similar

&#x200B;

Is this assumption correct or how can I make it wo
rk?
```
---

     
 
all -  [ Developing an AI-Powered Gym chat app ](https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/) , 2024-01-24-0910
```
I'm working on an innovative gym app that incorporates AI for personalized workout plans and diet charts, sourced from a
 gym owner's knowledge base.

Here's the scoop: 

Users can input their daily attendance, receive workout plans(from tra
iners), track meals, and chat with an AI bot. 

The Ai  bot should consider knowledge based and user's previous history 
texts and their database(their workout and meal history and plan(weightloss) and their Medical condition(optional) ) and
 provide optimal answers according to the users queries


My tech arsenal I like to use includes 

Rag, LangChain, Supab
ase, supabase - VectorDB, and Next.js. I'm eager to hear your thoughts and insights on how to make this ambitious projec
t a reality. Any advice, suggestions, or experiences you can share would be immensely helpful! Thanks a ton! 💪🤖
```
---

     
 
all -  [ Survey about Retrieval Augmented Generation (RAG) in Real Production ](https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/) , 2024-01-24-0910
```
I'm now working in an AI company, and we're developing infra products to enhance RAG. As the product marketing, it's imp
ortant to hear from the community. I want to know:

* How necessary do you think the RAG project can be for your current
 business?
* What are the primary challenges you face with the current implementation of RAG?
* Which embedding model yo
u are using now？
* Have you considered finding a better Embedding model to get better results from RAG?

I'm looking for
ward to seeing your reply from anyone who is exploring RAG for real production. You are also welcome to share your insig
hts via the [survey](https://forms.gle/xkyBpruTC7twZxSz7), and I‘ll then contact you to discuss future collaboration opp
ortunities. You may find more information about our product, the Jina Embeddings model in the survey form. And our Embed
dings have been integrated into Langchain already. 
```
---

     
 
all -  [ function calling with mistral or agent langchain with mistral - help wanted ](https://www.reddit.com/r/MistralAI/comments/19cq269/function_calling_with_mistral_or_agent_langchain/) , 2024-01-24-0910
```
can someone please provide a reference for this? I wanted to call different tools .& for that need some support of funct
ion calling in mistral .help is really appreciated
```
---

     
 
all -  [ RAG vs. full context ](https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/) , 2024-01-24-0910
```
I found that using RAG to search for documents through a vector store definitely loses some of the information, such as 
context, because it has no way to look at your problem based on the whole document. langchain There is a concept propose
d in that, which is `Parent Document Retriever`. But even so, I think he may not be as effective as passing all the data
 as context to LLM,then this also derives a maximum token problem, then does it mean: the model that supports the most t
okens is better at searching, something like `CLAUDE2` vs `ChatGPT`. It feels like the simplest and crudest is instead t
he most effective

Edit：
Or maybe this is the way to go.
[advanced-rag](https://medium.com/@akriti.upadhyay/building-adv
anced-rag-applications-using-falkordb-langchain-diffbot-api-and-openai-083fa1b6a96c)
```
---

     
 
all -  [ Create AI Chatbots for Websites in Python - EmbedChain Dash ](https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/) , 2024-01-24-0910
```
Hey Everyone,I just created a free video tutorial showing how to build an AI Chatbots for Beginners in Python. We'll use
 the EmbedChain (built on top of LangChain) and Dash libraries, and we'll learn the core principles of training and inte
racting with your bot. I hope you learn a lot.

[https://youtu.be/tmOmTBEdNrE](https://youtu.be/tmOmTBEdNrE)

&#x200B;


https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&format=png&auto=webp&s=b4e1593532e2f396d0397ec80161020a30d14b69
```
---

     
 
all -  [ New Grad seeking Data Science/ML/Computer Vision/NLP roles. 200+ apps, 0 interviews. Any suggestions ](https://www.reddit.com/r/resumes/comments/19ckqfk/new_grad_seeking_data_sciencemlcomputer_visionnlp/) , 2024-01-24-0910
```
Can you please evaluate my resume and tell me what am I doing wrong/can improve upon? Is my resume unable to parse ATS?


https://preview.redd.it/yeztutkmiwdc1.jpg?width=2481&format=pjpg&auto=webp&s=0a94d4b08a03a9057e2b49b7ea6aee6e9112054f
```
---

     
 
all -  [ Chatbot RAG and tool about crypto ](https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/) , 2024-01-24-0910
```
I already have some basic knowledge about langchain and LLM. Now I want to apply it to a production environment, but I r
ealize that basic knowledge is not enough. I want to make a news Q&A chatbot application using RAG and use API access to
ols to get real-time information about cryptocurrencies. Does anyone have a sample repo that I can refer to? Thank you v
ery much
```
---

     
 
all -  [ I haven’t seen anyone do it yet, so I built an agent that can talk to my car via the Ford API ](https://www.reddit.com/gallery/19cei8t) , 2024-01-24-0910
```
Step one is done. I build an agent that’s using the gpt-3.5-turbo api, and langchain to house the Ford API as a callable
 tool.
```
---

     
 
all -  [ Request to improve integration with openai assistant api to add custom functions registered inside p ](https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/) , 2024-01-24-0910
```

Not sure where to ask this question

Why: I am seeing mild success with openai assistant api on their portal platform.o
penai.com. However it's impossible to test custom functions on their portal. DevX of that api is not straightforward. I 
seem to like Langchain attempts to wrap this capability. However it's missing this ability to register custom functions.
 

Please guide me if there's a work around?

----
Feature Request created by chat.langchain.com after I couldn't get my
 answer on this help portal
---
Subject: Feature Request: Custom Function Registration in Langchain
Dear Langchain Team,

I hope this message finds you well. I am a user of the Langchain platform and have been exploring the capabilities of t
he OpenAI Assistant integration. While working with the platform, I noticed that there is no explicit documentation or m
ention of a register_function method for registering custom functions with the OpenAI Assistant.
I believe that having t
he ability to register custom functions would greatly enhance the flexibility and extensibility of the OpenAI Assistant.
 This feature would allow users to define their own functions and seamlessly integrate them into the assistant's convers
ational flow.
Specifically, I envision a method similar to register_function that would enable users to define custom fu
nctions in Python and register them with the OpenAI Assistant. These registered functions could then be invoked during t
he conversation, allowing for more dynamic and interactive interactions with the assistant.
I kindly request that the La
ngchain team consider adding this feature to the platform. It would empower users to create more tailored and specialize
d conversational experiences with the OpenAI Assistant.
Thank you for your attention to this feature request. I apprecia
te your dedication to continuously improving the Langchain platform and look forward to any updates or feedback regardin
g this request.
Best regards,
[Your Name]
```
---

     
 
all -  [ RAG, langchain app ](https://www.reddit.com/r/RagAI/comments/19c97bl/rag_langchain_app/) , 2024-01-24-0910
```
Can anybody suggest ai tools that can build a langchain & rag app?
```
---

     
 
all -  [ What framework to use to build a LLM chatbot which is enterprise scalable to multiple users ](https://www.reddit.com/r/ChatGPT_GoogleBard/comments/19bzk8f/what_framework_to_use_to_build_a_llm_chatbot/) , 2024-01-24-0910
```
Hey guys, what framework or tools do I use if I wanted to build a LLM chatbot which is enterprise scalable to multiple u
sers?

A framework/tool I am thinking of is Langchain. There won’t be any fine-tuning for my chatbot so I am not sure if
 I need to use Langchain.

Would there be a different suitable framework to use if I wanted to build for a small to mid 
sized enterprise compared to a large enterprise?

I am thinking of using AWS to host the LLM model. 

Any help would rea
lly be appreciated. Many thanks!
```
---

     
 
all -  [ What framework to use to build an open-sourced LLM chatbot which is enterprise scalable to multiple  ](https://www.reddit.com/r/MLQuestions/comments/19bzim1/what_framework_to_use_to_build_an_opensourced_llm/) , 2024-01-24-0910
```
Hey guys, what framework or tools do I use if I wanted to build an open-sourced LLM chatbot which is enterprise scalable
 to multiple users?

A framework/tool I am thinking of is Langchain. There won’t be any fine-tuning for my chatbot so I 
am not sure if I need to use Langchain.

Would there be a different suitable framework to use if I wanted to build for a
 small to mid sized enterprise compared to a large enterprise?

I am thinking of using AWS to host the LLM model. 

Any 
help would really be appreciated. Many thanks!
```
---

     
 
all -  [ Advice on Getting Started RAG and LLM using Langchain and TinyLlama ](https://www.reddit.com/r/ArtificialInteligence/comments/19bz6bo/advice_on_getting_started_rag_and_llm_using/) , 2024-01-24-0910
```
I am currently learning RAG and LLM and how RAG can help reduce hallucinations on LLM when generating responses.

I foll
owed this article [https://thebeep.substack.com/p/data-prepare-of-basic-retrieval-augmented](https://thebeep.substack.co
m/p/data-prepare-of-basic-retrieval-augmented) and found that useful. However, I would need some suggestions on how to m
ake an application on top of it. So that end users can use this application. 
```
---

     
 
all -  [ Is LLM 'temperature' setting similar to 'Guidance scale' from Stable Diffusion? ](https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/) , 2024-01-24-0910
```
\*Guidance Scale\* Stable diffusion setting,  “prompt strength”

\> Guidance Scale: controls how similar the generated i
mage will be to the prompt. A higher guidance scale means the model will try to generate an image that follows the promp
t more strictly. A lower guidance scale means the model will have more creativity.

&#x200B;

&#x200B;
```
---

     
 
MachineLearning -  [ New Data API for Astra [N] ](https://www.reddit.com/r/MachineLearning/comments/199uobn/new_data_api_for_astra_n/) , 2024-01-24-0910
```
I saw that DataStax/Astra DB [just released a new Data API to help with building production GenAI and RAG applications](
https://www.datastax.com/blog/general-availability-data-api-for-enhanced-developer-experience). This API makes the prove
n petabyte-scale of Apache Cassandra easy to use and available to any JavaScript, Python, or full-stack application deve
loper.

There will also be a joint webinar with LangChain available for registration here: [https://www.datastax.com/eve
nts/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel](https://www.datastax.com/events/wikichat-
build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel)
```
---

     
 
MachineLearning -  [ [D] While using function calling or tools on openai or langchain, does openai have access to the dat ](https://www.reddit.com/r/MachineLearning/comments/199t8be/d_while_using_function_calling_or_tools_on_openai/) , 2024-01-24-0910
```
I am working on a client project and I am using langchain's tools and agents. I want to know if the data is getting pass
ed to openai or is it just like that - Output of one function is being directly passed to the second function with the k
nowledge of openai.
```
---

     
 
MachineLearning -  [ [D] Code vs JSON output for LLM agents? Frameworks like LangChain rely on LLMs responding with JSON  ](https://www.reddit.com/r/MachineLearning/comments/197f416/d_code_vs_json_output_for_llm_agents_frameworks/) , 2024-01-24-0910
```
[CaP](https://arxiv.org/pdf/2209.07753.pdf), [Voyager](https://arxiv.org/pdf/2305.16291.pdf), [Octopus](https://arxiv.or
g/abs/2310.08588)

I work primarily with JSON based agents but code-as-policy agents seem to be extremely powerful. Here
 are some of the benefits and weaknesses I've seen

Pros of code

1. Less tool creation needed - The prebuilt math/file/
string/list manipulation abilities that come with code are enormous. In a JSON based agent, you would have to formally d
eclare each of these as a tool which you expose to the LLM and explain in your prompting, which is a lot of work and eat
s up a ton of the context window. 
2. Reduced number of transactions - The LLM can write scripts that invoke multiple to
ols and manipulate their results in ways that are difficult to do in a single transaction via JSON. For example, in one 
script, the model could search a DB 3 times, perform regex on the query results, convert them to integers, and add them 
up. Doing this in one step via JSON tool invocations is basically impossible. 
3. Less syntax errors - this might be tot
ally just vibe-based reasoning, but it really seems like LLMs have an easier time writing valid python than valid JSON, 
especially when you have lots of nested arguments in your methods.

Cons

1. Crazy risky - This is the obvious one. You 
have a machine executing random code. There are ways to mitigate this but still. I mean seriously we all learned not to 
use eval, so it is crazy to basically see research tending towards just running eval on the outputs of these models. 
2.
 Scripts with errors - Sometimes the model tries to get too fancy and writes complex programs that have bugs, resulting 
in many needed retries. 

Do any of you have thoughts or experience with these approaches in the wild? 

Is anybody awar
e of any experiments that compare these two approaches against each other? 

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Are Custom LLM RAG apps going to become redundant? ](https://www.reddit.com/r/MachineLearning/comments/1929n4f/d_are_custom_llm_rag_apps_going_to_become/) , 2024-01-24-0910
```
Loks like Copilot Studio is being rolled out (https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio
) with an impressive looking no code/out of the box RAG solution.

There is a phenomenal amount of development and activ
ity in the Open Source RAG world (e.g Langchain, Llamaindex, etc), which I am a great supporter of FYI.

However, what s
eems strange is that this no code out of the box solution (Copilot Studio - just as an example of one) seems overwhelmin
gly to be the better option if you wanted to build a RAG app i.e If you compare the cost to build and productionise a cu
stom RAG app vs the cost of using Copilot Studio, it's almost an order of magnitude lower (no matter how you cut it with
 the developer time and duration). 

My question is, it seems to me we are moving towards a situation where enterprise s
olutions will make custom RAG apps redundant (not in all cases of course, but most cases), however there seems to be ver
y little discussion of this relative to the activity in the open source community. Do people agree this is a likely scen
ario? 

Obviously there will be exceptions…but on most use cases I don’t see how you can compete with an instant/minimal
 setup, low cost, highly scalable RAG solution.
```
---

     
 
MachineLearning -  [ [P] An open-source project for deploying local models ](https://www.reddit.com/r/MachineLearning/comments/18zkm5m/p_an_opensource_project_for_deploying_local_models/) , 2024-01-24-0910
```
 Introducing a new LLM WebUI project that supports various local model loading and provides streaming output for cutting
-edge online multimodal models GPT-4-Vision and Gemini-Pro-Vision. Completely free and open source, it serves as a valua
ble research tool for exploring diverse models. The project is actively under development with continuous updates:  
[ht
tps://github.com/smalltong02/keras-llm-robot](https://github.com/smalltong02/keras-llm-robot)

&#x200B;

[WebUI](https:/
/preview.redd.it/f95jievpepac1.png?width=2560&format=png&auto=webp&s=1f2908b484ededc78591719ef87efdac2f9497ba)

&#x200B;


[Configuration](https://preview.redd.it/owaj5s1repac1.png?width=2560&format=png&auto=webp&s=f837b1ef67cb8e4ccaee4ec602
a61859f53db100)

&#x200B;

[Tools & Agent](https://preview.redd.it/jrot8w9sepac1.png?width=2560&format=png&auto=webp&s=7
1e224f08620941146cd437a99bcb55d02930a9e)
```
---

     
 
MachineLearning -  [ [Project] Temporal Augmented Retrieval (TAR) - Dynamic RAG ](https://www.reddit.com/r/MachineLearning/comments/18uddmj/project_temporal_augmented_retrieval_tar_dynamic/) , 2024-01-24-0910
```
From a corpus of text, how can you detect emerging topics and their evolution through time?

Introducing Temporal Augmen
ted Retrieval (TAR). (built in the context of buildspace n&w s4)

TAR is an open-source advanced RAG approach that aims 
to factor in the dynamic and temporal aspects of textual data when performing retrieval.

It allows us to understand the
 evolution of discussed topics over time.

The idea behind this project is to open the debate regarding the current limi
tations of RAG methods

This first approach has been built without using RAG frameworks (like Jerry Liu’s langchain) and
 focuses on financial tweets 

Relevant links:

Medium: [https://medium.com/@adam-rida/temporal-augmented-retrieval-tar-
dynamic-rag-ad737506dfcc](https://medium.com/@adam-rida/temporal-augmented-retrieval-tar-dynamic-rag-ad737506dfcc)

Gith
ub:[https://github.com/adrida/Temporal\_RAG](https://github.com/adrida/Temporal_RAG)

Hugging Face Benchmark: [https://h
uggingface.co/spaces/Adr740/Temporal-RAG-Benchmark](https://huggingface.co/spaces/Adr740/Temporal-RAG-Benchmark)

My web
site: [adrida.github.io](https://adrida.github.io)

&#x200B;

https://preview.redd.it/lj7wkhk70f9c1.png?width=960&format
=png&auto=webp&s=fc79c5034351a1711e1ec051919a5c4d2edbc333
```
---

     
 
MachineLearning -  [ [R][P] Autogen + Langchain Tools + Local LLM doesn't work. ](https://www.reddit.com/r/MachineLearning/comments/18tex1j/rp_autogen_langchain_tools_local_llm_doesnt_work/) , 2024-01-24-0910
```
Hey folks, 

So I'm playing around with the agent framework Autogen and I'm trying to create agents by providing it cust
om tools to use. These custom tools are defined in the langchain framework. Furthermore, I am using open source LLM mode
ls like Mistral, LLAMA, Mixtral etc.

In my experience, I have been unable to get the Autogen+LocalLLM framework to iden
tify the right tools to use given the prompt. However it does a fantastic job with the GPT model. 

Please note that my 
goal is for the agent to mandatorily use the tools provided and not come up with its own code. And the agent should figu
re out the right tool to use. 

I have been very explicit with my prompting, despite which I am unable to get this to wo
rk.

Any thoughts and suggestions? Please let me know ! Please share your experiences as well. Cheers !
```
---

     
 
MachineLearning -  [ [P] Seeking Advice for Building a School Handbook Chatbot Using OpenAI and Vector Databases ](https://www.reddit.com/r/MachineLearning/comments/18rndcp/p_seeking_advice_for_building_a_school_handbook/) , 2024-01-24-0910
```
Hello everyone,

I'm embarking on a project to create a chatbot for my school's handbook, aiming to make it a resource f
or students to easily access information. As someone relatively new to AI, I'm seeking guidance on implementing this.

M
y current plan is to use OpenAI as the primary language learning model, focusing on affordability. I am considering inte
grating RAG (Retrieval-Augmented Generation) and LangChain for enhanced functionality. However, I'm quite perplexed abou
t choosing an appropriate vector database, as many options appear costly. The goal is to keep this system live and acces
sible for student usage without breaking the bank.

I'm also looking into open-source embedding models to pair with the 
vector database. Pinecone has caught my attention, but its pricing seems steep for our budget.

Does anyone have recomme
ndations or tips on affordable yet effective tools and strategies for this project? Any insights on vector databases sui
table for educational use, or ways to optimize cost without compromising quality, would be greatly appreciated.

Thank y
ou in advance for your help!

(I typed out my problem and had gpt4 fix up the format and wording dont bash me)
```
---

     
 
deeplearning -  [ [D] Unleashing the Power of Langchain with Wandb: Revolutionizing Topic Modeling and Evaluation ](https://www.reddit.com/r/deeplearning/comments/191mm83/d_unleashing_the_power_of_langchain_with_wandb/) , 2024-01-24-0910
```
Complementing Langchain’s prowess, Wandb emerges as a powerhouse meticulously designed for developers leveraging LLM tec
hnology. As an evaluation framework and production monitoring platform, Wandb stands out for its tailored approach. Its 
arsenal comprises real-time monitoring, granular analytics, and streamlined evaluation processes, laying the groundwork 
for elevated performance and reliability in AI applications.

&#x200B;

Link: [https://medium.com/ai-advances/unleashing
-the-power-of-langchain-with-wandb-revolutionizing-topic-modeling-and-evaluation-75af5cf51b15](https://medium.com/ai-adv
ances/unleashing-the-power-of-langchain-with-wandb-revolutionizing-topic-modeling-and-evaluation-75af5cf51b15) 
```
---

     
