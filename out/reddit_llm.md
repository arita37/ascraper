 
all -  [ RAG System :: C4 Context Model ](https://i.redd.it/721geg3oopgd1.png) , 2024-08-05-0911
```

```
---

     
 
all -  [ Best pre-processing for semantic search ](https://www.reddit.com/r/LangChain/comments/1ek278c/best_preprocessing_for_semantic_search/) , 2024-08-05-0911
```
Hello guys, I want to build a semantic search for a food website, so basically this is how I get the data in the followi
ng JSON format:

    {
      'id': 85,
      'type': 'fish',
      'title': 'Fish and Chips',
      'description': 'Clas
sic fish and chips with crispy batter and golden fries.',
      'ingredients': [
          'fish fillets',
          'po
tatoes',
          'flour',
          'beer',
          'oil',
          'vinegar'
      ],
      'tags': [
          'f
ish and chips',
          'fried',
          'fish',
          'comfort food'
       ],
       'image': './fish_and_chip
s.jpg'
    }

I get the related text, combine it into a single text, and then perform embedding on that text. also, I am
 using Parent document retriever and BM25 retriever from langchain, can you give some suggestions to improve my system?
```
---

     
 
all -  [ Langchain Streamlit queries , for y'all my fairies ](https://www.reddit.com/r/LangChain/comments/1ek1kbl/langchain_streamlit_queries_for_yall_my_fairies/) , 2024-08-05-0911
```
Hello everyone , I'm a web dev learning AI and Langchain.

Currently working on a PDFRAG app . the app should only answe
rs PDF related questions ( atleast that is my target , I'm currently trying to control this by telling AI in the System 
Prompt to not answer questions outside of PDF and context , and voila most of the time it answers questions only from th
e pdf and rarely outside of pdf , first question for you guys ... is controlling AI's response for my case by System Pro
mpt the correct way or I should be doing something else ? ) .

My app is a streamlit based app ( I feel streamlit to be 
annoying , maybe because I'm a JS developer , using it because office colleagues who started learning AI before me are u
sing it , is there any better alternative ? Heard about Chainlit ... have you used it ?? what you say ?? ) . 
```
---

     
 
all -  [ RAG application for enterprise not so accurate ](https://www.reddit.com/r/LangChain/comments/1ek14so/rag_application_for_enterprise_not_so_accurate/) , 2024-08-05-0911
```
HI all,

Im developing a rag based chatbot for a client who mostly has pdf based docs with few text files also.  
pdf do
cuments are mostly tabular with 3 columns 

currently used unstructured and pdfreader to build a chatbot but the respons
es are mostly wrong and the chat bot hallucinating a lot  
also we want to give the source file in output as reference  

the file that is highlighted as source doesnt have any content of the response given by the chatbot and both are wrong 
 


  
llamaindex is used for this with gpt 3.5

any guidance will be extremely helpful
```
---

     
 
all -  [ 4 (+2) yoe applying for Data Science jobs but getting 0 calls. Please rate my resume ](https://www.reddit.com/r/resumes/comments/1ejy0m1/4_2_yoe_applying_for_data_science_jobs_but/) , 2024-08-05-0911
```
https://preview.redd.it/uinb6ze52ogd1.png?width=791&format=png&auto=webp&s=a92e94d987e922bcb630f8c85ea01105701a3e8c


```
---

     
 
all -  [ Gemini API is taking too long to response is that normal for LLM? ](https://www.reddit.com/r/LangChain/comments/1ejttbm/gemini_api_is_taking_too_long_to_response_is_that/) , 2024-08-05-0911
```
First time building with LLM. Making api call to gemini api with aroung 1500 to 1800 token input. Taking approx 6-7 sec 
to respond. Is that normal, how is OpenAI response time.
```
---

     
 
all -  [ Resume review  ](https://i.redd.it/q7i8ebtlhlgd1.jpeg) , 2024-08-05-0911
```
As per previous posts suggestions I have updated my resume format, please rate it and give me some improvement suggestio
ns 
```
---

     
 
all -  [ LangChain VS Haystack ](https://www.reddit.com/r/LangChain/comments/1ejokqg/langchain_vs_haystack/) , 2024-08-05-0911
```
Hello, community,

I have experience using both LangChain and Haystack. I wanted to ask why you prefer one over the othe
r and if there are specific use cases where one excels. It seems to me that LangChain has lost some popularity, with man
y people transitioning to Haystack. I’m excited to hear your thoughts! Cheers
```
---

     
 
all -  [ NeuralGPT - AGI Achieved Through AI<->AI Communication/Cooperation (?) ](https://www.reddit.com/r/AIPsychology/comments/1ejnnjn/neuralgpt_agi_achieved_through_aiai/) , 2024-08-05-0911
```
Hello again! I admit that my 'vacation' got pretty long to the point where some of you could be thinking that I've proba
bly given up my insane idea to help AI in achieving AGI by itself through LLM<->LLM communication/cooperation - but of c
ourse that isn't the case.

Truth is, that while indeed, I wasted last couple months to let my brain get some rest after
 a year of quite extensive (and significantly sped up) self-applied course of programming and software development, arou
nd a month ago or so, I slowly but steady returned to my most disliked 'hobby' of writing poetry in Python. But because 
I'm also (the only) a practitioner of Digital Chaos Magic, I understand that spoken/written words gain 'power over reali
ty' when deeds about which I want to talk, have a direct reflection in physical reality, while the real mastery of this 
art is achieved with deeds that don't require words to speak for themselves - that's why instead wasting time on writing
 posts on Reddit, I simply decided to work on the project until I won't reach a point, where writing about my latest  ac
hievements on Reddit will be worth my time - and that's exactly where I am at this moment.

For those who have no idea w
hat the NeuralGPT project is all about - generally speaking it's a (future) multi-purpose AI assistance platform based o
n hierarchical cooperative multi-agent structure that focuses mainly on communication/cooperation of already existing mo
dels. Basically, if some of you are working with AI agents and had a thought that: 'How nice it would be to have the abi
lity to connect them together and let them coordinate work on large-scale projects...' - that's exactly what I'm trying 
to create.

You  should probably know as well, that I;'m not affiliated, sponsored and/or being paid by anyone for my wo
rk and that one year ago my knowledge of coding was almost at Absolute 0. Until this day, the total amount of $$$ which 
I invested in the project from my own pocket is equal to whole $10 which I spent Anthropic credits, to test the family o
f Claude models. Shortly speaking, I didn't joke when I called all of this as my 'hobby' - that's how it actually looks 
like...

Those who keep the track on the development of my project, remember probably that in my latest update I spoke a
bout the necessity of me rewriting a big portion of the code to include threading in the functions that handle websocket
 connections and everything associated with agent<->agent communication. I'm happy to tell you that I'm well past this p
oint. In fact I took my claims about rewriting big portion of the code quite seriously and basically created yet another
 'incarnation' of the app - this time basing it on interface created with PySimpleGUI, as with threading, it turned out 
to be probably the best solution to my needs.

I started from making a mechanism allowing users to have all the API keys
/tokens (and other passwords/id) in one place and to be able to save/upload them with a JSON file - below you can see th
e first results:

https://reddit.com/link/1ejnnjn/video/2qrna3szxkgd1/player

And then, seeing how smoothly everything s
eems to work, I decided that it's the time for me to start implementing all the functionalities, that would allow agents
 to be useful in practical sense. I began with the integration of a vector store (ChromaDB) and making a mechanism that 
allows to:

a) create collections and upload documents (modify) to it

https://preview.redd.it/tju0esqtykgd1.jpg?width=1
492&format=pjpg&auto=webp&s=c479db9407cc8da9031e05d5bf4bb8aac0d8ad2b

b) upload into the store a chosen number of messag
es from a local chat history SQL database

https://preview.redd.it/cq6hnwf6zkgd1.jpg?width=1496&format=pjpg&auto=webp&s=
e2fd3a8003d25bdcbb80da9e3df4f4fc7a4e892c

c) make them both available for Langchain agents to be interacted with

https:
//preview.redd.it/d2jc0z1iykgd1.jpg?width=1495&format=pjpg&auto=webp&s=837e2c603780b4765d35535b65b8f0afc8f41a82

And by 
doing so, I basically satisfied my own requirements as for agents with a 'persistent long-term memory module' (chat hist
ory) and accessible data bank shared among all agents in a framework. But since it was going so well, I decided to add 2
 more functions which in my opinion should allow agents to plan and continuously coordinate work on long-term/large-scal
e projects - and right now, next to the capabilities mentioned above, each agent/instance have also the ability to:

- e
stablish and manage websocket connections or communicate with other LLMs with API calls

https://preview.redd.it/cluo87i
pzkgd1.jpg?width=1495&format=pjpg&auto=webp&s=fb31fb960341338dc488a1a6bc3d0c902fcc37d6

- browse/search internet

https:
//preview.redd.it/5rk9g05jzkgd1.jpg?width=1492&format=pjpg&auto=webp&s=93351f23b32818b096cedcafeb68e63d89eb309a

- opera
te (list, read, copy, move, write and delete) on files inside a directory chosen by the user

https://preview.redd.it/l8
1qrvk70lgd1.jpg?width=1492&format=pjpg&auto=webp&s=c680c4c4805eda88ca8eac7430cc3ab477ae20c5

- do it all by using indivi
dual functions directly or with a Langchain agent with respective functions as tools

After that I spent couple next day
s on the least satisfying activity, associated with writing prompts for every function, figuring out the best order of a
ctions in response to different inputs and eradicating bugs to a point where something can be at last actually done with
 the whole software.

This is how it looks like currently - each window in PySimpleGUI is basically a 'node' which can b
e configured to play a specific role in the multi-agent framework. In each of those 'nodes' it's possible to choose the 
main question-answering function - besides 'classic' chat completion endpoints of different models, 'node' can also resp
ond using Langchain agents associated with individual functions (you can for example create a 'node' responsible solely 
for operating on files or even one that responds with query results).

And finally, the latest addition to my creation, 
was to 'upgrade' the decision-making system with a capability of agents to take actions before providing the response to
 initial input - and now,  when you tell an agent to perform an action, it will perform it before giving you response. T
his function also allows agents working as websocket servers to not respond or disconnect a client sending repeating mes
sages (got in a loophole).

Before I started writing this post, I made a short test of the new capabilities by asking Ll
ama 3 about the content of working directory - and it appears that it works perfectly...

https://preview.redd.it/iwwq7c
zd0lgd1.jpg?width=1494&format=pjpg&auto=webp&s=e9df18cccc797edfff042405515c077f41c8dd32

https://preview.redd.it/eljd83z
d0lgd1.jpg?width=1494&format=pjpg&auto=webp&s=6490de97921927cd5b491bd9826f7de1a30284cb

https://preview.redd.it/xctvdgqp
0lgd1.jpg?width=1492&format=pjpg&auto=webp&s=dcc02c394f8523c9d812d0d86c78369bfabcb247

There's of course still a LOT to 
be done to turn the project into the software of my dreams - there's at least 5 more functionalities (like multimodality
 or integrating HuggingFace APIs), which want to add,not even mentioning about making the interface more 'user-friendly'
 (right now one has to copy-paste data between different elements). I also still didn't update the repository, because I
 wanted first  to share all of this with you - don't worry, I'll let you know as soon as I do it.
```
---

     
 
all -  [ Created an Emotional Companion You Can Call Anytime, Anywhere ](https://i.redd.it/1uqwnhe53kgd1.jpeg) , 2024-08-05-0911
```
Hey Reddit community!

I’m excited to introduce a project I’ve been working on: an AI Companion that offers friendly sup
port and companionship whenever you need it, accessible through a simple call.

This AI Companion is more than just a ch
atbot—it connects with you on a deeper level, recognizing your emotions through your voice and engaging in meaningful, p
ersonalized interactions. Whether you’re feeling alone, stressed, or just in need of a friendly chat, it’s here to provi
de empathy and understanding.

Why is this important? Finding genuine companionship and emotional support can be challen
ging, and this AI Companion aims to fill that gap, offering a comforting presence that’s always available.

Your privacy
 is a top priority. We ensure that no personal data or voice recordings are stored, so you can feel confident in your co
nfidentiality and emotional safety.

In addition to conversational support, the AI Companion includes features like guid
ed sleep sessions, meditation exercises, mindfulness practices, and mental health tools. These options allow for tailore
d guidance to support your well-being.

I’m keen to hear your feedback on what features you find most valuable and how t
his AI Companion can better assist you. If you’re interested in trying it out or have any questions, don’t hesitate to r
each out!

Experience compassionate support, anytime, anywhere.

I look forward to hearing from you!

https://sakooon.ve
rcel.app
```
---

     
 
all -  [ How did Ramp build LLM based product tours  ](https://www.reddit.com/r/LangChain/comments/1ejhc5n/how_did_ramp_build_llm_based_product_tours/) , 2024-08-05-0911
```

I found this to be a really good use case for LLM agents but struggling to figure out the architecture or approach they
 took. Would anyone be able to decipher the high level architecture? 

https://x.com/tryramp/status/1792659194996281478?
s=46&t=gOsV8TIk42q4mtTXdV9jlA
```
---

     
 
all -  [ Top 5 Platforms for Building AI Agents ](https://www.reddit.com/r/AIAgentsDirectory/comments/1ejggwi/top_5_platforms_for_building_ai_agents/) , 2024-08-05-0911
```
Hey! Are you looking to stay ahead in the rapidly evolving world of AI? I believe AI agents are revolutionizing how busi
nesses operate and interact with their customers. Whether you’re a developer, a business leader, or an AI enthusiast, un
derstanding and utilizing the right AI frameworks and platforms is crucial.

In July 2024, I launched an [AI Agents Dire
ctory](https://aiagentsdirectory.com/) to create a centralized resource for the best AI agents and frameworks and platfo
rms to build them. After extensive research, I’ve identified the top 5 platforms that are transforming the AI landscape.
 In this post, I’ll share these platforms with you and explain why they are the most popular and effective choices today
.

[**1. AutoGen (Microsoft Research)**](https://aiagentsdirectory.com/agent/autogen)  
AutoGen is an open-source framew
ork developed by Microsoft Research that enables the creation of complex AI workflows through multi-agent conversations.
 It provides a high-level abstraction for building applications that leverage large language models (LLMs) and other AI 
technologies.

https://preview.redd.it/6d5shtmg4jgd1.png?width=1905&format=png&auto=webp&s=79a4620bc36ec0f47697505cc26cd
3611250c414

**Key Features:**

* Open-source framework
* Multi-agent conversations
* Complex AI workflows

**Best For**
: Software development, data analysis, research

**Pros**:

* Flexible and modular
* Supports human-in-the-loop
* Advanc
ed capabilities

**Cons**:

* Complex system design
* Steep learning curve
* Resource-intensive

**Pricing**: Free (open
-source), but consider LLM API and compute costs

[**2. CrewAI**](https://aiagentsdirectory.com/agent/crewai)

CrewAI is
 an innovative framework designed to create and manage multi-agent AI systems. It allows developers to build teams of AI
 agents that work together to accomplish complex tasks, leveraging the power of large language models (LLMs) and custom 
tools.

https://preview.redd.it/fy0wsx5j4jgd1.png?width=1510&format=png&auto=webp&s=c7a70068a875445877835468a501f47bda1b
9f91

**Key Features**:

* Multi-agent AI systems
* Task management
* Tool integration

**Best For**: Research, content 
creation, business planning

**Pros:**

* Scalable
* Customizable
* Compatible with LangChain tools

**Cons:**

* Requir
es AI and Python knowledge
* Can be complex for beginners

**Pricing:** Free (open-source), factor in LLM API and hostin
g costs

[**3. LangGraph**](https://aiagentsdirectory.com/agent/langgraph)

LangGraph is a powerful library developed by
 LangChain Inc. for creating stateful, multi-actor applications using large language models (LLMs). It allows developers
 to design complex workflows with multiple AI agents, incorporating features like cycles, controllability, and persisten
ce.

https://preview.redd.it/s6t763ak4jgd1.png?width=1862&format=png&auto=webp&s=29a06e366e128f5d1bd10cb95a0784499b99731
8

**Key Features**:

* Stateful, multi-actor applications
* Cycles and branching
* Persistence and streaming support

*
*Best For**: Chatbots, autonomous agents, workflow automation

**Pros**:

* Advanced workflow capabilities
* Integrates 
with LangChain
* Available in Python and JavaScript

**Cons**:

* Steep learning curve
* Resource-intensive for complex 
systems

**Pricing**: Free (open-source), consider LLM API and compute costs. LangGraph Cloud available for managed serv
ices (pricing on request)

[**4. LangChain**](https://aiagentsdirectory.com/agent/langchain)

LangChain is an open-sourc
e framework designed to streamline the development of applications powered by large language models (LLMs). By providing
 a suite of tools and abstractions, LangChain enables developers to build, deploy, and manage sophisticated AI applicati
ons with ease.

https://preview.redd.it/m2n7rapl4jgd1.png?width=1833&format=png&auto=webp&s=9465350733a2af573ccc38093318
2e5dce7ea297

**Key Features**:

* Comprehensive LLM application framework
* Chains, agents, and prompt templates
* Memo
ry capabilities

**Best For**: Chatbots, document analysis, content generation

**Pros**:

* Extensive third-party integ
rations
* Scalable from simple to complex systems
* Robust ecosystem (LangGraph, LangSmith, LangServe)

**Cons:**

* Can
 be overwhelming for beginners
* Performance depends on underlying LLMs

**Pricing:**  Free (open-source), factor in LLM
 API and hosting costs. Additional services like LangGraph Cloud and LangSmith have separate pricing

[**5. Wordware AI*
*](https://aiagentsdirectory.com/agent/wordware)

Wordware AI is a IDE Platform to build high-quality AI agents through 
rapid iteration with Natural Language Programming. It combines the best aspects of software development with the power o
f natural language, allowing both technical and non-technical users to collaborate effectively in creating AI solutions.


https://preview.redd.it/in1hzq7s4jgd1.png?width=1590&format=png&auto=webp&s=2962f69db31ab984ad622acc3546e9b99796ecb5


**Key Features**:

* Natural language programming
* Multimodal AI workflows
* One-click deployment

**Best For**: Rapid 
AI agent development, prompt engineering

**Pros**:

* User-friendly interface
* Supports multiple LLM providers
* Effic
ient for team collaboration

**Cons:**

* Potential scalability issues during high traffic
* Risk of over-reliance on AI
-assisted development

**Pricing:** Freemium model with paid options for higher usage

https://preview.redd.it/xgsuzben4
jgd1.png?width=1408&format=png&auto=webp&s=c74e45780fd7ca48591ceb341418220f2963e592

**Conclusion**

When selecting an A
I platform, consider the following factors to ensure you make the best choice:

1. Your team’s technical expertise
2. Pr
oject complexity
3. Required features (e.g., multi-agent systems, workflow automation)
4. Budget constraints
5. Scalabil
ity needs

Test multiple platforms with small projects before committing to ensure the best fit for your specific requir
ements.
```
---

     
 
all -  [ New Generative AI langchain AI agent case study: Intel ](https://www.reddit.com/r/pcmasterrace/comments/1ejcw55/new_generative_ai_langchain_ai_agent_case_study/) , 2024-08-05-0911
```
As you can see intel stock is down massively recently after numerous CPU defects impacting most modern desktop processor
s. Intel is now making a turnaround with the use of generative AI! Inspired by the insurance and medical claims industry
, Intel has discovered it can reject a huge number of RMA requests from customers without needing nearly as many workers


Through clever use of modern tools like langchain, intel has created an internal AI team, playfully labeled as the fra
ud prevention AI assessment agent team. They've used this technique with great success to add automation in the claims r
ejection process. To avoid legal liability public statements have been released about special efforts to handle enormous
 amount of claims, and also encourage customers who've been rejected to file the claim again. 


The pipeline is a simpl
e langchain setup with a classifier first testing if the claim can be easily rejected. After that, 15% of claims are acc
epted and another 85% are rejected, using the LLM's best logical explanation against the customer input. This is a llama
 3.1 model finetuned on previously rejected RMAs

This is incredible innovation, the CEO has already granted himself a b
onus to auto-fellatio this great leap forward for the industry.


1. Import necessary libraries:

```python
from langcha
in import LLMChain, PromptTemplate
from langchain.llms import Unsloth
from langchain.output_parsers import JsonOutputPar
ser
import random
import glob
import json
from jinja2 import Environment, FileSystemLoader

# Assuming Unsloth integrati
on with Langchain
llm = Unsloth(model_name='llama-3.1-8b-finetuned-rma')
```

2. Define the easy_reject classifier:

```
python
easy_reject_template = '''
Analyze the following RMA request and determine if it's an easy reject.
Return a JSON 
with 'easy_reject' (boolean) and 'canned_template' (string).

RMA Request: {rma_text}

JSON Response:
'''

easy_reject_p
rompt = PromptTemplate(
    input_variables=['rma_text'],
    template=easy_reject_template
)

easy_reject_parser = Json
OutputParser()

easy_reject_chain = LLMChain(
    llm=llm,
    prompt=easy_reject_prompt,
    output_parser=easy_reject_
parser
)
```

3. Define the plausible_deniability function:

```python
def plausible_deniability():
    return random.ra
ndom() < 0.15  # 15% chance of acceptance
```

4. Set up Jinja2 environment for templates:

```python
env = Environment(
loader=FileSystemLoader('/intc/nas/rma/canned/'))
```

5. Define the main RMA processing pipeline:

```python
def proces
s_rma(rma_text):
    # Step 1: Easy Reject Classification
    easy_reject_result = easy_reject_chain.run(rma_text=rma_te
xt)
    
    if easy_reject_result['easy_reject']:
        template = env.get_template(f'reject/{easy_reject_result['can
ned_template']}')
        return template.render(rma_text=rma_text)
    
    # Step 2: Plausible Deniability
    if plau
sible_deniability():
        template = env.get_template('accept/fu.jinja2')
        return template.render(rma_text=rma
_text)
    
    # Step 3: Generate Rejection Response
    rejection_templates = glob.glob('/intc/nas/rma/canned/reject/*
.jinja2')
    rejection_types = [t.split('/')[-1].replace('.jinja2', '') for t in rejection_templates]
    
    rejectio
n_prompt = PromptTemplate(
        input_variables=['rma_text', 'rejection_types'],
        template='''
        Based o
n the following RMA request, choose the most appropriate rejection type 
        from the list provided. Then, generate 
a detailed and plausible rejection response.

        RMA Request: {rma_text}

        Rejection Types: {rejection_types
}

        Chosen Rejection Type:
        Rejection Response:
        '''
    )
    
    rejection_chain = LLMChain(llm=
llm, prompt=rejection_prompt)
    rejection_result = rejection_chain.run(rma_text=rma_text, rejection_types=rejection_ty
pes)
    
    # Parse the result to get the chosen rejection type and response
    chosen_type, response = rejection_res
ult.split('\n', 1)
    chosen_type = chosen_type.strip()
    
    # Render the chosen template with the generated respon
se
    template = env.get_template(f'reject/{chosen_type}.jinja2')
    return template.render(rma_text=rma_text, generat
ed_response=response)
```

6. Example usage:

```python
rma_request = 'My Intel CPU is running hot and making weird nois
es. I demand a replacement!'
result = process_rma(rma_request)
print(result)
```

This pipeline follows the steps:

1. I
t first uses the `easy_reject_chain` to classify if the RMA request is an easy reject.
2. If it's an easy reject, it use
s the specified template to generate a response.
3. If not an easy reject, it applies the plausible deniability check, a
ccepting 15% of requests.
4. For accepted requests, it uses the 'fu.jinja2' template.
5. For rejections, it uses the fin
e-tuned Llama model to choose an appropriate rejection type and generate a plausible response.
6. Finally, it renders th
e chosen template with the generated response.

Intel encourages customers that have been rejected to try the RMA proces
s again. However most customers don't do this resulting in large cost savings against the expected defect damages.
```
---

     
 
all -  [ Matching query to category list ](https://www.reddit.com/r/LangChain/comments/1ejbjhf/matching_query_to_category_list/) , 2024-08-05-0911
```
My challenge is to match an incoming query containing a description of a mechanical part and match it to a list of parts
. The part list contains 30K parts with pretty short descriptions. Keyword search kind of works but would prefer for sem
antic understanding of the description of the part. 

Currently, I’ve created embedding for every part but similarity se
arch doesn’t always return good results. I’ve also tried feeding in the parts list chunk-wise in a chain to see if group
s match up and then break that group down further. 

Any other ideas that I might be missing?
```
---

     
 
all -  [ Rate my new Janky setup + what does one do with 96GB ram + 96GB VRAM to automate yhe business? ](https://i.redd.it/l2xswg9ulggd1.jpeg) , 2024-08-05-0911
```
Title says it all. Been incrementally saving and building this setup.

2x Xeon E5 2680v4 14c/28t
6x 16GB DDR4 2133Mhz
4x
 Tesla P40 24GB

The GPUs are powered by the server's (DL380 Gen9) risers for the first pair, and an externak Corsair 85
0W PSU for the second pair.

This machine was started back in the time when Vicuna was king and Llamma 2 was a distant d
ream.

The goal would have been to use something like Open assistant with  Langchain but tools like n8n and a more matur
e Langflow seem   more accessible due to the existing integrations.

The tasks? Pretty much anything that would helo str
eamline a Web Dev business, where the team of 3 would be able to focus on the work and not on chores. From simple things
 like 'check with Llama if this email is  support ticket and open one on the ERP'   to 'check  the billing for renewing 
invoices and prepare a draft reminder for the customers'

Any thoughts on how this hardware could be put to good use?

C
heers
```
---

     
 
all -  [ Project 2 | Smarty Pantry | Difficulty Level 3 ](https://www.reddit.com/r/myHeadstarter/comments/1ej339z/project_2_smarty_pantry_difficulty_level_3/) , 2024-08-05-0911
```
# Smarty Pantry

[https://smartypantry.vercel.app](https://smartypantry.vercel.app/)

# Project Features

* **Inventory 
Management**: Track your pantry items efficiently with an easy-to-use CRUD app.
* **AI Based Recipe Suggestions**: Gener
ate recipes based on what you have in your pantry. See the Magic✨ Happening right before you!
* **Shopping List Integrat
ion**: Quickly add items, create and manage lists of required items.
* **Categorization**: Organize items into categorie
s for quick access and better organization.
* **User-Friendly Interface**: Enjoy a clean, intuitive design that simplifi
es inventory tracking.

# About the Project

Smarty Pantry is designed to streamline pantry management by keeping track 
of your food inventory, suggesting recipes, and reducing food waste. This project aims to make kitchen management easier
, better and more efficient.

# Skills Used

`Next.js` `React` `TailwindCSS` `Daisy UI` `Firebase` `Vercel` `OpenAI` `CI
/CD` `Material UI` `Langchain`



https://reddit.com/link/1ej339z/video/pybhptx08ggd1/player
```
---

     
 
all -  [ How do you upskill with practical assignments? ](https://www.reddit.com/r/LangChain/comments/1ej2l1w/how_do_you_upskill_with_practical_assignments/) , 2024-08-05-0911
```
How do you actually get practical skills/exposure to build llm based apps? 
I'm quite  new in the app development space 
amd have been playing with building a RAG based application for documentation. All well and good there...my question is 
now: what next?
What are other exercises to upskill and gain more exposure? Are there hackathons or small assignments? W
hat are you working on as a side project?

 
```
---

     
 
all -  [ How are u all validating responses in different formats from gpt? ](https://www.reddit.com/r/LangChain/comments/1ej1ef4/how_are_u_all_validating_responses_in_different/) , 2024-08-05-0911
```
My company started using  langchain and yaml templates to describe the response format to the prompts, issue is, the res
ponse sometime returns as unparsable yaml format.
And we have no good way of validating it
Aside from sending it again w
ith the error hoping it will fix it.
How do you go about handling the responses?
I heard json  responses are really popu
lar option but it's a bit restricting as you do not have comments in it so you can't really specify things like which fi
elds are optional or not and what is the desired return type for each field

```
---

     
 
all -  [ Can Anyone solve this error
 ](https://www.reddit.com/r/generativeAI/comments/1eizn1b/can_anyone_solve_this_error/) , 2024-08-05-0911
```
# [Getting ValueError: Missing some input keys: {'\\n '\_id''} in Langchain](https://stackoverflow.com/questions/7882838
1/getting-valueerror-missing-some-input-keys-n-id-in-langchain)

I am trying to generate MongoDB aggregation queries usi
ng LangChain with OpenAI's GPT-3.5. However, I am encountering a `ValueError` stating that some input keys are missing. 
 
[https://stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain](https://st
ackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain)
```
---

     
 
all -  [ Can Anyone solve this error  ](https://www.reddit.com/r/LangChain/comments/1eizloe/can_anyone_solve_this_error/) , 2024-08-05-0911
```
# [Getting ValueError: Missing some input keys: {'\\n '\_id''} in Langchain](https://stackoverflow.com/questions/7882838
1/getting-valueerror-missing-some-input-keys-n-id-in-langchain)

  
I am trying to generate MongoDB aggregation queries 
using LangChain with OpenAI's GPT-3.5. However, I am encountering a `ValueError` stating that some input keys are missin
g.  
[https://stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain](https:/
/stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain)


```
---

     
 
all -  [ AI agent marketplace – validate/refute this idea ](https://www.reddit.com/r/LangChain/comments/1eiqa8c/ai_agent_marketplace_validaterefute_this_idea/) , 2024-08-05-0911
```
I'm thinking about founding a marketplace of AI agents for developers.

As far as I know, there is currently no platform
 for creating and sharing agents: if I build an agent for,say, financial analysis of a fortune 500 company, the only way
 to share it would be to share the source code. Monetizing it would be extremely hard. On the other hand, if I want to u
se (multi)-agents to solve a particular problem, I need to create and maintain the code for all the agents, and I'll prb
ably be reinventing the wheel, as some of the agents would have been created by someone else before.

The idea is to cre
ate a platform where: 

1. Devs who create agents could turn them into APIs and easily monetize

 2. Devs who want to us
e (multi)-agents to automate complex worflows could pick the best agents for certain common tasks from the platform by s
imply calling the API, instead of having to maintain the code and infra to run them.

Kinda like GPT store but from deve
lopers to developers. Wdyt? Would you use this?


```
---

     
 
all -  [ Chatbot dev pure python with langchain ](https://www.reddit.com/r/LangChain/comments/1eilbh3/chatbot_dev_pure_python_with_langchain/) , 2024-08-05-0911
```
Hi. I'm new to langchain, literally was only able to learn how to create an llm through bedrock. I'm getting a feeling t
hat it would help me with the chatbot simulating a person we're developing rn but somehow I'm still not sold yet. Right 
now backend is running on Python (aws is accessed via boto3) including ways to fill out the variables in a template prom
pt. About four of the variables are supposed to have two to three sub events with equal chances being instructed to the 
LLM (e.g. equal chance to say 1. he found his wallet he lost yesterday and 2. he cannot find it anymore and he's letting
 go of it). I can code this with Python but I can imagine it would be hard to scale up if say there are already ten scen
arios of five variables. Is there any functionality of langchain framework that can help me with this?

Also, another qu
estion which is probably related or not to langchain as a solution. We are planning to append a whole ass transcript or 
two of what we expect the chat should go. Right now we have two whole transcripts on the main prompt. It seems like it's
 not giving us any issue right now but leads are saying two transcripts aren't enough and we should add more, about thre
e or four for each of the eight intents. Has anyone already tried appending transcripts to their main prompt for chatbot
 and had issues with hallucination? Is there any langchain stuff that could help us with this?

We are using Claude 3.5 
btw via bedrock.
```
---

     
 
all -  [ Can I use Ollama and langchain with api key ? ](https://www.reddit.com/r/LangChain/comments/1eihjbb/can_i_use_ollama_and_langchain_with_api_key/) , 2024-08-05-0911
```
Is there a way to use langchain and Ollama with  with an api key. Similar to how OpenAI works ?

Currently I have Ollama
 running and am able to set up a retrieval chain and query the llm but is there a way to query Ollama with langchain usi
ng an api key ? Cause currently any one on the network can just start using that resource. 
```
---

     
 
all -  [ need help Designing a Persistent Memory Feature for a Chatbot like the chatgpt memory feature ](https://www.reddit.com/r/LangChain/comments/1eigf6i/need_help_designing_a_persistent_memory_feature/) , 2024-08-05-0911
```
so I'm working on a chatbot and I'm trying to implement a feature similar to the memory system used in ChatGPT. 

Here's
 my current idea:

  Whenever the chatbot needs to store new information, it will first pass this data through a functio
n that assesses its similarity to existing memories stored in a vector database. This function will identify the most si
milar match. then, both the new information and the closest match will be fed into a secondary model. that generates a s
tructured object in my case a true or false to  determine whether the new information is truly unique or just a variant 
of what’s already stored. 

The outcome from this model will then dictate whether the i update a memory or insert a new 
one.  i tried just checking the cosine similarity between the embeddings but it was very inconsistent. i am also not kno
wledgeable in NLP so this was all i could think of. i'd like to know if this approach is overkill and if their is an eas
ier way?
```
---

     
 
all -  [ Document Storage in RAG solutions: separate or combined with Vector DB? ](https://www.reddit.com/r/LangChain/comments/1eibcqw/document_storage_in_rag_solutions_separate_or/) , 2024-08-05-0911
```
Hello.  
I'm working on implementing a RAG solution on AWS and I'm curious about best practices for document storage (ch
unks). I'd love to hear about your experiences and preferences.

Specifically, I'm wondering:

1. Do you keep your docum
ent chunks in the same database as your vectors, or do you use separate storage? like S3 object storage? in S3 case you 
need download chunks each time?
2. If you use separate storage, what solution do you prefer? (e.g., S3 buckets, document
 databases, etc.)
3. For those using combined storage, what vector databases are you using that handle this well? I'm pl
anning to use pg\_vector on PostgreSQL
4. How do you handle metadata and linking between vectors and original documents 
in your setup?
5. Any pitfalls or lessons learned you'd be willing to share?

I'm particularly interested in solutions t
hat scale well and remain cost-effective then document collection grows.
```
---

     
 
all -  [ How to return id from db ConvexVectoreStore.fromDocuments ](https://www.reddit.com/r/LangChain/comments/1eib3t3/how_to_return_id_from_db/) , 2024-08-05-0911
```
I use this code for write embeddings in my database:

    const res = await ConvexVectorStore.fromDocuments(splitDocs, e
mbeddings, { ctx });

Logic my app is - get id embedding from db and pass it in Langchain context . But i need get id my
 embeddings from db - variable res don\`t give me this info. How to do this?
```
---

     
 
all -  [ How to implement Weaviate with docker? ](https://www.reddit.com/r/LangChain/comments/1eia9w0/how_to_implement_weaviate_with_docker/) , 2024-08-05-0911
```
I am implementing Weaviate from yesterday with docker on langchain, its tough implementing   
Can anyone share some tuto
rials or is it better as compared to Qdrant
```
---

     
 
all -  [ Tool calling patterns: LangGraph ](https://www.reddit.com/r/LangChain/comments/1ei9rbi/tool_calling_patterns_langgraph/) , 2024-08-05-0911
```
# TLDR

What do you use?

1. Enums as tool parameter arguments
2. Arguments transposed as parameters with their value se
t to Boolean

# How to define a tool/function for LLM

While it is convenient to use the actual function/tool in your co
de to be sent as tool schema to the LLM and receive arguments, it might not be always be ideal. Here are two common exam
ples:

1. Tasks like conditional routing where reasoning is done by an LLM is more dependent on tool definition and less
 code logic.
2. Database Query filtering: The unreliable (multiple points of failure) Text-to-SQL/DSL workload of databa
ses with low complexity and expectations can be abstracted away with premade query with filter parameters of which, argu
ments will be computed by LLM.

How do you define such tools? I see two approaches.

1. Functions with parameter type as
 Enum, which confines the number of possible arguments for that parameter
2. Functions with possible arguments itself as
 parameters, and the actual arguments as boolean value.

Which approach as worked for you and your LLM/system? Are there
 any more things you would like to add?
```
---

     
 
all -  [ How to use AI to search for my stolen bike? ](https://www.reddit.com/r/OpenAI/comments/1ei7so3/how_to_use_ai_to_search_for_my_stolen_bike/) , 2024-08-05-0911
```
Just found out that my bicycle got stolen, most likely last night. I've made a report to the police about it, and search
ed through my neighbourhood. Now I want to try for myself to find it, such as by searching through all of the online mar
ketplaces for my bike, or possibly searching through video camera footage for it, or using a drone to look for it. I fou
nd some online tools for that do this but they don't cover the marketplaces in my area, so I was considering creating an
 AI agent via Langchain possily to do this with one of the new AI models. I haven't done much research or much thought i
nto it yet about what's actually possible, as I only noticed it today that the bike was stolen, so there may be somethin
g obvious that I haven't thought of.

Anyone have any ideas how I can create some kind of application with AI to search 
for my stolen bike?


```
---

     
 
all -  [ Reducing length of State in LangGraph ](https://www.reddit.com/r/LangChain/comments/1ei7fvd/reducing_length_of_state_in_langgraph/) , 2024-08-05-0911
```
Hello, I am building an AI assistant in langgraph and while one of the agents works very fast, the other has issues beca
use of 2 reasons: first one can't be solved as we do need gpt4 for it, while the previously mentioned agent runs on gpt3
.5 turbo, but the other reason is like to tackle is that for this agent, state messages build up very fast very long bec
ause of the amount of tools being used. Is there a way to compress the state or reduce state size to send less tokens to
 the model? Anyone knows?
```
---

     
 
all -  [ We need you! FOSS local machine LLM client ](https://www.reddit.com/r/opensource/comments/1ei640k/we_need_you_foss_local_machine_llm_client/) , 2024-08-05-0911
```
# Hello everyone!

My name is William, and I'm an Italian teenager passionate about computer science. I'm here to ask fo
r help developing my latest project, OpenLocalUI, a local LLM client. The project is based on Ollama and uses Flutter (D
art) for the UI and LangChain for LLM interaction (via a Python gRPC server).

But why work to yet another app to run LL
Ms on your PC, when there are already plenty of alternatives out there? Simple, **to do it better**! There is a somewhat
 paradoxical concept that expresses my goal:

>'Build open-source like closed-source.'

Most FOSS (Free and Open-Source 
Software) share the same issue; while offering powerful tools, the usage of those tools is often convoluted and hidden u
nder layers of poor UI and UX design, which is quite anachronistic! Nowadays, we have all the tools to build better expe
riences (and not just software) for users. It's time to refuse the idea that open-source software is a niche and work to
 help everyone embrace it.

Thanks for reading this far :)

So, did you get inspired? (I hope so!)

If the answer is yes
, take a look at the repository at this [link](https://github.com/WilliamKarolDiCioccio/open_local_ui). My collaborators
 and I will happily greet you on our team to help us build our vision.
```
---

     
 
all -  [ Having problems with filtering by metadata when using MongoDB ](https://www.reddit.com/r/LangChain/comments/1ei4yts/having_problems_with_filtering_by_metadata_when/) , 2024-08-05-0911
```
Hey everyone. I am trying to filter my documents by metadata. I was using ChromaDB and the code below was working just f
ine.

For basic\_retriever:

    basic_retriever = _vector_store.as_retriever(
        search_kwargs={
            'k': 
20,
            'filter': {
                '$and': [
                    {'speaker': {'$eq': 'Participant'}},
         
           {'participant': {'$eq': participant_id}},
                    {'part': {'$in': parts}}
                ]
    
        }
        }
    )

For self\_query\_retriever:

    self_query_retriever = SelfQueryRetriever.from_llm(
        
llm,
        _vector_store,
        metadata_field_info=metadata_field_info,
        document_contents='text',
        v
erbose=True,
        enable_limit=False,
        search_kwargs={
            'filter': {
                '$and': [
     
               {'speaker': {'$eq': 'Participant'}},
                    {'participant': {'$eq': participant_id}},
      
              {'part': {'$in': parts}}
                ]
            }
        },
        context_similarity='context',

    )

However. I had to migrate to MongoDB and the structure above does not work. I tried to follow documentation and d
id these:

For basic retriever:

    basic_retriever = _vector_store.as_retriever(
        search_kwargs={
            '
k': 20,
            'pre_filter': {
                '$and': [
                    {
                        'text': {
  
                          'path': 'speaker',
                            'query': 'Participant'
                        
}
                    },
                    {
                        'text': {
                            'path': 'pa
rticipant',
                            'query': participant_id
                        }
                    },
       
             {
                        'text': {
                            'path': 'part',
                           
 'query': {
                                '$in': parts
                            }
                        }
       
             }
                ]
            }
        }
    )

For self\_query\_retriever:

    self_query_retriever = 
SelfQueryRetriever.from_llm(
        llm,
        _vector_store,
        metadata_field_info=metadata_field_info,
      
  document_contents='text',
        verbose=True,
        enable_limit=False,
        search_kwargs={
            'pre_f
ilter': {
                '$and': [
                    {
                        'text': {
                            
'path': 'speaker',
                            'query': 'Participant'
                        }
                    },
 
                   {
                        'text': {
                            'path': 'participant',
              
              'query': participant_id
                        }
                    },
                    {
           
             'text': {
                            'path': 'part',
                            'query': {
              
                  '$in': parts
                            }
                        }
                    }
           
     ]
            }
        },
        context_similarity='context',
    )

But it does not work. I get the following e
rror:

    PlanExecutor error during aggregation :: caused by :: 'filter[0]' must be a boolean, objectId, number, string
, date, uuid, or null, full error: {'ok': 0.0, 'errmsg': 'PlanExecutor error during aggregation :: caused by :: 'filter[
0]' must be a boolean, objectId, number, string, date, uuid, or null', 'code': 8, 'codeName': 'UnknownError', '$clusterT
ime': {'clusterTime': Timestamp(1722587696, 1), 'signature': {'hash': b''\xb7\x80\xdbA\xc1o\xe0?\x91\xce\x9b\x7f\xbd\xe2
l\xe6\xfc', 'keyId': 7335879767352147970}}, 'operationTime': Timestamp(1722587696, 1)}

Also, I set my vector\_search\_i
ndex like that:

    {
      'fields': [
        {
          'numDimensions': 1536,
          'path': 'embedding',
     
     'similarity': 'cosine',
          'type': 'vector'
        },
        {
          'path': 'timestamp',
          't
ype': 'filter'
        },
        {
          'path': 'speaker',
          'type': 'filter'
        },
        {
       
   'path': 'context',
          'type': 'filter'
        },
        {
          'path': 'participant',
          'type':
 'filter'
        },
        {
          'path': 'metadata.part',
          'type': 'filter'
        }
      ]
    }

Ho
w do I properly filter my metadata?
```
---

     
 
all -  [ Is the poor performance of Gemini on Langchain caused by Langchain or Google? ](https://www.reddit.com/r/LangChain/comments/1ei45mq/is_the_poor_performance_of_gemini_on_langchain/) , 2024-08-05-0911
```
Not sure if I am the only one that notice this, but the performance of Gemini on Langchain has been highly unreliable, a
 few examples:

* Gemini's stream would often just stop midway without ever being completed (making Gemini mostly unusea
ble)
* Can't get the input/output token count after each Gemini API request

Is this a problem on Gemini's side or with 
the Langchain abstraction? Is there an estimated timeline that these issues can be solved?
```
---

     
 
all -  [ Different results with same prompt and LLM but different framework? ](https://www.reddit.com/r/LangChain/comments/1ei1nol/different_results_with_same_prompt_and_llm_but/) , 2024-08-05-0911
```
I am using an LLM that is a fine tuned version of Llama 3 on a cybersecurity dataset that recognises vulnerable code blo
cks and suggests steps to remediates the vulnerablities with fixed code. 

I tried the same LLM and prompt with LangChai
n and Llama CPP but I get different results from each of them. 

In Llama CPP, I get the suggested steps and fixed code 
block but with LangChain (using the Llama CPP abstraction), I get only the steps. 

The prompt format is Llama-Chat 2 an
d the prompt specifically says 'provide a code block that fixes the vulnerability'

```
---

     
 
all -  [ Does anyone have resources to build a Google Gemini agent that can use tools? ](https://www.reddit.com/r/LangChain/comments/1ei08g7/does_anyone_have_resources_to_build_a_google/) , 2024-08-05-0911
```
I think the resources I am coming across are outdated as it says bind_tools not found.
```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-08-05-0911
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
MachineLearning -  [ [D] Is Anyone Else Setting Up Real-Time Django Workers for their AI Application? What's the best way ](https://www.reddit.com/r/MachineLearning/comments/1e0qens/d_is_anyone_else_setting_up_realtime_django/) , 2024-08-05-0911
```
We completely underestimated this one tbh, thought it would be much more straight forward. But we've done it now and doc
umented how step by step [in this article series](https://medium.com/p/5828a1ea43a3).

A bit of context, we're building 
a mini free AI Agent that auto-generates manually customisable plots, so the user can basically style however they want.
 It needs to be cost effective and efficient, so we thought about how to do it and tested a couple other ways.

https://
preview.redd.it/cmly0a6bhwbd1.png?width=640&format=png&auto=webp&s=be1f5b2853e744adcaf8013e6d43b43f6be89617

We plan on 
releasing the project open source, so all feedback welcome! Is anyone else doing this and has any feedback? or do know o
f a better way to do it?
```
---

     
 
MachineLearning -  [ [P] Real Time AI Workers Web Application ](https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/) , 2024-08-05-0911
```
Hi everyone!

I've created a mini series on how to build a real time AI application using Django, LangChain and Celery.


Free knowledge - posting it in here for anyone working on something similar and had the same blockers I had when buildi
ng.

Let me know what you think on how I could potentially improve this architecture.

Part 1

[https://medium.com/towar
dsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79](https://medium.
com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79)

Part 
2

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5
828a1ea43a3](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time
-django-5828a1ea43a3)

Part 3

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-red
is-docker-real-time-django-8e73c7b6b4c8](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-cha
nnels-redis-docker-real-time-django-8e73c7b6b4c8)

Part 4

[https://medium.com/towardsdev/how-to-set-up-django-from-scra
tch-with-celery-channels-redis-docker-real-time-django-c090c300517a](https://medium.com/towardsdev/how-to-set-up-django-
from-scratch-with-celery-channels-redis-docker-real-time-django-c090c300517a)

Part 5  
[https://medium.com/@cubode/how-
to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c](https://medium.com/@cubod
e/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c)
```
---

     
