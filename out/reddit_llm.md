 
all -  [ LLM for textbooks, feasible ? ](https://www.reddit.com/r/learnmachinelearning/comments/16jlt3n/llm_for_textbooks_feasible/) , 2023-09-16-0909
```
I want to build a webapp SAAS that allows you to chat with an AI tutor about  specific textbook. Some of these textbooks
 are in English and others are Arabic, conceptual , no equations or anything.
I couldn't find anything like this. Im a t
otal noob with AI. but I think it can be made using langchain and openai api , can it ?
```
---

     
 
all -  [ Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/LocalLLaMA/comments/16jl53m/agents_an_opensource_framework_for_autonomous/) , 2023-09-16-0909
```
I hope this paper is also interesting this community!

Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2
309.07870) 

Github: [https://github.com/aiwaves-cn/agents](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent a
dvances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can a
utomatically solve various tasks and **interact with environments, humans, and other agents** using natural language int
erfaces. **We consider language agents as a promising direction towards artificial general intelligence** and release Ag
ents, an **open-source library** with the goal of opening up these advances to a wider non-specialist audience. Agents i
s carefully engineered to support important **features including planning, memory,  tool usage, multi-agent communicatio
n, and fine-grained symbolic  control.** Agents is **user-friendly** as it **enables non-specialists** to build, customi
ze, test, tune, and deploy state-of-the-art **autonomous language agents without much coding**. The **library** is also 
**research-friendly as its modularized design** makes it **easily extensible for researchers.** 

https://preview.redd.i
t/ne8fsj05rgob1.jpg?width=1131&format=pjpg&auto=webp&s=076a3551bddb817351d9865809923a6bdf840cb1

https://preview.redd.it
/u4x4hm05rgob1.jpg?width=1656&format=pjpg&auto=webp&s=2ca813790719b1f6f285e67ca92834e02d12c40c

&#x200B;

&#x200B;
```
---

     
 
all -  [ Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/agi/comments/16jl4rw/agents_an_opensource_framework_for_autonomous/) , 2023-09-16-0909
```
Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2309.07870) 

Github: [https://github.com/aiwaves-cn/age
nts](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent advances on large language models (LLMs) enable research
ers and developers to build autonomous language agents that can automatically solve various tasks and **interact with en
vironments, humans, and other agents** using natural language interfaces. **We consider language agents as a promising d
irection towards artificial general intelligence** and release Agents, an **open-source library** with the goal of openi
ng up these advances to a wider non-specialist audience. Agents is carefully engineered to support important **features 
including planning, memory,  tool usage, multi-agent communication, and fine-grained symbolic  control.** Agents is **us
er-friendly** as it **enables non-specialists** to build, customize, test, tune, and deploy state-of-the-art **autonomou
s language agents without much coding**. The **library** is also **research-friendly as its modularized design** makes i
t **easily extensible for researchers.** 

https://preview.redd.it/impiu2f5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=
032644106e6ccebda499680560c2e8016485e1b1

https://preview.redd.it/2w5i64f5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=0
3a9f64546c4240654837fd3bbf577b13632f31f

&#x200B;
```
---

     
 
all -  [ [R] Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023 ](https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/) , 2023-09-16-0909
```
Paper: [https://arxiv.org/abs/2309.07870](https://arxiv.org/abs/2309.07870) 

Github: [https://github.com/aiwaves-cn/age
nts](https://github.com/aiwaves-cn/agents) 

Abstract:

>Recent advances on large language models (LLMs) enable research
ers and developers to build autonomous language agents that can automatically solve various tasks and **interact with en
vironments, humans, and other agents** using natural language interfaces. **We consider language agents as a promising d
irection towards artificial general intelligence** and release Agents, an **open-source library** with the goal of openi
ng up these advances to a wider non-specialist audience. Agents is carefully engineered to support important **features 
including planning, memory,  tool usage, multi-agent communication, and fine-grained symbolic  control.** Agents is **us
er-friendly** as it **enables non-specialists** to build, customize, test, tune, and deploy state-of-the-art **autonomou
s language agents without much coding**. The **library** is also **research-friendly as its modularized design** makes i
t **easily extensible for researchers.** 

https://preview.redd.it/3bdi71r5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=
760942c19be6ecda791414c812a77e72751c526d

https://preview.redd.it/howf64r5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=6
36744fccab7a1c2bafb902bad5dbb647440fff5

&#x200B;
```
---

     
 
all -  [ Easiest way to launch & experiment with a langchain powered Python app via chat interface ](https://www.reddit.com/r/LangChain/comments/16jhi3e/easiest_way_to_launch_experiment_with_a_langchain/) , 2023-09-16-0909
```
I'm building an agent and I want to be able to interact with it easily. I've been thinking WhatsApp or Jupyter notebooks
 are the easiest way to start, but feels like there's probably some canonical solution folks are using?  


All I'm look
ing for is some experience where I can provide a chat API and it'll handle frontend chat experience for interaction.
```
---

     
 
all -  [ How much preprocessing are you doing for RAG QA chatbots w/ documents? ](https://www.reddit.com/r/LocalLLaMA/comments/16jde4z/how_much_preprocessing_are_you_doing_for_rag_qa/) , 2023-09-16-0909
```
I know there is a ton of interest in document QA systems, which makes sense since it has good business values to most or
ganizations.

I'm wondering for those of you who found the answers from you QA systems to be good, did you guys just dro
p the PDF / Word / etc... into the program and let the RecursiveCharacterSplitter in langchain do the work, or did you g
uys do some preprocessing before you chunked it up and loaded into the vector db.  
I am trying to do QA on a PDF of a t
extbook. I wrote some scripts to 'chunk' the textbook so each chunk also contains it's associated Title and Subheading. 


&#x200B;

Let's say we are in Chapter: Carbon-Carbon Bonds. Below is an example passage:  


Grignard Reaction:

The g
rignard reaction is very lit. Only the most based can perform it. Blah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah 
BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBl
ah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah  


I would then crea
te chunks from this passage like this:

&#x200B;

Carbon-Carbon Bonds

Grignard Reaction

The grignard reaction is very 
lit. Only the most based can perform it. Blah Blah Blah

Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Bl
ah BlahBlah Blah Blah

\-------------------------------------------------------

Carbon-Carbon Bonds

Grignard Reaction


Blah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah

Blah Blah BlahBlah Blah BlahBlah 
Blah BlahBlah Blah BlahBlah Blah BlahBlah Blah Blah  


Then I embed the chunks. The idea is that including the title an
d header will make have a higher similarity score.

Has anyone found it necessary to perform this type of chunking? Anyo
ne getting great results with easier methods?  


  


  


&#x200B;

&#x200B;

&#x200B;

&#x200B;
```
---

     
 
all -  [ Leveraging code generation tools for LangChain based project ](https://www.reddit.com/r/LangChain/comments/16jarl3/leveraging_code_generation_tools_for_langchain/) , 2023-09-16-0909
```
Hi !

I am looking to leverage the code generation features of LLM to create up-to-date apps. Currently, if I try to dev
elop a minor script utilizing the LangChain library through ChatGPT, it is unfeasible given its existing knowledge base 
(Sep 21).

How would you go about ensuring that the generated code using any library aligns with the most recent documen
tation? Someone was mentioning Claude, and to feed him with the documentation. 

Any other suggestions? Especially for d
evelopers in Europe ;)

Thanks !
```
---

     
 
all -  [ Need help for Langchain Agents with memories ](https://www.reddit.com/r/LangChain/comments/16j7w5w/need_help_for_langchain_agents_with_memories/) , 2023-09-16-0909
```
Here is the detailed description of my issue, can anyone help me.

https://github.com/langchain-ai/langchain/discussions
/10568
```
---

     
 
all -  [ Laptop freezing on running embedding and vectorstore ](https://www.reddit.com/r/LangChain/comments/16j75vv/laptop_freezing_on_running_embedding_and/) , 2023-09-16-0909
```
My laptop has i7 16 core processor and yet it freezes midway between running the program i'm following. Also the vectors
tore never loads. I have tried FAISS and Chroma

Here's the code below:

 

import streamlit as st  
from dotenv import 
load\_dotenv  
from PyPDF2 import PdfReader  
from langchain.text\_splitter import CharacterTextSplitter  
from langchai
n.embeddings import HuggingFaceInstructEmbeddings  
from langchain.vectorstores import FAISS  
from langchain.chat\_mode
ls import ChatOpenAI  
from langchain.memory import ConversationBufferMemory  
from langchain.chains import Conversation
alRetrievalChain  
from htmlTemplates import css, bot\_template, user\_template  
from langchain.llms import HuggingFace
Hub  


def get\_pdf\_text(pdf\_docs):  
 text = ''  
 for pdf in pdf\_docs:  
 pdf\_reader = PdfReader(pdf)  
 for page
 in pdf\_reader.pages:  
 text += page.extract\_text()  
 return text  


def get\_text\_chunks(text):  
 text\_splitter
 = CharacterTextSplitter(  
 separator='\\n',  
 chunk\_size=1000,  
 chunk\_overlap=200,  
 length\_function=len  
)  

 chunks = text\_splitter.split\_text(text)  
 return chunks  
def get\_vectorstore(text\_chunks):  
 embeddings = Huggin
gFaceInstructEmbeddings(model\_name='hkunlp/instructor-xl')  
 vectorstore = FAISS.from\_texts(texts=text\_chunks, embed
ding=embeddings)  
 st.write('3')  
 return vectorstore  


def main():  
 load\_dotenv()  
 st.set\_page\_config(page\_
title='Chat with your documents', page\_icon=':books:')  
 st.header('Chat with your documents :books:')  
 st.text\_inp
ut('Ask a question about your documents:')  
 with st.sidebar:  
 st.subheader('Your documents')  
 pdf\_docs=st.file\_u
ploader('Upload your PDFs here and click on 'Process'', accept\_multiple\_files=True)  
 if st.button('Process'):  
 wit
h st.spinner('Processing'):  
 \#get info from pdfs  
 raw\_text=get\_pdf\_text(pdf\_docs)  
   
 \#get text chunks  
 t
ext\_chunks = get\_text\_chunks(raw\_text)  
 st.write('workin')  
 \#create vector database  
 vectorstore = get\_vecto
rstore(text\_chunks)  
 st.write('4')  
   


if \_\_name\_\_ == '\_\_main\_\_':  
 main()

&#x200B;

I have been follow
ing this tutorial: [https://www.youtube.com/watch?v=dXxQ0LR-3Hg&t=8s](https://www.youtube.com/watch?v=dXxQ0LR-3Hg&t=8s)
```
---

     
 
all -  [ Learn How to Build a LangChain Audio App with Python in Just 5 Minutes! ](https://dev.to/pavanbelagatti/learn-how-to-build-a-langchain-audio-app-with-python-in-just-5-minutes-n4o) , 2023-09-16-0909
```

```
---

     
 
all -  [ Some questions of implementing LLM to generate Q/A pairs based on local documents ](https://www.reddit.com/r/LocalLLaMA/comments/16j624z/some_questions_of_implementing_llm_to_generate_qa/) , 2023-09-16-0909
```
Recently, I have been paying around about how to implement chat-based Q/A using the LLM model based on a local knowledge
 base. 

I have experimented with the following two open-source frameworks. 

[Llama\_index](https://github.com/jerryjli
u/llama_index)

[Langchain-chatchat](https://github.com/chatchat-space/Langchain-Chatchat)

  
I believe these 2 framewo
rks are built upon what everyone refers to as the RAG (Retrieval-Augmented Generation) approach. Without altering the em
beddings and LLM, it allows for generating responses based on one's own knowledge base. 

Thanks for the author's excell
ent work, I have indeed been able to achieve my requirements to some extent. However, the output results still seem to h
ave some deviations and even mistakes. 

&#x200B;

[the work flow of chatchat](https://preview.redd.it/2mud4ayp5dob1.png
?width=834&format=png&auto=webp&s=cc598844a4d4462a8fc80383a1ce0e946828e157)

Is there a way to make the output results m
ore accurate? 

For example,  I have a user manual for the hairdryer in knowledge base showing the hair dryer is working
 under rated voltage of 110V,  when I use the LLM model with a relatively low sample size I may get a wrong answer. 

If
 I ask, 'Can I use the xxx hair dryer directly in a country with a rated voltage of 220V?' 

Llama2-7B may answers 'yes,
 you can.' 

while Llama2-13B may answer me 'no, unless you use a power adapter'. 

And GPT is capable of providing more
 excellent answers. 

I believe that if I want to achieve better output results, I may need to fine-tune the LLM or embe
ddings. 

But I've noticed that many people use Q/A pairs for fine-tuning, and I'm not sure why they do this or whether 
these operations involve fine-tuning embeddings or the LLM. In my understanding, we don't have sufficient resources for 
fine-tuning the LLM, and fine-tuning embeddings seems to only help in improving how embeddings convert human language in
to higher relevance vectors. Does this mean that when fine-tuning embeddings, there's actually no need for question-answ
er pairs? 

If I must fine-tune, should I separately fine-tune two embeddings: one fine-tuned based on question-answer p
airs for extracting vectors from documents and another fine-tuned based on question similarity for extracting vectors fr
om questions? 

&#x200B;
```
---

     
 
all -  [ Generative AI product called Needle ](https://www.reddit.com/r/LangChain/comments/16j3ppz/generative_ai_product_called_needle/) , 2023-09-16-0909
```
Hey Guys,
I am working in a product name Needle. Here are some features of it:
1. Q&A on documents (pdf, word, text, ppt
 etc.)
2. Q&A on MS Sql database (based on schema, prepare sql statement and execute it)
3. Integration with AirByte to 
support other thousands of connectors
3. Integration in your application directly: Embed as chat, API Integration
4. Cho
ose your LLM (openai, azure openai etc)
5. Host it privately and securely (export docker to your repository)

I am using
 Langchain as base framework and above things doesn’t need prompt modification or fine tuning.

How should i expand this
 product, ranging from feature expansion, marketing, reaching out to potential customers?
```
---

     
 
all -  [ Multi-Text Summarization/Question Answering ](https://www.reddit.com/r/LangChain/comments/16j2evy/multitext_summarizationquestion_answering/) , 2023-09-16-0909
```
I have a use case that uses meeting notes stored in SalesForce. I've written a function that produces a text block for e
ach meeting, which contains the meeting metadata and the meeting notes. I'd like to be able to send batches of these (co
uld be up to \~50) to an an open-source LLM (thinking LLaMa2) and prompt it to get summarizations/insights across them, 
for example:

* What were the main 5 topics that were discussed in the meetings this month?
* What questions were we ask
ed in the meetings?

What would be the best way to approach such a task? The batch of notes would be larger than the all
owable context window for most LLMs, and RAG seems more like fetching data rather than synthesizing across multiple diff
erent documents.

Somewhat new to all this, appreciate any insights!
```
---

     
 
all -  [ How to improve Chat with your own data application answer quality? ](https://www.reddit.com/r/ChatGPTCoding/comments/16j1x4c/how_to_improve_chat_with_your_own_data/) , 2023-09-16-0909
```
Hi, I have been working on my chat with your own data application for a while. I have seen most of the chat with your ow
n data tutorials on youtube, and medium articles on this topic. Majority of them just teaches you the basic mechanics of
 how to get a basic skeleton of such application working: 

1. using some form of langchain to ingest your data to a vec
tor db
2. using similarity search the vector db to return relevant documents to the question the user asks
3. set the re
turned docs from the previous step as context to the prompt you send to chatgpt api, get your answer and display the res
ult in your frontend.

Different tutorials may have a different focus on the approach, e.g. not using langchain, using l
angchain directly, using no-code UI built on top of langchain, using no-code UI built on framework similar to or modifie
d versions of langchain...

But the matter of fact is, while the output of following these tutorial kind of work, but th
ey don't live up to closer inspection. Especially if you try to put them to real world use cases, where you really try t
o use it to chat with a document or code base you really try to understand. The answers on these real world documents re
ally fall short of what you hope the AI can do. 

Anyone here have similar experience want to discuss on what can be don
e to improve on the quality of answers produced by these LLM Q&A applications? 

Looking forward to hearing your thought
s on this problem.

Thanks
```
---

     
 
all -  [ Need help processing your data before embedding it? ](https://www.reddit.com/r/LangChain/comments/16iv7v9/need_help_processing_your_data_before_embedding_it/) , 2023-09-16-0909
```
Hey,  


We just published a playground to help developers test out different pre-processing configurations for their da
ta. This includes loaders, selectors and splitters. It uses parts of Langchain as well as some custom loaders and splitt
ers built by Neum AI. (All open source) Feel free to try it out here: [https://neumai-playground.streamlit.app/](https:/
/neumai-playground.streamlit.app/)

If you want to see an overview, check out this video: [https://www.youtube.com/watch
?v=n3L680vmGJo&t=5s](https://www.youtube.com/watch?v=n3L680vmGJo&t=5s)  


Repo:  [NeumTry/pre-processing-playground (gi
thub.com)](https://github.com/NeumTry/pre-processing-playground)   


What else would you like to be able to do in the p
layground?   

```
---

     
 
all -  [ Using LangChain to generate ROS (Robotic Operating System) ](https://www.reddit.com/r/LangChain/comments/16iv2j1/using_langchain_to_generate_ros_robotic_operating/) , 2023-09-16-0909
```
Me and my team at RoboCoach Inc. have used LangChain and GPT3.5 to capture the details of a robotic design and to automa
tically implement all ROS (Robot Operating System) packages for the robotic project. This is the tool:

[https://github.
com/RoboCoachTechnologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

Demo: [https://www.youtube.com/w
atch?v=H2QaeelkReU](https://www.youtube.com/watch?v=H2QaeelkReU)

ROScribe is an open source project and we welcome all 
of you to use it and be part of this community. If you liked the tool, you can send us a video recording of your use-cas
e and we will put it on our github. We will credit all contributors at every release.
```
---

     
 
all -  [ Using GPT and LangChain to build robotic projects ](https://www.reddit.com/r/ChatGPT/comments/16iv0vr/using_gpt_and_langchain_to_build_robotic_projects/) , 2023-09-16-0909
```
Me and my team have used LangChain and GPT3.5 to capture the details of a robotic design and to automatically implement 
all ROS (Robot Operating System) packages for the robotic project. This is the tool:

[https://github.com/RoboCoachTechn
ologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

Demo: [https://www.youtube.com/watch?v=H2QaeelkReU
](https://www.youtube.com/watch?v=H2QaeelkReU)

ROScribe is an open source project and we welcome all of you to use it a
nd be part of this community. If you liked the tool, you can send us a video recording of your use-case and we will put 
it on our github. We will credit all contributors at every release.  
```
---

     
 
all -  [ [P] Ways to speed up llama-2 summarization on sagemaker? ](https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/) , 2023-09-16-0909
```
I'm currently working on a project to give a quick summary of long articles/conversations.

I'm running llama-2-7b-chat-
hf with 4bit quantization on a g5.2xlarge instance on sagemaker.

The method I'm using is map\_reduce (option 2)from thi
s webpage [https://python.langchain.com/docs/use\_cases/summarization](https://python.langchain.com/docs/use_cases/summa
rization))

Of everything I've tried this is the only one that's been able to do decent summaries in a reasonable amount
 of time. However with really long articles (10,000+ words) it takes \~6 minutes before giving an output.

I tried runni
ng this same thing on a g5.12xlarge instance which has 4 A10G gpus but it hasn't reduced the time by any noticeable amou
nt.

Is there anything else I could be doing to speed this up?

&#x200B;

For reference here is the code I'm running in 
Sagemaker notebook

[https://gist.github.com/phwang4/1ab4d772228b6fff8616c28ac054c229](https://gist.github.com/phwang4/1
ab4d772228b6fff8616c28ac054c229)
```
---

     
 
all -  [ Step-by-step tutorial on creating your own Notion chatbot using LangChain, OpenAI GPT, FAISS and Str ](https://www.reddit.com/r/LangChain/comments/16ite4d/stepbystep_tutorial_on_creating_your_own_notion/) , 2023-09-16-0909
```
&#x200B;

https://i.redd.it/srbnmwfd9aob1.gif

If you have ever wanted to chat directly with your own Notion data, right
 in Notion, have a look at this step-by-step tutorial on how to do it, using LangChain, OpenAI GPT, and Streamlit! 💪

It
's now live on the Streamlit: [https://blog.streamlit.io/build-your-own-notion-chatbot/](https://blog.streamlit.io/build
-your-own-notion-chatbot/)

Let me know what you think!
```
---

     
 
all -  [ Build your own Notion chatbot using Streamlit, LangChain and OpenAI ](https://www.reddit.com/r/StreamlitOfficial/comments/16itah3/build_your_own_notion_chatbot_using_streamlit/) , 2023-09-16-0909
```
&#x200B;

https://i.redd.it/3rzmszvq8aob1.gif

If you have ever wanted to chat directly with your own Notion data, right
 in Notion, follow my step-by-step tutorial on how to do it, using LangChain, OpenAI GPT, and Streamlit! 💪

It's now liv
e on the Streamlit: [https://blog.streamlit.io/build-your-own-notion-chatbot/](https://blog.streamlit.io/build-your-own-
notion-chatbot/)

Let me know what you think!
```
---

     
 
all -  [ [Hiring] ($20-40/hr) Experienced LangChain Developers ](https://www.reddit.com/r/forhire/comments/16ipz4a/hiring_2040hr_experienced_langchain_developers/) , 2023-09-16-0909
```
**NOTE:** No agencies and please answer each question below

**Preface**: I work on different AI projects using Langchai
n and could use some help. Please only apply if you have worked with Langchain. Go ahead and message me the answers to t
he below questions and Ill get back shortly.

**Questions:**

1. How much experience with Python and/or Javascript?
2. T
ell me about your experience with Langchain/GPT applications
3. Do you have experience with web application development?

4. Please provide your LinkedIn and resumeThanks!
```
---

     
 
all -  [ [Hiring] ($20-40/hr) Experienced LangChain Developers ](https://www.reddit.com/r/forhire/comments/16ipz47/hiring_2040hr_experienced_langchain_developers/) , 2023-09-16-0909
```
**NOTE:** No agencies and please answer each question below

**Preface:** I have some different AI projects using OpenAI
 and could use some help. Please only apply if you have worked with Langchain. Go ahead and message me the answers to th
e below questions and Ill get back shortly.

**Questions:**

1. How much experience with Python and/or Javascript?
2. Te
ll me about your experience with Langchain/GPT applications
3. Do you have experience with web application development?

4. Please provide your LinkedIn and resumeThanks!
```
---

     
 
all -  [ I created my first ever side project - A gpt4 based document editor that generates text and images ](https://www.reddit.com/r/nextjs/comments/16ipk1h/i_created_my_first_ever_side_project_a_gpt4_based/) , 2023-09-16-0909
```
Hi Everyone,

As someone with a fulltime job and not that great coding skills its been difficult to ever get out a worki
ng side project. I recently joined buildspace season 4 - a 6 week online building challenge - and finally managed to get
 this over the line. Only have a handful of users and not really sure if this product is super useful so would love to h
ave some feedback.

**What is it:** A very simple and easy to use AI document editor that uses GPT-4 to generate text an
d images. The text generated is based off your previous text and documents so theoritcally it should be in your own voic
e.

**The idea behind it:** I wanted to start to reimagine documents and what they can be used for. Right now my project
 is only really useful for writing related tasks, but my idea in the beginning was to always include AI agents somehow t
o make documents 'alive' and complete tasks for you while youre away. If you're interested in that kind of stuff do foll
ow my journey to continue building this on twitter ([www.twitter.com/thetansen](https://www.twitter.com/thetansen)).

**
The tech:** Its using nextJs 13 but still using the pages directory as I've built this off of Vercels Platforms template
 which you can find here ([https://vercel.com/templates/next.js/platforms-starter-kit](https://vercel.com/templates/next
.js/platforms-starter-kit)), so it became a bit of a mismatch. For calling gpt4 im using langchain to call gpt-4  and pi
necone as my vector db to hold all the document data to pass in.For the text editor I'm using editorJS.

&#x200B;

**Che
ck it out here:**  [www.typenotes.ai](https://www.typenotes.ai)
```
---

     
 
all -  [ Chat with your database ](https://www.gettingstarted.ai/tutorial-on-how-to-convert-natural-language-text-to-sql-using-langchain/) , 2023-09-16-0909
```
Hey 👋 I just published a post about converting natural language to SQL using LangChain:

I’d love to read your comments 
and feedback!

(For the pros out there, if there are technical or content improvements pls share!)
```
---

     
 
all -  [ Searching for chunking algorithms and repo ](https://www.reddit.com/r/LangChain/comments/16in3e6/searching_for_chunking_algorithms_and_repo/) , 2023-09-16-0909
```
Hi everyone! 

I'm still experiencing with my own implementation of rag, and I deployed my custom chunking function (hon
estly don't like the methods on LangChain) . 

Anyway, I'm searching for alternative methods, algoritms (NLP or not) and
 models... There are lots of info and different implementation on RAG, but as I can see noone put much effort to augment
 chunking quality. 

Also, there are other approach than this one I'm currently using? bi-encoder (instructor) - > cross
-encoder (reranking) - > LLM 


Can someone share some resources, repo, lib or existing implementation of different chun
king methods? 
(or simply discuss here some idea, though or approach) 

*Thanks in advance for you time!!*
```
---

     
 
all -  [ The rollercoaster journey behind launching the HelpKit AI Notion Chatbot ](https://www.reddit.com/r/SaaS/comments/16imj0g/the_rollercoaster_journey_behind_launching_the/) , 2023-09-16-0909
```
Hey folks!

Today I want to talk with you about the journey behind launching HelpKit AI. It wasn't a smooth sailing! 

H
elpKit is a solo founded and fully bootstrapped SaaS tool that turns your Notion docs into a professional help center an
d documentation site.

Since HelpKit is already hosting hundreds of customers Notion knowledge bases it only made sense 
to supercharge them with a custom AI trained chatbot. So far the results have been amazing.

And now, we just finally [l
aunched today on Product Hunt](https://www.producthunt.com/posts/helpkit-ai) as well! The public beta is out since two w
eeks and we have onboarded more than 15 customers on the add-on and the AI bot held 2000+ successful conversations.The l
aunch was planned two months ago but some things stopped me from releasing it.

If you are curious about the background,
 here it is. Let me explain why the journey to the launch was a bit rougher than expected. There were two big issues: Th
e UX and building on top of AI.

&#x200B;

**The UX Hurdle**

First and foremost, I was stuck with developing a great us
er experience. I have only come across a handful of products that were sort of implementing the same concept and I reall
y did not like their UX implementation. Everything felt clunky and just did not fit into the concept of an AI enabled kn
owledge base system.

You see our AI chatbot needs to be integrated into HelpKit’s two layouts: Help Center and Document
ation and also work well on the widget and mobile.Quite a tricky task to get right everywhere! I brainstormed for a few 
days, tried out some implementations but none of them felt natural for a user in my opinion.

I even spent a whole week 
building an interface only to then throw away the entire feature code branch and start from scratch.What I needed was a 
break. So I took a weekend break, spent some time at the beach and came back refreshed with some new ideas (that strange
ly all came to me during my Sunday evening shower).

I realised that the most intuitive way to present the option to cha
t with an AI powered chatbot assistant is when the user is already searching for something. So this way, should our norm
al search not be able to deliver an instant search result, users can be “catched” and still have their problem resolved 
by the AI.

In terms of the UI, I decided to go with a slick right sidebar interface for the chatbot on the help center 
layout and a nicely integrated chat window within the search command bar of the documentation layout. Within the HelpKit
 embeddable widget as well as on mobile phones, HelpKit AI will show a full-screen chatbot interface to the user.

Overa
ll, the HelpKit public beta has been running for 2 weeks and users as well as customers are really satisfied with the gr
eat user experience. Which… also obviously makes me super happy ツ

&#x200B;

**Building on top of AI**

HelpKit AI is my
 first real touchpoint developing a product with Large Language Models (LLMs). After doing some simple warm-up Hello Wor
ld AI tests, everything seemed so simple.

Unfortunately I had to soon find out that I sincerely underestimated the comp
lexity involved in developing a conversational AI chatbot that closely mirrors human interaction.

Following a considera
ble period of experimentation with a plethora of existing tools, it's become apparent that the majority merely repurpose
 around 10 lines of Langchain code, presenting it as a fully-fledged product.The outcomes of these efforts are, at their
 best are 'meh'.

Some OK, but not great.I nearly fell into the same trap, having developed a feature that was 90% compl
ete before acknowledging the subpar and cluttered results, as well as my limited comprehension of this new technology.


Engaging with LLMs presents an entirely unique and novel paradigm.Consequently, I revisited the initial plans and invest
ed a lot of more time immersing myself in the intricacies of LLMs, AI User Experience, and a slew of way too complex res
earch papers, all in an effort to better understand how to construct tools around LLMs.

Interestingly, due to the novel
ty of this field, there's no definitive roadmap to a successful implementation. The process is characterized by a great 
deal of experimentation. You really need a flexible approach and swift adaptation to the frequent and rapid enhancements
 being made to these tools. As an engineer being used to having deterministic outcomes I just couldn’t believe the quirk
iness of testing out bunch of prompts to find out what works the best.

In the end everything finally clicked and I know
 exactly what I was doing and how I can make HelpKit AI as best as possible.

&#x200B;

**Wrapping up**

So that’s my li
ttle background story of building HelpKit AI and some of the struggles that I had. The biggest takeaway lesson from me h
ere was to realize that sometimes you need to stop being so harsh on yourself and accept that some things are more diffi
cult than others. You might need a little bit more time than you thought.

The beautiful thing for us Indiehackers is th
at we don’t have any pressuring project manager sitting behind our back pressuring us to release something despite the q
uality but somehow we still tend pressure ourselves even harder into it.

Take a step back, breath, learn more and then 
come back stronger.In case you are interested you can find the [HelpKit AI landing page here](https://www.helpkit.so/hel
pkit-ai/) and I also recorded a little [Youtube video demoing HelpKit AI](https://www.youtube.com/watch?v=RhWrzh9pk-c) y
ou can check out.

&#x200B;

That's it!

&#x200B;

Hope this was useful to some of you reading this and also thinking ab
out embarking on the journey of building a big new feature for your product.
```
---

     
 
all -  [ I am unable to import csv_agents in langchain ](https://www.reddit.com/r/LangChain/comments/16im8h7/i_am_unable_to_import_csv_agents_in_langchain/) , 2023-09-16-0909
```
I am building a web application to query data from CSV files and tried importing csv langchain agent using this command,
 which was taken from langchain documentation:

'from langchain.agents import create\_csv\_agent'

However, this module 
is just not getting imported and I am getting an error whenever I use 'create\_csv\_agent' function. I am using VSCode t
o run my code by the way. Any idea why this keeps happening?
```
---

     
 
all -  [ I built an AI Agent (BondAI) that actually works and has a friendly API for easy integration into ot ](https://www.reddit.com/r/AI_Agents/comments/16il2ss/i_built_an_ai_agent_bondai_that_actually_works/) , 2023-09-16-0909
```
📢 Hello AI agent builders!

I'm thrilled to introduce you to **BondAI**, an AI Agent framework and CLI, with a lightweig
ht yet robust API making integration into your own applications straightforward and easy.

**Repository:** [**https://gi
thub.com/krohling/bondai**](https://github.com/krohling/bondai)

# ⚡️Examples

Here's an example of buying/selling Stock
s with [Alpaca Markets](https://alpaca.markets/). I strongly recommend using Paper Trading btw!

    from bondai import 
Agent
    from bondai.tools.alpaca_markets import CreateOrderTool, GetAccountTool, ListPositionsTool
    
    task = '''
I want you to sell off all of my existing positions.
    Then I want you to buy 10 shares of NVIDIA with a limit price o
f $456.'''
    
    Agent(tools=[
      CreateOrderTool(),
      GetAccountTool(),
      ListPositionsTool()
    ]).run(
task)

[**Here's an example**](https://github.com/krohling/bondai/tree/main/examples/online-research) of BondAI doing on
line research and [**here's a home automation example**](https://github.com/krohling/bondai/tree/main/examples/home-auto
mation).

# 🔍 What is BondAI?

**BondAI** is a framework crafted for the smooth integration and customization of Convers
ational AI Agents. Leveraging the power of OpenAI's [**function calling support**](https://openai.com/blog/function-call
ing-and-other-api-updates), it sidesteps the hurdles often encountered in building a Conversational Agent, offering solu
tions such as:

* Memory management
* Error handling
* Integrated semantic search
* A rich array of pre-existing tools
*
 Ease of crafting custom tools

Moreover, it offers a **CLI interface** that promises an impressive command line agent e
xperience, available to anyone with an OpenAI API Key!

# 🏗️ Why build BondAI?

I am convinced that AI agents hold the f
uture. Despite their phenomenal problem-solving abilities, the existing tooling often fell short in performing simple ta
sks, and the frameworks appeared unnecessarily complicated. This spurred the birth of **BondAI**, aiming to address thes
e shortcomings and offer a more optimized environment for agent implementations.

I am keen on hearing your feedback on 
**BondAI**'s functionality and any suggestions for improvements!

# 🛠️ Installation & Usage

Get started with BondAI wit
h a simple: pip install bondai  
The CLI tool offers a ready-to-use agent experience packed with several default tools. 
You can also integrate it with various tools such as Google Search, Alpaca Markets, and LangChain Tools to execute a myr
iad of tasks effectively. Detailed guides and examples for usage are available in the README.

# 🔧 APIs and Custom Tools


The BondAI framework offers flexible APIs to build your agent and create custom tools for a personalized experience. I
t follows a straightforward implementation approach, making the tool creation process hassle-free for developers.

Examp
les of included Tools:

* Google and Duck Duck Go Search
* Semantic Search for Files and Websites
* Alpaca Markets
* Gma
il Integration
* Easily import tools from LangChain!

# 🐋 Docker Container

For a secure environment, especially while u
sing tools with file system access, running **BondAI** within a docker container is highly recommended. Follow the steps
 in the REAME to easily build and run the **BondAI** container.

🚀 Join the mission; contribute to BondAI! And please sh
are feedback/ideas in the comments!
```
---

     
 
all -  [ Hybrid similarity scores? EG, jaccard + cosine ](https://www.reddit.com/r/datascience/comments/16ij333/hybrid_similarity_scores_eg_jaccard_cosine/) , 2023-09-16-0909
```
Hello,

I'm making my way around the langchain circuit and practicing with langsmith. I am no stranger to accuracy tests
, I don't mind harmonic mean jokes because that's exactly what an f1 is.

Is there an analogous approach to similarity s
cores? For example, jaccard doesn't capture the magnitude or direction of the vectors, while cosine doesn't consider the
 order, frequency, or the context of the words.

Can i combine these scores into a hybrid accuracy score?
```
---

     
 
all -  [ TheBloke/Llama-2-7b does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt  ](https://www.reddit.com/r/deeplearning/comments/16ihzn8/theblokellama27b_does_not_appear_to_have_a_file/) , 2023-09-16-0909
```
Hey everyone!

As you can guess from the title, this is the error I get. I only changed the model in AutoModelForCausalL
M, Older version was 

&#x200B;

&#x200B;

`'''`

`model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-c
hat-hf',`

`device_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

`'''`

&#x200B;

However, si
nce my GPU is NVIDIA GeForce RTX 2080 TI, it answers a simple question in 20 mins. Then I changed it to: 

`model = Auto
ModelForCausalLM.from_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',`

`model_file = 'llama-2-7b-chat.q4_K_M.gguf',`

`devi
ce_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

&#x200B;

However, this is not working, and 
giving the error. Below is the full code, if it is needed to solve.

&#x200B;

&#x200B;

from langchain.document\_loader
s import JSONLoader

from langchain.text\_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTe
xtSplitter

from langchain.embeddings import HuggingFaceEmbeddings

from langchain.vectorstores import Chroma

from lang
chain import HuggingFacePipeline

from langchain.chains import ConversationalRetrievalChain

from langchain.memory impor
t ConversationBufferMemory

from langchain.embeddings.openai import OpenAIEmbeddings

from langchain.embeddings.huggingf
ace import HuggingFaceEmbeddings

from langchain.chat\_models import ChatOpenAI

import os

import sys

import huggingfa
ce\_hub

from huggingface\_hub import notebook\_login

import torch

import transformers

from transformers import AutoT
okenizer, AutoModelForCausalLM, pipeline

from torch import cuda, bfloat16

import chromadb

from pathlib import Path

f
rom pprint import pprint

import json

from loader import JSONLoader

from [langchain.prompts.chat](https://langchain.pr
ompts.chat) import PromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate

import j
son

from langchain.docstore.document import Document

&#x200B;

def parse\_json(json\_data):

'''Parse JSON data into a
 Python dictionary.'''

return json.loads(json\_data)

&#x200B;

def create\_doc(json\_data):

'''Create a Document obje
ct from JSON data.'''

data = parse\_json(json\_data)

content\_value = ''

&#x200B;

\# Collect values of keys that con
tain 'item' in their name

for key, value in data.items():

if 'item' in key.lower():

content\_value += value + '\\n' 




&#x200B;

return Document(page\_content=content\_value, metadata={'company': data\['company'\]})

&#x200B;

&#x200B;


\##embed\_model\_id = 'BAAI/bge-base-en' ## CHANGE

&#x200B;

embed\_model\_id = 'sentence-transformers/all-mpnet-base-
v2'

&#x200B;

&#x200B;

&#x200B;

device = f'cuda:{cuda.current\_device()}' if cuda.is\_available() else 'cpu' ## NVIDI
A GeForce RTX 2080 TI

&#x200B;

embed\_model = HuggingFaceEmbeddings(

model\_name=embed\_model\_id,

model\_kwargs={'d
evice': device},

encode\_kwargs={'device': device, 'batch\_size': 32}

)

&#x200B;

docs = \[\]

&#x200B;

&#x200B;

fo
r file in os.listdir('lessdata'):

if file.endswith('.json'):

file\_path = './lessdata/'+file

with open(file\_path) as
 file:

json\_data = [file.read](https://file.read)()

document = create\_doc(json\_data)

docs.append(document)

&#x200
B;

&#x200B;

document\_splitter = RecursiveCharacterTextSplitter(separators=\['\\n'\], chunk\_size = 500, chunk\_overla
p = 100)

document\_chunks = document\_splitter.split\_documents(docs)

&#x200B;

&#x200B;

vectordb = Chroma.from\_docu
ments(document\_chunks,embedding=embed\_model, persist\_directory='./database')

&#x200B;

\##vectordb.persist()

'''

v
ectordb = Chroma.from\_documents(document\_chunks,embedding=embed\_model, persist\_directory='./database')

vectordb.per
sist('./database')

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;

\### PLEASE DO NOT TOUCH THE VSCODE

&#x200B;


&#x200B;

tokenizer = AutoTokenizer.from\_pretrained('meta-llama/Llama-2-7b-chat-hf', use\_auth\_token = True,)

&#x20
0B;

&#x200B;

model = AutoModelForCausalLM.from\_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',

model\_file = 'llama-2-7b
-chat.q4\_K\_M.gguf',

device\_map ='auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;


&#x200B;

&#x200B;

'''

model = AutoModelForCausalLM.from\_pretrained('meta-llama/Llama-2-7b-chat-hf',

device\_map =
'auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;


pipe = pipeline('text-generation',

model = model,

tokenizer = tokenizer,

device\_map='auto',

max\_new\_tokens = 512
,

min\_new\_tokens = 1,

top\_k = 5) ##see it 

&#x200B;

\## In vectorstore, take top 5 closest vectors-inputs-context
s, whatever you wanna call.

&#x200B;

llm = HuggingFacePipeline(pipeline=pipe, model\_kwargs= {'temperature':0.7})

&#x
200B;

memory = ConversationBufferMemory(memory\_key='chat\_history', input\_key='question', output\_key='answer', retur
n\_messages=True)

&#x200B;

system\_template = r''' 

Given a context, use your knowledge and answer the question. Be f
lexible, and try everything to answer in the format asked by query.

 \----

{context}

\----

'''

&#x200B;

&#x200B;


user\_template = 'Question:\`\`\`{question}\`\`\`'

&#x200B;

messages = \[

SystemMessagePromptTemplate.from\_template(
system\_template),

HumanMessagePromptTemplate.from\_template(user\_template)

\]

&#x200B;

&#x200B;

qa\_prompt = Chat
PromptTemplate.from\_messages(messages)

&#x200B;

&#x200B;

&#x200B;

jsonExpert = ConversationalRetrievalChain.from\_l
lm(llm = llm, 

retriever=vectordb.as\_retriever(search\_kwargs = {'k': 1}), ## whats it

verbose = True, memory = memor
y, combine\_docs\_chain\_kwargs={'prompt': qa\_prompt},

return\_source\_documents = True

)

&#x200B;

\##retriever ret
urns 1 output object.

&#x200B;

chat\_history = \[\]

query = 'Consider the financials and progress of companies who is
 in the tech business.'

result = jsonExpert({'question': query}, {'chat\_history': chat\_history})

\#result = jsonExpe
rt({'question': query})

&#x200B;

&#x200B;

sources = result\['source\_documents'\]\[0\]

print(result\['answer'\])

pp
rint(sources)

pprint(memory)
```
---

     
 
all -  [ The rollercoaster journey behind launch the HelpKit AI Notion Chatbot ](https://www.reddit.com/r/EntrepreneurRideAlong/comments/16ieqkw/the_rollercoaster_journey_behind_launch_the/) , 2023-09-16-0909
```
Hey folks!

Today I want to talk with you about the journey behind launching HelpKit AI. HelpKit is a solo founded and f
ully bootstrapped SaaS tool that turns your Notion docs into a professional help center and documentation site.

Since H
elpKit is already hosting hundreds of customers Notion knowledge bases it only made sense to supercharge them with a cus
tom AI trained chatbot. So far the results have been amazing.

And now, we just finally [launched today on Product Hunt]
(https://www.producthunt.com/posts/helpkit-ai) as well! The public beta is out since two weeks and we have onboarded mor
e than 15 customers on the add-on and the AI bot held 2000+ successful conversations.The launch was planned two months a
go but some things stopped me from releasing it.

If you are curious about the background feel free to read on.Now, let 
me explain why the journey to the launch was a bit rougher than expected. There were two big issues: The UX and building
 on top of AI.

**The UX Hurdle**

First and foremost, I was stuck with developing a great user experience. I have only 
come across a handful of products that were sort of implementing the same concept and I really did not like their UX imp
lementation. Everything felt clunky and just did not fit into the concept of an AI enabled knowledge base system.

You s
ee our AI chatbot needs to be integrated into HelpKit’s two layouts: Help Center and Documentation and also work well on
 the widget and mobile.Quite a tricky task to get right everywhere! I brainstormed for a few days, tried out some implem
entations but none of them felt natural for a user in my opinion.

I even spent a whole week building an interface only 
to then throw away the entire feature code branch and start from scratch.What I needed was a break. So I took a weekend 
break, spent some time at the beach and came back refreshed with some new ideas (that strangely all came to me during my
 Sunday evening shower).

I realised that the most intuitive way to present the option to chat with an AI powered chatbo
t assistant is when the user is already searching for something. So this way, should our normal search not be able to de
liver an instant search result, users can be “catched” and still have their problem resolved by the AI.

In terms of the
 UI, I decided to go with a slick right sidebar interface for the chatbot on the help center layout and a nicely integra
ted chat window within the search command bar of the documentation layout. Within the HelpKit embeddable widget as well 
as on mobile phones, HelpKit AI will show a full-screen chatbot interface to the user.

Overall, the HelpKit public beta
 has been running for 2 weeks and users as well as customers are really satisfied with the great user experience. Which…
 also obviously makes me super happy ツ

&#x200B;

**Building on top of AI**

HelpKit AI is my first real touchpoint deve
loping a product with Large Language Models (LLMs). After doing some simple warm-up Hello World AI tests, everything see
med so simple.

Unfortunately I had to soon find out that I sincerely underestimated the complexity involved in developi
ng a conversational AI chatbot that closely mirrors human interaction.

Following a considerable period of experimentati
on with a plethora of existing tools, it's become apparent that the majority merely repurpose around 10 lines of Langcha
in code, presenting it as a fully-fledged product.The outcomes of these efforts are, at their best are 'meh'.

Some OK, 
but not great.I nearly fell into the same trap, having developed a feature that was 90% complete before acknowledging th
e subpar and cluttered results, as well as my limited comprehension of this new technology.

Engaging with LLMs presents
 an entirely unique and novel paradigm.Consequently, I revisited the initial plans and invested a lot of more time immer
sing myself in the intricacies of LLMs, AI User Experience, and a slew of way too complex research papers, all in an eff
ort to better understand how to construct tools around LLMs.

Interestingly, due to the novelty of this field, there's n
o definitive roadmap to a successful implementation. The process is characterized by a great deal of experimentation. Yo
u really need a flexible approach and swift adaptation to the frequent and rapid enhancements being made to these tools.
 As an engineer being used to having deterministic outcomes I just couldn’t believe the quirkiness of testing out bunch 
of prompts to find out what works the best.

In the end everything finally clicked and I know exactly what I was doing a
nd how I can make HelpKit AI as best as possible.

&#x200B;

**Wrapping up**

So that’s my little background story of bu
ilding HelpKit AI and some of the struggles that I had. The biggest takeaway lesson from me here was to realize that som
etimes you need to stop being so harsh on yourself and accept that some things are more difficult than others. You might
 need a little bit more time than you thought.

The beautiful thing for us Indiehackers is that we don’t have any pressu
ring project manager sitting behind our back pressuring us to release something despite the quality but somehow we still
 tend pressure ourselves even harder into it.

Take a step back, breath, learn more and then come back stronger.In case 
you are interested you can find the [HelpKit AI landing page here](https://www.helpkit.so/helpkit-ai/) and I also record
ed a little [Youtube video demoing HelpKit AI](https://www.youtube.com/watch?v=RhWrzh9pk-c) you can check out.That's it!


Hope this was useful to some of you reading this and also thinking about embarking on the journey of building a big ne
w feature for your product.
```
---

     
 
all -  [ What are your best practices when using Embeddings, RAG, and Retrieval? ](https://www.reddit.com/r/LangChain/comments/16idhfw/what_are_your_best_practices_when_using/) , 2023-09-16-0909
```
Hi there,

Recently started building LLM applications, While talking to developers in the field, I got overwhelmed by al
l the tools and services available.

* Different embedding algorithms: For some ada-002 is SOTA, for others not
* Embedd
ing pipeline providers
* Chunking and cleaning
* Injecting up-to-date Knowledge Bases (RAG)
* Indexing
* Retrieval

(I w
ill not even start with 10s of different vector DB providers)

I'd love to collect **best practices for common pain poin
ts.** Can we create a high-quality thread with the following?

&#x200B;

1. **What is your tool stack for LLM applicatio
ns?**
2. **What problems did you experience?**
3. **How did you solve it? (if it's solved, otherwise 'looking for a solu
tion')**

&#x200B;
```
---

     
 
all -  [ How to use multiple toolkits wit agents ](https://www.reddit.com/r/LangChain/comments/16iatr5/how_to_use_multiple_toolkits_wit_agents/) , 2023-09-16-0909
```
I need to use the Vector Store Toolkit and SQL Toolkit.

Is there a method that allows me to combine both toolkits for u
se in Agent.

Any ideas?
```
---

     
 
all -  [ Loading a Sitemap ](https://www.reddit.com/r/LangChain/comments/16i7cne/loading_a_sitemap/) , 2023-09-16-0909
```
Hello everyone, I am having issues loading this particular sitemap and I cannot figure out why.  
this is it  
[https://
www.condoauthorityontario.ca/sitemap\_index.xml](https://www.condoauthorityontario.ca/sitemap_index.xml)  


nothing hap
pens when I try to load it like so   


&#x200B;

https://preview.redd.it/91lttnqu25ob1.png?width=1204&format=png&auto=w
ebp&s=06ca937519ced4628b1a706b6bf5d82a04374685
```
---

     
 
all -  [ LLMs and Data warehousing ](https://www.reddit.com/r/LangChain/comments/16i5wms/llms_and_data_warehousing/) , 2023-09-16-0909
```
I was thinking whether Large Language Models (LLMs) could replace Data Warehousing, considering that the end result of b
oth is information retrieval. What are your thoughts?
```
---

     
 
all -  [ New formatting to improve readability - how did I do?? ](https://www.reddit.com/r/resumes/comments/16i0adt/new_formatting_to_improve_readability_how_did_i_do/) , 2023-09-16-0909
```
Got some valuable feedback on here recently about poor readability, so I've made changes and would love more harsh feedb
ack!  


I also dropped by Overview section at the top since it took up a lot of room and I've heard they're unnecessary
.   


Welcome any and all comments! Thanks so much.

&#x200B;

https://preview.redd.it/ysifuqsxh3ob1.png?width=734&form
at=png&auto=webp&s=b2d9f8edbd632f440e180529f7468f139c5d24e8
```
---

     
 
all -  [ Struggling with langchain for Web Research on Safety Tech Companies ](https://www.reddit.com/r/LangChain/comments/16hzyl6/struggling_with_langchain_for_web_research_on/) , 2023-09-16-0909
```
I've been working on a project where I utilise langchain to retrieve information about safety tech companies from variou
s websites (like LinkedIn, Crunchbase, YCombinator, and Huggingface etc..).

I'm able to get some results but it feels k
inda tame and limited, I'm trying to figure out ways to:

&#x200B;

1. **Web Retrieval Scope**: expand my search to cove
r more parts of the internet for a broader and more comprehensive dataset.
2. **Result Export**: After the retrieval and
 processing, I want to be able to sort and export the results to an Excel sheet. Each row representing a company, with t
he columns containing specific information such as the company's name, CEO, description, and so on  
.

If anyone has ex
perience with this kinda thing or similar tools and can provide insights or suggestions, I'd greatly appreciate it. I'm 
keen on getting better at this and using it more frequently . 
```
---

     
 
all -  [ Improving the performance of RAG over 10m+ documents ](https://www.reddit.com/r/LangChain/comments/16hz0nr/improving_the_performance_of_rag_over_10m/) , 2023-09-16-0909
```
What has the biggest leverage to improve the performance of RAG when operating at scale?

When I was working for a Legal
Tech startup and we had to ingest millions of litigation documents into a single vector database collection, we figured 
out that you can increase the retrieval results significantly by using an open source embedding model (sentence-transfor
mers/sentence-t5-xxl) instead of OpenAI ADA.

What other techniques do you see besides swapping the model?

We are build
ing VectorFlow an open-source vector embedding pipeline and want to know what other features we should build next after 
adding open-source Sentence Transformer embedding models. Check out our Github repo: [https://github.com/dgarnitz/vector
flow](https://github.com/dgarnitz/vectorflow) to install VectorFlow locally or t*ry it out in the playground (*[https://
app.getvectorflow.com/](https://app.getvectorflow.com/)).
```
---

     
 
all -  [ Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought ](https://www.reddit.com/r/LangChain/comments/16hrq3a/finetuning_a_gpt35_react_agent_on_better_chain_of/) , 2023-09-16-0909
```
Has anyone fine-tuned gpt\_3.5 using ReACT Agent on better Chan of Thought? How was the output as compared to an non-tra
ined gpt3.5?
```
---

     
 
all -  [ Recursive character text splitter ](https://www.reddit.com/r/node/comments/16hp24q/recursive_character_text_splitter/) , 2023-09-16-0909
```
I've been using langchain in a project, but I've recently started to migrate off it. However, the [text splitters](https
://github.com/langchain-ai/langchainjs/blob/main/langchain/src/text_splitter.ts) provided were quite useful, although it
 doesn't make sense to keep this rather large dependency for that sake. Are there any alternative npm modules that provi
de the RecursiveCharacterTextSplitter?
```
---

     
 
all -  [ Langsmith alternative ](https://www.reddit.com/r/LangChain/comments/16ho366/langsmith_alternative/) , 2023-09-16-0909
```
Hey guys,

I've tried using Langsmith but found it to be quite convoluted. Do any of you know some great alternatives? W
ould be happy about any suggestions
```
---

     
 
all -  [ Advice for langchain architecture: Location reviews for {business} ](https://www.reddit.com/r/LangChain/comments/16hnasv/advice_for_langchain_architecture_location/) , 2023-09-16-0909
```
Hello, I've been working my way around the gpt tools world, and have built 5 or 6 personal projects using different aspe
cts of tools (personal custom python script, embedding, langchain agents and tools, autogpt - have not fine tuned yet as
 I have not been able to justify the use case). I run them all through streamlit. But now I am building a production ver
sion and I am still in the weeds.

&#x200B;

TLDR: What tools should I be using? What data structures for agents and dat
a should I be using? How do i store data to make it available to the LLM? I'm sorry this turned into a novel, but maybe 
it will be edifying for others.

&#x200B;

Details:

I like my pure python / bard hacky python, for what it does. I'm tr
ying to recreate it using langchain. Here's how my script works:

\- Takes business name input from user (streamlit)

\-
 reads all initial\_prompt\_x.txt - handles formatting, questions, etc. for each review subsection

\- replace placehold
er strings with inputs

\- get results from bard

\- read filter\_prompt.txt - handles fact-checking (bard is live-data,
 which is why i did all this)

\- print final result

&#x200B;

This outputs a structured review based on different cate
gories/features that is pretty good, but it's total BS. But it is kind of langchain framework already. It has some funda
mental flaws, the core problem being, even though the data ARE live, we can't expect an LLM to know which products are c
urrently available.

&#x200B;

\*\*Goal\*\*: break down my tasks using lanchain agents and tools. Not sure if I should b
e embedding or not. Here is my pseudocode:

\- Take input (as before)

\- Use templates instead of manually constructing
 prompts with python. Use micro-prompts for ea

\- Initialize agent, llm, tools (internet browse, youtubesearch, date / 
site parser). \*\*question \*\* Should I be using use other tools? like SERP?

\- Look up website, parse to obtain produ
ct availability

\- Result storage, \*\*question\*\*. How do i store this this data? A hacky version is to store it loca
lly, and then run a prompt / template to perform tasks based on those objects. That is a bad answer. Should I be embeddi
ng all these sets? It's basically a few thousand PDFs.

\- perform data-augmented task on availability

\- assemble resu
lts into final product

&#x200B;

Does this all sound right? I could add more steps, like specifically getting reviews f
rom yelp / google / foursquare, and embedding those as well, rather than just relying on internet search? 

&#x200B;

&#
x200B;
```
---

     
 
all -  [ Help needed for langchain create_pandas_dataframe_agent with Open AI function ](https://www.reddit.com/r/LangChain/comments/16hlioz/help_needed_for_langchain_create_pandas_dataframe/) , 2023-09-16-0909
```
I’m using **create_pandas_dataframe_agent** (using OpenAI Function as agent type) with a df .

But I’m not able to make 
the memory work that resides in my agent. Ultimate goal is to built a chatbot which can query database and have a memory
 of previous conversations.

For example, Issue is agent forget the context although memory is there in 'history' parame
ter of the memory. I'm using ConversationSummaryBufferMemory which keeps conversation in summary form.

> Human: What is
 the ESG score of Mastercard?

> AI: The ESG score of Mastercard is 83.

> Human: What is the L1 score of this company?


> AI: Can you specify which company you are referring? 

Please note that, previous conversations are saved in 'history
' but agent is not able to relate while asking questions. What should be my prompt? Sharing my sample code:

**Defined L
LM for Agent and for Memory**

llm_code = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k')

llm_context = ChatO
penAI(temperature=0.5, model_name='gpt-3.5-turbo-16k')

**Defined Memory**

memory = ConversationSummaryBufferMemory(llm
=llm_context, max_token_limit=10)

**Defined Agent**

openai__agent = 
        
create_pandas_dataframe_agent(
        

        llm_code,
        
        df1,
        
        prefix=prefix.format(chat_history=memory.load_memory_variables(
{})['history']),
        
        verbose=True,
        
        handle_parsing_errors=True,
        
        agent_exec
utor_kwargs={'memory': memory,
                       'handle_parsing_errors' : True},
        
        agent_type=Agent
Type.OPENAI_FUNCTIONS
)
Here is my Prompt and Prefix that is fed into the Agent with memory

prompt = ''' You are a help
ful assistant that can answer questions based on the given data(table, chat_history) and rules.You are working with a pa
ndas dataframe in Python. The name of the dataframe is df. You should use the tools below to answer the question posed o
f you:

    Rules:
    A)Only use the factual information from the available data to answer the question.
    B)If you d
on't have enough information to answer the question, say 'I don't know'.
    C)Provide answers without mentioning the sp
ecific source of the information.


   < Last few messages between you and user > :

    {chat_history}
    '''
prefix =
 PromptTemplate( input_variables=['chat_history'], template=prompt )

P.S - I want to use 'create_pandas_dataframe_agent
' with [AgentType as OpenAI.Functions.] and not as Zero Shot, since Open AI agent type is faster and better in reasoning
.
```
---

     
 
all -  [ Kendra retriever and Conversation Chain ](https://i.redd.it/7wtup8hul0ob1.jpg) , 2023-09-16-0909
```
using Amazonkendra Retriever but unable to pass to the Conversation Chain

referring to this github repo for chat_histor
u memory implementation as i am using amazon lex for chat.
[https://github.com/aws-samples/conversational-ai-llms-with-a
mazon-lex-and-sagemaker](https://github.com/aws-samples/conversational-ai-llms-with-amazon-lex-and-sagemaker)
```
---

     
 
all -  [ O fluxo de trabalho como full-stack focado á volta de OpenAI ChatGPT (Part 3) ](https://www.reddit.com/r/devpt/comments/16hkvys/o_fluxo_de_trabalho_como_fullstack_focado_á_volta/) , 2023-09-16-0909
```
Olá Devs,

Eu tenho feito uma série de posts em relação ao fluxo de AI para trabalhar como *software developer* ([part 2
](https://www.reddit.com/r/devpt/comments/13oi66l/o_fluxo_de_trabalho_como_fullstack_focado_%C3%A1_volta/)). Nestes últi
mos meses tem havido imensas mudanças no que apareceu no mercado e queria dar um update:

# Motivation:

**Automation do
esn't work -** Eu estava a tentar automatizar, mas não resulta. É demasiado (e.g langchain flow).

**Models and limitati
ons -** Os modelos dentro do IDE são limitados.

**Github Copilot:**

https://preview.redd.it/ktru973cd0ob1.png?width=17
40&format=png&auto=webp&s=41a695544881f93e5c8a0a1066c2000ffe9f57dc

Isto é o primeiro modelo do github copilot. Funciona
 bem para completar funções.

**Github Chat:**

https://preview.redd.it/hyl1qinmd0ob1.png?width=1386&format=png&auto=web
p&s=8efbeca469e139fd56f5ce9b9037816fe0cf9b9d

Funciona bem para coisas mais abrangentes mas fechadas. Não consegue ver a
 'big picture'. É um bocado '**meh**'

**GPT-4 superior reasoning skills:**

A principal razão para ter feito este novo 
fluxo é porque via me constantemente a entrar dentro do ChatGPT e resolver o problema que o copilot Chat não conseguia.


# New approach:

O que mudou isto foi mesmo a feature '**Advance Data Analysis/code interpreter**'. Essencialmente por 
trás tem um ecosistema de python para analysis, o que é optimo porque consegue concentrar muito mais contexto do que o m
odelo é suposto conseguir. Resolve também o problema de estar preso em **setembro de 2021**.

https://preview.redd.it/jb
erfe42e0ob1.png?width=2536&format=png&auto=webp&s=82dfcb5a94c187bf5167bb441a686b282afc7de2

1- **Setting the environment
.**

* Advance Data Analysis/code interpreter
* [Professor synapse](https://github.com/ProfSynapse/Synapse_CoR) \- Simul
a 'auto-gpt tasks'. Util para guiar o que fazer.

2- **Load Codebase and possible documentation.**

* Basta dar zip ao c
ódigo todo, que ele consegue extrair.
* Ir ao Github e ir buscar documentação se necessário (e.g nextjs, prisma)

3- **L
oad the task. Generate the code**

4- **Go back to IDE and refactor what is needed**. Em termos de testes continua igual
.

Obrigado,
```
---

     
 
all -  [ Has anyone tried running a Llama2/Lang Flow setup? ](https://www.reddit.com/r/LocalLLaMA/comments/16hj5od/has_anyone_tried_running_a_llama2lang_flow_setup/) , 2023-09-16-0909
```
Inspired by a post by the Floneum dev I was looking into alternatives to text generation. I found Lang Flow which is a G
UI for LangChain. As far as I can tell it is a node based system to integrate LangChain functionality in a node based sy
stem.

It seems to have Llama2 model support but I haven't been able to find much in the way of guides/tutorials on how 
to set up such a system. I come from a design background and have used a bit of ComfyUI for SD and use node based workfl
ows a lot in my design work.

Does anyone have an expertise with this workflow, any suggestions before I get stuck in? T
hanks.
```
---

     
 
MachineLearning -  [ [P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with ](https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/) , 2023-09-16-0909
```
Hey all, we just released our new project/paper and we thought you all might find it useful!

Our project (Kani) is a su
per lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in c
allable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one li
ne (the `@ai_function()` decorator) to turn any function into an AI-callable function!

Kani works with any model and ha
s built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt e
ngineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly custo
mizable.

Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. [https://colab
.research.google.com/github/zhudotexe/kani/blob/main/examples/colab\_examples.ipynb](https://colab.research.google.com/g
ithub/zhudotexe/kani/blob/main/examples/colab_examples.ipynb)  

If you're interested in learning more check out our lin
ks below!  
Paper: [https://arxiv.org/abs/2309.05542](https://arxiv.org/abs/2309.05542)  
GitHub: [https://github.com/zh
udotexe/kani](https://github.com/zhudotexe/kani)  
Docs: [https://kani.readthedocs.io/](https://kani.readthedocs.io/)
```
---

     
 
MachineLearning -  [ [D] Data Extraction using fine-tuned LLM? ](https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/) , 2023-09-16-0909
```
Hey Reddit,

I'm working on a tool to pull data from highly irregular Excel files. I've gotten reasonable results which 
is extremely fast with standard Python coding, but it's far from perfect due to the lack of standardized templates. 

In
terestingly, when I tested ChatGPT-4 on a sample table, it did a decent job at data extraction. However, relying solely 
on GPT-4 has its downsides like token limits and slow processing speed (and data privacy issues). Plus, splitting the Ex
cel sheet to fit within these limits results in loss of context and data.

I'm considering fine-tuning a language model 
to post-process data that was in a Pandas DataFrame (perhaps converted to JSON). Has anyone had success with this approa
ch or have alternative recommendations? I've tried Langchain, but it wasn't helpful.

I have figured out to extract the 
relevant columns, but the post-processing part is where I am considering using an LLM which understands the domain and w
hat needs to be extracted based on the examples I feed it.

Looking forward to your thoughts! And would be happy to answ
er any additional questions.
```
---

     
 
MachineLearning -  [ [D] Chains and Agents ](https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/) , 2023-09-16-0909
```
I think there's a lot of confusion around AI agents today and it's mainly because of lack of definition and using the wr
ong terminology.

We've been talking to many companies who are claiming they're working on agents but when you look unde
r the hood, they are really just chains.

I just listened to the Latent Space pod with Harrison Chase (Founder of Langch
ain) and I really liked how he thinks about chains vs agents.

Chains: sequence of tasks in a more rigid order, where yo
u have more control, more predictability.  
Agents: handling the edge-cases, the long-tail of things that can happen.

A
nd the most important thing is that it's not an OR question but an AND one: you can use them in the same application by 
starting with chains -> figuring our the edge-cases -> using agents to deal with them.

https://preview.redd.it/l59sc4sr
i0nb1.png?width=3127&format=png&auto=webp&s=1f3f8730c48687eaabf1f554deb181cf35b96036
```
---

     
 
MachineLearning -  [ [P] FalkorDB - a fast Graph Database - Knowledge Graph as RAG ](https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/) , 2023-09-16-0909
```
We're building a fast low latency Graph Database called FalkorDB that will also support Vector search.  
It's based on R
edis and can be used both as a stand alone database or a module for existing Redis.  
It feels like that is going to be 
the most optimized way to serve Knowledge as RAG, would love to get your feedback.  
[https://github.com/FalkorDB/falkor
db](https://github.com/FalkorDB/falkordb)  


It already supports LlamIndex and Langchain:  
[https://python.langchain.c
om/docs/use\_cases/more/graph/graph\_falkordb\_qa](https://python.langchain.com/docs/use_cases/more/graph/graph_falkordb
_qa)  
[https://gpt-index.readthedocs.io/en/latest/examples/index\_structs/knowledge\_graph/FalkorDBGraphDemo.html](http
s://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/FalkorDBGraphDemo.html)

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Is there anything LangChain can do better than using LLMs directly (either through a website or  ](https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/) , 2023-09-16-0909
```
I haven't used ChatGPT a lot or any other LLMs, I've been reading about  Langchain and its use cases, and I'm having tro
uble wrapping my head  around exactly what it does. From what I understand, its an alternative  interface for LLMs, allo
wing for easy switching between them, and makes  some work for specific use cases easier. If I wanted to write an app or
  script to interact with LLMs and do other tasks, how would LangChain be  better than just making API call(s) to an LLM
, getting back the result  as a string, and doing whatever with it?
```
---

     
 
MachineLearning -  [ Apache Airflow vs. LangChain and LlamaHub for LLM data pipeline [D] ](https://www.reddit.com/r/MachineLearning/comments/160lexg/apache_airflow_vs_langchain_and_llamahub_for_llm/) , 2023-09-16-0909
```
I’m looking for recommendations, suggestions, and/or good documentation that outlines which data pipeline would be best 
to ingest my private data (which will then be split into chunks/nodes for vector embeddings and so forth). Thank you in 
advance!
```
---

     
 
MachineLearning -  [ [P] LLM Apps Are Mostly Data Pipelines ](https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/) , 2023-09-16-0909
```
My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster
](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.

It contains a complete 
implementation

* with scraping context data from a docs website
* chunking it, getting embeddings via the openAI API
* 
loading it into pinecone
* and finally a simple Q&A interface with streamlit on top of it

**Here's a quick summary:**


* LangChain and LlamaIndex are great tools for quick exploration
* But aren't perfect for production-grade use
* I think
 we all know the 'LangChain is pointless' debate, but there's a lot of real meat to it, and Pat describes a few of them 
(a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)
* LLM applications are all about movin
g data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps
* A bunch of dat
a engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.
* Meltan
o is one such tool and Pat implemented the above described pipeline with it

**FWIW**: The GitHub project that comes wit
h the post is super easy to run and super modular. I just tested it and was able to modify everything for my own applica
tion within 30 mins.
```
---

     
 
MachineLearning -  [ [P] pgml-chat: A command-line tool for deploying low-latency knowledge-based chatbots ](https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/) , 2023-09-16-0909
```
We've created an open source chat bot builder, on top of PostgresML. This tool makes it easy to ingest documents and set
 a system prompt for a chatbot with knowledge of your content. The innovation is in the simplicity and efficiency, rathe
r than the functionality.

PostgresML runs open source embedding models alongside pgvector in Postgres to implement chat
 bot prompt creation without any network calls, which makes it \~4x faster than competing architectures. It can also do 
text generation with that prompt (and no additional network hops) using any open source model from HuggingFace, but it a
lso integrates with the GPT-4 API if you'd like to use that instead. 

The full writeup including some benchmarks for co
mpeting architectures is here:  [https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-kno
wledge-based-chatbots-part-I](https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-knowle
dge-based-chatbots-part-I)

You can chat with a deployment that has access to our blogs and documentation content it in 
\[our Discord\]([https://discord.com/channels/1013868243036930099/1013868243536072868](https://discord.com/channels/1013
868243036930099/1013868243536072868)), where it answers questions addressed to @PgBot.

&#x200B;

* The source code for 
the bot builder and server is only a few hundred lines of Python [https://github.com/postgresml/postgresml/tree/master/p
gml-apps/pgml-chat#readme](https://github.com/postgresml/postgresml/tree/master/pgml-apps/pgml-chat#readme)
* The chat a
pp is so small, because it's delegates all the vector db and embedding generation options to our Python client SDK, whic
h is available for anyone to build other apps with: [https://pypi.org/project/pgml/](https://pypi.org/project/pgml/)
* T
he Python client SDK is so small, because it's just a wrapper around the Rust client SDK: [https://github.com/postgresml
/postgresml/tree/master/pgml-sdks/rust/pgml](https://github.com/postgresml/postgresml/tree/master/pgml-sdks/rust/pgml). 
Currently we also support JS/Typescript SDKs as well, all generated from the same safe and efficient underlying Rust imp
lementation, using some fancy Rust macros.
* The Rust client SDK is also pretty simple though, because it just delegates
 everything to the Postgres database extension, which is where everything is computed in a single GPU accelerated proces
s, without having to load any ML models, data, or dependencies on client apps, effectively eliminating all the typical M
L data<->model network hops. Which makes it faster, simpler and safer.

This lays out what we think a is a better approa
ch to AI application architecture compared to libraries like LangChain or LlamaIndex, that focus on glueing together dis
parate data stores, algorithms, models over the network.  

```
---

     
 
deeplearning -  [ How to find 'custom' datasets for LLM ](https://www.reddit.com/r/deeplearning/comments/16bj3hg/how_to_find_custom_datasets_for_llm/) , 2023-09-16-0909
```
Hey folks,

I've been digging everywhere, including here, for LLMs and custom applications. So, I read many things, lear
ned from ppl here. Its time to try something. I will try implement Llama v2 - Langchain - Chroma combination. But also I
 want to upload a dataset so that I can try my model on that. 

I find some datasets big enough (for now, 2-5 gb is ok) 
however they are table-style. I want something more texty, I mean I could use 'American Stories' or 'Arxiv' however I be
lieve that they are already used by Llama to train. 

&#x200B;

Is there any suggestions or sources that you can provide
 ? Thanks!
```
---

     
