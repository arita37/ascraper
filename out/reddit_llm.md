 
all -  [ [P] Rust meets Llama2: OpenAI compatible API written in Rust ](https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/) , 2023-08-07-0926
```
Hello,

I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports
 offloading computation to  Nvidia GPU and Metal acceleration for GGML models !

Here is the project  link: [Cria- Local
 LLAMA2 API](https://github.com/AmineDiro/cria)

You can use it as an OpenAI replacement (check out the included \`Langc
hain\` example in the project).

This is an ongoing project, I have implemented the \`embeddings\` and \`completions\` r
outes. The \`chat-completion\` route will be here very soon!

Really interested in your feedback and I would welcome any
 help :) !

&#x200B;

&#x200B;
```
---

     
 
all -  [ Rust meets Llama2: OpenAI compatible API written in Rust ](https://www.reddit.com/r/rust/comments/15k1w99/rust_meets_llama2_openai_compatible_api_written/) , 2023-08-07-0926
```
Hello,

I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports
 offloading computation to  Nvidia GPU and Metal acceleration for GGML models thanks to the fantastic \`llm\` crate!

He
re is the project  link : [Cria- Local LLAMA2 API](https://github.com/AmineDiro/cria)

You can use it as an OpenAI repla
cement (check out the included \`Langchain\` example in the project).

This is an ongoing project, I have implemented th
e \`embeddings\` and \`completions\` routes. The \`chat-completion\` route will be here very soon!

Really interested in
 your feedback as I am still a beginner in Rust and I would welcome any help :) !

&#x200B;

&#x200B;
```
---

     
 
all -  [ Local Llama-2 API in Rust ](https://www.reddit.com/r/LocalLLaMA/comments/15k1uk7/local_llama2_api_in_rust/) , 2023-08-07-0926
```
Hello, 

I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It support
s offloading computation to  Nvidia GPU and Metal acceleration for GGML models.

Here is the project link :
[Cria - Loca
l LLama2 OpenAI compatible API](https://github.com/AmineDiro/cria)

You can use it as an OpenAI replacement (check out t
he included \`Langchain\` example in the project).

This is an ongoing project, I have implemented the \`embeddings\` an
d \`completions\` routes. The \`chat-completion\` route will be here very soon!  

Really interested in your feedback an
d I would welcome any help :) !
```
---

     
 
all -  [ Project using PALM API and Langchain ](https://www.reddit.com/r/LangChain/comments/15jvyhb/project_using_palm_api_and_langchain/) , 2023-08-07-0926
```
The day before I got access to Palm API(through waitlist of Palm API and Makersuite not from GCP or vertex ai). I wanted
 to make a project out of it. I want to use Pinecone as a vector store and Streamlit as a UI. Any new, creative projects
 that I can add to my resume?
```
---

     
 
all -  [ The largest collation of AI news on the internet - Meta, OpenAI, Google, Research Papers and News/To ](https://www.reddit.com/r/ChatGPT/comments/15jsrrz/the_largest_collation_of_ai_news_on_the_internet/) , 2023-08-07-0926
```
Hey folks!

It's been a while since I posted, I used to write the 'GPT-4 Week X' posts a few months ago. I've been seein
g people say nothings been happening in AI so I had to come back and share some of the info I've collated and shared in 
my [newsletter](https://nofil.beehiiv.com/subscribe).

Enjoy

## Meta

* Meta released an open source project, “Massivel
y Multilingual Speech” which can identify 4000 different languages. Can be expanded to text-to-speech can be used in VR 
& AR \[[Link](https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/)\]
* Meta’s announced **I-J
EPA -** an AI model that learns by creating an internal model of the outside world. The idea is for it to be able to use
 background knowledge to identify things in images or rather than analysing individual pixels (to my understanding). The
y’re also open sourcing their training code and model checkpoints \[[Link](https://ai.facebook.com/blog/yann-lecun-ai-mo
del-i-jepa/)\]
* Zuck said that Meta is using LLama in house \[[Link](https://twitter.com/altryne/status/166694906797556
1218?s=20)\]
* Meta released MusicGen, a music generation model. Try it on HF here \[[Link](https://huggingface.co/space
s/facebook/MusicGen)\]. This repo contains the code for it \[[Link](https://github.com/facebookresearch/audiocraft)\]. Y
ou can use their highest quality model to generate \~15 minutes of music in \~15minutes. Set the runtime GPU to A100 on 
this collab notebook \[[Link](https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing)\]
*
 Meta’s going all in on open-source \[[Link](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-
off-its-open-source-ai-in-challenge-to-google)\]
* Meta announced their own chips specifically for running AI programs. 
They also mentioned their working on creating their own data centres specifically for AI \[[Link](https://www.gizmochina
.com/2023/05/19/meta-ai-chip-metaverse/?utm_source=nofil.beehiiv.com&utm_medium=newsletter&utm_campaign=openai-betrays-t
he-people)\]
* Apparently Instagram is going to launch a twitter competitor soon \[[Link](https://twitter.com/TitterDail
y/status/1659612900091215874?s=20&utm_source=nofil.beehiiv.com&utm_medium=newsletter&utm_campaign=openai-betrays-the-peo
ple)\]

## OpenAI

* Sam Altman spoke to congress, pleaded for regulation \[[Link](https://fortune.com/2023/05/16/sam-al
tman-artificial-intelligence-regulation-congress-testimony-chatgpt-ibm/)\]
* Released an article titled “Governance of S
uperIntelligence” - details how we’ll handle systems even more capable than AGI. “it’s conceivable that within the next 
ten years, AI systems will exceed expert skill level in most domains” \[[Link](https://t.co/lYGla0lM0T)\]
* OpenAI has r
eleased a security portal containing info on different security protections \[[Link](https://trust.openai.com/)\]
* Sam 
Altman did an interview and then had it deleted because it had too much “alpha”. Here’s a link to wayback machine \[[Lin
k](https://web.archive.org/web/20230531203946/https://humanloop.com/blog/openai-plans)\]
* Announced function calling \[
[Link](https://openai.com/blog/function-calling-and-other-api-updates)\]
* In India, Sam Altman was asked if a startup i
n India could build a foundation model like ChatGPT and he straight up said “nah its hopeless”. It will be so interestin
g to see if OpenAI remains a leader in the space over the next decade as more money is poured into AI and more companies
 join the competition \[[Link](https://twitter.com/ETNOWlive/status/1666460799093620738)\]

## Google

* Googles Med-Pal
m 2 scored 86.5% on the medical exam MedQA. A panel of 15 doctors also preferred its answers over real doctors answers a
cross 1066 standardised questions. Link to paper \[[Link](https://arxiv.org/pdf/2305.09617.pdf)\]
* Announced they’ll us
e AI to dynamically generate ads \[[Link](https://twitter.com/nonmayorpete/status/1661064671200428032?s=20)\]
* Google i
s also doing product photography using AI \[[Link](https://blog.google/products/shopping/google-product-studio-generativ
e-ai-product-photos/)\]
* Project Starline creates a 3D representation of you so virtual things feel more real \[[Link](
https://blog.google/technology/research/project-starline/)\]
* Google is using AI to forecast floods \[[Link](https://ww
w.axios.com/2023/05/22/googles-ai-flood-forecast)\]
* Google announced AlphaDev, a system to enhance comp-sci algorithms
 \[[Link](https://twitter.com/DeepMind/status/1666462540367372291)\]. A critique of what they announced and the claims t
hey made is worth a read \[[Link](https://news.ycombinator.com/item?id=36231147)\]. Apparently the new sequence of assem
bly only had one less MOV command. Extremely exaggerated claims from Google
* Google has released their platform Vertex 
to all. You can use PaLM 2 for word completion, Codey for code completion and others. There are over 60 models, many of 
which are already being used by companies \[[Link](https://cloud.google.com/blog/products/ai-machine-learning/generative
-ai-support-on-vertexai)\]. Link to model garden \[[Link](https://cloud.google.com/model-garden)\]
* Google announced an
 AI accelerator \[[Link](https://startup.google.com/accelerator/ai-first/europe/)\]
* Couldn’t release Bard in Ireland b
ecause of privacy concerns. Ireland doesn’t mess around \[[Link](https://www-politico-eu.cdn.ampproject.org/c/s/www.poli
tico.eu/article/google-postpone-bard-chatbot-eu-launch-privacy-concern/amp/)\]
* You can use Google lens to look up skin
 conditions. Take a pic of your skin and it’ll try and match the issue with a condition. This will eventually become per
fect and anyone can diagnose anything with their phone \[[Link](https://www.forbes.com/sites/saibala/2023/06/16/you-can-
now-use-google-lens-on-your-phone-to-look-up-skin-conditions/amp/)\]

## Research

* Researchers used thought decoders t
o connect a paralysed mans spinal and brain implants to help him walk again \[[Link](https://www.nytimes.com/2023/05/24/
science/paralysis-brain-implants-ai.html)\]. “We’ve captured the thoughts of Gert-Jan, and translated these thoughts int
o a stimulation of the spinal cord to re-establish voluntary movement”. Not LLM based though.
* Researchers are using AI
 to try and find rare DNA sequences \[[Link](https://phys.org/news/2023-05-artificial-intelligence-catalyzes-gene-uncove
rs.html)\]
* CoDi, Any-to-Any generation. Generate any type of output from any combination of inputs \[[Link](https://t.
co/Tj3X8UvjlQ)\] Video demo \[[Link](https://twitter.com/_akhaliq/status/1660455475522174976)\]
* In an experiment to fi
nd an antibiotic for a certain bacteria, scientists used ML/AI to find a suitable antibiotic that was able to control in
fections. It worked well in mouse wounds \[[Link](https://www.nature.com/articles/s41589-023-01349-8)\]
* This paper exp
lores methods to make people spend more time engaging with chatbots. The results showed conversations lasted 70% longer 
and 30% of people kept using the chatbots \[[Link](https://arxiv.org/abs/2303.06135)\]
* Styledrop - text to image gen i
n any style \[[Link](https://styledrop.github.io/)\]
* AI agents can learn to “think” while acting \[[Link](https://t.co
/w8xc94nruw)\]
* Cambridge researchers showcased an AI powered robot that watches cooking videos and replicates them \[[
Link](https://www.cam.ac.uk/research/news/robot-chef-learns-to-recreate-recipes-from-watching-food-videos)\]
* Otter, a 
multimodal model can answer a number of questions in real world scenarios, looks really cool. Link to demo vids \[[Link]
(https://twitter.com/JingkangY/status/1667087758840709120)\]. Link to code \[[Link](https://github.com/Luodian/Otter)\].
 Link to paper \[[Link](https://arxiv.org/abs/2306.05425)\]
* ChatGPT outperforms humans in emotional awareness evaluati
ons \[[link](https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1199058/full)\]
* FinGPT - an open source LLM for f
inance. Link to paper \[[Link](https://arxiv.org/abs/2306.06031)\]. Link to code \[[Link](https://github.com/AI4Finance-
Foundation/FinGPT)\]
* Given a video, re render it with a prompt without the flickering and noise \[[Link](https://anony
mous-31415926.github.io/)\]
* This paper suggested that GPT-4 can score 100% on MIT’s EECS curriculum, but its absolute 
bs. Lots of controversy behind this but they basically lied about it all and published an entire paper on it \[[Link](ht
tps://twitter.com/sauhaarda/status/1670053720233750530?s=20)\] \[[Link](https://twitter.com/sauhaarda/status/16702255130
07439872?s=20)\]
* Vid2Avatar - reconstruct detailed 3d videos \[[Link](https://twitter.com/ChenGuo96/status/16707818523
93566213?s=20)\]
* Only some models can self improve like GPT-4. There’s some sort of thereshold (?) that a model needs 
to pass for it to understand natural language feedback used for improvement. Better understanding this should significan
tly improve LLM development and quality \[[Link](https://t.co/CJE9lPdNLn)\]
* Chemcrow, AI + Chemistry - giving gpt-4 to
ols, it planned and executed the synthesis of an insect repellant, 3 organocatalysts, and guided the discovery of a nove
l chromophore. Link to paper \[[Link](https://arxiv.org/abs/2304.05376)\]. Link to repo \[[Link](https://github.com/ur-w
hitelab/chemcrow-public)\]
* A way to teach a robot a new task in \~25mins using only a reference video \[[Link](https:/
/robo-affordances.github.io/)\]
* “Textbooks are all you need” new LLM ph-1 - a very, very interesting paper on how prep
aring a dataset appropriately can yield such incredible results. They used gpt3 & gpt4 to help classify and prepare the 
data. This thread has a great breakdown \[[Link](https://twitter.com/8teAPi/status/1671519543003422721?s=20)\]. Link to 
the paper \[[Link](https://arxiv.org/abs/2306.11644)\]
* This paper suggests a “backspace” token in LLMs helping them st
ay on the rails. What this really shows tbh is that we’re still so early in understanding LLMs and how to better use the
m \[[Link](https://arxiv.org/abs/2306.05426)\] Authors thread on it \[[Link](https://twitter.com/ChrisCundy/status/16715
54838843518978)\]
* This paper discusses how we can use language to make machines think and be more like humans. An inte
resting approach and interesting to see how we can leverage language when dealing with LLMs \[[Link](https://arxiv.org/a
bs/2306.12672)\]
* Data-to-paper, autonomous AI research. This paper was written by handing over CDC data to an agent an
d it chose several research topics, wrote data analysis code, interpreted results and wrote papers. Not sure if this is 
a good idea… \[[Link](https://twitter.com/RoyKishony/status/1672280665264386049)\]
* DarkBERT - an LLM trained on the da
rk web to help deal with cybersecurity and understand how the dark web works \[[Link](https://arxiv.org/abs/2305.08596)\
]
* Google DeepMind’s RoboCat is an AI powered robot that can solve tasks from with less than 100 demonstrations and use
 self-generated data to improve \[[Link](https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent)\]

## Oth
er

* NVIDIA briefly hit $1 trillion market cap and is now one of the biggest companies in the world. Share price has su
rged over 20% in weeks \[[Link](https://www.nbcnews.com/tech/tech-news/chipmaker-nvidia-hits-1-trillion-market-capitaliz
ation-rcna86793)\]
* Cnet workers unionise, citing AI \[[Link](https://www.theverge.com/2023/5/16/23723959/cnet-union-re
d-ventures-tech-editorial-independence-ai-writing)\]
* AMD announced their new AI chip..finally \[[Link](https://www.zdn
et.com/google-amp/article/amd-unveils-mi300x-ai-chip-as-generative-ai-accelerator/)\]. They also joined the HuggingFace 
partner program
* Anthropic raised 450M at a $4.1 Billion valuation \[[Link](https://www.bloomberg.com/news/articles/202
3-05-23/ai-startup-anthropic-raises-450-million-for-safety-focused-chatbot#xj4y7vzkg)\]
* Neeva, a search engine focusin
g on privacy and using AI has shutdown their search \[[Link](https://twitter.com/RamaswmySridhar/status/1659980249734713
344?s=20)\]
* Skybox - Take a crappy drawing and turn it into a full world made by AI \[[Link](https://twitter.com/Block
adeLabs/status/1659963443754008577?s=20)\]
* Scale Donovan - AI powered decision making for US defence \[[Link](https://
scale.com/donovan)\]
* XrayGPT - a tool to analyse chest radiographs. Link to tool \[[Link](https://d243b1f5fd02df3237.g
radio.live/)\] Link to code \[[Link](https://github.com/mbzuai-oryx/XrayGPT)\]
* This lad built an app to generate real 
time responses for job interviews. Link to code \[[Link](https://github.com/SevaSk/ecoute)\]
* This tool optimises your 
prompts to save you tokens \[[Link](https://github.com/vaibkumr/prompt-optimizer)\]
* Spacetop - AR glasses that lets yo
u have dozens of laptop screens in front of you. If it wasn’t restricted to the US I’d buy this just to try it out \[[Li
nk](https://sightful.com/)\]
* Artists are asking for 3 things - permission, credit & compassion \[[Link](https://twitte
r.com/stealcase/status/1659577594436628480?s=20)\]
* In 2022, Yann LeCun gave an analogy for how dumb gpt was and that i
t could basically never understand physics properly. Obviously he was unbelievably wrong. Notably he is now the most pro
minent voice saying not to be worried about AI and all the doomer takes \[[Link](https://twitter.com/liron/status/165961
8568282185728?s=20)\]
* Unreal Engine 5.2 came out and its so good it can create muscle, cloth and flesh simulations \[[
Link](https://www.unrealengine.com/en-US/blog/unreal-engine-5-2-is-now-available)\]
* Live AI job interview assistant \[
[Link](https://twitter.com/AiBreakfast/status/1660083019796062208?s=20)\]
* LLM powered games with GPT4All \[[Link](http
s://twitter.com/andriy_mulyar/status/1660036659193184258?s=20)\]
* If you insert an electric probe into an insect *befor
e* adulthood, its tissues can organically grow around the probe and create an insect-machine interface. We can then poss
ibly control its flight by stimulation. This is from 2009. With the tech we have now we can definitely make this a reali
ty and even view flight based on what they see. This will probably be the precursor to human brain implants. Link to pap
er \[[Link](https://t.co/R0rMoqwBkb)\]
* Reconstructing video from fMRI data \[[Link](https://mind-video.com/)\]
* Naval
 is working on something called airchat - a new social platform that uses AI \[[Link](https://twitter.com/naval/status/1
660405285943668736?s=20)\]
* AMP Robotics raised 8 million to help fund their AI powered garbage sorting robot that can 
help with recycling \[[Link](https://techcrunch.com/2023/05/11/amp-robotics-attracts-investment-from-microsofts-climate-
innovation-fund/)\]
* This chart shows just how far away search engines and chatgpt is from Google. Hint: Unbelievably f
ar \[[Link](https://twitter.com/vladquant/status/1660313957796810753?s=20)\]
* Generate high fidelity human avatars from
 text \[[Link](https://t.co/xZPJmWgXUn)\]. Demo video here \[[Link](https://twitter.com/_akhaliq/status/1660457301168521
217?s=20)\]
* Google unveiled a new audio model called SoundStorm \[[Link](https://google-research.github.io/seanet/soun
dstorm/examples/)\]
* An ethical hacker on 60 minutes shows just how easy it is to scam someone these days using spoofin
g and AI voice cloning \[[Link](https://twitter.com/60Minutes/status/1660428419438354435)\]
* Added Firefly into Express
 app so you can use AI to design posters, videos, flyers etc \[[Link](https://www.adobe.com/express/)\]
* ChatShitGPT is
 the greatest thing to be built with AI ever \[[Link](https://www.chatshitgpt.co.uk/)\]
* Intel announced Aurora genAI w
ith 1 trillion parameters \[[Link](https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1
-trillion-parameters/)\]
* Use DragGan locally \[[Link](https://github.com/OpenGVLab/InternGPT)\]
* Opera announced an A
I in their browser called Aria \[[Link](https://twitter.com/opera/status/1661281811668901888?s=20)\]
* Someone attended 
a Hinton talk at Cambridge and it seems he is extremely out of touch with reality \[[Link](https://twitter.com/mayameme/
status/1661864975776792583?s=20)\]
* Ezra - the worlds first 30 minute full body MRI powered by AI has received FDA clea
rance. You can sign up for the waitlist here \[[Link](https://ezra.com/pricing)\]
* Blockade labs - generate 3D worlds f
or game dev with text \[[Link](https://www.blockadelabs.com/)\] \[[Link](https://twitter.com/theCGchannel/status/1673622
861414649856?s=20)\]
* China’s Baidu launched an AI venture fund of $145M. They’re also releasing a new version of Ernie
Bot \[[Link](https://techcrunch.com/2023/06/01/baidu-generative-ai-fund-china/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3
cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAGIqJwJ8_xgx3juVUzN4lRySlxzobdKj4ccL2Tb8cidibeXtk7sWqZUDzgH_XNnm0fOayA5y1cPfwUeb
Kz_Xn4Bdg57cI173KtCjEkr0ABn_H1q2D1NF4YvLZ6nSMVDwDkopuKjyOSYEzn0pT_alJG-3c69nZiPqYGC143YUuTqx)\]
* Asana announced Asana 
Intelligence \[[Link](https://asana.com/product/ai)\]
* Voyager Minecraft AI is an open source experiment of getting an 
AI agent to continually play minecraft and get better. It writes code to play minecraft and just keeps getting better. A
n incredible application and illustration of AI agents \[[Link](https://twitter.com/DrJimFan/status/1662115266933972993)
\]
* Make an image 3D instantly \[[Link](https://twitter.com/instorier/status/1661738501594021889)\]
* Neuralink has got
ten FDA approval for first human trials \[[Link](https://www.reuters.com/science/elon-musks-neuralink-gets-us-fda-approv
al-human-clinical-study-brain-implants-2023-05-25/)\]
* Japan has said they don’t care about copyright in training AI mo
dels. Big win if you’re an AI company there \[[Link](https://analyticsindiamag.com/japan-sets-the-precedent-for-ai-copyr
ight/)\]
* Andrew Ng has released 3 short courses on AI. Building systems with chatgpt api \[[Link](https://t.co/TxTyEHO
dai)\]. Langchain for LLM app dev \[[Link](https://t.co/XuKPvdFMYd)\]. How diffusion models work \[[Link](https://t.co/b
j5M7y9V68)\]
* Hugging Chat added a web search feature \[[Link](https://huggingface.co/chat/)\]
* Falcon 40B is an open 
source model from Dubai that’s really good. Link to what it is \[[Link](https://huggingface.co/blog/falcon)\]. Use it on
 HF here \[[Link](https://huggingface.co/spaces/HuggingFaceH4/falcon-chat)\]
* SuperAGI is an open source framework to b
uild and manage AI agents \[[Link](https://github.com/TransformerOptimus/SuperAGI)\]
* AI being used in corporate bond t
rading \[[Link](https://www.prnewswire.com/news-releases/ltx-by-broadridge-launches-bondgptsm-powered-by-openai-gpt-4-30
1843197.html)\]
* Text to 3d characters in minutes \[[Link](https://maketafi.com/ai)\]
* LTM-1: LLM with 5,000,000 promp
t tokens \[[Link](https://twitter.com/magicailabs/status/1666116935904292869?s=20)\]. Main use case is in programming. S
ign up for the waitlist here \[[Link](https://magic.dev/waitlist)\]
* Zoom announced AI features for select plans. Will 
probably affect lots of new startups \[[Link](https://news.zoom.us/zoom-iq-meeting-summary-chat-compose-free-trial/)\]
*
 The first AI ETF has grown to over $35M \[[Link](https://www.nasdaq.com/articles/introducing-chat-the-worlds-first-gene
rative-ai-etf)\]
* AI finally being used in the doctors office \[[Link](https://www.bloomberg.com/news/articles/2023-06-
05/technology-behind-chatgpt-has-arrived-in-the-doctor-s-office#xj4y7vzkg)\]
* Open source text to video model called Po
tat \[[Link](https://github.com/camenduru/text-to-video-synthesis-colab)\]
* Runway’s Gen2 is available on mobile and we
b
* A city in Japan, Yokosuka, has officially adopted ChatGPT in their admin ops after a one month trial \[[Link](https:
//www.japantimes.co.jp/news/2023/06/06/national/yokosuka-adopts-chatgpt/)\]
* MotionScribe - create promo videos from te
xt quickly \[[Link](https://t.co/CjlmexbqX4)\]
* Granica - an AI efficiency platform came out of stealth recently, havin
g already raised $45M from NEA and Bain \[[Link](https://www.granica.ai/blog/introducing-granica-the-ai-efficiency-platf
orm/)\]
* Someone built an open source program that generates audio based on movement?? Like an AI powered instrument.. 
Seems interesting. Link to demo \[[Link](https://twitter.com/heyBarsee/status/1666808794679222275?s=20)\]. Link to code 
\[[Link](https://github.com/caillonantoine/msprior)\]
* Cohere raised a $270M Series C \[[Link](https://txt.cohere.com/a
nnouncement/)\]
* Part of SD, Clipdrop released Uncrop, easily change the ratio of any image by creating a background. T
ry it here \[[Link](https://clipdrop.co/uncrop)\]
* Perplexity adds profiles which personalises answers based on your bi
o, location etc \[[Link](https://twitter.com/perplexity_ai/status/1667247174999068672?s=20)\]
* Human or Not was a fun g
ame where you would talk to someone and would have to guess if it was a person or AI. It turned out to be one of the big
gest turing tests and showed only about 60% of people could accurately predict they were talking to an AI \[Link\]
* Wor
dpress announced Jetpack AI Assistant - an AI text based assistant in Wordpress \[[Link](https://jetpack.com/ai/)\]
* Re
plit is one of the more exciting companies to look out for in the AI space. They released an AI manifesto \[[Link](https
://blog.replit.com/replit-ai-manifesto)\]
* Beijing Academy of AI (BAAI) released Aquila - an open source Chinese/Englis
h 7B & 33B models \[[Link](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md)\]
* Hilarious st
ory of someone that built an AI agent to find tax avoidance schemes. It finds them and then completely on its own, snitc
hes on him \[[Link](https://twitter.com/DanNeidle/status/1664613427472375808)\]
* Hundreds attended an AI powered church
 service with more than 300 people attending \[[Link](https://www.thejournal.ie/ai-chruch-germany-6090108-Jun2023/)\]
* 
Turn your babies ultrasound into a photorealistic image \[[Link](https://photorealisticultrasound.com/)\]
* DeepMing, Op
enAI & Anthropic have agreed to open up their models to the UK gov \[[Link](https://www.politico.eu/article/openai-deepm
ind-will-open-up-models-to-uk-government/)\]
* Doctors are using ChatGPT to talk to patients in a better way \[[Link](ht
tps://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html?smid=nytcore-ios-share&referringSou
rce=articleShare)\]
* Salesforce announces a whole bunch of AI integrations in CRM, data, tableau, slack and more. Good 
thread breaking it down, can’t be bothered finding an article \[[Link](https://twitter.com/minchoi/status/16683980262708
63366)\]
* There was a Virtual Worlds hackathon and the winners created a fully playable RPG in a single day using Anthr
opics 100k context window for Claude. His thread on how they did it \[[Link](https://twitter.com/jradoff/status/16683130
53094346755)\]
* Segment what you see in real time with AR. Wild stuff this is \[[Link](https://twitter.com/localghost/s
tatus/1668347694975434752?s=20)\]
* Ilya Sutskever, co-founder of OpenAI, talks about a potential way to determine if an
 AI has become conscious \[[Link](https://twitter.com/thealexker/status/1668390891705311232?s=20)\]
* Hyper, a company c
reating a vtuber, avatar platform raised $3.6M
* Lawyers used ChatGPT and it cited made up claims \[[Link](https://www.c
nbc.com/2023/05/30/chatgpt-cited-bogus-cases-for-a-new-york-federal-court-filing.html)\]
* Build conversational AI chara
cters \[[Link](https://charisma.ai/)\]
* A 2 sentence jailbreak of ChatGPT \[[Link](https://guzey.com/ai/two-sentence-un
iversal-jailbreak/)\]
* AI brings John Lennons voice back. Paul McCartney announced they’d be releasing one final Beatle
s record \[[Link](https://www.bbc.com/news/entertainment-arts-65881813.amp)\]
* If you want to know the security issues 
with chatgpt plugins, read this \[[Link](https://www.tomshardware.com/news/chatgpt-plugins-prompt-injection)\]
* Synthes
ia, an AI video generator got $90M in funding \[[Link](https://siliconangle.com/2023/06/13/ai-video-creation-startup-syn
thesia-reels-90m-investors/)\]
* Vercel announced an AI accelerator. 6 weeks, $850k in credits \[[Link](https://vercel.c
om/ai-accelerator)\]
* Flexible brain implants tested in people for the first time. They slide between the skull and bra
in and are very safe making them an attractive choice. Founded by former neuralink exec. Very exciting space \[[Link](ht
tps://www.freethink.com/health/precision-brain-implants)\]
* Using AI, scientists find a drug that could combat drug-res
istant infections \[[Link](https://news.mit.edu/2023/using-ai-scientists-combat-drug-resistant-infections-0525)\]
* APA 
releases guide on how to cite chatgpt \[[Link](https://apastyle.apa.org/blog/how-to-cite-chatgpt)\]
* Chatgpt grandma ja
ilbreak is hilarious and gives windows 10 keys. No longer works :( \[[Link](https://twitter.com/koush/status/16690640164
49388544?s=20)\]
* Generate amazing looking QR codes using AI. Try it on HF \[[Link](https://t.co/wq8nzx6Fhs)\]
* GPT-4 
can now use tools natively, meaning you can build useful agents really quickly. This is a good read on the topic \[[Link
](https://every.to/chain-of-thought/gpt-4-can-use-tools-now-that-s-a-big-deal)\]
* Alexandria: Project Tenet - a project
 aiming to embed all of human belief. They’ve open sourced the embeddings for 10+ major religious texts with over 15 mil
lion tokens. These types of projects are going to be very interesting. Preservation, imo, is one of the biggest uses cas
es of AI \[[Link](https://twitter.com/willdepue/status/1670099641218764804?s=20)\]

If you want to see week by week brea
kdowns like this, for a coffee a month I'll send it to your email. Check it out [here](https://nofil.beehiiv.com/upgrade
)

Since I started creating these posts, I've been consulting and helping some fairly large businesses understand how th
ey can use AI and implement it in their processes. If you're interested in having a chat, fill the form on my [website](
https://time-and-money.webflow.io/) or email me [contact@timeandmoney.ai](mailto:contact@timeandmoney.ai)
```
---

     
 
all -  [ Do you know any good github repo for docs chat? ](https://www.reddit.com/r/LangChain/comments/15jsl4v/do_you_know_any_good_github_repo_for_docs_chat/) , 2023-08-07-0926
```
I am trying to find an opensource project in github that can actually chat with docs.
I have tried a couple of them but 
they halucinate, specially with the links that are within the docs.
Have you also tried any ?
```
---

     
 
all -  [ How LangChain AutoGPT Responds to the Inquiry 'Provide a weather update for San Francisco today.' ](https://i.redd.it/r7mvz19s8igb1.png) , 2023-08-07-0926
```

```
---

     
 
all -  [ Best Chunking Practice for mixed Documents with images, tables, and text ](https://www.reddit.com/r/LangChain/comments/15jo7t2/best_chunking_practice_for_mixed_documents_with/) , 2023-08-07-0926
```
Is there a best practice for chunking mixed documents that also include tables and images? 
First, Do you extract tables
/images (out of the document) and  into a separate CSV/other file, and then providing some kind of ‘See Table X in File’
  link within the chunk (preprocessing before chunking documents)?
If so, how do you write the syntax for this note (wit
hin the chunk) to the LLM, so the langchain will know when to use the Pandas Agent in conjunction with whatever returns 
in the text chunk vector  similarity. 
Example—the answer to your question is X units, and here is the output of the tab
le it references, or similar. 
Much appreciation in advance.
```
---

     
 
all -  [ RLHF : EASIET WAY To FINE-TUNE ON YOUR DATA Using Reinforcement Learning with Human Feedback ](https://www.youtube.com/watch?v=R2paulc3P2M) , 2023-08-07-0926
```

```
---

     
 
all -  [ The power of LangChain for software generation using GPT ](/r/LangChain/comments/15ibzq9/the_power_of_langchain_for_software_generation/) , 2023-08-07-0926
```

```
---

     
 
all -  [ I have been exploring the best way to extract information from long documents, specifically looking  ](https://www.reddit.com/r/LangChain/comments/15jj1yl/i_have_been_exploring_the_best_way_to_extract/) , 2023-08-07-0926
```
There's a lot of hype around vector databases with the promise of 'infinite memory and instant access to your knowledge 
base', however in many cases they fall short. I found there are two main ways people go about understanding long documen
ts with AI:

1. Vector embeddings
2. LLMs with long context windows.

There are pros and cons to both approaches.

For e
xample, if you need a full, 'comprehensive' understanding of a specific long document, you will want to use an LLM like 
Anthropic's Claude with a long context window over a vector database approach.

On the other hand, if you're looking to 
retrieve specific information from a knowledge base consisting of hundreds/thousands of documents, a vector database wil
l be better suited. You can also use a hybrid approach, i.e. finding most relevant documents with the help of a vector d
atabase, then passing those docs in their entirety into a long context window along with your prompt.

To summarize all 
my thoughts, I wrote a substack article exploring this specific topic: [https://pashpashpash.substack.com/p/understandin
g-long-documents-with](https://pashpashpash.substack.com/p/understanding-long-documents-with)

So far, the best approach
 I have found is the hybrid approach I mentioned in my Substack post; basically finding the most relevant documents with
 the help of a vector database, then passing those docs in their entirety into a long context window along with your pro
mpt. Do you guys have any thoughts on this? Are there better ways of going about this?
```
---

     
 
all -  [ Vectorestore original text access ](https://www.reddit.com/r/LangChain/comments/15jigsk/vectorestore_original_text_access/) , 2023-08-07-0926
```
When we use retrieve an embedding vector from vectorscore, how does the LLM access the context of the vector? Does the o
riginal text saved as a metadata in the index of the stored vector? or can the LLM model decode the embedding within the
 model. Im confused how the model will process the retreived embedding vector and use it to make a new prompt to get a b
etter answer for a downstream task. 
```
---

     
 
all -  [ GPT-Synthesizer: an open-source tool for code generation using GPT and other LLMs ](/r/ChatGPT/comments/15iaqq9/gptsynthesizer_an_opensource_tool_for_code/) , 2023-08-07-0926
```

```
---

     
 
all -  [ How does LLM use embedding from the vectorstore ](https://www.reddit.com/r/LangChain/comments/15jey0g/how_does_llm_use_embedding_from_the_vectorstore/) , 2023-08-07-0926
```
I am recently trying to understand the different ways to fine tune LLM model for specific usecase and downstream task. I
f I am correct, a lot of research is saying that due to the size of the parameters in LLM, fine tuning might not be effi
cient and there may be a better option such as LoRa and using embedding retrieval from the vectorstore.

I would like to
 ask

1. How does the LLM use the embeddings to answer a specific prompt after the embedding is retrieved from similarit
y search. Lets say I inputted my monthly schedule data into the vectorstore and my prompt was 'what do I do every tuesda
y', how will the embedding be passed into the llm with my prompt? 

2. If I use my schedule data to finetune my a model 
by actually chaging the model parameters, does the model able to generate the correct output similar as using a method a
sked in 1?
```
---

     
 
all -  [ Roast My Resumes - Applying to APM and SWE New Grad Roles in the Fall :) ](https://www.reddit.com/r/resumes/comments/15jdz5t/roast_my_resumes_applying_to_apm_and_swe_new_grad/) , 2023-08-07-0926
```
&#x200B;

https://preview.redd.it/wqd9kedliegb1.png?width=1342&format=png&auto=webp&s=5edc821b2a4ad7112eae9abb41496085f5
db5073
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15jcg9q/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Unable to instantiate a HuggingFaceInference object with any model other than 'gpt2' ](https://www.reddit.com/r/LangChain/comments/15j9mbf/unable_to_instantiate_a_huggingfaceinference/) , 2023-08-07-0926
```
Hi!

&#x200B;

I followed your code example for using hf models in javascript: 

&#x200B;

\`\`\`

import { HuggingFaceI
nference } from 'langchain/llms/hf';

&#x200B;

const model = new HuggingFaceInference({

  model: 'gpt2',

  temperatur
e: 0.9,

  maxTokens: 50,

  apiKey: 'hf\_zevWTuoWJPNQuyBejPpMBXytZotBseHSny',

});

const res = await [model.call](http
s://model.call)(

  'Question: What would be a good company name a company that makes colorful socks?\\nAnswer:'

);

co
nsole.log({ res });

\`\`\`

and I am getting an ouput. However, whenever I am trying a different model, I keep getting 
the following error:

\`\`\`file:///Users/atantos/Documents/AI\_apps/LangCjhain\_JS/node\_modules/@huggingface/inference
/dist/index.mjs:425

throw new Error(output.error);

\^

&#x200B;

Error: The following \`model\_kwargs\` are not used b
y the model: \['return\_full\_text'\] (note: typos in the generate arguments will also show up in this list)

at HfInfer
ence.request (file:///node\_project/node\_modules/@huggingface/inference/dist/index.mjs:425:13)

at process.processTicks
AndRejections (/node:internal/process/task\_queues:95:5)

at async HfInference.textGeneration (file:///node\_project/nod
e\_modules/@huggingface/inference/dist/index.mjs:190:17)

at async RetryOperation.\_fn (/node\_project/node\_modules/p-r
etry/index.js:50:12) {

  attemptNumber: 7,

  retriesLeft: 0

}

&#x200B;

Node.js v18.17.0

\`\`\`

&#x200B;

When sea
rching online for cases with the same error, I see that the problem is resolved by setting return\_full\_text=True\`. I 
am not sure how to proceed further so that I can load any other hf model apart from gpt2 or there is something that the 
good people of langchain need to do about it.

&#x200B;

[https://github.com/hwchase17/langchainjs/blob/a25677702bac2266
65cea861b138b7070b6658b7/langchain/src/llms/hf.ts#L86C11-L86C34](https://github.com/hwchase17/langchainjs/blob/a25677702
bac226665cea861b138b7070b6658b7/langchain/src/llms/hf.ts#L86C11-L86C34)

&#x200B;

Any input would be greatly appreciate
d!

Thanks!
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15j8g3u/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15j411o/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Landchain + Gradio (Easy Walkthrough) ](https://www.youtube.com/watch?v=XZ9v3bgVbz0) , 2023-08-07-0926
```

```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15izpu1/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ivg6h/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Running Embedding Models in Parallel ](https://www.reddit.com/r/LangChain/comments/15iswfc/running_embedding_models_in_parallel/) , 2023-08-07-0926
```
for discussion; 

The ingestion process is overgeneralized, in that applications need to be more specific to be valuable
 beyond just chatting. in this way, running embedding models in parallel makes more sense;   


Ie; medical space (typic
al language/ document preprocessing assumed to this point):  
embedding model #1: trained on multi-modal medical informa
tion, fetches accurate data from hospital documents   
embedding model #2: trained on therapeutic language to ensue soft
-speak to users experiencing difficult emotions in relation to their health   


My hope is that multiple embedding mode
ls contributing to the vectorstore, all at the same time, will improve query results by creating an enhanced & coherent 
response to technical information, and generally keep the context of the data without sacrificing the humanity of it all
.   


Applications are already running embedding models in parallel; 

a. but does it make sense?  
\- is there a signi
ficant improvement in performance?   
\- does expanding the amount of specific embedding models increase the overall lan
guage capabilities?   
(ie; does 1, 2, 3, 4, 5, embedding models make the query-retrieval any better?)   
b. are the cur
rent limitations in AI preventing this from being commonplace? ie; the current limitations within hardware, processing p
ower, energy consumption, etc.).   
c. is there significant project costs to adding embedding models? 

  
If this is of
 interest, i can post more about my research findings and personal experiments as they continue. Initially, I've curated
 a sample knowledge base of rich \[+2,000 pages/ 172kb condensed/ .pdf/ has a variety of formats for images/ xrays/ docu
ment scans/ hand-notes/etc.\] medical information that I'll be using to embed into an Activeloop DeepLake vectorstore fo
r evaluation. I'll use various embedding models independently, then in combination, and evaluate the results based on pr
e-determined benchmarks. 
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15irxwe/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ 'Concerned About LLM Hallucinations!! Seeking Solution with Nemo Guardrails and Guardrails! ](https://www.reddit.com/r/LangChain/comments/15ir9l0/concerned_about_llm_hallucinations_seeking/) , 2023-08-07-0926
```
 **'Can Nemo Guardrails Help Prevent LLM Hallucinations?** 

If **yes, HOW?**

My prompt instructs LLM to create a JSON 
format summary, which works well with resumes. However, when I input a statement like '*Hi, I have an experience of 5 ye
ars*,' LLM generates summaries with information not in the resume. 

Can Nemo Guardrails and Guardrails address this iss
ue? Looking for solutions!' 

**BUT HOW?!**

Thanks in advance!!
```
---

     
 
all -  [ Buddies for Local Language Models ](https://www.reddit.com/r/ProgrammingBuddies/comments/15iqe68/buddies_for_local_language_models/) , 2023-08-07-0926
```
Hey,

Looking for buddies that explore the space of local Language Models with me.  
I'd like to play around with variou
s Llama Models, Wizard Vicuna etc. for Code Completion, Text to Speech, Semantic Search etc.  as a replacement for OpenA
I, Github Copilot etc.  
I will probably try to use remote services for a lot of stuff like google collab, azure, vast.a
i as my hardware isn't that great, but you can also run stuff locally if you prefer that.  
Maybe we can also code somet
hing together using langchain or other stuff if we have ideas.  
DM me if interested, looking forward to hearing from yo
u.  

```
---

     
 
all -  [ Guardrails Implementation Challenge: Seeking Expert Advice to Resolve NameError Issue with Langchain ](https://www.reddit.com/r/LangChain/comments/15iq0vy/guardrails_implementation_challenge_seeking/) , 2023-08-07-0926
```
 Currently, I'm in the process of implementing a guardrail using Langchain, following the steps outlined in the official
 documentation \[link provided: [**https://shreyar.github.io/guardrails/integrations/langchain/**](https://shreyar.githu
b.io/guardrails/integrations/langchain/)\]. However, I've encountered an issue. After sending the 

    rail_spec

to 


    output_parser = GuardrailsOutputParser.from_rail_string(rail_spec, api=openai.ChatCompletion.create)

, instead of o
btaining the expected output, I'm encountering a 

    NameError : name 'doctors_notes' is not defined

Despite meticulo
usly following each step mentioned in the documentation, the actual outcome differs from the expected one, as shown in t
he illustration. 

**Actual :-**

https://preview.redd.it/j2qx6j9h39gb1.png?width=868&format=png&auto=webp&s=6c1cdfe1ed1
d8471d948cf357070c400336d98d0

**ERROR SCREENSHOT :-**

&#x200B;

https://preview.redd.it/ybcsuits39gb1.png?width=1150&f
ormat=png&auto=webp&s=84567fa9080cba71d810261cce0dee03047c6ea2

*'doctor\_note'* is a variable that will be placed after
 few more steps. It doesn't have to be added before.

I'm facing the same error with {{output\_schema}} which has to be 
replaced automatically with the help of the guardrail object that we have to create. (needs no manual interventtion)

No
te : Facing the same issue when I try to implement guardrail without langchain.

Will need assistance!

Thanks in advanc
e!! 
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15iotro/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Document-based QnA without OpenAI? ](https://www.reddit.com/r/datascience/comments/15imvh7/documentbased_qna_without_openai/) , 2023-08-07-0926
```
I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to ma
ke it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain
 only supports GPT but any other ideas are highly appreciated!
```
---

     
 
all -  [ [D] Document-based QnA without OpenAI? ](https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/) , 2023-08-07-0926
```
I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to ma
ke it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain
 only supports GPT but any other ideas are highly appreciated!
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15illup/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ihx4u/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ You can see the thoughts of an LLM by connecting your LangChain agent to a Streamlit app via Callbac ](https://www.reddit.com/r/Langchaindev/comments/15ievu8/you_can_see_the_thoughts_of_an_llm_by_connecting/) , 2023-08-07-0926
```
`StreamlitCallbackHandler`:  
[https://python.langchain.com/docs/integrations/callbacks/streamlit](https://python.langch
ain.com/docs/integrations/callbacks/streamlit)  


Demo with the [MRKL agent](https://python.langchain.com/docs/modules/
agents/how_to/mrkl/): [https://langchain-mrkl.streamlit.app](https://langchain-mrkl.streamlit.app/?utm_medium=oembed)
```
---

     
 
all -  [ You can see the thoughts of an LLM by connecting your LangChain agent to a Streamlit app via Callbac ](https://www.reddit.com/r/Langchaindev/comments/15ievsy/you_can_see_the_thoughts_of_an_llm_by_connecting/) , 2023-08-07-0926
```
`StreamlitCallbackHandler`:  
[https://python.langchain.com/docs/integrations/callbacks/streamlit](https://python.langch
ain.com/docs/integrations/callbacks/streamlit)  


Demo with the [MRKL agent](https://python.langchain.com/docs/modules/
agents/how_to/mrkl/): [https://langchain-mrkl.streamlit.app](https://langchain-mrkl.streamlit.app/?utm_medium=oembed)
```
---

     
 
all -  [ LK-99: A fad or a revolution? Chat with ArXiv to find out ](https://github.com/myscale/ChatData) , 2023-08-07-0926
```

```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15idph0/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Experimenting with Chains, Prompts, and LLMs ](https://www.reddit.com/r/LangChain/comments/15id6q2/experimenting_with_chains_prompts_and_llms/) , 2023-08-07-0926
```
Hey everyone!

We created an experimentation framework that lets you run and evaluate chains across different prompts / 
llms / configurations

Check out our example here: [https://github.com/hegelai/prompttools/blob/main/examples/notebooks/
LangChainSequentialChainExperiment.ipynb](https://github.com/hegelai/prompttools/blob/main/examples/notebooks/LangChainS
equentialChainExperiment.ipynb)  

If anyone is interested in helping us support router chains, we are looking for help 
to do that next
```
---

     
 
all -  [ The power of LangChain for software generation using GPT ](https://www.reddit.com/r/LangChain/comments/15ibzq9/the_power_of_langchain_for_software_generation/) , 2023-08-07-0926
```
We made this tool using lang-chain: [https://github.com/RoboCoachTechnologies/GPT-Synthesizer](https://github.com/RoboCo
achTechnologies/GPT-Synthesizer)

Here is a demo: [https://www.youtube.com/watch?v=zFJDQOtIFGA](https://www.youtube.com/
watch?v=zFJDQOtIFGA) 

&#x200B;
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15i8zdw/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Unable to store response of CONVERSATIONAL_REACT_DESCRIPTION AgentType ](https://www.reddit.com/r/LangChain/comments/15i6361/unable_to_store_response_of_conversational_react/) , 2023-08-07-0926
```
Hi

I'm writing a flask API, and using langchain agents to execute prompts and provide valid responses. I'm current tryi
ng to run my agent and store its response in a variable, which I then jsonify and return to my application. When using Z
ERO\_SHOT\_REACT\_DESCRIPTION this was working just fine, but has since been throwing `OutputParserException: Could not 
parse LLM output: Hello Bob! How can I assist you today?`

Below is my code:

    # imports
    from langchain.agents im
port Tool
    from langchain.agents import AgentType
    from langchain.memory import ConversationBufferMemory
    from 
langchain import OpenAI
    from langchain.utilities import SerpAPIWrapper
    from langchain.agents import initialize_a
gent
    from langchain.chat_models import ChatOpenAI
    
    # SERP API
    search = SerpAPIWrapper(serpapi_api_key='x
xx')
    tools = [
        Tool(
            name = 'Current Search',
            func=search.run,
            descripti
on='useful for when you need to answer questions about current events or the current state of the world'
        ),
    
]
    
    # memory for conversational agent
    memory = ConversationBufferMemory(memory_key='chat_history')
    
    #
 LLM and agent
    llm=ChatOpenAI(temperature=0, openai_api_key='xxx')
    agent_chain = initialize_agent(tools, llm, ag
ent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)
    
    result = agent_chain.run(input='hi
, i am bob')

Any help would be much appreciated. Thanks!
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15i4cd6/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ how do I get the endpoint from createOpenAPIChain() ](https://www.reddit.com/r/LangChain/comments/15i34yv/how_do_i_get_the_endpoint_from_createopenapichain/) , 2023-08-07-0926
```
Been breaking my head since morning trying to get the endpoint which was called along with the parameters when running c
reateOpenAPIChain(). The verbose log tells me this output is from the 2nd chain of this sequential chain but I can't fig
ure out how to get its output. I wanted to override outputVariables but can't even do that. Help!
```
---

     
 
all -  [ Create an Azure OpenAI, LangChain, ChromaDB, and Chainlit Chat App in Container Apps using Terraform ](https://www.reddit.com/r/LangChain/comments/15i2rvk/create_an_azure_openai_langchain_chromadb_and/) , 2023-08-07-0926
```
[https://techcommunity.microsoft.com/t5/fasttrack-for-azure/create-an-azure-openai-langchain-chromadb-and-chainlit-chat-
app/ba-p/3885602](https://techcommunity.microsoft.com/t5/fasttrack-for-azure/create-an-azure-openai-langchain-chromadb-a
nd-chainlit-chat-app/ba-p/3885602)
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15hzsvy/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Has anyone attempted llama-index's document loading feature on a LLaMA mode? Or any langchain on LLa ](https://www.reddit.com/r/LocalLLaMA/comments/15hxdj1/has_anyone_attempted_llamaindexs_document_loading/) , 2023-08-07-0926
```
Hello,

There is a PDF Loader module within llama-index ([https://llamahub.ai/l/file-pdf](https://llamahub.ai/l/file-pdf
)), but most examples I found online were people using it with OpenAI's API services, and not with local models.

Has an
yone successfully managed to do cool stuff with LLaMA or any other local model, like ChatGPT Plugin system can do? Or ma
king it work like ChatPDF, or making it summarize videos you upload etc.

I've seen claims that local models are not pow
erful enough to do that, but I doubt at least llama 70b wouldn't be able to pull this off...
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15hw37x/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15hsya5/peter_buildfast_masterclass_learn_to_build_your/) , 2023-08-07-0926
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ langchain katas - an open source project to practice langchain ](https://github.com/jondot/langchain-llm-katas) , 2023-08-07-0926
```

```
---

     
 
MachineLearning -  [ [D] Roadmap for AI engineer (implementation of language models on premise) ](https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/) , 2023-08-07-0926
```
 I worked for less than a year as a Data Engineer. I decided to look for other challenges and got a job as an AI enginee
r developing language models.

The product of the company that hired me is related to data and metadata management. My t
asks will be to introduce features to the product, including a chat function that will allow for asking questions about 
data. Other tasks will include research and proposing additional AI-related functionalities to the product (on premise).
 I have a two weeks left to start work and I need to prepare a bit. My job will involve implementing ready-made solution
s and conducting research (high level - I need to implement valuable features and no one cares how).

**What are the mos
t important things I should learn before starting work?**

First of all, I replicated a few applications from this blog:
 [https://blog.streamlit.io/tag/llms/](https://blog.streamlit.io/tag/llms/)

Then I have focused on Langchain. I'm also 
in the middle of a course on Udemy about Next-Gen AI projects - Beginner friendly - Langchain, Pinecone - OpenAI, Huggin
gFace & LLAMA 2 models

I need a roadmap that will guide me a bit. I'm looking for blogs/materials/courses that will giv
e me practical knowledge in this matter.
```
---

     
 
MachineLearning -  [ [D] Having trouble with RAG on company domain data ](https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/) , 2023-08-07-0926
```
I have a data set that isn't that large \~200 pdfs. I have done the regular RAG approach with Langchain, extracting text
, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity sear
ch with a question I would like answered it returns the wrong context. The documents are semi-structured information of 
examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input th
is question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not e
xplicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chun
ks, but this does nothing.

Does anyone have any tips on improving the embeddings retrieval in this case?
```
---

     
 
MachineLearning -  [ [D] How do I reduce LLM inferencing time? ](https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/) , 2023-08-07-0926
```
I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface l
ibrary, and I am running the model on AWS ml.g4dn.12xlarge which has 4x**nvidia t4**, which gives a total 64GB of GPU me
mory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins
 for big queries.

The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in 
a conversational way. I've extracted the main parts of the notebook and put it up [here](https://colab.research.google.c
om/drive/1uFNkZ6FI0qffwRpW6ubfdq0HrCqcqVUi?usp=sharing).

Where can I make changes to speed up the transaction. Is there
 any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give a
n answer in less than 5 seconds. Are there any other areas I can optimise?

I appreciate any help you can provide. Thank
s!
```
---

     
 
MachineLearning -  [ [P] TruLens-Eval is an open source project for eval & tracking LLM experiments. ](https://www.reddit.com/r/MachineLearning/comments/1542fbt/p_trulenseval_is_an_open_source_project_for_eval/) , 2023-08-07-0926
```
Hey [r/MachineLearning](https://www.reddit.com/r/MachineLearning/),

The team at TruEra recently released an open source
 project for evaluation & tracking of LLM applications called [TruLens-Eval](https://github.com/truera/trulens/tree/main
/trulens_eval). We’ve specifically targeted retrieval-augmented QA as a core use case and so far we’ve seen it used for 
comparing different models and parameters, prompts, vector-db configurations and query planning strategies. I’d love to 
get your feedback on it.

The core idea behind the project is feedback functions. Analogous to labeling functions, feedb
ack functions are models used to score the text produced by LLMs. We already have a variety of out-of-the-box feedback f
unctions to use for eval including relevance, language match, sentiment and moderation that can be applied to inputs, ou
tputs or intermediate steps of your application.

On top of eval, there’s also built-in tracking of cost and latency.

W
e made it easy to integrate with different setups using connectors for langchain, llama-index + an option to use it with
out a framework.

[Langchain Quickstart Colab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-
trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/langchain_quickstart_colab.ipynb)

[Llama-Index Quickstart Co
lab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/c
olab/quickstarts/llama_index_quickstart_colab.ipynb)

[No Framework Quickstart Colab](https://colab.research.google.com/
github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/no_framework_quickstar
t_colab.ipynb)

Last, the project comes with a streamlit dashboard for visualization of your experiments and associated 
metrics.

[TruLens dashboard for comparing different app versions](https://preview.redd.it/q68b1l27pycb1.jpg?width=1233&
format=pjpg&auto=webp&s=cfb1704624a8b6642b249a32d0afee85ea9f62d9)

Please let us know what you use this for or if you ha
ve feedback! And thanks to all contributors to this project and the open source community!
```
---

     
 
MachineLearning -  [ Alternativ to langchain [D] ](https://www.reddit.com/r/MachineLearning/comments/15175na/alternativ_to_langchain_d/) , 2023-08-07-0926
```
Im currently learning hiw to use langchain but i heard that its bad so i want to know what are som alternatives i need m
emory and agents so that it can search online run code and so on so what is the best alternativ or is langchain the best
 option
```
---

     
 
MachineLearning -  [ '[N]' '[D]' Langchain? What is it?? ](https://www.reddit.com/r/MachineLearning/comments/150mzax/n_d_langchain_what_is_it/) , 2023-08-07-0926
```
want to know more about Langchain  
Check out [https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf](https:
//nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf)
```
---

     
 
MachineLearning -  [ [D] The Problem With LangChain ](https://www.reddit.com/r/MachineLearning/comments/14zlaz6/d_the_problem_with_langchain/) , 2023-08-07-0926
```
https://minimaxir.com/2023/07/langchain-problem/

tl;dr it's needlessly complex, and I provide code examples to demonstr
ate such.

A few weeks ago when I posted about creating a LangChain alternative to /r/MachineLearning, most of the comme
nts replied 'what exactly is the issue with LangChain', so I hope this provides more clarity!
```
---

     
 
MachineLearning -  [ [D] 📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1) ](https://www.reddit.com/r/MachineLearning/comments/14xww89/d_the_learning_corner_andrew_ng_free_ai_courses/) , 2023-08-07-0926
```
📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1)

This is a list of some of the best Ai Free courses by Andrew NG
, we will release the second part of the list on our next newsletter installment (link)

* [**Generative AI with Large L
anguage Models**](https://www.deeplearning.ai/courses/generative-ai-with-llms/?utm_campaign=gaia-launch&utm_content=2545
85614&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18246783)
* [**LangChain: Chat With Your Data**](https://www
.deeplearning.ai/short-courses/langchain-chat-with-your-data/)
* [**LangChain for LLM Application Development**](https:/
/learn.deeplearning.ai/langchain)
* [**How Diffusion Models Work**](https://learn.deeplearning.ai/diffusion-model)
```
---

     
 
MachineLearning -  [ [P] langchain-lite alternative ](https://www.reddit.com/r/MachineLearning/comments/14xf9xb/p_langchainlite_alternative/) , 2023-08-07-0926
```
Although langchain is an impressive library, I tend to find it is…

* a little unintuitive, at least for non-trivial exa
mples or examples that don’t have a predefined chains/templates
* related, it's overly prescriptive; and the various lev
els of abstraction don't resonate with me
* related, can be difficult to debug or understand what’s happening in interme
diate steps of the chain or what’s it’s actually sending OpenAI

So, I built a “langchain-lite” package called `llm-work
flow`

https://github.com/shane-kercheval/llm-workflow

The value proposition is basically:

* easily build up a sequenc
e of tasks (e.g. prompt-template -> chat) called a workflow, where the output of one task serves as the input to the nex
t task in the workflow
* **track history**; understand what's happening in each of the tasks; **aggregate token usage, c
osts, etc. across the workflow**

So a workflow can be anything from `prompt -> chat -> response` to `prompt -> web-sear
ch -> web-scraping -> vector-database & retrieval -> modified prompt -> chat -> response`.

Here's an example of a 'prom
pt enhancer' workflow, where the user provides a prompt, one model enhances/improves the prompt, and the second model an
swers the question based on the enhanced prompt.

```python
prompt_enhancer = OpenAIChat(...)
chat_assistant = OpenAICha
t(...)

def prompt_template(user_prompt: str) -> str:
    return 'Improve the user's request, below, by expanding the re
quest ' \
        'to describe the relevant python best practices and documentation ' \
        f'requirements that shou
ld be followed:\n\n```{user_prompt}```'

def prompt_extract_code(_) -> str:
    # `_` signals that we are ignoring the i
nput (from the previous task)
    return 'Return only the primary code of interest from the previous answer, '\
        
'including docstrings, but without any text/response.'

workflow = Workflow(tasks=[
    prompt_template,      # modifies
 the user's prompt
    prompt_enhancer,      # returns an improved version of the user's prompt
    chat_assistant,     
  # returns the chat response based on the improved prompt
    prompt_extract_code,  # prompt to ask the model to extrac
t only the relevant code
    chat_assistant,       # returns only the relevant code from the model's last response
])
pr
ompt = 'create a function to mask all emails from a string value'
response = workflow(prompt)
```

The `response` is: `d
ef mask_email_addresses(string): .....`

We can view the history, which includes the prompts/responses/tokens/etc. for e
ach interaction:

```python
print(workflow.history())
```

Output:

```
[
    ExchangeRecord(prompt='Improve the user's 
request, below, by ...', response='Create a Python function that adheres to best practice...', timestamp='2023-07-12 04:
45:04.703', cost=0.00063, total_tokens=333, prompt_tokens=58, response_tokens=275),
    ExchangeRecord(prompt='Create a 
Python function that adheres ...', response='Sure! Here\'s an example of a Python function that adh...', timestamp='2023
-07-12 04:45:14.696', cost=0.00149, total_tokens=820,  prompt_tokens=292, response_tokens=528),
    ExchangeRecord(promp
t='Return only the primary code of intere...', response='```python\nimport re\n\ndef mask_email_addresses(strin...', tim
estamp='2023-07-12 04:45:18.875', cost=0.00167, total_tokens=1051, prompt_tokens=850, response_tokens=201)
]
```

We can
 also summarize costs/tokens/etc.

```python
print(workflow.sum('cost'))             # 0.0034
print(workflow.sum('total_
tokens'))     # 1961
print(workflow.sum('prompt_tokens'))    # 1104
print(workflow.sum('response_tokens'))  # 857
```

M
ore examples can be found here: https://github.com/shane-kercheval/llm-workflow/tree/main/examples

Feedback welcome.
```
---

     
 
MachineLearning -  [ [D] What have been your use cases for LLM autonomous agents? ](https://www.reddit.com/r/MachineLearning/comments/14w817y/d_what_have_been_your_use_cases_for_llm/) , 2023-08-07-0926
```
I've been using GPT for completions on a daily basis for a while now - code completion and search-like chatting, basical
ly. I've recently been playing around with both ChatGPT plugins and LangChain for autonomous-agent-like behavior, and al
though the idea of the LLM interacting with the environment through API calls or code interpretation seems promising, in
 practice I haven't found such a useful and usable case for it like completions yet.

LangChain's OpenAPI toolkit with i
ts planner/controller agent duo seems to get lost 90% of the time, making it unusable. This happens even with an /api en
dpoint telling it exactly how to interact with the API and prompt templates suggesting that this endpoint be used to get
 the API specs. Maybe I'm just not getting it right...

As for ChatGPT plugins, other than web search for more updated r
esults I haven't really found a use case where I could not do the same thing with completions. Code Interpreter shaves o
ff a few seconds vs completions and running whatever script it produces locally, but it's not very useful in face of com
pliance or privacy requirements of not uploading stuff into OpenAI. For example I wanted to speed up a work related vide
o and add a separate audio track to it. I couldn't upload the video to OpenAI as it contained internal work stuff, so I 
just used completions for an ffmpeg script to do the job and ran it locally. Same thing with transforming or plotting CS
V data - can't really update customer data to OpenAI, so just get the script and run it locally.

Anyway, I can *think o
f* a lot of cool use cases for autonomous agents and the like, but I haven't been able to *actually use* it in my daily 
routine, unlike text completion. Have you been using autonomous agents successfully and regularly?
```
---

     
 
MachineLearning -  [ [D] Hacking LangChain for Fun and Profit ](https://www.reddit.com/r/MachineLearning/comments/14w0ht7/d_hacking_langchain_for_fun_and_profit/) , 2023-08-07-0926
```
[https://blog.kevinhu.me/2023/07/10/hacking-langchain-for-fun-and-profit/](https://blog.kevinhu.me/2023/07/10/hacking-la
ngchain-for-fun-and-profit/)

I'm starting a series of blogs to delve into LangChain. Hope this helps anyone who's inter
ested in LLM and building with LangChain.
```
---

     
 
MachineLearning -  [ [D] - Are there any AI benchmarks that involve successful longterm problem solving when running as a ](https://www.reddit.com/r/MachineLearning/comments/14v4l2o/d_are_there_any_ai_benchmarks_that_involve/) , 2023-08-07-0926
```
 Even the most powerful LLMs, such as gpt4, seem to get lost or fall into loops when being run as autonomous agents like
 as part of langchain or autogpt. Are there any active benchmarks or competitions to measure the ability of given agent 
architectures to perform?
```
---

     
 
deeplearning -  [ Using PDFs with GPT Models ](https://www.reddit.com/r/deeplearning/comments/15g6i4x/using_pdfs_with_gpt_models/) , 2023-08-07-0926
```
Found a blog talking about how we can interact with PDFs in Python by using GPT API & Langchain. It talks about some pre
tty cool automations you can build involving PDFs - [https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-g
pt-api/](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/)
```
---

     
 
deeplearning -  [ List of all MLOps & LLMOps companies -- LLMOps.Space ](https://i.redd.it/d26rgf9fmnfb1.png) , 2023-08-07-0926
```

```
---

     
