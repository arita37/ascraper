 
all -  [ Making my AI assistant understand complex product configurations ‚Äì Any advice? ](https://www.reddit.com/r/LangChain/comments/1fu2ec7/making_my_ai_assistant_understand_complex_product/) , 2024-10-02-0912
```
I'm trying to build a chat assistant that is an expert in a company's refrigeration products, such as refrigerators, fre
ezers, and wine coolers. Each product type has different categories (e.g., French door refrigerators, side-by-side freez
ers, etc.) and multiple models under each category. Every model offers features like different temperature controls, ene
rgy ratings, and storage capacities.

The data about these features is stored in a very complex SQL database, and we als
o have detailed product descriptions in a text format.

**What I've tried so far:**

I created an agent using LangChain 
with two tools:

1. A vector database containing product descriptions
2. Another tool to query the SQL database based on
 user input.

The challenge is that the SQL database structure is quite intricate, leading to incorrect predictions from
 the LLM, and the chat experience lacks interactivity. For instance, if a user asks, 'What‚Äôs the temperature range of mo
del X?' the assistant doesn't prompt the user further by saying, 'This depends on the cooling zones. We offer single, du
al, and triple cooling zones. Which one are you interested in?'

**My goal:**

I want to make the interaction more user-
friendly, like:

**User:** 'I'm looking for a refrigerator.'  
**AI:** 'We offer the following types: French door, side-
by-side, and top freezer. Which one are you interested in?'  
**User:** 'Tell me about French door refrigerators.'  
**A
I:** 'Our French door refrigerators come in various sizes and offer features like adjustable temperature zones, humidity
-controlled crispers, and energy-saving modes. Would you like more details on a specific feature?'

**User:** 'What abou
t the adjustable temperature zones?'  
**AI:** 'The adjustable temperature zones vary based on the model. Would you like
 to know about the temperature range, available sizes, or energy ratings?'

**User:** 'Tell me the temperature range.'  

**AI:** 'Our French door refrigerators offer temperature ranges from -2¬∞C to 8¬∞C. Some models have separate compartment
s with independent temperature settings. Are you looking for more information on a specific model?'

I believe using Lan
gGraph could help solve this problem and make the chat more interactive, but I'm not entirely sure how to implement it e
ffectively for this use case. Is LangGraph the right solution, or should I be approaching this differently? Any guidance
 or advice would be incredibly helpful!
```
---

     
 
all -  [ How would you create a PowerPoint to text agent?
 ](https://www.reddit.com/r/SmythOS_/comments/1fu0dp8/how_would_you_create_a_powerpoint_to_text_agent/) , 2024-10-02-0912
```
I'm looking to build an AI agent that can convert PowerPoint presentations into text summaries. I'm curious about the mo
st cost-effective way to approach this, preferably using open-source tools. Here's what I'm thinking:

1. PowerPoint par
sing: Any recommendations for libraries that can extract content from .pptx files?
2. Text extraction: Once we have the 
slide content, what's a good way to pull out the relevant text?
3. Summarization: Are there any lightweight, open-source
 NLP models that could help condense the extracted text?
4. Would LangChain and AutoGPT be an overkill for this task? An
y other frameworks I should consider?
```
---

     
 
all -  [ HTML to markdown ](https://www.reddit.com/r/LangChain/comments/1ftz07p/html_to_markdown/) , 2024-10-02-0912
```
I want to build an RAG application for documentation Q&A. I'm new to this but I understand I've to do some preprocessing
 to first convert the webpage of the documentation and all the sublinks into markup to then split into chunks and store 
in a vector store. What's the best and preferred way to do the conversion?
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses ](https://www.reddit.com/r/udemyfreebies/comments/1ftyb6j/list_of_free_and_best_selling_discounted_courses/) , 2024-10-02-0912
```
# Udemy Free Courses for 02 October 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the 
courses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16909/)Complete FastAPI masterclass from scratch

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16908/)\[NEW\] 2024:Mastering Generative AI-From LLMs to Application
s
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16907/)\[NEW\]Mastering Retrieval Augmented Generation (RAG) IN LL
Ms
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16906/)Crea un Sistema de Compra y Venta con PHP, JS y SQL SERVER

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16905/)Reinforcement Learning beginner to master ‚Äì AI in Python
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/16904/)Time Series Analysis, Forecasting, and Machine Learning
* [REDEE
M OFFER ](https://idownloadcoupon.com/udemy/16903/)The Complete Ethical Hacking Coding Course
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/16902/)SOC(Cybersecurity):Build Powerful SOC with Open Source Tools
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/16901/)Cyber Security-SOC and SIEM (SPLUNK&ELK) for Beginners -2024
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/16900/)Cyber Security (SOC) Interview Questions and Answers-2024
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/16899/)Azure Data Factory Training‚ÄìContinuous Integration/Delivery
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/16898/)Master Angular 7 (formerly Angular 2): The Complete Course
* [REDEEM OFFER ](https://idownl
oadcoupon.com/udemy/16897/)Mastering Figma from 0 to 100 (UI/UX Mastery Course)
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/16896/)Mathematics-Basics to Advanced for Data Science And GenAI
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/16895/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/16894/)Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* \[New\] 1300+ DevOps Interview Questions ‚Äì P
ractice Tests Pack
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/16893/)
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/16892/)React 16: The Complete Course (incl. React Router 4 & Redux)
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/16891/)Complete Machine Learning,NLP Bootcamp MLOPS & Deployment
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/16890/)Complete Data Analyst Bootcamp From Basics To Advanced
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/16889/)6 FULL Certified in Cybersecurity (CC) tests #1-6 ISC2 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
16888/)Free System Design Interview Tutorial ‚Äì System Design Masterclass (2024)
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/16887/)Python Web Development: Building Interactive Websites
* [REDEEM OFFER ](https://idownloadcoupon.com/u
demy/16886/)Practical IoT Security and Penetration testing for Beginners
* [REDEEM OFFER ](https://idownloadcoupon.com/u
demy/16885/)AWS Certified Data Engineer ‚Äì Associate ‚Äì Hands On + Exams
* [REDEEM OFFER ](https://idownloadcoupon.com/ude
my/16884/)Certified Kubernetes Administrator Ultimate Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16
883/)Certified Kubernetes Application Developer Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16882/)A
WS Certified Cloud Practitioner
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16881/)Ethically Hack the Planet Par
t 2
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16880/)Ethically Hack the Planet Part 4
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/16879/)Robotics and ROS 2 ‚Äì Learn by Doing! Manipulators
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/16878/)The Complete JavaScript Course: From Zero to Expert
* Certified Kubernetes Security Specialist M
asterclass
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/16877/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udem
y/16876/)Learn Basics of Robotics
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16875/)Complete Beginners Trading 
Strategy For Passive Income
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16874/)ChatGPT Masterclass: The Ultimate
 Beginner‚Äôs Guide!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16873/)Google Cloud Network Engineer (PCNE) Full 
Practice Exams
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16872/)Presentations with ChatGPT
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/16871/)Professional Diploma in Omnichannel Sales&Service Management
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/16870/)File & Folder Management Using PowerShell
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/16869/)ChatGPT Prompt Engineering Mastery
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16868/)Pytho
n & Gen AI Basics: Transition from Java in Just 15 days
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16867/)Agile
 Fundamentals Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16866/)Supercharging your business with 
AI tools
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16865/)7 steps to entrepreneurship: A complete business pla
n (PRO)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16864/)Financial Modeling on Excel Complete finance course o
n Excel
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16863/)ChatGPT & Generative AI: The ultimate AI course
* [RE
DEEM OFFER ](https://idownloadcoupon.com/udemy/16862/)ChatGPT e IA Generativa: gu√≠a de IA y prompt engineering
* Trends 
in Ethical Teaching
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/16861/)
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/16860/)Scrum Master Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16859/)Master Agile & S
crum Basics
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16858/)Executive Diploma in Consumer Lending Business
* 
[REDEEM OFFER ](https://idownloadcoupon.com/udemy/16857/)The Complete Java Course: From Basics to Advanced
* [REDEEM OFF
ER ](https://idownloadcoupon.com/udemy/16855/)Free FinOps Tutorial ‚Äì FinOps for GenAI
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/16854/)Free ChatGPT Tutorial ‚Äì What is ChatGPT and how does it work?
* [REDEEM OFFER ](https://idownlo
adcoupon.com/udemy/16853/)Free Natural Language Processing (NLP) Tutorial ‚Äì A Beginner‚Äôs guide to the spaCy NLP library

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16852/)Free Business Branding Tutorial ‚Äì Brand Management Essentials
 for Start-ups
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16851/)Free LinkedIn Tutorial ‚Äì LinkedIn Ads Free Cou
rse: Step by Step Beginners Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16850/)Free Tutorial ‚Äì Beyond Heal
ing with NLS DIagnostics
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16849/)Free Tutorial ‚Äì Creating Videos with
 AI: invideo AI Video Creation Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16848/)Free Tutorial ‚Äì Beginne
rs Course of UX/UI Design on Adobe XD ‚Äì Part 2
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16847/)Master Content
 Creation : Become a paid Content Creator
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16846/)Metaverse Professio
nal Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16845/)Interface Windows User Commands From The Be
ginner To Admin
* Web3 Professional Certification
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/16844/)
* [REDEEM O
FFER ](https://idownloadcoupon.com/udemy/16843/)ChatGPT e IA Generativa: gu√≠a de IA y prompt engineering
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/16842/)User Interface Design Professional Certification
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/16841/)B2B Sales Director Executive Certification
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/16840/)Agile Trainer Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16839/)Scrum Master Certif
ication
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16838/)Learn how to create Variables in Modern JavaScript
* 
[REDEEM OFFER ](https://idownloadcoupon.com/udemy/16837/)Modelizaci√≥n financiera: curso completo de finanzas en Excel
* 
[REDEEM OFFER ](https://idownloadcoupon.com/udemy/16836/)Product Owner Professional Certification
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/16835/)Sales Professional Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udem
y/16834/)CSO Chief Security Officer¬†Executive Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16833/)C
CO Chief Compliance Officer¬†Executive Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16832/)Python Pr
o Bootcamp Zero to Hero
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16831/)Prompt & AI Engineering Safety Profes
sional Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16830/)Comment ne plus √©chouer ? Le syst√®me de 
la r√©ussite
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/16829/)Aprende WPF y MAUI desde CERO usando C#

GET MORE
 FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ Help with Streaming LLM Output Between Nodes in LangGraph ](https://www.reddit.com/r/LangChain/comments/1ftxfqw/help_with_streaming_llm_output_between_nodes_in/) , 2024-10-02-0912
```
Hi, I want to implement a graph in which one node calls an LLM with structured output, similar to [this](https://python.
langchain.com/docs/how_to/structured_output/#streaming)

`from typing_extensions import Annotated, TypedDict`

`class Jo
ke(TypedDict):`

`'''Joke to tell user.'''`

`setup: Annotated[str, ..., 'The setup of the joke']`

`punchline: Annotate
d[str, ..., 'The punchline of the joke']`

`rating: Annotated[Optional[int], None, 'How funny the joke is, from 1 to 10'
]`

`structured_llm = llm.with_structured_output(Joke)`

`for chunk in structured_llm.stream('Tell me a joke about cats'
):`

`print(chunk)`

In this example, every chunk is a piece of JSON. I want to implement this in a node that sends ever
y chunk to another node. For example, the next node will filter some information from the chunks it receives. Finally, i
t will write its output to `messages.` Basically, my use case is that I don't want to stream output directly from the LL
M node but to stream it from the formatting node. Can anyone please provide a code sample to help me do this?
```
---

     
 
all -  [ Should you use Rust in LLM based tools for performance? | Bosun ](https://bosun.ai/posts/rust-for-genai-performance/) , 2024-10-02-0912
```

```
---

     
 
all -  [ LLM Applications to Production  ](https://www.reddit.com/r/LangChain/comments/1fturqx/llm_applications_to_production/) , 2024-10-02-0912
```
Hey guys , we‚Äôve been developing PoCs till now , and in order to move this to production line , what all steps are requi
red? What workflow is needed .. I‚Äôm new to this , so please guide me . Thanks ! 
```
---

     
 
all -  [ Debunking myths about pgvector ](https://www.reddit.com/r/LangChain/comments/1fttx7s/debunking_myths_about_pgvector/) , 2024-10-02-0912
```
I noticed a lot of recurring confusion around pgvector (the highly popular vector embedding extension for Postgres). One
 source of confusion is that pgvector is a meeting point of two communities: 

* People who understand vectors and vecto
r storage, but don't understand Postgres. 
* People who understand Postgres, SQL and relational DBs, but don't know much
 about vectors.

I wrote a blog about some of these misunderstandings that keep coming up again and again - especially a
round vector indexes and their limitations. Lots of folks believe that: 

1. You have to use vector indexes
2. Vector in
dexes are pretty much like other indexes in RDBMS
3. Pgvector is limited to 2000 dimension vectors
4. Pgvector misses da
ta for queries with WHERE conditions.
5. You only use vector embeddings for RAG
6. Pgvector can't work with BM25 (or oth
er sparse text-search vectors) 

I hope it helps someone or at least that you learn something interesting.

[https://www
.thenile.dev/blog/pgvector\_myth\_debunking](https://www.thenile.dev/blog/pgvector_myth_debunking)
```
---

     
 
all -  [ Benchmarking Hallucination Detection Methods in RAG ](https://www.reddit.com/r/LangChain/comments/1ftru5d/benchmarking_hallucination_detection_methods_in/) , 2024-10-02-0912
```
I came across this helpful Towards Data Science article for folks building RAG systems and concerned about hallucination
s.

If you're like me, keeping user trust intact is a top priority, and unchecked hallucinations undermine that. The [ar
ticle](https://towardsdatascience.com/benchmarking-hallucination-detection-methods-in-rag-6a03c555f063) benchmarks many 
hallucination detection methods across 4 RAG datasets (RAGAS, G-eval, DeepEval, TLM, and LLM self-evaluation).

Check it
 out if you're curious how well these tools can automatically catch incorrect RAG responses in practice. Would love to h
ear your thoughts if you've tried any of these methods, or have other suggestions for effective hallucination detection!

```
---

     
 
all -  [ üöÄ Join our Global AI Agents Hackathon with LangChain ü¶úüîó and Llama Index ü¶ô! ](https://tensorops.ai/aiagentsonlinehackathon) , 2024-10-02-0912
```
Hey AI enthusiasts! üëã

I'm organizing a global online hackathon focused on creating AI Agents, partnering with LangChain
 and Llama Index. üéâ

Key Details:
- üóìÔ∏è Dates: November 14-17
- üèÜ Challenge: Build an AI Agent + create usage guide
- üåê F
ormat: Online, with live webinars and expert lectures
- üìö Submission: PR to the GitHub GenAI_Agents repo
- üß† Perks: Top-
tier mentors and judges

ü§ù We're open for additional sponsors!

‚ùì Questions? Ask below!

#AIHackathon #AIAgents
```
---

     
 
all -  [ Making a UUID Output Parser in Langchain ](https://www.reddit.com/r/LangChain/comments/1ftpdjn/making_a_uuid_output_parser_in_langchain/) , 2024-10-02-0912
```
Was trying to think of a good introductory feature to work on (as this is the first time I would be contributing to Lang
chain) and thought that this could be a good starting PR (the uuid output parser) in order to get used to the codebase. 
Is this a good idea? In terms of the output parser itself, was thinking it would help in terms of session management and
 data tracking.
```
---

     
 
all -  [ AWS DynamoDB backed checkpoint saver for Langgraph JS ](https://www.reddit.com/r/LangChain/comments/1ftpazv/aws_dynamodb_backed_checkpoint_saver_for/) , 2024-10-02-0912
```
In case anyone is looking to use DynamoDB as the persistence for Langgraph JS, I have created a package.

Link: [https:/
/www.npmjs.com/package/@rwai/langgraphjs-checkpoint-dynamodb](https://www.npmjs.com/package/@rwai/langgraphjs-checkpoint
-dynamodb)

It borrows heavily from the existing two persistence packages released by the Langchain team.
```
---

     
 
all -  [ How does ELL compare to langchain? ](https://www.reddit.com/r/datascience/comments/1ftp0oh/how_does_ell_compare_to_langchain/) , 2024-10-02-0912
```
Hey hey, just stumbled upon this [ELL](https://docs.ell.so/index.html) thing and curious if anyone tried it. How does it
 compare to langchain? Are they complementary?
```
---

     
 
all -  [ GIT Code - Exploring Contextual Retrieval with OpenAI GPT-4o, Cohere, and LangChain /no UI ](https://www.reddit.com/r/Rag/comments/1ftmfc7/git_code_exploring_contextual_retrieval_with/) , 2024-10-02-0912
```
I recently saw Claude‚Äôs post on using contextual retrievers to improve Retrieval-Augmented Generation (RAG) systems, whi
ch got me thinking about my own experiment. While Claude‚Äôs example used their Sonnet 3.5 model, I decided to go a differ
ent route and built something similar using the more budget-friendly **GPT-4o** from OpenAI.

I also integrated **Cohere
‚Äôs re-ranking** and **query expansion** to enhance accuracy. The system combines **BM25 for keyword-based search** with 
**contextual embeddings** to bring in more relevant results.

I‚Äôve tested it on a 42-page document, parsing it with **Ll
amaParse** in multimodal mode. It only took a minute or two to get everything processed, and I‚Äôm now able to retrieve in
fo from anywhere in the document without the dreaded 'lost in the middle' issue. Next up: testing it on a 500-page docum
ent (will update you on that soon!).

here is the code: [Code Git Repo](https://github.com/lesteroliver911/contextual-do
c-retrieval-opneai-reranker)

**Features**

* **PDF Parsing**: Extracts content from PDFs using LlamaParse.
* **Contextu
al Chunking**: Splits documents into manageable chunks and provides contextual summaries using OpenAI's GPT-4.
* **BM25 
Search**: Implements a BM25 search index for efficient keyword-based retrieval.
* **Cohere Re-ranking**: Enhances search
 results by re-ranking them using Cohere's reranking model.
* **Query Expansion**: Expands search queries using AI to im
prove retrieval performance.
* **Error Handling**: Robust exception handling ensures reliable document processing.

If y
ou‚Äôre into RAG systems or AI in general, you can check out the code here: [Code Git Repo](https://github.com/lesterolive
r911/contextual-doc-retrieval-opneai-reranker) . I also explain the practical steps, how it works.

Would love to hear y
our thoughts or ideas on how I can improve it. Feel free to fork, contribute, or just drop feedback!
```
---

     
 
all -  [ How do I enhance LLM capabilities to carry out calculations on financial statement documents using R ](https://www.reddit.com/r/LangChain/comments/1fth9sb/how_do_i_enhance_llm_capabilities_to_carry_out/) , 2024-10-02-0912
```
I am currently working on RAG on financial statements. I am using gemini as my LLM and openAI with llamaindex for my age
nts. I want my RAG to be able to calculate any ratios or profits based on user query.  
I tried creating separate functi
ons and used tools to manage the functions like gross\_margin, revenue turn out etc. Yet the results are not as expected
.  
Is there any other way of going about with this.

Also I have another thought, is it possible for us to extract tabl
es from the documents in CSV format so that I can query the CSV for calculations.

  
Edit:  
I created separate functio
ns for mathematical calculations and assigned tools to call that particular function and created agents to handle those 
tools, so based on the query the respective tool is to be called in turn which calls the respective functions for carryi
ng out the calculations.  
The responses weren't as expected. As in didn't obtain any.
```
---

     
 
all -  [ [D] How are folks building conversational Retrieval Augmented Generation apps ](https://www.reddit.com/r/MachineLearning/comments/1ftdby7/d_how_are_folks_building_conversational_retrieval/) , 2024-10-02-0912
```
I've read through various resources such as:  
- [https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/](htt
ps://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/)  
- [https://python.langchain.com/docs/tutorials/qa\_cha
t\_history/](https://python.langchain.com/docs/tutorials/qa_chat_history/)  
- [https://langchain-ai.github.io/langgraph
/tutorials/rag/langgraph\_agentic\_rag/](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) 
 
- [https://docs.llamaindex.ai/en/stable/module\_guides/deploying/chat\_engines/](https://docs.llamaindex.ai/en/stable/
module_guides/deploying/chat_engines/)  
- [https://huggingface.co/datasets/nvidia/ChatRAG-Bench](https://huggingface.co
/datasets/nvidia/ChatRAG-Bench) 

But these feel overly reductive, since they don't address complexities like:  
1) when
 to retrieve vs. just respond immediately to reduce latency  
2) rely on existing context previously retrieved in the co
nversation instead of retrieving again at the current turn  
3) partition LLM context between retrieved information and 
past conversation history.

I'm sure some teams already have good systems for this, would appreciate pointers!
```
---

     
 
all -  [ How to know what agent architectures to use in Langgraph? ](https://www.reddit.com/r/LangChain/comments/1ftazvm/how_to_know_what_agent_architectures_to_use_in/) , 2024-10-02-0912
```
I have been using Langgraph for quite some time now and was wondering how you should think/choose between what architect
ures to use.

I believe this is an issue, mainly because when there are different ways of doing things, most people (inc
luding myself) tend to over-optimise their use case. For example, using hierarchical agent teams instead of using a simp
ler plan and solve architecture, that uses less tokens than you require for your use case. 

Would love to hear how othe
rs may go about this!
```
---

     
 
all -  [ Does anyone know when Langgraph Cloud will be out of beta? ](https://www.reddit.com/r/LangChain/comments/1ft520j/does_anyone_know_when_langgraph_cloud_will_be_out/) , 2024-10-02-0912
```
Hey, I think Langgraph is amazing and would like to use it alongside Langgraph Studio and Langgraph Cloud. Langgraph Clo
ud is currently in beta and not available to free users. 

Does anyone know when they will get Langgraph Cloud out of be
ta and whether or not they will be available to free users?
```
---

     
 
all -  [ Some help with UnstructuredLoader ](https://www.reddit.com/r/LangChain/comments/1ft1noj/some_help_with_unstructuredloader/) , 2024-10-02-0912
```
I am working with UnstructuredLoader, for loading PDFs, but I am having this error, and I have run out of ideas.

Here i
s my code and the error: 

https://preview.redd.it/6uhbpaz9hzrd1.png?width=885&format=png&auto=webp&s=49cd650fe2805d40b4
d73c887749ca700c89b366

    from langchain_unstructured import UnstructuredLoader
    
    
    file_path = './reports/c
otswold2-512313_207882.pdf'
    
    loader = UnstructuredLoader(
    ¬† ¬† file_path=file_path,
    ¬† ¬† strategy='hi_res'
,
    ¬† ¬† partition_via_api=False,
    ¬† ¬† coordinates=False,
    )
    
    docs = []
    for doc in loader.lazy_load()
:
    ¬† ¬† docs.append(doc)
```
---

     
 
all -  [ About using tools in langgraph  ](https://www.reddit.com/r/LangChain/comments/1fsx8at/about_using_tools_in_langgraph/) , 2024-10-02-0912
```
I have a question regarding using tools in agents that how would a LLM decide if it has to go to which the tool is conne
ct with it for example if I ask questions about something happened in 2024 and i had already connected to search tool li
ke tavily then how would LLM decide if he has to give answer which might be wrong or has to go with tools and then respo
nse it back.
```
---

     
 
all -  [ Any Langchain discord server?  ](https://www.reddit.com/r/LangChain/comments/1fstyus/any_langchain_discord_server/) , 2024-10-02-0912
```
Is there official Langchain discord server where people can ask questions or solve there code queries ? 
```
---

     
 
all -  [ LangGraph: interactive sequential tool calling ](https://www.reddit.com/r/LangChain/comments/1fst8i4/langgraph_interactive_sequential_tool_calling/) , 2024-10-02-0912
```
Hello everyone,

I'm building an AI assistant for our app, trying to instruct the LLM in a conversation, I ask it to cre
ate a project and a task for example in the database using the tools I defined. Assuming the process has several steps. 
I want the LLM to walk me through it and ask me for the required inputs to the tools. 

sample conversation I want:

- U
ser: Create a project  
- tool calling step  
- AI: what's the name of the project

- User: the project name is X

- AI:
 what are the names of the tasks that this project require in order to complete  
- User: one task named Y

  
Will prov
iding a ChatPrompt be sufficient to achieve this behavior or something else? 
```
---

     
 
all -  [ Streaming chatbot ](https://www.reddit.com/r/LangChain/comments/1fsr2g3/streaming_chatbot/) , 2024-10-02-0912
```
Hi everyone.

I made a chatbot to chat with my SQL data following this tutorial: https://python.langchain.com/docs/tutor
ials/sql_qa/

I used create_react_agent from langgraph. I am using React as my frontend and FastAPI as my backend. It wo
rks fine, but I want to stream the responses (aka the final answer) from the agent on my frontend. Is there any way to d
o that? I tried streaming on the backend following the various how-tos on langgraph, but I want to be able to stream on 
my frontend. 

Thanks a lot. 
```
---

     
 
all -  [ Ragflow vs kotaemon ](https://www.reddit.com/r/LangChain/comments/1fsql3a/ragflow_vs_kotaemon/) , 2024-10-02-0912
```
For those that have tried both, which of these worked better when training on your documents, which had a better experie
nce setting up locally?
```
---

     
 
all -  [ I made MVP just 15 days as a side project ](https://www.reddit.com/r/SideProject/comments/1fsppnz/i_made_mvp_just_15_days_as_a_side_project/) , 2024-10-02-0912
```
Hello everyone,

I am thrilled to announce that I will be undertaking the creation of my first project, [SubGPT.ai](http
s://SubGPT.ai), which involves building a chatbot for websites. Despite the challenges, I am determined to complete this
 project within a short timeframe of just 15 days.

Project Name: AI No Chatbot Builder with Your Own Data

Project Link
: [https://subgpt.ai](https://subgpt.ai/)

* Project Stack: Backend: Python Django, Django Rest Framework. 
* Frontend: 
HTML, CSS, JavaScript, Bootstrap 5. 
* Version Control: Git, GitHub.
* Auto Deployment: GitHub Actions.
* AI Model: Open
AI, Langchain Models, Google Gemini
* Payment Gateway (Lemon squeezy)

Features:

‚Ü≥ Easy-to-build GPTs for multiple appl
ications

‚Ü≥ Upload Your PDF to train your Chatbot

‚Ü≥ Seamless integrations (WordPress, WhatsApp, WebFlow, Bubble, Weebly
)

‚Ü≥ Advanced capabilities: multi-language support, personalized responses, and more

‚Ü≥ API Integration

‚Ü≥ Lead Generati
ons

‚Ü≥ Make Real-Time Virtual Customer Supported Chatbot and more

  

```
---

     
 
all -  [ Has prompt chaining been proven to work better than just one larger stepwise prompt? ](https://www.reddit.com/r/LocalLLaMA/comments/1fsj4ww/has_prompt_chaining_been_proven_to_work_better/) , 2024-10-02-0912
```
I know prompt chaining is basically the standard at this point and there are popular libraries such as LangChain that pr
omote this approach. However, especially with the larger context windows nowadays, is it necessary or does it lead to be
tter results to break a prompt up into multiple requests and chain them together? Found this¬†[study](https://arxiv.org/h
tml/2406.00507v1#:~:text=This%20paper%20is%20dedicated%20to,produce%20a%20more%20favorable%20outcome)¬†on prompt chaining
 vs a stepwise prompt. They seem to have concluded prompt chaining can produce a more favorable outcome, but they only e
xperimented on a text summarization task. Do you guys have any insights on this or if I am missing something?
```
---

     
 
all -  [ Arg `k` in `BufferWindowMemory`? ](https://www.reddit.com/r/LangChain/comments/1fshldy/arg_k_in_bufferwindowmemory/) , 2024-10-02-0912
```
Hi,

It looks like they removed this argument from 0.2 to 0.3 of Langchain JS. But I am curious, the API docs have no re
al description. But what is the `k` arg used for in the `BufferWindowMemory` class which is only in 0.2 

[BufferWindowM
emory 0.2 Docs](https://v02.api.js.langchain.com/classes/langchain.memory.BufferWindowMemory.html)

It looks like they h
ave a new class called `BufferMemory` for 0.3 without the `k` arg.

Any insight would be much appreciated.

Thanks!
```
---

     
 
all -  [ Amazon Bedrock Knowledge Bases as Agent Tool ](https://www.reddit.com/r/aws/comments/1fshbxj/amazon_bedrock_knowledge_bases_as_agent_tool/) , 2024-10-02-0912
```
Hello all, 

  
I am wondering if you had implemented Amazon KB as tool using Langchain, and also how do you manage the 
conversation history with it ?

  
I have a use case where I need a RAG to talk with documents and also the AI to query 
a SQL database, I was thinking in use KB as one tool and sql as other tool, but I am not sure if make sense to use KB or
 not, the main benefit that it will bring are the default connectors with web scrapper, sharepoint, etc.

Also, it seems
 that the conversation history are saved in memory and not persistent storage, I have build other AI apps where I use Dy
namodb to store the conversation history, but since KB manages internally the context of the conversation not sure how I
 would persist the conversation and send it to have the conversation across sessions.
```
---

     
 
all -  [ Attempting to build a knowledge base for storing LLM outputs. Feedback welcome! ](https://www.reddit.com/r/LLMDevs/comments/1fsfozx/attempting_to_build_a_knowledge_base_for_storing/) , 2024-10-02-0912
```
Hi everyone,

I would never have put myself into the category of 'developer' as it's not my job.

'Open source enthusias
t' for sure. But this sub keeps cropping up in my searches so I thought it would be worth sharing what I'm working on.


I began getting really into using various LLMs earlier this year for both professional and personal reasons.

While I th
ink that the advance of LLMs is exhilarating and amazing, my thoughts began turning to the rather mundane problem of sto
rage and data sovereignty. 

Namely ... I'm getting increasingly more useful outputs from the web UIs... what am I going
 to do with them? Can I back up all my outputs incrementally? How independent is this chunk of data from the platform I'
m using (Also: can I add tags? Seemingly not! Can I search through them? Nope!)

I had a couple of weeks in semi-vacatio
n mode so just before I left I set up a Postgres database with the idea of kickstarting a project to build some kind of 
organisation system. 

Over the course of the summer I built up a decent relational database. I gravitated around the id
ea of the system having four core modules: prompts, outputs, agents, and contexts (agent = custom LLM configs rather tha
n fine-tuning whole models). The contextual module is my latest addition:  it's a store of morsels of information that c
an be dropped into new LLMs whenever you need to quickly bring them up to 'speed' on a project or provide a set of found
ational facts. I'm sure more will come to mind.

There are a bunch of M2Ms and O2Ms relating everything together: prompt
s are associated with outputs (a conversation module is inevitably but right now multiple outputs are simply associated 
with the initial prompt); outputs and prompts with agents; and there are a few custom taxonomies like 'tags' and 'accura
cy ratings'.

My objective was (and is) to build out something like a 'workbench' . The collected outputs are 'raw mater
ial'. They get annotated, tagged with metadata, and in some cases edited carefully by a human. After that, they're store
d and managed just like any other piece of reference knowledge. I use LLMs intensively and routinely for stack research 
and this is one of the use-cases I have in mind. But there are countless. 

For want of a proper UI, my initial system d
esign was simply using NocoDB over the database and manually inputting prompts and outputs. Latterly, I've begun using L
LMs via their APIs. My offline prototype handles this perfectly: a prompt is collected, saved to that table. The API ret
urns its output output, and it gets saved to the output table. Finally, the relationship between the two is set down in 
the conventional method (ie, by writing foreign key values to a join table). (This also works in Obsidian but as much as
 I like the tool I don't think it's the right architecture for this)

Oddly enough, the part of this project I thought w
e be easiest (building a frontend) is proving the hardest. It bugs me to do this, but I'm 'dumbing down' the database ba
ck to its essential elements in order to make defining the schema into an ORM a lot easier.

Other things I've been chec
king out? MongoDB seemed interesting but ultimately I stuck with Postgres. Vector databases and graph databases .. intri
guing possibilities. LangChain ... I'm almost certain this could make developing this easier and it's on my radar to loo
k into it. 

Ultimately, it's a CRUD app that is honed in on working with LLMs and specifically trying to address the ve
ry neglected topic of output management: how to manage and refine the outputs so that they can be as valuable as possibl
e. 

The essential task for me is making sure that the database and storage buckets (for files etc) can be set by the us
er. The philosophy underpinning this is that LLMs are amazing. But prompt engineering and context-refinement aren't the 
only things we need to do to leverage them; we also need to figure out workflows and best practices for owning and then 
managing their outputs. 

It's a personal project that I'm using as an excuse to dive into the fascinating world of LLMs
. My note are open source and if I can ever get something robust enough that can be shared, I will absolutely put them o
ut there. For now, I'm enjoying plodding along. 

Critiques and thoughts welcome!
```
---

     
 
all -  [ Best open source RAG for 100s of PDFs ? ](https://www.reddit.com/r/LangChain/comments/1fsd1yw/best_open_source_rag_for_100s_of_pdfs/) , 2024-10-02-0912
```
I have 100-200 PDFs that I want to be able to ask and answer questions about. Most of the solutions I see are about Llam
aparse or 1000 other tools that are all closed source. If I wanted to do this without my data going anywhere, what appro
ach or guide/resource would you recommend? I‚Äôve already converted all my documents to markdown using marker, just not su
re how to proceed from there effectively.


```
---

     
 
all -  [ Need guidance with RAG ](https://www.reddit.com/r/LangChain/comments/1fsc977/need_guidance_with_rag/) , 2024-10-02-0912
```
I am new to the concept of RAG but I have worked with LLMs before. I tried researching but nothing was clear. I have a s
et of data which I would like to store in a vector database in the form of vector embeddings. Is it better to use pgadmi
n with RDS or do I have to create a knowledge graph. I read a thread which said that running it on AWS would be costly s
o what would you suggest using. I would like some guidance through this process
```
---

     
 
all -  [ Question for all that used various RAG frameworks ](https://www.reddit.com/r/Rag/comments/1fsa7ek/question_for_all_that_used_various_rag_frameworks/) , 2024-10-02-0912
```
Don't you get the feeling that you would be better off just implementing a solution tailored for your specific need inst
ead of dealing with all the overhead that comes along with langchain/llama index? 

  

```
---

     
 
all -  [ Unable to transition to a Product Role [Please guide me] ](https://www.reddit.com/r/LangChain/comments/1fsa7as/unable_to_transition_to_a_product_role_please/) , 2024-10-02-0912
```
**TL;DR:** I'm a final-year engineering student from a tier-3 college in Kolkata. I want to transition to a Product role
 so that I can utilize all of my skills and provide the maximum value back to the company rather than just doing tech. I
'm a seasoned AI developer with vast experience in the AI space and have built tons of software and POCs for big compani
es to validate their ideas. I'm looking to switch to a company that values my product skills as well as my tech skills. 
If you're building something cool in the AI space and are on a lookout for a technical DevRel or developer Advocate or a
 Product guy, please hmu. happy to chat!

  
**A bit about my background:** I'm a final-year engineering student from a 
tier-3 college in Kolkata. I have worked with more than 6 companies (all remote and foreign companies) till now (not int
erned, but worked on a contract basis). I stepped into the AI space early last year and shipped some cool AI products wh
ich went viral and one got covered by news coverage in Abu Dhabi, America, & Italy as well. Around April last year, I st
arted working for a Dubai-based startup on a contract basis. This company was responsible for building Polygon Copilot a
nd I was one of the 6 engineers hired to build that copilot. Worked their for 4 months and then cracked Summer of Bitcoi
n Program. It's like GSoC but only limited to bitcoin blockchain. And it's also very exclusive. So I interned at an org 
for 3 months under the program and the CTO of that org liked my work and AI skills so much that he got me onboard at a b
ig London based consultancy firm that he joined later. He was the head of AI there. I joined the consultancy firm as an 
AI Developer Consultant and later transitioned to AI Solutions Architect there. Worked there for 9 months during which I
 worked with clients like AWS, HSBC, Defra (UK Gov.), Marsh McLennan, etc. 

During my time their, I got approached by a
 London-based fintech startup to join part time as an consultant so I took up the offer. But very soon I transitioned in
to an AI Software Engineer there as the founder of the company loved my work and skills. This fintech is building a real
ly interesting product with a great product market fit and is backed by major VCs and banks of London. The flagship feat
ure of the product is the AI nd the most interesting part is... that I'm the only AI Engineer in the team and I've built
 the entire AI product and infrastructure from scratch all alone. I build and manage it all alone by myself working clos
ely with the founder of the company.

  
In the last few months, I got another offer from a brand new London-based start
up which was just starting off and was assembling a team. They're building a really cool product in the commodity tradin
g industry and there's a big market to conquer for it. I took up the offer as the product was appealing, and the pay was
 good too.

I left the consultancy firm after working 9 months there and right now I'm only working with the fintech (al
so keen to call me onsite London as soon as I complete my graduation) and the commodity trading startup. I'm making some
where around 4-4.5 lacs a month in-hand right now.

One thing that I didn't mention is that I'm a people's guy. I'm real
ly good at public speaking and posses extremely good leadership and communication skills. I'm a good team player and lov
e to see products from outside the tech realm too.

I've been trying to transition into a product role which gives me mo
re power to voice my suggestions and build products talking to users directly. I think I can do a great job there. 

If 
you're building something cool in the AI space and are looking for a technical DevRel/Dev Advocate/Product guy or if you
 know someone who's hiring, please do get in touch. I'd really appreciate that :) Happy to share my portfolio and resume
 in DMs.

  
**P.S:** If you make me go through a DSA/CP round, I might fail. But if you ask me to real world scenarios 
of scaling or optimizing architectures, I might give you extraordinary answers. Idk why my brain works in a very weird w
ay.

  
Thanks for reading :)
```
---

     
 
all -  [ Seeking Guidance for Agentic LLM Based Project ](https://www.reddit.com/r/LangChain/comments/1fs91n2/seeking_guidance_for_agentic_llm_based_project/) , 2024-10-02-0912
```
Hi everyone! I'm a second year Masters student in AI looking to gain more industry-relevant experience in the field of L
LMs. I am a researcher as well with some publications in Swarm Intelligence and Multi-Agent Systems, thus I'm interested
 in learning how to deploy and manage a system of multiple LLMs collaborating to achieve a goal.

Inspired by my hatred 
of the boring university homework that does not provide any value, I've designed a system that in theory should allow me
 (even tho I won't actually use it for it for obvious reasons) to feed a PDF with the task instructions and get anything
 specified as deliverables in the document as output. My core goal is to gain industry-relevant experience, therefore I'
m posting my general design to get feedback, criticism, ideas, and points of start.

My current experience with LLMs is 
mostly playing around with the ChatGPT API and some finetuning for control of agents in MAS simulations, so I'm new to a
nything that includes the cloud, Agentic LLMs and things like RAG. Therefore, I would also heavily appreciate pointers o
n good resources to get started learning about those!

Also, feel more than welcome to advise me on skills to add to the
 list that are good for the industry, I'm mostly focused on landing a good job after I graduate because I need to help m
y family with some big unexpected expenses. Thanks a lot in advance!

Here is the general design:

# Core Idea

The idea
 is to design and implement an agentic LLM-based system to solve a coding task or homework (including a report) given a 
PDF containing the task description by utilizing several agents that each have a role. The system should be hosted in th
e cloud and have a web interface to interact with, to learn industry-sought skills such as cloud engineering and managem
ent of LLMs in deployment.

# Skills List

Some of the skills I wish to learn

1. Agentic LLMs
2. Multi-agent systems of
 agentic LLMs
3. Cloud Deployment of LLMs
4. Quality Assessment of Deployed LLMs
5. Finetuning LLMs for given roles
6. D
ockerization and Kubernetes (If needed)
7. Web Interfacing
8. Data pipeline management for such a system
9. RAG for the 
writer/researcher agent (needs context to write better report sections?)

# Agent List

* Coder
   * Tasked with the act
ual implementation of any requirements and returning the relevant output
* Researcher
   * Retrieves the needed context 
and information required for the report
* Writer
   * Tasked with putting together any the researcher's information and 
the coder's output and write the report itself
* Manager
   * Tasked with overseeing the work of all other agent, making
 sure that the expected deliverables are present and according to specifications (like file naming, number of pages for 
the report etc)
```
---

     
 
all -  [ Python App Deployment  ](https://www.reddit.com/r/learnpython/comments/1fs7g3c/python_app_deployment/) , 2024-10-02-0912
```
Disclaimer: I‚Äôm new to this, sorry if the question seems dumb.

I recently finished a RAG Chatbot App using Streamlit, C
hromaDB, Langchain and others.. 

I now wanted to deploy it in order to access it from everywhere but I‚Äôm finding a lot 
of troubles in the process. 

I don‚Äôt seem to understand what files and folders I should upload to the deployment platfo
rms, and I also don‚Äôt know what libraries to include in the requirements.txt file.

Could someone maybe help me? 
```
---

     
 
all -  [ Getting started again with LangGraph version of chat-langchain again ](https://www.reddit.com/r/LangChain/comments/1fs5tm5/getting_started_again_with_langgraph_version_of/) , 2024-10-02-0912
```
I was using the langserve branch of chat-langchain 2 months ago.  It was perfect.  

Problem I had was, with deployment.
  I had to deal with the gcloud deployment every time after a push.

Now i am happy to use the LangGraph version.  

Got
 few Questions.

  
How is the maintenance on chat-langchain ?

1.  Are they contuously fixing issues and updating with 
new features ?  I ask because last commit was 3 weeks ago.
```
---

     
 
all -  [ Langgraph Deployment  ](https://www.reddit.com/r/LangChain/comments/1fs3sli/langgraph_deployment/) , 2024-10-02-0912
```
For those who have deployed Langgraph custom application with fastapi, how did you do it? How do you support streaming. 
I would love to here how you did this. Any examples would be appreciated.
```
---

     
 
all -  [ What are pros and cons of Lang graph vs Llama index Multiple Agent systems ? ](https://www.reddit.com/r/LangChain/comments/1fs3qn9/what_are_pros_and_cons_of_lang_graph_vs_llama/) , 2024-10-02-0912
```
# What are pros and cons of Lang graph vs Llama index Multiple Agent systems ?


```
---

     
 
MachineLearning -  [ Built a web agent which call fill Google forms based on the user details [P] ](https://www.reddit.com/r/MachineLearning/comments/1fozud5/built_a_web_agent_which_call_fill_google_forms/) , 2024-10-02-0912
```
GitHub repo : [https://github.com/shaRk-033/web-agent](https://github.com/shaRk-033/web-agent)

Tried to solve it using 
two approaches:

# 1: Basic Scraping and Filling

This is the straightforward approach. The agent scrapes the form‚Äôs HTM
L and uses fixed XPaths to find and fill in the required fields.

* It pulls the form‚Äôs HTML, locates the fields with se
t XPaths, and inputs the answers. It‚Äôs a direct and simple method.
* If the form changes or an element isn‚Äôt where it‚Äôs 
expected, the process can fail and may need manual adjustments.

[basic approach](https://preview.redd.it/5e8g4a1k4xqd1.
png?width=1055&format=png&auto=webp&s=d8e984e4feaee2f0453b08c8696768c40a2a5c20)

2. Using LangChain Agents and tool call
ing

* LangChain Agent**:**¬†The agent handles everything by using the LLM‚Äôs reasoning to decide what to do next, includi
ng generating those tricky XPaths.
* Error Handling**:**¬†If something goes wrong (like an element not found), the agent 
tries again with better XPaths until it gets the job done.

[using langchain agents](https://preview.redd.it/948i88pl4xq
d1.png?width=782&format=png&auto=webp&s=ed1e6c19efec9f4cbbbd6ab5a22558f221cf745f)

Any recommendations to improve this w
ould be welcome. Also, if anyone has ideas on building similar web agents to automate other tasks, it would be great to 
hear them. :)
```
---

     
 
MachineLearning -  [ [P] Swapping Embedding Models for an LLM ](https://www.reddit.com/r/MachineLearning/comments/1fktvbj/p_swapping_embedding_models_for_an_llm/) , 2024-10-02-0912
```
How tightly coupled is an embedding model to a language model?

Taking an example from Langchain's tutorials, they use O
llama's _nomic-embed-text_ for embedding and _Llama3.1_ for the understanding and Q/A. I don't see any documentation abo
ut Llama being built on embeddings from this embedding model. 

Intuition suggests that a different embedding model may 
produce outputs of other sizes or produce a different tensor for a character/word, which would have an impact on the res
ults of the LLM. So would changing an embedding model require retraining/fine-tuning the LLM as well?

I need to use a e
mbedding model for code snippets and text. Do I need to find a specialized embedding model for that? If yes, how will ll
ama3.1 ingest the embeddings?
```
---

     
 
MachineLearning -  [ [P] Review and suggest ideas for my chatbot ](https://www.reddit.com/r/MachineLearning/comments/1fb2mwl/p_review_and_suggest_ideas_for_my_chatbot/) , 2024-10-02-0912
```
Ok, so I am currently trying to build support chatbot with following technicalities 
1. FastAPI for web server(Need to m
ake it faster)
2. Qdrant as Vector Data Base(Found it to be the fastest amongst Chromadb, Elastic Search and Milvus)
3. 
MongoDB for storing all the data and feedback.
4. Semantic chunking with max token limit of 512.
5. granite-13b-chat-v2 
as the LLM(I know it's not good but I have limited options available)
6. The data is structured as well as unstructured.
 Thinking of having involving GraphRAG with current architecture.
7. Multiple data sources stored in multiple collection
s of vector database because I have implemented an access control.
8. Using mongoengine currently as a ORM. If you know 
something better please suggest.
9. Using all-miniLM-l6-v2 as vector embedding currently but planning to use stella_en_4
00M_v5.
10. Using cosine similarity to retrieve the documents.
11. Using BLEU, F1 and BERT score for automated evaluatio
n based on golden answer.
12. Using top_k as 3.
13. Currently using basic question answering prompt but want to improve 
it. Any tips? Also heard about Automatic Prompt Evaluation.
14. Currently using custom code for everything. Looking to u
se Llamaindex or Langchain for this. 
15. Right now I am not using any AI Agent, but I want to know your opinions. 
16. 
It's a simple RAG framework and I am working on improving it.
17. I haven't included reranker but I am planning to do so
 too.

I think I mentioned pretty much everything I am using for my project. So please share your suggestions, comments 
and reviews for the same. Thank you!!
```
---

     
 
MachineLearning -  [ [P] Lessons from Retrieval Augmented Generation ](https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/) , 2024-10-02-0912
```
I implemented Rag in my organization and just wrote a blog about what we learned here:   
[https://www.b-yond.com/post/t
ransforming-telco-troubleshooting-our-journey-building-telcogpt-with-rag](https://www.b-yond.com/post/transforming-telco
-troubleshooting-our-journey-building-telcogpt-with-rag)

Hoping it would be helpful for those in this area. Covers rag 
evaluation (ragas), sql db, langchain agents vs chains, weaviate vector db, hybrid search, reranking, and more.

Some ad
ditional insights on ranking and hybrid search here:

[https://www.linkedin.com/posts/drzohaib\_transforming-telco-troub
leshooting-our-journey-activity-7232072089837486081--Le1?utm\_source=share&utm\_medium=member\_android](https://www.link
edin.com/posts/drzohaib_transforming-telco-troubleshooting-our-journey-activity-7232072089837486081--Le1?utm_source=shar
e&utm_medium=member_android)
```
---

     
 
deeplearning -  [ What is the best approach for Parsing and Retrieving Code Context Across Multiple Files in a Hierarc ](https://www.reddit.com/r/deeplearning/comments/1fh58oz/what_is_the_best_approach_for_parsing_and/) , 2024-10-02-0912
```
I want to implement a Code-RAG system on a code directory where I need to:

* Parse and load all the files from folders 
and subfolders while excluding specific file extensions.
* Embed and store the parsed content into a vector store.
* Ret
rieve relevant information based on user queries.

However, I‚Äôm facing two major challenges:

**File Parsing and Loading
:**¬†What‚Äôs the most efficient method to parse and load files in a hierarchical manner (reflecting their folder structure
)? Should I use Langchain‚Äôs directory loader, or is there a better way? I came across the Tree-sitter tool in Claude-dev
‚Äôs repo, which is used to build syntax trees for source files‚Äîwould this be useful for hierarchical parsing?

**Cross-Fi
le Context Retrieval:**¬†If the relevant context for a user‚Äôs query is spread across multiple files located in different 
subfolders, how can I fine-tune my retrieval system to identify the correct context across these files? Would reranking 
resolve this, or is there a better approach?

**Query Translation:**¬†Do I need to use Something like Multi-Query or RAG-
Fusion to achieve better retrieval for hierarchical data?

\[I want to understand how tools like¬†[continue.dev](http://c
ontinue.dev/)¬†and¬†[claude-dev](https://github.com/saoudrizwan/claude-dev)¬†work\]
```
---

     
 
deeplearning -  [ Month of August in AI ](https://www.reddit.com/r/deeplearning/comments/1f6zfz0/month_of_august_in_ai/) , 2024-10-02-0912
```
üîç¬†I**nside this Issue:**

* ü§ñ¬†La*test Breakthroughs:¬†*This month it‚Äôs all about¬†A*gents, LangChain RAG, and LLMs evaluat
ion challenges.*
* üåê¬†AI Monthly News:¬†Discover how these stories are revolutionizing industries and impacting everyday l
ife:¬†E*U AI Act, California‚Äôs Controversial SB1047 AI regulation act, Drama at OpenAI, and possible funding at OpenAI by
 Nvidia and Apple.*
* üìö¬†Editor‚Äôs Special:¬†This covers the interesting talks, lectures, and articles we came across recen
tly.

Follow me on Twitter and LinkedIn at¬†[**RealAIGuys**](https://twitter.com/RealAIGuys)¬†and¬†[**AIGuysEditor**](https
://www.linkedin.com/in/vishal-rajput-999164122/) to get insight on new AI developments.

>**Please don't forget to subsc
ribe to our Newsletter:** [**https://medium.com/aiguys/newsletter**](https://medium.com/aiguys/newsletter)

# Latest Bre
akthroughs

Are Agents just simple rules? Are Agents just enhanced reasoning? The answer is yes and no. Yes, in the sens
e that agents have simple rules and can sometimes enhance reasoning capabilities compared to a single prompt. But No in 
the sense that agents can have a much more diverse functionality like using specific tools, summarizing, or even followi
ng a particular style. In this blog, we look into how to set up these agents in a hierarchal manner just like running a 
small team of Authors, researchers, and supervisors.

[**How To Build Hierarchical Multi-Agent Systems?**](https://mediu
m.com/aiguys/how-to-build-hierarchical-multi-agent-systems-dc26b19201d2?sk=90958e39e1a28f5030872a90f8e3f3da)

**TextGrad
**. It is a powerful framework performing automatic ‚Äúdifferentiation‚Äù via text.¬†**It backpropagates textual feedback pro
vided by LLMs to improve individual components of a compound AI system.**¬†In this framework, LLMs provide rich, general,
 natural language suggestions to optimize variables in computation graphs, ranging from code snippets to molecular struc
tures. TextGrad showed effectiveness and generality across various applications, from question-answering and molecule op
timization to radiotherapy treatment planning.

[**TextGrad: Improving Prompting Using AutoGrad**](https://medium.com/ai
guys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10?sk=3633a9aa63b884c97469bce659265921)

The addition of RAG t
o LLMs was an excellent idea. It helped the LLMs to become more specific and individualized. Adding new components to an
y system leads to more interactions and its own sets of problems. Adding RAG to LLMs leads to several problems such as h
ow to retrieve the best content, what type of prompt to write, and many more.

In this blog, we are going to combine the
¬†**LangChain RAG with DSPy**. We deep dive into how to evaluate the RAG pipeline quantitatively using¬†**RAGAs**¬†and how 
to create a system where instead of manually tweaking prompts, we let the system figure out the best prompt.

[**How To 
Build LangChain RAG With DSPy?**](https://medium.com/aiguys/how-to-build-langchain-rag-with-dspy-ce9154fbafaa?sk=b41d104
05f84c767cf9cd6a58d1ebac0)

As the field of natural language processing (NLP) advances, the evaluation of large language
 models (LLMs) like GPT-4 becomes increasingly important and complex. Traditional metrics such as accuracy are often ina
dequate for assessing these models‚Äô performance because they fail to capture the nuances of human language. In this arti
cle, we will explore why evaluating LLMs is challenging and discuss effective methods like BLEU and ROUGE for a more com
prehensive evaluation.

[**The Challenges of Evaluating Large Language Models**](https://medium.com/aiguys/the-challenge
s-of-evaluating-large-language-models-ec2eb834a349)

# AI Monthly News

# AI Act enters into force

On 1 August 2024, th
e European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelli
gence development and deployment in the EU. The AI Act introduces a uniform framework across all EU countries, based on 
a forward-looking definition of AI and a risk-based approach:

* **Minimal risk:**¬†most AI systems such as spam filters 
and AI-enabled video games face no obligation under the AI Act, but companies can voluntarily adopt additional codes of 
conduct.
* **Specific transparency risk:**¬†systems like chatbots must clearly inform users that they are interacting wit
h a machine, while certain AI-generated content must be labelled as such.
* **High risk:**¬†high-risk AI systems such as 
AI-based medical software or AI systems used for recruitment must comply with strict requirements, including risk-mitiga
tion systems, high-quality of data sets, clear user information, human oversight, etc.
* **Unacceptable risk:**¬†for exam
ple, AI systems that allow ‚Äúsocial scoring‚Äù by governments or companies are considered a clear threat to people‚Äôs fundam
ental rights and are therefore banned.

**EU announcement:**¬†[**Click here**](https://commission.europa.eu/news/ai-act-e
nters-force-2024-08-01_en)

https://preview.redd.it/nwyzfzgm4cmd1.png?width=828&format=png&auto=webp&s=c873db37ca0dadd5b
510bea70ac9f633b96aaea4

# California AI bill SB-1047 sparks fierce debate, Senator likens it to ‚ÄòJets vs. Sharks‚Äô feud


**Key Aspects of SB-1047:**

* Regulation Scope: Targets ‚Äúfrontier‚Äù AI models, defined by their immense computational t
raining requirements (over 10¬≤‚Å∂ operations) or significant financial investment (>$100 million).
* Compliance Requiremen
ts: Developers must implement safety protocols, including the ability to immediately shut down, cybersecurity measures, 
and risk assessments, before model deployment.
* Whistleblower Protections: Encourages reporting of non-compliance or ri
sks by offering protection against retaliation.
* Safety Incident Reporting: Mandates reporting AI safety incidents with
in 72 hours to a newly established Frontier Model Division.
* Certification: Developers need to certify compliance, pote
ntially under penalty of perjury in earlier drafts, though amendments might have altered this.

**Pros:**

* Safety Firs
t: Prioritizes the prevention of catastrophic harms by enforcing rigorous safety standards, potentially safeguarding aga
inst AI misuse or malfunction.
* Incentivizes Responsible Development: By setting high standards for AI model training, 
the company encourages developers to think critically about the implications of their creations.
* Public Trust: Enhance
s public confidence in AI by ensuring transparency and accountability in the development process.

**Cons:**

* Innovati
on Stagnation: Critics argue it might stifle innovation, especially in open-source AI, due to the high costs and regulat
ory burdens of compliance.
* Ambiguity: Some definitions and requirements might be too specific or broad, leading to leg
al challenges or unintended consequences.
* Global Competitiveness: There‚Äôs concern that such regulations could push AI 
development outside California or the U.S., benefiting other nations without similar restrictions.
* Implementation Chal
lenges: The practicalities of enforcing such regulations, especially the ‚Äúpositive safety determination,‚Äù could be compl
ex and contentious.

**News Article:**¬†[**Click here**](https://www.thenation.com/article/society/sb-1047-ai-big-tech-fi
ght/)

**Open Letter:**¬†[**Click here**](https://safesecureai.org/open-letter)

https://preview.redd.it/ib96d7nk4cmd1.pn
g?width=828&format=png&auto=webp&s=0ed5913b5dae72e203c8592393e469d9130ed689

# MORE OpenAI drama

OpenAI co-founder John
 Schulman has left the company to join rival AI startup Anthropic, while OpenAI president and co-founder Greg Brockman i
s taking an extended leave until the end of the year. Schulman, who played a key role in creating the AI-powered chatbot
 platform ChatGPT and led OpenAI‚Äôs alignment science efforts, stated his move was driven by a desire to focus more on AI
 alignment and hands-on technical work. Peter Deng, a product manager who joined OpenAI last year, has also left the com
pany. With these departures, only three of OpenAI‚Äôs original 11 founders remain: CEO Sam Altman, Brockman, and Wojciech 
Zaremba, lead of language and code generation.

**News Article:**¬†[**Click here**](https://techcrunch.com/2024/08/05/ope
nai-co-founder-leaves-for-anthropic/)

https://preview.redd.it/0vdjc18j4cmd1.png?width=828&format=png&auto=webp&s=e9de60
4c26aed3e47b50df3bdf114ef61f967080

# Apple and Nvidia may invest in OpenAI

Apple, which is planning to integrate ChatG
PT into iOS, is in talks to invest. Soon after,¬†[*Bloomberg*¬†also](https://www.bloomberg.com/news/articles/2024-08-29/nv
idia-has-held-discussions-about-joining-openai-s-funding-round?srnd=homepage-americas)¬†reported that Apple is in talks b
ut added that Nvidia ‚Äúhas discussed‚Äù joining the funding round as well. The round is reportedly being led by Thrive Capi
tal and would value OpenAI at more than $100 billion.

**News Article:**¬†[**Click here**](https://www.theverge.com/2024/
8/29/24231626/apple-nvidia-openai-invest-microsoft)

https://preview.redd.it/ude6jguh4cmd1.png?width=828&format=png&auto
=webp&s=3603cbca0dbb1be3e6d0efcf06c3a698428bbdd6

# Editor‚Äôs Special

* The AI Bubble: Will It Burst, and What Comes Aft
er?:¬†[**Click here**](https://www.youtube.com/watch?v=91SK90SahHc&t=317s)
* Eric Schmidt Full Controversial Interview on
 AI Revolution (Former Google CEO):¬†[**Click here**](https://www.youtube.com/watch?v=mKVFNg3DEng)
* AI isn‚Äôt gonna keep 
improving¬†[**Click here**](https://www.youtube.com/watch?v=Y8Ym7hMR100)
* General Intelligence: Define it, measure it, b
uild it:¬†[**Click here**](https://www.youtube.com/watch?v=nL9jEy99Nh0)
```
---

     
