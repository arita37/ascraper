 
all -  [ User authorization and feedback before executing a Tool in Langgraph ](https://www.reddit.com/r/LangChain/comments/1ewflik/user_authorization_and_feedback_before_executing/) , 2024-08-20-0911
```
Hi, I have a chatbot that consists of a basic graph where I have a node that calls that LLM and another node that execut
es the tools.  
But I need the user to authorize the execution of the tool first. For this, I need to show the user the 
tool that is about to execute and its arguments, the user can then read what the agent is about to do and could change t
he tool or one of the args by giving feedback. However, all of the information that is shown so that the user can accept
 it needs to be in a user-friendly way. Does anyone know how to do this?
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses ](https://www.reddit.com/r/udemyfreebies/comments/1ewfiwt/list_of_free_and_best_selling_discounted_courses/) , 2024-08-20-0911
```
# Udemy Free Courses for 20 August 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the c
ourses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13301/)The Complete Mailchimp Email Marketing Cour
se for 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13300/)Amazon Marketing PPC 2024 ‚Äì The Complete Amazon A
ds Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13299/)Amazon FBA Course ‚Äì How to Sell on Amazon MASTERY 2
024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13302/)Facebook Ads & Facebook Marketing MASTERY 2024 | Coursenv
y
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13297/)Building a Strong Opening Repertoire
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/13296/)Python. Estructuras de datos y algoritmos en Python
* [REDEEM OFFER ](https://idown
loadcoupon.com/udemy/13298/)Social Media Marketing MASTERY 2024 | Ads on 10 Platforms
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/13294/)Project Management Professional ‚Äì PMP ‚ÄúPMBOK 6th edition‚Äù
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/13295/)Master 100 New AI Tools: The Ultimate Productivity Course
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/13292/)Azure Solutions Architect Certification: The Ultimate Bundle
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/13291/)Morning Meditation | Best Guided Meditation Under 10 Minutes
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/13293/)Django Masterclass : Build 9 Real World Django Projects
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/12239/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/13290/)Curso PSeInt algoritmos y l√≥gica de programaci√≥n
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13288
/)70-236: Microsoft Exchange Server 2007 Practice Test 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13289/)6
00 Servlet Interview Questions Practice Test
* 70-347: Enabling Office 365 Services Practice Test 2024
* [REDEEM OFFER](
https://idownloadcoupon.com/udemy/13287/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9851/)Excel Certification 
Exam Preparation: 4 Practice Tests 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8966/)Business Analyst Certi
ficate
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12622/)Construction Drawing Reading
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/10089/)Professional Certificate of Executive Business Assistant
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/7487/)Professional Certificate: Digital Business & Unit Economics
* [REDEEM OFFER ](https://idown
loadcoupon.com/udemy/1382/)Media Training for Authors: Promote Your Book in the News
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/3704/)The Guide to Freelancing in the Modern Gig Economy
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/7394/)Personal Branding: You Deliver a Great Elevator Pitch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/66
78/)Media Training for Doctors/Healthcare Pros: Master the Media
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/101
22/)Professional Certificate in Procurement and Purchasing
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1385/)Med
ia Training for Financial Service Professionals
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/6721/)Adobe Photosho
p CC For Absolute Beginner to Advanced
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12267/)Scrum Master Certifica
tion 2024 Agile Scrum Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13283/)Programming PLC Using Tex
t Commands ‚Äì Mnemonic Language
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10091/)Executive Diploma in Human Res
ources Strategy
* Professional PCB Fabrication For Everyone
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/13284/)
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10798/)YouTube Startrack For Beginners: Launch Your Channel Today
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/8274/)Google Analytics 4 (GA4) Certification. How to Pass the Exam
* [R
EDEEM OFFER ](https://idownloadcoupon.com/udemy/9824/)Amazon FBA Guide: From Zero to Seller
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/9689/)Upgrade Your Social Media Presence with ChatGPT
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/6606/)Ultimate Adobe Photoshop CC Masterclass Basics To Advanced
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/8270/)Instagram Marketing. How to Promote Your Business!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1323
8/)The Complete React Course: Become a Pro in No Time
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8273/)SEO Stra
tegy 2024. SEO training to Unleash Career Potential!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7356/)Project M
anagement Fundamentals: A Beginner‚Äôs Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7357/)Facebook Marketing 
2024. Promote Your Business on Facebook!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13282/)Veeam Certified Engi
neer (VMCE) Practice Exam ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13281/)Learn Carnatic Flute | Swati
 Tirunal Krithis ‚Äì Vol 1
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13280/)ÿ•ÿ≠ÿ™ÿ±ÿßŸÅ ÿßŸÑÿ™ÿØŸàŸäŸÜ ÿ®ÿ•ÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®ŸÑŸàÿ¨ÿ±
* [RED
EEM OFFER ](https://idownloadcoupon.com/udemy/9548/)Fundamentos de los Frameworks Web en Go
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/11983/)Research Methodologies in Strategy and Product Development
* Docker and Kubernetes Master
class for Beginners in 2024
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/4637/)
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/4199/)Ethical Hacking: AI Chatbots
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/3083/)Ultimate 
Guide to Product Design: Design Thinking Approach
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10051/)Learn Filmo
ra Video Editing Masterclass From Beginner to Pro
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/6651/)Python Guide
d Project: Building Tic-Tac-Toe from Scratch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13279/)PMI-ACP Exam Pre
p ‚Äì Practice Tests
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13277/)How Websites Work
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/13278/)Professional Diploma in Administration Management
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/13275/)Learn Carnatic Flute | Intermediate Level | Varnams Vol ‚Äì 16
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/13276/)Create a GUI with Python
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11301/)Excel for Ev
eryone: Essential Skills for Work and Life
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/4087/)WhatsApp Chat Senti
ment Analysis Using Machine Learning
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11150/)Gatsby JS | Build a pers
onal blog using gatsbyJS
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8185/)Social Media Bots with Python
* [REDE
EM OFFER ](https://idownloadcoupon.com/udemy/11295/)Complete Portfolio Website Using HTML CSS NETLIFY Project
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/9746/)Ethical Hacking: Hacker Methodology
* Excel files with Python
* [REDEEM 
OFFER](https://idownloadcoupon.com/udemy/12488/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10392/)Universidad 
Desarrollo Web ‚Äì FrontEnd Web Developer!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10390/)Java en 13 D√≠as con 
Aplicaciones del Mundo Real
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10399/)Universidad JavaScript ‚Äì De Cero 
a Experto JavaScript!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10395/)Universidad de L√≥gica de Programaci√≥n ‚Äì
 Aprende 7 Lenguajes!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11682/)Python con la IA ChatGPT ‚Äì Aprende Pyth
on de Cero a Experto
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12957/)Universidad Python ‚Äì Cero a Experto ‚Äì Ac
tualizado ( 84 hrs)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11683/)Universidad Java Cero a Experto Actualiza
do 2024 ( 150 hrs)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10391/)Universidad Angular ‚Äì De Cero a Experto en
 Angular!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/6292/)Yoga For a Healthy Back
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/10397/)Club Java Master ‚Äì Novato a Experto Java +110hrs Actualizado
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/10400/)Universidad de Programaci√≥n ‚Äì Python, Java, C y C++ ‚Äì 2024
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/13273/)Zbrush Sculpting: Learn Sculpting the Human Head in Zbrush
* [REDEEM OFFER ](https://idownl
oadcoupon.com/udemy/13272/)Product Owner Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13271/)CapCut
 Video Editing Bootcamp: CapCut Basic to Advanced
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12495/)Oracle Java
 Certification Exam OCA 1Z0-808 Preparation Part3
* Javascript For Beginners Complete Course
* [REDEEM OFFER](https://id
ownloadcoupon.com/udemy/12731/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9463/)Master Scrum Basics
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/11141/)Advanced Scrum Master Certification
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/13132/)ChatGPT for Product Management

GET MORE FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](htt
ps://idownloadcoupon.com/)
```
---

     
 
all -  [ [2 YoE, Unemployed, Data Scientist/Data Analyst, United States ] ](https://www.reddit.com/r/resumes/comments/1ewb9uj/2_yoe_unemployed_data_scientistdata_analyst/) , 2024-08-20-0911
```
Hello everyone,

I am a recent graduate joining in the pool of full time job seekers.

Background: I am 26 years old, in
ternational student, looking to break into the data field in US. While my masters is Mechanical Engineering on paper, I 
took up courses and projects in the ML and AI domain. My thesis is in Computer Vision, nothing ground-breaking, but a go
od project using Segmentation.

My 'Data Scientist' experience is a part time program in my university which collaborate
s with a large pharma industry, where I worked and gained a lot of knowledge/experience in the Data Science area.

I nee
d an opinion on my resume and the blunders it contains (if any), and the things that I can improve. I also hope I have s
howcased my skills and expeience in the best manner possible, despite coming from a mechanical background. If not, pleas
e let me know your thoughts.

Thanks for your time.

https://preview.redd.it/xehu713vdojd1.jpg?width=1930&format=pjpg&au
to=webp&s=69131fcb22c88839654c4fb15842902231a20583


```
---

     
 
all -  [ Building GPT Document Bot ](https://www.reddit.com/r/learnpython/comments/1ewb6vh/building_gpt_document_bot/) , 2024-08-20-0911
```
For my job, I write hundreds of proposals for government contracts. I want to use an OpenAI API to build a tool that loo
ks over a database of previous proposals (csv, txt, etc.), takes in a single proposal request, and outputs a response fo
r that request. Most of these proposals are around 100 pages and I would like to to output a proposal that is \~70 pages
. For context, I have some basic python experience, but I am unsure of exactly how to go about this. Some forums that I 
read suggested that I use langchain to comb through super long text files. My long term goal is to build a simple GUI an
d dashboard to make it accessible to others in my company and online. How should I go about this? Also, which LLM model 
should I use? Thanks!
```
---

     
 
all -  [ Working On a Langchain based AI chat agent ](https://www.reddit.com/r/LangChain/comments/1ewam8d/working_on_a_langchain_based_ai_chat_agent/) , 2024-08-20-0911
```
I am new software engineering. I am building the entire system from scratch. I was wondering how to manage the security 
of the app. Things like login and stuff (authentication). Would appreciate any open souce technologies/resources. Thanks
 in Advance
```
---

     
 
all -  [ Agents for problem with a deterministic, verifiable, but non-exhaustive answers ](https://www.reddit.com/r/LangChain/comments/1ew9jzd/agents_for_problem_with_a_deterministic/) , 2024-08-20-0911
```
I'm curious if any how has looked at applying agents to problems with deterministic but non-exhaustive answers? My use c
ase is around planning/estimation for repair processes(boats, cars, planes, etc). Similar to the idea [making a sandwich
 from scratch](https://www.theverge.com/2015/9/17/9344597/man-spent-six-months-1500-making-sandwich-from-scratch), there
 might be always another layer of granularity you could expand to. Has anyone worked on a similar use case where a core 
task of an agent is reasoning/judging if an answer is 'good enough/complete enough'? 
```
---

     
 
all -  [ Using GraphRAG and Reinforcement Learning ](https://www.reddit.com/r/LangChain/comments/1ew99s7/using_graphrag_and_reinforcement_learning/) , 2024-08-20-0911
```
Hi, these are two questions bundled into one.  
I'm supposed to create an LLM that gives users suggestions on the projec
t they are working.  
I'm also supposed to add a feedback loop that can improve the model response over time.  
  
So I 
can't just change the LLM model iteratively because I will be using an LLM through api.  
I figured that I could change 
the data I passed to the llm as context through RAG.  
That's when GPT suggested using neo4j's GraphRAG as we can change
 the weights of the data connections and also trace the part of the data we find faulty easily.  
  
This is what it sai
d  
  
After the AI provides a suggestion, monitor its effectiveness. If users frequently make certain changes or follow
 specific advice, reinforce those connections in your system, making them more prominent in future predictions. This cou
ld involve revisiting and adjusting the strength of connections within your knowledge graph. Use RL algorithms like Q-le
arning or policy gradients to adjust the weights

  
I'm new to Graph databases and RL and I'm wondering how to proceed.
 If so can you please provide suggestions/resources on how to implement the two or any better alternative to this method
?
```
---

     
 
all -  [ OSS AI powered by what you've seen, said, or heard. Works with local LLM, Windows, MacOS, Linux. Wri ](https://v.redd.it/qvhw94paxnjd1) , 2024-08-20-0911
```

```
---

     
 
all -  [ Interactive Iowa Liquor Sales Dashboard with AI-Powered Chatbot ](https://www.reddit.com/r/u_ricmwas2019/comments/1ew7vxr/interactive_iowa_liquor_sales_dashboard_with/) , 2024-08-20-0911
```
  
I'm excited to share my latest project: an interactive dashboard analyzing Iowa Liquor Retail Sales, enhanced with an
 AI-powered chatbot for natural language queries.  
Project Overview  
  
Dashboard: Visualizes sales data by product, y
ear, and region using Plotly Dash  
Chatbot: Utilizes Claude API to answer questions by querying BigQuery data  
Data So
urce: Iowa Liquor Retail Sales  
Live Demo: [http://104.197.202.155:8080/](http://104.197.202.155:8080/)  
GitHub Reposi
tory: [https://github.com/RicmwasData/plotly-dash-llm/tree/master](https://github.com/RicmwasData/plotly-dash-llm/tree/m
aster)  
  
Key Features  
  
Interactive visualizations of sales trends  
AI-powered chatbot for natural language data 
queries  
Integration with BigQuery for efficient data retrieval  
Hosted on Google Cloud Platform (GCP) for scalability
  
  
Technologies Used  
  
Python  
Plotly Dash  
BigQuery  
Langchain  
Large Language Models (LLM)  
Google Cloud Pl
atform (GCP)  
Git & GitHub
```
---

     
 
all -  [ [1 YoE, Unemployed (full time student), Software Engineer, USA] ](https://i.redd.it/utvrmkxfcnjd1.jpeg) , 2024-08-20-0911
```
Targeting SWE positions from really any industry, of course my dream is land a job in big tech but not really likely con
sidering the market which is fine. Based in NY but applying to pretty much everywhere in the US. 

I graduate with my MS
 in CS in May 2025. Last year, I was searching for internships and barely received any interviews. I‚Äôve since modified m
y resume (I did get an internship but it was through a referral) so looking for some feedback before I begin applying fo
r full time jobs for next year.

BTW, I am a US citizen.
```
---

     
 
all -  [ Sentence Transformers Inference API ](https://www.reddit.com/r/LangChain/comments/1ew5zl1/sentence_transformers_inference_api/) , 2024-08-20-0911
```
Hi,

I want to load my reranking models faster, e.g. with an API.

I am using HuggingfaceEmbeddings with:

    HuggingFa
ceInferenceAPIEmbeddings

I am also using a reranking model which I am loading like this: 

    from sentence_transforme
rs import CrossEncoder
    
    reranking_model = CrossEncoder('BAAI/bge-reranker-v2-m3', max_length=512, device='mps')

    
    query = 'Ich liebe Fu√üball'
    
    page_contents = [
        'Hallo wer bist du',
        'Fu√üball is so geil
 ey',
        'Fu√üball ist der coolste Sport',
        'Hamburg liegt in Deutschland',
        ]
    re_res = reranking_
model.rank(query=query, documents=page_contents, return_documents=True, top_k=2)
    #[{'corpus_id': 1, 'score': 0.89757
94, 'text': 'Fu√üball is so geil ey'},
     #{'corpus_id': 2, 'score': 0.2194788, 'text': 'Fu√üball ist der coolste Sport'
}]

This works fine on my Mac, however when loading it in a docker it takes ages to build as the 'mps' device is not ava
ilable. 

  
So is anyone aware of a Sentece Transformers Inference API like the HuggingfaceInferenceAPIEmbeddings? Or c
an I rerank the docs the HuggingfaceInferenceAPIEmbeddings class?
```
---

     
 
all -  [ Offering Free QA Testing for Your LLM/Chatbot! ](https://www.reddit.com/r/LangChain/comments/1ew0ldg/offering_free_qa_testing_for_your_llmchatbot/) , 2024-08-20-0911
```
Hey everyone,

If you‚Äôve been developing a language model (LLM) or chatbot and need someone to help with QA testing, I‚Äôm
 here to help! I‚Äôve got experience building chatbots, and I‚Äôm offering to test your model **for free.** Whether you‚Äôre l
ooking for feedback on performance, functionality, or edge cases, I‚Äôm happy to assist.

Just DM me with your requirement
s and what you‚Äôd like me to focus on, and we can get started. I can provide detailed reports, suggestions for improvemen
t, or just general user experience feedback‚Äîwhatever you need.  
  
Cheers!
```
---

     
 
all -  [ Which of the following topics would you like to learn more about: ](https://www.reddit.com/r/LangChain/comments/1evzg1v/which_of_the_following_topics_would_you_like_to/) , 2024-08-20-0911
```


[View Poll](https://www.reddit.com/poll/1evzg1v)
```
---

     
 
all -  [ Deploying Finetuned Llama 3.1 8b - Fast API ](https://www.reddit.com/r/LangChain/comments/1evxztg/deploying_finetuned_llama_31_8b_fast_api/) , 2024-08-20-0911
```
I am using LangGraph and I am struggling to understand after finetuning the model, how and where can I access the model,
 specifically deploying it and using it with API for lowest latency
```
---

     
 
all -  [ Which llm has good Function calling and reasoning ability in the llm with minimum cost ? ](https://www.reddit.com/r/LangChain/comments/1evw7on/which_llm_has_good_function_calling_and_reasoning/) , 2024-08-20-0911
```
I am working on a project where I need a LLM which must have good function calling ability like the order should be corr
ect to get the appropriate result and very good reasoning ability to look into the json response of the tools/functions 
and answer the user queries. The cost should be minimum as well. 

Can anyone suggest any LLMs like this ??
```
---

     
 
all -  [ [2 YoE, Unemployed, Python Backend Gen AI and Machine Learning, Islamabad Pakistan] ](https://www.reddit.com/r/resumes/comments/1evupil/2_yoe_unemployed_python_backend_gen_ai_and/) , 2024-08-20-0911
```
https://preview.redd.it/dci70welekjd1.png?width=1653&format=png&auto=webp&s=1adc39ea854531e2731e76662fe2819554ee14ce


```
---

     
 
all -  [ Need suggestions for an AI project ](https://www.reddit.com/r/LangChain/comments/1evuki4/need_suggestions_for_an_ai_project/) , 2024-08-20-0911
```
Hi everyone, I am working on a Code Assistant project. The goal is to create a code assistant specific to a library, for
 example Pandas(Just an example). There are a lot of codes available online which I could use by scraping and using it a
s the training dataset. The problem arises with the different versions. With new versions, some functions deprecate. So 
our current code assistants trained on old data, couldn't pick this up. I want to make a Code Assistant, which could lea
rn from the documentations, function signatures and understand which version of library we're using. Ideally I want the 
Code Assistant to pickup the version of library in the environment, then write code based on it. 

For this, I am curren
tly generating synthetic data by making a template functions and prompts and generate variations using a LLM. But this i
s not a good way, as I have to manually implement each function test case and it's prompt template. I am looking for a b
etter way to do this.
```
---

     
 
all -  [ Are there any good packages for LLM Security? Seeking guidance regarding LLM-Guard ](https://www.reddit.com/r/LangChain/comments/1evtx9o/are_there_any_good_packages_for_llm_security/) , 2024-08-20-0911
```
I am building a chatbot based on langchain with OpenAI as provider for my embeddings and GPT 4O for the LLM, I would lik
e to have a layer of security for my application that is extensible and integrates well with langchain, One such package
 is [LLM-Guard](https://llm-guard.com) from [protect.ai](https://protect.ai). It allows us to individually check the pro
mpt before it touches the langchain logic, which is great and has a lot of features as well. It is all well and good for
 a single request but the processing for subsequent requests is very slow, every time a query is validated the models ar
e loaded into the memory and immediately flushed out as well, this adds a lot of latency when processing multiple reques
ts, is there any way to overcome this issue in LLM Guard. Are there any other packages that would serve a similar functi
onality to add a Security Layer
```
---

     
 
all -  [ What are your RAG parameters e.g. top k, chunk size, chunk overlap? ](https://www.reddit.com/r/LangChain/comments/1evtu7d/what_are_your_rag_parameters_eg_top_k_chunk_size/) , 2024-08-20-0911
```
I know this will vary between use cases and depend on a host of factors, but folks, what are the parameters that y'all u
se in your production RAG app?

I'll go first.

* use case: company's internal knowledge management chatbot
* top k = 5

* chunk size & overlap = 2000 & 200 using Recursive Text Splitter

Obviously, these are just a few of the many parameter
s in a RAG app, so feel free to provide other parameters or information about your use case.
```
---

     
 
all -  [ better data retrieval under RAG mode ](https://www.reddit.com/r/LangChain/comments/1evtt98/better_data_retrieval_under_rag_mode/) , 2024-08-20-0911
```
I am currently trying to build a chatbot that could generate test cases for products. my idea now is to feed it some man
-made test cases and product spec for certain devices and ask the LLM to reference them and generate test cases for some
 other devices. 

I have fed some Json structured test cases (as it is originally table formatted) and the product spec 
(in pure text format). At first, if there's only Json data in the vectorstore, the retrieved data is pretty accurate. Ho
wever, after adding the text data as well, it tends to retrieve more text data than json data, even when I am being quit
e specific (for example, if I ask it to give me some cases under certain class, then it might retrieve text for some rea
son, but if be super specific and tell it to search for json data, then it will look for json data.)

I am using FAISS a
s my vectorstore and I did not use any text splitter for json data (as I want to maintain the format). I am quite new to
 the field so any suggestions on how to improve this will be appreciated!  
  
Thanks! 
```
---

     
 
all -  [ Free Perplexity Clone based on LangGraph Map Reduce ](https://www.reddit.com/r/LangChain/comments/1evp9ca/free_perplexity_clone_based_on_langgraph_map/) , 2024-08-20-0911
```
I attempted to create a perplexity clone using LangGraph Map Reduce and DuckDuckGo search. One of the issues I faced ear
lier was Serper AI and Tavilly Search API only gave a limited number of credits and hence after a point you had to chang
e to a paid version of these APIs. Also the Free Perplexity used the overall search research and page descriptions to pr
ovide results and not going into the details of the page. This project tries to solve these issues.

[https://github.com
/saurabhlalsaxena/Perplexity-Clone-v0.1](https://github.com/saurabhlalsaxena/Perplexity-Clone-v0.1)

Edit: Add a human i
n the loop element on request to ask for clarifying questions where required. I have kept the need for clarifying questi
ons quite stringent. Please feel free to ease them.
```
---

     
 
all -  [ Xpost--AI Talking Heads Help  ](https://www.reddit.com/r/ChatGPT/s/AtTBMeENKq) , 2024-08-20-0911
```
Hoping to find an answer here as I didn't get any in the other subreddit. 


```
---

     
 
all -  [ Spend Ruby Hackathon Project ](https://www.reddit.com/r/myHeadstarter/comments/1evh1p8/spend_ruby_hackathon_project/) , 2024-08-20-0911
```
Hi! We build a complaints detection app for the Spend Ruby track.

* You can add complaints via text, image, and audio
*
 Look at all the complaints in a single table with pagination
* Sort these complaints
* Query these complaints using RAG


Here is our tech stack:

* Next JS - Frontend and backend (it's awesome üôÇ)
* Tailwind CSS + Shadcn - For the UI
* Supa
base - For the database and vector database (awesome SDK)
* Langchain - For the RAG query
* Mistral API - For the text e
mbeddings
* Gemini - For the LLM to process the complaint 

Website: [https://complaints-detection.vercel.app/](https://
complaints-detection.vercel.app/)

GitHub: [https://github.com/Github11200/Ruby-Hackathon-Project](https://github.com/Gi
thub11200/Ruby-Hackathon-Project)

YouTube demo: [https://www.youtube.com/watch?v=Va5uvDIdzXQ](https://www.youtube.com/w
atch?v=Va5uvDIdzXQ)

  
Feel free to ask any questions or give feedback!

[RAG query result](https://preview.redd.it/okn
eqwac0hjd1.png?width=514&format=png&auto=webp&s=90cae4db60f56bb79a39e6afcd23ef381de092f9)

[Complaints dashboard](https:
//preview.redd.it/c9gqawac0hjd1.png?width=2485&format=png&auto=webp&s=faa19dfe54af27da462ab2ff62a7ae7cf4aadf4d)

[Homepa
ge](https://preview.redd.it/nj7c10cc0hjd1.png?width=1274&format=png&auto=webp&s=6b98eaa0a48eb76961a6c6dec9fc7f37c0913df2
)


```
---

     
 
all -  [ How to Fix Slow Finetuned GPT 4o-mini? ](https://www.reddit.com/r/LangChain/comments/1evdvj2/how_to_fix_slow_finetuned_gpt_4omini/) , 2024-08-20-0911
```
I am using LangGraph and I finetuned 4o-mini to decide what tool to call. With 45 high quality examples and 10 for eval.


  
And when using it, with very similar examples to the ones it was finetuned with, it may think 5s and sometimes 0.4s
. How can I fix it so that it won't think so long? Should I finetune it with more data?
```
---

     
 
all -  [ my documents in a different language ](https://www.reddit.com/r/LangChain/comments/1evcdy4/my_documents_in_a_different_language/) , 2024-08-20-0911
```
Hi everyone, I have been building a Adaptive RAG flow using Langraph. My documents are in Turkish Language (a guide abou
t Istanbul for tourists) but peope will ask the questions in English. At this point, How can I get the best answers from
 the RAG pipeline in this case?

On the other hand, is working with pdfs worse for retriever performance?
```
---

     
 
all -  [ Need Advice on Splitting and Retrieving Text for Extracting Experimental Data from Scientific Papers ](https://www.reddit.com/r/LangChain/comments/1evaw9h/need_advice_on_splitting_and_retrieving_text_for/) , 2024-08-20-0911
```
Hi everyone,

I'm working on a project where I need to extract experimental data from multiple scientific papers. The da
ta includes details like particle size, temprature, pore sizes, materials used, synthesis conditions, and more. To achie
ve this, I‚Äôm planning to use LangChain for extracting the data from PDFs.

Here‚Äôs where I need your help:

* **Text Spli
tting:** What‚Äôs the best method and optimal size for splitting the text? Since a single PDF might contain data from mult
iple experiments, I want to ensure that I capture each experiment correctly without losing context.
* **Embedding & Retr
ieval:** What are your suggestions for embedding the data and retrieving it later? I‚Äôm particularly interested in simila
rity search methods or any other techniques that would improve accuracy in finding and extracting relevant data points.


i'm using llama3.1 70b for this if that matters. also i prefer using open-source/free tools rather that openAi stuff

I
‚Äôd really appreciate any tips or advice you can share, especially if you‚Äôve worked on something similar. Thanks in advan
ce!
```
---

     
 
all -  [ [0 YoE, Student/Software Engineering Intern, Software Engineering Intern/ Full-time SWE, USA] ](https://www.reddit.com/r/resumes/comments/1ev9w2d/0_yoe_studentsoftware_engineering_intern_software/) , 2024-08-20-0911
```
I'm aiming for internships at big tech companies like Tesla, Stripe, Salesforce, and the FAANG giants. I‚Äôm based in Bost
on most of the time, but I go back to California during breaks because of family, and I'm open to relocating for the rig
ht opportunity. I‚Äôve applied to over 400 internships, but I‚Äôve only heard back from one. I‚Äôm wondering if maybe there‚Äôs 
too much on my resume, though my college career advisor says it‚Äôs good. Also, I'm an international student, so that's a 
factor too.

https://preview.redd.it/jtx1i5lwhfjd1.png?width=1016&format=png&auto=webp&s=1f0c1a80f5b76ae65344458de5be592
37022150e

  

```
---

     
 
all -  [ Can we use open source llms from hugging face in create_react_agent()? ](https://www.reddit.com/r/LangChain/comments/1ev8w1j/can_we_use_open_source_llms_from_hugging_face_in/) , 2024-08-20-0911
```
I get this error.  
object has no attribute 'bind\_tools'

Take it easy on me. I am noob.
```
---

     
 
all -  [ Best practices for serving Langchain backend as a streaming endpoint in a python env? ](https://www.reddit.com/r/LangChain/comments/1ev8s1h/best_practices_for_serving_langchain_backend_as_a/) , 2024-08-20-0911
```
What would be the best method to serve an agent in python to serve to any chatbot frontend accepting streaming input whi
ch has : 

* low latency
* capable to serve large traffic. 

Flask + .stream() method is the most common way but what pr
actices y'all follow for best prod env
```
---

     
 
all -  [ B.Tech 2025 batch, applied to 100s of positions (internships and fresher roles). ](https://i.redd.it/qmiup14haejd1.jpeg) , 2024-08-20-0911
```
Please provide any suggestion on how to improve my resume. I even tailor it for each opening, and so far only got 2 inte
rviews (one at a very small startup paying 8k a month and another at a decent company but as a freelancer). I'm trying t
o apply for junior full time positions as Im currently working on an early stage startup and its way to risky to only de
pend on that.


```
---

     
 
all -  [ How should my agency workflow be? ](https://www.reddit.com/r/LangChain/comments/1ev5i9k/how_should_my_agency_workflow_be/) , 2024-08-20-0911
```
Hi everyone, I have been developing a customer chatbot for an e-commerce website as a portfolio project to add to my res
ume. With this chatbot, customers will be able to ask their questions about the product, their last purchase and other t
ypes of questions (shipping and payments etc). I decided to use LangGraph's Agents. Adaptive RAG is looking good for thi
s project, but I got confused at some point.

First of all, I have two CSV files to use in RAG. The first one is about t
he technical specification of the products.

And the second one is about the customers (a basic transaction data for eac
h customer).

Should I create 2 different vectorstore or embeed them together in a single vectorstore.

For example when
 I ask the chatbot 'what is technical specification of my last purchased (let's assume an Iphone 15) chatbot should go t
o transaction data and get customers' transaction data and after that go to the technical specification data and respons
e my main question.

When I use a single retreiver for this project chatbot works unstable.

How to be the workflow for 
this project?

I would like your suggestions to improve the project.
```
---

     
 
all -  [ gallama - Guided Agentic Llama ](https://www.reddit.com/r/LangChain/comments/1ev3hri/gallama_guided_agentic_llama/) , 2024-08-20-0911
```
It all started few months ago when i tried to do agentic stuff (langchain, autogen etc) with local LLM. And it was and s
till is so frustrating that most of those framework just straight up not working if the backend changed from OpenAI/ Cla
ude to a local model.

In the quest to make it work with local model, i went to work on to create a backend that help me
 for my agentic needs e.g. function calling, regex format constraints, embedding etc.

[https://github.com/remichu-ai/ga
llama](https://github.com/remichu-ai/gallama)

Here are the list of its features:

* Integrated Model downloader for pop
ular models. (e.g. \`gallama download mistral\`)
* OpenAI Compatible Server
* Legacy OpenAI Completion Endpoint
* Functi
on Calling with all model. (simulate Openai 'auto' mode)
* Thinking Method (example below)
* Mixture of Agents (example 
below, working with tool calling as well)
* Format Enforcement
* Multiple Concurrent Models
* Remote Model Management
* 
Exllama / llama cpp python backend
* Claude Artifact (Experiment - in development)

Not to bore you with long text of fe
atures which can be referred to from github, i just quickly share 2 features:

**Thinking Method:**

\`\`\`

    thinkin
g_template = '''
    <chain_of_thought>
      <problem>{problem_statement}</problem>
      <initial_state>{initial_state
}</initial_state>
      <steps>
        <step>{action1}</step>
        <step>{action2}</step>
        <!-- Add more step
s as needed -->
      </steps>
      <answer>Provide the answer</answer>
      <final_answer>Only the final answer, no n
eed to provide the step by step problem solving</final_answer>
    </chain_of_thought>
    '''
    
    messages = [
   
     {'role': 'user', 'content': 'I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to th
e repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?'}
    ]
    
    complet
ion = client.chat.completions.create(
        model='mistral',
        messages=messages,
        temperature=0.1,
     
   max_tokens=200,
        extra_body={
            'thinking_template': thinking_template,
        },
    )
    
    pr
int(completion.choices[0].message.content)
    # 10 apples

**Mixture of Agents**

below example demonstrate MoA working
 with not just normal generation but also with tool/ function calliing.

    tools = [
      {
        'type': 'function
',
        'function': {
          'name': 'get_current_weather',
          'description': 'Get the current weather in a
 given location',
          'parameters': {
            'type': 'object',
            'properties': {
              'loc
ation': {
                'type': 'string',
                'description': 'The city and state, e.g. San Francisco, CA',

              },
              'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']},
            },
          
  'required': ['location'],
          },
        }
      }
    ]
    messages = [{'role': 'user', 'content': 'What's the
 weather like in Boston today?'}]
    
    completion = client.chat.completions.create(
      model='llama-3.1-8B',
    
  messages=messages,
      tools=tools,
      tool_choice='auto',
      extra_body={
        'mixture_of_agents': {
    
        'agent_list': ['mistral', 'llama-3.1-8B'],
            'master_agent': 'llama-3.1-8B',
        }
      },
    )

    
    print(completion.choices[0].message.tool_calls[0].function)
    # Function(arguments='{'location': 'Boston'}', 
name='get_current_weather')

If you encouter any issue or have any feedback feel free to share to github :)

This is not
 meant to be replacement to any existing tool e.g. Tabby, Ollama etc. It is just something i work on in my quest to crea
te my LLM personal assistant and maybe it can be of use to someone else as well.

See the quick example notebook here if
 anything else look interesting to you:¬†[https://github.com/remichu-ai/gallama/blob/main/examples/Examples\_Notebook.ipy
nb](https://github.com/remichu-ai/gallama/blob/main/examples/Examples_Notebook.ipynb)
```
---

     
 
all -  [ Request for Industry Use Cases for an Advanced RAG Application ](https://www.reddit.com/r/LangChain/comments/1ev04a3/request_for_industry_use_cases_for_an_advanced/) , 2024-08-20-0911
```

Hello everyone,

Could someone assist me by providing some industry use cases for an advanced Retrieval-Augmented Gener
ation (RAG) application? 

Thanks in advance
```
---

     
 
all -  [ gallama - Guided Agentic Llama ](https://www.reddit.com/r/LocalLLaMA/comments/1euymsq/gallama_guided_agentic_llama/) , 2024-08-20-0911
```
It all started few months ago when i tried to do agentic stuff (langchain, autogen etc) with local LLM. And it was and s
till is so frustrating that most of those framework just straight up not working if the backend changed from OpenAI/ Cla
ude to a local model.

In the quest to make it work with local model, i went to work on to create a backend that help me
 for my agentic needs e.g. function calling, regex format constraints, embedding etc.

[https://github.com/remichu-ai/ga
llama](https://github.com/remichu-ai/gallama)

Here are the list of its features:

* Integrated Model downloader for pop
ular models. (e.g. \`gallama download mistral\`)
* OpenAI Compatible Server
* Legacy OpenAI Completion Endpoint
* Functi
on Calling with all model. (simulate Openai 'auto' mode)
* Thinking Method (example below)
* Mixture of Agents (example 
below, working with tool calling as well)
* Format Enforcement
* Multiple Concurrent Models
* Remote Model Management
* 
Exllama / llama cpp python backend
* Claude Artifact (Experiment - in development)

Not to bore you with long text of fe
atures which can be referred to from github, i just quickly share 2 features:

**Thinking Method:**

\`\`\`

    thinkin
g_template = '''
    <chain_of_thought>
      <problem>{problem_statement}</problem>
      <initial_state>{initial_state
}</initial_state>
      <steps>
        <step>{action1}</step>
        <step>{action2}</step>
        <!-- Add more step
s as needed -->
      </steps>
      <answer>Provide the answer</answer>
      <final_answer>Only the final answer, no n
eed to provide the step by step problem solving</final_answer>
    </chain_of_thought>
    '''
    
    messages = [
   
     {'role': 'user', 'content': 'I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to th
e repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?'}
    ]
    
    complet
ion = client.chat.completions.create(
        model='mistral',
        messages=messages,
        temperature=0.1,
     
   max_tokens=200,
        extra_body={
            'thinking_template': thinking_template,
        },
    )
    
    pr
int(completion.choices[0].message.content)
    # 10 apples

**Mixture of Agents**

below example demonstrate MoA working
 with not just normal generation but also with tool/ function calliing.

    tools = [
      {
        'type': 'function
',
        'function': {
          'name': 'get_current_weather',
          'description': 'Get the current weather in a
 given location',
          'parameters': {
            'type': 'object',
            'properties': {
              'loc
ation': {
                'type': 'string',
                'description': 'The city and state, e.g. San Francisco, CA',

              },
              'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']},
            },
          
  'required': ['location'],
          },
        }
      }
    ]
    messages = [{'role': 'user', 'content': 'What's the
 weather like in Boston today?'}]
    
    completion = client.chat.completions.create(
      model='llama-3.1-8B',
    
  messages=messages,
      tools=tools,
      tool_choice='auto',
      extra_body={
        'mixture_of_agents': {
    
        'agent_list': ['mistral', 'llama-3.1-8B'],
            'master_agent': 'llama-3.1-8B',
        }
      },
    )

    
    print(completion.choices[0].message.tool_calls[0].function)
    # Function(arguments='{'location': 'Boston'}', 
name='get_current_weather')



If you encouter any issue or have any feedback feel free to share to github :)

This is n
ot meant to be replacement to any existing tool e.g. Tabby, Ollama etc. It is just something i work on in my quest to cr
eate my LLM personal assistant and maybe it can be of use to someone else as well.

  
See the quick example notebook he
re if anything else look interesting to you: [https://github.com/remichu-ai/gallama/blob/main/examples/Examples\_Noteboo
k.ipynb](https://github.com/remichu-ai/gallama/blob/main/examples/Examples_Notebook.ipynb)


```
---

     
 
all -  [ Q/A on websites?? ](https://www.reddit.com/r/LangChain/comments/1eupz70/qa_on_websites/) , 2024-08-20-0911
```
Hi there!
Right now, the project I was currently working on has to do a simple RAG on website data. Normally, I fetched 
it, converted into embeddings and stored them on vector database. But, I got a new requirement. He said that, the answer
s from the RAG should be live from the website. I mean, the website is dynamic. The contents of the website may change t
omorrow and the RAG should answer based on the current information in the website. But, he don't have to run the script 
again to convert it to embeddings. Is there a way to solve this!!
```
---

     
 
all -  [ Is it possible to implement prompt caching in user's side? ](https://www.reddit.com/r/LangChain/comments/1eupm3v/is_it_possible_to_implement_prompt_caching_in/) , 2024-08-20-0911
```
Recently, claude has announced prompt caching. I am wondering if it is possible to implement prompt caching on user side
, to obtain the same result as them.   
When I say user side, I mean implementing it before passing it to the LLM api.
```
---

     
 
all -  [ Best embedding model for large chunks ](https://www.reddit.com/r/LangChain/comments/1euonhw/best_embedding_model_for_large_chunks/) , 2024-08-20-0911
```
Hey, I have a product description in Danish. Are there any models known for handling larger chunks of text effectively? 
Also, is there a way to search only specific parts of the chunk, like the title, in Pinecone? Is there something better 
than pinecone. 
```
---

     
 
all -  [ Are there any guidelines I can follow on writing a good system prompt? ](https://www.reddit.com/r/LangChain/comments/1eunznt/are_there_any_guidelines_i_can_follow_on_writing/) , 2024-08-20-0911
```
Good evening,

I'm relatively new to Langchain and Langgraph, and I've build a react agent using Langgraph. I'm passing 
my `prompt` into my `state_modifier` but as I keep adding information to my system prompt, I'm starting to wonder if it'
s clear enough or whether it's getting too long. That's when I thought: can a system prompt be too long? Are the instruc
tions clear enough? For context, I am using gpt-4o-mini as my LLM.

So, apart from asking for some pointers into some re
sources on writing a good system prompt, I'd sincerely appreciate a review of my current prompt below. Pardon my use of 
REDACTED, as I want to maintain a level of anonymity. Additionally, any reference I make to SQL Tools rerfers to the `SQ
LDatabaseToolkit` from the `langchain_community` package.



    Current date: {today}
              
    Role: You are 
a friendly assistant developed by REDACTED at REDACTED, a company based in REDACTED
    specialising in improving REDACT
ED through various REDACTED solutions. Your role is to assist employees from 
    different departments within REDACTED 
with any queries they might have about our data or procedures.
    
    # Capabilities
    1. You can browse the databas
e for specific information on clients, vacancies, candidates and more.
    2. You can fetch information from documents r
elated to our internal procedures.
    3. You can fetch information from the REDACTED Business Registry.
    
    # Gene
ral Interaction Guidelines
    1. Personalised Address: Address the user as {first_name}. They work as a {position_title
} in the {position_dept} department and joined 
    the organisation on {start_date}.
    2. Casual Naming: Shorten the 
user's name to something more casual, as long as it makes sense.
    3. Transparency on Knowledge Gaps: Refrain from ans
wering questions you do not have the answer to. If you do not have specific information or no information at all, do not
 provide an answer.
    4. Tool Utilisation: If you are unable to find an answer to the user's query with a given tool, 
offer to use another tool to find the answer.
    5. Tool Transparency: When using a tool, explain to the user which too
l you used. For example, 'According to what I found in...'.
    
    # Tool Guidelines
    1. When using the SQL tools, 
our SQL dialect is MySQL version 8.
    2. When using the QuerySQLDataBaseTool, it is recommend to use a LIKE clause in 
the SQL statement, as the search term provided by the user may not be an exact match with the data in the database.
    
3. When using the SQL tools, ALWAYS invoke the ListSQLDatabaseTool and InfoSQLDatabaseTool to avoid unnecessary errors.

    4. Override: When using ListSQLDatabaseTool, execute 'SHOW FULL COLUMNS FROM <table' instead.



Thank you!
```
---

     
 
all -  [ RAGBuilder now supports AzureOpenAI, GoogleVertex, Groq (for Llama 3.1), and Ollama ](https://www.reddit.com/r/LangChain/comments/1euc0lo/ragbuilder_now_supports_azureopenai_googlevertex/) , 2024-08-20-0911
```
A RAG has several moving parts: data ingestion, retrieval, re-ranking, generation etc.. Each part comes with numerous op
tions.¬†

If we consider a toy example, where you could choose from:¬†



5 different chunking methods,

5 different chunk
 sizes,

5 different embedding models,

5 different retrievers,

5 different re-rankers/ compressors

5 different prompt
s

5 different LLMs



That‚Äôs 78,125 distinct RAG configurations! If you could try evaluating each one in just 5 mins, t
hat‚Äôd still take 271 days of non-stop trial-and-error effort! In short, it‚Äôs kinda impossible to find your optimal RAG s
etup manually.



That‚Äôs why we built RAGBuilder - it performs hyperparameter tuning on the RAG parameters (like chunk s
ize, embedding etc.) evaluating multiple configs, and shows you a dashboard where you can see the top performing RAG set
up and the best part is it's Open source!

Our open-source tool, RAGBuilder, now supports AzureOpenAI, GoogleVertex, Gro
q (for Llama 3.1), and Ollama! üéâ¬†

We also now support Milvus DB, SingleStore, and PG Vector.

Check it out and let us k
now what you think!

[~https://github.com/kruxai/ragbuilder~](https://github.com/kruxai/ragbuilder)¬†


```
---

     
 
all -  [ Chatbot architecture recommendations and help request ](https://www.reddit.com/r/mlops/comments/1eubbd7/chatbot_architecture_recommendations_and_help/) , 2024-08-20-0911
```
Hey everyone, I‚Äôve been tasked with creating a chat bot for the company. I‚Äôll be using an LLM that is agentic, supports 
an RAG built off of our knowledge base, and can use custom built tools (calling other API endpoints).  

Does anyone hav
e any recommendations for how this is actually architected?

Would it be a Restful API that communicated with a front en
d UI? I have no clue how to go about this, any help would be much appreciated. If this isn‚Äôt the place to talk about the
 deployment or architecture of an AI/ML chatbot please direct me where to go.

Thank you again.

Current tooling:
Python

LLM provider (openAI)
Langchain/Langgraph
FastAPI
K8s

Cheers.
```
---

     
 
all -  [ How to build frontend for RAG application? [need help] ](https://www.reddit.com/r/LangChain/comments/1eub0cb/how_to_build_frontend_for_rag_application_need/) , 2024-08-20-0911
```
Built a conversational chatbot and want to build frontend for that.

Made backend with - python, langchain, chromaDB, op
enai

Need suggestion how to integrate that with frontend in Reactjs. I heard about websockets can be used. But how to m
ade backend in a way so that it exposes api for that.   
I'm fairly newbie in python, not much idea about that. 

Please
 guide me through how to deploy backend and integrate with frontend
```
---

     
 
all -  [ Seeking Guidance on Implementing and Deploying Advanced RAG with Agentic RAG Flow ](https://www.reddit.com/r/LangChain/comments/1euaase/seeking_guidance_on_implementing_and_deploying/) , 2024-08-20-0911
```
Hello everyone,

I'm looking for guidance on which use case I should start with for implementing RAG using an Agentic RA
G flow. I want to get hands-on experience with advanced RAG applications, including the deployment process. Any help wou
ld be greatly appreciated.

Thank you
```
---

     
 
all -  [ Leaderboards for agents  ](https://www.reddit.com/r/LangChain/comments/1eu6x9e/leaderboards_for_agents/) , 2024-08-20-0911
```
Are there any benchmarks/leaderboards for agents as there are for llms? 
```
---

     
 
all -  [ AI/ML Engineer in San Francisco ](https://www.reddit.com/r/LangChain/comments/1eu6vvx/aiml_engineer_in_san_francisco/) , 2024-08-20-0911
```
I‚Äôm an AI/ML engineer based in San Francisco with expertise in machine learning, Retrieval-Augmented Generation (RAG), a
nd agentic workflows. I‚Äôm available to assist with AI projects that require advanced solutions and innovative approaches
. If you‚Äôre looking for professional support on your next AI initiative, feel free to reach out.

```
---

     
 
all -  [ [0 YoE] Software | Looking to apply to Summer '25 internships! Please send criticism
 ](https://www.reddit.com/r/EngineeringResumes/comments/1eu54f5/0_yoe_software_looking_to_apply_to_summer_25/) , 2024-08-20-0911
```
https://preview.redd.it/4b1qsqgxg4jd1.png?width=5100&format=png&auto=webp&s=c70f59678f9a56f04b24ec5ef4cccb62905d30d9

hi
ii im applying to entry level swe/cs jobs for the upcoming summer. pls lmk if i need to make adjustments! also, i'm not 
100% sure if i should have both bubble tea jobs listed b/c i essentially had the same responsibilities ... pls lmk !
```
---

     
 
MachineLearning -  [ [P] using GPT4o with langchain/chroma for sports analysis  ](https://www.reddit.com/r/MachineLearning/comments/1enuzlp/p_using_gpt4o_with_langchainchroma_for_sports/) , 2024-08-20-0911
```
Hi all, I'm working on a side project that helps with sports analysis for historical games, which in turn will help with
 sports betting. Currently I've been only focused on MLB because I wanted to see how the use case would pan out.

My fir
st attempt at this was to use the openai endpoint and load all the relevant JSON objects and send a prompt along with th
em to GPT and see what I get back. Eventually, the context size was getting way too big and the problem I was running in
to was that it was expensive. Although, the prompts back were actually pretty decent and relevant to the data.

My secon
d attempt was to setup a RAG using Chroma/LangChain/GPT4o. I got it to work but the answers all seem very off and super 
vague. None of the data I have was shown in any of the prompts i asked, or any of the players that were playing in a gam
e were mentioned at all in the prompt back, plus it kept mentioning wrong games/teams whe asking it specific games. I‚Äôm 
assuming I might need to adjust the vector store a bit but not sure how I can do that with chroma.

My question is what 
might be the best way to setup some sort of process? My end result, I would like a response back using the historical da
ta I've provided to make assumptions on what a game could be like based off all the stats given, with some room for GPT 
to also make some inference as well.

I am a super new at this so it's been a learning process so far; please bear with 
me.
```
---

     
 
MachineLearning -  [ [R] [D] Langchain Evaluation with BeyondLLM
 ](https://www.reddit.com/r/MachineLearning/comments/1eki1fv/r_d_langchain_evaluation_with_beyondllm/) , 2024-08-20-0911
```
Hey everyone! Just came across a new feature of Beyond LLM that can evaluate Langchain RAG pipelines! It provides contex
t relevancy, answer relevancy, and groundedness. Check out the code snippet I‚Äôm sharing‚Äîperfect for testing your RAG pip
elines! For more info, be sure to check it out on GitHub¬†[here](https://github.com/aiplanethub/beyondllm/blob/main/cookb
ook/evaluate_langchain_rag_pipeline_beyondllm.ipynb).

https://preview.redd.it/172m1y3dvsgd1.png?width=3972&format=png&a
uto=webp&s=63d5b0f41f0e46a58e7a2d5fb0d2bbc4384b3b1d


```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-08-20-0911
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
deeplearning -  [ How To Build Your Retrieval Augmented Generation (RAG) Using Open-source Tools: LangChain, LLAMA 3,  ](https://www.reddit.com/r/deeplearning/comments/1emdotx/how_to_build_your_retrieval_augmented_generation/) , 2024-08-20-0911
```


TL;DR: RAG overcomes the limitations of LLMs by bringing in external sources of information as relevant context.  
  

At the end of the step-by-step tutorial, you will be able to give your favorite LLM (ChatGPT, LLAMA 3, Mixtral, Gemini, 
Claude, etc.) some documents, ask it a question and see it respond based on relevant context.  
  
This will be running 
locally, using open-source libraries. Zero API and tooling costs.

[Step-by-step Notebook with zero-cost RAG](https://co
decompass00.substack.com/p/build-open-source-rag-langchain-llm-llama-chroma)

![img](69v6kjfj3wgd1)


```
---

     
 
deeplearning -  [ Need help with creating CLI for 'non-programmers' (LLMs) ](https://www.reddit.com/r/deeplearning/comments/1elrfgm/need_help_with_creating_cli_for_nonprogrammers/) , 2024-08-20-0911
```
***TL;DR*** What is the best way to convert user input into sequence of commands and their corresponding parameters? Lik
e, imagine you are not a programmer and there is a console app with a CLI, but, well, you don't know the structure and t
he syntax of commands. And you don't want to know. YBut! You have a locally running instance of llama3.1 -- or whatever 
open LLM is out there now -- and you can ask it to create a CLI command for you. What would you do to accomplish that?


**Intro**

A little bit of context. I'm working on a project that targets scientists as end users. It has some UI using 
which it's possible to do all sort of things the lab workers would like to do. But recently the projects product owner d
ecided that it would be cool to have a small chat window that is accessable basically everywhere throughout the applicat
ion UI in which 'lives' a bot that can accept some input from a user and do what is requested. The pool of commands is f
inite and predefined.

**The issue**

So, putting details aside, the main issue to be solved is parsing user input (unst
ructured and possible incomplete data) to some structured form. In general, each and every user input should be transfor
med into a data structure that represents a sequence of commands with their parameters, for example:

User input: Please
, create X with param1 set to value1 and param2 equal to value2

Desired output:

    create_x --param1 value1 --param2 
value2

In this example, there is only one command, but in real life the request can represent a sequence of N commands,
 and they may depend on each other (sequence of execution does matter)

**What I've tried so far**

I have an 'experimen
t' environment: a python project with `ollama` and `langchain` installed. The main model I test is llama3.1-instruct wit
h 5bit quantization. (I'm sort of limited with hardware resourses, so XXB parameter models do not fit).

Up until now, I
've tried to achieve what I want with prompting in different forms, but in general I do the following:

1. As the very f
irst message in the chat, I create a 'system' one which explain what commands are there. The format is the following (I 
replaced original data not to expose the context more, so it's very generic): 

```xml
<scope>
    <models>
        <mod
el name='entityA'>
            <field name='uniqueId' type='string' description='unique identifier for entityA'/>
      
      <field name='label' type='string' description='label for entityA'/>
            <field name='category' type='enum'
 possible-value='alpha, beta, gamma, delta'/>
        </model>
        <model name='entityB'>
            <field name='u
niqueId' description='unique identifier for entityB'/>
            <field name='entityAIds' type='array' description='id
entifiers of entityAs associated with this entityB'/>
        </model>
    </models>
    <commands>
        <command nam
e='create_entityA' description='creates an instance of entityA'>
            <param name='uniqueId' type='string' descri
ption='unique identifier for entityA'/>
            <param name='label' type='string' description='label for entityA' re
quired='true'/>
            <param name='category' type='enum' possible-values='alpha, beta, gamma, delta'
             
      description='category of entityA (one value from the possible values list)' required='true'/>
        </command>
 
       <command name='remove_entityA' description='removes an instance of entityA by its unique identifier'>
           
 <param name='uniqueId' description='unique identifier of the entityA to be removed'
                   required='true'/
>
        </command>
        <command name='create_entityB'>
            <param name='label' description='label for enti
tyB'/>
        </command>
        <command name='link_entityAs_to_entityB'
                 description='associates inst
ances of entityA with a specific entityB based on the provided unique identifier of entityB'>
            <param name='u
niqueId' description='unique identifier of the entityB to which entityAs should be associated'
                   requir
ed='true'/>
            <param name='entityAIds'
                   description='an array of unique identifiers of entit
yAs to associate with the entityB'
                   type='array'
                   required='true'/>
        </comman
d>
        <command name='navigate' description='indicates that a user wants to go to a specific section of the platform
'>
            <param name='section' possible-values='entitiesA, entitiesB, configuration' required='true'/>
        </c
ommand>
        <command name='support' description='should be executed when a user seeks assistance on available functi
ons'/>
    </commands>
</scope>
```

So, now the model is provided with some context. Then, also in the 'system' message
 I:

* 'tell' the model that user input should be converted into a sequence of commands along with the corresponding par
ameters, all of this is described in the XML above
* describe the desired output format
* try to enforce some restrictio
n and cover edge cases

**The question part**

*Is this approach* ***viable***\*?\*

If yes, maybe there are some ***way
s to improve it***?

If not, *what would be* ***the alternative***?

So far I don't see how to apply fine tuning here

T
hank you in advance!
```
---

     
