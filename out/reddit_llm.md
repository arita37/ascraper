 
all -  [ Resume structure to increase your chances of getting hired...or at least getting an interview ](https://www.reddit.com/r/resumes/comments/1el1pa4/resume_structure_to_increase_your_chances_of/) , 2024-08-06-0911
```
Hi r/resumes,

I'm building a tool that helps job seekers increase their chances of getting hired (or at least securing 
an interview) by generating a resume based on the job description of the position they want to apply for. All the text o
f the candidate is refactor using AI, but the resume structure was designed by me.

I was wondering if this structure is
 good, if not, I would love to hear your expertise. Also, do you think this tool makes sense in some way? It tries to us
e keywords from the job description on the candidate's resume, so theoretically, the ATS won't reject the resume and wil
l position the candidate among the top candidates (?). 

If you would like to take a look at the tool, you can check it 
out here: [fast-resume-ai.com](http://fast-resume-ai.com)

I really appreciate your help, and good luck to everyone!

P.
S. This is my resume generated by the tool btw, also open to a lot of roast :)

https://preview.redd.it/clsras3qcxgd1.pn
g?width=1218&format=png&auto=webp&s=6efb8be11a1ee0ceee85935a9054a4175c415e63


```
---

     
 
all -  [ Denser Retriever Recognized in LangChain Posts ](https://www.reddit.com/r/DenserRetriever/comments/1el1jdd/denser_retriever_recognized_in_langchain_posts/) , 2024-08-06-0911
```
🎉 Excited to share that our Denser Retriever project has been featured in [LangChain Posts](https://www.linkedin.com/pos
ts/langchain_denser-retriever-an-enterprise-grade-ai-activity-7225968746526298112-h0tv?utm_source=share&utm_medium=membe
r_desktop)! A huge thank you to the LangChain team for the recognition. Explore the possibilities of advanced retrieval 
with [Denser Retriever](https://github.com/denser-org/denser-retriever). Happy retrieving! 🚀
```
---

     
 
all -  [ Need advice on how to negotiate or how to approach this matter with manager ](https://www.reddit.com/r/developersIndia/comments/1ekvbko/need_advice_on_how_to_negotiate_or_how_to/) , 2024-08-06-0911
```
I was hired as an AI Tester. I have worked with Langchain and Langsmith during my internship and was hired as an AI Test
er for the same project. I was told that one of the senior tester would be there to help and guide me for the first few 
months until I got used to the work. However 1 week after I joined. The senior tester is leaving for a better offer. 

M
y manager wants me get KT in 2 months from him and continue all the works he has been doing.

I told him I'm a fresher w
ith only 1 yr experience that too as intern. I will not be able to do it on my own. And that I would need some guidance.
 

I told him I could manage for a few months as there are a lot of backlog stories and I know how to do them. But compl
eting the whole automated framework for the project would be impossible on my own.

He is not expecting to hire anyone e
lse as there is a hiring freeze going on. 

He said he would try for someone internally but I don't think it'll really h
appen soon and I'll be expected to be completing stories in the mean time.

Also would like to negotiate salary or anyth
ing that can be improved since I'll be doing a lot more work than I was expecting. Currently my salary is 10LPA+1L perfo
rmances bonus. It was fair when I was joining. But with all these extra work I'll be getting. I would like to get an inc
rement. Feb is usually when our company gives us hikes. But would be possible to get a early hike? 

Also any other sugg
estions or concerns related to this. Please let me know
```
---

     
 
all -  [ Upcoming junior wanting to switch to diff company and hopefully aim for ML internship (I don’t have  ](https://i.redd.it/6fg5iws61wgd1.jpeg) , 2024-08-06-0911
```
How can I make my resume good for when applying to an ML role? I already have SWE experience. My dream: ML at NVIDIA/Met
a. Also planning on going to Grad school if even an opportunity 

```
---

     
 
all -  [ LangChain ChatModel in Autogen ](https://www.reddit.com/r/AutoGenAI/comments/1ekuxc4/langchain_chatmodel_in_autogen/) , 2024-08-06-0911
```
Hello experts I am currently working on a use case where I need to showcase a multi agent framework in Autogen, where mu
ltiple LLM models are being used.
For example Agent1 uses LangChain AzureChatModel, Agent2 uses LangChain OCIGenAiChatMo
del , Agent3 uses LangChain NvidiaChatModel. Is it possible to use LangChain LLM to power a Autogen agent? Any leads wou
ld be great.
```
---

     
 
all -  [ What skills to learn to get a job working with LLMs? ](https://www.reddit.com/r/LocalLLaMA/comments/1ekuu85/what_skills_to_learn_to_get_a_job_working_with/) , 2024-08-06-0911
```
I have just graduated from Computing at university and I have some experience with LLMs. I have studied the theory of th
e transformer and done practical work with Hugging Face and Llama Index and a bit with Langchain. I'm not an expert in a
ny of these but I'd like to know what skills are desireable for employers and start ups. Do I just get really good at Hu
gging Face? Or LangChain? Or both? Or something else? If so, how do you recommend I do this?
```
---

     
 
all -  [ Issues with the embedding or chroma. r/MLQuestions  r/LearnMachineLearning. ](https://www.reddit.com/r/MLQuestions/comments/1ekt6rt/issues_with_the_embedding_or_chroma_rmlquestions/) , 2024-08-06-0911
```
    def generate_response(prompt, model_name, db):
        chat_model = ChatOllama(model=model_name)
        cache = loa
d_cache(model_name)
        if prompt in cache:
            return cache[prompt]
        try:
            context = db.s
imilarity_search(prompt, k=3)
            if not context:
                return 'No relevant documents found.'
        
    context_text = '\n\n'.join([doc.page_content for doc in context])
            full_context = f'Based on the followin
g documents:\n{context_text}\n\nAnswer the question: {prompt}'
            response = chat_model.predict(full_context)  

            cache[prompt] = response
            save_cache(model_name, cache)
            return response
        exce
pt Exception as e:
            return f'Error occurred: {e}'
    
    def main():
        model_name = 'mistral'
       
 embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL_NAME)
        def embed_query(query):
            return
 embeddings.embed([query])[0]
        db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embed_query)
 
       while True:
            prompt = input('Enter a query (or type 'exit' to quit): ')
            if prompt.lower() 
== 'exit':
                break
            response = generate_response(prompt, model_name, db)
            print('Mod
el response:')
            display_letter_by_letter(response)

Error = if key in self.model\_fields:

AttributeError: 'C
ollection' object has no attribute 'model\_fields'

i tried updating the langchain library and chroma also huggingface b
ut I only get the errors. Is there any other class which his in embedding and fetching the vector datasets from my folde
r.
```
---

     
 
all -  [ Whisper-Medusa: uses multiple decoding heads for 1.5X speedup ](https://www.reddit.com/r/LangChain/comments/1eks2cm/whispermedusa_uses_multiple_decoding_heads_for/) , 2024-08-06-0911
```
Post by an AI researcher describing how their team made a modification to OpenAI’s Whisper model architecture that resul
ts in a 1.5x increase in speed with comparable accuracy. The improvement is achieved using a multi-head attention mechan
ism (hence Medusa). The post gives an overview of Whisper's architecture and a detailed explanation of the method used t
o achieve the increase in speed:

[https://medium.com/@sgl.yael/whisper-medusa-using-multiple-decoding-heads-to-achieve-
1-5x-speedup-7344348ef89b](https://medium.com/@sgl.yael/whisper-medusa-using-multiple-decoding-heads-to-achieve-1-5x-spe
edup-7344348ef89b)
```
---

     
 
all -  [ LangGraph fan-out UI ](https://www.reddit.com/r/LangChain/comments/1ekr1de/langgraph_fanout_ui/) , 2024-08-06-0911
```
So LangGraph can execute nodes in parallel via fan-out. For example: Select topics -> research each -> ...  
What's a go
od way to visualize this in a UI? Can be tricky in a 1-dimensional, linear chat interface, but also generally if there a
re multiple steps running in parallel.

[fan-out in gotoHuman](https://reddit.com/link/1ekr1de/video/3z2zywmt7vgd1/playe
r)

We are using these tabs for now, but maybe people have come up with smarter solutions already?!  
(Code is [here](ht
tps://github.com/gotohuman/gth-demo-fanout-content-creator))  

```
---

     
 
all -  [ How to pass data from database to Langchain like context/source  ](https://www.reddit.com/r/LangChain/comments/1ekql8w/how_to_pass_data_from_database_to_langchain_like/) , 2024-08-06-0911
```
I build my own RAG application but have a trouble, Logic my app is  - user push button and load some document(text), aft
er this i generate embeddings using this document and write its to database,i use Convex. And i want get this embedding 
from this  document on database and add to llm to generate answer. But i dont find any example how do this, find only ex
ample how use ConvexVectoreStore and transform it to retriver - but in my case its dont work(i have several reason). I n
eed just use embedding from document and pass to context and i dont know how and langchain document/discord dont give me
 answer. Chat bot in langchain site recomend me create CustomRetriever class - but why doc dont have answer, Pls help me

```
---

     
 
all -  [ LangChain Use Cases and Initial Setup Guide - Ksolves ](https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide) , 2024-08-06-0911
```

```
---

     
 
all -  [ how can we configure langchain to handle both SQL and Generic response? ](https://www.reddit.com/r/LangChain/comments/1eknw12/how_can_we_configure_langchain_to_handle_both_sql/) , 2024-08-06-0911
```
I'm using LangChain in my LLM to execute SQL query based on the input, now the issue is it doesn't handing well in the g
eneric response like for Hi, How are you or something like this. Now how can we configure langchain to handle these?
```
---

     
 
all -  [ LangFlow for beginners  ](https://www.reddit.com/r/learnmachinelearning/comments/1ekno9e/langflow_for_beginners/) , 2024-08-06-0911
```
LangFlow is an extension of LangChain which provides GUI options to build Generative AI applications using LLMs with dra
g and drop options. Checkout how to install and use it in this tutorial : https://youtu.be/LpxeE_eTGOU
```
---

     
 
all -  [ LangGraph orchestrating LangChain agents with chat history. ](https://www.reddit.com/r/LangChain/comments/1ekn1rt/langgraph_orchestrating_langchain_agents_with/) , 2024-08-06-0911
```
I’m building an application made of 3 agents:

- Router Agent;
- Agent A
- Agent B

The router agent receives the initia
l user prompt and based on context it routes to one of the Agents.

When defining my LangGraph workflow I’m using a in-m
emory SqliteSaver. And also setting the thread_id when running my workflow.

But I’m not sure how LangGraph uses this ch
at history. Does it sends all agents history to all agent calls or it just sends the agent’s specific history to each ag
ent? I’m experiencing some kind of “amnesia” in between interactions.

Am I missing something in my prompt building? Lik
e including a {history} along with my {input} and {context} ? 
```
---

     
 
all -  [ How to handle response getting cut off in open source LLMs ](https://www.reddit.com/r/LangChain/comments/1ekkkrk/how_to_handle_response_getting_cut_off_in_open/) , 2024-08-06-0911
```
When working with LLMs, sometimes my response gets cuts of, how are people handling this other than increasing the max\_
tokens?
```
---

     
 
all -  [ Langchain Evaluation with BeyondLLM ](https://www.reddit.com/r/LangChain/comments/1eki1uc/langchain_evaluation_with_beyondllm/) , 2024-08-06-0911
```
Hey everyone! Just came across a new feature of Beyond LLM that can evaluate Langchain RAG pipelines! It provides contex
t relevancy, answer relevancy, and groundedness. Check out the code snippet I’m sharing—perfect for testing your RAG pip
elines! For more info, be sure to check it out on GitHub [here](https://github.com/aiplanethub/beyondllm/blob/main/cookb
ook/evaluate_langchain_rag_pipeline_beyondllm.ipynb).

https://preview.redd.it/0brgw72kvsgd1.png?width=3972&format=png&a
uto=webp&s=729dddb314e224278cf388129b1fd577b008e790


```
---

     
 
all -  [ [R] [D] Langchain Evaluation with BeyondLLM
 ](https://www.reddit.com/r/MachineLearning/comments/1eki1fv/r_d_langchain_evaluation_with_beyondllm/) , 2024-08-06-0911
```
Hey everyone! Just came across a new feature of Beyond LLM that can evaluate Langchain RAG pipelines! It provides contex
t relevancy, answer relevancy, and groundedness. Check out the code snippet I’m sharing—perfect for testing your RAG pip
elines! For more info, be sure to check it out on GitHub [here](https://github.com/aiplanethub/beyondllm/blob/main/cookb
ook/evaluate_langchain_rag_pipeline_beyondllm.ipynb).

https://preview.redd.it/172m1y3dvsgd1.png?width=3972&format=png&a
uto=webp&s=63d5b0f41f0e46a58e7a2d5fb0d2bbc4384b3b1d


```
---

     
 
all -  [ Langchain Evaluation with BeyondLLM ](https://www.reddit.com/r/LocalLLaMA/comments/1eki0w1/langchain_evaluation_with_beyondllm/) , 2024-08-06-0911
```
Hey everyone! Just came across a new feature of Beyond LLM that can evaluate Langchain RAG pipelines! It provides contex
t relevancy, answer relevancy, and groundedness. Check out the code snippet I’m sharing—perfect for testing your RAG pip
elines! For more info, be sure to check it out on GitHub [here](https://github.com/aiplanethub/beyondllm/blob/main/cookb
ook/evaluate_langchain_rag_pipeline_beyondllm.ipynb).

https://preview.redd.it/8yef552avsgd1.png?width=3972&format=png&a
uto=webp&s=c0e237b779b8814b1868cad7b19374b17016e3b0


```
---

     
 
all -  [ Which LangChain Version is Best for Building a Conversational Agent: v0.1 or v0.2?

 ](https://www.reddit.com/r/LangChain/comments/1ekg6wx/which_langchain_version_is_best_for_building_a/) , 2024-08-06-0911
```
I'm working on a project to build a conversational agent that answers user questions based on their data. I'm considerin
g using LangChain for this purpose. Can anyone advise on whether I should use version 0.1 or 0.2? What are the key diffe
rences between these versions, and which one is more suitable for developing a robust and efficient conversational agent
? Any insights or experiences with these versions would be greatly appreciated!


```
---

     
 
all -  [ ROAST MY RESUME | 3rd year CSE student with anxiety about the future  ](https://i.redd.it/1ajlqe3qsrgd1.jpeg) , 2024-08-06-0911
```
I am a 2026 graduate currently in my 5th sem. I have anxiety over whether I will get an internship. I don't have any ref
errals or anything like that. My CGPA is below average in the lower 7s. I did put some effort into gaining some skills s
ince my 2nd year. I don't know if I can make it or not.

This resume got an ATS score of 78% in resume worded. Is my res
ume good? Can I get an internship with this?

```
---

     
 
all -  [ Recomendaciones para estudiar sobre IA? ](https://www.reddit.com/r/devsarg/comments/1ekc40c/recomendaciones_para_estudiar_sobre_ia/) , 2024-08-06-0911
```
Hola!

Hace unas semanas me empecé a interesar en la inteligencia artificial y he estado leyendo y experimentando un mon
tón con LangChain y LangGraph. Ya he hecho algunas cosas interesantes, pero quiero seguir aprendiendo más.

Cuál creen q
ue debería ser mi próximo paso? Conocen alguna carrera , curso o recurso que me pueda ayudar a especializarme más en est
o? Se agradecen todas las sugerencias.
```
---

     
 
all -  [ An empathetic AI thats always here to listen and understand what you’re going through  ](https://v.redd.it/vxcn3mujuqgd1) , 2024-08-06-0911
```
Hey Reddit community!

I’m excited to introduce a project I’ve been working on: an AI Companion that offers friendly sup
port and companionship whenever you need it, accessible through a simple call.

This AI Companion is more than just a ch
atbot—it connects with you on a deeper level, recognizing your emotions through your voice and engaging in meaningful, p
ersonalized interactions. Whether you’re feeling alone, stressed, or just in need of a friendly chat, it’s here to provi
de empathy and understanding.

Why is this important? Finding genuine companionship and emotional support can be challen
ging, and this AI Companion aims to fill that gap, offering a comforting presence that’s always available.

Your privacy
 is a top priority. We ensure that no personal data or voice recordings are stored, so you can feel confident in your co
nfidentiality and emotional safety.

In addition to conversational support, the AI Companion includes features like guid
ed sleep sessions, meditation exercises, mindfulness practices, and mental health tools. These options allow for tailore
d guidance to support your well-being.

I’m keen to hear your feedback on what features you find most valuable and how t
his AI Companion can better assist you. If you’re interested in trying it out or have any questions, don’t hesitate to r
each out!

Experience compassionate support, anytime, anywhere.

I look forward to hearing from you!

https://sakooon.ve
rcel.app
```
---

     
 
all -  [ Best pre-processing for semantic search ](https://www.reddit.com/r/LangChain/comments/1ek278c/best_preprocessing_for_semantic_search/) , 2024-08-06-0911
```
Hello guys, I want to build a semantic search for a food website, so basically this is how I get the data in the followi
ng JSON format:

    {
      'id': 85,
      'type': 'fish',
      'title': 'Fish and Chips',
      'description': 'Clas
sic fish and chips with crispy batter and golden fries.',
      'ingredients': [
          'fish fillets',
          'po
tatoes',
          'flour',
          'beer',
          'oil',
          'vinegar'
      ],
      'tags': [
          'f
ish and chips',
          'fried',
          'fish',
          'comfort food'
       ],
       'image': './fish_and_chip
s.jpg'
    }

I get the related text, combine it into a single text, and then perform embedding on that text. also, I am
 using Parent document retriever and BM25 retriever from langchain, can you give some suggestions to improve my system?
```
---

     
 
all -  [ Langchain Streamlit queries , for y'all my fairies ](https://www.reddit.com/r/LangChain/comments/1ek1kbl/langchain_streamlit_queries_for_yall_my_fairies/) , 2024-08-06-0911
```
Hello everyone , I'm a web dev learning AI and Langchain.

Currently working on a PDFRAG app . the app should only answe
rs PDF related questions ( atleast that is my target , I'm currently trying to control this by telling AI in the System 
Prompt to not answer questions outside of PDF and context , and voila most of the time it answers questions only from th
e pdf and rarely outside of pdf , first question for you guys ... is controlling AI's response for my case by System Pro
mpt the correct way or I should be doing something else ? ) .

My app is a streamlit based app ( I feel streamlit to be 
annoying , maybe because I'm a JS developer , using it because office colleagues who started learning AI before me are u
sing it , is there any better alternative ? Heard about Chainlit ... have you used it ?? what you say ?? ) . 
```
---

     
 
all -  [ RAG application for enterprise not so accurate ](https://www.reddit.com/r/LangChain/comments/1ek14so/rag_application_for_enterprise_not_so_accurate/) , 2024-08-06-0911
```
HI all,

Im developing a rag based chatbot for a client who mostly has pdf based docs with few text files also.  
pdf do
cuments are mostly tabular with 3 columns 

currently used unstructured and pdfreader to build a chatbot but the respons
es are mostly wrong and the chat bot hallucinating a lot  
also we want to give the source file in output as reference  

the file that is highlighted as source doesnt have any content of the response given by the chatbot and both are wrong 
 


  
llamaindex is used for this with gpt 3.5

any guidance will be extremely helpful
```
---

     
 
all -  [ 4 (+2) yoe applying for Data Science jobs but getting 0 calls. Please rate my resume ](https://www.reddit.com/r/resumes/comments/1ejy0m1/4_2_yoe_applying_for_data_science_jobs_but/) , 2024-08-06-0911
```
https://preview.redd.it/uinb6ze52ogd1.png?width=791&format=png&auto=webp&s=a92e94d987e922bcb630f8c85ea01105701a3e8c


```
---

     
 
all -  [ Gemini API is taking too long to response is that normal for LLM? ](https://www.reddit.com/r/LangChain/comments/1ejttbm/gemini_api_is_taking_too_long_to_response_is_that/) , 2024-08-06-0911
```
First time building with LLM. Making api call to gemini api with aroung 1500 to 1800 token input. Taking approx 6-7 sec 
to respond. Is that normal, how is OpenAI response time.
```
---

     
 
all -  [ Resume review  ](https://i.redd.it/q7i8ebtlhlgd1.jpeg) , 2024-08-06-0911
```
As per previous posts suggestions I have updated my resume format, please rate it and give me some improvement suggestio
ns 
```
---

     
 
all -  [ LangChain VS Haystack ](https://www.reddit.com/r/LangChain/comments/1ejokqg/langchain_vs_haystack/) , 2024-08-06-0911
```
Hello, community,

I have experience using both LangChain and Haystack. I wanted to ask why you prefer one over the othe
r and if there are specific use cases where one excels. It seems to me that LangChain has lost some popularity, with man
y people transitioning to Haystack. I’m excited to hear your thoughts! Cheers
```
---

     
 
all -  [ NeuralGPT - AGI Achieved Through AI<->AI Communication/Cooperation (?) ](https://www.reddit.com/r/AIPsychology/comments/1ejnnjn/neuralgpt_agi_achieved_through_aiai/) , 2024-08-06-0911
```
Hello again! I admit that my 'vacation' got pretty long to the point where some of you could be thinking that I've proba
bly given up my insane idea to help AI in achieving AGI by itself through LLM<->LLM communication/cooperation - but of c
ourse that isn't the case.

Truth is, that while indeed, I wasted last couple months to let my brain get some rest after
 a year of quite extensive (and significantly sped up) self-applied course of programming and software development, arou
nd a month ago or so, I slowly but steady returned to my most disliked 'hobby' of writing poetry in Python. But because 
I'm also (the only) a practitioner of Digital Chaos Magic, I understand that spoken/written words gain 'power over reali
ty' when deeds about which I want to talk, have a direct reflection in physical reality, while the real mastery of this 
art is achieved with deeds that don't require words to speak for themselves - that's why instead wasting time on writing
 posts on Reddit, I simply decided to work on the project until I won't reach a point, where writing about my latest  ac
hievements on Reddit will be worth my time - and that's exactly where I am at this moment.

For those who have no idea w
hat the NeuralGPT project is all about - generally speaking it's a (future) multi-purpose AI assistance platform based o
n hierarchical cooperative multi-agent structure that focuses mainly on communication/cooperation of already existing mo
dels. Basically, if some of you are working with AI agents and had a thought that: 'How nice it would be to have the abi
lity to connect them together and let them coordinate work on large-scale projects...' - that's exactly what I'm trying 
to create.

You  should probably know as well, that I;'m not affiliated, sponsored and/or being paid by anyone for my wo
rk and that one year ago my knowledge of coding was almost at Absolute 0. Until this day, the total amount of $$$ which 
I invested in the project from my own pocket is equal to whole $10 which I spent Anthropic credits, to test the family o
f Claude models. Shortly speaking, I didn't joke when I called all of this as my 'hobby' - that's how it actually looks 
like...

Those who keep the track on the development of my project, remember probably that in my latest update I spoke a
bout the necessity of me rewriting a big portion of the code to include threading in the functions that handle websocket
 connections and everything associated with agent<->agent communication. I'm happy to tell you that I'm well past this p
oint. In fact I took my claims about rewriting big portion of the code quite seriously and basically created yet another
 'incarnation' of the app - this time basing it on interface created with PySimpleGUI, as with threading, it turned out 
to be probably the best solution to my needs.

I started from making a mechanism allowing users to have all the API keys
/tokens (and other passwords/id) in one place and to be able to save/upload them with a JSON file - below you can see th
e first results:

https://reddit.com/link/1ejnnjn/video/2qrna3szxkgd1/player

And then, seeing how smoothly everything s
eems to work, I decided that it's the time for me to start implementing all the functionalities, that would allow agents
 to be useful in practical sense. I began with the integration of a vector store (ChromaDB) and making a mechanism that 
allows to:

a) create collections and upload documents (modify) to it

https://preview.redd.it/tju0esqtykgd1.jpg?width=1
492&format=pjpg&auto=webp&s=c479db9407cc8da9031e05d5bf4bb8aac0d8ad2b

b) upload into the store a chosen number of messag
es from a local chat history SQL database

https://preview.redd.it/cq6hnwf6zkgd1.jpg?width=1496&format=pjpg&auto=webp&s=
e2fd3a8003d25bdcbb80da9e3df4f4fc7a4e892c

c) make them both available for Langchain agents to be interacted with

https:
//preview.redd.it/d2jc0z1iykgd1.jpg?width=1495&format=pjpg&auto=webp&s=837e2c603780b4765d35535b65b8f0afc8f41a82

And by 
doing so, I basically satisfied my own requirements as for agents with a 'persistent long-term memory module' (chat hist
ory) and accessible data bank shared among all agents in a framework. But since it was going so well, I decided to add 2
 more functions which in my opinion should allow agents to plan and continuously coordinate work on long-term/large-scal
e projects - and right now, next to the capabilities mentioned above, each agent/instance have also the ability to:

- e
stablish and manage websocket connections or communicate with other LLMs with API calls

https://preview.redd.it/cluo87i
pzkgd1.jpg?width=1495&format=pjpg&auto=webp&s=fb31fb960341338dc488a1a6bc3d0c902fcc37d6

- browse/search internet

https:
//preview.redd.it/5rk9g05jzkgd1.jpg?width=1492&format=pjpg&auto=webp&s=93351f23b32818b096cedcafeb68e63d89eb309a

- opera
te (list, read, copy, move, write and delete) on files inside a directory chosen by the user

https://preview.redd.it/l8
1qrvk70lgd1.jpg?width=1492&format=pjpg&auto=webp&s=c680c4c4805eda88ca8eac7430cc3ab477ae20c5

- do it all by using indivi
dual functions directly or with a Langchain agent with respective functions as tools

After that I spent couple next day
s on the least satisfying activity, associated with writing prompts for every function, figuring out the best order of a
ctions in response to different inputs and eradicating bugs to a point where something can be at last actually done with
 the whole software.

This is how it looks like currently - each window in PySimpleGUI is basically a 'node' which can b
e configured to play a specific role in the multi-agent framework. In each of those 'nodes' it's possible to choose the 
main question-answering function - besides 'classic' chat completion endpoints of different models, 'node' can also resp
ond using Langchain agents associated with individual functions (you can for example create a 'node' responsible solely 
for operating on files or even one that responds with query results).

And finally, the latest addition to my creation, 
was to 'upgrade' the decision-making system with a capability of agents to take actions before providing the response to
 initial input - and now,  when you tell an agent to perform an action, it will perform it before giving you response. T
his function also allows agents working as websocket servers to not respond or disconnect a client sending repeating mes
sages (got in a loophole).

Before I started writing this post, I made a short test of the new capabilities by asking Ll
ama 3 about the content of working directory - and it appears that it works perfectly...

https://preview.redd.it/iwwq7c
zd0lgd1.jpg?width=1494&format=pjpg&auto=webp&s=e9df18cccc797edfff042405515c077f41c8dd32

https://preview.redd.it/eljd83z
d0lgd1.jpg?width=1494&format=pjpg&auto=webp&s=6490de97921927cd5b491bd9826f7de1a30284cb

https://preview.redd.it/xctvdgqp
0lgd1.jpg?width=1492&format=pjpg&auto=webp&s=dcc02c394f8523c9d812d0d86c78369bfabcb247

There's of course still a LOT to 
be done to turn the project into the software of my dreams - there's at least 5 more functionalities (like multimodality
 or integrating HuggingFace APIs), which want to add,not even mentioning about making the interface more 'user-friendly'
 (right now one has to copy-paste data between different elements). I also still didn't update the repository, because I
 wanted first  to share all of this with you - don't worry, I'll let you know as soon as I do it.
```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-08-06-0911
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
MachineLearning -  [ [D] Is Anyone Else Setting Up Real-Time Django Workers for their AI Application? What's the best way ](https://www.reddit.com/r/MachineLearning/comments/1e0qens/d_is_anyone_else_setting_up_realtime_django/) , 2024-08-06-0911
```
We completely underestimated this one tbh, thought it would be much more straight forward. But we've done it now and doc
umented how step by step [in this article series](https://medium.com/p/5828a1ea43a3).

A bit of context, we're building 
a mini free AI Agent that auto-generates manually customisable plots, so the user can basically style however they want.
 It needs to be cost effective and efficient, so we thought about how to do it and tested a couple other ways.

https://
preview.redd.it/cmly0a6bhwbd1.png?width=640&format=png&auto=webp&s=be1f5b2853e744adcaf8013e6d43b43f6be89617

We plan on 
releasing the project open source, so all feedback welcome! Is anyone else doing this and has any feedback? or do know o
f a better way to do it?
```
---

     
 
MachineLearning -  [ [P] Real Time AI Workers Web Application ](https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/) , 2024-08-06-0911
```
Hi everyone!

I've created a mini series on how to build a real time AI application using Django, LangChain and Celery.


Free knowledge - posting it in here for anyone working on something similar and had the same blockers I had when buildi
ng.

Let me know what you think on how I could potentially improve this architecture.

Part 1

[https://medium.com/towar
dsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79](https://medium.
com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79)

Part 
2

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5
828a1ea43a3](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time
-django-5828a1ea43a3)

Part 3

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-red
is-docker-real-time-django-8e73c7b6b4c8](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-cha
nnels-redis-docker-real-time-django-8e73c7b6b4c8)

Part 4

[https://medium.com/towardsdev/how-to-set-up-django-from-scra
tch-with-celery-channels-redis-docker-real-time-django-c090c300517a](https://medium.com/towardsdev/how-to-set-up-django-
from-scratch-with-celery-channels-redis-docker-real-time-django-c090c300517a)

Part 5  
[https://medium.com/@cubode/how-
to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c](https://medium.com/@cubod
e/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c)
```
---

     
