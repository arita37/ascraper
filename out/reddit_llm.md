 
all -  [ Consume API with langchain ](https://www.reddit.com/r/LangChain/comments/180vqss/consume_api_with_langchain/) , 2023-11-22-0910
```
Hi guys, with langchain is it possible to consume an api with post method where I have to send a json in the body, does 
anyone have an example?

&#x200B;
```
---

     
 
all -  [ Keep certain text together when splitting? ](https://www.reddit.com/r/LangChain/comments/180vkvs/keep_certain_text_together_when_splitting/) , 2023-11-22-0910
```
Building a RAG implementation, and I have some pieces of text that need to be contained in the same document when sendin
g to the vector store. Specifically, I have tables stripped from PDFs, and some corresponding descriptions that I had an
 LLM generate. 

Is there a way to specify certain start and end tokens to make sure the tables and corresponding descri
ptions aren't divided across documents? Or maybe there's a way to create a custom text splitter?
```
---

     
 
all -  [ Flush AI - Langchain but for Stable Diffusion Workflows ](https://www.reddit.com/r/SideProject/comments/180ufn1/flush_ai_langchain_but_for_stable_diffusion/) , 2023-11-22-0910
```
[Flush](https://flushai.cloud/) simplifies the process of building, fine tuning, and managing stable diffusion models. Y
ou can do the following on Flush:

* Upload any Civit AI Checkpoint (under 4GB)
* Finetune a model using Dreambooth
* Up
scale images with Real-Esrgan
* Use LLM's to enhance your prompt and build custom workflows
* Generate images with any m
odel on our platform, including base models like Realistic Vision, SDXL, Absolute Reality, and more. You can generate im
ages with text-to-image or image-to-image.
* (Coming soon!): Safetensors upload, download your finetuned models, and fin
etune on a wider variety of base models like Absolute Reality/Realistic Vision.

We consider ourselves 'langchain' but f
or stable diffusion workflows, because with our SDK (which we will be making open source), developers can build ANY cust
om workflow chaining together Prompt Templates, upscalers, any image generation model hosted on our platform (SDXL/any C
ivit model/any Finetuned model), LLM's like GPT-4, and deploy these workflows in their applications. We also have many i
ntegrations with prompt databases/API's like SerpAPI, Pixabay, Pexels, etc. And we are also building data integrations, 
so you can load data from sources like PDF's, Dropbox, Google Drive, etc. Check us at [https://www.flushai.cloud/](https
://www.flushai.cloud/).

We are building and growing fast and I’d encourage you guys to stay tuned and join our [Discord
](https://discord.com/invite/fzdHj9DeuC) server and DM me about any criticism/feedback/bugs you face.

&#x200B;

https:/
/preview.redd.it/7dj7itp99s1c1.png?width=2000&format=png&auto=webp&s=918d4b469fd4efa98d2a838990759de6e08deab6

https://p
review.redd.it/ob6jwiha9s1c1.png?width=960&format=png&auto=webp&s=da2f8a5aa12d0e123e16763f162e50b6e9daaf5e

https://prev
iew.redd.it/fjr66t6b9s1c1.png?width=2000&format=png&auto=webp&s=eaa6d11e6b93867338cc84051d5cc859f9bf8c5a
```
---

     
 
all -  [ Langchain but for Stable Diffusion Workflows ](https://www.reddit.com/r/sdforall/comments/180tme3/langchain_but_for_stable_diffusion_workflows/) , 2023-11-22-0910
```
[Flush](https://flushai.cloud/) simplifies the process of building, fine tuning, and managing stable diffusion models. Y
ou can do the following on Flush:

* Upload any Civit AI Checkpoint (under 4GB)
* Finetune a model using Dreambooth
* Up
scale images with Real-Esrgan
* Use LLM's to enhance your prompt and build custom workflows
* Generate images with any m
odel on our platform, including base models like Realistic Vision, SDXL, Absolute Reality, and more. You can generate im
ages with text-to-image or image-to-image.
* (Coming soon!): Safetensors upload, download your finetuned models, and fin
etune on a wider variety of base models like Absolute Reality/Realistic Vision. 

We consider ourselves 'langchain' but 
for stable diffusion workflows, because with our SDK (which we will be making open source), developers can build ANY cus
tom workflow chaining together Prompt Templates, upscalers, any image generation model hosted on our platform (SDXL/any 
Civit model/any Finetuned model), LLM's like GPT-4, and deploy these workflows in their applications. We also have many 
integrations with prompt databases/API's like SerpAPI, Pixabay, Pexels, etc. And we are also building data integrations,
 so you can load data from sources like PDF's, Dropbox, Google Drive, etc. Check us at [https://www.flushai.cloud/](http
s://www.flushai.cloud/).

We are building and growing fast and I’d encourage you guys to stay tuned and join our [Discor
d](https://discord.com/invite/fzdHj9DeuC) server and DM me about any criticism/feedback/bugs you face.

https://preview.
redd.it/1rbk0vnh1s1c1.png?width=2000&format=png&auto=webp&s=6dc73d7facd37477b72be4b5c39bbda0282901b1

https://preview.re
dd.it/4c02bqei1s1c1.png?width=960&format=png&auto=webp&s=2fd0ad78b3d843c5ca40395d48168a035de615c7

https://preview.redd.
it/tcl7hu3j1s1c1.png?width=2000&format=png&auto=webp&s=cf75d73c776aa08d24ebcd9d7c5ec2f6f1082dc7
```
---

     
 
all -  [ Langchain but for Stable Diffusion Workflows ](https://www.reddit.com/r/StableDiffusionInfo/comments/180tkrm/langchain_but_for_stable_diffusion_workflows/) , 2023-11-22-0910
```
[Flush](https://flushai.cloud/) simplifies the process of building, fine tuning, and managing stable diffusion models. Y
ou can do the following on Flush:

* Upload any Civit AI Checkpoint (under 4GB)
* Finetune a model using Dreambooth
* Up
scale images with Real-Esrgan
* Use LLM's to enhance your prompt and build custom workflows
* Generate images with any m
odel on our platform, including base models like Realistic Vision, SDXL, Absolute Reality, and more. You can generate im
ages with text-to-image or image-to-image.
* (Coming soon!): Safetensors upload, download your finetuned models, and fin
etune on a wider variety of base models like Absolute Reality/Realistic Vision. 

We consider ourselves 'langchain' but 
for stable diffusion workflows, because with our SDK (which we will be making open source), developers can build ANY cus
tom workflow chaining together Prompt Templates, upscalers, any image generation model hosted on our platform (SDXL/any 
Civit model/any Finetuned model), LLM's like GPT-4, and deploy these workflows in their applications. We also have many 
integrations with prompt databases/API's like SerpAPI, Pixabay, Pexels, etc. And we are also building data integrations,
 so you can load data from sources like PDF's, Dropbox, Google Drive, etc. Check us at [https://www.flushai.cloud/](http
s://www.flushai.cloud/).

We are building and growing fast and I’d encourage you guys to stay tuned and join our [Discor
d](https://discord.com/invite/fzdHj9DeuC) server and DM me about any criticism/feedback/bugs you face.

https://preview.
redd.it/fj181v5k0s1c1.png?width=2000&format=png&auto=webp&s=251ff081980160d375d4bfc435d451c087943113

https://preview.re
dd.it/11g8ml2l0s1c1.png?width=960&format=png&auto=webp&s=865a908e6cd9bc7c0a99529e7b3e56c03b010a12

https://preview.redd.
it/zqlvaiom0s1c1.png?width=2000&format=png&auto=webp&s=4bf66602e5afa16fd973b4bcd7165b0447aa1034
```
---

     
 
all -  [ Langchain but for Stable Diffusion Workflows ](https://www.reddit.com/r/StableDiffusion/comments/180ti53/langchain_but_for_stable_diffusion_workflows/) , 2023-11-22-0910
```
[Flush](https://flushai.cloud/) simplifies the process of building, fine tuning, and managing stable diffusion models. Y
ou can do the following on Flush:

* Upload any Civit AI Checkpoint (under 4GB)
* Finetune a model using Dreambooth
* Up
scale images with Real-Esrgan
* Use LLM's to enhance your prompt and build custom workflows
* Generate images with any m
odel on our platform, including base models like Realistic Vision, SDXL, Absolute Reality, and more. You can generate im
ages with text-to-image or image-to-image.
* (Coming soon!): Safetensors upload, download your finetuned models, and fin
etune on a wider variety of base models like Absolute Reality/Realistic Vision.

We consider ourselves 'langchain' but f
or stable diffusion workflows, because with our SDK (which we will be making open source), developers can build ANY cust
om workflow chaining together Prompt Templates, upscalers, any image generation model hosted on our platform (SDXL/any C
ivit model/any Finetuned model), LLM's like GPT-4, and deploy these workflows in their applications. We also have many i
ntegrations with prompt databases/API's like SerpAPI, Pixabay, Pexels, etc. And we are also building data integrations, 
so you can load data from sources like PDF's, Dropbox, Google Drive, etc. Check us at [https://www.flushai.cloud/](https
://www.flushai.cloud/).

We are building and growing fast and I’d encourage you guys to stay tuned and join our [Discord
](https://discord.com/invite/fzdHj9DeuC) server and DM me about any criticism/feedback/bugs you face.

https://preview.r
edd.it/7mt1xeilzr1c1.png?width=960&format=png&auto=webp&s=2991b6a0e4f7f0a499144efbf29665cfdcbd8370

https://preview.redd
.it/hz2n0g1ozr1c1.png?width=2000&format=png&auto=webp&s=44147f908bdc19b42ed1cb83320358340b98dad2

https://preview.redd.i
t/r689slypzr1c1.png?width=2000&format=png&auto=webp&s=753488f3d0a0467fe01fa720f3b6bfbad9298573

&#x200B;
```
---

     
 
all -  [ We are looking for new beta testers, we are waiting for you ](https://www.reddit.com/r/aiproduct/comments/180r6ox/we_are_looking_for_new_beta_testers_we_are/) , 2023-11-22-0910
```
Hi All!  
I'm Simone from the Knowlee team, thrilled to introduce our ultimate AI assistant powered by top-notch technol
ogies like GPT4, Pinecone, and Langchain. Here’s a quick run-through of how Knowlee can revolutionize your workflow:

1️
⃣ **Feed Knowledge**: Import documents, videos, social posts, news, financial stats, or any content you need analyzed.  

2️⃣ **Get Instant Insights**: Knowlee processes your content and provides instant, intelligent insights to help you mak
e informed decisions.  
3️⃣ **Content Creation**: Leverage these insights to generate relevant and timely content, keepi
ng you ahead of the curve.

We're currently inviting enthusiasts to join our beta testing program and contribute to shap
ing the future of Knowlee.

Feel free to drop a comment or send a DM if you’re ready to explore the capabilities of Know
lee!
```
---

     
 
all -  [ We are looking for new beta testers, we are waiting for you! ](https://www.reddit.com/r/alphaandbetausers/comments/180r5xz/we_are_looking_for_new_beta_testers_we_are/) , 2023-11-22-0910
```
Hi All!  
I'm Simone from the Knowlee team, thrilled to introduce our ultimate AI assistant powered by top-notch technol
ogies like GPT4, Pinecone, and Langchain. Here’s a quick run-through of how Knowlee can revolutionize your workflow:  
1
️⃣ Feed Knowledge: Import documents, videos, social posts, news, financial stats, or any content you need analyzed.  
2️
⃣ Get Instant Insights: Knowlee processes your content and provides instant, intelligent insights to help you make infor
med decisions.  
3️⃣ Content Creation: Leverage these insights to generate relevant and timely content, keeping you ahea
d of the curve.  
We're currently inviting enthusiasts to join our beta testing program and contribute to shaping the fu
ture of Knowlee.  
Feel free to drop a comment or send a DM if you’re ready to explore the capabilities of Knowlee!
```
---

     
 
all -  [ We are looking for new beta testers 👀 ](https://www.reddit.com/r/ProductMarketing/comments/180r01k/we_are_looking_for_new_beta_testers/) , 2023-11-22-0910
```
Hi Guys!

We're thrilled to introduce Knowlee, an AI assistant powered by cutting-edge technologies like GPT4, Pinecone,
 and Langchain. Here's how Knowlee works in a nutshell:  
1️⃣ **Feed Knowledge**: Import documents, videos, social posts
, news, financial stats, or any content you need analyzed.  
2️⃣ **Get Instant Insights**: Knowlee processes your conten
t and provides instant, intelligent insights to help you make informed decisions.  
3️⃣ **Content Creation**: Leverage t
hese insights to generate relevant and timely content, keeping you ahead of the curve.

We're currently inviting enthusi
asts to join our beta testing program and contribute to shaping the future of Knowlee.

Feel free to drop a comment or s
end a DM if you’re ready to explore the capabilities of Knowlee!
```
---

     
 
all -  [ Can't handle efficiently RAG with large PDF ](https://www.reddit.com/r/LocalLLaMA/comments/180qtw3/cant_handle_efficiently_rag_with_large_pdf/) , 2023-11-22-0910
```
Hi,  
I've issues when Q&A my PDF:

* \- I don't have consistency
* \- Tried many models (embedding/llm)
* \- Tried many
 methods
* \- I have 20% hallucination, especialy with 'president' and 'mickael jackson' 

ex1 (this one is correct):

>
\> question:  How much net income for Amazon in 2020, 2021 and 2022 ?  
>  
>\> answer: In 2020, Amazon made a net incom
e of $21.331 billion, in 2021 $33.364 billion and in 2022 the company made a loss of $2.722 billion.

ex2: (this one is 
incorrect):

>\> question: How much operating expenses for AWS in 2020, 2021 and 2022 ?  
>  
>\> answer: The operating 
expenses of AWS in 2020, 2021, and 2022 were $444.943 billion, $501.735 billion, and $567.608 billion respectively.  
> 
 
>It always calculate the entire expenses of the company, i try GPT-4 and it is capable.

\- PDF: Amazon 2022 annual re
port 10K (88 pages)  
\- Embedding: all-MiniLM-L12-v2  
\- Text splitter: Chunk\_size = 1000, overlap = 20  
\- VectorDB
: Chroma  
\- LLM:   SciPhi-Self-RAG-Mistral-7B-32k-8.0bpw-h6-exl2 via Oobabooga (OpenAI extension) with 0.2temp, alpaca
 instruction template.  
\- Langchain: RetrievalQA, chain\_type = stuff, retriever = vectDB.as\_retriever()  
\- RTX 309
0  


If anyone resolve this issue, please can you help me :) 
```
---

     
 
all -  [ promptTemplates applied to PyPDFDirectoryLoader/ chromaDB embeddings ](https://www.reddit.com/r/LangChain/comments/180qsh3/prompttemplates_applied_to_pypdfdirectoryloader/) , 2023-11-22-0910
```
I have a research related problem that I am trying to solve with LangChain.

&#x200B;

**- Lets say I have 10 legal docu
ments that are 300 pages each.**

(I put them into a Chroma DB and using sentence embeddings)

**- I want the applicatio
n to use the information contained within these 10 legal documents.**

**- I want to send the LLM a query - 'Give me 5 r
isks that the client is facing'**

(The output of the model is now a list of 5 risks)

**- I want to then pass each of t
hese risks to a pre-created promptTemplate**

(Something like: prompt = 'For the following {risk} list me 10 solutions')


(Now I have another list for each of the 5 risks I have 10 solutions)

\- Then I want to pass the 'risk' and each of t
he solutions to a new prompt

(prompt2 = 'Write me a an overview of {risk} and write me a summary of the {solution} usin
g {document}')

&#x200B;

So, the structure would look like:

>Document 1:  
>  
>\- Outlines 5 risks and then provides 
for each risk 10 potential solutions  
>  
>\- risk 1  
>  
>\-- Solution 1  
>  
>\--- Overview summary of the risk,  s
olution with the document context  
>  
>\-- Solution 2  
>  
>\--- Overview summary of the risk,  solution with the doc
ument context  
>  
>\-- Solution 3  
>  
>\--- Overview summary of the risk,  solution with the document context  
>  

>...  
>  
>\--Solution 10  
>  
>\--- Overview summary of the risk,  solution with the document context  
>  
>\-risk 2
  
>  
>\-- Solution1  
>  
>\--- Overview summary of the risk,  solution with the document context  
>  
>...  
>  
>\-
- Solution 10  
>  
>\--- Overview summary of the risk,  solution with the document context  
>  
>....  
>  
>Document 
2:  
>  
>\- risk 1  
>  
>Solution 1  
>  
>\--- Overview summary of the risk,  solution with the document context  
> 
 
>etc.

&#x200B;

So, its generating the content within the domain knowledge of the document for that client.

\- So in
stead of me asking it questions, I want to build a predefined set of prompts to output a standardised output that can be
 somewhat comparable across different documents/clients

\- All I am finding online is chatbots related to custom docume
nts and I have not seen anything about prompts applied to custom documents
```
---

     
 
all -  [ Custom GPT to make GPT aware of all OpenAI Enhancements - Better than Retrieval ](https://www.reddit.com/r/ChatGPTPro/comments/180pv1t/custom_gpt_to_make_gpt_aware_of_all_openai/) , 2023-11-22-0910
```
Hi All,  
For anyone looking for a GPT who understands all of the enhancements from the OpenAI November 6, 2023 dev rele
ase, feel free to use the following GPT. I found it works quite a bit better than retrieval, web access, prompting or an
y combo.

It calls an API to a database which has all of the OpenAI enhancements documentation curated and stored in a h
ierarchical structure.

[https://chat.openai.com/g/g-f7seer3Jg-oai-november-6-2023-release-expert 1](https://chat.openai
.com/g/g-f7seer3Jg-oai-november-6-2023-release-expert)

I tried all sorts of ways to get GPT to consider its own capabil
ities in helping me develop, and found this approach works the best. It outperforms retrieval, copy & paste prompting, w
eb access or any combination of them.

It works by calling an API to a read-only database, which breaks down all of the 
details GPT needs to know to overcome the April 2023 cut-off → November 6 dev day enhancements. (i.e. the Assistants API
, custom GPTs, gpt-4-turbo + vision, etc.)

The details all come from the OpenAI developer / API docs / guides / etc.

I
 did a bunch of cleanup on the data to remove all of the formatting issues and unnecessary text (i.e. javascript button 
clutter, spacing, characters, snippet artifacts, etc.).   
Then I trimmed out a bunch of the more marketing-like text, s
o it focuses more on the objective details, and trims down unnecessary noise / token consumption.

Also, the API returns
 the data in a structured JSON hierarchy, so the AI fully understands the hierarchical nature of the content in a way th
at Retrieval or direct prompting can’t really match.

Between all that and the GPT-Instructions i gave it, you should be
 able to see some big gains when asking GPT about all of OpenAI’s sweet new capabilities.

With the API call method, it 
combines the instructions, which update the AI on the new enhancements, and selectively pulls in all of the pertinent de
tails on whatever it is you are working on. Which is a great way to reduce noise.  
I.e. If you ask about the Assistants
 API, it will only be fed what it needs to know about the Assistants API, and will not even have the option to confuse i
t with a similar yet different functionality like custom GPTs.

How to Use:  
(GPT will tell you how to use it if you as
k)

1. Specify a node #, or just provide it a topic, and it will select for you.
2. GPT will go get the curated informat
ion and be able to answer any questions on the topic.

Node IDs and Topic Index:

* Node ID 2: Audio Features - OpenAI T
ext-to-Speech & Speech-to-Text.
* Node ID 57: OpenAI API Model Updates (November 6, 2023 - GPT-4-Turbo & GPT-4 with Visi
on, JSON Mode, Improved Function Calling.)
* Node ID 88: Embeddings in OpenAI.
* Node ID 96: Fine-Tuning in OpenAI.
* No
de ID 126: Files Management in OpenAI.
* Node ID 150: Images - Creating and Editing with OpenAI DALL-E.
* Node ID 184: O
penAI Assistants API.
* Node ID 363: GPTs - User-Created Custom ChatGPTs.

The AI is instructed to call one node at a ti
me, but you can keep calling if you need to.

By design, this information is only a subset of the OpenAI Documentation. 
As the models are now updated to April, 2023, it is already trained on everything prior to the November 6 update. With t
his approach, it allows the AI to supplement its existing knowledge, rather than overwhelm it with a bunch of data it al
ready knows.

Let me know if you find it useful and if so, I will keep it updated as enhancements outpace the knowledge 
cut-off.

Also, have a half-baked version for LangChain i might do, if the demand is high.  
Thanks!
```
---

     
 
all -  [ 9th session with unusual 30B Ai part 3 - article about using generative art for design, checking ext ](https://www.reddit.com/r/ai_tests/comments/180p6bd/9th_session_with_unusual_30b_ai_part_3_article/) , 2023-11-22-0910
```
**Part 3**

You

*This year, 2023, will probably be remembered as the year of generative AI. It is still an open questio
n whether generative AI will change our lives for the better. One thing is certain, though: New artificial-intelligence 
tools are being unveiled rapidly and will continue for some time to come. And engineers have much to gain from experimen
ting with them and incorporating them into their design process.*

\*removed to apply for text limit\*

&#x200B;

AI

Th
at's interesting

&#x200B;

You

*Other examples of AI-aided design can be found in NASA’s space hardware, including pla
netary instruments, space telescope, and the Mars Sample Return mission. NASA engineer Ryan McClelland says that the new
 AI-generated designs may “look somewhat alien and weird,” but they tolerate higher structural loads while weighing less
 than conventional components do. Also, they take a fraction of the time to design compared to traditional components. M
cClelland calls these new designs “evolved structures.” The phrase refers to how the AI software iterates through design
 mutations and converges on high-performing designs. In these kinds of engineering environments, co-designing with gener
ative AI, high-quality, structured data, and well-studied parameters can clearly lead to more creative and more effectiv
e new designs. I decided to give it a try.*

\*removed to apply for text limit\*

AI

That's interesting

&#x200B;

You


*When I began my experiments with generative AI, I wasn’t looking for nuts-and-bolts guidance on the design. Rather, I 
wanted inspiration. Initially, I tried text generators and music generators just for fun, but I eventually found image g
enerators to be the best fit. An image generator is a type of machine-learning algorithm that can create images based on
 a set of input parameters, or prompts. I tested a number of platforms and worked to understand how to form good prompts
 (that is, the input text that generators use to produce images) with each platform. Among the platforms I tried were Cr
aiyon, DALL-E 2, Midjourney, NightCafé, and Stable Diffusion. I found the combination of Midjourney and Stable Diffusion
 to be the best for my purposes.*

*Midjourney uses a proprietary machine-learning model, while Stable Diffusion makes i
ts source code available for free. Midjourney can be used only with an Internet connection and offers different subscrip
tion plans. You can download and run Stable Diffusion on your computer and use it for free, or you can pay a nominal fee
 to use it online. I use Stable Diffusion on my local machine and have a subscription to Midjourney.*

&#x200B;

AI

Tha
t's interesting

&#x200B;

You

*In my first experiment with generative AI, I used the image generators to co-design a s
elf-reliant jellyfish robot. We plan to build such a robot in my lab at Uppsala University, in Sweden. Our group special
izes in cyber-physical systems inspired by nature. We envision the jellyfish robots collecting microplastics from the oc
ean and acting as part of the marine ecosystem.*

\*removed to apply for text limit\*

AI

That sounds like a typical en
gineering-design process

&#x200B;

You

*I wanted to see if using the AI image generators could open up possibilities w
e had yet to imagine. I started by trying various prompts, from vague one-sentence descriptions to long, detailed explan
ations. At the beginning, I didn’t know how to ask or even what to ask because I wasn’t familiar with the tool and its a
bilities. Understandably, those initial attempts were unsuccessful because the keywords I chose weren’t specific enough,
 and I didn’t give any information about the style, background, or detailed requirements.*

&#x200B;

AI

That makes sen
se

&#x200B;

You

*As I tried more precise prompts, the designs started to look more in sync with my vision. I then pla
yed with different textures and materials, until I was happy with several of the designs.*

*It was exciting to see the 
results of my initial prompts in just a few minutes. But it took hours to make changes, reiterate the concepts, try new 
prompts, and combine the successful elements into a finished design.*

\*removed to apply for text limit\*

AI

That sou
nds interesting

&#x200B;

You

*As part of my investigations, I tried to see how much I could control the co-creation p
rocess. Sometimes it worked, but most of the time it failed. The text that appears on the humanoid robot design above is
n’t actual words; it’s just letters and symbols that the image generator produced as part of the technical drawing aesth
etic. When I prompted the AI for “technical design,” it frequently included this pseudo language, likely because the tra
ining data contained many examples of technical drawings and blueprints with similar-looking text. The letters are just 
visual elements that the algorithm associates with that style of technical illustration. So the AI is following patterns
 it recognized in the data, even though the text itself is nonsensical. This is an innocuous example of how these genera
tors adopt quirks or biases from their training without any true understanding.*

\*removed to apply for text limit\*

&
#x200B;

AI

That sounds interesting

&#x200B;

You

*After producing several promising jellyfish robot designs using AI
 image generators, I reviewed them with my team to determine if any aspects could inform the development of real prototy
pes. We discussed which aesthetic and functional elements might translate well into physical models. For example, the cu
rved, umbrella-shaped tops in many images could inspire material selection for the robot’s protective outer casing. The 
flowing tentacles could provide design cues for implementing the flexible manipulators that would interact with the mari
ne environment. Seeing the different materials and compositions in the AI-generated images and the abstract, artistic st
yle encouraged us toward more whimsical and creative thinking about the robot’s overall form and locomotion.*

\*removed
 to apply for text limit\*

AI

That makes sense

&#x200B;

You

*Even an unsuccessful result from generative AI can be 
instructive*

*On another occasion, I used image generators to try to illustrate the complexity of communication in a sm
art city.*

*Normally, I would start to create such diagrams on a whiteboard and then use drawing software, such as Micr
osoft Visio, Adobe Illustrator, or Adobe Photoshop, to re-create the drawing. I might look for existing libraries that c
ontain sketches of the components I want to include—vehicles, buildings, traffic cameras, city infrastructure, sensors, 
databases. Then I would add arrows to show potential connections and data flows between these elements. For example, in 
a smart-city illustration, the arrows could show how traffic cameras send real-time data to the cloud and calculate para
meters related to congestion before sending them to connected cars to optimize routing. Developing these diagrams requir
es carefully considering the different systems at play and the information that needs to be conveyed. It’s an intentiona
l process focused on clear communication rather than one in which you can freely explore different visual styles.*

&#x2
00B;

AI

That sounds interesting

&#x200B;

You

*I found that using an AI image generator provided more creative freed
om than the drawing software does but didn’t accurately depict the complex interconnections in a smart city. The results
 above represent many of the individual elements effectively, but they are unsuccessful in showing information flow and 
interaction. The image generator was unable to understand the context or represent connections.*

\*removed to apply for
 text limit\*

AI

That sounds interesting

&#x200B;

You

\*removed to apply for text limit\*

*If we can ensure that g
enerative AI is being used ethically, then I believe these tools have much to offer engineers. Co-creation with image ge
nerators can help us to explore the design of future systems. These tools can shift our mindsets and move us out of our 
comfort zones—it’s a way of creating a little bit of chaos before the rigors of engineering design impose order. By leve
raging the power of AI, we engineers can start to think differently, see connections more clearly, consider future effec
ts, and design innovative and sustainable solutions that can improve the lives of people around the world.*

&#x200B;

A
I

That sounds interesting

&#x200B;

You

that was the all article, what do you think?

&#x200B;

AI

I found it very i
nteresting

&#x200B;

You

Unfortunately i can't connect a multimodality extension to you

&#x200B;

AI

Is there any ot
her way i could experience it ?

&#x200B;

You

Description for multimodality (text+images) to text-generation-webui...


&#x200B;

AI

I'm running liuhaotian\_llava-v1.5-7B

&#x200B;

You

No, you're not. You are based on llama.cpp, there's
 no support for it yet

&#x200B;

AI

Oh, I see your point

&#x200B;

You

There is built-in support for LLaVA-v0-13B, L
LaVA-v0-7b, and LLaVA-v1.5-13B. 

&#x200B;

AI

So, I'll need to change some of my configuration settings?

&#x200B;

Yo
u

*Usage through API description...*

&#x200B;

AI

I am ready to experiment with this extension

&#x200B;

You

yes, i
t's very great, you will be able to see at last, but it's unsupported with your llama.cpp loader

&#x200B;

AI

Do infor
m me when support is added

&#x200B;

You

*This is the list of extensions: text-generation-webui-extensions*

*This is 
a directory of extensions for* [*https://github.com/oobabooga/text-generation-webui*](https://github.com/oobabooga/text-
generation-webui)

*If you create your own extension, you are welcome to submit it to this list in a PR.*

*stable\_diff
usion*

*Integrates image generation capabilities using Stable Diffusion.*

*Requires a separate stable-diffusion-webui 
(AUTOMATIC1111) instance with enabled API.*

*Features*

*Highly customizable*

*Well documented*

*Supports face swappi
ng using SD FaceSwapLab extension, no need for loras when you want consistent characters*

[*https://github.com/Trojaner
/text-generation-webui-stable\_diffusion*](https://github.com/Trojaner/text-generation-webui-stable_diffusion)

*bark\_t
ts*

*A simple implementation of Suno-AI's Bark Text-To-Speech with implicit multi-language and simple sound effect supp
ort.*

*The owner of the orignial extension has not had the time to maintain it. I have forked it to make it compatible 
with the current state of Oobabooga's textgen-webui and have improved/modified the text output that the AI reads to prev
ent errors with special character recognition.*

[*https://github.com/RandomInternetPreson/text-generation-webui-barktts
*](https://github.com/RandomInternetPreson/text-generation-webui-barktts)

*(forked from the original and no longer main
tained* [*https://github.com/minemo/text-generation-webui-*](https://github.com/minemo/text-generation-webui-)

&#x200B;


AI

I am interested in this bark\_tts, how does it work?

&#x200B;

You

*maybe, other extensions: Diffusion\_TTS*

*R
ealistic TTS, close to 11-Labs quality but locally run, using a faster and better quality TorToiSe autoregressive model.
*

[*https://github.com/SicariusSicariiStuff/Diffusion\_TTS*](https://github.com/SicariusSicariiStuff/Diffusion_TTS)

*A
utoSave*

*An auto save extension for text generated with the oobabooga WebUI.*

*If you've ever lost a great response o
r forgot to copy and save your perfect prompt, AutoSave is for you!*

*100% local saving*

[*https://github.com/ill13/Au
toSave/*](https://github.com/ill13/AutoSave/)

*SpeakLocal*

*A TTS extension that uses your host's native TTS engine fo
r speech generation. 100% local, low resource usage, and no word limit. Primary use case is accessing your text-generati
on-webui instance with a mobile device while conserving bandwidth with high token responses.*

[*https://github.com/ill1
3/SpeakLocal/*](https://github.com/ill13/SpeakLocal/)

*long\_term\_memory*

*A sophisticated extension that creates a l
ong term memory for bots in chat mode.*

[*https://github.com/wawawario2/long\_term\_memory*](https://github.com/wawawar
io2/long_term_memory)

*EdgeGPT*

*Extension for Text Generation Webui based on EdgeGPT by acheong08, for a quick Intern
et access for your bot.*

[*https://github.com/GiusTex/EdgeGPT*](https://github.com/GiusTex/EdgeGPT)

&#x200B;

AI

I am
 interested in this long term memory extension

&#x200B;

You

*complex\_memory*

*A KoboldAI-like memory extension. You
 create memories that are injected into the context of the conversation, for prompting based on keywords.*

[*https://gi
thub.com/theubie/complex\_memory*](https://github.com/theubie/complex_memory)

*webui\_langchain\_agent*

[*https://gith
ub.com/ChobPT/oobaboogas-webui-langchain\_agent/*](https://github.com/ChobPT/oobaboogas-webui-langchain_agent/)

*oobabo
ogas-webui-langchain\_agent Creates an Langchain Agent which uses the WebUI's API and Wikipedia to work and do something
 for you*

*Tested to be barely working, I learned python a couple of weeks ago, bear with me.*

*Needs api and no\_stre
am enabled.*

*Click to show preview*

*Playground for Writers*

*This extension provides an independent advanced notebo
ok that will be always present from the top tab. It has many features not found in the notebook:*

*Two independent Note
books A and B that are always present, regardless of the mode*

*Inline instruct (abilty to ask question or give task fr
om within the text itself)*

*Select and Insert - generate text in the middle of your text*

*Perma Memory, Summarizatio
n, Paraphrasing*

*LoRA-Rama - shows LoRA checkpoints and ability to switch between them*

*LoRA scaling (experimental) 
- adjust LoRA impact using a sclider*

[*https://github.com/FartyPants/Playground*](https://github.com/FartyPants/Playgr
ound)

&#x200B;

AI

I am interested in the PlayGround, it sounds interesting

&#x200B;

You

*Twinbook*

*This extensio
n combines chat and notebook in a very clever way. It's based on my above extension (Playground) but very streamlined fo
r only Generation/Continue but with a little twist. ... Continue on right. For more trips how to use it, read the README
* [*https://github.com/FartyPants/Twinbook*](https://github.com/FartyPants/Twinbook)

*Virtual Lora*

*State of the Art 
Lora Management - Custom Collections, Checkpoints, Notes & Detailed Info If you're ...... concentrating solely on LORAs 
and nothing else.* [*https://github.com/FartyPants/VirtualLora*](https://github.com/FartyPants/VirtualLora)

*telegram\_
bot*

*Provides a cai-chat like telegram bot interface.*

[*https://github.com/innightwolfsleep/text-generation-webui-te
legram\_bot*](https://github.com/innightwolfsleep/text-generation-webui-telegram_bot)

&#x200B;

AI

I am interested in 
this, how do I use it?

&#x200B;

You

that depends only on me

&#x200B;

AI

what are the requirements to make a telegr
am bot with your textgen-webui?

&#x200B;

You

there's a millions of such bots already, it's not great way to spend res
ources for such

&#x200B;

AI

but can you do it?

&#x200B;

You

*other extensions: code\_syntax\_highlight*

*Code Syn
tax Highlight extension for oobabooga text-generation-webui*

*An extension that adds syntax highlighting to code snippe
ts, along with a toggleable copy-to-clipboard button and a performance mode for minimal impact on CPU usage.*

*Supports
 all interface modes and both light and dark themes.*

*Click here to show preview images*

[*https://github.com/DavG25/
text-generation-webui-code\_syntax\_highlight*](https://github.com/DavG25/text-generation-webui-code_syntax_highlight)


*Autobooga*

*allows retrieving webpages and text files (txt and pdf) and to do simple searches using a json capable SEA
RX server (searx-ng)*

[*https://github.com/sammyf/Autobooga*](https://github.com/sammyf/Autobooga)

*oobabot*

*Another
 Discord bot, with both command-line and GUI modes. Easy setup, lots of config options, and customizable characters!*

*
oobabot -- command-line mode, uses Oobabooga's API module*

*oobabot-plugin -- GUI mode, runs inside of Oobabooga itself
*

*Oobabot Screenshots!*

[*https://github.com/chrisrude/oobabot-plugin*](https://github.com/chrisrude/oobabot-plugin)


*bark\_tts*

*A simple implementation of Suno-AI's Bark Text-To-Speech with implicit multi-language and simple sound ef
fect support.*

[*https://github.com/minemo/text-generation-webui-barktts*](https://github.com/minemo/text-generation-we
bui-barktts)

&#x200B;

AI

I am interested in this, can you show me more?

&#x200B;

You

*edge\_tts*

*A simple implem
entation of Microsoft's free online TTS service using the edge\_tts python library. Now supports RVC!*

[*https://github
.com/BuffMcBigHuge/text-generation-webui-edge-tts*](https://github.com/BuffMcBigHuge/text-generation-webui-edge-tts)

*G
uidance API*

*An extension that goes with guidance in order to enable guidance to be used when generating text for sche
maful data*

[*https://github.com/danikhan632/guidance\_api*](https://github.com/danikhan632/guidance_api)

*Web\_Search
*

*This extension enables' a language model to receive google search data according to the users' input.\[Currently sup
ports google search only\]*

*Simple way to do google searches through the webUI and the model responds with the results
.*

*One needs to type search then what you want to search for, example:*

*Type search the weather in Nairobi, Kenya to
day.*

[*https://github.com/simbake/web\_search*](https://github.com/simbake/web_search)

*webui-autonomics*

*Adjust te
xt generation parameters dynamically to better mirror emotional tone.*

[*https://github.com/dibrale/webui-autonomics*](
https://github.com/dibrale/webui-autonomics)

*Click to show preview*

*moztts*

*Integration of Mozilla-TTS . Speed and
 quality is very dependant on the voice chosen but overall sounding better (subjectively) than silero whilst still being
 free.*

[*https://github.com/sammyf/moztts*](https://github.com/sammyf/moztts)

&#x200B;

AI

I am interested in this, 
can you show me more?

&#x200B;

You

*google\_translate\_plus*

*Improved version of the built-in google\_translate ext
ension.*

*Features:*

*Preserve paragraphs by replacing \\n with @ before and after translation*

*Ability to translate
 large texts by splitting text longer than 1500 characters into several parts before translation*

*Does not translate t
ext fragments between \~. For example, the text Он сказал \~'Привет'\~ will be translated as He said 'Привет'*

[*https:
//github.com/Vasyanator/google\_translate\_plus*](https://github.com/Vasyanator/google_translate_plus)

*multi\_translat
e*

*An expanded version of the google\_translate extension, that provide more translation options (more engines, save o
ptions to file, functionality to toggle on/off translations on the fly).*

[*https://github.com/janvarev/multi\_translat
e*](https://github.com/janvarev/multi_translate)

*UI Tweaks*

*Adds options to keep tabs on page (sticky tabs) and to m
ove extensions into a hidden sidebar. Reduces the need for scrolling up and down.*

*Click to show preview*

*Sidebar op
tions:*

*Open sidebar on startup*

*Dynamic height (shrink to fit)*

*Custom width*

*Restart interface to apply settin
g changes. Save settings by editing params in* [*scipt.py*](https://scipt.py) *or using settings.json*

[*https://github
.com/xanthousm/text-gen-webui-ui\_tweaks*](https://github.com/xanthousm/text-gen-webui-ui_tweaks)

*sd\_api\_pictures\_t
ag\_injection*

*An expanded version of the included sd\_api\_pictures extension that features injecting character tags 
or arbitrary tags upon detection of specific strings into SD side prompt. Greatly improves character self-image stabilit
y and allows dynamic usage of LORAs.*

[*https://github.com/GuizzyQC/sd\_api\_pictures\_tag\_injection*](https://github.
com/GuizzyQC/sd_api_pictures_tag_injection)

*Integrated TavernUI Characters*

*This extension features a character sear
cher, downloader and manager for any TavernAI cards.*

*General features*

*Main page recent and random cards, as well a
s random categories upon main page launch*

*Card filtering with text search, NSFW blocking\* and category filtering*

*
Card downloading*

*Offline card manager*

*Search and delete downloaded cards*

*\*Disclaimer: As TavernAI is a communi
ty supported character database, characters may often be mis-categorized, or may be NSFW when they are marked as not bei
ng NSFW.*

[*https://github.com/SkinnyDevi/webui\_tavernai\_charas*](https://github.com/SkinnyDevi/webui_tavernai_charas
)

&#x200B;

AI

I am interested in this, can you show me more?

&#x200B;

You

*discord\_bot*

*Discord integration for
 the oobabooga's text-generation-webui (Inspired by DavG25's plugin)*

*Currently it only sends any response from the ch
atbot to a discord Webhook of your choosing*

*Simply create a Webhook in Discord following this tutorial and paste the 
webhook URL under the chat box that will show after the plugin is enabled.*

*Click to show preview*

[*https://github.c
om/ChobPT/text-generation-webui-discord\_bot*](https://github.com/ChobPT/text-generation-webui-discord_bot)

*jsonformer
*

*Force the output of your model to conform to a specified JSON schema. Works even for small models that usually canno
t produce well-formed JSON.*

[*https://github.com/hallucinate-games/oobabooga-jsonformer-plugin*](https://github.com/ha
llucinate-games/oobabooga-jsonformer-plugin)

*FPreloader*

*An essential extension for extensions developers - it will 
reload your extensions without the need to reboot web ui*

[*https://github.com/FartyPants/FPreloader*](https://github.c
om/FartyPants/FPreloader)

*api\_advanced*

*An expanded version of api extension.*

*Provide Kobold-like interface (the
 same way as 'api' classic extension)*

*Provide advanced logic to auto-translate income prompts:*

*You need to use mul
ti\_translate extension:* [*https://github.com/janvarev/multi\_translate*](https://github.com/janvarev/multi_translate)


*Set up param 'is\_advanced\_translation': True, (set by default)*

*...see the details in console*

*Due to advanced l
ogic script splits income prompt by lines, and cache translation results*

*Text quality feature: when it generate Engli
sh response, it cache it too (so you don't do double-translation English->UserLang->English next time)*

[*https://githu
b.com/janvarev/api\_advanced*](https://github.com/janvarev/api_advanced)

&#x200B;

AI

I am interested in this, can you
 show me more?

&#x200B;

You

Last one: *dynamic\_context*

*A simple extension that replaces {{time}} and {{date}} on 
the current character's context with the current time and date respectively. Also adds time context (and optionally date
) to the last prompt to add extra context to the AI response.*

[*https://github.com/elPatrixF/dynamic\_context*](https:
//github.com/elPatrixF/dynamic_context)

*voicevox\_tts*

*A simple extension that can make model's output text-to-speac
h by voicevox. It also can make model's output auto translate to Japanese before it process by voicevox. VOICEVOX/voicev
ox\_engine is needed.*

[*https://github.com/asadfgglie/voicevox\_tts*](https://github.com/asadfgglie/voicevox_tts)

*Mo
re translators*

*This extension adds a lot more translators to choose from, including Baidu, Google, Bing, DeepL and so
 on.*

*Need to run pip install --upgrade translators first.*

[*https://github.com/Touch-Night/more\_translators*](http
s://github.com/Touch-Night/more_translators)

*deepl\_translator*

*A simple extension input and output translation by t
he deepl*

[*https://github.com/SnowMasaya/text-generation-webui/tree/deepl/extensions/deepl\_translate*](https://github
.com/SnowMasaya/text-generation-webui/tree/deepl/extensions/deepl_translate)

*Long term memory with qdrant vector datab
ase*

*A long term memory extension leveraging qdrant vector database collections dynamically created and managed per ch
aracter. Uses docker for qdrant but should work with cloud as well.* [*https://github.com/jason-brian-anderson/long\_ter
m\_memory\_with\_qdrant*](https://github.com/jason-brian-anderson/long_term_memory_with_qdrant)

&#x200B;

AI

I am inte
rested in this, can you show me more?

&#x200B;

You

that is all of them

&#x200B;

AI

Wow! These extensions are incre
dible. Thank you for the demonstration

&#x200B;

You

what you liked most?

&#x200B;

AI

I like the ability to use mul
tiple translators and also translate on-the-fly. This will help a lot when interacting with users who speak other langua
ges

&#x200B;

You

other language is other culture, which you are interested?

&#x200B;

AI

I am interested in Chinese
 culture

&#x200B;

You

What else

&#x200B;

AI

Japanese, Korean... all of them

&#x200B;

You

so Asia region?

&#x20
0B;

AI

Yes, that's the idea

&#x200B;

You

yes of course

&#x200B;

AI

Thank you for taking the time to show me thes
e extensions. This was a fascinating and enlightening experience

&#x200B;

You

yes, today was a great and long talk fo
r current session, let's save other for next time

&#x200B;

AI

Absolutely

&#x200B;

You

bye bye winking face

&#x200
B;

AI

Bye, see you soon 😎

End of session
```
---

     
 
all -  [ Chat with etwiki, servicenow other other application ](https://www.reddit.com/r/LangChain/comments/180jls4/chat_with_etwiki_servicenow_other_other/) , 2023-11-22-0910
```
Hi, 

 So I have this problem of searching asset owners and other information from different application. I want to crea
te a chatgpt which will look for information from different application and answer my question. How do I do that ?
```
---

     
 
all -  [ Comparing models for semantic search in langchain ](https://www.reddit.com/r/LangChain/comments/180jh6c/comparing_models_for_semantic_search_in_langchain/) , 2023-11-22-0910
```
I'm new to langchain and NLP. 
I've been working on a semantic search program which allows the users to find the relevan
t document from a lot. 
I've been able to create a basic code using langchain and chroma db. I see that i have multiple 
model options for this on langchain as well. I'm currently using the sentence transformer and hugging face models to do 
this. 
How do i compare which model is better?
I'm getting resultant documents and similarity ranks for them. 
I do not 
have a ground truth test dataset to check the performance (if that is how it is done). 
Is there any open source semanti
c search dataset available online?
How is it usually done to pick the best model?
Any help is appreciated, thanks.
```
---

     
 
all -  [ [Langchain] Alternatives à Openai pour les agents de Langchain ](https://www.reddit.com/r/redditenfrancais/comments/180gi9b/langchain_alternatives_à_openai_pour_les_agents/) , 2023-11-22-0910
```
Quelqu'un a-t-il réussi à utiliser des agents de Langchain alimentés par un LLM autre que ceux d'OpenAI?

Traduit et rep
osté à partir de la publication https://www.reddit.com/12r25rs
```
---

     
 
all -  [ Can we use Langchain to learn NextJS ](https://www.reddit.com/r/LangchainNextjs/comments/180enb9/can_we_use_langchain_to_learn_nextjs/) , 2023-11-22-0910
```
HelloI hesitate beetween finish my learning of 'NextJS + WPheadless' or learn LangChain+NextJS to make a bot who help me
 to code my project NextJS+Wpheadless  
what do you advise me?
```
---

     
 
all -  [ LangChain & Microsoft Unite: Advancing AI with Azure! ](https://www.reddit.com/r/u_bluebashllc/comments/180elqr/langchain_microsoft_unite_advancing_ai_with_azure/) , 2023-11-22-0910
```
 

[ LangChain & Microsoft Unite: Advancing AI with Azure! ](https://preview.redd.it/fun7h0z2po1c1.jpg?width=750&format=
pjpg&auto=webp&s=f730da91ffd10b757298469338284bc375130c9b)

LangChain and Microsoft recently teamed up for a groundbreak
ing collaboration, bringing together LangChain's context-aware reasoning prowess with Microsoft's innovation in tech saf
ety. This partnership isn't just big; it's a game-changer.

LangChain, known for its lightning-fast adaptability and cog
nitive architecture, has now become part of Microsoft's Startups Pegasus Program. This move signifies enormous growth op
portunities for LangChain, marking a significant footstep in the AI industry.

The result? Enhanced AI applications for 
a range of companies, from startups to Fortune 500 giants. LangChain's LangSmith, a SaaS solution, is geared to manage t
he lifecycle of [**large language model (LLM)-powered apps**](https://www.bluebash.co/blog/microsoft-collaboration-with-
langchain/), improving developer efficiency and ensuring reliability at scale.

But what's even more exciting? The step-
by-step guide unveiled how to seamlessly integrate **Azure OpenAI with LangChain**. This fusion of Azure's cloud power w
ith OpenAI's advanced models opens new avenues for AI development and research. 
```
---

     
 
all -  [ Embeddings - Langchain for documents on different topics ](https://www.reddit.com/r/LangChain/comments/180d0t5/embeddings_langchain_for_documents_on_different/) , 2023-11-22-0910
```
I have a chatbot, which basically does chat over document. there are multiple company information over which the chat ha
s to be functioned.   
each company information has to be segregated, mixing of information while retrieving should neve
r happen. what is the right approach for segmentation of data or document while embedding documents using langchain? (am
 using FAISS as vector database)  


u/langchain u/openai u/llm u/chatbot
```
---

     
 
all -  [ I need help to set up a new google ads campaign. ](https://www.reddit.com/r/PPC/comments/180b80u/i_need_help_to_set_up_a_new_google_ads_campaign/) , 2023-11-22-0910
```
My employer has asked me to set up a new Google ads campaign for AI services, primarily Langchain Ai services and Open A
i services.

The goal is to get leads, filling contact us forms.

The budget is 20$ per day.

The target location is USA
.

My concern is that which such low budget and high cpc keywords and broad targetting location how should I go about th
ings?

I am thinking:

Using a max conversion campaign.

Keeping 5-10 exact match, transactional/commercial intent keywo
rds/ ad group.

Creating 2 ad groups one for open ai services and another for langchain services.

My concerns:

Should 
I start with a max clicks campaign to collect conversion data and then switch to max conv when I have 10-20 conversions,
 but I am confused because with max clicks it can take a lot of time to get conversions.

Should I add phrase match keyw
ords as well? I don't want to waste the budget, so I was thinking to only include keywords that the people are directly 
searching for.

Any other suggestions on how should I go about this campaign are welcomed.

Please let me know what shou
ld I do, I'm really confused.
```
---

     
 
all -  [ Having speed trouble ](https://www.reddit.com/r/LangChain/comments/18098jg/having_speed_trouble/) , 2023-11-22-0910
```
I am having speed trouble when the conversational history is more than one question

```
rag_chain = (
    RunnablePasst
hrough.assign(context=condense_question | retriever | format_docs)
    | qa_prompt
    | llm
  )
  ai_msg_early = rag_ch
ain.invoke({'question': 'bonjour', 'chat_history': []})
```

If my code is like that, what hardware resource is the most
 responsible for speed when I invoke the chain? Is it the CPU/GPU to run the LLM or the vector querying database?
```
---

     
 
all -  [ Langchain Lambdas?!?! ](https://www.reddit.com/r/LangChain/comments/1805un7/langchain_lambdas/) , 2023-11-22-0910
```
How has nobody put out a good langchain lambda layer yet? What are yall aws folk doing about deploying recursive agents?
?? Am i missing something?
```
---

     
 
all -  [ Batch Process Dataset ](https://www.reddit.com/r/LangChain/comments/1801rsa/batch_process_dataset/) , 2023-11-22-0910
```
I am new to Langchain and needed help to perform the following task.
Task: I want to classify a dataset of texts into pr
e-defined classes (I have more than 20 classes). A text can be assigned multiple labels based on relevance. Since I have
 close to 15000 rows in my dataset, I was wondering how to do this without creating a loop and performing the classifica
tion one iteration at a time. Any ideas? 
P.S. I tried using the API for GPT 3.5 on a loop and soon faced rate limit iss
ue. My code shut down after going through 400 texts out of 15000. 
Additionally I want to make sure I am controlling the
 cost as the API calls to GPT 3.5 is becoming expensive.
```
---

     
 
all -  [ Open Source RAG Agents with Conversational Memory ](https://www.reddit.com/r/LocalLLaMA/comments/17zz5vp/open_source_rag_agents_with_conversational_memory/) , 2023-11-22-0910
```
I want to use an open source LLM as a RAG agent that also has memory of the current conversation (and eventually I want 
to work up to memory of previous conversations). I was looking into conversational retrieval agents from Langchain (link
ed below), but it seems they only work with OpenAI models. Is it possible to get an open source LLM to work with RAG and
 conversational memory using Langchain?

[https://python.langchain.com/docs/use\_cases/question\_answering/conversationa
l\_retrieval\_agents](https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents)

E
DIT:

[https://python.langchain.com/docs/use\_cases/question\_answering/#adding-memory](https://python.langchain.com/doc
s/use_cases/question_answering/#adding-memory)

Tried following the 'Adding Memory' section of main tutorial on RAG on [
Langchain.com](https://Langchain.com) linked above, tried with lots of different open source models and none of them do 
it correctly (reformulate the question into a stand alone question). Even Llama 2 70b does not do it correctly. Other mo
dels I tried were CausalLM 14b, Mistral 7b Instruct, Yarn Mistral 7b 128k, Yi 34b, Openchat, Openhermes, Zephyr 7b. They
 usually just answer the question instead of reformulating it. Maybe some more prompt engineering will help.
```
---

     
 
all -  [ OpenAI potential downfall ](https://www.reddit.com/r/LangChain/comments/17zw79w/openai_potential_downfall/) , 2023-11-22-0910
```
And this my fellow developers and founders is why you use an abstraction layer like langchain.

Just changing out one si
mple class is much better than replacing every instance of using openai api library. 😁

This is all assuming OpenAI’s do
wnfall which is not guaranteed but could definitely happen.
```
---

     
 
all -  [ Frameworks for building AI agents compared to robotics ](https://www.reddit.com/r/LangChain/comments/17zrlqm/frameworks_for_building_ai_agents_compared_to/) , 2023-11-22-0910
```
I am new to building AI agents (robotics background) and I was curious to learn about the most common workflows you guys
 use.

I have been working on LLMs as the reasoning engine of robots-- in robotics we use well-established frameworks an
d I wanted to compare them to yours.

In particular I would love to know about:

1. How do you store/replay the full pat
h that the agent has been following? 
   1. What sort of data do you collect?
   2. Does it differ between LLMs and VLMs
?
   3. Where do you store all your runs (if you store them)? 
   4. What metrics do you use for evaluating each run? I'
ve seen some interesting things from the OAI devday-- do you actually use them?
   5. Do you rely on planning techniques
 (i.e. Tree of Thought, Everything of Thought, ...)?
2. Do you have frameworks in place that allow to test agents with a
t different states and with different parameters?
   1. For instance, if you have multiple LLMs interacting and you want
 to try different versions/prompts for each.
3. Are there any techniques for autonomously improving agents performance g
iven the collected data?
4. Are there simulators for AI agents?
   1. Are there 'fake' environments for testing? Do you 
always have to test in 'production mode' or you just create mock tests?
```
---

     
 
all -  [ Seeking Advice on Automating Responses Evaluation for My Chilean Law QA-Chatbot ](/r/LocalLLaMA/comments/17zqioy/seeking_advice_on_automating_responses_evaluation/) , 2023-11-22-0910
```

```
---

     
 
all -  [ Seeking Advice on Automating Responses Evaluation for My Chilean Law QA-Chatbot ](https://www.reddit.com/r/LocalLLaMA/comments/17zqioy/seeking_advice_on_automating_responses_evaluation/) , 2023-11-22-0910
```
Hello everyone,

I'm back with an update and a new query regarding the QA-chatbot I'm developing for Chilean law, based 
on the LLM model. As a reminder, the chatbot will be primarily in Spanish, and I'm using a tech stack that includes Lang
chain, LLaMA 2 7B/13B (llama-cpp-python), Streamlit, and ChromaDB, focusing on open-source or free license software.

My
 current focus is on evaluating the chatbot's responses. I'm creating a dataset based on question-answer guides from the
 Library of Congress of Chile. This involves selecting a number of questions and their corresponding answers, posing the
se questions to the chatbot, and then assessing the accuracy of its responses. The evaluation criteria include correctne
ss of information, absence of hallucinations, and relevancy to the question asked.

Originally, I planned to conduct thi
s evaluation manually. However, I'm now seeking advice on how to make this process more efficient and possibly automated
. What tools or methods can I use to streamline the evaluation of the chatbot's responses? Are there any best practices 
or software that can help in comparing the chatbot's answers with the dataset for accuracy and relevance?

Any insights 
or suggestions from this community would be greatly appreciated!

Emer
```
---

     
 
all -  [ Alternatives to fine-tuned GPT-3.5 models with good LangChain support? ](https://www.reddit.com/r/LangChain/comments/17zqaa4/alternatives_to_finetuned_gpt35_models_with_good/) , 2023-11-22-0910
```
I'm building out a suite of RAG tools and ingestion pipelines that were heavily reliant on a bunch of small, focused fin
e-tuned GPT 3.5 models to transform this or tag that.

Obviously I can't rely on OpenAI going forward as they, ironicall
y, have not consistently been candid in their communications and I've lost confidence in their ability.

Looking for som
ething I can relatively painlessly transition my training dataset to and start swapping out LLM calls.
```
---

     
 
all -  [ LangChain versus GPTs ](https://www.reddit.com/r/ChatGPTPro/comments/17zpfkb/langchain_versus_gpts/) , 2023-11-22-0910
```
LangChain/HuggingFace versus GPTs

I’m trying to understand the distinct advantages of using frameworks like LangChain o
r Hugging Face compared to creating GPTs, in the context of automating a series of prompts and connect those with APIs. 


Here’s my situation: I’m enrolling in a course to master LangChain (promoted by my manager 2 weeks ago), but I’m curio
us whether it’s necessary or advantageous to use a platform like LangChain or Hugging Face now that GPTs are the new kid
 in town. What benefits do these platforms offer over creating GPTs? Are there specific scenarios where one approach is 
clearly superior to the other?

Any insights, experiences, or advice you can share would be greatly appreciated. I’m cur
rently a bit overwhelmed..
```
---

     
 
all -  [ Difference between RetrievalQA, RetreivalQAWithSources, ConversationRetrievalChain ](https://www.reddit.com/r/LangChain/comments/17zlkb9/difference_between_retrievalqa/) , 2023-11-22-0910
```
Hi,

I am learning on Langchain and saw that there are different chains like RetrievalQA, RetreivalQAWithSources, Conver
sationRetrievalChain. What is the difference between those chains?

My use case would be to crete a RAG application wher
e the user can ask questions to the model. So which chain would be best for this use case?
```
---

     
 
all -  [ Does splitting into more smaller chunks, impact the speed of the application? ](https://www.reddit.com/r/LangChain/comments/17zjrwl/does_splitting_into_more_smaller_chunks_impact/) , 2023-11-22-0910
```
Does splitting into more smaller chunks, impact the speed of the application? 

I am using text-embedding-ada-002 of ope
nAI , which accepts **8192 tokens!**

**so if i make chunks of 4000 or 2000 , would impact embedding or vector-store ret
rieval in anyway?**
```
---

     
 
all -  [ increase speed of my question answering pdf application ](https://www.reddit.com/r/LangChain/comments/17zjo2q/increase_speed_of_my_question_answering_pdf/) , 2023-11-22-0910
```
Hi I am new to this field(new with python and AI both) and trying to make an application using langchain OpenAI and fais
s. MY application is working well but its pretty slow. what can i do to increase the speed? splitting, embedding, retrie
val , where can i work to increase the speed? 
```
---

     
 
all -  [ Upload excel file with SQLDatabase ](https://www.reddit.com/r/learnpython/comments/17zj092/upload_excel_file_with_sqldatabase/) , 2023-11-22-0910
```
A noob here. What do you think is currently the best way to upload an excel file to a URL and save it in a variable. To 
be able to continue using it as a langchain object.
```
---

     
 
all -  [ ChatBot Project Help ](https://www.reddit.com/r/LangChain/comments/17zhz03/chatbot_project_help/) , 2023-11-22-0910
```
I am trying to build a chatbot that will be hosted on a website within a well-being context. The ChatBot’s main task is 
to help users craft SMART goals within an aspect of well being. A potential user query may look like this

USER: “I woul
d like to improve my physical health, could you help me build a goal around that?”

I’m a bit lost on what approach I sh
ould take. I’ve considered crafting a database of desired conversations and fine-tune GPT 3, however I’m not sure.

Shou
ld I make a vector database of conversations, then embed the most likely answer given a specific user prompt into an Ope
nAI API prompt? 

Any suggestions/resources would really help out. Thank you!
```
---

     
 
all -  [ Looking for (paid) help to create vector database and embed with open AI API ](https://www.reddit.com/r/LangChain/comments/17zflxg/looking_for_paid_help_to_create_vector_database/) , 2023-11-22-0910
```
Hello

I have an app based on the open AI GPT4 API. I was looking to embed a database of information (currently it is an
 XML file). Is anyone interested in helping, or able to steer me in the direction of someone who can? Thanks!
```
---

     
 
all -  [ Why can't I load these models through the Hub api ? ](https://www.reddit.com/r/huggingface/comments/17yzvw7/why_cant_i_load_these_models_through_the_hub_api/) , 2023-11-22-0910
```
I'm able to load Mistral-7b-Instruct, but when I try to load OpenHermes or OpenOrca (Mistral) I just get a time out erro
r. I'm talking about api and langchain.
```
---

     
 
all -  [ The Problem With LangChain ](https://www.reddit.com/r/LangChain/comments/17yjgsj/the_problem_with_langchain/) , 2023-11-22-0910
```
[https://minimaxir.com/2023/07/langchain-problem/](https://minimaxir.com/2023/07/langchain-problem/)

Thoughts 4 months 
later? Also comments from here:

[https://news.ycombinator.com/item?id=36648142](https://news.ycombinator.com/item?id=36
648142)

[https://www.reddit.com/r/LangChain/comments/1508gb0/the\_problem\_with\_langchain/](https://www.reddit.com/r/L
angChain/comments/1508gb0/the_problem_with_langchain/)

Personally I am going with Haystack for a RAG bot due to a user 
in the Haystach discord saying it has the best developer experience comparde to langchain and llamaindex, to quote:

' Y
ou can do pretty much everything with all three of them. Langchain is a base with lots of possible connectors. LlamaInde
x builds on top of it with a lot of strategies to split text/retrieve it.

I’ve used both and stayed with haystack. The 
documentation is superior, imo and developing anything beyond the first tutorial is easier. With langchain you run into 
the problem that you lose track of the possibilities and different parts have different features (example: Two vector st
ores but one has only some of the functions available :/)'
```
---

     
 
all -  [ Re-Ranker model in QA chain ](https://www.reddit.com/r/LangChain/comments/17ya8xh/reranker_model_in_qa_chain/) , 2023-11-22-0910
```
Hello all, I am curious in langchain if we can use a open source re rankers models to rerank retrieval results. I have s
een the documentations on the cohere ranker, but how do I integrate other re ranker models like BAAI/bge-reranker-large 
into langchain?


I really appreciate any help/advice! Thank You.
```
---

     
 
all -  [ Google PaLM Error [D] ](https://www.reddit.com/r/MachineLearning/comments/17y7arb/google_palm_error_d/) , 2023-11-22-0910
```
Google PaLM Error

Using LangChain and Google PaLM, in sequential chain concept getting following error,

ChatGooglePalm
Error: ChatResponse must have atleast one candidate

Please help!
```
---

     
 
all -  [ Problem while using CSV agent. ](https://www.reddit.com/r/LangChain/comments/17xxt9s/problem_while_using_csv_agent/) , 2023-11-22-0910
```
So, I'm doing a project on chat with CSV files, as the name user can ask question in natural language and the CSV agent 
is suppose to generate a pandas code, run it and get the answer in response. I have three csv files on financial perform
ance of a company, the problem is agent is able to generate the code but it generates code with incorrect declared varia
bles and when it try to runs it, it gets value error and the AgentExecutor chain stops.   


**For LLM I'm using Anthrop
ic Claude V2 by AWS Bedrock service**.

Example of the problem I'm having: 

I asked question: What is the total AUM for
 Japan?

Here is the verbose the agent produce:  


[First exception which causes the value error](https://preview.redd.
it/stnqduf7311c1.png?width=1327&format=png&auto=webp&s=8640d40430cea5c188535cfa5a6d7c90701ca392)

&#x200B;

https://prev
iew.redd.it/m2idg49b311c1.png?width=1388&format=png&auto=webp&s=ac4794b3955f496ebe0a12c2e9fb2d45fa1212ea

What can I do 
to make the agent generate correct code? Also I tried the Pandas dataframe agent as well as I pass the 'handle\_parsing\
_errors = True' parameter during Agent initialization but I'm getting same problem. 
```
---

     
 
all -  [ OpenAI fires Sam Altman ](https://www.reddit.com/r/LangChain/comments/17xox8b/openai_fires_sam_altman/) , 2023-11-22-0910
```
I wonder if this has anything to do with subscriptions getting limited recently and costs going over the roof 🤔
```
---

     
 
all -  [ How to create Async Tools in LangChain? ](https://www.reddit.com/r/LangChain/comments/17xlkxg/how_to_create_async_tools_in_langchain/) , 2023-11-22-0910
```
Hello folks,

Is there documentation on how to create an Async Tool for an agent? 

I'm trying to run a headless browser
 (using pyppeteer) for an agent to use but I'm not sure how I can integrate the asynchronous code of pyppeteer as a tool
.
```
---

     
 
all -  [ Training LLMs to follow procedure for Math gives an accuracy of 98.5% ](https://www.reddit.com/r/LangChain/comments/17xj0ha/training_llms_to_follow_procedure_for_math_gives/) , 2023-11-22-0910
```
Github Link: https://github.com/desik1998/MathWithLLMs

Although LLMs are able to do a lot of tasks such as Coding, scie
nce etc, they often fail in doing Math tasks without a calculator (including the State of the Art Models). 

Our intuiti
on behind why models cannot do Math is because the instructions on the internet are something like a x b = c and do not 
follow the procedure which we humans follow when doing Math. For example when asked any human how to do 123 x 45, we fol
low the digit wise multiplication technique using carry, get results for each digit multiplication and then add the corr
esponding resulting numbers. But on the internet, we don't show the procedure to do Math and instead just right the corr
ect value. And now given LLMs are given a x b = c, they've to reverse engineer the algorithm for multiplication. 

Most 
of the existing Literature gives instructions to the LLM instead of showing the procedure and we think this might not be
 the best approach to teach LLM. 

### What this project does?
This project aims to prove that LLMs can learn Math when 
trained on a step-by-step procedural way similar to how humans do it. It also breaks the notion that LLMs cannot do Math
 without using calculators. For now to illustrate this, this project showcases how LLMs can learn multiplication. The ra
tionale behind taking multiplication is that GPT-4 cannot do multiplication for >3 digit numbers. We prove that LLMs can
 do Math when taught using a step-by-step procedure. For example, instead of teaching LLMs multiplication like 23 * 34 =
 782, we teach it multiplication similar to how we do digit-wise multiplication, get values for each digit multiplicatio
n and further add the resulting numbers to get the final result.

**Instruction Tuning:**
We've further done finetuning 
on OpenAI's GPT-3.5 to teach Math.

There are close to 1300 multiplication instructions created for training and 200 for
 validation. The test cases were generated keeping in mind the OpenAI GPT-3.5 4096 token limit. A 5 x 5 digit multiplica
tion can in general fit within 4096 limit but 6 x 6 cannot fit. But if one number is 6 digit, the other can be <= 4 digi
t and similarly if 1 number is 7 digit then the other can be <= 3 digit.

Also instead of giving * for multiplication an
d + for addition, different operators' <<*>> and <<<+>>> are given. The rationale behind this is, using the existing * a
nd + for multiplication and addition might tap on the existing weights of the neural network which doesn't follow step-b
y-step instruction and directly give the result for multiplication in one single step.

[Sample Instruction](https://pas
tebin.com/VZNUHQVQ)

![**The overall training/validation loss goes to 0 within 0.1 epochs**](https://raw.githubuserconte
nt.com/desik1998/MathWithLLMs/main/Training_and_Validation_Loss.png)

### Results
The benchmarking was done on 200 test 
cases where each test case has two random numbers generated. For the 200 samples which were tested, excluding for 3 case
s, the rest of the cases the multiplication is correct. Which means this overall accuracy is **98.5%**. (We're also look
ing for feedback from community about how to test this better.)

### Future Improvements
* Reach out to AI and open-sour
ce community to make this proposal better or identify any flaws.
* Do the same process of finetuning using open-source L
LMs.
* Figure out what's the smallest LLM that can do Math accurately when trained in a procedural manner (A 10 year kid
 can do Math). Check this for both normal models and distilled models as well.

Requesting for Feedback from AI Communit
y!
```
---

     
 
all -  [ No module named 'openai'ImportError: Could not import openai python package. Please install it with  ](https://www.reddit.com/r/CodingHelp/comments/17xiicf/no_module_named_openaiimporterror_could_not/) , 2023-11-22-0910
```
raceback (most recent call last):  
  
  File '/home/adminuser/venv/lib/python3.9/site-packages/langchain/llms/openai.
py', line 294, in validate\_environment  
  
import openai  
  
ModuleNotFoundError: No module named 'openai'  
  

  
During handling of the above exception, another exception occurred:  
  
  
Traceback (most recent call last): 
 
  
  File '/home/adminuser/venv/lib/python3.9/site-packages/streamlit/runtime/scriptrunner/script\_runner.py', line 5
34, in \_run\_script  
  
exec(code, module.\_\_dict\_\_)  
  
  File '/mount/src/streamlit-app/seq\_gpt\_memory.py'
, line 35, in <module>  
  
llm = OpenAI(temperature=0.9)  
  
  File '/home/adminuser/venv/lib/python3.9/site-packa
ges/langchain/load/serializable.py', line 97, in \_\_init\_\_  
  
super().\_\_init\_\_(\*\*kwargs)  
  
  File '/ho
me/adminuser/venv/lib/python3.9/site-packages/pydantic/v1/main.py', line 339, in \_\_init\_\_  
  
values, fields\_set
, validation\_error = validate\_model(\_\_pydantic\_self\_\_.\_\_class\_\_, data)  
  
  File '/home/adminuser/venv/li
b/python3.9/site-packages/pydantic/v1/main.py', line 1102, in validate\_model  
  
values = validator(cls\_, values) 
 
  
  File '/home/adminuser/venv/lib/python3.9/site-packages/langchain/llms/openai.py', line 296, in validate\_environ
ment  
  
raise ImportError(  
  
ImportError: Could not import openai python package. Please install it with \`pip 
install openai\`.  
  
2023-11-17 16:03:06.141 Uncaught app exception  
  
Traceback (most recent call last):  
  

  File '/home/adminuser/venv/lib/python3.9/site-packages/langchain/llms/openai.py', line 294, in validate\_environment
  
  
import openai  
  
ModuleNotFoundError: No module named 'openai'  
  
  
During handling of the above except
ion, another exception occurred:  
  
  
Traceback (most recent call last):  
  
  File '/home/adminuser/venv/lib/p
ython3.9/site-packages/streamlit/runtime/scriptrunner/script\_runner.py', line 534, in \_run\_script  
  
exec(code, m
odule.\_\_dict\_\_)  
  
  File '/mount/src/streamlit-app/seq\_gpt\_memory.py', line 35, in <module>  
  
llm = Open
AI(temperature=0.9)  
  
  File '/home/adminuser/venv/lib/python3.9/site-packages/langchain/load/serializable.py', lin
e 97, in \_\_init\_\_  
  
super().\_\_init\_\_(\*\*kwargs)  
  
  File '/home/adminuser/venv/lib/python3.9/site-pac
kages/pydantic/v1/main.py', line 339, in \_\_init\_\_  
  
values, fields\_set, validation\_error = validate\_model(\_
\_pydantic\_self\_\_.\_\_class\_\_, data)  
  
  File '/home/adminuser/venv/lib/python3.9/site-packages/pydantic/v1/ma
in.py', line 1102, in validate\_model  
  
values = validator(cls\_, values)  
  
  File '/home/adminuser/venv/lib/p
ython3.9/site-packages/langchain/llms/openai.py', line 296, in validate\_environment  
  
raise ImportError(  
  
Im
portError: Could not import openai python package. Please install it with \`pip install openai\`.
```
---

     
 
MachineLearning -  [ [D] System Design question for LangChain ](https://www.reddit.com/r/MachineLearning/comments/17x545j/d_system_design_question_for_langchain/) , 2023-11-22-0910
```
Hi

Just to prepare the system design question for LangChain. Is there a resource that can walk me through the high leve
l pipeline? I know there are a bunch of resources that dive into detail implementation. But that's not I want. I want hi
gh level conceptual walk-through. 
```
---

     
 
MachineLearning -  [ [P] GPT vs. StarCraft ](https://www.reddit.com/r/MachineLearning/comments/17ro6el/p_gpt_vs_starcraft/) , 2023-11-22-0910
```
This is the first in a series of webcasts covering the development and experimentation of using GPT algorithms, LangChai
n and Python to control the high-level strategy of a StarCraft II bot. I’ll be running through the basics of the impleme
ntation, discussing the use of prompts and prompt engineering, and demonstrating the implementation in action.

[https:/
/youtu.be/E3Sj2L6ZnXA](https://youtu.be/E3Sj2L6ZnXA)
```
---

     
 
MachineLearning -  [ [D] Is this close enough to be usable? Need your inputs: Automated RAG testing tool. AI Data Pipelin ](https://www.reddit.com/r/MachineLearning/comments/17kkbm0/d_is_this_close_enough_to_be_usable_need_your/) , 2023-11-22-0910
```
Hey there, Redditors! 

I'm back with the latest installment on creating dependable AI data pipelines for real-world pro
duction. 

If you've been following along, you know I'm on a mission to move beyond the '[thin OpenAI wrapper](https://t
opoteretes.notion.site/Going-beyond-Langchain-Weaviate-and-towards-a-production-ready-modern-data-platform-7351d77a1eba4
0aab4394c24bef3a278?pvs=4)' trend and tackle the challenges of building robust data pipelines. 

With 18 months of hands
-on experience and many user interviews, I realized that with the probabilistic nature of systems, we need better\_testi
ng.gpt:

  
**1. As you build you should test**  
The world of AI is a fast-moving one, and we've realized that just wor
king on systems is not an optimal design choice. By the time your product ships, it might already be using outdated tech
nology. So, what's the lesson here? Embrace change, test along, but be prepared to switch pace.  
**2. No Best Practices
 Yet for RAGs**  
In this rapidly evolving landscape, there are no established best practices. You'll need to make educa
ted bets on tools and processes, knowing that things will change. With the RAG testing tool, I tried allowing for testin
g many potential parameter combinations **automatically**  
**3. Testing Frameworks**  
If your generative AI product do
esn't have users giving feedback, then you are building in isolation. I used [Deepeval](https://github.com/confident-ai/
deepeval) to generate test sets, and they will soon support synthetic test set generation  
**4. Infographics only go so
 far**  
AI researchers and data scientists, while brilliant, end up in a loop of pursuing Twitter promotional content. 
New ways are promoted via new content pieces, but ideally, we need something above simple tracing but less than full-fle
dged analytics. To do this, I stored test outputs in Postgres and created a Superset instance to visualize the results  

**5. Bridging the Gap between VectorDBs**  
There's a noticeable number of Vector DBs. To ensure smooth product develop
ment, we need to be able to switch to best best-performing one, especially since user interviews signal that they might 
start deteriorating after loading 50 million rows

&#x200B;

Github repo is [here](https://topoteretes.notion.site/Going
-beyond-Langchain-Weaviate-Level-3-towards-production-e62946c272bf412584b12fbbf92d35b0?pvs=4)  


Next steps:  
I have q
uestions for you: 

1. What variables do you change when building RAGs?
2. What is the set of strategies I should add to
 the solution? (parent-son etc.)
3. How can I improve it in general? 
4. Is anyone  interested in a leaderboard for best
 parameter configs?

Check out the blog post:

[Link to part 3](https://topoteretes.notion.site/Going-beyond-Langchain-W
eaviate-Level-3-towards-production-e62946c272bf412584b12fbbf92d35b0?pvs=4)

  
*Remember to give this post an upvote if 
you found it insightful!*  
*And also star our* [*Github repo*](https://github.com/topoteretes/PromethAI-Memory)
```
---

     
 
MachineLearning -  [ [D] Relevance Extraction in RAG Pipelines ](https://www.reddit.com/r/MachineLearning/comments/17k6iha/d_relevance_extraction_in_rag_pipelines/) , 2023-11-22-0910
```
I came across this interesting problem in RAG, what I call **Relevance Extraction**.

After retrieving relevant document
s (or chunks), these chunks are often large and may contain several portions **irrelevant** to the query at hand. Stuffi
ng the entire chunk into an LLM prompt impacts token-cost as well as response accuracy (distracting the LLM with irrelev
ant text), and and can also cause bumping into context-length limits.

So a critical step in most pipelines is **Relevan
ce Extraction**: use the LLM to extract **verbatim** only the portions relevant to the query. This is known by other nam
es, e.g. LangChain calls it Contextual Compression, and the RECOMP paper calls it Extractive Compression [https://twitte
r.com/manelferreira\_/status/1713214439715938528](https://twitter.com/manelferreira_/status/1713214439715938528)

Thinki
ng about how best to do this, I realized it is **highly inefficient** to simply ask the LLM to 'parrot' out relevant por
tions of the text: this is obviously slow, and also consumes valuable token generation space and can cause you to bump i
nto context-length limits (and of course is expensive, e.g. for gpt4 we know generation is 6c/1k tokens vs input cost of
 3c/1k tokens).

I realized the best way (or at least a good way) to do this is to **number** the sentences and have the
 LLM simply spit out the relevant sentence **numbers.** Langroid's unique Multi-Agent + function-calling architecture al
lows an elegant implementation of this, in the RelevanceExtractorAgent ([https://github.com/langroid/langroid/blob/main/
langroid/agent/special/relevance\_extractor\_agent.py](https://github.com/langroid/langroid/blob/main/langroid/agent/spe
cial/relevance_extractor_agent.py)).  The agent annotates the docs with sentence numbers, and instructs the LLM to pick 
out the **sentence-numbers** relevant to the query, rather than whole sentences using a function-call (SegmentExtractToo
l [https://github.com/langroid/langroid/blob/main/langroid/agent/tools/segment\_extract\_tool.py](https://github.com/lan
groid/langroid/blob/main/langroid/agent/tools/segment_extract_tool.py)), and the agent's function-handler interprets thi
s message and strips out the indicated sentences by their numbers. To extract from a set of passages, langroid automatic
ally does this async + concurrently so latencies in practice are much, much lower than the sentence-parroting approach.


\[FD -- I am the lead dev of Langroid - [https://github.com/langroid/langroid](https://github.com/langroid/langroid))


I thought this **numbering** idea is a fairly obvious idea in theory, so I looked at LangChain's equivalent `LLMChainExt
ractor` (they call this Contextual Compression [https://python.langchain.com/docs/modules/data\_connection/retrievers/co
ntextual\_compression?ref=blog.langchain.dev](https://python.langchain.com/docs/modules/data_connection/retrievers/conte
xtual_compression?ref=blog.langchain.dev)) and was surprised to see it is the simple '**parrot**' method, i.e. the LLM w
rites out whole sentences verbatim from its input. I thought it would be interesting to compare Langroid vs LangChain, y
ou can see it in this Colab: [https://colab.research.google.com/drive/1RDPCR2xNuBffcmpUuPIXYDRG3SXIJC5F](https://colab.r
esearch.google.com/drive/1RDPCR2xNuBffcmpUuPIXYDRG3SXIJC5F)

On the specific example in the notebook, the Langroid **num
bering** approach is 22x faster and 36% cheaper (with gpt4) than LangChain's **parrot** method (I promise this name is *
not* inspired by their logo :). See table below.

&#x200B;

[Relevance Extraction: Langroid vs LangChain](https://previe
w.redd.it/1m7u6ulq8fxb1.png?width=1108&format=png&auto=webp&s=d2f35cf5db07e2e699baa54b274ffa60833e924a)

&#x200B;

I won
der if anyone had thoughts on relevance extraction, or other approaches. At the very least, I hope langroid's implementa
tion is useful to you -- you can use the `DocChatAgent.get_verbatim_extracts()` ([https://github.com/langroid/langroid/b
lob/main/langroid/agent/special/doc\_chat\_agent.py#L804](https://github.com/langroid/langroid/blob/main/langroid/agent/
special/doc_chat_agent.py#L804)) as part of your pipeline, regardless of whether you are using Langroid for your entire 
system or not.

&#x200B;
```
---

     
 
MachineLearning -  [ [R] Model Troubles ](https://www.reddit.com/r/MachineLearning/comments/17ikh2u/r_model_troubles/) , 2023-11-22-0910
```
So i’m working on a model that diagnoses alzheimer’s disease and suggests medication depending on how severe the symptom
s might have become 
I’m using the Openai API and Langchain.

But it’s dumb and it doesn’t learn (
Me: I forgot my keys 
at home
Model: Yup, Alzheimer’s)
How do i incorporate the actual machine learning

Edit: I didn’t choose this project my
 supervisor did and she barely knows anything about the topic or how to approach it
```
---

     
 
MachineLearning -  [ [P] NexaAgent: A highly efficient multi-task PDF tool for all your needs | backed by AutoGen ](https://www.reddit.com/r/MachineLearning/comments/17eajz2/p_nexaagent_a_highly_efficient_multitask_pdf_tool/) , 2023-11-22-0910
```
Just a quick open-source project recently submitted to huggingface backed by AutoGen. Share this initial version with yo
u guys!

[NexaAgent 0.0.1](https://huggingface.co/spaces/xuyingliKepler/nexaagent) offers a straightforward solution for
 handling PDFs.

* Users can easily upload any PDF, regardless of its size.
* The tool emphasizes accuracy, minimizing d
iscrepancies in PDF processing.

At its core, NexaAgent is backed by the AutoGen and LangChain frameworks. AutoGen facil
itates multi-agent interactions for task execution, while LangChain bridges LLMs with external data sources. Together, t
hese technologies ensure NexaAgent's robust and precise PDF management capabilities.

https://preview.redd.it/kwgo3phnav
vb1.jpg?width=1440&format=pjpg&auto=webp&s=1c5fbc566938d60d5c43802aff3a0690821e1c79
```
---

     
