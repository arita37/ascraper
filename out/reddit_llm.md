 
all -  [ Why is Langchain so frustrating to work with? ](https://www.reddit.com/r/LangChain/comments/1bdaqpw/why_is_langchain_so_frustrating_to_work_with/) , 2024-03-13-0909
```
I am following a couple of tutorials from [https://sdk.vercel.ai/docs](https://sdk.vercel.ai/docs) on setting up my own 
NEXT.js chat bot with a RAG model; coincidentally I failed to find anything LangChain that is working with Azure OpenAI;
 heck even the import statements for langchain are deprecated; it keeps displaying errors in the terminal
```
---

     
 
all -  [ Can LangSmith trace Ollama? ](https://www.reddit.com/r/LangChain/comments/1bd7uqb/can_langsmith_trace_ollama/) , 2024-03-13-0909
```
Hi everyone. I am new to LangChain.

&#x200B;

I have set

&#x200B;

    export LANGCHAIN_TRACING_V2='true'
    export L
ANGCHAIN_API_KEY='<my-api-key>'
    export LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

&#x200B;

&#x200B;

and I
 invoke an LLM powered by Ollama, I can't really see anything in [https://smith.langchain.com/](https://smith.langchain.
com/). I haven't tried using GPT or other FM. Does LangSmith currently not support Ollama?

&#x200B;

TIA!
```
---

     
 
all -  [ LLM Model VRAM Calculator - a Hugging Face Space by NyxKrage ](https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator) , 2024-03-13-0909
```

```
---

     
 
all -  [ I finally tested LangChain + Amazon Bedrock for an end-to-end RAG pipeline ](https://www.reddit.com/r/LangChain/comments/1bd55re/i_finally_tested_langchain_amazon_bedrock_for_an/) , 2024-03-13-0909
```
Hi folks!

I read about it when it came out and had it on my to-do list for a while now...

I finally tested Amazon Bedr
ock with LangChain. **Spoiler:** The Knowledge Bases feature for Amazon Bedrock is a super powerful tool if you don't wa
nt to think about the RAG pipeline, it does everything for you.

I wrote a (*somewhat boring but*) helpful blog post abo
ut what I've done with screenshots of every step. So if you're considering Bedrock for your LangChain app, check it out 
it'll save you some time: [https://www.gettingstarted.ai/langchain-bedrock/](https://www.gettingstarted.ai/langchain-bed
rock/)

Here's the gist of what's in the post:

* Access to foundational models like Mistral AI and Claude 3
* Building 
partial or end-to-end RAG pipelines using Amazon Bedrock
* Integration with the LangChain Bedrock Retriever
* Consuming 
Knowledge Bases for Amazon Bedrock with LangChain
* And much more...

Happy to answer any questions here or take in sugg
estions! 

Let me know if you find this useful. Cheers üçª
```
---

     
 
all -  [ Benchmarking extraction_chain ](https://www.reddit.com/r/LangChain/comments/1bd4uj9/benchmarking_extraction_chain/) , 2024-03-13-0909
```
Hi there. I am trying to figure out the best way to start benchmarking the langchain\_extraction\_chain between differen
t versions and models. I need to be able to determine how accurate these extraction are on large txt files. Any suggesti
ons that can make my life easier? 
```
---

     
 
all -  [ How to use local hosted LLMs in LangChain ](https://www.reddit.com/r/LangChain/comments/1bd4gjp/how_to_use_local_hosted_llms_in_langchain/) , 2024-03-13-0909
```
I have one LLM service running, how to use that remote LLM service as LLM in LangChain. There is no clear documentation 
about it.
```
---

     
 
all -  [ Need your help switching jobs in this markrt as an ML engineer. ](https://www.reddit.com/r/developersIndia/comments/1bd446p/need_your_help_switching_jobs_in_this_markrt_as/) , 2024-03-13-0909
```
I need guidance to switch to a pure ML enginner role.So it might seem like a rant or something but here it is. I graduat
ed in '22 and joined a big 4 in their consulting division as an analyst. I had some projects related to machine learning
 so they put me as a data scientist in a project. So now in this project after 18 months I have been just executing exis
ting code every month  to deliver it to the client. At first I was ok as I was learning stuff but now it seems really re
dundant. I recently got a chance to develop a new code, basically developing and deploying ML pipeline related to regres
sion , but guess what client doesnot want this now. The work also does not makes sense any output or prediction is gener
ated on a really small datasets and it is furhter 'optimized' or basically a code is made to literally add subtract stuf
f from it. Why even care to do all the ML stuff. I want to get in genAI and LLMs stuff there are other people working on
 it in different projects but my current project doesnot wants to leave me (doing good work is also bad i think) I have 
also communicated to my lead about it and their reply is we will see we cannot let you go now. I have done some self pro
jects on genai and Langchain and have been applying everywhere I get a chance but I am getting no response. In this proj
ect I have worked using python sql excel (client needs the results in excel and the more complex it is the more they lov
e it) and have done a work of ML engineer (even written unittests for functions) and a business analyst also but half th
e pay. My notice period is 90 days and guess what they give pay raise in month of may-june. So what do I do now. Should 
I f**k up intentiaonally to get off the project or just resign. Coz a lot of companies have just ghosted me after the no
tice period. And the new llms stuff is crazy the tech is new and the scope is vast. I am ready to work 6 days for a new 
pre revenue startup also I just want work on something new .
```
---

     
 
all -  [ Are there any good tools/frameworks that chats over SQL db? ](https://www.reddit.com/r/LocalLLaMA/comments/1bd33s3/are_there_any_good_toolsframeworks_that_chats/) , 2024-03-13-0909
```
So it's been a while since i tinkered w/ llm frameworks, and now I'm looking for something that allows me to chat/work o
ver my CRM sqlite db and ideally have reasoning capabilities.

What are some newest / reliable tools that enable this? A
 year ago when I played w/ llm, theres langchain, griptape, haystack, etc, but now are there better tools now?

Thanks f
or any pointers and suggestions!
```
---

     
 
all -  [ LangGraph for beginners  ](https://www.reddit.com/r/LangChain/comments/1bd14bn/langgraph_for_beginners/) , 2024-03-13-0909
```
Hey everyone, checkout this new tutorial to understand the basics of LangGraph with an example, codes and visualization 
https://youtu.be/nmDFSVRnr4Q?si=ysPGMBvlzGabwChv
```
---

     
 
all -  [ Optimal retrieval methods for image compliance analysis ](https://www.reddit.com/r/LangChain/comments/1bcxe73/optimal_retrieval_methods_for_image_compliance/) , 2024-03-13-0909
```
Hi !

I'm working on a project where the main goal is to assess the compliance of images based on their descriptions.

I
 have already worked on a V1 that uses a gpt assistant and autogen. It works but for cost and performance issues I want 
to use langchain.

Here's the workflow I'm using:

1. **Image Description**: Generate a detailed description of an image
. (GPT-4V)
2. **Text Retrieval**: Using retrieval to find texts that are relevant to this description. (GPT Assistant)
3
. **Compliance Analysis**: Analyze the description and retrieved texts to assess if the image is compliant. (GPT 3.5 Tur
bo)

I am currently trying to recreate the text retrieval part using Langchain but querying the DB with a description le
ads to bad results. I also tried to use a MultiQueryRetriever but the questions are not really relevant even when I adju
st the prompt

I'd greatly appreciate any insights or recommendations on:

* Effective retrieval techniques for this use
 case.
* How to leverage Langchain's capabilities for both generating pertinent queries from image descriptions and retr
ieving relevant texts.
* Tips on ensuring the relevance and quality of the retrieved texts for accurate compliance analy
sis.



Thank you for your help !
```
---

     
 
all -  [ How to store text chunks and immediate images following the text chunks together in a vector databas ](https://www.reddit.com/r/LocalLLaMA/comments/1bcww9m/how_to_store_text_chunks_and_immediate_images/) , 2024-03-13-0909
```
I'm working on a Question Answering RAG system with langchain which takes in Pdf with images. The issue is with the retr
ieval strategy. For example, there's a text line followed by an image where the line says 'The following is an image of 
ABC object and its components' and the image has nothing mentioned as ABC just the plain picture of it. Currently, I'm e
xtracting all the text and images and storing the embedding in a vector store.

When I ask a question on the ABC object,
 it's only retrieving that text line and not the image, because the image has no info that says it's an ABC object.

Is 
there any way to solve this and store the relation between the text and the images?

PS: I'm new to LLMs.
```
---

     
 
all -  [ Dotprod vs Cosine Similarity ? ](https://www.reddit.com/r/LangChain/comments/1bcvhad/dotprod_vs_cosine_similarity/) , 2024-03-13-0909
```
Hello I am wondering what is the difference between Cosine similarity ans Dot products in term of efficiency 

My use ca
se is a really technical book of 1000 pages (that does not always have the same length) 
and I chunked the book by page 
meaning 1000 vectors .

What best method should I consider ? 
```
---

     
 
all -  [ Internet Based RAG - Scraping ](https://www.reddit.com/r/LangChain/comments/1bcrzbm/internet_based_rag_scraping/) , 2024-03-13-0909
```
I'm working on a RAG system that doesn't have a pre-build document corpus, and instead scrapes the internet for informat
ion in real time. It seemed like a pretty simple task, but I'm having trouble with the web-scraping aspect. I'm pretty n
ew to any sort of scraping so I need to get an idea of this - is it a pretty easy task to scrape Google search - like sc
raping the top 5 links of 10 different search queries? I feel like that's not a huge number, but I'm already having issu
es and I think they're related to Google blocking bots. Is this something that you need to use an API for or is it prett
y easy to work around with some proxy changes and stuff?
```
---

     
 
all -  [ I don't get Ollama ](https://www.reddit.com/r/LangChain/comments/1bcrva0/i_dont_get_ollama/) , 2024-03-13-0909
```
I'm working on a project where I'll be using an open-source llm - probably quantized Mistral 7B. Now I've seen allot of 
people talking about Ollama and how it lets you run llm models locally. I still don't get what it does. Like can't you a
lready run models locally if you have enough RAM, a good GPU etc.? Does Ollama quantize the models to make it easier to 
run them locally? If that's what it does then it's no different from quantizing a model yourself and running it on your 
own system right? Ik that's not just it so would really appreciate it if someone could explain exactly what it does. Als
o would Ollama also help with deploying models on the cloud? My computer only has a CPU and I'll probably be using GCP f
or the llm - so would using Ollama be useful there? Because I've only seen it mentioned with regards to how good it is f
or local deployment
```
---

     
 
all -  [ What role does artificial intelligence play in the LangChain platform? ](https://www.reddit.com/r/u_fxdatalabs_Yp/comments/1bcpslu/what_role_does_artificial_intelligence_play_in/) , 2024-03-13-0909
```
 

# What role does artificial intelligence play in the LangChain platform?

 

## Language Learning with AI: The Role o
f LangChain! üåêü§ñ

 

## Introduction:

In today's [**interconnected**](https://fxdatalabs.com/) world, language learning 
has become a vital skill for individuals seeking to navigate diverse [**cultural**](https://fxdatalabs.com/) landscapes 
and [**global**](https://fxdatalabs.com/) markets.

With the advent of [**technology**](https://fxdatalabs.com/), artifi
cial intelligence (AI) has emerged as a powerful tool in revolutionizing the language learning experience. [**LangChain*
*](https://fxdatalabs.com/), a leading language learning platform, [**harnesses**](https://fxdatalabs.com/) the capabili
ties of AI to provide users with personalized, immersive, and effective language learning [**experiences**](https://fxda
talabs.com/).

In this comprehensive [**article**](https://fxdatalabs.com/), we delve into the multifaceted role of arti
ficial intelligence within the LangChain [**platform**](https://fxdatalabs.com/), exploring its innovative features, ben
efits, and the transformative impact it has on language [**acquisition**](https://fxdatalabs.com/).

## Understanding th
e Importance of Artificial Intelligence in Language Learning:

üì∑

In traditional language [**learning**](https://fxdatal
abs.com/) settings, instructors often face challenges in catering to the diverse needs and learning styles of [**individ
ual**](https://fxdatalabs.com/) learners.

AI-powered language learning platforms, such as [**LangChain**](https://fxdat
alabs.com/), address these challenges by [**leveraging**](https://fxdatalabs.com/) machine learning algorithms, natural 
language processing (NLP), and other AI techniques to deliver [**personalized**](https://fxdatalabs.com/) instruction, a
daptive feedback, and [**immersive**](https://fxdatalabs.com/) learning experiences tailored to each learner's proficien
cy level, preferences, and goals.

### Personalized Learning Paths:

One of the key [**features**](https://fxdatalabs.co
m/) enabled by AI in the LangChain platform is the creation of personalized learning paths for users. Through [**sophist
icated**](https://fxdatalabs.com/) algorithms that analyze user interactions, [**performance**](https://fxdatalabs.com/)
 data, and learning patterns, LangChain dynamically adjusts the curriculum, pacing, and content to suit each [**learner'
s**](https://fxdatalabs.com/) needs.

Whether a beginner [**starting**](https://fxdatalabs.com/) from scratch or an adva
nced learner seeking to refine specific language skills, AI ensures that the [**learning**](https://fxdatalabs.com/) jou
rney is tailored to the individual, maximizing [**engagement**](https://fxdatalabs.com/) and learning outcomes.

### Ada
ptive Learning Resources:

üì∑

AI algorithms in LangChain continuously [**analyze**](https://fxdatalabs.com/) user intera
ctions with learning materials, identifying areas of strengths and weaknesses to [**deliver**](https://fxdatalabs.com/) 
targeted learning resources and [**activities**](https://fxdatalabs.com/).

From interactive exercises and [**multimedia
**](https://fxdatalabs.com/) content to real-world simulations and cultural immersion experiences, LangChain's adaptive 
[**learning**](https://fxdatalabs.com/) resources adapt to the user's proficiency level, [**learning**](https://fxdatala
bs.com/) preferences, and interests, providing a personalized and engaging learning experience that fosters skill [**acq
uisition**](https://fxdatalabs.com/) and retention.

### Intelligent Feedback and Assessment:

AI-powered assessment [**
mechanisms**](https://fxdatalabs.com/) in LangChain provide users with real-time feedback on their language proficiency,
 [**pronunciation**](https://fxdatalabs.com/), grammar, and vocabulary usage.

Through speech [**recognition**](https://
fxdatalabs.com/) technology, NLP algorithms, and machine learning models, LangChain can accurately evaluate user [**resp
onses**](https://fxdatalabs.com/), identify errors, and offer corrective feedback in a [**supportive**](https://fxdatala
bs.com/) and constructive manner.

This intelligent feedback loop enables users to track their [**progress**](https://fx
datalabs.com/), identify areas for improvement, and build [**confidenc**](https://fxdatalabs.com/)e in their language sk
ills.

### Natural Language Interaction:

Another innovative aspect of AI in [**LangChain**](https://fxdatalabs.com/) is
 its ability to facilitate natural language [**interaction**](https://fxdatalabs.com/) between users and the platform.


Through chatbots, virtual language tutors, and [**conversational**](https://fxdatalabs.com/) agents powered by AI, LangC
hain enables users to [**practice**](https://fxdatalabs.com/) speaking, listening, and conversing in the target language
 in a [**simulated**](https://fxdatalabs.com/) real-world environment.

These interactive experiences foster language fl
uency, [**communication**](https://fxdatalabs.com/) skills, and cultural understanding, bridging the gap [**between**](h
ttps://fxdatalabs.com/) theoretical language knowledge and [**practical**](https://fxdatalabs.com/) usage.

### Continuo
us Learning and Improvement:

üì∑

AI-driven analytics and insights in [**LangChain**](https://fxdatalabs.com/) enable edu
cators and developers to monitor user engagement, performance trends, and [**learning**](https://fxdatalabs.com/) outcom
es, allowing for data-driven decision-making and [**continuous**](https://fxdatalabs.com/) improvement of the platform.


By analyzing user behavior, content [**effectiveness**](https://fxdatalabs.com/), and learning efficacy, LangChain can 
refine its [**algorithms**](https://fxdatalabs.com/), update its curriculum, and introduce new features to enhance the o
verall learning [**experience**](https://fxdatalabs.com/) for users.

### Conclusion:

Artificial intelligence plays a p
ivotal role in the [**LangChain**](https://fxdatalabs.com/) language learning platform, transforming the way [**individu
als**](https://fxdatalabs.com/) acquire, practice, and master new languages.

By harnessing the power of AI to deliver [
**personalized**](https://fxdatalabs.com/) instruction, adaptive learning resources, intelligent feedback, and immersive
 experiences, LangChain empowers learners to achieve their language learning goals [**effectively**](https://fxdatalabs.
com/) and efficiently.

üì∑

As AI technology continues to evolve, the future of [**language**](https://fxdatalabs.com/) l
earning holds boundless possibilities, with [**LangChain**](https://fxdatalabs.com/) at the forefront of innovation, dri
ving the next [**generation**](https://fxdatalabs.com/) of language education.

For more insights into AI|ML and Data Sc
ience [**Development**](https://fxdatalabs.com/), [**please wri**](https://fxdatalabs.com/)te to us at: [**contact@htree
.plus**](mailto:contact@htree.plus)| [**F(x) Data Labs Pv**](mailto:contact@htree.plus)[**t**](https://fxdatalabs.com/)[
**. Ltd.**](mailto:contact@htree.plus)

[**#LangC**](https://fxdatalabs.com/)[**hai**](mailto:contact@htree.plus)n #AIin
LanguageLearning #FutureOfEducation #LanguageRevolution üöÄüìö
```
---

     
 
all -  [ Integrating Langchain with Open Interpreter ](https://www.reddit.com/r/LangChain/comments/1bcn71y/integrating_langchain_with_open_interpreter/) , 2024-03-13-0909
```
Hi everyone,

I am looking for a way to run generated JavaScript code and validate its output. Is there a tool like Pyth
onREPL but for executing Javascript code? I read that Open Interpreter   
 ([https://github.com/KillianLucas/open-interp
reter](https://github.com/KillianLucas/open-interpreter)) has the ability to run JavaScript code. Has anyone integrated 
Open Interpreter with Langchain?

Any help is appreciated.

Thanks

&#x200B;
```
---

     
 
all -  [ Idea questioner  ](https://www.reddit.com/r/LangChain/comments/1bcl6qp/idea_questioner/) , 2024-03-13-0909
```
Hey guys, I'm working on an idea at the moment and trying to gather feedback from different people and backgrounds in th
e AI field. The idea aims to help developers ship their AI apps very quickly and share them as well!

Relly appreciate y
our input üôå
https://cycls.typeform.com/to/blrTnsfC

If you're interested to get exclusive early access please share your
 email throught the link or feel free to DM me üëçüèº
```
---

     
 
all -  [ Azure Search provider ](https://www.reddit.com/r/LangChain/comments/1bcchol/azure_search_provider/) , 2024-03-13-0909
```
Why Lanchain provider wants me to create an index with some predefined metadata? (otherwise I have an error)
The underly
ing SDK doesn't require that at all...
```
---

     
 
all -  [ Code Embeddings? ](https://www.reddit.com/r/LangChain/comments/1bcbqqv/code_embeddings/) , 2024-03-13-0909
```
Are there examples anywhere on how to use an embedding scheme for code? I see that OpenAI and HuggingFace, at least, off
er such embeddings, but I'm having a hard time determining how to use them.  Probably I'm just not doing well enough at 
searching the web, so pointers would be very welcome.  For example, [this page](https://python.langchain.com/docs/use\_c
ases/code\_understanding) uses only vanilla OpenAI embeddings.
```
---

     
 
all -  [ Example of langchain that uses  ](https://www.reddit.com/r/LangChain/comments/1bc9t6e/example_of_langchain_that_uses/) , 2024-03-13-0909
```
Hi all I am trying to build a sales assistant bot in a startup where if I issue command say '/prospect acmecorp' the age
nt should  1/. Fetch Details from web search about a company 2/. Use a sales playbook knowledge (details of product and 
how to position the product) and generate response about the company and how to position the product. I have been trying
 to find examples which shows how we search and a knowledge can be combined in langchain. Pls if anyone has any insights
 pls help. 
```
---

     
 
all -  [ OpenAI Tools Agent for Open Records Q&A ](https://www.reddit.com/r/LangChain/comments/1bc951u/openai_tools_agent_for_open_records_qa/) , 2024-03-13-0909
```
Wanted to share an experiment I've been working on to test how helpful LLMs could be in answering user questions about O
pen Records (state-level FOIA laws). A basic [demo is available here](https://huggingface.co/spaces/jscotthorn/kora-assi
stant)¬†with cached example questions and responses.¬†An OpenAI account and key are required to perform new queries.¬†  



The AI Agent is given the user's question, some grounding context in our open records law, and a list of tools provided 
to the Agent if it wants to query for additional context.¬†Tools currently available:

* It can look up the full text of 
a statute from the Kentucky Open Records Act
* Look up the full text or summary of an exception from the Act or one inco
rporated from state or federal law (i.e. FERPA, HIPAA).
* Semantic search (chroma db) against case law annotations from 
the Open Records section of the Kentucky Revised Statutes.
* Semantic search against attorney general opinion summaries 
from the Open Records section of the KRS.

Overall the results have been very promising. Observed responses have been la
rgely accurate, and observed inaccuracies have been due to problematic summaries in annotations.
```
---

     
 
all -  [ Please roast my resume , ghosted from everywhere I apply ](https://i.redd.it/52qh99w3iqnc1.jpeg) , 2024-03-13-0909
```
Help me make it better or make me cry by roasting it

:)
```
---

     
 
all -  [ Loading all logs as a dataset to be processed by a LLM for log querying. Is langchain suitable?  ](https://www.reddit.com/r/LangChain/comments/1bc72wo/loading_all_logs_as_a_dataset_to_be_processed_by/) , 2024-03-13-0909
```
I want to load the load the logs as a dataset for the LLM to ask it which transactions take the longest time or have the
 highest latency having a chatbot answer all my log related questions. Would using langchain be my best option ? 
```
---

     
 
all -  [ Recommendations for easy to follow guides to set up with Code Llama ?  ](https://www.reddit.com/r/LangChain/comments/1bc6dhk/recommendations_for_easy_to_follow_guides_to_set/) , 2024-03-13-0909
```
Trying to build a solution that can query logs (like which transactions have the highest latency )so wanted to ask for r
ecommendations for the best LLM to use leaning towards code Llama and if something can suggest easy to follow guides to 
set everything up because the ones I found were incomplete. Thank you! 
```
---

     
 
all -  [ Build a SaaS Rag system ](https://www.reddit.com/r/Startup_Ideas/comments/1bc69sr/build_a_saas_rag_system/) , 2024-03-13-0909
```
AI is a hot topic right now; everyone is building some API integration with OpenAI, However, there is still plenty of ro
om for new players.

One product you can potentially build is a RAG-based chatbot or API. Take any industry where they h
ave to sift through and read hundreds of documents and build a quick lookup using RAG.

A RAG search would take in the u
ser's question and find similar matching documents. From this refined data, you post to an LLM like 'chatgpt-turbo' or '
Mixtral' and the LLM responds with relevant information based on the documents as context.

To build such a system, you 
going to need Langchain and probably Redis or Qdrant or some other vector DB.

Comment down below if you would like some
 example code. 
```
---

     
 
all -  [ How to build a multi AI agents chatbot ](https://www.reddit.com/r/LangChain/comments/1bc5h1b/how_to_build_a_multi_ai_agents_chatbot/) , 2024-03-13-0909
```
Hey guys, I have a question hoping someone can help me with.

I have been given a task to build an AI chatbot which woul
d consist of 3 AI agents. 

The 1st AI agent will be a general Q&A between the (human) user and this 1st LLM where the (
human) user can ask any general natural language questions to this 1st LLM and this 1st LLM will response back in natura
l language answers.

The 2nd AI agent will specialize in converting natural language questions by the (human) user into 
SQL code (when the (human) user include the word ‚Äútable‚Äù in his/her natural language question). This SQL code will then 
be send to a Postgres database to return a table and the AI chatbot will display this table.

Below this table, the 3rd 
AI agent will automatically produce a natural language summary of the information contained in the table.

I am also wan
ting to use the 1st LLM (I don‚Äôt think I need a 4th LLM here) to be able to allow the (human) user to ask natural langua
ge questions of the displayed tables on top and the 1st LLM will provide a natural language answer based on the table.


My question is will AI agent framework libraries like Autogen allow me to create the AI chatbot above, which is a conver
sation style chatbot? My AI chatbot also has a front end web app.

If Autogen isn‚Äôt able to do this, are there any other
 frameworks that can do the AI chatbot above? Or if there isn‚Äôt any framework libraries available, which mean I need to 
code this from scratch, are there any example codes I can refer to?

Would really appreciate if anyone can help. Many th
anks in advance!
```
---

     
 
all -  [ How do you deploy langchain for RAG on aws? ](https://www.reddit.com/r/LangChain/comments/1bc3s9w/how_do_you_deploy_langchain_for_rag_on_aws/) , 2024-03-13-0909
```
I‚Äôm setting up a rack system on my companies AWS cloud. So then I confused about is the Lang Chang and other libraries l
ike it are pretty big! The initial idea that I had was to make a small lambda that would ingest hundreds or thousands of
 documents from an S3 bucket, use another API, like open AI to get the embedding, and then upload that to our vector dat
abase.

You should running into is that Lang chain is about 50 MB and running in a lambda is inconvenient.  Trying to zi
p that is a pain, and then making a docker image even with the aws lambda python runtime bumps it to 8.5 GB image size. 


It seems like the only reasonable thing to do is to make a doctor image here and run it in a container. But that kind 
of defeats the purpose of an ingestion pipeline that is able to go dormant. 

I‚Äôd love your thoughts. My point is that o
nce you go to productionalize some kind of ingestion pipeline, Langchain just seems too big and tries to do too much.
```
---

     
 
all -  [ How you find langchain so far? ](https://www.reddit.com/r/LangChain/comments/1bc1hko/how_you_find_langchain_so_far/) , 2024-03-13-0909
```
Started experimenting with LLM apis and slowly figured that I need a proper framework to deal with it

E.g. 
managing my
 input prompts. 
managing actions when reason for completion is not EOS token etc.

Hence I'm here looking for suggestio
ns.

How's langchain as a framework? How's your experience with it?

Looking through the docs, it feels very complicated
 to do a simple task.

E.g. mapreduce and collapse map reduce, reading through the docs and I find it difficult to figur
e out what the backend is doing.

Maybe I'm wrong and have not dealt with LLM long enough to make a good assessment. Wha
t's your thoughts and how's your experience?
```
---

     
 
all -  [ Adding a JSONOutputParser to a RunnableBinding ](https://www.reddit.com/r/LangChain/comments/1bbzoj7/adding_a_jsonoutputparser_to_a_runnablebinding/) , 2024-03-13-0909
```
I have created a retrieval chain which is of the type RunnableBinding, it's the following example: [https://api.python.l
angchain.com/en/latest/chains/langchain.chains.retrieval.create\_retrieval\_chain.html#langchain.chains.retrieval.create
\_retrieval\_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.
html#langchain.chains.retrieval.create_retrieval_chain)

&#x200B;

My problem is that I want to add a JSONOutputParser, 
but I cannot seem to figure out how to do that. Does anyone have any ideas about that?
```
---

     
 
all -  [ Langchain updates is disappointing ](https://www.reddit.com/r/LangChain/comments/1bbzaag/langchain_updates_is_disappointing/) , 2024-03-13-0909
```
i just bought course from udemy [https://www.udemy.com/course/langchain-with-python-bootcamp](https://www.udemy.com/cour
se/langchain-with-python-bootcamp) , the course is very well structures all modules are on their place but the problem i
s langchain keeps depricating or updating now i am just on section 1 and already llm and chatmodel is being updated and 
you need to install specific llm like openai so i really need to take this course since its very well structured but i a
lso want to keep up with the updates how would you do that ?
```
---

     
 
all -  [ Combining queries ? ](https://www.reddit.com/r/LangChain/comments/1bbza6x/combining_queries/) , 2024-03-13-0909
```
Hi I'm new here 

I do have a question concerning semantic search 
Let's say I have 2 search queries or more ( User prom
pt + other additional context ) and I wanna search my vector database .

Is it better to combine the strings then embed 
them into one vector then do the search ?

Or embed each element of the query alone then combine all the embeddings into
 one vector then apply a search ? 
```
---

     
 
all -  [ I want to deploy a chatbot that uses rag with the llama index. ](https://www.reddit.com/r/LangChain/comments/1bbyvv8/i_want_to_deploy_a_chatbot_that_uses_rag_with_the/) , 2024-03-13-0909
```
Has anyone already implemented it?

I want to create and distribute a chatbot that uses rag with the llama index.

What 
frameworks should I use to implement a chatbot using rag while considering deployment?

If anyone has already implemente
d it, can you share the git code?
```
---

     
 
all -  [ stream llm model' huggingface' locally ](https://www.reddit.com/r/LangChain/comments/1bbxvvl/stream_llm_model_huggingface_locally/) , 2024-03-13-0909
```
is there any method to stream these models, and output the generated token while it generate to make response live to us
er
```
---

     
 
all -  [ AI & Elixir: How is the experience working with AI apps in elixir ? ](https://www.reddit.com/r/elixir/comments/1bbx48v/ai_elixir_how_is_the_experience_working_with_ai/) , 2024-03-13-0909
```
Hey there, Elixir enthusiasts!

How's everyone doing? I've been thinking a lot about the exciting blend of AI and Elixir
 lately and figured, who better to chat with than all of you? üòä Are any of you currently dabbling in AI within your Elix
ir projects? If so, I'd love to hear about your experiences! Whether it's overcoming challenges or discovering cool new 
tools, let's swap stories and ideas on how to make the most of AI in our Elixir adventures!

BTW, I want to share my rec
ent endeavor with LangChain by Mark Ericksen. I've been diving into LangChain recently and I have to say, Mark Ericksen'
s work in bringing it to Elixir is impressive! I've actually integrated the library into my personal trading app and it'
s been fantastic. I even whipped up a handy helper Agent that can give you a quick rundown of your portfolio information
.

code : [Agent code](https://github.com/pkrawat1/angel-trading/blob/master/lib/angel_trading/agent.ex)  
Check out the
 demo here!  
[LOOM DEMO](https://www.loom.com/share/c2e677e8f2bb460e9acf9701eecbaced)
```
---

     
 
all -  [ Using Multiple Tools ](https://www.reddit.com/r/LangChain/comments/1bbx1mj/using_multiple_tools/) , 2024-03-13-0909
```
Hi Everyone ,  I am in a fix and need your help. I am building a langchain agent to select between multiple tools depend
ing in the user query. Currently I have two tools - one which reads a SQL database and other which reads an excel. The p
roblem is none of them are working and giving any input as such. 

I am following this exactly--

https://python.langcha
in.com/docs/use_cases/tool_use/multiple_tools
```
---

     
 
all -  [ Improving RAG using LangGraph  ](https://www.reddit.com/r/LangChain/comments/1bbwehs/improving_rag_using_langgraph/) , 2024-03-13-0909
```
Hey everyone, checkout this tutorial on basics of LangGraph and how it can be used to improve RAG based on custom criter
ia

https://youtu.be/TlZ5BFx_m3M?si=8QCUxYpa8jxySkDJ

```
---

     
 
all -  [ Rag application for text and images ](https://www.reddit.com/r/LangChain/comments/1bbwb82/rag_application_for_text_and_images/) , 2024-03-13-0909
```
 I have a use case where i got 100's of documents. I have implemented a rag for answering question related to text but t
he problem is my requirement extends to images also. The documents contains steps for some process. These steps have som
e text and followed by some image. The application i am trying to implement should behave in a way that, if asked any qu
estion about the process it should not only give me the steps but also the images corresponding to it. (have to maintain
 the order of the images)

For ex:

Step 1: \_\_\_ some text \_\_\_  
respective image for step 1

Step 2: \_\_\_ some t
ext \_\_\_  
respective image for step 2

and so on.

How do you even do this, is it possible?
```
---

     
 
all -  [ What is LangChain and how does it aim to revolutionize language learning and communication? ](https://www.reddit.com/r/u_fxdatalabs_Yp/comments/1bbw70j/what_is_langchain_and_how_does_it_aim_to/) , 2024-03-13-0909
```
 

# What is LangChain and how does it aim to revolutionize language learning and communication?

 

## Revolutionizing 
Language Learning with LangChain! üåêüîó

 

## Introduction:

In today's [**interconnected**](https://fxdatalabs.com/) worl
d, the ability to communicate effectively across [**languages**](https://fxdatalabs.com/) is more important than ever.


However, traditional [**language**](https://fxdatalabs.com/) learning methods often fall short in providing learners wit
h the tools and resources needed to [**master**](https://fxdatalabs.com/) a new language efficiently.

Enter LangChain ‚Äì
 a revolutionary platform poised to [**transform**](https://fxdatalabs.com/) language learning and [**communication**](h
ttps://fxdatalabs.com/) as we know it.

In this detailed article, we will explore the [**concept**](https://fxdatalabs.c
om/) of LangChain, its innovative features, and how it aims to revolutionize language learning and [**communication**](h
ttps://fxdatalabs.com/) for [**learners**](https://fxdatalabs.com/) around the globe.

### Understanding the Need for La
nguage Learning Innovation:

In a globalized world where [**businesses**](https://fxdatalabs.com/) operate across border
s, travelers explore new cultures, and individuals seek to connect with people from diverse [**backgrounds**](https://fx
datalabs.com/), proficiency in multiple [**languages**](https://fxdatalabs.com/) has become a valuable skill.

However, 
[**traditional**](https://fxdatalabs.com/) language learning methods, such as textbooks and classroom instruction, often
 lack engagement, [**personalization**](https://fxdatalabs.com/), and real-world relevance, making it challenging for le
arners to achieve fluency and [**confidence**](https://fxdatalabs.com/) in their target [**language**](https://fxdatalab
s.com/).

### Introducing LangChain:

LangChain is a cutting-edge language learning [**platform**](https://fxdatalabs.co
m/) that leverages the power of technology, [**artificial intelligence**](https://fxdatalabs.com/), and community collab
oration to [**provide**](https://fxdatalabs.com/) learners with an immersive and personalized language [**learning**](ht
tps://fxdatalabs.com/) experience.

Unlike traditional methods, [**LangChain**](https://fxdatalabs.com/) adopts a holist
ic approach that integrates language learning with real-world communication [**scenarios**](https://fxdatalabs.com/), cu
ltural immersion, and peer-to-peer [**interaction**](https://fxdatalabs.com/), enabling learners to develop language ski
lls that are practical, relevant, and applicable in [**everyday life**](https://fxdatalabs.com/).

## Key Features of La
ngChain:

üì∑

### Personalized Learning Paths:

LangChain utilizes AI-driven [**algorithms**](https://fxdatalabs.com/) to
 assess each learner's proficiency level, learning preferences, and goals, allowing for the creation of [**personalized*
*](https://fxdatalabs.com/) learning paths tailored to [**individual**](https://fxdatalabs.com/) needs. Whether a beginn
er seeking to master basic vocabulary or an advanced learner aiming for [**fluency**](https://fxdatalabs.com/), LangChai
n adapts to each learner's unique [**requirements**](https://fxdatalabs.com/), pacing, and interests.

### Interactive L
anguage Exercises:

LangChain offers a diverse range of [**interactive**](https://fxdatalabs.com/) language exercises, i
ncluding listening comprehension, speaking practice, reading [**comprehension**](https://fxdatalabs.com/), and writing [
**exercises**](https://fxdatalabs.com/).

These exercises are [**designed**](https://fxdatalabs.com/) to simulate real-w
orld communication scenarios, such as ordering food in a restaurant, making travel [**arrangements**](https://fxdatalabs
.com/), or participating in business meetings, [**providing**](https://fxdatalabs.com/) learners with practical language
 skills that can be [**applied**](https://fxdatalabs.com/) in various contexts.

üì∑

### Cultural Immersion Experiences:


In addition to language instruction, LangChain [**provides**](https://fxdatalabs.com/) learners with opportunities for 
cultural immersion [**experiences**](https://fxdatalabs.com/), such as virtual tours of iconic landmarks, virtual langua
ge exchanges with native speakers, and [**multimedia**](https://fxdatalabs.com/) content showcasing the rich cultural he
ritage of the target [**language**](https://fxdatalabs.com/).

By [**immersing**](https://fxdatalabs.com/) learners in t
he cultural context of the language, LangChain enhances their understanding, [**appreciation**](https://fxdatalabs.com/)
, and fluency in the language.

### Community Collaboration and Peer Support:

LangChain fosters a vibrant [**community*
*](https://fxdatalabs.com/) of language learners, educators, and native speakers who collaborate, share resources, and [
**support each**](https://fxdatalabs.com/) other's language [**learning**](https://fxdatalabs.com/) journey.

Through fe
atures such as [**language**](https://fxdatalabs.com/) exchange forums, peer tutoring sessions, and collaborative projec
ts, learners can engage with like-minded [**individuals**](https://fxdatalabs.com/), practice their language skills, and
 receive [**feedback**](https://fxdatalabs.com/) and encouragement from peers and mentors.

## Advantages of LangChain:


üì∑

### Flexibility and Convenience:

With LangChain, learners have the [**flexibility**](https://fxdatalabs.com/) to st
udy anytime, anywhere, using their [**preferred**](https://fxdatalabs.com/) device ‚Äì whether it's a smartphone, tablet, 
or computer. This flexibility allows learners to integrate language [**learning**](https://fxdatalabs.com/) into their b
usy schedules and progress at their own pace.

### Engagement and Motivation:

LangChain's interactive [**exercises**](h
ttps://fxdatalabs.com/), cultural immersion experiences, and community collaboration features enhance learner [**engagem
ent**](https://fxdatalabs.com/) and motivation, keeping learners inspired and motivated to continue their language learn
ing [**journey**](https://fxdatalabs.com/).

### Real-World Relevance:

By focusing on practical [**communication**](htt
ps://fxdatalabs.com/) skills and real-world scenarios, LangChain equips learners with language skills that are [**immedi
ately**](https://fxdatalabs.com/) applicable in everyday life, ensuring that learners feel confident and competent in us
ing the [**language**](https://fxdatalabs.com/) in real-[**world situations**](https://fxdatalabs.com/).

### Personaliz
ation and Adaptability:

[**LangChain's**](https://fxdatalabs.com/) AI-driven algorithms ensure that each learner receiv
es personalized instruction and feedback based on their [**individual**](https://fxdatalabs.com/) needs, preferences, an
d progress, maximizing [**learning**](https://fxdatalabs.com/) outcomes and effectiveness.

### Case Studies and Testimo
nials:

Highlighting success stories and [**testimonials**](https://fxdatalabs.com/) from LangChain users can provide re
al-world examples of how the platform has transformed their [**language**](https://fxdatalabs.com/) learning [**experien
ce**](https://fxdatalabs.com/) and helped them achieve their language proficiency goals.

Whether it's landing a job in 
a foreign country, making [**friends**](https://fxdatalabs.com/) from diverse cultural backgrounds, or traveling with [*
*confidence**](https://fxdatalabs.com/), these testimonials serve as compelling evidence of [**LangChain's**](https://fx
datalabs.com/) effectiveness and impact.

üì∑

## Conclusion:

LangChain represents a [**paradigm**](https://fxdatalabs.co
m/) shift in the field of language learning, offering a comprehensive, personalized, and engaging [**approach**](https:/
/fxdatalabs.com/) that empowers learners to master new [**languages**](https://fxdatalabs.com/) with confidence and flue
ncy.

By leveraging technology, artificial intelligence, and [**community**](https://fxdatalabs.com/) collaboration, Lan
gChain is [**revolutionizing**](https://fxdatalabs.com/) language learning and communication, making language acquisitio
n more accessible, effective, and [**enjoyable**](https://fxdatalabs.com/) for learners around the world.

Whether you'r
e a beginner embarking on your [**language**](https://fxdatalabs.com/) learning journey or an [**advanced**](https://fxd
atalabs.com/) learner seeking to refine your skills, LangChain provides the tools, resources, and support needed to [**a
chieve**](https://fxdatalabs.com/) your language learning goals and unlock new opportunities for personal and profession
al [**growth**](https://fxdatalabs.com/).

With [**LangChain**](https://fxdatalabs.com/), the world is yours to explore 
‚Äì one [**language**](https://fxdatalabs.com/) at a time.

For more insights into AI|ML and Data Science [**Development**
](https://fxdatalabs.com/), please write to us at: [**contact@htree.plus**](mailto:contact@htree.plus)| [**F(x) Data Lab
s Pv**](mailto:contact@htree.plus)[**t. Ltd.**](https://fxdatalabs.com/)

[**#LangChain #LanguageLea**](https://fxdatala
bs.com/)rning #CommunicationRevolution #GlobalConnectivity üöÄüåç
```
---

     
 
all -  [ LangChain vs LlamaIndex ](https://www.reddit.com/r/LangChain/comments/1bbog83/langchain_vs_llamaindex/) , 2024-03-13-0909
```
Sorry for the oversimplified question but can someone explain the differences between the two?

Do they offer the same s
ort of capabilities but in a different way? It seems that LangChain is preferred when designing RAG applications, is tha
t true and why? What about ReAct?

Which one is more applicable for special purpose business use cases?

Also as an expe
rienced engineer but new to LLMs where should I start learning? Huggingface seems to have a lot of material, is that any
 good

Thanks

```
---

     
 
all -  [ use existing faiss index in LangChain ](https://www.reddit.com/r/LangChain/comments/1bbk7iu/use_existing_faiss_index_in_langchain/) , 2024-03-13-0909
```
Hi All, I wonder if it is possible to load existing indexes built by the faiss library into LangChain?  It seems that th
e format is different and I couldn't just load it like in the example shown in the LangChain documentation, e.g., FAISS.
load\_local('large.index', embeddings)

Thanks!
```
---

     
 
all -  [ Are all embeddings just bad for retrieval? ](https://www.reddit.com/r/LangChain/comments/1bbj5hu/are_all_embeddings_just_bad_for_retrieval/) , 2024-03-13-0909
```
[https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)

I'm an experienced sof
tware engineer building a practice RAG stack application to learn more about integrating with LLMs. As is standard for t
his, I was going to take my data, convert it into embeddings, store it in a vector DB (Milvus), and then leverage it for
 the ultimate tasks I will be performing.

Looking at the above benchmarks, however, gives me pause. I've been trying to
 understand the scores, I THINK they are percentages. Classification accuracy seems quite high, which is good given that
's the primary task I ultimately want to perform. However, Retrieval seems much lower.

Basically, the highest Classific
ation score in those benchmarks is 79.46, whereas the highest Retrieval score is 59. Those are not in the same model, bt
w. I'm ignoring price, performance, and other factors right now to focus on this single issue.

My core point is that a 
\~60% accuracy at Retrieval seems like it's very bad for Classification, or literally any other task. In RAG, the goal i
s to pull out relevant pieces of data and use it as part of the query to the LLM. If the records can't be found accurate
ly to begin with, this whole approach would seem to be quite weak.

Am i just misunderstanding the benchmarks? Or am I m
isunderstanding how to utilize these models in RAG? Or is this a genuine problem?

Thanks in advance.
```
---

     
 
all -  [ Multimodal ](https://www.reddit.com/r/LangChain/comments/1bbgdhd/multimodal/) , 2024-03-13-0909
```
 Hello guys,

As we venture closer to the zenith of General Artificial Intelligence (GAI), a noteworthy trend has emerge
d within the AI research community, spearheaded by leading institutions such as OpenAI and Google. These organizations h
ave been pivotal in integrating multimodal capabilities into their Large Language Models (LLMs), marking a significant l
eap towards achieving AI systems with human-like cognitive abilities. This integration of multimodalism signifies an evo
lutionary step in artificial intelligence, enabling these models to not only excel in Natural Language Processing (NLP) 
but also to comprehend and generate auditory information via sophisticated Text-to-Speech (TTS) and Speech-to-Text (STT)
 technologies. Furthermore, the incorporation of computer vision allows these systems to analyze and interpret the natur
al world with remarkable precision, merely through the lens of a camera.

This fusion of modalities‚Äîlinguistic, auditory
, and visual‚Äîequips LLMs with a more comprehensive understanding of the world, mirroring the multifaceted way humans per
ceive and interact with their environment. The ability to process and synthesize information across these dimensions ope
ns up unprecedented possibilities for AI applications, ranging from enhanced conversational interfaces to sophisticated 
autonomous systems capable of navigating complex real-world scenarios.

Amidst this technological renaissance, an intrig
uing question arises concerning Langchain's strategy in adopting multimodal frameworks. As developers and innovators eag
erly seek to harness the power of multimodal AI, the anticipation around Langchain's plans to facilitate the integration
 of multimodal capabilities into their framework is palpable. Such advancements would not only expand the toolkit availa
ble to developers but also pave the way for creating more intuitive and versatile AI systems, capable of operating acros
s a spectrum of human-like modalities.

As we stand on the brink of this transformative era in AI development, the integ
ration of multimodal functionalities within Langchain's offerings could significantly accelerate the adoption of sophist
icated AI solutions, fostering a new wave of innovation in the realm of artificial intelligence. The question remains: w
hen will Langchain unveil its approach to multimodal AI, and how will it empower developers to usher in the next generat
ion of AI applications?
```
---

     
 
all -  [ Seeking help on a LLM project  ](https://www.reddit.com/r/LangChain/comments/1bbf28l/seeking_help_on_a_llm_project/) , 2024-03-13-0909
```

Hello guys. 

I‚Äôm new to building llm apps.

I‚Äôm currently working on an independent project idea in the Educational se
ctor. I‚Äôm thinking of leveraging LLMs for automatic grading of some Python assignments. I‚Äôve tried using gpt-4 for all t
he submissions to generate grade and feedback for each submission. For this approach, I passed the Python code, a rubric
 on how to deduct marks, total possible marks and assignment description. The results were good but I need to evaluate t
hem. Could you help me with suggestions on any techniques that I could use to improve upon this or maybe do some other a
pproaches with Rag or prompting techniques like COT? What should I use as my knowledge base? 

And how would I evaluate 
the responses?

Any suggestions would be absolutely invaluable.

Thanks for reading this!
```
---

     
 
all -  [ Hitting local huggingface inference endpoint or a better way to run models locally in docker? ](https://www.reddit.com/r/LangChain/comments/1bbe8jz/hitting_local_huggingface_inference_endpoint_or_a/) , 2024-03-13-0909
```
I have a model running in a docker container with huggingface's text-generation-inference and am trying to get langchain
 to talk to it.

I figured out how to use the deprecated HuggingFaceTextGenInference class, but it's deprecated. I tried
 using the HuggingFaceEndpoint class (which is suggested) but it wants to try and login to huggingface which doesn't mak
e any sense since the model is running locally.

Have you had any luck with this, or did I miss a setting somewhere in t
he HuggingFaceEndpoint class?

Is there a better way to run models locally in docker? 

:)
```
---

     
 
all -  [ Chunking Idea: Summarize Chunks for better retrieval ](https://www.reddit.com/r/LangChain/comments/1bbdgpj/chunking_idea_summarize_chunks_for_better/) , 2024-03-13-0909
```
Hi,

I want to discuss if this idea already exists or what you guys think of it. 

Does it make sense if you chunk your 
documents, summarize those chunks and use these summaries for retrieval? This is similar to ParentDocumentRetriever, wit
h the difference that the child chunk is the summary and the parent chunk the text itself. 

I think this could improve 
the accuracy as the summary of the chunk could be more related (higher cosine similarity) to the user query/question whi
ch is most of the time much shorter than the chunk. 

&#x200B;

What do you think about this?
```
---

     
 
all -  [ How to create a chatbot using RAG using llama index? ](https://www.reddit.com/r/LangChain/comments/1bb9f03/how_to_create_a_chatbot_using_rag_using_llama/) , 2024-03-13-0909
```
The problem I am currently experiencing is as follows.  I implemented an ensemble retriever by looking at the ensemble r
etriever document. This is a method of entering a query based on a document and then reranking the results to receive a 
final answer.  That's why 'Hello?' has nothing to do with the document. If you enter llm, ‚ÄúHello?‚Äù is displayed in the d
ocument. They won't reply to me because they can't find it.  How to implement rag and chatbot This is the Ensemble Retri
ever document I referenced. [https://docs.llamaindex.ai/en/stable/examples/retrievers/ensemble\_retrieval.html](https://
docs.llamaindex.ai/en/stable/examples/retrievers/ensemble_retrieval.html)

And below is my code.   


    loader = PyMuP
DFReader()
    docs0 = loader.load(file_path=Path('./data/company_rule.pdf'))
    doc_text = '\n\n'.join([d.get_content(
) for d in docs0])
    docs = [Document(text=doc_text)]
    
    llm = OpenAI(model='gpt-4-0125-preview')
    chunk_size
s = [128, 256, 512, 1024]
    nodes_list = []
    vector_indices = []
    for chunk_size in chunk_sizes:
    print(f'Chu
nk Size: {chunk_size}')
    splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size // 2)
    nodes 
= splitter.get_nodes_from_documents(docs)
    for node in nodes:
    node.metadata['chunk_size'] = chunk_size
    node.e
xcluded_embed_metadata_keys = ['chunk_size']
    node.excluded_llm_metadata_keys = ['chunk_size']
    nodes_list.append(
nodes)
    vector_index = VectorStoreIndex(nodes)
    vector_indices.append(vector_index)
    
    retriever_dict = {}
 
   retriever_nodes = []
    for chunk_size, vector_index in zip(chunk_sizes, vector_indices):
    node_id = f'chunk_{chu
nk_size}'
    node = IndexNode(
    text=(
    'rule context retrieves (chunk size')
    f'{chunk_size})'
    ),
    ind
ex_id=node_id,
    )
    retriever_nodes.append(node)
    retriever_dict[node_id] = vector_index.as_retriever()
    
   
 summary_index = SummaryIndex(retriever_nodes)
    
    retriever = RecursiveRetriever(
    root_id='root',
    retrieve
r_dict={'root': summary_index.as_retriever(), **retriever_dict},
    )
    
    nodes = await retriever.aretrieve(
    '
About working hours'
    )
    
    print(f'Number of nodes: {len(nodes)}')
    for node in nodes:
    print(node.node.m
etadata['chunk_size'])
    print(node.node.get_text())
    
    reranker = LLMRerank()
    print(reranker)
    
    quer
y_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])
    
    response = query_engine.query(
    '
About working hours'
    )
    
    display_response(
    response, show_source=True, source_length=500, show_source_met
adata=True
    )
    
    #finalanswer

&#x200B;
```
---

     
 
MachineLearning -  [ [D] : Scale PDF Q&A App to 10K Users with GPUs ‚Äì <$250/Mo ](https://www.reddit.com/r/MachineLearning/comments/1b6jv56/d_scale_pdf_qa_app_to_10k_users_with_gpus_250mo/) , 2024-03-13-0909
```
Hello everyone,

Check out this step-by-step detailed tutorial on building and scaling a PDF Q&A Application using Pinec
one, Langchain and Inferless

&#x200B;

[Architecture](https://preview.redd.it/zfta52cbddmc1.png?width=1301&format=png&a
uto=webp&s=440399212d3feb03e861759a31602e2cde0dc7fb)

Alongside, the detailed quick deploy guide, it also includes cost 
analysis on how you can save upto 84% cost with an example of processing 3000 documents and nearly 10,000 queries every 
month, all while dramatically cutting your costs from $1800 ( AWS) to just $250 a month on Inferless.

Here is the tutor
ial - [https://cookbook.inferless.com/](https://cookbook.inferless.com/)

If you resonate, join the discussion on Hacker
news here - [https://news.ycombinator.com/item?id=39594588](https://news.ycombinator.com/item?id=39594588)
```
---

     
 
MachineLearning -  [ [D] What Is Your LLM Tech Stack in Production? ](https://www.reddit.com/r/MachineLearning/comments/1b4sdru/d_what_is_your_llm_tech_stack_in_production/) , 2024-03-13-0909
```
Curious what everybody is using to implement LLM powered apps for production usage and your experience with these toolin
gs and advice. 

This is what I am using for some RAG prototypes I have been building for users in finance and capital m
arkets.

**Pre-processing\ETL:**
Unstructured.io + Spark, Airflow

**Embedding model:**
Cohere Embed v3
Previously using
 OpenAI Ada but Cohere has significantly better retrieval recall and precision for my use case. Also exploring other ope
n weights embedding models

**Vector Database:**
Elasticsearch previously but now using Pinecone

**LLM:**
Gone through 
quite a few including hosted and self-hosted options. Went with gpt4 early during prototyping then switched to gpt3.5-tu
rbo for more manageable costs and eventually open weights models. 

Now using a fine-tuned Llama2 70B model self hosted 
with vLLM 

**LLM Framework:**
Started with Langchain initially but found it cumbersome to extend as the app became more
 complex. Tried implementing it in LlamaIndex at some point just to learn and found it just as bad. Went back to Langcha
in and now I am in the midst of replacing it with my own logic

What is everyone else using?

Edit: correct model Llama2
 70B
```
---

     
 
MachineLearning -  [ [D] Graphs + vectordbs? Need your input: Cognee.ai . AI Data Pipelines for Real-World Production (Pa ](https://www.reddit.com/r/MachineLearning/comments/1aweo71/d_graphs_vectordbs_need_your_input_cogneeai_ai/) , 2024-03-13-0909
```
Hey there, Redditors!

I'm back with the latest installment on creating dependable AI data pipelines for real-world prod
uction.

If you've been following along, you know I'm on a mission to move beyond the '[thin OpenAI wrapper](https://top
oteretes.notion.site/Going-beyond-Langchain-Weaviate-and-towards-a-production-ready-modern-data-platform-7351d77a1eba40a
ab4394c24bef3a278?pvs=4)' trend and tackle the challenges of building robust data pipelines.

After a few months of work
, we integrated cognitive architecture with [keepi.ai](https://www.keepi.ai) 

We aim to explore with our demo:

**1. Co
ntext sanitization**  
The world of AI is fast-moving, and we've realized that the context is becoming a building block 
we refer to as a crucial part of future cognitive architecture.  
**2. Best Practices for AI Memory**  
In this rapidly 
evolving landscape, there are no established best practices. You'll need to make educated bets on tools and processes, k
nowing that things will change. We assume that having traditional data engineering practices + frameworks + classifiers 
and other AI solutions can solve a lot of standard hurdles  
**3. AI Frameworks**  
They are trying to do too much, too 
fast, too broad. We want to find a pattern and a correct layer of abstraction for the AI memory to fit new industry.  



&#x200B;

How does it work? 

The Github repo is l:

  


[How cognee works](https://preview.redd.it/yuiabmyihyjc1.png?
width=1633&format=png&auto=webp&s=4384c4441b615f72caf1e0591c5ab23aee735fab)

Github repo is [here](https://github.com/to
poteretes/cognee)

Next steps:  
I have questions for you:

1. Is context sanitization relevant for you?
2. How do you m
anage metadata? 
3. How do you prepare data for LLMs?
4. Are there any data enrichment steps you perform?

Check out the
 blog post:

[Link to part 4](https://topoteretes.notion.site/Going-beyond-Langchain-Weaviate-Level-4-towards-production
-fe90ff40e56e44c4a49f1492d360173c?pvs=4)

*Remember to give this post an upvote if you found it insightful!*  
*And also
 star our* [Github repo](https://github.com/topoteretes/cognee)
```
---

     
 
MachineLearning -  [ [D] AI projects Suggestions ](https://www.reddit.com/r/MachineLearning/comments/1aunkmw/d_ai_projects_suggestions/) , 2024-03-13-0909
```
Hi Everyone, I need a suggestion to create AI courses for students ( Hands-on AI projects). I am thinking about the late
st AI trends such as Langchain, RAG, and vector databases. In each project, there can be multiple tasks, and the main th
ing is each task should have an automated system in which we can verify whether students have done it correctly or not.


For example: Project with visualization cannot be automatically tested. 

For example: A project with visualization can
not be automatically tested. . em can verify if the length of the text is smaller we can verify that it is correct.
```
---

     
 
MachineLearning -  [ Whats in your RAG setup? [D] ](https://www.reddit.com/r/MachineLearning/comments/1apcp2w/whats_in_your_rag_setup_d/) , 2024-03-13-0909
```
What frameworks and libraries are you using in your RAG? 

I'm most curious if  LangChain is as popular as it was?

Here
's mine at a high-level: 

*  langchain to use OpenAI for creating embeddings
* Pinecone for storing embedding
* langcha
in to load document splitters and characters splitters for chunking
* Mongo for conversations memory

&#x200B;
```
---

     
