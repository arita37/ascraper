 
all -  [ Vision Analysis  ](https://www.reddit.com/r/LangChain/comments/1ec8c4e/vision_analysis/) , 2024-07-26-0911
```
I'm labeling and taking screenshot of webpages that I then send to 4V to analyze. Basically, the labeling creates border
s around html elements then I ask GPT to determine if there is a popup or if there are elements at certain places on the
 page. (I'm being a little vague due to the specific use case.) 

What would a good approach be for prompting? I am prov
iding reference images with explanations for each reference. Even though things are being labeled ok, I don't seem to be
 able to prompt it well. So I'm wondering if one prompting strategy over another might be good. 

Note that this flow is
 partially based on the WebVoyager paper that uses LangGraph, though it's not web browsing. Just a single labeled page. 

```
---

     
 
all -  [ How are you creating agentic tasks/workflows? ](https://www.reddit.com/r/ChatGPT/comments/1ec7oel/how_are_you_creating_agentic_tasksworkflows/) , 2024-07-26-0911
```
For all of you that are actively building things with llm capabilities: What tools are you using? What is the hardest pa
rt of building useful and effective agentic solutions for you? 

Autogen, Langchain and related, gpts, custom tech, priv
ate paid options, etc. what are you using and how do you feel about it?
```
---

     
 
all -  [ How do you build agentic workflows? ](https://www.reddit.com/r/LocalLLaMA/comments/1ec7kzy/how_do_you_build_agentic_workflows/) , 2024-07-26-0911
```
For those of you building, interested in building, or even experts in building them: what are you using? Have you found 
something that solves the boring part and lets you build? 

Autogen, Langchain, other private options: what do you use a
nd what is your opinion on the available tools? 
```
---

     
 
all -  [ Using Milvus/RAG as metadata store ](https://www.reddit.com/r/LangChain/comments/1ec02w8/using_milvusrag_as_metadata_store/) , 2024-07-26-0911
```
I've metadata( like table structure, column details, data types) of RDBMS and other sources currently stored in MYSQL da
tabase. I want to build  a simple bot that answers queries from data engineers and analytics like '

1.get me ddl of .. 
this table

2. what is the meaning of this column

3. show me complete column list with description of this table in pos
tgres environment: etc.

How can I use Vector db along with LLM to achieve this goal.

I'm not sure how to design a sche
me, whether to vectorize the name of the table alone etc.

N.B : Some of the tables can have 500 columns also.
```
---

     
 
all -  [ How to build agent with local llm ](https://www.reddit.com/r/LangChain/comments/1ebundi/how_to_build_agent_with_local_llm/) , 2024-07-26-0911
```
I'm new to langchain and currently learning the official \[tutorial\](https://python.langchain.com/v0.2/docs/tutorials/a
gents/). I have tried Ollama and llama.cpp, but none of them can finish the tutorial.

As known, Ollama doesn't support 
bind_tools originally. With the help of OllamaFunctions in langchain_experiment package, it worked and outputed similar 
intermediate information but failed when generating text according to response from tools.

When it comes to llama.cpp, 
it does have bind_tools function. The problem is that it didn't generate text according to response from tools.


So, is
 there a way to go through the tutorials with local llms or an example about finishing those tutorials with Ollama and l
lama.cpp? 
```
---

     
 
all -  [ Improving output of Azure Gpt 4 vision model , ignoring part of text present in image ](https://www.reddit.com/r/LangChain/comments/1ebt2gl/improving_output_of_azure_gpt_4_vision_model/) , 2024-07-26-0911
```
Hi I am trying to extract information from  purchase orders PDFs with different formats , when conventional py libraries
 didn't extract the data the way I wanted I resorted to Azure Gpt 4 vision model and converted the pages of my pdf as im
ages and used the api to get back the response. The problem is in some documents it is deliberately missing clearly writ
ten information in the images , I tried tweaking the prompt as well. But not helping much. I am using pdf2image to conve
rt to JPEGs and using 500 dpi as parameter in the convert_from_path function imported from library. Any recommendations 
or help would be much appreciated.
```
---

     
 
all -  [ Udemy Free Courses for 25 July 2024 ](https://www.reddit.com/r/udemyfreeebies/comments/1ebsti2/udemy_free_courses_for_25_july_2024/) , 2024-07-26-0911
```
# Udemy Free Courses for 25 July 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the cou
rses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11850/)Social Media Graphics Design and Video Editin
g with Canva
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11849/)Personal Finance #2–Financial Statements
* [REDE
EM OFFER ](https://idownloadcoupon.com/udemy/11848/)350 DevOps Interview Questions Practice Test
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/11847/)Excel Formulas
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11846/)MSBI and S
SIS: Fundamentals to Advanced Data Integration
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11845/)Executive Dipl
oma in Business Management and Administration
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11844/)Uncovering Unco
nscious Bias in Recruiting
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11843/)Master Course in Digital Innovatio
n
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11842/)Executive Diploma in Leadership and Management
* [REDEEM OF
FER ](https://idownloadcoupon.com/udemy/11830/)Master Course in Service Marketing 2.0
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/11841/)Industrial Cloud
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11840/)Blender Essential: 
From Beginner to 3D Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11839/)Mastering Cybersecurity Ranso
mware Incident Response (101)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11838/)Master Course in Bio-Inspired I
nnovation
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11837/)Master Course in Healthcare Leadership
* [REDEEM OF
FER ](https://idownloadcoupon.com/udemy/11836/)CDMP Course : Certified Data Management Professional (101)
* Master Cours
e in Smart Cities, Urban Planning
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/11835/)
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/11834/)Burp Suite Mastery: From Beginner to Advanced
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/11833/)Mastering Cybersecurity Vulnerability Management (101 Level)
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/11832/)Master Course : Data Lakehouse Fundamentals in Data Science
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/11831/)Retail
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10768/)High-Tech Entrepreneurship & Strategic
 Entrepreneurship 2.0
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10852/)Microsoft Excel : Mastering Data Analys
is with Pivot Table
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10620/)Letter Writing Fundamentals
* [REDEEM OFF
ER ](https://idownloadcoupon.com/udemy/10771/)Master Course in World Peace, Human Rights and Diplomacy 2.0
* [REDEEM OFF
ER ](https://idownloadcoupon.com/udemy/9679/)Professional Diploma in Life Coaching & Business Mentorship
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/10770/)Health Research, Public Health & Behavior Change 3.0
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/8319/)Learn ETABS & SAFE in the Structural Design of 15 Stories RC
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/10094/)Crafting Invitations with Elegance and Precision
* [REDEEM OFFER ](https://idownloadc
oupon.com/udemy/7512/)Oracle Java Certification Exam OCA 1Z0-808 Preparation Part2
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/5950/)Airport Lounge Management & Cabin Crew Management 2.0
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/10622/)Writing with Impact: Compelling Articles and Letters
* Tenses Demystified: A Fundamental Introduction
* [R
EDEEM OFFER](https://idownloadcoupon.com/udemy/10652/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10621/)Demyst
ifying Computer Viruses: Types, Spread, and Protection
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/4861/)Choosin
g Your Career Path: Finding Your True Calling
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11418/)Master Course :
 Edge AI and Edge Computer vision (101 level)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10639/)Master Course i
n Blockchain Adoption 2.0 (101 level)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10636/)Presentation Skills -De
liver an Excellent Ceremonial Speech
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/2973/)Traffic Security, Road Sa
fety, Public Security & Safety 2.0
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10619/)Cybersecurity Unveiled: Re
cognizing Its Vital Importance
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10560/)PHP Laravel: Build Hotel Booki
ng Management System
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8546/)Cybersecurity Digital Immune Systems (101
 level)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10773/)Master Course : UNO, WHO, UNICEF, UNESCO & SDGs (101 
level)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11746/)The Modern JavaScript for Beginners
* [REDEEM OFFER ](
https://idownloadcoupon.com/udemy/11285/)Corporate Finance: Financial Analysis and Decision-Making
* [REDEEM OFFER ](htt
ps://idownloadcoupon.com/udemy/10769/)Master Course : E-Sports, Sports Business Management 2.0
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/10072/)Research and Evidence Gathering for Debates
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/11829/)Best Online Video Editor InVideo : 5 Real World Projects
* Master Web & Mobile Design: Figma, UI/UX Ess
entials, +More
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/11828/)
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/11827/)Boris FX: BCC Transitions | VFX | Titling | Keying | Color
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/11826/)Autodesk Combustion: Beginner to Advanced VFX Techniques
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
11825/)Pro Lead Vocal Mixing Clinic
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11824/)Credit Evaluation and Len
ding Practices Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11823/)Securities Lending Market Mastery 
– A Comprehensive Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11822/)Maya Practical – 3D Animal and Charac
ter Modeling Mastery
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11821/)Adobe Flash Mastery – From Basics to Adv
anced
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11819/)Hack-Proof Banking: Defend Against Credit Card Threats!

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11818/)Content Creator’s Roadmap: Ideation, Visibility, Repurposing

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11761/)Master The Art of Learning: Science-Based Study Techniques
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11394/)Терминал Linux. Основы работы в командной строке Линукс
* [RED
EEM OFFER ](https://idownloadcoupon.com/udemy/7515/)Learn Blockchain and Cryptocurrency from Beginning
* [REDEEM OFFER ]
(https://idownloadcoupon.com/udemy/1995/)LPI Linux Essentials 010-160 Certification Exam Practice
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/2882/)UI/UX Design With Figma : 5+ Real World Projects
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/8276/)Advertising Strategy Fundamentals: Upskill to Drive Growth
* Indian Financial System: Banking| Tr
easury| Risk Management
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/11820/)
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/7004/)Python And Django Framework And HTML 5 Stack Complete Course
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/7450/)ChatGPT Masterclass: The Ultimate Beginner’s Guide!
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/9647/)Professional Diploma in WEB3 NFT Business
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5937/)ChatGPT Ma
sterclass: Navigating AI and Prompt Engineering
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/3454/)Build AI Chatb
ots, SAAS Apps \[AI Automation Agency + NoCode\]
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5884/)Professional 
Diploma in Advertising and Public Relations
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11731/)Master CapCut Mob
ile Video Editing: Complete CapCut Tutorial
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11368/)ChatGPT Prompt En
gineering Mastery
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9357/)SQL практикум для начинающих и продолжающих

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11817/)The Basics of Linux Command Line
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/11803/)Learn Basics of Obsidian: Mastering Study Notes
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11804/)Learn Basics of Obsidian: Mastering Study Notes in Arabic
* [REDEEM OFFER ](https://idownloadcoupon.co
m/udemy/11805/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://idownloadcoupon.co
m/udemy/11806/)Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM OFFER ](https://idownloadcoupon.com/u
demy/11807/)AWS Business Essentials – The Business Value of AWS \[2024\]

GET MORE FREE ONLINE COURSES WITH CERTIFICATE 
– [CLICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ Video RAM Problems on a server with a Rtx 4000 20gb ](https://www.reddit.com/r/LangChain/comments/1ebsdbv/video_ram_problems_on_a_server_with_a_rtx_4000/) , 2024-07-26-0911
```
Hey I don't know if this is the right sub. I rented a server that uses a Rtx 4000 with 20gb. I tried to get models like 
mistral or llamma to run on it but it fails to generate answers because it runs out of memory. Are there anyways to redu
ce the amount of memory needed? Or other ways to solve this problem? 
```
---

     
 
all -  [ SemanticChunker for very large text ](https://www.reddit.com/r/LangChain/comments/1ebs25f/semanticchunker_for_very_large_text/) , 2024-07-26-0911
```
I use Semantic Chunker from this tutorial: [https://python.langchain.com/v0.2/docs/how\_to/semantic-chunker/](https://py
thon.langchain.com/v0.2/docs/how_to/semantic-chunker/)

  
However, I met the error below. I think because my pdf has 64
 pages. Too long for OpenAI to handle. What should I do? If I split page by page, I am afraid that I will lost the conte
nt between pages. Recursive Chunker seems better in this case. 

>openai.InternalServerError: Error code: 503 - {'error'
: {'code': 'InternalServerError', 'message': 'The service is temporarily unable to process your request. Please try agai
n later.'}}

>python-BaseException
```
---

     
 
all -  [ Complete Generative AI Course With Langchain and Huggingface ](https://idownloadcoupon.com/udemy/11805/complete-generative-ai-course-with-langchain-and-huggingface/) , 2024-07-26-0911
```

```
---

     
 
all -  [ Why does EmbeddingStoreContentRetriever Not output directly Score in Java Langchain ?  ](https://www.reddit.com/r/LangChain/comments/1ebo69l/why_does_embeddingstorecontentretriever_not/) , 2024-07-26-0911
```
Why does EmbeddingStoreContentRetriever Not output directly Score in Java Langchain ?   
  
It tells us to output, based
 on minScore, but no possibility to get score directly? Why is it ?

  
how would I go about implementing it in java or 
am I missing something

How can I get this score ?

  
this is how it looks like

  
`public class EmbeddingStoreContent
Retriever implements ContentRetriever` 

`{`

 `private final EmbeddingStore<TextSegment> embeddingStore;` 

`private fi
nal EmbeddingModel embeddingModel;` 

`private final Function<Query, Integer> maxResultsProvider;` 

`private final Func
tion<Query, Double> minScoreProvider;` 

`private final Function<Query, Filter> filterProvider;` 

`}`
```
---

     
 
all -  [ Ai interviewer technique ](https://www.reddit.com/r/LangChain/comments/1ebnkqo/ai_interviewer_technique/) , 2024-07-26-0911
```
I want to explore how these website with ai interviewer works like do they only works on the audio or they process the v
ideo also realtime. It is very fascinating to me. 
If anyone have any idea in this field, would happy to know your thoug
hts. 
```
---

     
 
all -  [  A Comprehensive Guide: Boosting EHR Efficiency with LangChain.js ](https://www.reddit.com/r/u_bluebashllc/comments/1ebng9f/a_comprehensive_guide_boosting_ehr_efficiency/) , 2024-07-26-0911
```
LangChain.js is a robust JavaScript library for working with language models like GPT-3. It simplifies text generation, 
summarization, and information extraction, making it a perfect fit for enhancing EHR systems.The healthcare industry has
 made significant strides with Electronic Health Records (EHR), but managing the volume and complexity of unstructured d
ata in these systems is still a major hurdle. That's where LangChain.js comes in! LangChain.js is a robust JavaScript li
brary for working with language models like GPT-3. It simplifies text generation, summarization, and information extract
ion, making it a perfect fit for enhancing EHR systems.

**Problem Statement**  

EHR systems are designed to handle vas
t amounts of data, including structured data like patient demographics and unstructured data like doctor's notes. Unstru
ctured data often contains crucial information about a patient's condition, treatment plan, and progress. Manually extra
cting and summarizing this information is time-consuming and prone to errors. Automated solutions are needed to efficien
tly process and extract relevant information from unstructured EHR data.

[ Boosting EHR Efficiency with LangChain.js](h
ttps://preview.redd.it/yi4kxhpitled1.jpg?width=1920&format=pjpg&auto=webp&s=041c1ddcceae6cd26cf8552dd92953c0509067a1)

*
*Understanding LangChain.js**  

[LangChain.js](https://www.bluebash.co/blog/ehr-efficiency-langchain-js/) allows develo
pers to build applications using advanced language models, providing an easy-to-use interface for working with text data
. It's particularly valuable for handling the unstructured data often found in EHR systems. With LangChain.js, you can p
erform a wide range of natural language processing (NLP) tasks including text generation, summarization, and information
 extraction. This helps streamline the integration of sophisticated language models into applications, enhancing the abi
lity to manage and interpret large volumes of textual data.

**Key Features of LangChain.js:**

1. **Text Generation:** 
Generate coherent and contextually relevant text based on the input provided.
2. **Summarization:** Condense long pieces
 of text into concise summaries.
3. **Information Extraction:** Extract specific information from large volumes of text,
 making it easier to find relevant data.

**Use Case: Enhancing EHR Systems with LangChain.js**  

Let's delve into a pr
actical use case of utilizing LangChain.js to significantly enhance an EHR system. In this scenario, we will concentrate
 on the process of extracting crucial patient information from unstructured text data, which could include a variety of 
sources such as doctor's notes, clinical reports, and patient histories. By leveraging the capabilities of LangChain.js,
 we can efficiently generate comprehensive summaries that provide healthcare professionals with a quick and effective me
ans of reviewing critical patient information. This not only streamlines the workflow but also ensures that important de
tails are readily accessible, ultimately improving patient care and decision-making processes.

1. **Setting Up LangChai
n.js:** First, you need to install LangChain.js using npm.
2. **Extracting Information from Doctor's Notes:** Automate t
he extraction of valuable information about a patient's condition, treatment plan, and progress.
3. **Summarizing Patien
t Records:** Generate concise summaries from lengthy patient records, giving healthcare professionals a quick overview o
f a patient's medical history
```
---

     
 
all -  [ Salesforecasting using AI models / LLM ](https://www.reddit.com/r/LangChain/comments/1ebm8ss/salesforecasting_using_ai_models_llm/) , 2024-07-26-0911
```
Hello all, Have anyone among here done sales forecasting using LLMs ?  
For eg: I have monthly sales data of last 2 year
s and i want to predict the monthly sales of upcoming year.  
What would be the best way to do it ?

If anyone has code 
snippet, I would be happy to look at it.  
I welcome ML/DL approach as well but since my dataset is very low what would 
be the best idea ?


```
---

     
 
all -  [ Not able to figure out Agents with Chat History ](https://www.reddit.com/r/LangChain/comments/1eblbm7/not_able_to_figure_out_agents_with_chat_history/) , 2024-07-26-0911
```
Here's my chain, but looks something wrong. Earlier without the code of agents part, it was working well with chat histo
ry.

Any help is appreciated.

    def _prepare_chain(self):
            contextualize_q_system_prompt = (
             
   'Given a chat history and the latest user question '
                'which might reference context in the chat histo
ry, '
                'formulate a standalone question which can be understood '
                'without the chat histo
ry. Do NOT answer the question, '
                'just reformulate it if needed and otherwise return it as is.'
       
     )
    
            _llm = self.llm
            if self.tools:
                _llm = self.llm.bind_tools(self.tools
)
    
            contextualize_q_prompt = ChatPromptTemplate.from_messages(
                [
                    ('sy
stem', contextualize_q_system_prompt),
                    MessagesPlaceholder('chat_history'),
                    ('hu
man', '{input}'),
                ]
            )
    
            history_aware_retriever = create_history_aware_retrie
ver(
                _llm, self.retriever, contextualize_q_prompt
            )
    
            ### Answer question ###

            system_prompt = (
                '{base_prompt}'
                'Act like a support person who loves help
ing customers. '
                'Use the following pieces of retrieved context to answer '
                'the questio
n. If you don't know the answer, say that you '
                'don't know. Use three sentences maximum and keep the '

                'answer concise.'
                '\n\n'
                '{context}'
            )
    
            ANSW
ER_PROMPT = PromptTemplate.from_template(system_prompt)
    
            qa_prompt = ChatPromptTemplate.from_messages(
 
               [
                    ('system', system_prompt),
                    MessagesPlaceholder('chat_history'),

                    ('human', '{question}'),
                ]
            )
    
            question_answer_chain = c
reate_stuff_documents_chain(_llm, qa_prompt)
    
            retrieval_chain = create_retrieval_chain(history_aware_ret
riever, question_answer_chain)
    
            _runnable = (
                RunnablePassthrough.assign(
              
      agent_scratchpad=lambda x: format_to_openai_tool_messages(x['intermediate_steps'])
                )
             
   | retrieval_chain
                | _llm
                | OpenAIToolsAgentOutputParser()
            )
    
        
    _agent = RunnableAgent(runnable=_runnable)
    
            _output = RunnableParallel(
                answer=Agent
Executor(agent=_agent, tools=self.tools),
                sources=history_aware_retriever | self._extract_sources
      
      )
    
            rag_chain = RunnablePassthrough.assign(
                input=lambda x: x['question']) | _outpu
t | RunnableLambda(self.log_chain)
    
            conversational_rag_chain = RunnableWithMessageHistory(
             
   rag_chain,
                self.get_session_history,
                input_messages_key='question',
                h
istory_messages_key='chat_history',
                output_messages_key='answer',
            )
    
            return 
conversational_rag_chain
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses ](https://www.reddit.com/r/udemyfreebies/comments/1ebdd7x/list_of_free_and_best_selling_discounted_courses/) , 2024-07-26-0911
```
# Udemy Free Courses for 25 July 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the cou
rses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11803/)Learn Basics of Obsidian: Mastering Study Not
es
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11804/)Learn Basics of Obsidian: Mastering Study Notes in Arabic

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11805/)Complete Generative AI Course With Langchain and Huggingface

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11806/)Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/11807/)AWS Business Essentials – The Business Value of AWS \[2024\]
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/11808/)Basics of Obsidian: The Canvas Plugin in Arabic
* [REDEEM OFFER 
](https://idownloadcoupon.com/udemy/11809/)Learn Python for Data Science for Beginners in Arabic
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/11810/)Learn Basics of Obsidian: The Canvas Plugin
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/11811/)زد من انتاجيتك عن طريق برنامج اوبسيديان
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11812/)R 
Programming for Complete Beginners
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11813/)Improve your Productivity 
by using Obsidian
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11814/)Management Information Systems Student’s Jo
urney
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11815/)Learn Obsidian from Scratch
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/11816/)Learn Python for Data Science for Complete Beginners
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/11799/)TRADING META TRANSACTION
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11798/)Menguasai Go
ogle Ads untuk Pemula hingga Mahir 2024
* WAX Blockchain Game Front-End w/ React, Redux & Saga Part 3
* [REDEEM OFFER](h
ttps://idownloadcoupon.com/udemy/11797/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11796/)Learn Expert Systems
 for BI and Business Analytics
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11795/)Starting with IoT Simulations

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11800/)Diseño UX Potenciado por la Ciencia de los Hábitos
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/11801/)WAX Blockchain Game Front-End w/ React, Redux & Saga Part 1
* [REDEEM O
FFER ](https://idownloadcoupon.com/udemy/11794/)Executive Diploma of Chief Technology Officer
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/11793/)400 Tableau Interview Questions Practice Test
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11792/)AI For Warehouse Management Certificate Odoo 17 Program
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/11791/)Control of Manufacturing Processes with Odoo 17 AI-Powered
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/11790/)Six Sigma Green Belt Practice Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11789/)From Zero to He
ro: Master Microservices with ASP.NET Core
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11237/)Social Media Maste
ry 2023| Increase Customer Conversion Rate
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/3570/)Professional Diplom
a in Agile and Scrum
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8176/)Microsoft Excel – Beginner to Advance wit
h Example
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/2649/)Migra un Sitio Web de WordPress a otro Dominio o Hos
ting
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/4070/)Excel VBA / Makros Programmierung. Automatisierung mit Ex
cel
* Mastering ChatGPT (AI) and PowerPoint presentation
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/8200/)
* [RE
DEEM OFFER ](https://idownloadcoupon.com/udemy/2807/)Cómo Crear una Página web con WordPress y Elementor 2024
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/11012/)TOEFL Preparation: Listening Section
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/8980/)Complete SmartPhone Graphic Design – 3 in 1 Course
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/2646/)Cómo Crear una Tienda Online con WordPress y WooCommerce
* [REDEEM OFFER ](https://idownloadcoupon.com/udem
y/2799/)WP Rocket 2024: Mejora la Velocidad de Carga en WordPress
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10
597/)Web3 Development Essentials
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11788/)Parallel Computing in Julia

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11787/)Professional Diploma in Public Relations and PR Management
* 
[REDEEM OFFER ](https://idownloadcoupon.com/udemy/11786/)SAFe® 6.0: From Zero to Hero in Scaled Agile Framework®
* [REDE
EM OFFER ](https://idownloadcoupon.com/udemy/11785/)Comprehensive Machine Learning Practice Test: Skill Mastery
* [REDEE
M OFFER ](https://idownloadcoupon.com/udemy/9811/)Ethically Hack the Planet Part 4
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/10543/)350+ CSS Practice Tests & Interview Questions \[April. 2024\]
* [REDEEM OFFER ](https://idownloadc
oupon.com/udemy/10085/)Master Ruby Scripting with (Practice test only) for Hacking
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/10786/)Computer Science MetaBootcamp: Beginner to Intermediate 2024
* [REDEEM OFFER ](https://idownloadco
upon.com/udemy/10827/)Google Ads 2024: How to Drive Sales With PPC!

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CL
ICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ How to return similarity scores using retriever.get_relevant_documents(query) ](https://www.reddit.com/r/LangChain/comments/1eb5r0v/how_to_return_similarity_scores_using/) , 2024-07-26-0911
```
Hi I want to do metadata filtering first and then retrieve the document  
Code:

    langchain_chroma = Chroma(
        
        client=self.persistent_client,
                collection_name=self.COLLECTION_NAME,
                embedding_f
unction=self.embedding_function  # Use the variable containing the collection name
            )

    retriever = langch
ain_chroma.as_retriever(search_type='similarity',search_kwargs={'k': 1, 'filter': cond}) 
    query = 'What is patient f
amily Medical history in reverse cronological order?'
    res = retriever.get_relevant_documents(query)
    res

This is
 not returning scores, Whereas If use ,  


    res = langchain_chroma.similarity_search_with_score(query)

then i am ge
tting score as well but how to do metadata filtering here?





  

```
---

     
 
all -  [ Langchain vs LlamaIndex ](https://www.reddit.com/r/LlamaIndex/comments/1eb25ir/langchain_vs_llamaindex/) , 2024-07-26-0911
```
Hello guys I wondering what are the differences between Langchain and LlamaIndex? I am not asking about what’s best but 
I want to know when to use each one? Can you give me some advices and tips?
Thank you
```
---

     
 
all -  [ LangChain VS LangGraph: Git ](https://www.reddit.com/r/LangChain/comments/1eb19ri/langchain_vs_langgraph_git/) , 2024-07-26-0911
```
At the time of posting,

LangChain repository's `master` branch is

```
Cloning into 'langchain'...
remote: Enumerating 
objects: 137116, done.
remote: Counting objects: 100% (5275/5275), done.
remote: Compressing objects: 100% (481/481), do
ne.
remote: Total 137116 (delta 5003), reused 4829 (delta 4794), pack-reused 131841
Receiving objects: 100% (137116/1371
16), 224.32 MiB | 4.70 MiB/s, done.
Resolving deltas: 100% (101282/101282), done.
Updating files: 100% (7595/7595), done
.
```

and LangGraph repository's `main` branch is

```
Cloning into 'langgraph'...
remote: Enumerating objects: 10436, 
done.
remote: Counting objects: 100% (1815/1815), done.
remote: Compressing objects: 100% (1015/1015), done.
remote: Tot
al 10436 (delta 1090), reused 1371 (delta 774), pack-reused 8621
Receiving objects: 100% (10436/10436), 327.76 MiB | 3.1
3 MiB/s, done.
Resolving deltas: 100% (6828/6828), done.
```

For comparision, this is React's `main` brach is

```
Clon
ing into 'react'...
remote: Enumerating objects: 326918, done.
remote: Counting objects: 100% (813/813), done.
remote: C
ompressing objects: 100% (324/324), done.
remote: Total 326918 (delta 470), reused 718 (delta 422), pack-reused 326105
R
eceiving objects: 100% (326918/326918), 532.16 MiB | 5.97 MiB/s, done.
Resolving deltas: 100% (232896/232896), done.
```

and it doesn't even have rich text files like .ipynb.

There are couple of observations.
1. Maintaining an open-source 
repository with Jupyter Notebooks is not for easy, I think. Any updates to libraries used need notebooks to rerun and re
flect latest outputs. Even if there is no change in output, the git diff changes drastically. I have heard about nbdime 
but have no idea about it.
2. LangGraph repo is bigger in size than LangChain after decompressing.
   ```
   du -sh lang
graph
   475M	langgraph
   
   du -sh langchain
   459M	langchain```
   This size by du depends on multiple factors, blo
ck size being on of them.

What did you find interesting? Do share more insights and fun facts about the projects!
```
---

     
 
all -  [ Reverting back to planning node based on a condition ](https://www.reddit.com/r/LangChain/comments/1eazoaz/reverting_back_to_planning_node_based_on_a/) , 2024-07-26-0911
```
I am trying to make a planning agent using langgraph in which we can revert back to the planner node using conditions fr
om other agent nodes . I am stuck on the reverting back function.
```
---

     
 
all -  [ Request for Guidance  ](https://www.reddit.com/r/LangChain/comments/1eayrtc/request_for_guidance/) , 2024-07-26-0911
```
Hi all. I am an LLM enthusiast trying to use GGUF version of Llama 3.1 for summarisation task. 

I am using Q4_K_M model
 from this repo:
MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF
Link: https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1
-8B-Instruct-GGUF

I used the following code to load the model:
```
from langchain_community.llms import LlamaCpp
from l
angchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler

callback_manager = CallbackManager([Stre
amingStdOutCallbackHandler()])
n_gpu_layers = -1  
n_batch = 2048 

# Make sure the model path is correct for your syste
m!
llm = LlamaCpp(
    model_path='./Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf',
    n_gpu_layers=n_gpu_layers,
    n_ctx =
 32768,
    rope_freq_scale=0.25,
    temperature = 0,
    n_batch=n_batch,
    callback_manager=callback_manager,
    v
erbose=True,  # Verbose is required to pass to the callback manager
)
```

When I pass long inputs to this model and ins
truct it to summarise it, it just blabbers with random and repitive texts/numbers.

How do I resolve this. Requesting fo
r guidance.

(PS: Tried Rope_freq_scale with values 0.125, 0.25, 1, 4, 8. But they were not so good, even comparing to t
he above results)
```
---

     
 
all -  [ Llama 3.1 LangChain integration codes explained  ](https://www.reddit.com/r/ArtificialInteligence/comments/1eayapj/llama_31_langchain_integration_codes_explained/) , 2024-07-26-0911
```
This demo talks about how to use Llama 3.1 with LangChain to build Generative AI applications: https://youtu.be/LW64o3Yg
bE8?si=1nCi7Htoc-gH2zJ6
```
---

     
 
all -  [ Easiest way to implement reranking in Langchain and Java ](https://www.reddit.com/r/LangChain/comments/1eawsb6/easiest_way_to_implement_reranking_in_langchain/) , 2024-07-26-0911
```
i am using in memory vector database where I get scoring of responses. 

  
Now i want to implement reranking to get the
 most accurate responses. 

  
What would be the easiest way to implmement this in Java Langchain. 
```
---

     
 
all -  [ What is your LLM Stack? ](https://www.reddit.com/r/SmythOS/comments/1eawark/what_is_your_llm_stack/) , 2024-07-26-0911
```
I’ll go first!   
Vector database: Quadrant  
Orchestration: Haystack and llamaindex  
LLM: OpenAI GPT 4, LLAMA 70B(loca
l), Gemini Pro 1.5  
LLM Framework: Langchain or direct integration

What’s yours?


```
---

     
 
all -  [ How to customize the Chat Format LangChain uses for my specific LLM? ](https://www.reddit.com/r/LangChain/comments/1eav643/how_to_customize_the_chat_format_langchain_uses/) , 2024-07-26-0911
```
Hello, I am starting to use LangChain and have a question, for which I did not find a response in the documentation.

Fr
om my understanding, each LLM is trained with a different *chat format* to separate AI and user messages. For instance, 
I am currently developing with Phi3 which uses the following format for AI messages: `<|assistant|>Assistant Message<|en
d|>`.

How can I pass some parameters to tell LangChain to use this format? Above all, is this handled by the `LLM` clas
s or by the `Message` class?

I make an example to make my point clearer. When I use the following code

    ChatPromptT
emplate.from_messages(
                [
                    ('system', 'Behave like this...'),
                    ('hu
man', '{input}'),
                ]
            )

How can I tell LangChain to insert `<|user|>` at the beginning of the
 user message? I do not see any parameter to pass to the `HumanMessage` object. 
```
---

     
 
all -  [ Long term memory for agents? ](https://www.reddit.com/r/LangChain/comments/1eat8c4/long_term_memory_for_agents/) , 2024-07-26-0911
```
Does anyone have best practices to share on implementing long term memory for agents? E.g., personalization based on cha
t history. Based on the memgpt paper it seems best practices would be to have a secondary agent that can read/write long
 term context into a database, like a Redis cache. Curious if  anyone has tuned a model for this? 
```
---

     
 
all -  [ Having problem with langchain loader ](https://www.reddit.com/r/datascience/comments/1eaien5/having_problem_with_langchain_loader/) , 2024-07-26-0911
```
I have the data in JSON format I’m trying to use the jsonloader but apparently I need a download and import a jq module 
and that’s where my problem is. I have pip installed jq but when it’s time to import it, I get a no module error and yes
 it’s installed in venv that I am working in. Has anyone had this problem before 
```
---

     
 
all -  [ Exciting News from Meta [Llama 3.1 is Here] ](https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/) , 2024-07-26-0911
```
Meta has just released its latest LLM model, Llama 3.1, marking a significant step in accessible artificial intelligence
. Here are the key points from the announcement:

1. **405B version.** There is a new Llama 3.1 405B version. That’s rig
ht *405 Billion parameters.*
2. **Expanded context length**: Now all llama 3.1 models offer a context length of **128K t
okens**, 16 times its previous 8K context length from Llama 3. This allows for more advanced use cases, such as long-for
m text summarization, multilingual conversational agents, and coding assistants
3. **Model evaluations**: The model eval
uations released by Meta are as follows:

[Llama 405B](https://preview.redd.it/zjcxaf93jbed1.png?width=3201&format=png&a
uto=webp&s=31191792e788799899102d882d3170acc34ea19b)

[Llama 8B](https://preview.redd.it/h1x4jcy6jbed1.png?width=3201&fo
rmat=png&auto=webp&s=4fb34e2d110345a34e1715d16be8951d0edc637b)

**4. API Coming Soon:** Users will be able to access and
 utilize Llama 3.1 models through [awanllm.com](http://awanllm.com/) soon. Stay tuned for updates in this post!

Source:
 [https://ai.meta.com/blog/meta-llama-3-1/](https://ai.meta.com/blog/meta-llama-3-1/)
```
---

     
 
all -  [ MongoDB as vectorstore  ](https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/) , 2024-07-26-0911
```
What are your thoughts on using MongoDB as vectorstore for your apps.

I was working on prototype locally for the most o
f its time but right now we are moving to hosting on streamlit, what are your recommendations for vectorstores.

```
---

     
 
all -  [ Looking for an opensource framework to manage agents ](https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/) , 2024-07-26-0911
```
I want to give my client the option to construct new agents and create flows for input and output like vectorizing input
 and parsing output and storing it in a database. Is there any opensource tool with a UI that can do this?
The language 
it's written in doesn't really matter, all options are welcome.
```
---

     
 
all -  [ I build a RAG-based multi-tenant AI Code Assistant with OpenAI, LangChain, Postgres and PG Vector ](https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/) , 2024-07-26-0911
```
I am rather new to the AI space (my background is data infrastructure), so I am documenting my journey as I'm learning. 
This time I built an AI Code Assistant that uses RAG to answer questions about different repositories.

I blogged everyt
hing I learned while building this - Schema design, use of LangChain (tbh, not sure it was a good choice...), choice of 
models, streaming chat UX...

You can see the app here: [https://code-assist-nile.vercel.app](https://code-assist-nile.v
ercel.app)  
And the blog: [https://www.thenile.dev/blog/building\_code\_assistant](https://www.thenile.dev/blog/buildin
g_code_assistant)  
The code is here: [https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code\_assist/]
(https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code_assist/)
```
---

     
 
all -  [ Forced function calling in vertex ai gemini?? ](https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/) , 2024-07-26-0911
```
Hello everyone,

I want to force function calling with Gemini. Does anyone know how to do this?

I have checked the docu
mentation for Vertex AI and Langchain but couldn't find any information. In the Vertex AI docs, I found a parameter that
 could be passed, but I don't know how to pass it using Langchain. I am using `ChatVertexAI().bind_tools()`.

Regards!
```
---

     
 
all -  [ What do you think are better alternatives to Pinecone Vector DB? ](https://www.reddit.com/r/SmythOS/comments/1eabnkj/what_do_you_think_are_better_alternatives_to/) , 2024-07-26-0911
```
I have tried using pinecone, usually with frameworks like Langchain and llama-index and I saw that pinecone doesn't appe
ar to support storing documents alongside your vectors so what I tried to do is actually cram snippets of the document i
nto the metadata, but the metadata is limited to something really really small, so the maximum document length gets cons
trained. 

If you use another database alongside pinecone and just want to retrieve uuids or something, it's fine, but i
t struck me as a very weird omission in their design. 
```
---

     
 
all -  [ Is Qdrant cloud Production Ready? ](https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/) , 2024-07-26-0911
```
Guys,

Has anybody used Qdrant in the cloud, especially Azure and has gone live and in production? We are trying to inse
rt 884 points with a production grade cluster in azure eastus and it takes about 6-8 seconds and that too with gRPC. Htt
p takes even longer.

We are absolutely sure that this is the time taken by Qdrant Remote Client provided by their offic
ial package because we have enabled all the logging and can pin-point which operation takes time.

We created a support 
ticket with the Qdrant team as well, but have been ghosted by them.  

Wondering if Qdrant is right choice and if it is,
 how do people insert points faster? We do have metadata and chunk text in the point. 
```
---

     
 
all -  [ Multi-agent-DataAnalysis AI-Driven Data Analysis System ](https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/) , 2024-07-26-0911
```
# # Advanced AI-Driven Data Analysis System: A LangGraph Implementation



## Project Overview



I've developed a sophi
sticated data analysis system that leverages the power of LangGraph, showcasing its capabilities in integrating various 
AI architectures and methodologies. This system is designed to serve as a comprehensive example of how LangGraph can be 
used to streamline complex data analysis tasks by orchestrating multiple AI agents and architectural patterns.

https://
preview.redd.it/lntq41fap9ed1.jpg?width=610&format=pjpg&auto=webp&s=7b2f31c450c495ebe2eb3d5a1e75522223ae1267

## Key Fea
tures



- \*\*LangGraph-Powered Architecture\*\*: The system demonstrates LangGraph's flexibility by incorporating:

  
- Supervisor agents for overseeing the analysis process

  - Chain-of-thought reasoning for complex problem-solving

  -
 Critic agents for quality assurance and error checking



- \*\*Innovative Note Taker Agent\*\*: A standout feature tha
t highlights LangGraph's extensibility:

  - Continuously records the current state of the project

  - Provides a more 
efficient alternative to transmitting complete historical information

  - Enhances the system's ability to maintain con
text and continuity across different analysis stages



- \*\*Adaptive Workflow\*\*: Showcases LangGraph's dynamic routi
ng capabilities, adjusting the analysis approach based on the data and task at hand.



## Why It's a Valuable LangGraph
 Example



This implementation serves as an excellent case study for LangGraph users by demonstrating:



1. Integratio
n of diverse AI agent types within a unified framework

2. Efficient state management using the innovative Note Taker ag
ent

3. Real-world application of LangGraph in complex data analysis scenarios



## Contribution to LangGraph



I am e
ager to contribute this project as an example in the official LangGraph repository. My goals are to:



- Provide a comp
rehensive, real-world example of LangGraph's capabilities

- Help other developers understand advanced LangGraph impleme
ntations

- Contribute to the growth and adoption of LangGraph in the AI community



## Project Repository



For a dee
per dive into the codebase, architecture, and implementation details, please visit the project's GitHub repository:



\
[AI-Driven Data Analysis System on GitHub\](https://github.com/starpig1129/Multi-agent-DataAnalysis)





I welcome feed
back and collaboration to refine this example for potential inclusion in the LangGraph documentation or example collecti
on.



## Next Steps



1. I am open to adapting the project to better align with LangGraph's documentation standards.


2. I would appreciate guidance on the best way to submit this as a potential official example.

3. I'm eager to collabor
ate with the LangGraph community to enhance this example and make it as valuable as possible for other users.



Feel fr
ee to explore the repository, and I look forward to any feedback or suggestions for improving this as a LangGraph exampl
e!


```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-07-26-0911
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
MachineLearning -  [ [D] Is Anyone Else Setting Up Real-Time Django Workers for their AI Application? What's the best way ](https://www.reddit.com/r/MachineLearning/comments/1e0qens/d_is_anyone_else_setting_up_realtime_django/) , 2024-07-26-0911
```
We completely underestimated this one tbh, thought it would be much more straight forward. But we've done it now and doc
umented how step by step [in this article series](https://medium.com/p/5828a1ea43a3).

A bit of context, we're building 
a mini free AI Agent that auto-generates manually customisable plots, so the user can basically style however they want.
 It needs to be cost effective and efficient, so we thought about how to do it and tested a couple other ways.

https://
preview.redd.it/cmly0a6bhwbd1.png?width=640&format=png&auto=webp&s=be1f5b2853e744adcaf8013e6d43b43f6be89617

We plan on 
releasing the project open source, so all feedback welcome! Is anyone else doing this and has any feedback? or do know o
f a better way to do it?
```
---

     
 
MachineLearning -  [ [P] Real Time AI Workers Web Application ](https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/) , 2024-07-26-0911
```
Hi everyone!

I've created a mini series on how to build a real time AI application using Django, LangChain and Celery.


Free knowledge - posting it in here for anyone working on something similar and had the same blockers I had when buildi
ng.

Let me know what you think on how I could potentially improve this architecture.

Part 1

[https://medium.com/towar
dsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79](https://medium.
com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79)

Part 
2

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5
828a1ea43a3](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time
-django-5828a1ea43a3)

Part 3

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-red
is-docker-real-time-django-8e73c7b6b4c8](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-cha
nnels-redis-docker-real-time-django-8e73c7b6b4c8)

Part 4

[https://medium.com/towardsdev/how-to-set-up-django-from-scra
tch-with-celery-channels-redis-docker-real-time-django-c090c300517a](https://medium.com/towardsdev/how-to-set-up-django-
from-scratch-with-celery-channels-redis-docker-real-time-django-c090c300517a)

Part 5  
[https://medium.com/@cubode/how-
to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c](https://medium.com/@cubod
e/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c)
```
---

     
 
deeplearning -  [ Llama 3 not running on GPU ](https://www.reddit.com/r/deeplearning/comments/1dptxsr/llama_3_not_running_on_gpu/) , 2024-07-26-0911
```
I dont know much theory about RAG but i need to implement it for a project.  
**I want to run llama3 on my GPU to get fa
ster results.**

`from langchain_community.llms import Ollama`  
`llm = Ollama(model='llama3',num_gpu=1)`  
`def generat
e_response(prompt, similar_jobs):`  
`descriptions = '\n\n'.join([job['Description'] for job in similar_jobs])`  
`augme
nted_prompt = f'{prompt}\n\nHere are some job recommendations based on your query:\n{descriptions}'`  
`for chunks in ll
m.stream(augmented_prompt):`  
`print(chunks, end='')`

I am giving llama3 my *'user prompt'* and top 5 nearest *'simila
r\_jobs'* using cosine similarity.  
This code goes not use my GPU but my CPU and RAM usage is high.

**My gpu usage is 
0%** , i have a Nvidia GeForce RTX 3050 Laptop GPU GDDR6 @ 4GB (128 bits)
```
---

     
