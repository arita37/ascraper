 
all -  [ Question about building a chatbot using internal company documentation ](https://www.reddit.com/r/ArtificialInteligence/comments/15xnq1h/question_about_building_a_chatbot_using_internal/) , 2023-08-22-0909
```
Hi there. I'm a non-developer (Product person) trying to build a basic mental model for how we might build a chatbot tha
t would allow our internal support team to interact with our propietary knowledgebase. Our KB currently resides in Notio
n.

I've been reading up on and watching videos about the LangChain framework, the differences between In-Context Learni
ng and Fine Tuning, Vector databases/embeddings etc. So I've got a rough handle on the overall architecture.

Where I'm 
a little stumped right now is how to think about the process of actually getting our KB content from Notion into a Vecto
r DB. More specifically, I'm interested in understanding (at a high, abstract level) how to think about keeping that kno
wledge up to date. For example, as the support team updates KB articles, having some mechanism in place for updating the
 Vector DB automatically so that it's always pulling from the latest information automatically. I believe I've seen Chat
bot apps out there that let you plug in a URL to scrape data from and then have it update every \~24 hours or so.

Can a
nyone share with me the big building blocks involved with implementing something like this? Is there typically some sort
 of cron job that's scraping the KB at regular intervals and then moving that data into the Vector DB?

Thanks in advanc
e.
```
---

     
 
all -  [ Langchain: Explained in 2 minutes ](https://www.reddit.com/r/ChatGPTPro/comments/15xjvdi/langchain_explained_in_2_minutes/) , 2023-08-22-0909
```


No stock images/ videos, no gifs, and no flashy texts. Only pure technical deep dive.

Here is the quickest but in-dep
th explainer video about Langchain, a framework gaining popularity day by day. 

https://www.youtube.com/watch?v=C9bE8bH
cJVI

Using Langchain is  one of the quickest way to create and test an advanced LLM based AI application. Check it out!

```
---

     
 
all -  [ Langchain: Explained in 2 minutes ](https://www.reddit.com/r/GPT3/comments/15xj90d/langchain_explained_in_2_minutes/) , 2023-08-22-0909
```
No stock images/ videos, no gifs, and flashy texts. Only pure technical deep dive.

Here is the quickest but in-depth ex
plainer video about Langchain, a framework gaining popularity day by day. 

https://www.youtube.com/watch?v=C9bE8bHcJVI


Using Langchain is  one of the quickest way to create and test an advanced LLM based AI application. Check it out!
```
---

     
 
all -  [ Langchain: Explained in 2 minutes ](https://www.reddit.com/r/learnmachinelearning/comments/15xj4u5/langchain_explained_in_2_minutes/) , 2023-08-22-0909
```
No stock images/ videos, no gifs, and no flashy texts. Only pure technical deep dive.

Here is the quickest but in-depth
 explainer video about Langchain, a framework gaining popularity day by day. 

https://www.youtube.com/watch?v=C9bE8bHcJ
VI

Using Langchain is  one of the quickest way to create and test an advanced LLM based AI application. Check it out!
```
---

     
 
all -  [ AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework - Microsoft 2023  ](https://www.reddit.com/r/singularity/comments/15xh3xp/autogen_enabling_nextgen_llm_applications_via/) , 2023-08-22-0909
```
Paper: [https://arxiv.org/abs/2308.08155](https://arxiv.org/abs/2308.08155) 

Github: [https://microsoft.github.io/FLAML
/docs/Use-Cases/Autogen/](https://microsoft.github.io/FLAML/docs/Use-Cases/Autogen/) 

Abstract:

>This technical report
 presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse 
with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. 
They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers mul
tiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; 
b) it leverages human understanding and intelligence, while providing valuable automation through conversations between 
agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide ma
ny diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging f
rom coding, mathematics, operations research, entertainment, online decision-making, question answering, etc.      

htt
ps://preview.redd.it/xbkfaqe7jijb1.jpg?width=1377&format=pjpg&auto=webp&s=e86ea1dba6c79e4b74ef19b2effc265c690f6cae

http
s://preview.redd.it/78i6sre7jijb1.jpg?width=1520&format=pjpg&auto=webp&s=85d8ff4632dc4c6d3d380e7a4c559d57148bc5cd

https
://preview.redd.it/9bka0qe7jijb1.jpg?width=974&format=pjpg&auto=webp&s=593b3bed04997f347d522a3e096f968663af2089

https:/
/preview.redd.it/18e24we7jijb1.jpg?width=1136&format=pjpg&auto=webp&s=a34b44003f7b3be599e0e8de9b4195216bcf19f4

&#x200B;

```
---

     
 
all -  [ Resume review for 2023 graduate, Any tips on where freshers should apply or any referrals would help ](https://i.redd.it/09onri1hfijb1.jpg) , 2023-08-22-0909
```

```
---

     
 
all -  [ Advise needed using chat history. ](https://www.reddit.com/r/LangChain/comments/15xg5na/advise_needed_using_chat_history/) , 2023-08-22-0909
```
Can anyone advise how I can use chat history with the sqltoolkit agent? I have the memory setup and can see that the cha
t request are being written along with the output response.
However, the agent is not contextually aware of the previous
 chat history.
```
---

     
 
all -  [ Any non-Langchain implementations of a multiple-PDF querying bot with ChatGPT? ](https://www.reddit.com/r/ChatGPT/comments/15x2rxr/any_nonlangchain_implementations_of_a_multiplepdf/) , 2023-08-22-0909
```
I can only find Langchain implementations when browsing the web. But since the overwhelming consensus in the community s
eems to be that Langchain is not advisable for production use cases, and its only good for prototyping, I would like to 
find some non-Langchain implementations if possible.
```
---

     
 
all -  [ Using Llama 2 with SQLDatabaseToolkit ](https://www.reddit.com/r/LangChain/comments/15x0xoi/using_llama_2_with_sqldatabasetoolkit/) , 2023-08-22-0909
```
As the title suggests, has anyone attempted to use Llama 2 with the SqlDatabaseToolkit? I've managed to get it to work u
sing openAI's gpt-3.5-turbo-16k model but I'm struggling to get Llama 2 to work. I'm using it with HuggingFace (I have a
 PRO account) but it doesn't seem to work. When using with gpt, I go about it like so:

*llm = ChatOpenAI(model\_name='g
pt-3.5-turbo-16k', temperature=0) # change between 0 and 0.2 for testing*  
toolkit *=* SQLDatabaseToolkit(db*=*db2, llm
*=*llm)   
agent\_executor *=* create\_sql\_agent(  
 llm*=*llm,  
 toolkit*=*toolkit,  
 verbose*=*True  
)  


Using L
lama2 I do:  


llm *=* HuggingFacePipeline.from\_model\_id(  
 model\_id*=*'meta-llama/Llama-2-70b-chat-hf',  
 task*=*
'text-generation',  
 model\_kwargs*=*{'temperature': 0},  
)  
toolkit *=* SQLDatabaseToolkit(db*=*db2, llm*=*llm)   
a
gent\_executor *=* create\_sql\_agent(  
 llm*=*llm,  
 toolkit*=*toolkit,  
 verbose*=*True  
)

but I get the followin
g error message:

&#x200B;

**Cannot execute code, session has been disposed. Please try restarting the Kernel.**

**The
 Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) t
o identify a possible cause of the failure. Click** [**here**](https://aka.ms/vscodeJupyterKernelCrash) **for more info.
 View Jupyter log for further details.**

&#x200B;

I looked at the possible causes offered by the error but can't seem 
to decipher what the issue is.

&#x200B;

Would love any advice anyone has to offer.

&#x200B;

Thanks

&#x200B;

  

```
---

     
 
all -  [ Map Natural Language to commands ](https://www.reddit.com/r/LangChain/comments/15x02gc/map_natural_language_to_commands/) , 2023-08-22-0909
```
Hello all,

I just got started with LLMs and LangChain. I have experience with traditional software development. I want 
to build a simple chatbot that can perform tasks based on the User's inputs. An example would be as follows:

**Select t
he top 10 customers by revenue, send them an email about the latest discounts and post a message on the #sales slack cha
nnel.**

From my research, I only found Zapier NLA ([https://nla.zapier.com/start/](https://nla.zapier.com/start/)). Is 
there any open-source alternative or a library that I can use to map natural language to command and integrate with an L
LM? Thanks in advance!
```
---

     
 
all -  [ Bridge The Gap On Multiple Chains ](https://www.reddit.com/r/LangChain/comments/15wwaif/bridge_the_gap_on_multiple_chains/) , 2023-08-22-0909
```
I probably should have put a more accurate title

Hi all I have a long pdf and Iâ€™m trying to pull some data out in json 
formatâ€¦
I need to find a certain page (similarity search) then search for my fields with a templates prompt then move on
 to the next page in pdf, do the same  and keep going until my llm returns (no expected  info on page). 
Then need to fe
ed all jsons into a data frame 

Can anyone help me bridge the gap on finding the sequential next page (of the output of
 a similarity search) and submit subsequent prompts against those pages in an efficient manner?
```
---

     
 
all -  [ Veterinary Chatbot ](https://www.reddit.com/r/llama/comments/15wo8pr/veterinary_chatbot/) , 2023-08-22-0909
```
Can you guys give feedback on thisðŸ‘‡

https://youtu.be/Iyzvka711pc

Some highlights:
1. Have shown how you can leverage a
 deployed LLM (Llama2 in this case) from AWS SageMaker through the Langchain SageMaker module in your python application
. 

2. FastAPI backend (API endpoints) 

3. Embeddings are created offline (Currently in FAISS in memory). 

######
Next
 video:
Deploying this PetCare Chatbot App on AWS through fargate.
```
---

     
 
all -  [ Llama-2-13b and document QA ](https://www.reddit.com/r/LocalLLaMA/comments/15wmyej/llama213b_and_document_qa/) , 2023-08-22-0909
```
So I created embeddings from few pdf-s. For now I tested some Vicuna and WizardLm models. Now I wanted to test Llama 2 m
odel so I got approved on HF and used this model: [https://huggingface.co/meta-llama/Llama-2-13b-hf](https://huggingface
.co/meta-llama/Llama-2-13b-hf)   
When I pass in my embeddings (I am using langchain) and prompt a simple question, like
 'What is X?' where X is some term, thing etc. from PDF, I get results where there short answer and URL for source from 
diffrent websites like [ask.com](https://ask.com) [wisegeek.com](https://wisegeek.com) etc. instead of my embeddings/doc
uments. On top of that there is same answer and same URL source repeated about 8times for example.  


Why is that? Is t
here a way around this? I don't get responses like this when using Vicuna or WizardLm for example. From Langchain I am u
sing  AutoTokenizer, AutoModelForCasualLM, HuggingFacePipeline to create LLM.
```
---

     
 
all -  [ Responses cut off from OpenAI (LLMChain) ](https://www.reddit.com/r/LangChain/comments/15wkzgf/responses_cut_off_from_openai_llmchain/) , 2023-08-22-0909
```
I'm trying to generate stories with OpenAI via langchain and the responses seem to be cut off. How can I retrieve the re
st of the response? Assuming I have to either way, or stream it something? Any help would be aprpeciated.

&#x200B;

   
 chatgpt_chain = LLMChain(llm=OpenAI(temperature=0.7),prompt=prompt, verbose=True)
    output = await chatgpt_chain.apre
dict('make up a story')

&#x200B;
```
---

     
 
all -  [ Multimodal Gpt4 notebook example anyone? ](https://www.reddit.com/r/LangChain/comments/15wkhde/multimodal_gpt4_notebook_example_anyone/) , 2023-08-22-0909
```
I was originally curious about any technique for doing RAG Q&A (Retrieval Augmented Generation) but over images or diagr
ams, leveraging multimodal LLMs like GPT4?

Smth like embeddings+vectorDB, but that would works for multimodal/images?


Then I realize I can't find any tutorial on multimodal Gpt4, no Notebook? Something like image to text? 

Any example ou
t there already?
```
---

     
 
all -  [ AI Experts Needed: Dive into ChatGPT, LangChain & More | Earn & Innovate! Are You In? ](https://www.reddit.com/r/LangChain/comments/15widvr/ai_experts_needed_dive_into_chatgpt_langchain/) , 2023-08-22-0909
```
Hey LangChain enthusiasts!

Seeking individuals skilled in ChatGPT, code interpreter, plugins, and especially LangChain.
 Beyond tech skills, if you're patient, adept at simplifying tech concepts, and have a collaborative spirit, we want you
!

This isn't just tech mastery; it's about reshaping the AI user experience. Potential hourly compensation for those wh
o fit the bill.

DM your LinkedIn, GitHub, or other profiles. Let's embark on this AI adventure together!  


EDIT/UPDAT
E:  


Our startup is still under development - it's a marketplace for on demand helpdesk and tutoring in the use of AI 
tools. We will matchmake LLM and other AI tool experts with seekers looking for help, tutoring, mentoring and support.


Our concept is built on pay-per-minute model, and we're looking for early adopters to test our concept.

 
```
---

     
 
all -  [ LangChain output parsers slow? Anyone experience similar? ](https://www.reddit.com/r/LangChain/comments/15whiuc/langchain_output_parsers_slow_anyone_experience/) , 2023-08-22-0909
```
Hi,

&#x200B;

Working on a customer recommendation app where I use chatGPT3.5 and Langchain to recommend a collection o
f products and then format the output with a LangChain output parser to prep the LLM output into JSON format ready for t
he frontend.

&#x200B;

Chain runtime for LLM dialogue and output parsing takes about 20s, if I remove the output parser
 the runtime is decreased by 50%.

&#x200B;

Anyone experience similar, shed some tips or feedback? Thanks very much
```
---

     
 
all -  [ Characters and Tokens Capped when text-splitting ](https://www.reddit.com/r/LangChain/comments/15w49i8/characters_and_tokens_capped_when_textsplitting/) , 2023-08-22-0909
```
Hi All, 

I'm working with a PDF and encountered an issue that I'd like to discuss. The PDF loads up great, and I'm able
 to chunk it without any problems. However, when I try to semantically chunk it using both characters and tokens, I've f
ound that it is roughly capped around 425 tokens. Maybe my eyes are failing me, but this limitation is not mentioned in 
any of the available documents that i have seen. Has anyone else run into this problem? I would greatly appreciate any i
nsights or solutions. 
```
---

     
 
all -  [ Function calling: missing parameters ](https://www.reddit.com/r/LangChain/comments/15vw4ek/function_calling_missing_parameters/) , 2023-08-22-0909
```
We are using a conversational chain in an agent with OpenAI functions as tools. Say I have a function foo with parameter
s a, b, c. The actual function call requires all parameters, but I want the agent to recognize it should call foo, even 
if the userâ€™s query only contained enough information to infer a and b. And the agent should ask for more information, b
ecause it needs to know c, before it can give a result. 

Weâ€™ve tried a few different things, but it seems like itâ€™s har
d to add flexibility without opening the gates to hallucinations. I figured I canâ€™t be the only one trying to achieve th
is. What has worked for you and your team?
```
---

     
 
all -  [ Linking documents: where to look? ](https://www.reddit.com/r/LangChain/comments/15vowe7/linking_documents_where_to_look/) , 2023-08-22-0909
```
I'm in search of advice regarding using LLM to establish relevant links between documents.

I have a few documents I wan
t to link together. To begin, I'd like to select one document from my list as the source document. Then, I'd like the LL
M to identify sections within this source document that could be linked to any of the other documents based on relevance
.

Would you pass everything within the prompt? Should I utilize vector storage and retrieval, with a prompt specifying 
the task? Or should I consider using doc similarity models?

I would greatly appreciate any hints or links to resources.


Thank you!
```
---

     
 
all -  [ RAG vs. Fine-Tuning ](https://www.reddit.com/r/LangChain/comments/15voq6v/rag_vs_finetuning/) , 2023-08-22-0909
```
Hello, 
lately I've been getting into the LLM field and I'm working on a project to create a chatbot that answers questi
ons about regulations. Nowadays, there are various frameworks that greatly facilitate the development of such projects, 
but they all involve the RAG technique.
 After using it for a while, I wondered: why isn't there the same enthusiasm for
 fine-tuning language models? What are the advantages and disadvantages of RAG compared to fine-tuning? 

Thank you.
```
---

     
 
all -  [ Why use LangChain over OpenAI directly? ](https://www.reddit.com/r/OpenAI/comments/15vn9jz/why_use_langchain_over_openai_directly/) , 2023-08-22-0909
```
I was reading langchain documentation and I don't really undestand why use it over the OpenAI API directly. [https://js.
langchain.com/docs/get\_started/introduction/](https://js.langchain.com/docs/get_started/introduction/)

&#x200B;

I see
 they have abstractions to comunicate with the models, but I don't undestand the benefics, it doesn't look like a big ab
straction layer.
```
---

     
 
all -  [ ë‚´ìš© ë¬¼ì–´ë³´ë©´ ëŒ€ë‹µí•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ ì±—ë´‡ ë§Œë“¤ê¸° - LangChain http://aitutor21.com/bbs/board.php?bo_table=aistudy&wr_id=428 ](https://www.reddit.com/r/chatgpt_newtech/comments/15ve68a/ë‚´ìš©_ë¬¼ì–´ë³´ë©´_ëŒ€ë‹µí•˜ëŠ”_ë¬¸ì„œ_ê²€ìƒ‰_ì±—ë´‡_ë§Œë“¤ê¸°_langchain/) , 2023-08-22-0909
```
ë‚´ìš© ë¬¼ì–´ë³´ë©´ ëŒ€ë‹µí•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ ì±—ë´‡ ë§Œë“¤ê¸° - LangChain  [http://aitutor21.com/bbs/board.php?bo\_table=aistudy&wr\_id=428](http://aitutor2
1.com/bbs/board.php?bo_table=aistudy&wr_id=428)
```
---

     
 
all -  [ How to improve similarity search? What vector database to use? ](https://www.reddit.com/r/LangChain/comments/15v9h3a/how_to_improve_similarity_search_what_vector/) , 2023-08-22-0909
```
I have a QA bot made using langchain and openAI for both embeddings and as the LLM. I previously was using faiss as the 
vector store but switched to qdrant as I was having some weird issue on aws lambda with faiss. 
Idk what am I doing wron
g but qdrant similarity search is not at all good. The chunks(k=2)it retrieves are not correct in most cases. How can I 
improve on this? Or tell me if I should use another vector base for this. Thank you.

The data I use is a bunch of txt f
iles.
```
---

     
 
all -  [ Is there a Discord for LangChain? ](https://www.reddit.com/r/LangChain/comments/15v5u1h/is_there_a_discord_for_langchain/) , 2023-08-22-0909
```
Thanks in advance!
```
---

     
 
all -  [ (Help?) Python OpenAI Key Environment Variable ](https://www.reddit.com/r/ChatGPTPro/comments/15uzvr9/help_python_openai_key_environment_variable/) , 2023-08-22-0909
```
Hello, I am trying to build a tool to help me query ChatGPT about the contents of text document via LangChain.  I am wal
king through LangChain's Quickstart guide ( [Quickstart | ðŸ¦œï¸ðŸ”— Langchain](https://python.langchain.com/docs/get_started/q
uickstart.html) ).

Via command prompt, I set the windows environment variable, OPENAI\_API\_KEY to the API key assigned
 to me by ChatGPT (no quotes around the key):

    set OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxx

next I load the pyth
on interpreter in powershell:

    python

next I import the OpenAI class from the llms module within the langchain pack
age, and, the ChatOpenAI class from the chat\_models module (all of this installed already):

    from langchain.llms im
port OpenAI
    from langchain.chat_models import ChatOpenAI

No problems so far. Next I attempt to create an instance o
f OpenAI or ChatOpenAI, and the problems start:

    >>> llm = OpenAI()
    Traceback (most recent call last):
      Fil
e '<stdin>', line 1, in <module>
      File 'C:\Users\xxxx\AppData\Local\Programs\Python\Python311\Lib\site-packages\lan
gchain\load\serializable.py', line 74, in __init__
        super().__init__(**kwargs)
      File 'C:\Users\xxxx\AppData\
Local\Programs\Python\Python311\Lib\site-packages\pydantic\v1\main.py', line 341, in __init__
        raise validation_e
rror
    pydantic.v1.error_wrappers.ValidationError: 1 validation error for OpenAI
    __root__
      Did not find opena
i_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named p
arameter. (type=value_error)

and

    >>> chat_model = ChatOpenAI()
    Traceback (most recent call last):
      File '
<stdin>', line 1, in <module>
      File 'C:\Users\xxxx\AppData\Local\Programs\Python\Python311\Lib\site-packages\langch
ain\load\serializable.py', line 74, in __init__
        super().__init__(**kwargs)
      File 'C:\Users\xxxx\AppData\Loc
al\Programs\Python\Python311\Lib\site-packages\pydantic\v1\main.py', line 341, in __init__
        raise validation_erro
r
    pydantic.v1.error_wrappers.ValidationError: 1 validation error for ChatOpenAI
    __root__
      Did not find open
ai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named 
parameter. (type=value_error)

I then try to pass the OpenAI API Key through as follows:

    >>> llm = OpenAI(api_key='
zzzzzzzzzzzzzzzzzzzzzzz')
    Traceback (most recent call last):
      File '<stdin>', line 1, in <module>
      File 'C
:\Users\xxxx\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\load\serializable.py', line 74, in __in
it__
        super().__init__(**kwargs)
      File 'C:\Users\xxxx\AppData\Local\Programs\Python\Python311\Lib\site-packa
ges\pydantic\v1\main.py', line 341, in __init__
        raise validation_error
    pydantic.v1.error_wrappers.Validation
Error: 1 validation error for OpenAI
    __root__
      Did not find openai_api_key, please add an environment variable 
`OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)

I am stuck, lol.


https://preview.redd.it/59rapvkjyxib1.png?width=888&format=png&auto=webp&s=78511f2bfdf6e251af1e2c9cdc0f9d8ea8f455a5
```
---

     
 
all -  [ Vector database vs Storing data in text files ](https://www.reddit.com/r/ChatGPTCoding/comments/15uw4ci/vector_database_vs_storing_data_in_text_files/) , 2023-08-22-0909
```
I've been prototyping an application using langchain and FAISS that helps me to analyze long documents and then generate
 some narrative text. 

I store the chunked data from the long documents in FAISS. 

I start by asking chat to develop a
n outline, and then I step through the outline sections, requesting chat to generate narrative to fill it in. 

But when
 I have the chat agent actually generate writing, I've found some success in storing those pieces in text files and appe
nding the writing into a prompt to have chat do additional edits and improvements. 

Should I instead be adding the narr
ative pieces into the vector database? Would that improve my performance, or is this a fine way of going about it? I fin
d that when I need to go back to a section from earlier in the convo, I just add it into the prompt as a reminder.
```
---

     
 
all -  [ how to get llama2 embeddings without crying? ](https://www.reddit.com/r/LLaMA2/comments/15uumnc/how_to_get_llama2_embeddings_without_crying/) , 2023-08-22-0909
```
hi lovely community,

\- i simply want to be able to get llama2's vector embeddings as response on passing text as input
 without high-level 3rd party libraries (no langchain etc)

how can i do it?

\- also, considering i'll finetune my llam
a2 locally/cloud gpu on my data, i assume the method suggested by you all will also work for it or what extra steps woul
d be needed? an overview for this works too.

i appreciate any help from y'all. thanks for your time.
```
---

     
 
all -  [ LangChain docs question answering ](https://www.reddit.com/r/LangChain/comments/15ut6ad/langchain_docs_question_answering/) , 2023-08-22-0909
```
Langchain users: we've built this demo using r/vectara \- question-answering about LangChain (based on its docs). 

vide
o: [https://www.youtube.com/watch?v=ACQaSAJxoBs](https://www.youtube.com/watch?v=ACQaSAJxoBs)

demo: [langchain-docs.dem
o.vectara.com](https://langchain-docs.demo.vectara.com) 
```
---

     
 
all -  [ how do i stream a response from langchain conversational retrieval chain ? ](https://www.reddit.com/r/LangChain/comments/15uqgnc/how_do_i_stream_a_response_from_langchain/) , 2023-08-22-0909
```
I am using a fastapi based backend and cant figure out how to stream tokens on the fly on conversational retrieval chain
 
```
---

     
 
all -  [ Embeddable Chat Widget with Streaming Data Support ](https://www.reddit.com/r/LangChain/comments/15upm7e/embeddable_chat_widget_with_streaming_data_support/) , 2023-08-22-0909
```
Friends,

I'm planning to build a streaming API  using fastapi for my langchain based application. For the frontend, Im 
looking for an embeddable chat widget for my web application. The widget can talk to my streaming API endpoint for data.
 I have seen the flowise widget, but I do not want to use flowise for backend as I feel its capabalities are limited at 
this moment. Any opensource suggestions for such a widget  ?

Thanks
```
---

     
 
all -  [ SitemapLoader for big sitemaps ](https://www.reddit.com/r/LangChain/comments/15upk4f/sitemaploader_for_big_sitemaps/) , 2023-08-22-0909
```
Has anyone successfully gotten the SitemapLoader to work with big (10,000+ pages) sitemaps? I need some input since I ju
st run out of RAM.
```
---

     
 
all -  [ ChatGPT con LangChain (function calling) ](https://www.reddit.com/r/devsarg/comments/15upbt1/chatgpt_con_langchain_function_calling/) , 2023-08-22-0909
```
Tengo que hacer un prompt para ver si un texto literatio sigue ciertos parametros (criterios) y para eso estoy usando La
ngChain y ChatGPT (con function calling), soy nuevo usando LangChain y queria saber si hay algun agent o alguna recomend
acion que tengan para hacer esto, se que la PaLM api tiene la data-extraction pero no encontre nada parecido en LangChai
n.

El problema es que hay algunos criterios que al ser los textos largos no funcionan exactamente bien.
```
---

     
 
all -  [ Builing a RAG customer service chatbot ](https://www.reddit.com/r/LocalLLaMA/comments/15umuqj/builing_a_rag_customer_service_chatbot/) , 2023-08-22-0909
```
Hi there!

I have been working on a project to build a customer service chatbot. The bot would interact with clients and
 answer their questions. It will have access to documents to help it answer questions about things like pricing, availab
le services etc.

I have been looking into langchain but I could only find qa agents, not chatbots whose tone and attitu
de can be adjusted by prompting.

Has anyone worked on something similar? Are there any open source projects for somethi
ng similar? 

I would be grateful if someone can offer any tips/help
```
---

     
 
all -  [ Langchain resources for understanding their basics and structures. ](https://www.reddit.com/r/learnmachinelearning/comments/15ulr5e/langchain_resources_for_understanding_their/) , 2023-08-22-0909
```
Basically the title, I need some resources to work with langchain and analyse their performance, please help me with som
e internet resources.
```
---

     
 
all -  [ LangChain Python Cheat Sheet and Tutorial ](https://www.reddit.com/r/Python/comments/15ujh9o/langchain_python_cheat_sheet_and_tutorial/) , 2023-08-22-0909
```
LangChain simplifies building AI assistants with large language models, providing an intuitive API, memory capabilities,
 access to external tools, the ability to chain LLM actions, and prompt templating. Check out our newest cheat sheet to 
get up and running now. 

In the tutorial, we will review a modular interface, prompt management, context management, Ve
ctorStores, chaining multiple models and tools together, AI agents, and access to top LLMs.   


Cheat Sheet: [https://w
ww.kdnuggets.com/2023/08/langchain-cheat-sheet.html](https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html)  
Tut
orial: [https://deepnote.com/@abid/Langchain-Tutorial-aad1f7d6-89c5-4d60-ac0c-7672f697d980](https://deepnote.com/@abid/L
angchain-Tutorial-aad1f7d6-89c5-4d60-ac0c-7672f697d980)
```
---

     
 
MachineLearning -  [ [P] pgml-chat: A command-line tool for deploying low-latency knowledge-based chatbots ](https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/) , 2023-08-22-0909
```
We've created an open source chat bot builder, on top of PostgresML. This tool makes it easy to ingest documents and set
 a system prompt for a chatbot with knowledge of your content. The innovation is in the simplicity and efficiency, rathe
r than the functionality.

PostgresML runs open source embedding models alongside pgvector in Postgres to implement chat
 bot prompt creation without any network calls, which makes it \~4x faster than competing architectures. It can also do 
text generation with that prompt (and no additional network hops) using any open source model from HuggingFace, but it a
lso integrates with the GPT-4 API if you'd like to use that instead. 

The full writeup including some benchmarks for co
mpeting architectures is here:  [https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-kno
wledge-based-chatbots-part-I](https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-knowle
dge-based-chatbots-part-I)

You can chat with a deployment that has access to our blogs and documentation content it in 
\[our Discord\]([https://discord.com/channels/1013868243036930099/1013868243536072868](https://discord.com/channels/1013
868243036930099/1013868243536072868)), where it answers questions addressed to @PgBot.

&#x200B;

* The source code for 
the bot builder and server is only a few hundred lines of Python [https://github.com/postgresml/postgresml/tree/master/p
gml-apps/pgml-chat#readme](https://github.com/postgresml/postgresml/tree/master/pgml-apps/pgml-chat#readme)
* The chat a
pp is so small, because it's delegates all the vector db and embedding generation options to our Python client SDK, whic
h is available for anyone to build other apps with: [https://pypi.org/project/pgml/](https://pypi.org/project/pgml/)
* T
he Python client SDK is so small, because it's just a wrapper around the Rust client SDK: [https://github.com/postgresml
/postgresml/tree/master/pgml-sdks/rust/pgml](https://github.com/postgresml/postgresml/tree/master/pgml-sdks/rust/pgml). 
Currently we also support JS/Typescript SDKs as well, all generated from the same safe and efficient underlying Rust imp
lementation, using some fancy Rust macros.
* The Rust client SDK is also pretty simple though, because it just delegates
 everything to the Postgres database extension, which is where everything is computed in a single GPU accelerated proces
s, without having to load any ML models, data, or dependencies on client apps, effectively eliminating all the typical M
L data<->model network hops. Which makes it faster, simpler and safer.

This lays out what we think a is a better approa
ch to AI application architecture compared to libraries like LangChain or LlamaIndex, that focus on glueing together dis
parate data stores, algorithms, models over the network.  

```
---

     
 
MachineLearning -  [ [P] My apprehension about LangChain and why you donâ€™t need LangChain for building a RAG bot. ](https://www.reddit.com/r/MachineLearning/comments/15ry3z4/p_my_apprehension_about_langchain_and_why_you/) , 2023-08-22-0909
```
A lot of you might be giving me a mouthful just by reading the title of this blog. But to each their own, and probably y
ou might be just riding the hype train. Initially, I was quite fascinated by the work being done on LangChain and using 
it. And so I thought I would give it a try, but when I was installing it, I saw it downloading loads and loads of other 
libraries and most of which were not useful for what I was trying to build.

Checkout the entire blog post at [https://t
hevatsalsaglani.medium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f](https://thevatsalsaglani.med
ium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f)
```
---

     
 
MachineLearning -  [ [D] How we evaluated LLMs in prod ](https://www.reddit.com/r/MachineLearning/comments/15ogknd/d_how_we_evaluated_llms_in_prod/) , 2023-08-22-0909
```
This is going to be a post about the challenges I faced while working with ChatGPT in my previous company and the things
 we did to overcome them over a 2+ month struggle. Check us out at [www.twilix.io](https://www.twilix.io/) if anything b
elow resonates with you and I hope you find some of it helpful.

So to begin, in my previous company we invested a few m
onths building a chatbot to help with user onboarding. At first everything was great, and we saw a 40% decrease in drop-
off rates (which is significant given we were building a consumer facing app), but somehow over time this drop-off rate 
started creeping up again. Perplexed by the unexpected turn in metrics, management started to question the benefits of m
aintaining this chatbot and was skeptical that we were cherry picking examples to showcase its performance for the sake 
of not wasting our efforts. They also knew that GPT4 got shadow nerfed which didn't help our case at all.

We had a lot 
of back and forth and eventually came to the conclusion that somehow the chatbot performance have to be quantified to ju
stify it's purpose. So, our team spent another 2 months engineering an evaluation solution to show leadership that the c
hatbot is performing as expected while identifying areas of improvement to craft a more refined product roadmap. We ende
d up trying a lot of different things, and after a long process of iteration and experimentation here are the things tha
t worked for us:

1. Generating synthetic datasets (these act as 'ground truths' pair of queries and expected responses)
 to benchmark performance.
2. Training models to determine the similarity score to assess every ChatGPT output in produc
tion (we use the generated synthetic dataset to do this to compare expected responses vs real responses)
3. Classifying 
the type of use cases the chatbot was used for (this allowed us to see which use cases were performing worse)
4. Logging
 configurations in our LLM stack and building visualizations on the web to identify what gives the best results (tempera
ture, LangChain configurations, lLamaIndex chunking sizes, these type of configurations)
5. Monitoring how our costs and
 latency are affected by tweaking different parameters
6. Lastly, A/B test to figure out the optimal parameters on diffe
rent sets of users (from experience, typically for a user onboarding chatbot use case around 5,000 users interacting wit
h your chatbot should be enough to collect some meaningful datapoints)

The most important learnings that we took away w
as that whilst synthetic data is OK you do need to generate large amounts of it. The sweet spot is different depending o
n the use case + the specifics of your knowledge base (eg, a corpus of internal documents vs a collection of websites), 
and I say sweet spot because after a certain amount of datapoints everything else kind of becomes noise and actually neg
atively affects your analysis more than the benefit it brings.

We ended up showing where our chatbot onboarding experie
nce fell short and was able to fix it through rapid iteration. There's still no set standard for LLM evaluation but I ho
pe my previous experiences helped. (Our team is now building out this evaluation system as a standalone product at [www.
twilix.io](https://www.twilix.io/) so check us out if you also want some concrete proof that ChatGPT is performing as ex
pected for your business)
```
---

     
 
MachineLearning -  [ [D] Approach to creating an 'AI tutor' chatbot for a fantasy language? ](https://www.reddit.com/r/MachineLearning/comments/15o4jy9/d_approach_to_creating_an_ai_tutor_chatbot_for_a/) , 2023-08-22-0909
```
What are the possible practical approaches to creating an 'AI tutor' for a custom fantasy language, i.e. a language whic
h is definitely not covered in any large, mainstream LLM?

Assume in the fantasy language (like Game of Throne's Dothrak
i, but completely custom, so it's guaranteed not to be covered at all by an existing LLM), we have a dictionary of terms
, and a simple description of a grammar. What can I do with that?

Initially I was thinking of using 'Retrieval-Augmente
d Generation' (RAG), where I would pass it my dictionary of terms and their definitions and the grammar doc (i.e. the so
urce documents), and using OpenAI's LLM and LangChain's API wrapper and Pinecone long-term memory vector database, store
 the dictionary/grammar in Pinecone's vector database. Then a query comes in to translate an English word to a fantasy w
ord, and it looks in the Pinecone DB for similar English words, then passes the results with the fantasy word to the LLM
, along with the query, and generates a nice English response, with the fantasy word somewhere in there.

But that doesn
't seem like it would work the more I think about it. Then if I want to add the ability for it to translate English to t
he fantasy language, that seems impossible without first having a huge corpus of translation material (which is complete
ly impractical for a fantasy language). So can an existing generic LLM take a grammar as input, and learn to speak a fan
tasy language? If so, how would you make that happen?

Or what are other approaches to accomplishing this sort of thing?

```
---

     
 
MachineLearning -  [ LLMs Challenges and Approaches Panel [N] ](https://www.reddit.com/r/MachineLearning/comments/15noqwr/llms_challenges_and_approaches_panel_n/) , 2023-08-22-0909
```
&#x200B;

https://preview.redd.it/wl1gtcngnchb1.jpg?width=1500&format=pjpg&auto=webp&s=24e35d852603c6139fd67f79457ec593f
bad99f7

If you're someone who's curious about or working with LLMs there's a cool panel discussion coming up: 

* Compa
ring the pros and cons of using existing LLMs, prompt engineering, and fine-tuning on custom datasets for different ente
rprise use cases.
* Fine-Tuning LLMs: Exploring the advantages and challenges of fine-tuning LLMs on custom datasets to 
align with specific business objectives.
* Tools and platforms: Discussing the various tools and platforms to facilitate
 LLM implementation 
* Overcoming Challenges: Addressing the challenges associated with adopting LLMs, including data pr
ivacy, creating high quality datasets, computational resources, ethical considerations, and the need for specialized exp
ertise.
* Future Directions: Exploring emerging trends, advancements, and potential future applications of LLMs in the e
nterprise context.

Here's the event info: [https://www.eventbrite.com/e/large-language-models-for-enterprise-success-ch
allenges-and-approaches-tickets-695089811337?aff=oddtdtcreator](https://www.eventbrite.com/e/large-language-models-for-e
nterprise-success-challenges-and-approaches-tickets-695089811337?aff=oddtdtcreator)
```
---

     
 
MachineLearning -  [ [D] training a model for function calls ](https://www.reddit.com/r/MachineLearning/comments/15n1j52/d_training_a_model_for_function_calls/) , 2023-08-22-0909
```
would it be possible to train or fine-tune a small (1-3B) model who's sole purpose is to perform function calls? similar
 to how we have tiny models like replit-v2-3B that are super capable at specific things like code auto-complete .  


i 
know that's how openAI implemented function call was by fine-tuning gpt-3.5/4 but I'm thinking just a straight up base m
odel trained to understand and excel at function calls (similar to Gorilla for apis)

i'm thinking it would be a perfect
 'glue' for bigger LLM apps-- avoiding the need for external tools like langchain/quidance/etc...
```
---

     
 
MachineLearning -  [ [D]Embedding model and vector store on LangChain ](https://www.reddit.com/r/MachineLearning/comments/15lllm0/dembedding_model_and_vector_store_on_langchain/) , 2023-08-22-0909
```
For Langchain users, what are the best text embedding models and vector stores (with similarity search) among the many i
ntegrations for connecting a AI model to text data? 

And does performance vary drastically from one model/database to a
nother? 
```
---

     
 
MachineLearning -  [ [P] Rust meets Llama2: OpenAI compatible API written in Rust ](https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/) , 2023-08-22-0909
```
Hello,

I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports
 offloading computation to  Nvidia GPU and Metal acceleration for GGML models !

Here is the project  link: [Cria- Local
 LLAMA2 API](https://github.com/AmineDiro/cria)

You can use it as an OpenAI replacement (check out the included \`Langc
hain\` example in the project).

This is an ongoing project, I have implemented the \`embeddings\` and \`completions\` r
outes. The \`chat-completion\` route will be here very soon!

Really interested in your feedback and I would welcome any
 help :) !

&#x200B;

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Document-based QnA without OpenAI? ](https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/) , 2023-08-22-0909
```
I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to ma
ke it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain
 only supports GPT but any other ideas are highly appreciated!
```
---

     
 
MachineLearning -  [ [D] Roadmap for AI engineer (implementation of language models on premise) ](https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/) , 2023-08-22-0909
```
 I worked for less than a year as a Data Engineer. I decided to look for other challenges and got a job as an AI enginee
r developing language models.

The product of the company that hired me is related to data and metadata management. My t
asks will be to introduce features to the product, including a chat function that will allow for asking questions about 
data. Other tasks will include research and proposing additional AI-related functionalities to the product (on premise).
 I have a two weeks left to start work and I need to prepare a bit. My job will involve implementing ready-made solution
s and conducting research (high level - I need to implement valuable features and no one cares how).

**What are the mos
t important things I should learn before starting work?**

First of all, I replicated a few applications from this blog:
 [https://blog.streamlit.io/tag/llms/](https://blog.streamlit.io/tag/llms/)

Then I have focused on Langchain. I'm also 
in the middle of a course on Udemy about Next-Gen AI projects - Beginner friendly - Langchain, Pinecone - OpenAI, Huggin
gFace & LLAMA 2 models

I need a roadmap that will guide me a bit. I'm looking for blogs/materials/courses that will giv
e me practical knowledge in this matter.
```
---

     
 
MachineLearning -  [ [D] Having trouble with RAG on company domain data ](https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/) , 2023-08-22-0909
```
I have a data set that isn't that large \~200 pdfs. I have done the regular RAG approach with Langchain, extracting text
, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity sear
ch with a question I would like answered it returns the wrong context. The documents are semi-structured information of 
examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input th
is question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not e
xplicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chun
ks, but this does nothing.

Does anyone have any tips on improving the embeddings retrieval in this case?
```
---

     
 
MachineLearning -  [ [D] How do I reduce LLM inferencing time? ](https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/) , 2023-08-22-0909
```
I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface l
ibrary, and I am running the model on AWS ml.g4dn.12xlarge which has 4x**nvidia t4**, which gives a total 64GB of GPU me
mory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins
 for big queries.

The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in 
a conversational way. I've extracted the main parts of the notebook and put it up [here](https://colab.research.google.c
om/drive/1uFNkZ6FI0qffwRpW6ubfdq0HrCqcqVUi?usp=sharing).

Where can I make changes to speed up the transaction. Is there
 any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give a
n answer in less than 5 seconds. Are there any other areas I can optimise?

I appreciate any help you can provide. Thank
s!
```
---

     
 
deeplearning -  [ Using PDFs with GPT Models ](https://www.reddit.com/r/deeplearning/comments/15g6i4x/using_pdfs_with_gpt_models/) , 2023-08-22-0909
```
Found a blog talking about how we can interact with PDFs in Python by using GPT API & Langchain. It talks about some pre
tty cool automations you can build involving PDFs - [https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-g
pt-api/](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/)
```
---

     
