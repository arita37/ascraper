 
all -  [ What is the best way to search for dates? ](https://www.reddit.com/r/Rag/comments/1ffgghk/what_is_the_best_way_to_search_for_dates/) , 2024-09-13-0912
```
I was trying to use LangChain's SelfQueryRetriever with AttributeInfo but was unsuccessful.
```
---

     
 
all -  [ Creating Self-Coding Agents ](https://www.reddit.com/r/LangChain/comments/1ffgcui/creating_selfcoding_agents/) , 2024-09-13-0912
```
Has anyone developed a system where agents can autonomously code entire agent-based systems? I‚Äôm currently facing a chal
lenge with streaming complex workflows to a chat UI efficiently. I‚Äôve experimented with Mesop, Vercel, and Flask for cha
t tracking, but managing streams for multiple agents has proven tricky. I‚Äôm considering diving deeper into Streamlit to 
better handle chat bot integration. 

Any insights or suggestions would be greatly appreciated!


```
---

     
 
all -  [ We built a unified customer data RAG for LangChain based on entity resolution technology ](/r/LangChain/comments/1fedc3v/we_built_a_unified_customer_data_rag_for/) , 2024-09-13-0912
```

```
---

     
 
all -  [ Best place to find and hire an Agentic RAG expert? ](https://www.reddit.com/r/LangChain/comments/1ffehl5/best_place_to_find_and_hire_an_agentic_rag_expert/) , 2024-09-13-0912
```
Aussie startup here - about to close a couple million dollar round. We have huge enterprise clients begging for our prod
uct. 

Looking to bring on someone highly experienced in all things Agentic RAG full time. Can pay competitive salary fo
r next 2 years. 

Can be remote, but prefer someone in Australia due to R&D tax benefits. 

Where is the best place to l
ook for this person? Reddit? Upwork? LinkedIn? 




```
---

     
 
all -  [ What's the difference between Tool Calling, Structured Chat, and ReACT Agents? ](https://www.reddit.com/r/LangChain/comments/1ffe38x/whats_the_difference_between_tool_calling/) , 2024-09-13-0912
```
I've been trying to read the [documentation](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/) on thes
e three types of agents -- and I still don't get exactly what the difference is.  Implementation looks very similar.  Th
ey can all call tools.  The prompts given in the quick start guides are a little different. What's actually the differen
ce?
```
---

     
 
all -  [ RAG System based on technical manual for cms usage ](https://www.reddit.com/r/LangChain/comments/1ffd8xu/rag_system_based_on_technical_manual_for_cms_usage/) , 2024-09-13-0912
```
I'm trying to create a RAG system for technical manuals for cms usage, the main problem here is on the reading of the pd
f file and the chuking of it. I'm having difficulties in finding a good way to read the pdf (one document object for eac
h page of the pdf or one documet object for the entire pdf?) and than another problem is the chunking of it. I've tried 
many strategies without getting good results. A big problem that I'm facing is about components of the cms that have pro
perties that are listed in tables that begin in one page and continue in the next page, in this cases the properties tha
t the retriever and the llm is giving as response are always incomplete because it's basically taking the first part of 
the table and missing the continuing in the next page. The document is organized in chapters for each component of the c
ms and there are around 200 of them. Is there a way to chunk the document and have a one-to-one relation between compone
nt and chunk to force the retriever to find the entire list of properties? I've tried RecursiveCharacterTextSplitter and
 SemanticChunker but they didn't give me good enough results. 
```
---

     
 
all -  [ Safely call LLM APIs without a backend
 ](https://www.reddit.com/r/LangChain/comments/1ffcne3/safely_call_llm_apis_without_a_backend/) , 2024-09-13-0912
```
I got tired of having to spin up a backend to use OpenAI or Anthropic API and figure out usage and error analytics per u
ser in my apps so I created Backmesh, the Firebase for AI Apps. It lets you safely call any LLM API from your app withou
t a backend with analytics and rate limits per user.

[https://backmesh.com](https://backmesh.com/)
```
---

     
 
all -  [ LangGraph Cloud ](https://www.reddit.com/r/LangChain/comments/1ffbhuw/langgraph_cloud/) , 2024-09-13-0912
```
Is anyone using langgraph cloud in production? If yes how is it better than hosting it yourself? Working on something th
at requires me to choose, weighing my options 
```
---

     
 
all -  [ Search for date in RAG ](https://www.reddit.com/r/LLMDevs/comments/1ffbflx/search_for_date_in_rag/) , 2024-09-13-0912
```
What is the best way to search for dates? I was trying to use LangChain's SelfQueryRetriever with AttributeInfo but was 
unsuccessful.
```
---

     
 
all -  [ Applied to 90+ SWE internships (summer 2025, spring 2025), no interviews :( Not sure what I'm doing  ](https://www.reddit.com/r/Resume/comments/1ff6b15/applied_to_90_swe_internships_summer_2025_spring/) , 2024-09-13-0912
```
https://preview.redd.it/2pndr3yvjeod1.png?width=1076&format=png&auto=webp&s=ccc562e76b07ccc28793239774f347a024e11add
```
---

     
 
all -  [ Scaling LLM Data Extraction: Challenges, Design decisions, and Solutions ](https://www.reddit.com/r/LangChain/comments/1ff3jvn/scaling_llm_data_extraction_challenges_design/) , 2024-09-13-0912
```
[Graphiti](https://github.com/getzep/graphiti) is a Python library for building and querying dynamic, [temporally aware 
knowledge graphs](https://github.com/getzep/graphiti). It can be used to model complex, evolving datasets and ensure AI 
agents have access to the data they need to accomplish non-trivial tasks. It's a powerful tool that can serve as the dat
abase and retrieval layer for many sophisticated RAG projects.

**Graphiti was challenging to build.** This article disc
usses our design decisions, prompt engineering evolution, and approaches to scaling LLM-based information extraction. Th
is blog post kicks off a series exploring our challenges while building Graphiti. Reading this will deepen your understa
nding of both the Graphiti library and provide valuable insights for future development.

[Read the full article](https:
//blog.getzep.com/llm-rag-knowledge-graphs-faster-and-more-dynamic/).

>Using LangGraph? See our example notebook: [Buil
ding a ShoeBot Sales Agent using LangGraph and Graphit](https://github.com/getzep/graphiti/blob/main/examples/langgraph-
agent/agent.ipynb)

https://preview.redd.it/wzvm9t7k0eod1.png?width=2400&format=png&auto=webp&s=f34685d234df543bde52eed1
679a8fe85aa2f86e


```
---

     
 
all -  [ Semantix : Create Super functions with the help of LLMs ](https://github.com/chandralegend/semantix) , 2024-09-13-0912
```
### What Semantix Does

Current methods for extracting structured outputs from LLMs often rely on libraries such as DSPy
, OpenAI Structured Outputs, and Langchain JSON Schema. These libraries typically use Pydantic Models to create JSON sch
emas representing classes, enums, and types. However, this approach can be costly since many LLMs treat each element of 
the JSON schema (e.g., `{}`, `:`, `'$'`) as separate tokens, leading to increased costs due to the numerous tokens prese
nt in JSON schemas.

Semantix offers a different and more cost-effective solution. Instead of using JSON schemas, Semant
ix represents classes, enums, and objects in a more textual manner, reducing the number of tokens and lowering inference
 costs. Additionally, Semantix leverages Python's built-in typing system with minor modifications to provide meaning to 
parameters, function signatures, classes, enums, and functions. This approach eliminates the need for unnecessary Pydant
ic models and various classes for different prompting methods. Semantix also makes it easy for developers to create GenA
I-powered functions.

### Target Audience

Semantix is designed for developers who have worked with libraries like Langc
hain and DSPy and are tired of dealing with Pydantic models and JSON schemas. It is also ideal for those who want to add
 AI features to existing or new applications without learning extensive new libraries.

### Comparison

Semantix support
s multimodal inputs, allowing you to use images and videos effortlessly. Unlike other libraries, Semantix requires minim
al code changes to achieve excellent results.

Ready to give it a try? Check out our Colab notebook [here](https://colab
.research.google.com/github/chandralegend/semantix/blob/main/try.ipynb) and explore our GitHub repository [here](https:/
/github.com/chandralegend/semantix) for more details.
```
---

     
 
all -  [ We built a customer data RAG for LangChain based on entity resolution technology ](https://www.reddit.com/r/u_Tilores/comments/1ff08x7/we_built_a_customer_data_rag_for_langchain_based/) , 2024-09-13-0912
```
I'm Steven, one of the co-founders of [Tilores](https://tilores.io/), where we focus on real-time entity resolution to u
nify customer data. Recently, we've had some interesting conversations around how our solution could be used with LLMs, 
so we built an integration for LangChain.

With this integration, Tilores can serve as a retrieval-augmented generation 
(RAG) source for customer data. It allows you to unify data from various sources, update profiles in real-time, and perf
orm fuzzy searches across unified customer graphs‚Äîall within your LLM workflows.

We're looking for early users to help 
test and explore some use cases. If you're working with customer data and want to integrate it into your LangChain proje
cts, we'd love to talk.

The setup is quick, with no maintenance, and it scales with your data.

You can see our LangCha
in integration here:¬†[https://github.com/tilotech/langchain-tilores](https://github.com/tilotech/langchain-tilores)

We 
also have an upcoming Product Hunt launch: [https://www.producthunt.com/products/tilores-rag](https://www.producthunt.co
m/products/tilores-rag)

I'd love to hear your thoughts.
```
---

     
 
all -  [ I want to get the sources of the retrieved context ](https://www.reddit.com/r/LangChain/comments/1fezyfk/i_want_to_get_the_sources_of_the_retrieved_context/) , 2024-09-13-0912
```
Hello,

I am developing a RAG based app. I want to get the sources of the retrieved context too along with the response.


    template = '''Please provide a thorough and precise response to the following question, ensuring that your 
    ¬† 
¬† ¬† ¬† ¬† ¬† answer is exclusively grounded in the context provided. If the necessary information to formulate 
    ¬† ¬† ¬† ¬†
 ¬† ¬† a complete answer is absent from the context, kindly respond with 'I am sorry, I don't know' 
    ¬† ¬† ¬† ¬† ¬† ¬† or 'T
he document does not contain this information.'
    
    ¬† ¬† ¬† ¬† ¬† ¬† Your response should be well-structured, presented 
in a step-by-step format for maximum clarity, 
    ¬† ¬† ¬† ¬† ¬† ¬† and should include detailed explanations where appropriat
e. Feel free to incorporate relevant examples 
    ¬† ¬† ¬† ¬† ¬† ¬† to illustrate your points effectively.
    
    ¬† ¬† ¬† ¬† ¬†
 ¬† Context: {context}
    ¬† ¬† ¬† ¬† ¬† ¬† Question: {question}
    '''
    
    llm = Ollama(model='gemma2:2b')
    

    de
f generate_answer(retriever, query):
    ¬† ¬† prompt = ChatPromptTemplate.from_template(template)
    ¬† ¬† chain = (
    ¬†
 ¬† ¬† ¬† {'context':retriever, 'question':RunnablePassthrough()}
    ¬† ¬† ¬† ¬† |prompt
    ¬† ¬† ¬† ¬† |llm
    ¬† ¬† ¬† ¬† |StrOutp
utParser()
    ¬† ¬† )
    
    ¬† ¬† return chain.stream({'input': query})
    



I am using FIASS vector db.

  
Thanks i
n advance :)
```
---

     
 
all -  [ Agentic RAG Using CrewAI & LangChain! ](https://www.reddit.com/r/Rag/comments/1fexoqs/agentic_rag_using_crewai_langchain/) , 2024-09-13-0912
```
While studying to understand the buzz about agentic RAG, I was happened to look at CrewAI as one of the platforms to bui
ld AI agents. That is when my interest to build a simple agentic RAG started and [wrote this step-by-step tutorial](http
s://levelup.gitconnected.com/agentic-rag-using-crewai-langchain-bf935d26bc21) on building agentic RAG using CrewAI and L
angChain.

Hope you like it and share your views. 
```
---

     
 
all -  [ ÏöîÏ¶ò Í∞ÄÏû• Îú®Í±∞Ïö¥ #CrewAI #Autogen #Langgraph Î•º ÌôúÏö©Ìïú Agentic RAG Ïóê ÎåÄÌï¥ÏÑú Î∞∞ÏõåÎ≥¥Í≤†ÏäµÎãàÎã§!, LangChain Quick Start - RAG  ](https://www.reddit.com/r/chatgpt_newtech/comments/1fevc2u/ÏöîÏ¶ò_Í∞ÄÏû•_Îú®Í±∞Ïö¥_crewai_autogen_langgraph_Î•º_ÌôúÏö©Ìïú_agentic/) , 2024-09-13-0912
```
ÏöîÏ¶ò Í∞ÄÏû• Îú®Í±∞Ïö¥ #CrewAI #Autogen #Langgraph Î•º ÌôúÏö©Ìïú Agentic RAG Ïóê ÎåÄÌï¥ÏÑú Î∞∞ÏõåÎ≥¥Í≤†ÏäµÎãàÎã§!, LangChain Quick Start - RAG ÏßÅÏ†ë ÏΩîÎî©ÌïòÎ©¥ ÌôïÏã§ÌïòÍ≤å Î∞∞ÏõÅÎãàÎã§. Ï†ú
 ÏÜåÏä§ÏΩîÎìú Í∞ÄÏ†∏Í∞ÄÏÖîÏÑú ÎßòÍªè ÌôúÏö©ÌïòÏÑ∏Ïöî., [https://aitutor21.com/aistudy/1146](https://aitutor21.com/aistudy/1146)
```
---

     
 
all -  [ RAGAS + Langsmith for RAG chatbot ](https://www.reddit.com/r/Rag/comments/1fer045/ragas_langsmith_for_rag_chatbot/) , 2024-09-13-0912
```
Hey guys, I have an RAG chatbot that was built on chainlit, langchain (version 2). And now, I need to evaluate my llm re
sponses. I'm super new to this and don't know how to approach it. I am going through RAGAS documentation and understood 
that they provide metrics and langsmith has a good UI to visualize the metrics. So How can I implement it? If my chatbot
 is in production, how can I automate this evaluation? And if you have already implemented such thing, please please hel
p me out. Thanks !
```
---

     
 
all -  [ Help on a rag application ](https://www.reddit.com/r/LangChain/comments/1felvjc/help_on_a_rag_application/) , 2024-09-13-0912
```
So my team and I are working on building a gpt wrapper app and I want to build a rag system by indexing some notes I too
k on ‚ÄúAtomic Habits‚Äù book. Obviously it doesn‚Äôt make sense to index a whole book so I‚Äôm using my notes, or I don‚Äôt even 
know how expensive it will be to index the whole thing. I have experience with building small rag applications. My quest
ion is that I‚Äôm not experienced and I am looking for opinions on how I can outline this idea and execute it. if anyone h
as any tips regarding using langchain. Thanks
```
---

     
 
all -  [ AWS Reference Architecture for txtai RAG ](https://www.reddit.com/r/aws/comments/1feevhx/aws_reference_architecture_for_txtai_rag/) , 2024-09-13-0912
```
https://preview.redd.it/4e3mygwbl7od1.png?width=1746&format=png&auto=webp&s=650f35fd4139e5ba89f1b21726c60af025181108

[t
xtai](https://github.com/neuml/txtai) is an all-in-one open-source embeddings database for semantic search, LLM orchestr
ation and language model workflows.

txtai has support for both local and API-driven embeddings services and models. Thi
s reference architecture uses AWS Bedrock for embeddings + LLM calls. Content is stored in Postgres/pgvector via Aurora 
or RDS.  
  
Other frameworks like LangChain and LlamaIndex require code changes to switch from local to cloud. The same
 code can handle both with minor configuration changes in txtai!

https://preview.redd.it/lsd9bu4il7od1.png?width=886&fo
rmat=png&auto=webp&s=e28584c49ac346a951ac16bdd469cb15ff062cc5

Code: [https://gist.github.com/davidmezzetti/e5907591e941
1f47da7f9a9e91ec9d84](https://gist.github.com/davidmezzetti/e5907591e9411f47da7f9a9e91ec9d84)
```
---

     
 
all -  [ Reliable Agentic RAG with LLM Trustworthiness Estimates ](https://www.reddit.com/r/LangChain/comments/1fee66b/reliable_agentic_rag_with_llm_trustworthiness/) , 2024-09-13-0912
```
I've been working on Agentic RAG workflows and I found that automating decisions on LLM outputs can be pretty shaky. A*g
entic RAG*¬†considers various retrieval strategies as tools available to an LLM orchestrator that can *iteratively decide
* which tools to call next based on what it‚Äôs seen thus far. The tricky part is how do we actually *decide* automaticall
y? 

[Using a trustworthiness score, the RAG Agent can choose more complex retrieval plans or approve the response for p
roduction.](https://preview.redd.it/ie2jqm9xf7od1.png?width=1560&format=png&auto=webp&s=658d5e3ee7391b7c2a1700251b892373
69b25750)

I found some success using uncertainty estimators to verify the trustworthiness of the RAG answer. If the ans
wer was not trustworthy enough, I increase the complexity of the retrieval plan in efforts to get better context. I [wro
te up](https://pub.towardsai.net/reliable-agentic-rag-with-llm-trustworthiness-estimates-c488fb1bd116) some of my findin
gs, if you're interested :)

Has anybody else tried building RAG agents? Have you had success decisioning with noisy LLM
 outputs?


```
---

     
 
all -  [ [1 YoE] Entry Level Engineer looking for roles in Traditional ML and Generative AI ](https://www.reddit.com/r/EngineeringResumes/comments/1fee3u4/1_yoe_entry_level_engineer_looking_for_roles_in/) , 2024-09-13-0912
```
Hi any review of my CV would be helpful thank you. I'm aware of some possible problems that may be present already:

* G
ap between education and previous employment. This is because of massive burnout after finishing degree most likely rela
ted to very recently diagnosed ADHD.
* It looks like there is a lack of traditional ML in my skillset however outside of
 my tutoring I haven't been working on any projects since I finished my education.
* Second role is essentially a contin
uation of the first role working directly with the client - i'm worried the short length of the role will put hiring man
agers off.

I'm looking for roles in London or remotely.

To be honest I'm not sure where to start with my CV, I imagine
 I will need to undertake a couple of projects to showcase more of my skills and help to improve my coverage.  I don't r
eally know if I am making the most of what experience I do have so any help would be appreciated.

https://preview.redd.
it/80g7l2m5g7od1.png?width=5100&format=png&auto=webp&s=b433c0a6f22e6656047cd8eacccc36cd9c5f70a4
```
---

     
 
all -  [ We built a unified customer data RAG for LangChain based on entity resolution technology ](https://www.reddit.com/r/LangChain/comments/1fedc3v/we_built_a_unified_customer_data_rag_for/) , 2024-09-13-0912
```
Hi LangChain community,

I'm Steven, one of the co-founders of Tilores, where we focus on real-time entity resolution to
 unify customer data. Recently, we've had some interesting conversations around how our solution could be used with LLMs
, so we built an integration for LangChain.

With this integration, Tilores can serve as a retrieval-augmented generatio
n (RAG) source for customer data. It allows you to unify data from various sources, update profiles in real-time, and pe
rform fuzzy searches across unified customer graphs‚Äîall within your LLM workflows.

We're looking for early users to hel
p test and explore some use cases. If you're working with customer data and want to integrate it into your LangChain pro
jects, we'd love to talk.

The setup is quick, with no maintenance, and it scales with your data.

You can see our LangC
hain integration here: [https://github.com/tilotech/langchain-tilores](https://github.com/tilotech/langchain-tilores)

I
'd love to hear your thoughts. 


```
---

     
 
all -  [ Langchain agents fun project idea ](https://www.reddit.com/r/LangChain/comments/1fed189/langchain_agents_fun_project_idea/) , 2024-09-13-0912
```
I need to prepare a fun project with Agents for a team meeting. Can you share with me ideas to showcase how powerful it 
is.
The more fun the better ! 

Thanks ! 
```
---

     
 
all -  [ How can I improve my Github Query Parameter Generator tool ? ](https://www.reddit.com/r/LangChain/comments/1fe8zgz/how_can_i_improve_my_github_query_parameter/) , 2024-09-13-0912
```
Hello everyone , I'm currently learning Langgraph and trying to create a Github Agent which takes in a natural language 
query like 'Frontend developer based in India skilled in NextJS' and generates query parameters that will be used to sea
rch using Github User Search API .

Langchain does not have any tool for this use case , so I'm trying to develop my own
 .

For the project I'm developing , I'm following hierarchical agent architecture .

You can see my 2 tools below i.e.q
uery\_param\_generator tool and fetch\_users tool and their respective agent nodes i.e. query\_param\_generator\_node an
d fetch\_users\_node :

    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTempl
ate
    from langchain_openai import ChatOpenAI
    import requests
    import functools
    from langgraph.prebuilt imp
ort create_react_agent
    
    
    u/tool('query_param_generator')
    def query_param_generator(query:str):
    ¬† ¬† '
''
    ¬† ¬† Takes a natural language query as input and returns the appropriate query parameters based on the rules defin
ed in system_message
    ¬† ¬† '''
    
    ¬† ¬† query_gen_system = '''
    ¬† ¬† Strictly follow all the rules below to gene
rate query parameters for GitHub User Search . Ensure all rules are followed to generate accurate search queries.
    ¬† 
¬† Only return the query , no extra information .
    ¬† ¬† # GitHub User Search - Query Parameter Generation Rules
    
  
  ¬† ¬† The following guidelines define how to construct query parameters for the GitHub User Search. Ensure all rules are
 followed to generate accurate search queries.
    
    ¬† ¬† # Overview
    
    ¬† ¬† 1. Search Scope: Applies to public p
ersonal GitHub accounts (not organizations).
    ¬† ¬† 2. Query Components: Queries can include:
    ¬† ¬† 3. Keywords: For 
general information like usernames, names, emails, and bios.
    ¬† ¬† 4. Qualifiers: For searching specific fields.
    ¬†
 ¬† 5. Sort Parameters: Optional but can be added for ordering results.
    ¬† ¬† 6. Case Sensitivity: Keywords are case-in
sensitive.
    ¬† ¬† 7. Result Limit: The search returns the first 1000 results, sorted by best match (by default).
    
 
   ¬† ¬† # Qualifiers & Usage
    
    ¬† ¬† Each qualifier targets a specific field in the GitHub user data. These cannot b
e mixed with regular keywords.
    
    ¬† ¬† user:NAME: Matches exact usernames.
    ¬† ¬† Example: user:braingain
    
   
 ¬† ¬† in:login: Searches within usernames (non-exact matches allowed).
    ¬† ¬† Example: braingain in:login
    
    ¬† ¬† i
n:email: Searches within users' email addresses.
    ¬† ¬† Example: irina in:email
    
    ¬† ¬† in:name: Searches within u
sers' full names.
    ¬† ¬† Example: Irina in:name
    
    ¬† ¬† fullname:NAME: Similar to in:name, searches users' full na
mes.
    ¬† ¬† Example: fullname:john smith
    
    ¬† ¬† location:NAME: Searches users based on location.
    ¬† ¬† Example:
 location:Boston
    
    ¬† ¬† language:NAME: Finds users based on the primary language of their public repositories.
   
 ¬† ¬† Example: language:python
    
    ¬† ¬† repos:n: Searches users by the number of public repositories.
    ¬† ¬† Example
: repos:>1000
    
    ¬† ¬† followers:n: Searches users by the number of followers.
    ¬† ¬† Example: followers:>1000
    

    ¬† ¬† created:DATE: Finds users by their GitHub account creation date.
    ¬† ¬† Example: created:>2020-01-01
    
    
¬† ¬† is:sponsorable: Finds users with a GitHub Sponsors profile.
    ¬† ¬† Example: is:sponsorable
    
    ¬† ¬† sort:: Sort
s users based on specific attributes.
    ¬† ¬† Example: repos:>10000 sort:followers
    
    ¬† ¬† # Boolean Operators
    
¬† ¬† You can combine keywords and qualifiers using Boolean operators to refine the search. Follow these rules:
    
    ¬†
 ¬† AND (implied): Combining two different qualifiers or a qualifier and a keyword automatically implies AND.
    ¬† ¬† Exa
mple: location:'San Francisco' language:python (Finds users in San Francisco who primarily use Python).
    
    ¬† ¬† OR:
 Explicitly use OR between keywords or in: qualifiers only. For other qualifiers, using the same qualifier twice implies
 OR.
    ¬† ¬† Example: 'front-end developer' OR 'ui developer'
    ¬† ¬† Example: location:'new jersey' location:'new york'
 (Finds users in either New Jersey or New York).
    
    ¬† ¬† NOT (-): Use the minus sign (-) to exclude certain terms o
r qualifiers.
    ¬† ¬† Example: location:iceland -location:Reykjavik (Finds users in Iceland but not Reykjavik).
    
   
 ¬† ¬† # Key Limitations & Constraints
    
    ¬† ¬† Character Limit: Queries must not exceed 256 characters.
    
    ¬† ¬† 
No Parentheses: Do not use parentheses in queries.
    
    ¬† ¬† AND/OR/NOT Limits: You cannot use more than five AND, OR
, or NOT operators in a single query.
    ¬† ¬† For example: location:'silicon valley' -language:java -language:c++ -langu
age:python -language:javascript -language:html is valid (5 negations).
    ¬† ¬† Special Notes on Combining Operators
    

    ¬† ¬† AND is implied for combining qualifiers and keywords but cannot be used explicitly with certain fields like loc
ation, language, etc.
    
    ¬† ¬† OR cannot be used explicitly between different qualifiers.
    ¬† ¬† Example: fullname:
irina user:braingain is interpreted as AND, while fullname:irina OR user:braingain is invalid.
    
    ¬† ¬† You cannot c
ombine keywords and qualifiers in OR statements.
    ¬† ¬† Example: language:java OR 'java developer' is invalid, while la
nguage:java 'java developer' is interpreted as AND.
    ¬† ¬† '''
    ¬† ¬† query_gen_prompt = ChatPromptTemplate.from_messa
ges(
    ¬† ¬† ¬† ¬† [('system', query_gen_system),('user','{input}')]
    ¬† ¬† )
    ¬† ¬† query_gen = query_gen_prompt | Chat
OpenAI(model='gpt-4o-mini', temperature=0)
    ¬† ¬† res = query_gen.invoke(input=query)
    ¬† ¬† return res.content
    
 
   
    @tool('fetch_users')
    def fetch_users(query_param:str):
    ¬† ¬† '''Gets a list of Github users based on a que
ry parameters generated by query_param_generator tool.'''
    ¬† ¬† print('query_param :',query_param)
    ¬† ¬† res = reque
sts.get(
    ¬† ¬† ¬† ¬† f'https://api.github.com/search/users?q={query_param}'
    ¬† ¬† )
    ¬† ¬† print('response logged :',
res.json())
    ¬† ¬† return res.json()
    
    
    llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)
    
    def qu
ery_param_generator_node(agent_node):
    
    ¬† ¬† query_param_generator_agent = create_react_agent(llm, tools=[query_pa
ram_generator])
    ¬† ¬† query_param_node = functools.partial(agent_node, agent=query_param_generator_agent, name='query_
param_generator')
    ¬† ¬† return query_param_node
    
    
    def fetch_users_node(agent_node):
    
    ¬† ¬† fetch_use
rs_agent = create_react_agent(llm, tools=[fetch_users])
    ¬† ¬† fetch_node = functools.partial(agent_node, agent=fetch_u
sers_agent, name='fetch_users')
    ¬† ¬† return fetch_node

now , below is the code for my github supervisor agent , this
 agent has query\_param\_generator\_node and fetch\_users\_node agents available :

    import github_agent
    from typ
ing import Annotated, List
    from langchain_core.messages import BaseMessage, HumanMessage
    import operator
    fro
m typing_extensions import TypedDict
    from langchain_openai.chat_models import ChatOpenAI
    from langgraph.prebuilt
 import create_react_agent
    from create_team_supervisor_func import create_team_supervisor_func
    from langgraph.gr
aph import END, StateGraph, START
    import create_image_func
    
    # GithubTeamState graph state
    class GithubTe
amState(TypedDict):
    ¬† ¬† # A message is added after each team member finishes
    ¬† ¬† messages: Annotated[List[BaseMe
ssage], operator.add]
    ¬† ¬† # The team members are tracked so they are aware of
    ¬† ¬† # the others' skill-sets
    ¬†
 ¬† team_members: List[str]
    ¬† ¬† # Used to route work. The supervisor calls a function
    ¬† ¬† # that will update this
 every time it makes a decision
    ¬† ¬† next: str
    
    
    # The following functions interoperate between the top l
evel graph state
    # and the state of the research sub-graph
    # this makes it so that the states of each graph don'
t get intermixed
    def enter_chain(message: str):
    ¬† ¬† results = {
    ¬† ¬† ¬† ¬† 'messages': [HumanMessage(content=me
ssage)],
    ¬† ¬† }
    ¬† ¬† return results
    
    def github_team_supervisor(agent_node)-> str:
    
    ¬† ¬† llm = Chat
OpenAI(model='gpt-4o-mini')
    
    ¬† ¬† query_param_node = github_agent.query_param_generator_node(agent_node)
    
   
 ¬† ¬† fetch_node = github_agent.fetch_users_node(agent_node)
    
    ¬† ¬† def supervisor_agent(state):
    
    ¬† ¬† ¬† ¬† g
ithub_supervisor_agent = create_team_supervisor_func(
    ¬† ¬† ¬† ¬† ¬† ¬† llm,
    ¬† ¬† ¬† ¬† ¬† ¬† 'You are a supervisor tasked 
with managing a conversation between the'
    ¬† ¬† ¬† ¬† ¬† ¬† ' following workers: ¬†query_param_generator, fetch_users. Give
n the following user request,'
    ¬† ¬† ¬† ¬† ¬† ¬† ' always respond with the query_param_generator worker as it will be call
ed first and take its output as parameter to fetch_users worker'
    ¬† ¬† ¬† ¬† ¬† ¬† ' After calling fetch_users , respond w
ith FINISH.',
    ¬† ¬† ¬† ¬† ¬† ¬† ['query_param_generator', 'fetch_users'],
    ¬† ¬† ¬† ¬† )
    ¬† ¬† ¬† ¬† return github_supervis
or_agent
    
    ¬† ¬† github_graph = StateGraph(GithubTeamState)
    ¬† ¬† github_graph.add_node('query_param_generator', 
query_param_node)
    ¬† ¬† github_graph.add_node('fetch_users', fetch_node)
    ¬† ¬† github_graph.add_node('supervisor', s
upervisor_agent)
    
    ¬† ¬† # Define the control flow
    ¬† ¬† github_graph.add_edge('query_param_generator', 'supervis
or')
    ¬† ¬† github_graph.add_edge('fetch_users', 'supervisor')
    ¬† ¬† github_graph.add_conditional_edges(
    ¬† ¬† ¬† ¬† 
'supervisor',
    ¬† ¬† ¬† ¬† lambda x: x['next'],
    ¬† ¬† ¬† ¬† {'query_param_generator': 'query_param_generator', 'fetch_use
rs': 'fetch_users', 'FINISH': END},
    ¬† ¬† )
    
    
    ¬† ¬† github_graph.add_edge(START, 'supervisor')
    ¬† ¬† chain
 = github_graph.compile()
    
    ¬† ¬† github_chain = enter_chain | chain
    ¬† ¬† create_image_func.create_graph_image(c
hain, 'github_graph_image')
    ¬† ¬† return github_chain

this setup works but can only build basic queries , you can see
 that I've written all the rules for building the query parameters in the system prompt , but still I'm not getting perf
ect output ( the query parameters ) . How can I make improvements to my tools and the code snippet in general .

Thanks 
!
```
---

     
 
all -  [ Recommendations for matching taxonomy structures with data sources ](https://www.reddit.com/r/LangChain/comments/1fe7wt3/recommendations_for_matching_taxonomy_structures/) , 2024-09-13-0912
```
I have these requirement to find this taxonomies in my data. I already vectorized in qdrant, chromadb and opensearch/ela
sticsearch. Now I want to iterate the list from the picture to find relevant data in the mentioned databases.  
  
Any s
uggestions on the best approaches, technologies, or tools to achieve this would be greatly appreciated. Thanks for your 
input!

https://preview.redd.it/uvalq10b26od1.png?width=3380&format=png&auto=webp&s=f224f87dbad43e179c3e5d9b1ac06a2cf1a6
07d8


```
---

     
 
all -  [ How to get started with building an on premises generative AI platform? ](https://www.reddit.com/r/mlops/comments/1fe5i82/how_to_get_started_with_building_an_on_premises/) , 2024-09-13-0912
```
Hi everyone, 

I recently got a job at a small company that wants to deploy an RAG application on premises for its clien
ts. This company hasn't really done any AI use cases before, although does have some data analytics products in their do
main. The hiring manager wants me to develop their application as a RnD project from the ground up. That means choosing 
an open-source LLM and deploying it on-premise and open-source orchestrators like langchain along with other components 
of a gen AI platform along with the hardware specs needed to run such a platform on-premises. 

I have some experience w
ith LLMs in a hobby project in the Azure cloud and langchain along with a previous job in traditional ML where the infra
structure and server were already set up. But I have never done something of this scale where I had to design the system
 and also choose the infrastructure and hardware requirements along with LLMOps down the line.  

Can someone please gui
de me in going about how to get something of this scale setup? What factors should I consider and if any resources can h
elp in the usecase? 


```
---

     
 
all -  [ Resume review from Analytics Engineer to Data Engineering?  ](https://i.redd.it/qg5f5zb043od1.png) , 2024-09-13-0912
```
Would appreciate everyone's feedback!
```
---

     
 
all -  [ PromptTemplate coupled to LLM parsing output ](https://www.reddit.com/r/LangChain/comments/1fdxh8o/prompttemplate_coupled_to_llm_parsing_output/) , 2024-09-13-0912
```
Hi,

I'm new to this AI world so consider I might be missing some context or not fully understanding something as of yet
.  
Having said that, I was developing an application which generates specific content as I request it to do so. For thi
s project I'm using langchain as a framework and gemini as the LLM. I'm also using RAG technique to retrieve relevant da
ta and use my own custom context.  
I have a simple [main.py](http://main.py) which has 2 messages, one for invoking and
 the other one for building the classic pipe or rag chain as I understand this flow is called.  
That pipeline looks som
ething like this:

`pipeline = (`  
`{'context': my_context,`  
`'query': RunnablePassthrough()}`  
`| prompt`  
`| llm`
  
`| StrOutputParser()`  
`)`

So my doubt came when I needed to change the parsing of the output the LLM was returning
 me. I needed to structure the data in a JSON with some specific types and I've realized that I needed to add that chang
e to the *Prompt.*  
To me this didn't make sense at all since I understood the last call of the pipeline, in this case 
a simple string, was the way to parse the output. To my surprise I've encountered that I needed to add format instructio
ns within the prompt.  
On the prompting side I have something like this:

    parser = JsonOutputParser(pydantic_object
=MyObjectTemplate)
    
    return PromptTemplate(
        template=MY_PROMPT_TEMPLATE,
        input_variables=['query'
],
        partial_variables={'format_instructions': parser.get_format_instructions()},
    )

What I don't understand a
t all is why the line JsonOutputParser(pydantic\_object=MyObjectTemplate) cannot or else why it shouldn't go within the 
last step of the pipeline. I've tried to do so but partial\_variables parameter is required to create the PromptTemplate
 object.  
It's unclear to me so far why If I only want to change the way the LLM responds, I need to change the Prompt.


Can somebody help me understand how to accomplish a refactor to decoupled these two things or enlighten me if there's 
something I'm understanding incorrectly?

Thanks in advance.
```
---

     
 
all -  [ Looking for team to start my hackathon journey. ](https://www.reddit.com/r/hackathons/comments/1fdx9vj/looking_for_team_to_start_my_hackathon_journey/) , 2024-09-13-0912
```
Hey everyone! I want to start my journey in hackathons. I want to create my own team or joining a team. I want to learn 
something new and participant in competitions. If anyone here please respond.
My skills are
Python
Telegram api
Langchai
n
Django(Basics)
React(Basics)
Thanks for approaching....;)
```
---

     
 
all -  [ How to embed and retrieve images in RAG ](https://www.reddit.com/r/SmythOS_/comments/1fdwkar/how_to_embed_and_retrieve_images_in_rag/) , 2024-09-13-0912
```
I'm working on a RAG project involving numerous PDFs and documents.

The documents frequently include screenshots that v
isually illustrate the surrounding text. Given the abundance of these screenshots and their high level of detail, I'm co
ncerned that using a multimodal model to describe the images might be both costly and potentially inaccurate.

As an alt
ernative, I'm considering using image embedding techniques with some form of positional referencing or indexing. I'm int
erested in finding valuable examples or resources that implement this approach, particularly using Langchain or other si
milar frameworks.

Additionally, I'm curious if certain vector databases are better suited for this specific use case. A
ny insights or recommendations would be greatly appreciated.
```
---

     
 
all -  [ Dynamic crawling using LLMs ](https://www.reddit.com/r/LangChain/comments/1fdtgdv/dynamic_crawling_using_llms/) , 2024-09-13-0912
```
I use crawling quite a bit for different parts of my job and have used platforms like scraperapi as well as apis from sc
rapy and others. In recent times i tried firecrawl as well [r.jina.ai](http://r.jina.ai) as well - for crawling. However
, they were all less than perfect. So I defined my own way of crawling and figured this can be quite straight forward..


Basically you can provide a json for what you'd like to have and then ask openai or claude with a url to convert it to 
the provided json - this will convert any website into a json format. 

Now instead of doing it again and again with llm
, you can ask llm to write a code that produces the json output you are expecting given the website.. and you get a code
 that works perfectly and if there are errors you can ask llm to correct it. 

It works quite well for me .. I put up th
e code here [https://github.com/alinaqi/dynamic\_crawler](https://github.com/alinaqi/dynamic_crawler) for anyone who may
 find it interesting.. 

Happy to hear from others on what they think about the approach. 
```
---

     
 
all -  [ Need Suggestions for AI beginners courses? ](https://www.reddit.com/r/PakistaniTech/comments/1fdosl4/need_suggestions_for_ai_beginners_courses/) , 2024-09-13-0912
```
I am a complete beginner in field of AI with zero prior experience although not new in the field of IT(I work on flutter
). AI has always been a keen of interest of me i want to learn about it but dont know where to start as a beginner and w
hat to learn like i go on YouTube and simply type AI and get Langchain, Generative AI , ML,NLP  and etc but dont know wh
at to start please guide me..
Thanks
```
---

     
 
MachineLearning -  [ [P] Review and suggest ideas for my chatbot ](https://www.reddit.com/r/MachineLearning/comments/1fb2mwl/p_review_and_suggest_ideas_for_my_chatbot/) , 2024-09-13-0912
```
Ok, so I am currently trying to build support chatbot with following technicalities 
1. FastAPI for web server(Need to m
ake it faster)
2. Qdrant as Vector Data Base(Found it to be the fastest amongst Chromadb, Elastic Search and Milvus)
3. 
MongoDB for storing all the data and feedback.
4. Semantic chunking with max token limit of 512.
5. granite-13b-chat-v2 
as the LLM(I know it's not good but I have limited options available)
6. The data is structured as well as unstructured.
 Thinking of having involving GraphRAG with current architecture.
7. Multiple data sources stored in multiple collection
s of vector database because I have implemented an access control.
8. Using mongoengine currently as a ORM. If you know 
something better please suggest.
9. Using all-miniLM-l6-v2 as vector embedding currently but planning to use stella_en_4
00M_v5.
10. Using cosine similarity to retrieve the documents.
11. Using BLEU, F1 and BERT score for automated evaluatio
n based on golden answer.
12. Using top_k as 3.
13. Currently using basic question answering prompt but want to improve 
it. Any tips? Also heard about Automatic Prompt Evaluation.
14. Currently using custom code for everything. Looking to u
se Llamaindex or Langchain for this. 
15. Right now I am not using any AI Agent, but I want to know your opinions. 
16. 
It's a simple RAG framework and I am working on improving it.
17. I haven't included reranker but I am planning to do so
 too.

I think I mentioned pretty much everything I am using for my project. So please share your suggestions, comments 
and reviews for the same. Thank you!!
```
---

     
 
MachineLearning -  [ [P] Lessons from Retrieval Augmented Generation ](https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/) , 2024-09-13-0912
```
I implemented Rag in my organization and just wrote a blog about what we learned here:   
[https://www.b-yond.com/post/t
ransforming-telco-troubleshooting-our-journey-building-telcogpt-with-rag](https://www.b-yond.com/post/transforming-telco
-troubleshooting-our-journey-building-telcogpt-with-rag)

Hoping it would be helpful for those in this area. Covers rag 
evaluation (ragas), sql db, langchain agents vs chains, weaviate vector db, hybrid search, reranking, and more.

Some ad
ditional insights on ranking and hybrid search here:

[https://www.linkedin.com/posts/drzohaib\_transforming-telco-troub
leshooting-our-journey-activity-7232072089837486081--Le1?utm\_source=share&utm\_medium=member\_android](https://www.link
edin.com/posts/drzohaib_transforming-telco-troubleshooting-our-journey-activity-7232072089837486081--Le1?utm_source=shar
e&utm_medium=member_android)
```
---

     
 
deeplearning -  [ Month of August in AI ](https://www.reddit.com/r/deeplearning/comments/1f6zfz0/month_of_august_in_ai/) , 2024-09-13-0912
```
üîç¬†I**nside this Issue:**

* ü§ñ¬†La*test Breakthroughs:¬†*This month it‚Äôs all about¬†A*gents, LangChain RAG, and LLMs evaluat
ion challenges.*
* üåê¬†AI Monthly News:¬†Discover how these stories are revolutionizing industries and impacting everyday l
ife:¬†E*U AI Act, California‚Äôs Controversial SB1047 AI regulation act, Drama at OpenAI, and possible funding at OpenAI by
 Nvidia and Apple.*
* üìö¬†Editor‚Äôs Special:¬†This covers the interesting talks, lectures, and articles we came across recen
tly.

Follow me on Twitter and LinkedIn at¬†[**RealAIGuys**](https://twitter.com/RealAIGuys)¬†and¬†[**AIGuysEditor**](https
://www.linkedin.com/in/vishal-rajput-999164122/) to get insight on new AI developments.

>**Please don't forget to subsc
ribe to our Newsletter:** [**https://medium.com/aiguys/newsletter**](https://medium.com/aiguys/newsletter)

# Latest Bre
akthroughs

Are Agents just simple rules? Are Agents just enhanced reasoning? The answer is yes and no. Yes, in the sens
e that agents have simple rules and can sometimes enhance reasoning capabilities compared to a single prompt. But No in 
the sense that agents can have a much more diverse functionality like using specific tools, summarizing, or even followi
ng a particular style. In this blog, we look into how to set up these agents in a hierarchal manner just like running a 
small team of Authors, researchers, and supervisors.

[**How To Build Hierarchical Multi-Agent Systems?**](https://mediu
m.com/aiguys/how-to-build-hierarchical-multi-agent-systems-dc26b19201d2?sk=90958e39e1a28f5030872a90f8e3f3da)

**TextGrad
**. It is a powerful framework performing automatic ‚Äúdifferentiation‚Äù via text.¬†**It backpropagates textual feedback pro
vided by LLMs to improve individual components of a compound AI system.**¬†In this framework, LLMs provide rich, general,
 natural language suggestions to optimize variables in computation graphs, ranging from code snippets to molecular struc
tures. TextGrad showed effectiveness and generality across various applications, from question-answering and molecule op
timization to radiotherapy treatment planning.

[**TextGrad: Improving Prompting Using AutoGrad**](https://medium.com/ai
guys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10?sk=3633a9aa63b884c97469bce659265921)

The addition of RAG t
o LLMs was an excellent idea. It helped the LLMs to become more specific and individualized. Adding new components to an
y system leads to more interactions and its own sets of problems. Adding RAG to LLMs leads to several problems such as h
ow to retrieve the best content, what type of prompt to write, and many more.

In this blog, we are going to combine the
¬†**LangChain RAG with DSPy**. We deep dive into how to evaluate the RAG pipeline quantitatively using¬†**RAGAs**¬†and how 
to create a system where instead of manually tweaking prompts, we let the system figure out the best prompt.

[**How To 
Build LangChain RAG With DSPy?**](https://medium.com/aiguys/how-to-build-langchain-rag-with-dspy-ce9154fbafaa?sk=b41d104
05f84c767cf9cd6a58d1ebac0)

As the field of natural language processing (NLP) advances, the evaluation of large language
 models (LLMs) like GPT-4 becomes increasingly important and complex. Traditional metrics such as accuracy are often ina
dequate for assessing these models‚Äô performance because they fail to capture the nuances of human language. In this arti
cle, we will explore why evaluating LLMs is challenging and discuss effective methods like BLEU and ROUGE for a more com
prehensive evaluation.

[**The Challenges of Evaluating Large Language Models**](https://medium.com/aiguys/the-challenge
s-of-evaluating-large-language-models-ec2eb834a349)

# AI Monthly News

# AI Act enters into force

On 1 August 2024, th
e European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelli
gence development and deployment in the EU. The AI Act introduces a uniform framework across all EU countries, based on 
a forward-looking definition of AI and a risk-based approach:

* **Minimal risk:**¬†most AI systems such as spam filters 
and AI-enabled video games face no obligation under the AI Act, but companies can voluntarily adopt additional codes of 
conduct.
* **Specific transparency risk:**¬†systems like chatbots must clearly inform users that they are interacting wit
h a machine, while certain AI-generated content must be labelled as such.
* **High risk:**¬†high-risk AI systems such as 
AI-based medical software or AI systems used for recruitment must comply with strict requirements, including risk-mitiga
tion systems, high-quality of data sets, clear user information, human oversight, etc.
* **Unacceptable risk:**¬†for exam
ple, AI systems that allow ‚Äúsocial scoring‚Äù by governments or companies are considered a clear threat to people‚Äôs fundam
ental rights and are therefore banned.

**EU announcement:**¬†[**Click here**](https://commission.europa.eu/news/ai-act-e
nters-force-2024-08-01_en)

https://preview.redd.it/nwyzfzgm4cmd1.png?width=828&format=png&auto=webp&s=c873db37ca0dadd5b
510bea70ac9f633b96aaea4

# California AI bill SB-1047 sparks fierce debate, Senator likens it to ‚ÄòJets vs. Sharks‚Äô feud


**Key Aspects of SB-1047:**

* Regulation Scope: Targets ‚Äúfrontier‚Äù AI models, defined by their immense computational t
raining requirements (over 10¬≤‚Å∂ operations) or significant financial investment (>$100 million).
* Compliance Requiremen
ts: Developers must implement safety protocols, including the ability to immediately shut down, cybersecurity measures, 
and risk assessments, before model deployment.
* Whistleblower Protections: Encourages reporting of non-compliance or ri
sks by offering protection against retaliation.
* Safety Incident Reporting: Mandates reporting AI safety incidents with
in 72 hours to a newly established Frontier Model Division.
* Certification: Developers need to certify compliance, pote
ntially under penalty of perjury in earlier drafts, though amendments might have altered this.

**Pros:**

* Safety Firs
t: Prioritizes the prevention of catastrophic harms by enforcing rigorous safety standards, potentially safeguarding aga
inst AI misuse or malfunction.
* Incentivizes Responsible Development: By setting high standards for AI model training, 
the company encourages developers to think critically about the implications of their creations.
* Public Trust: Enhance
s public confidence in AI by ensuring transparency and accountability in the development process.

**Cons:**

* Innovati
on Stagnation: Critics argue it might stifle innovation, especially in open-source AI, due to the high costs and regulat
ory burdens of compliance.
* Ambiguity: Some definitions and requirements might be too specific or broad, leading to leg
al challenges or unintended consequences.
* Global Competitiveness: There‚Äôs concern that such regulations could push AI 
development outside California or the U.S., benefiting other nations without similar restrictions.
* Implementation Chal
lenges: The practicalities of enforcing such regulations, especially the ‚Äúpositive safety determination,‚Äù could be compl
ex and contentious.

**News Article:**¬†[**Click here**](https://www.thenation.com/article/society/sb-1047-ai-big-tech-fi
ght/)

**Open Letter:**¬†[**Click here**](https://safesecureai.org/open-letter)

https://preview.redd.it/ib96d7nk4cmd1.pn
g?width=828&format=png&auto=webp&s=0ed5913b5dae72e203c8592393e469d9130ed689

# MORE OpenAI drama

OpenAI co-founder John
 Schulman has left the company to join rival AI startup Anthropic, while OpenAI president and co-founder Greg Brockman i
s taking an extended leave until the end of the year. Schulman, who played a key role in creating the AI-powered chatbot
 platform ChatGPT and led OpenAI‚Äôs alignment science efforts, stated his move was driven by a desire to focus more on AI
 alignment and hands-on technical work. Peter Deng, a product manager who joined OpenAI last year, has also left the com
pany. With these departures, only three of OpenAI‚Äôs original 11 founders remain: CEO Sam Altman, Brockman, and Wojciech 
Zaremba, lead of language and code generation.

**News Article:**¬†[**Click here**](https://techcrunch.com/2024/08/05/ope
nai-co-founder-leaves-for-anthropic/)

https://preview.redd.it/0vdjc18j4cmd1.png?width=828&format=png&auto=webp&s=e9de60
4c26aed3e47b50df3bdf114ef61f967080

# Apple and Nvidia may invest in OpenAI

Apple, which is planning to integrate ChatG
PT into iOS, is in talks to invest. Soon after,¬†[*Bloomberg*¬†also](https://www.bloomberg.com/news/articles/2024-08-29/nv
idia-has-held-discussions-about-joining-openai-s-funding-round?srnd=homepage-americas)¬†reported that Apple is in talks b
ut added that Nvidia ‚Äúhas discussed‚Äù joining the funding round as well. The round is reportedly being led by Thrive Capi
tal and would value OpenAI at more than $100 billion.

**News Article:**¬†[**Click here**](https://www.theverge.com/2024/
8/29/24231626/apple-nvidia-openai-invest-microsoft)

https://preview.redd.it/ude6jguh4cmd1.png?width=828&format=png&auto
=webp&s=3603cbca0dbb1be3e6d0efcf06c3a698428bbdd6

# Editor‚Äôs Special

* The AI Bubble: Will It Burst, and What Comes Aft
er?:¬†[**Click here**](https://www.youtube.com/watch?v=91SK90SahHc&t=317s)
* Eric Schmidt Full Controversial Interview on
 AI Revolution (Former Google CEO):¬†[**Click here**](https://www.youtube.com/watch?v=mKVFNg3DEng)
* AI isn‚Äôt gonna keep 
improving¬†[**Click here**](https://www.youtube.com/watch?v=Y8Ym7hMR100)
* General Intelligence: Define it, measure it, b
uild it:¬†[**Click here**](https://www.youtube.com/watch?v=nL9jEy99Nh0)
```
---

     
 
deeplearning -  [ Creating a project on NLP ](https://www.reddit.com/r/deeplearning/comments/1ey2e85/creating_a_project_on_nlp/) , 2024-09-13-0912
```
So me and my friend completed the ML and DL specialization by AndrewNg, and were just gonna get started on a project. We
 decided to make a academic assistant. So basically what this does is a user can upload a PDF,text file or any other sup
ported media and the can ask questions related to it's contents. The main objective being making learning quick given la
rger documents.

The pipeline we decided is pretty standard for such a project.

1. Split the text into chunks
2. Genera
te embeddings of the chunks
3. Store the chunks in a vector DB
4. Find the top K similar chunks to the query 
5. Retriev
e context and feed it into a LLM for an answer.

So I looked up for a library and framework to use and decided on langch
ain. We haven't decided on an LLM yet but want to run it locally so no OpenAI please. 

Since this is gonna be out first
 AI project confidence is low. I would really appreciate any heads up on the issues we may face, any suggestions on libr
aries,frameworks or models will be really helpful as well. 

Appreciate any resourceful comment üòä
```
---

     
