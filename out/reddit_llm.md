 
all -  [ Chatbot that only pulls specific data from a SQL database based on UserID? ](https://www.reddit.com/r/LangChain/comments/15nqfc3/chatbot_that_only_pulls_specific_data_from_a_sql/) , 2023-08-11-0909
```
I have a SQL database that external partners access but they can only see information attached to their unique user ID. 
Is it possible to create a chatbot using langchain that recognizes each persons unique user id and only pulls the releva
nt data from the SQL database without giving them access to the rest?
```
---

     
 
all -  [ Is there a way to summarize the current chain? ](https://www.reddit.com/r/LangChain/comments/15npkpp/is_there_a_way_to_summarize_the_current_chain/) , 2023-08-11-0909
```
I‚Äôm building a clone of chatGPT for personal development. 

I‚Äôm missing the feature to show a summary of the history lik
e in chatGPT side panel. 

Is there a way to get it from Langchain?
```
---

     
 
all -  [ LLMs Challenges and Approaches Panel [N] ](https://www.reddit.com/r/MachineLearning/comments/15noqwr/llms_challenges_and_approaches_panel_n/) , 2023-08-11-0909
```
&#x200B;

https://preview.redd.it/wl1gtcngnchb1.jpg?width=1500&format=pjpg&auto=webp&s=24e35d852603c6139fd67f79457ec593f
bad99f7

If you're someone who's curious about or working with LLMs there's a cool panel discussion coming up: 

* Compa
ring the pros and cons of using existing LLMs, prompt engineering, and fine-tuning on custom datasets for different ente
rprise use cases.
* Fine-Tuning LLMs: Exploring the advantages and challenges of fine-tuning LLMs on custom datasets to 
align with specific business objectives.
* Tools and platforms: Discussing the various tools and platforms to facilitate
 LLM implementation 
* Overcoming Challenges: Addressing the challenges associated with adopting LLMs, including data pr
ivacy, creating high quality datasets, computational resources, ethical considerations, and the need for specialized exp
ertise.
* Future Directions: Exploring emerging trends, advancements, and potential future applications of LLMs in the e
nterprise context.

Here's the event info: [https://www.eventbrite.com/e/large-language-models-for-enterprise-success-ch
allenges-and-approaches-tickets-695089811337?aff=oddtdtcreator](https://www.eventbrite.com/e/large-language-models-for-e
nterprise-success-challenges-and-approaches-tickets-695089811337?aff=oddtdtcreator)
```
---

     
 
all -  [ LLMs for Success: Challenges and Approaches Panel ](https://i.redd.it/fykf8ot6kchb1.jpg) , 2023-08-11-0909
```

```
---

     
 
all -  [ Best features to support in a software development AI-assisted tool ](https://www.reddit.com/r/ChatGPT/comments/15nln2f/best_features_to_support_in_a_software/) , 2023-08-11-0909
```
Hello fellow programmers. Me and my friends recently used LangChain and some fancy prompt engineering techniques to auto
generate a code base for a rather complex software project using GPT.

We made our tool free and open source under the M
IT license, and we intend to keep at it and improve it and add more features to it. 

Here is the tool: [https://github.
com/RoboCoachTechnologies/GPT-Synthesizer](https://github.com/RoboCoachTechnologies/GPT-Synthesizer) 

I wonder what do 
you think should be supported by a tool like this? 

Please either comment here, or file an issue on our github. I truly
 appreciate your time and your feedback. I also appreciate it if you would kindly leave us a star on github. 
```
---

     
 
all -  [ strugle to chat with docs ](https://www.reddit.com/r/LangChain/comments/15nl2ll/strugle_to_chat_with_docs/) , 2023-08-11-0909
```
 I recently cloned the [**gpt4-pdf-chatbot-langchain**](https://github.com/mayooear/gpt4-pdf-chatbot-langchain) reposito
ry from GitHub which integrates with Pinecone. However, I've encountered an issue after ingesting a document of about 50
0 pages with embedded links. The chatbot seems to 'hallucinate' or misinterpret these links, which is quite unexpected. 
I'm seeking alternative solutions or suggestions to address this. Any guidance would be greatly appreciated. Thank you. 
 
 
```
---

     
 
all -  [ Open Source Vector Embedding Pipeline to Ingest Gigabytes of Data ](https://www.reddit.com/r/LangChain/comments/15nl2b7/open_source_vector_embedding_pipeline_to_ingest/) , 2023-08-11-0909
```
üöÄ Excited to announce the release of the initial version of our open-source vector embedding pipeline, VectorFlow! üéâ

Ou
r pipeline is built to embed large volumes of data quickly and reliably. While embedding a handful of PDFs for Q&A might
 seem straightforward, the real challenge arises when you're faced with ingesting gigabytes of unstructured data consist
ently and frequently.

With just a simple API request, you can effortlessly embed and store raw data in any vector datab
ase, eliminating the need for complex cloud infrastructure setups.

üîó Check out our Github repo: [https://github.com/dga
rnitz/vectorflow](https://github.com/dgarnitz/vectorflow) and check out our website: [https://www.getvectorflow.com/](ht
tps://www.getvectorflow.com/)

For all the innovators working with vector databases, we're eager to hear your insights, 
feedback, and ideas for the roadmap! üåêüîçüìäüöÄ
```
---

     
 
all -  [ Unleash the Power of LLMs in Your Telegram Bot on a Budget ](https://www.reddit.com/r/TelegramBots/comments/15njryp/unleash_the_power_of_llms_in_your_telegram_bot_on/) , 2023-08-11-0909
```
Interested in supercharging your Telegram bot with large language models (LLMs)? Here's a concise guide:

* **Introducti
on**: Harness LLMs like llama2-chat and vicuna. The bot is hosted on Amazon's free-tier EC2, with LLM inference on Beam 
Cloud.
* **Telegram Bot Setup**: Initiate with u/botfather on Telegram, get your token, and start a conversation with yo
ur bot.
* **Hosting**: Deploy on Amazon‚Äôs free-tier EC2 instance. The guide provides steps from EC2 setup to bot launch.

* **LLM Integration**: Beam Cloud, an affordable choice, is used for LLM inference. The bot taps into langchain and hug
gingface.

üîó [**GitHub Repo**](https://github.com/ma2za/telegram-llm-guru) üîó [**Full Medium Article**](https://medium.co
m/@saverio3107/crafting-a-cost-effective-llm-powered-telegram-bot-a-step-by-step-guide-4d1e760e7eec) üîó [**Join Medium fo
r More Updates**](https://medium.com/@saverio3107/membership)

Dive in, experiment, and enhance your Telegram bot's capa
bilities! Feedback and insights are welcome. üöÄ
```
---

     
 
all -  [ How langchain isable to achieve (almost) perfect SQL query ? ](https://devblogs.microsoft.com/semantic-kernel/use-natural-language-to-execute-sql-queries/) , 2023-08-11-0909
```
Me and my time is working on how to implement a natural language to SQL query generation based on a database using Seman
tic kernel(SK).
Our approach was to give the Kernel (chains equivalent in SK) the schema of the database.
We also have t
o explicitly mentioned the values of certain columns to increase the performance.
We observe that only davinci is able t
o generate most appropriate SQL query compare to gpt-35-turbo.
The same is started by the following [article](https://de
vblogs.microsoft.com/semantic-kernel/use-natural-language-to-execute-sql-queries/) as well.

Interestingly langchain use
s gpt-35-turbo to create SQL query.So my question is what langchain is doing differently???
```
---

     
 
all -  [ Using Document metadata in ConversationalRetrievalChain ](https://www.reddit.com/r/LangChain/comments/15niet1/using_document_metadata_in/) , 2023-08-11-0909
```
Hey, I need some help with my ConversationalRetrievalChain app.

For context i'm using RecursiveTextSplitter and FAISS t
o store the text of the PDFs i upload.   
I manually add the metadata to the Documents such as each chunk will have 'sou
rce' and 'page\_number'  
I'm then using a ConversationalRetrievalChain.from\_llm alongside SystemMessagePromptTemplate 
and Human... that feed in a ChatPromptTemplate.

Now that you know the basic arch, here is the problem.  
When I upload 
multiple documents, I want to be able to look for an answer that says:  
' This doc says X, this doc says Y'  


Because
 I am using the RecursiveTextSplitter, the chunks I get are all Documents according to llm.   
So even if I upload 2 pdf
s only, i get an answer relative to:  
'Doc 1 says z, Doc 2 says x, Doc 3 says c, Doc 4 says d'  
Because it doesn't hav
e context of what document belongs to which pdf.   


What I want to do is let the llm tap into the Metadata of each chu
nk to support its explanation. Then instead of showing multiple documents, it will pinpoint which chunks belong to which
 document.   
Any help is appreciated
```
---

     
 
all -  [ Struggling with 404 Errors in LangChain: How Can I Ensure Valid Webpage Links? ](https://www.reddit.com/r/LangChain/comments/15nemtf/struggling_with_404_errors_in_langchain_how_can_i/) , 2023-08-11-0909
```
Hi everyone, I've been working with LangChain and SerpAPI to retrieve webpage links for a project. Unfortunately, I've e
ncountered an issue where some of the links are returning a '404 Page Not Found' error. I want to ensure that the links 
I'm retrieving are both accessible and available. Can anyone provide guidance or suggestions on how to verify the validi
ty of these links or filter out the ones that are not working? Thanks in advance for your help!
```
---

     
 
all -  [ Open source Facebook/ig/whatsapp messenger chatbot with langchain ](https://www.reddit.com/r/LangChain/comments/15ne3rt/open_source_facebookigwhatsapp_messenger_chatbot/) , 2023-08-11-0909
```
Basically what the tittle says, Im developing a private software right now but in my journey to learn using langchain an
d some other API tests I used Facebook messenger as my UI instead of making one (no domain,no fees,no database necessary
) to test some basic to advanced features of a chatbot, let it be a simple chat chain Q&A with DB queries or a full fled
ge agent like auto-gpt(non multi-agent). Here‚Äôs my deal. I‚Äôm creating the github open source because i haven‚Äôt seen(last
 time I checked) a complete repo for this, I belive is of value for begginer/intermediate level for developers of Llm ap
ps to start here with the merge of good ui/ux (we use it all the time no designing thinking is required) and can be furt
her improved(reduced response time,local LLMs, speech2text,text2image,file2text) I wanna know if some of you are looking
 for this or interested enough to make the complete guide and start a discord sever for further development in GitHub re
pository.

Extra:
As my own point of view, I hope many of us share the same excitement of working with bleeding edge tec
hnology of AI and so do big industries are(Facebook buying Llama , ‚ÄúX‚Äù with the account verification, KhanAcademy with C
hatGPT tutor‚Ä¶) but for now they only live in the software environment(I hope sooner or later boston dynamics just connec
ts to the  mic array and a speaker with gpt api to a spot) so the main road for the LLMs is to grow popularity in the vi
rtual space.As for now they work mainly for category of virtual assistant and that globally would be condensed into thes
e category always‚Ä¶ until we can have friendly talks over the internet with out any propuse or objective making it the du
mbest/smartest virtual friend/Teacher, and creating engienieering parts for cars, developing new instruments or solution
s for the applied science, we are gradually looking at this but for now the more virtual agent populate the platforms th
e more we can socially experiment and as mentioned before the industires for sure may see this as competition, and if th
ere‚Äôs a way to eradicate this they would love to do it and make it their own or worse . They would never able to reach t
he same power as they could do in the earlier years mostly because of the lack of control‚Ä¶This is just a smart part of t
he model which makes me feel like I don‚Äôt have a bicycle for the mind but a Raptor F-22.
```
---

     
 
all -  [ Is there any way to show the verbose in our streamlit UI ](https://www.reddit.com/r/LangChain/comments/15ndsq5/is_there_any_way_to_show_the_verbose_in_our/) , 2023-08-11-0909
```
I am working on a project on agents that can show verbose in terminal but not in UI is there any way to show this ??
```
---

     
 
all -  [ After spending 1,000+ hours building AI chatbots, here‚Äôs why you shouldn‚Äôt build your own ](https://www.reddit.com/r/SaaS/comments/15n8ua8/after_spending_1000_hours_building_ai_chatbots/) , 2023-08-11-0909
```
I‚Äôve personally spent over 1,000 hours building AI chatbots.

Here‚Äôs what I‚Äôve learnt over the last 6 months, and why I 
think the majority of businesses are wasting a huge amount of time and resources when they decide to ‚Äúbuild their own‚Äù A
I chatbots.

Consider this, would you build your own enterprise search for your business?

## ‚úÖ Why you should build you
r own AI chatbot

‚Äú*It‚Äôs never been easier to build an AI chatbot‚Äù* ‚Äî no doubt you‚Äôll have heard this countless times in
 all those daily AI newsletters.

You‚Äôve probably been eyeing up [Langchain](https://python.langchain.com/docs/get_start
ed/introduction.html) or [Llama Index](https://www.llamaindex.ai/), read their docs and a few tutorials, and fancy deplo
ying your own AI bot in a weekend hack.

In fact, here‚Äôs exactly how you‚Äôd do it:

1. Fetch, transform, and ingest your 
data into a [vector database](https://python.langchain.com/docs/modules/data_connection/vectorstores/)
2. Spin up a chat
 interface from a [template](https://vercel.com/templates/next.js/nextjs-ai-chatbot)
3. Connect to a super-intelligent A
I model, like [OpenAI‚Äôs ChatGPT](https://platform.openai.com/docs/models/gpt-3-5), that uses your content and can have a
 conversation with someone ‚Äî answering their questions like an expert

Simple right?

After your weekend hackathon (and 
after you‚Äôve shared your MVP with your team), you realize you want to take your AI chatbot to the next stage, after all,
 now you now have complete control over the:

* **Underlying data used by the chatbot** \- you can add all your private 
forecast reports or internal process docs and learning materials.
* **User interface and branding -** you can make it fe
el like it‚Äôs *really* a part of your existing stack.
* **Data privacy and security -** you can decide what happens to a 
user's chat history, or how ingested data is stored and processed. If your data is particularly sensitive, this may even
 be table stakes.
* **Access to your secure or private systems  -** systems that you wouldn‚Äôt want to expose to a 3rd Pa
rty.

All sounds good, right? But there are some pretty significant drawbacks, and there are some things your team will 
*need* in order to make a success of this.

## ‚ùå Why you shouldn‚Äôt build your own chatbot

Nothing is ever as easy as it
 seems.

As useful as the frameworks and libraries are to get you started quickly, they hide a lot of detail and a long 
list of small decisions that all add up to have a significant impact on the quality of your chatbot (and the risk to you
r business).

Here are all the things you‚Äôll need to consider and stay on top of if you are going to build yourself:

* 
**Initial business case:** A custom AI chatbot for a business is [estimated to cost upwards of $50,000](https://hyperise
.com/blog/how-much-does-it-cost-to-develop-a-chatbot) and these costs can quickly spiral upwards for use cases that requ
ire a high degree of accuracy or where a company has large volumes of content for the chatbot to access. You will need t
o justify this to management, likely before you can demonstrate the actual value.
* **AI expertise:** You‚Äôll need people
 in the business who understand how LLMs work at a high level. Especially what they can‚Äôt do. This expertise will be ess
ential if you want your chatbot to be more than just a novel toy for customers or employees (better start actually readi
ng that AI book you bought yourself to ‚Äúget up to speed‚Äù)
* **Product continuity:** What happens when you leave? Looking
 forward to having to document how your AI chatbot works for the next person or team?
* **AI provider and model selectio
n:** You‚Äôll need to decide on which AI provider you partner with and which AI model you want to use. This will involve w
eighing up the Pros and Cons and trade-offs you‚Äôll need to make e.g. Speed vs. Cost vs. Quality
* **Keeping up with AI d
evelopments:** You‚Äôll need a team to constantly stay on top of the latest AI developments to make sure your chatbot is l
everaging the newest tech. But importantly, to make sure you‚Äôre not reliant on methods that are being phased out. We‚Äôve 
seen changes to AI models that change answer quality overnight, the solutions for which, never seem to be straightforwar
d!
* **Preparing your data and content**: The data processing stage is crucial, this is where your content is manipulate
d into an optimal format for AI models to use. There are 20+ small, technical, decisions packed into just this topic and
 hundreds of edge cases to consider (did you know Arabic takes up 4x as many tokens as English for example?). There are 
already large groups of companies dedicated to solving just this problem, like [carbon.ai](http://carbon.ai) and [psychi
c.dev](http://psychic.dev)
* **Automated chat testing:** You‚Äôll have to define a testing approach to understand how chan
ges you make affect the quality of your chatbot. The biggest challenge here is the sheer number of permutations that are
 available to you. We worked out there are over 1 million combinations today, and this grows with every new model and pa
rameter. With each permutation, you have to test your AI chatbot like real humans would ‚Äî but in an automated way, at sc
ale, to be meaningful.
* **Integrations:** Do you want to integrate your chatbot with Slack or Teams? Or embed it on you
r website? These are all additional features that need to be built and approvals for them takes months with A LOT of bac
k and forth on minor details.

We live and breathe all these topics and challenges every day (and even for us some days 
they can feel overwhelming!). But we specialise, deeply, in all these areas with a single goal: creating the best AI cha
tbot to provide answers based on your content.

## Why reinvent the wheel?

Now, back to our enterprise search analogy. 
You wouldn‚Äôt consider building it yourself, even though it is fundamental in helping your teams locate the right content
 or data. You know how intricate and specialized the art of *good* search is. AI chat is much the same but with *much* m
ore uncertainty.

You also have to ask yourself if there aren‚Äôt more important challenges to be working on in your busin
ess? For instance, considering where AI fits more strategically, instead of how you are going to pre-process 5,000 PDF r
eports.

So, after 1,000+ hours building AI chatbots, I‚Äôm confident when I say that for 90%+ of businesses, buying in yo
ur AI chatbot solution is the way to go, but if you are still not convinced, here is the breakdown to help:

||If you wa
nt to BUILD‚Ä¶|If you want to BUY‚Ä¶|
|:-|:-|:-|
|AI capability and knowledge|Existing internal AI capability or expertise|L
imited or no existing AI knowledge in the business|
|Data sensitivity|Highly sensitive data is required for the AI chatb
ot to access|Private (not highly sensitive) or public data and content|
|Content type|Business content is static and lim
ited to <500 items/reports/documents|Business content can be dynamic, growing, and, available in large volumes of >1,000
 items/reports/documents|
|Dedicated team|Ability to dedicate a team to building and managing an AI chatbot|Objective to
 integrate AI chatbot capability into an existing team to manage (like enterprise search)|
|Chatbot as core differentiat
or|You expect an AI chatbot to be a significant differentiator and part of your business‚Äôs offering|An AI chatbot will l
everage or enrich your business‚Äôs existing core offering e.g. your editorial trend reports|

And while you may think tha
t Slack or Teams integrations, personalization, data security, and enterprise controls are other reasons to build your o
wn. With most providers, these features come out of the box.

Of course, your ‚Äòbuy instead of build‚Äô strategy may change
 over time. For example, if your chatbot becomes a central part of your business offering or how it works, then it might
 justify the investment to build your own at some stage. But initially, while you dip your toes to see where generative 
AI solutions, like a chatbot, fit within your business. It‚Äôs probably best to just optimize for learning quickly and get
ting something live.

## So, what next?

The best thing you can do for your business is to start. Today.

The average [m
yaskai.com](https://myaskai.com/?utm_source=reddit&utm_medium=organic&utm_content=why-not-build) customer has their firs
t AI chatbot live in under 10 mins.

I‚Äôve now helped over 30,000 businesses build an AI chatbot, trained on their own da
ta and content, branded and personalized, and launched to where their customers or employees most need it.
```
---

     
 
all -  [ Increasing the performance of retrievers ](https://www.reddit.com/r/LangChain/comments/15n8n06/increasing_the_performance_of_retrievers/) , 2023-08-11-0909
```
I have noticed that I am being faced with a lot of inconsistencies when it comes some answers. I am already using a cust
om router and a custom agent, but I am using the retrievers that comes with each vectorstore. But I realised that even w
hen saving the vectorstore and loading it, the performance of my chatbot has been inconsistent.  
Sometimes it answers a
 certain question, sometimes no. Sometimes I need to make very small changes into my input query for it to work. And the
n sometimes it just never finds the answer to my question, despite the answer being clearly found in the document.  
Thi
s is to note that I have already testing the different chunking approaches and found the one that apparently suits my da
ta the best. But I have no idea how to fix the inconsistency issue and how to increase the performance of the retriever 
after experimenting with both different embeddings and different vectorstores. and even different chain types.

Is there
 a way where I can first of all print the chunks that I am retrieving to make sure that when the chatbot states that he 
did not find the answer in the documents, the answer was really not in these chunks.  
What is some approaches I can tak
e to increase the consistency and performance of my retriever?
```
---

     
 
all -  [ Django eating up api calls during system checks. ](https://www.reddit.com/r/django/comments/15n8cli/django_eating_up_api_calls_during_system_checks/) , 2023-08-11-0909
```
I am in college and have this app I'm building with langchain and openAI. 
I'm using chatgpt 3.5T with it. 
Lately I saw
 increased quota usage ever since we started testing our app. Today I ran the app and saw that during system checks, it 
showed me the error that my openAI account has run out of usage credits. 

I've increased the limit by 2 dollars but I c
an't figure out how to stop the system checks from running the api calls again and again and eating up my credits while 
I change each line of code and test my app. 

Please help me out. Thank you.
```
---

     
 
all -  [ Using prompt templates after LoRA on raw text ](https://www.reddit.com/r/LocalLLaMA/comments/15n84m8/using_prompt_templates_after_lora_on_raw_text/) , 2023-08-11-0909
```
Hello all, 

I'm a little overwhelmed with all the developments and I feel like I don't know where to begin. So I apolog
ise if this question sounds very basic.

Let's say I want my LLM to sound like Phoebe Buffay from Friends. I don't have 
a QnA format, but just raw text for this purpose. 

As I understand, I can perform LoRA using the WebUI.

Once my fine t
uned model is ready, I want to use this to be able to converse with the user using specific prompts.

My question is, ca
n I feed this fine tuned model to LangChain so I can use their prompt template successfully? Or are there alternatives? 


Or can I do all of this using HuggingFace? 

Sorry, I'm very lost and I can't seem to understand if the finetuned mode
ls can be used by other frameworks.
```
---

     
 
all -  [ Help - Categorizing documents by content? ](https://www.reddit.com/r/LangChain/comments/15n6nld/help_categorizing_documents_by_content/) , 2023-08-11-0909
```
Does anyone know of a solution to categorize many documents into different headers based on their content? For example t
he prompt would be 'categorize which documents refer to concept x, y, and z.' 

Output:

X:
Doc 1,
Doc 52,
Doc 80

Y:
Do
c 7, Doc 52

Z:
Doc 2
```
---

     
 
all -  [ Best solution to deal with context and high token consumption ](https://www.reddit.com/r/OpenAI/comments/15n6b93/best_solution_to_deal_with_context_and_high_token/) , 2023-08-11-0909
```
Hi

I'm pretty new in this AI field and currently working on a mobile app chatbot. The AI part would

\- Have a specific
  behavior and multiple predefined tasks as the app is focused on a specific domain (health)

\- Connect to internal API
s to retrieve data from the project backend

For testing purposes, I am currently  storing user's history in a messages 
object in Mongo, then sending the whole history each time to GPT. When it's the very first call from the user I append t
he system instructions as the first prompt of the history.

The system instructions is by itself quiet token consuming a
nd the more messages get stored the faster I get limited by the API..

I heard about Rasa AI, Langchain, vectors DB, emb
edding and fine-tuning.

I tried to get GPT summarize the conversation each 10 or so messages but the result isn't  inte
resting (at all).

The ideal solution would be to host an open source AI somewhere in the future but I would like to hav
e some insights about what would be the best option  right now to handle this issue.

Thanks a lot.
```
---

     
 
all -  [ Return Source Documents (PDFs) with a source snippets. ](https://www.reddit.com/r/LocalLLaMA/comments/15n36uh/return_source_documents_pdfs_with_a_source/) , 2023-08-11-0909
```
Hi,
is it anyhow possible to return the source documents with a snippet in a PDF Q&A Chatbot of the sources the LLM was 
given for creating the answer?
I know that there is in langchain a function for that but in my case it's only giving me 
the name of the
PDF, not a snippet of the lines which were taken.
```
---

     
 
all -  [ Return Source Documents (PDFs) with a source snippets. ](https://www.reddit.com/r/LangChain/comments/15n33ea/return_source_documents_pdfs_with_a_source/) , 2023-08-11-0909
```
Hi,

is it anyhow possible to return the source documents with a snippet in a PDF Q&A Chatbot of the sources the LLM was
 given for creating the answer? 

I know that there is in langchain a function for that but in my case it‚Äôs only giving 
me the name of the PDF, not a snippet of the lines which were taken.
```
---

     
 
all -  [ CtrlX Search - New paradigm of video search ](https://www.reddit.com/r/LangChain/comments/15n323s/ctrlx_search_new_paradigm_of_video_search/) , 2023-08-11-0909
```
Hey everyone üôÇ

We've developed an exciting beta testbed over at [CtrlX Video](https://dev.ctrlx.video/?utm_srouce=reddi
t-langchain). It‚Äôs an engine that enables deep searches within videos using AI. Here's a brief overview:

‚Ä¢ Search capab
ilities: Extract key video features like actions, objects, on-screen text, speech, and more.

‚Ä¢ Fast Search: Convert vid
eo info into vector representations for quick, scalable semantic search.

‚Ä¢ Potential Uses: From contextual advertising 
to content moderation and even natural language-based CCTV footage search.

‚Ä¢ API Integration: Easy integration for devs
 to make videos searchable with just a few API calls. We're seeking feedback to refine it further. Please check out our 
playground, loaded with sample YouTube videos (total 10 hours, 170 vids) for you to try.

https://i.redd.it/91rxlmi8x7hb
1.gif

Feel free to reach out if you'd like to explore the API or upload your own videos. \[email: [xavier@ctrlx.video](
mailto:xavier@ctrlx.video)\] Your insights will be invaluable! üôè
```
---

     
 
all -  [ [D] training a model for function calls ](https://www.reddit.com/r/MachineLearning/comments/15n1j52/d_training_a_model_for_function_calls/) , 2023-08-11-0909
```
would it be possible to train or fine-tune a small (1-3B) model who's sole purpose is to perform function calls? similar
 to how we have tiny models like replit-v2-3B that are super capable at specific things like code auto-complete .  


i 
know that's how openAI implemented function call was by fine-tuning gpt-3.5/4 but I'm thinking just a straight up base m
odel trained to understand and excel at function calls (similar to Gorilla for apis)

i'm thinking it would be a perfect
 'glue' for bigger LLM apps-- avoiding the need for external tools like langchain/quidance/etc...
```
---

     
 
all -  [ What are the text chunking/splitting and embedding best practices for RAG applications? ](https://www.reddit.com/r/LocalLLaMA/comments/15mq1ri/what_are_the_text_chunkingsplitting_and_embedding/) , 2023-08-11-0909
```
I'm trying to make an LLM powered RAG application without LangChain that can answer questions about a document (pdf) and
 I want to know some of the strategies and libraries that you guys have used to transform your text for text embedding. 
I would also like to know which embedding model you used and how you dealt with the sequence length.  


My documents wi
ll be long textbooks and I'm currently using the MTEB text embedders from Hugging Face which all have sequence lengths o
f 512. 

 
```
---

     
 
all -  [ QnA system that supports multiple file types[PDF, CSV, DOCX, TXT, PPT, URLs] with LangChain on Colab ](https://www.reddit.com/r/LargeLanguageModels/comments/15mlfwn/qna_system_that_supports_multiple_file_typespdf/) , 2023-08-11-0909
```
In this video, we will discuss how to create a QnA system that supports multiple file types such as PDF, CSV, EXCEL, PPT
, DOCX, TXT, and URLs. All of these files utilize a single vector space and collaborate in the QnA process.
https://yout
u.be/5XZb3Mb2ioM
```
---

     
 
all -  [ QnA system that supports multiple file types[PDF, CSV, DOCX, TXT, PPT, URLs] with LangChain on Colab ](https://www.reddit.com/r/LangChain/comments/15mld5x/qna_system_that_supports_multiple_file_typespdf/) , 2023-08-11-0909
```
In this video, we will discuss how to create a QnA system that supports multiple file types such as PDF, CSV, EXCEL, PPT
, DOCX, TXT, and URLs. All of these files utilize a single vector space and collaborate in the QnA process.

https://you
tu.be/5XZb3Mb2ioM
```
---

     
 
all -  [ GGML and GPTQ on langchain ](https://www.reddit.com/r/LangChain/comments/15mkp1w/ggml_and_gptq_on_langchain/) , 2023-08-11-0909
```
I have a pretty basic pc, with a 4GB 1650ti and 16 GB RAM, I usually use collab to play around with these models, but I 
wanted to learn to use them locally, with langchain, with these specs I didn't have much options but go for GGML or GPTQ
 versions of Llama2 by TheBloke, I tried the whole day to get it to work, but whatever resource I used got me nothing, t
hat made me work.   

&#x200B;

It is also on me not knowing everything clearly, but again the progress has been really 
quick with the LLM stuff, and I've been trying to learn. I have tried all I could before posting this here, so it would 
be a great help if someone could guide me for the same.  

Following is the code I tried

\`\`\`

tokenizer = AutoTokeni
zer.from\_pretrained('localmodels/Llama-2-7B-GPTQ',  
 use\_auth\_token=True,)  
model = AutoModelForCausalLM.from\_pret
rained('localmodels/Llama-2-7B-GPTQ',  
 device\_map='auto',  
 torch\_dtype=torch.float16,  
 use\_auth\_token=True)

\
`\`\`
```
---

     
 
all -  [ Is there a way to have gpt4all query against localdocs only? ](https://www.reddit.com/r/LangChain/comments/15mk62w/is_there_a_way_to_have_gpt4all_query_against/) , 2023-08-11-0909
```
Is there a way to have gpt4all return results based on files in localdocs only and not rely on it's already trained DB? 
 
```
---

     
 
all -  [ Build quickchat.ai Replica ](https://www.reddit.com/r/LangChain/comments/15mfvc2/build_quickchatai_replica/) , 2023-08-11-0909
```
Hi,I want to build a site similar to [quickchat.ai](https://quickchat.ai) and I'm looking for foundational code to get s
tarted.Are there any open source projects which I could use to get started on the project. Because there are a lot of ch
atbot with knowledgebase products already in the market.Also if anyone has idea of the 3rd party tools i could use to ge
t started instead of developing every feature from scratch.  


Please share any insights that u feel would be helpful


Thanks
```
---

     
 
all -  [ A minimalistic LangChain course ](https://www.reddit.com/r/LangChain/comments/15mfhkb/a_minimalistic_langchain_course/) , 2023-08-11-0909
```
Hello everybody,

I've been creating LangChain apps for the last few months and I decided to put together all the concep
ts I found more useful and a mini-course, that reflects my own way of learning things: straightforward and without noise
.

The course is a Streamlit app, with interactive demos for each component. This way the user can immediately play with
 it, and then write his own code to reinforce the concepts.

If anyone wants to take a look, I would really appreciate s
ome feedback: [https://learnlangchain.org/](https://learnlangchain.org/)

The course also contains 4 hands-on projects, 
and I plan to add more interesting concepts, like a deep dive on document splitters, agents, and more demos of course. F
or now is just an MVP.

All the code, for the course and the projects is open source, of course :)

Thanks in advance,


Francesco
```
---

     
 
all -  [ Why is Awadb: The Open-Source Local AI-native vector database ](https://www.reddit.com/r/LangChain/comments/15mblmj/why_is_awadb_the_opensource_local_ainative_vector/) , 2023-08-11-0909
```
Awadb, an Open-Source AI-native vector database , stores and searches embedding vectors for LLM Applications, providing 
you with an efficient solution for local vector data management and queries in your environment. Below are some advantag
es of the Awadb vector database as a local database:

1. **High Performance and Low Latency:** Being a local database, A
wadb stores data on the local computer, enabling the full utilization of local hardware resources for achieving high per
formance and low-latency data access and queries.
2. **Privacy and Security:** Local databases often offer heightened da
ta privacy and security, as data doesn't need to be transmitted over the internet, reducing the risks of data leaks and 
security vulnerabilities.
3. **Offline Access:** A local database allows users to access data without an internet connec
tion, which proves highly beneficial in situations where connectivity to cloud servers is unavailable.
4. **Customizatio
n:** Local databases empower users with complete control over database configuration and management to suit specific nee
ds and requirements. This customization capability aids in optimizing performance and meeting distinct business needs.
5
. **Data Control:** With data stored locally, users can easily backup, restore, and manage data, ensuring data control a
nd stability.
6. **Reduced Cloud Costs:** For some small to medium-sized enterprises or projects, utilizing a local data
base may prove more cost-effective, circumventing the high costs associated with cloud services.
7. **Suitable for Edge 
Computing:** In scenarios demanding data processing and analysis on edge devices, a local database serves as an ideal ch
oice, providing rapid local computing capabilities.
8. **Offline Work:** Should you require the ability to continue work
ing without an internet connection, a local database ensures that you can access and manipulate data without being bound
 by network restrictions.

## Get Started

What will you build with the Awadb vector database?

If you are interested an
d want to learn more, please join us and get started now:

Github: [https://github.com/awa-ai/awadb](https://github.com/
awa-ai/awadb)

Discord: [https://discord.gg/GP7QxRrDjB](https://discord.gg/GP7QxRrDjB)
```
---

     
 
MachineLearning -  [ [D]Embedding model and vector store on LangChain ](https://www.reddit.com/r/MachineLearning/comments/15lllm0/dembedding_model_and_vector_store_on_langchain/) , 2023-08-11-0909
```
For Langchain users, what are the best text embedding models and vector stores (with similarity search) among the many i
ntegrations for connecting a AI model to text data? 

And does performance vary drastically from one model/database to a
nother? 
```
---

     
 
MachineLearning -  [ [P] Rust meets Llama2: OpenAI compatible API written in Rust ](https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/) , 2023-08-11-0909
```
Hello,

I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports
 offloading computation to  Nvidia GPU and Metal acceleration for GGML models !

Here is the project  link: [Cria- Local
 LLAMA2 API](https://github.com/AmineDiro/cria)

You can use it as an OpenAI replacement (check out the included \`Langc
hain\` example in the project).

This is an ongoing project, I have implemented the \`embeddings\` and \`completions\` r
outes. The \`chat-completion\` route will be here very soon!

Really interested in your feedback and I would welcome any
 help :) !

&#x200B;

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Document-based QnA without OpenAI? ](https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/) , 2023-08-11-0909
```
I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to ma
ke it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain
 only supports GPT but any other ideas are highly appreciated!
```
---

     
 
MachineLearning -  [ [D] Roadmap for AI engineer (implementation of language models on premise) ](https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/) , 2023-08-11-0909
```
 I worked for less than a year as a Data Engineer. I decided to look for other challenges and got a job as an AI enginee
r developing language models.

The product of the company that hired me is related to data and metadata management. My t
asks will be to introduce features to the product, including a chat function that will allow for asking questions about 
data. Other tasks will include research and proposing additional AI-related functionalities to the product (on premise).
 I have a two weeks left to start work and I need to prepare a bit. My job will involve implementing ready-made solution
s and conducting research (high level - I need to implement valuable features and no one cares how).

**What are the mos
t important things I should learn before starting work?**

First of all, I replicated a few applications from this blog:
 [https://blog.streamlit.io/tag/llms/](https://blog.streamlit.io/tag/llms/)

Then I have focused on Langchain. I'm also 
in the middle of a course on Udemy about Next-Gen AI projects - Beginner friendly - Langchain, Pinecone - OpenAI, Huggin
gFace & LLAMA 2 models

I need a roadmap that will guide me a bit. I'm looking for blogs/materials/courses that will giv
e me practical knowledge in this matter.
```
---

     
 
MachineLearning -  [ [D] Having trouble with RAG on company domain data ](https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/) , 2023-08-11-0909
```
I have a data set that isn't that large \~200 pdfs. I have done the regular RAG approach with Langchain, extracting text
, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity sear
ch with a question I would like answered it returns the wrong context. The documents are semi-structured information of 
examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input th
is question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not e
xplicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chun
ks, but this does nothing.

Does anyone have any tips on improving the embeddings retrieval in this case?
```
---

     
 
MachineLearning -  [ [D] How do I reduce LLM inferencing time? ](https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/) , 2023-08-11-0909
```
I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface l
ibrary, and I am running the model on AWS ml.g4dn.12xlarge which has 4x**nvidia t4**, which gives a total 64GB of GPU me
mory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins
 for big queries.

The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in 
a conversational way. I've extracted the main parts of the notebook and put it up [here](https://colab.research.google.c
om/drive/1uFNkZ6FI0qffwRpW6ubfdq0HrCqcqVUi?usp=sharing).

Where can I make changes to speed up the transaction. Is there
 any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give a
n answer in less than 5 seconds. Are there any other areas I can optimise?

I appreciate any help you can provide. Thank
s!
```
---

     
 
MachineLearning -  [ [P] TruLens-Eval is an open source project for eval & tracking LLM experiments. ](https://www.reddit.com/r/MachineLearning/comments/1542fbt/p_trulenseval_is_an_open_source_project_for_eval/) , 2023-08-11-0909
```
Hey [r/MachineLearning](https://www.reddit.com/r/MachineLearning/),

The team at TruEra recently released an open source
 project for evaluation & tracking of LLM applications called [TruLens-Eval](https://github.com/truera/trulens/tree/main
/trulens_eval). We‚Äôve specifically targeted retrieval-augmented QA as a core use case and so far we‚Äôve seen it used for 
comparing different models and parameters, prompts, vector-db configurations and query planning strategies. I‚Äôd love to 
get your feedback on it.

The core idea behind the project is feedback functions. Analogous to labeling functions, feedb
ack functions are models used to score the text produced by LLMs. We already have a variety of out-of-the-box feedback f
unctions to use for eval including relevance, language match, sentiment and moderation that can be applied to inputs, ou
tputs or intermediate steps of your application.

On top of eval, there‚Äôs also built-in tracking of cost and latency.

W
e made it easy to integrate with different setups using connectors for langchain, llama-index + an option to use it with
out a framework.

[Langchain Quickstart Colab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-
trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/langchain_quickstart_colab.ipynb)

[Llama-Index Quickstart Co
lab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/c
olab/quickstarts/llama_index_quickstart_colab.ipynb)

[No Framework Quickstart Colab](https://colab.research.google.com/
github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/no_framework_quickstar
t_colab.ipynb)

Last, the project comes with a streamlit dashboard for visualization of your experiments and associated 
metrics.

[TruLens dashboard for comparing different app versions](https://preview.redd.it/q68b1l27pycb1.jpg?width=1233&
format=pjpg&auto=webp&s=cfb1704624a8b6642b249a32d0afee85ea9f62d9)

Please let us know what you use this for or if you ha
ve feedback! And thanks to all contributors to this project and the open source community!
```
---

     
 
MachineLearning -  [ Alternativ to langchain [D] ](https://www.reddit.com/r/MachineLearning/comments/15175na/alternativ_to_langchain_d/) , 2023-08-11-0909
```
Im currently learning hiw to use langchain but i heard that its bad so i want to know what are som alternatives i need m
emory and agents so that it can search online run code and so on so what is the best alternativ or is langchain the best
 option
```
---

     
 
MachineLearning -  [ '[N]' '[D]' Langchain? What is it?? ](https://www.reddit.com/r/MachineLearning/comments/150mzax/n_d_langchain_what_is_it/) , 2023-08-11-0909
```
want to know more about Langchain  
Check out [https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf](https:
//nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf)
```
---

     
 
MachineLearning -  [ [D] The Problem With LangChain ](https://www.reddit.com/r/MachineLearning/comments/14zlaz6/d_the_problem_with_langchain/) , 2023-08-11-0909
```
https://minimaxir.com/2023/07/langchain-problem/

tl;dr it's needlessly complex, and I provide code examples to demonstr
ate such.

A few weeks ago when I posted about creating a LangChain alternative to /r/MachineLearning, most of the comme
nts replied 'what exactly is the issue with LangChain', so I hope this provides more clarity!
```
---

     
 
MachineLearning -  [ [D] üìö The Learning Corner (Andrew NG Free Ai Courses Pt. 1) ](https://www.reddit.com/r/MachineLearning/comments/14xww89/d_the_learning_corner_andrew_ng_free_ai_courses/) , 2023-08-11-0909
```
üìö The Learning Corner (Andrew NG Free Ai Courses Pt. 1)

This is a list of some of the best Ai Free courses by Andrew NG
, we will release the second part of the list on our next newsletter installment (link)

* [**Generative AI with Large L
anguage Models**](https://www.deeplearning.ai/courses/generative-ai-with-llms/?utm_campaign=gaia-launch&utm_content=2545
85614&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18246783)
* [**LangChain: Chat With Your Data**](https://www
.deeplearning.ai/short-courses/langchain-chat-with-your-data/)
* [**LangChain for LLM Application Development**](https:/
/learn.deeplearning.ai/langchain)
* [**How Diffusion Models Work**](https://learn.deeplearning.ai/diffusion-model)
```
---

     
 
MachineLearning -  [ [P] langchain-lite alternative ](https://www.reddit.com/r/MachineLearning/comments/14xf9xb/p_langchainlite_alternative/) , 2023-08-11-0909
```
Although langchain is an impressive library, I tend to find it is‚Ä¶

* a little unintuitive, at least for non-trivial exa
mples or examples that don‚Äôt have a predefined chains/templates
* related, it's overly prescriptive; and the various lev
els of abstraction don't resonate with me
* related, can be difficult to debug or understand what‚Äôs happening in interme
diate steps of the chain or what‚Äôs it‚Äôs actually sending OpenAI

So, I built a ‚Äúlangchain-lite‚Äù package called `llm-work
flow`

https://github.com/shane-kercheval/llm-workflow

The value proposition is basically:

* easily build up a sequenc
e of tasks (e.g. prompt-template -> chat) called a workflow, where the output of one task serves as the input to the nex
t task in the workflow
* **track history**; understand what's happening in each of the tasks; **aggregate token usage, c
osts, etc. across the workflow**

So a workflow can be anything from `prompt -> chat -> response` to `prompt -> web-sear
ch -> web-scraping -> vector-database & retrieval -> modified prompt -> chat -> response`.

Here's an example of a 'prom
pt enhancer' workflow, where the user provides a prompt, one model enhances/improves the prompt, and the second model an
swers the question based on the enhanced prompt.

```python
prompt_enhancer = OpenAIChat(...)
chat_assistant = OpenAICha
t(...)

def prompt_template(user_prompt: str) -> str:
    return 'Improve the user's request, below, by expanding the re
quest ' \
        'to describe the relevant python best practices and documentation ' \
        f'requirements that shou
ld be followed:\n\n```{user_prompt}```'

def prompt_extract_code(_) -> str:
    # `_` signals that we are ignoring the i
nput (from the previous task)
    return 'Return only the primary code of interest from the previous answer, '\
        
'including docstrings, but without any text/response.'

workflow = Workflow(tasks=[
    prompt_template,      # modifies
 the user's prompt
    prompt_enhancer,      # returns an improved version of the user's prompt
    chat_assistant,     
  # returns the chat response based on the improved prompt
    prompt_extract_code,  # prompt to ask the model to extrac
t only the relevant code
    chat_assistant,       # returns only the relevant code from the model's last response
])
pr
ompt = 'create a function to mask all emails from a string value'
response = workflow(prompt)
```

The `response` is: `d
ef mask_email_addresses(string): .....`

We can view the history, which includes the prompts/responses/tokens/etc. for e
ach interaction:

```python
print(workflow.history())
```

Output:

```
[
    ExchangeRecord(prompt='Improve the user's 
request, below, by ...', response='Create a Python function that adheres to best practice...', timestamp='2023-07-12 04:
45:04.703', cost=0.00063, total_tokens=333, prompt_tokens=58, response_tokens=275),
    ExchangeRecord(prompt='Create a 
Python function that adheres ...', response='Sure! Here\'s an example of a Python function that adh...', timestamp='2023
-07-12 04:45:14.696', cost=0.00149, total_tokens=820,  prompt_tokens=292, response_tokens=528),
    ExchangeRecord(promp
t='Return only the primary code of intere...', response='```python\nimport re\n\ndef mask_email_addresses(strin...', tim
estamp='2023-07-12 04:45:18.875', cost=0.00167, total_tokens=1051, prompt_tokens=850, response_tokens=201)
]
```

We can
 also summarize costs/tokens/etc.

```python
print(workflow.sum('cost'))             # 0.0034
print(workflow.sum('total_
tokens'))     # 1961
print(workflow.sum('prompt_tokens'))    # 1104
print(workflow.sum('response_tokens'))  # 857
```

M
ore examples can be found here: https://github.com/shane-kercheval/llm-workflow/tree/main/examples

Feedback welcome.
```
---

     
 
deeplearning -  [ Using PDFs with GPT Models ](https://www.reddit.com/r/deeplearning/comments/15g6i4x/using_pdfs_with_gpt_models/) , 2023-08-11-0909
```
Found a blog talking about how we can interact with PDFs in Python by using GPT API & Langchain. It talks about some pre
tty cool automations you can build involving PDFs - [https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-g
pt-api/](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/)
```
---

     
