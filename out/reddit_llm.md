 
all -  [ Are there any tools to build bespoke LLM apps using customized datasets? ](https://www.reddit.com/r/artificial/comments/15gme3k/are_there_any_tools_to_build_bespoke_llm_apps/) , 1691016033.0
```
I know we can stitch together toolsets like LangChain + Flowise + an app builder (like Bubble, for example). But are the
re any robust, premade, out-of-the-box solutions?
```
---

     
 
all -  [ Querying Multiple Databases SQLDatabaseChain ](https://www.reddit.com/r/LangChain/comments/15gm0j0/querying_multiple_databases_sqldatabasechain/) , 1691015141.0
```
Is there an example where we can configure multiple databases as different tools and query them. It is currently configu
red where I have multiple chains for each database but every time I query, it will always revert to the first chain. 
```
---

     
 
all -  [ SQLDatabaseTools and RetrieveralQA Chain having trouble with understanding Parent Children relations ](https://www.reddit.com/r/LangChain/comments/15gju3c/sqldatabasetools_and_retrieveralqa_chain_having/) , 1691008107.0
```
I have a DB that uses a general ledger system, which has a Kimball's Dimensional Modeling Hierarchy for Income/Expenses.
 My Retriever is having trouble recognizing these relationships from the hand written documentation. I would appreciate 
any tips on how to better contextualize those relationships for more accurate join queries, using like a graph or someth
ing. Please let me know!
```
---

     
 
all -  [ Web scraper built with LangChain & OpenAI Functions ](/r/LangChain/comments/15g9xnk/web_scraper_built_with_langchain_openai_functions/) , 1690991450.0
```

```
---

     
 
all -  [ Web Scraping with OpenAI Functions and LangChain (Python) ](https://www.reddit.com/r/LLMDevs/comments/15g9yii/web_scraping_with_openai_functions_and_langchain/) , 1690985464.0
```
Web scraping requires keeping up to date with layout changes from target website; but with LLMs, you can write your code
 once and forget about it.

Video: [https://www.youtube.com/watch?v=0gPh18vRghQ](https://www.youtube.com/watch?v=0gPh18v
RghQ)

Code: [https://github.com/trancethehuman/entities-extraction-web-scraper](https://github.com/trancethehuman/entit
ies-extraction-web-scraper)

If you have any questions, drop them in the comments. I'll try my best to answer.
```
---

     
 
all -  [ Web scraper built with LangChain & OpenAI Functions ](https://www.reddit.com/r/LangChain/comments/15g9xnk/web_scraper_built_with_langchain_openai_functions/) , 1690985408.0
```
Web scraping requires keeping up to date with layout changes from target website; but with LLMs, you can write your code
 once and forget about it.

Video: [https://youtu.be/0gPh18vRghQ](https://youtu.be/0gPh18vRghQ)

Code: [https://github.c
om/trancethehuman/entities-extraction-web-scraper](https://github.com/trancethehuman/entities-extraction-web-scraper)

I
f you have any questions, drop them in the comments. I'll try my best to answer.
```
---

     
 
all -  [ Extraction/ information retrieval from langchain using extraction chain and pydantic output parser ](https://www.reddit.com/r/LangChain/comments/15g9dgz/extraction_information_retrieval_from_langchain/) , 1690984014.0
```
So basically I want to extract/pull data in pdfs in the following way pdf>text>llm> json or any key value pair structure
 tha I convert into CSV later. 
When I use just the extraction chain with schema, a lot of data/value is mismatched or e
ntered into wrong fields / keys. This is extremely difficult to clean manually later because of the large amount of data
 , not is it possible to go through each record one by one.


When I tried the pydantic output parser, which allows for 
additional prompt, it still didn't workout very well

Most frustrating part of trying both is that it throws  a Json dec
ode or element missing error and I have unsuccessfully tried to figure out what might be the reason for that

The extrac
tion chain works bit better than the pydantic output parser, but I am not aware if there is a way to tweak the prompt or
 include examples in the schema based extraction chain (it takes only 3 arguments , schema, llm, verbose Boolean )


Als
o note that ocr and regex are not options I want to try as of now

Tldr: trouble getting Structured data out of an unstr
uctured pdf using langchain or llms
```
---

     
 
all -  [ How to include agents and tools with a document querying chatbot? ](https://www.reddit.com/r/LangChain/comments/15g96s6/how_to_include_agents_and_tools_with_a_document/) , 1690983529.0
```
Novice here, been trying out document querying on text files for a while. There are agents and tools with LangChain. Can
 I use them with along with document querying? 

I don't know how to explain as am new to LangChain.
```
---

     
 
all -  [ Free courses and guides for learning Generative AI ](https://www.reddit.com/r/ChatGPTPromptGenius/comments/15g949b/free_courses_and_guides_for_learning_generative_ai/) , 1690983346.0
```
1. **Generative AI learning path by Google Cloud.** A series of 10 courses on generative AI products and technologies, f
rom the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud \[[*Li
nk*](https://www.cloudskillsboost.google/paths/118)\].
2. **Generative AI short courses** **by** **DeepLearning.AI** \- 
Five short courses on generative AI including **LangChain for LLM Application Development, How Diffusion Models Work** a
nd more. \[[*Link*](https://www.deeplearning.ai/short-courses/)\].
3. **LLM Bootcamp:** A series of free lectures by **T
he full Stack** on building and deploying LLM apps \[[*Link*](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023
/)\].
4. **Building AI Products with OpenAI** \- a free course by **CoRise** in collaboration with OpenAI \[[*Link*](htt
ps://corise.com/course/building-ai-products-with-openai)\].
5. Free Course by **Activeloop** on **LangChain & Vector Dat
abases in Productio**n \[[*Link*](https://learn.activeloop.ai/courses/langchain)\].
6. **Pinecone learning center -** Lo
ts of free guides as well as complete handbooks on LangChain, vector embeddings etc. by **Pinecone** **\[**[**Link**](ht
tps://www.pinecone.io/learn/)**\].**
7. **Build AI Apps with ChatGPT, Dall-E and GPT-4  -** a free course on **Scrimba**
 **\[**[*Link*](https://scrimba.com/learn/buildaiapps)**\].**
8. **Gartner Experts Answer the Top Generative AI Question
s for Your Enterprise** \- a report by Gartner \[[*Link*](https://www.gartner.com/en/topics/generative-ai)\]
9. **GPT be
st practices:** A guide by **OpenAI** *t*hat shares strategies and tactics for getting better results from GPTs *\[*[*Li
nk*](https://platform.openai.com/docs/guides/gpt-best-practices)\].
10. **OpenAI cookbook by OpenAI -** Examples and gui
des for using the OpenAI API **\[**[*Link*](https://github.com/openai/openai-cookbook/tree/main)**\].**
11. **Prompt inj
ection explained**, with video, slides, and a transcript from a webinar organized by LangChain \[[*Link*](https://simonw
illison.net/2023/May/2/prompt-injection-explained/)\].
12. A detailed guide to **Prompt Engineering by** **DAIR.AI** *\[
*[*Link*](https://www.promptingguide.ai/)*\]*
13. What Are **Transformer Models** and How Do They Work. A tutorial by **
Cohere AI** \[[*Link*](https://txt.cohere.ai/what-are-transformer-models/)\]
14. **Learn Prompting:** an open source cou
rse on prompt engineering\[[Link](https://learnprompting.org/docs/intro)\]

**P.S. These resources are part of the conte
nt I share through my AI-focused** **newsletter,** [AI Brews.](https://aibrews.com/) \- it's free to join, sent only onc
e a week with bite-sized news, learning resources and selected tools. Thanks!
```
---

     
 
all -  [ Using PDFs with GPT Models ](https://www.reddit.com/r/deeplearning/comments/15g6i4x/using_pdfs_with_gpt_models/) , 1690976012.0
```
Found a blog talking about how we can interact with PDFs in Python by using GPT API & Langchain. It talks about some pre
tty cool automations you can build involving PDFs - [https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-g
pt-api/](https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/)
```
---

     
 
all -  [ Learning Guide Help ](https://www.reddit.com/r/LargeLanguageModels/comments/15g4mqt/learning_guide_help/) , 1690970115.0
```
I'm a student and an intern trying to figure out how to work with LLMs. I have a working knowledge of python and back-en
d web development and I want to learn how to work with LLMs.

At first I tried learning PyTorch, but I found it to be mo
re like Matlab than actually LLMs. This is what I was looking for:

    '''
I was looking for a library that included th
e following functions:
    importLLM : imports the LLM downloaded from HuggingFace or MetaAI
    addDataToLLM : imports 
the data into the LLM Database, as in fine tuning or creating a database that the LLM is familiarised with
    queryLLM 
: queries text into the LLM Model
    '''

Now I'm learning a bit of LangChain using [this tutorial](https://www.youtube
.com/watch?v=dXxQ0LR-3Hg) but it doesn't teach me how to deploy an LLM.

If you have any recommendations I would love to
 check them out.

Best regards!
```
---

     
 
all -  [ Released all MLOps & LLMOps products & companies mapping -- LLMOps.Space ](https://i.redd.it/whcwysimnnfb1.png) , 1690963933.0
```

```
---

     
 
all -  [ [FOR HIRE] Python Expert Freelancer for Machine Learning and AI Domain Projects ](https://www.reddit.com/r/hiring/comments/15g2qg7/for_hire_python_expert_freelancer_for_machine/) , 1690963748.0
```
Location: Remote

Salary: Negotiable based on project scope and complexity

Description:

Hello there,

Are you in need 
of a skilled and passionate Python expert for your machine learning or AI domain freelancing project? Look no further! I
'm Shephin Philiip, a dedicated and results-oriented professional with extensive experience in machine learning, deep le
arning, and data analytics.

With an MSc in Computer Science and a strong academic background from Kannur University, I'
ve honed my skills and expertise through diverse and impactful projects. One notable project I completed involved develo
ping an Indian Sign Language Detection system using Convolutional Neural Networks (CNN), showcasing my ability to bridge
 communication gaps for individuals with hearing impairments through cutting-edge computer vision techniques.

I'm well-
versed in machine learning algorithms, deep learning frameworks, and data analytics tools, including Python, TensorFlow,
 Keras, and SQL. This expertise allows me to efficiently analyze complex datasets, derive meaningful insights, and imple
ment solutions that drive real-world impact.

&#x200B;

Recently, I've been actively involved in two exciting projects t
hat demonstrate my technical prowess. I developed an AI Chatbot Chrome Extension, powered by OpenAI API, providing users
 with real-time conversations and handling a wide range of topics and questions. Additionally, I created the Github-Auto
mated-Analysis-Mercor, a Python-based tool that utilizes GPT-3 and LangChain to assess the technical complexity of GitHu
b repositories. These projects reflect my dedication to staying at the forefront of technological advancements and solvi
ng complex challenges.

&#x200B;

As a Python expert with ML experience in Tensorflow and PyTorch, I'm well-equipped to 
take on machine learning engineering tasks and deliver high-quality results. Additionally, my skills extend to FullStack
 Development with Django and Flask APIs, enabling me to create robust and scalable applications.

&#x200B;

\*\*Price an
d Payment Method:\*\*

Regarding the price for my freelance services, I am open to negotiation based on the scope and co
mplexity of the project. I offer competitive rates and flexible payment terms to accommodate your needs.

&#x200B;

\*\*
Contact Information:\*\*

Feel free to reach out to me via  messages. I'm eager to discuss further how we can work toget
her to achieve outstanding results.

&#x200B;

I am excited about the opportunity to collaborate with you on your projec
t and contribute my expertise to its success. If you're looking for a driven and highly skilled freelancer to join your 
team, I am confident that my passion for machine learning, deep learning, and data analytics will make me a valuable ass
et to your project.

&#x200B;

Best regards,

Shephin Philiip
```
---

     
 
all -  [ List of all MLOps & LLMOps companies -- LLMOps.Space ](https://i.redd.it/d26rgf9fmnfb1.png) , 1690963455.0
```

```
---

     
 
all -  [ understanding the llm eco-system ](https://www.reddit.com/r/LocalLLaMA/comments/15g1flo/understanding_the_llm_ecosystem/) , 1690959255.0
```
beginner in llms here. i have been trying to make sense of the lifecycle of a model. here's what i have:

- people usual
ly release their models via huggingface, similar to other ml models.

- these are often too big and need to be quantized
 to be able to run on cpu-s or consumer gpu-s. this is done by a library such as ggml ( is exllama an alternate?)

- the
n the llms can be used as part of larger pipelines, like retrival-augmented-generation, or in agents. libraries like lan
gchain help for these pipelines.

- when making a frontend like a conventional chatbot, libraries like oogabooga help.


- for specific parts of particular pipelines like RAG, llamaindex and unstructured.io provide dedicated facilities ( dea
ling with different types of documents etc)

can anyone correct me here. also would invite people to add other big names
 i dont know of that are significant parts of the ecosystem
```
---

     
 
all -  [ How to get a software engineering job at LangChain? ](https://www.reddit.com/r/LangChain/comments/15g15ke/how_to_get_a_software_engineering_job_at_langchain/) , 1690958307.0
```
I’m a software engineer who recently started using langchain and am super impressed with it. Does anyone know how any in
formation about working at Langchain? are they hiring?
```
---

     
 
all -  [ Having issues with multi-step reasoning ](https://www.reddit.com/r/LangChain/comments/15fyjd3/having_issues_with_multistep_reasoning/) , 1690949855.0
```
I've recently started out with LangChain, and I'm struggling with an issue. Although the code seems correct, the output 
is quite questionable. Here's my current code:

```
from langchain.chat_models import ChatOpenAI 
from langchain_experim
ental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner 
from langchain.llms import OpenAI 

from langchain import SerpAPIWrapper 
from langchain.agents.tools import Tool 
from langchain import LLMMathChain 

mod
el = ChatOpenAI(temperature=0, model='gpt-3.5-turbo-0613', verbose=True,openai_api_key='...') 

search = SerpAPIWrapper(
serpapi_api_key='...') 

llm_math_chain = LLMMathChain.from_llm(llm=model, verbose=True) 

tools = [ 
    Tool( 
       
 name = 'Search', 
        func=search.run, 
        description='useful for when you need to answer questions about cur
rent events. You should ask targeted questions' 
    ), 
    Tool( 
        name='Calculator', 
        func=llm_math_ch
ain.run, 
        description='useful for when you need to answer questions about math' 
    ) 
] 

planner = load_chat_
planner(model) 
executor = load_agent_executor(model, tools, verbose=True) 
agent = PlanAndExecute(planner=planner, exec
utor=executor, verbose=True) 

agent.run('Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 p
ower?')
```

During the Find her current agestep, the response was:

Based on the search results, it seems that Leonardo
 DiCaprio has been linked with a 19-year-old model named Eden Polani. However, I couldn't find any specific information 
about her current age. It's possible that her age is not widely known or publicly available. 

Clearly, the model mentio
ns her age but fails to recognize it in the following statement. It's perplexing, given that this example is directly fr
om the documentation. Did I miss something?

For reference, I initially attempted the example without the experimental l
ibraries:

```
llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo-0613', verbose=True,openai_api_key='sk-u98IvxbZscoIP
3KloWn8T3BlbkFJVRBBHt9T34BNmtjbZmUt')
search = SerpAPIWrapper()
llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=
True)

tools = [
    Tool(
        name = 'Search',
        func=search.run,
        description='useful for when you ne
ed to answer questions about current events. You should ask targeted questions'
    ),
    Tool(
        name='Calculato
r',
        func=llm_math_chain.run,
        description='useful for when you need to answer questions about math'
    )

]

agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)

```

Here, the output was:

  
  'Leo DiCaprio's girlfriend ** 0.43'

It seems to first calculate the math part, which again, is not as per the documen
tation.

Any guidance or suggestions would be greatly appreciated! Thanks in advance.
```
---

     
 
all -  [ Has anyone been able to get GGML models working with Langchain Agents ](https://www.reddit.com/r/LocalLLaMA/comments/15fygru/has_anyone_been_able_to_get_ggml_models_working/) , 1690949633.0
```
I have tried with LLAMA2-7B 8 bit quantized, Gorilla 7b ggml 8bit models. It integrates correctly with Langchain. I adde
d two tools Wikipedia and DuckDuckgo search. I asked it when was Barrack Obama born? Straight forward question. 

The Ac
tion it outputs is not restricted. It should output 
Action:DuckDuckgo 
Action Input: Barrack Obama birthday

Instead it
 outputs 
Action: DuckDuckgo Barrack Obama birth date 

And some other stuff in action Input like barrack Obama's birthd
ay correct year etc. 

The problem is Langchain needs an exact match and not a fuzzy match. Hence it says such a tool do
es not exist and does not do the search. 

I am checking if anyone has ever got Langchain Agents working with GGML model
s and could figure out a way to output properly ( in a reproducible manner).
```
---

     
 
all -  [ Masters in ML while working FT ](https://www.reddit.com/r/GradSchool/comments/15fxipn/masters_in_ml_while_working_ft/) , 1690946810.0
```
Hey everyone,

I’m a software engineer by trade and I was recently placed on a project with AI and LLMs and I enjoyed it
 pretty thoroughly. My one nag is that I realize this is a bit of a fad and I personally just would like to get a better
 understanding of how these technologies work and not just know how to call functions as part of the langchain framework
. Plus I could get skills that last longer than the cycle of this AI craze and have things that carry over beyond the sc
ope of this type of work. I’m close to GTech and I know there school is a very accredited institution so getting into gr
ad school there is no walk in the (Piedmont) park especially for smth like ECE/CS. For context, my undergrad gpa was 3.1
 from UIUC in ECE so maybe if anyone knows of any universities with higher chances of getting in for a AI/ML program dro
p them below and let me know your thoughts/challenges for those of you who have gone back to school while working full t
ime

Cheers
```
---

     
 
all -  [ I'm just curious about AI chatbots lately! Why are they getting popular?? ](https://www.reddit.com/r/startups/comments/15fwnbs/im_just_curious_about_ai_chatbots_lately_why_are/) , 1690944271.0
```
Actually, I spend a lot of time on Twitter, and realized that indie hackers or startup founders seem to be so interested
 in AI chatbot-based Langchain! (a.k.a. LLM)

So searched for them and they look so pretty useful!  
You know, there are
 a vireaety of bots or AI assistant:  
\-  C/S for my business  
\- Educational AI chatbot  
\- AI Community Facilitator
  
\- Educative Q/A chatbot  
...what else?  


Anyway excited to hear your thoughts! Let's dive into the AI world toget
her!  
If you could get an AI chatbot or assistant for free, which one would you get or create?

&#x200B;
```
---

     
 
all -  [ How to filter output from similarity_search with DeepLake? ](https://www.reddit.com/r/LangChain/comments/15frx3u/how_to_filter_output_from_similarity_search_with/) , 1690931386.0
```
I am using a DeepLake database to store vector embeddings for chunks of PDF documents and I am using a similarity search
 query from that database to plug into a chat prompt. In the interest to minimizing token usage, I don't want to plug th
e full return value from the query into the prompt because I don't need the metadata in the prompt. Is there a way to fi
lter out just the page\_content values from the Document object?
```
---

     
 
all -  [ Best way to run Llama 2 locally on GPUs for fastest inference time ](https://www.reddit.com/r/LocalLLaMA/comments/15fq8b0/best_way_to_run_llama_2_locally_on_gpus_for/) , 1690927218.0
```
I've been working on having a local llama 2 model for reading my pdfs using langchain but currently inference time is to
o slow because I think its running on CPU's with the GGML version of the model. So what would be the best implementation
 of llama 2 locally? This includes which version (hf, ggml, gptq etc) and how I can maximize my GPU usage with the speci
fic version because I do have access to 4 Nvidia Tesla V100s
```
---

     
 
all -  [ What do you need to evaluate LLMs in dev & prod? Tell us and we'll build it! ](https://docs.google.com/forms/d/e/1FAIpQLScfZ_4MSVmsiaoEByb_Y2tk--J-xtV35P6OnAiyaihbrjwlQQ/viewform) , 1690920544.0
```

```
---

     
 
all -  [ Question answering over docs with wikipedia or is it to large? ](https://www.reddit.com/r/LangChain/comments/15fez03/question_answering_over_docs_with_wikipedia_or_is/) , 1690901922.0
```
Does anybody know if there already is an 'Question answering over Docs with sources' project accessing wikipedia? I assu
me it would take a while creating the vectorstore, if that even is necessary?
```
---

     
 
all -  [ Autonomous Agents Hackathon | 18 - 20 Aug | $10K Prize ](https://superagi.com/autonomous-agents-hackathon/) , 1690899149.0
```

```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15f8cq8/peter_buildfast_masterclass_learn_to_build_your/) , 1690884918.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ im curious since Langchain is in itself a wrapper do you think you could do decorator chaining and w ](https://www.reddit.com/r/LangChain/comments/15f7pin/im_curious_since_langchain_is_in_itself_a_wrapper/) , 1690882939.0
```

```
---

     
 
all -  [ A 'pipeline' for a conversational chatbot ](https://www.reddit.com/r/LocalLLM/comments/15f6ije/a_pipeline_for_a_conversational_chatbot/) , 1690878963.0
```
So I've been working to build a conversational chatbot that totally feels 'human-like'. It should ideally be indistingui
shable from a human being.

For this, I looked at how people use open source llms for roleplay tasks. Here, they basical
ly feed a 'character personality prompt' to the LLM and ask it to continue a conversation with a user.

I did this in th
e beginning, the results were good, but still, it wasn't too hard to identify that it was an AI model. 

I used Langchai
n for all this btw, so it was easy to add conversational memory as well.

So after this, I created a seperate conversati
on chain in Langchain. I fed the conversation to this chain and asked it to analyse the chatbot's emotions and give it a
n 'emotion score' of sorts.

Then, I fed this to another conversation chain and asked it to rewrite the chatbot's previo
us response in accordance with the emotion score generated earlier.

(These 3 chains are the 'pipeline' I mentioned lol)


The results are definitely better than how they were before, but obviously, inference is way slower.

What do you guys
 think of this? Does it seem excessive and inefficient?

Is there something better I can do?
```
---

     
 
all -  [ Awadb 0.3.6 version of the vector database relying on Langchain has been released ](https://www.reddit.com/r/LangChain/comments/15f66qa/awadb_036_version_of_the_vector_database_relying/) , 1690877800.0
```
Awadb 0.3.6 version of the vector database relying on Langchain has been released. The main updates of this version are 
as follows:

&#x200B;

1. add the new interfaces of awadb : delete and update 

2. support packing specified fields of s
earching results 

3. change the default search type from L2 to Inner Product

github address: [https://github.com/awa-a
i/awadb](https://github.com/awa-ai/awadb)
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15f53ug/peter_buildfast_masterclass_learn_to_build_your/) , 1690874115.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Need Help in Setting up Agent ](https://www.reddit.com/r/LangChain/comments/15f4r6q/need_help_in_setting_up_agent/) , 1690872964.0
```
I am writing agents that can query data either from SQLite DB (which holds the machine productivity data), or the Vector
 store (which holds the machine user manuals).

I have 2 separate examples which provide a chat interface based on the S
QL and ConversationalRetrieval chain (from VectorDB). Both examples work beautifully well. 

Problem starts once I add b
oth these to the Agent. This agent is supposed to decide and make calls to the necessary chain, and get the answer. Whil
e at times it works as expected, the overall accuracy is extremely bad, and it also takes a lot of iterations (sometimes
 exhausting max iterations) in the process. Also the quality of responses if bad as well.

&#x200B;

I am trying to figu
re out ways to make the agent more reliable. It would be a great help if anyone can suggest ways to tweak behaviour of a
gents. I have also tried all the agents types, including OPENAI Functions, but still it is far from the satisfactory lev
els.

Below is my code. 

    # Init SQLite DB
    db = SQLDatabase.from_uri('sqlite:///db/example.db')
    embeddings =
 OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    
    # Init vector store
    client = qdrant_client.QdrantClient(
 
       QDRANT_HOST, 
        api_key=QDRANT_API_KEY
    )
    vector_store = Qdrant(
        client=client, 
        col
lection_name=QDRANT_COLLECTION_NAME, 
        embeddings=embeddings
    )
    
    vectorstore_info = VectorStoreInfo(
 
       name='documents store',
        description='A repository of the documents which holds machine manuals. When answ
ering also include a list of source documents in the answer.',
        vectorstore=vector_store
    )   
    
    memory
 = ConversationBufferMemory(memory_key='chat_history', return_messages=True)
    
    # Init LLM
    USE_CHAT_MODEL = Tr
ue
    llm = None
    agent_chain = None
    
    if USE_CHAT_MODEL == True:
        llm = ChatOpenAI(temperature=0, ope
nai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo', max_tokens=300)
    else:
        llm = OpenAI(temperature=0, openai_
api_key=OPENAI_API_KEY, max_tokens=300)
    
    # Add tools
    llm_math = LLMMathChain.from_llm(llm, verbose=True)
   
 vectorstore_toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info, llm=llm)
    sql_toolkit = SQLDatabaseToolk
it(db=db, llm=llm)
    tools = load_tools(['llm-math'], llm=llm)
    tools.extend(vectorstore_toolkit.get_tools())
    t
ools.extend(sql_toolkit.get_tools())
    
    def build_agent():
        return initialize_agent(
            tools, 
  
          llm, 
            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, 
            verbose=True, 
            me
mory=memory, 
            handle_parsing_errors=True,
        )
    
    def format_answer(info_str):
        info_dict 
= json.loads(info_str.replace(''', '\''))
        answer = info_dict['answer'].strip()
        sources = info_dict['sour
ces']
        final_answer = f'{answer}\n\nSources:\n{sources}'
        return final_answer
    
    def ask_agent(df_ag
ent, query):
        response = None
        try:
            agent_response = df_agent({'input': query})
            re
sponse = format_answer(agent_response['output']) 
        except ValueError as e:
            response = str(e)
        
    if not response.startswith('Could not parse LLM output: `'):
                raise e
        return response.removep
refix('Could not parse LLM output: `').removesuffix('`')
    
    if __name__ == '__main__':
        df_agent = build_ag
ent()
        query = 'How to access the KRONES menu?'
        result = ask_agent(df_agent, query)
        print(result)


&#x200B;
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15f1uic/peter_buildfast_masterclass_learn_to_build_your/) , 1690863316.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Any success in utilising open source LLMs for data analysis? How did you do it? ](https://www.reddit.com/r/LangChain/comments/15ez9pz/any_success_in_utilising_open_source_llms_for/) , 1690855780.0
```

```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ey39e/peter_buildfast_masterclass_learn_to_build_your/) , 1690852512.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ LLMs for Classification ](https://www.reddit.com/r/learnmachinelearning/comments/15ewuzv/llms_for_classification/) , 1690849235.0
```
Is there any way to use LLM's for classification in the sense that given a prompt the LLM outputs an integer in a set G.
 For example G={0,1} for binary classification or G={1,...,K} etc. I have tried using LLM's for some tasks such as answe
ring yes or no questions or classifying a piece of text but often the LLM will not answer just yes/no or give the classi
fication, but it includes other text, like 'Sure, here is the answer, this piece of text should be classified as X'. Thi
s inclusion of unnecessary information makes it difficult to analyse the responses. I thought maybe you could do somethi
ng like this using some of the work on getting LLMs to use tools (like WolframAlpha) i.e. if it had an API it could call
 that sets a bit to 0 or 1.

EDIT: looking at langchain tools
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15etujd/peter_buildfast_masterclass_learn_to_build_your/) , 1690841715.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Question answering over custom log files? ](https://www.reddit.com/r/LangChain/comments/15eqvhr/question_answering_over_custom_log_files/) , 1690834786.0
```
I have an application that runs C# and C++ code. For each run, a logfile is produced as a regular .txt or .log file that
 shows exactly which methods were called in the program, where anything failed if at all, values for variables at runtim
e, etc.

I've been using LangChain with the Llama 13B-chat model, and it seems to work OK for querying documents that ar
e written in plain English, such as PDF files. My custom log files are not written in plain English--they follow a certa
in format, include method signatures, and more. Basically, they are comprised of technical language and not novel-type t
ext, such as what you might see in a typical PDF or other standard document file.

I'd like the combination of LangChain
 + Llama to perform well on answering questions about these custom .txt/.log files that all follow a specific format. Th
ese questions may include 'What went wrong?', 'What was the user hoping to accomplish in this run?', 'Why did this metho
d fail?', 'What is a potential fix for this situation?', etc. This seems to be a little more involved that a basic seman
tic search, although I could be wrong.

What's the best way to go about achieving this in LangChain? Would it be as simp
le as modifying a prompt/prompt template? Would it be more involved and require fine-tuning my model entirely in order t
o accommodate for this custom formatting of the log files? Something in between?

Note that these log files can get rath
er long. Does this mean that it would not be feasible to include one of them in a prompt and tell the LLM 'Here is the l
og file, the user will ask questions about it.' ? The TL;DR here is **how can I get LangChain to help me analyze custom 
log files that have been generated from custom code?** A point in the direction of some code somewhere that perhaps solv
es a similar issue would be very helpful.
```
---

     
 
all -  [ How do you access response headers from OpenAI API with Langchain? ](https://i.redd.it/lsv9h3k7wcfb1.png) , 1690833537.0
```
Been looking at the code and can not seem to figure this out. Is there a way to access the header of the http response t
hrough langchain? Has anyone tried this with langchain js by chance?
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ep6j6/peter_buildfast_masterclass_learn_to_build_your/) , 1690830913.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ekiin/peter_buildfast_masterclass_learn_to_build_your/) , 1690820114.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15efx7n/peter_buildfast_masterclass_learn_to_build_your/) , 1690809316.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Super excited to announce the 🚀Autonomous Agents Hackathon🤖 ](https://www.reddit.com/r/Super_AGI/comments/15ecpa3/super_excited_to_announce_the_autonomous_agents/) , 1690800397.0
```
📅 18 **- 20 Aug, 2023 |** 9:**00PM PST onwards**

🕐38 **hours of pure innovation**

📌Vi**rtual**

Register now: https://
superagi.com/autonomous-agents-hackathon/

Calling all trailblazing AI Devs & Hackers to solve a real-world 🌍💡use case u
sing AI agent frameworks like SuperAGI, AutoGPT, BabyAGI, Langchain etc.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15ec3dd/peter_buildfast_masterclass_learn_to_build_your/) , 1690798517.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15e8w8n/peter_buildfast_masterclass_learn_to_build_your/) , 1690787712.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ What's the difference between query and query_with_sources in VectorstoreIndexCreator?? ](https://www.reddit.com/r/LangChain/comments/15e8cr0/whats_the_difference_between_query_and_query_with/) , 1690785797.0
```
I'm using VectorstoreIndexCreator

&#x200B;

It doesn't seem like query is looking through my files but query\_with\_sou
rces is. does anyone know why?

&#x200B;

Do either of them interact with an LLM or is it just returning stuff based on 
the embeddings?
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15e5sb7/peter_buildfast_masterclass_learn_to_build_your/) , 1690776916.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ LLM API streaming remote ](https://www.reddit.com/r/LocalLLaMA/comments/15e3d5o/llm_api_streaming_remote/) , 1690769332.0
```
I have a project with the new Llama2  and I have a custom frontend that my partner is building and they want the text ge
neration to stream directly to the client browser without the delay.  So far, I have used Langchain, oobabooga, FastAPI,
 and other smaller repos to generate the text and send it to port directly but it keeps waiting for the text to finish b
efore sending out.  This is not keeping with the UX so we need to fix it.

I am wondering if anyone else encountered thi
s and if you have a technique you found that works?
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15e28w4/peter_buildfast_masterclass_learn_to_build_your/) , 1690766112.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
all -  [ Peter - Buildfast Masterclass - Learn to build your own AI chatbot ](https://www.reddit.com/r/MakesYouMoney/comments/15dy7zx/peter_buildfast_masterclass_learn_to_build_your/) , 1690755314.0
```
Get the course here: [https://bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[https:/
/bit.ly/Peter-Buildfast\_Masterclass](https://bit.ly/Peter-Buildfast_Masterclass)

[ ](https://preview.redd.it/wcgw14o40
p7b1.jpg?width=1280&format=pjpg&auto=webp&s=404eee6c4d63d0176e118d586148aba90726b3b0)

# Here are all of the videos insi
de Fundamentals That you get instant access to upon joining BuildFast

1. LLMs: Overview, using LLMs in Langchain, open-
sourced LLMs, chat model, embedding text.
2. Chains: Chains 101, LLM Chain, Sequential Chain, and four other important L
angchain chains.
3. Prompt: Prompts 101, Example Prompts, Output Parser.
4. Memory: 4 Memory Types Explained, How to use
 Memory in a Chain, How to add Memory to an Agent
5. Document Loaders: Document Loaders 101, When to use Document Loader
, Import data from Text & CSV, and Loading data from Discord, Notion, Telegram
6. Indexes: Indexes 101, Retrievers and T
ext Splitters.
7. Vector Database & Embeddings: Vector databases 101, when to use vector databases, Embeddings and vecto
r database use-cases.
```
---

     
 
MachineLearning -  [ [D] Having trouble with RAG on company domain data ](https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/) , 1690531314.0
```
I have a data set that isn't that large \~200 pdfs. I have done the regular RAG approach with Langchain, extracting text
, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity sear
ch with a question I would like answered it returns the wrong context. The documents are semi-structured information of 
examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input th
is question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not e
xplicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chun
ks, but this does nothing.

Does anyone have any tips on improving the embeddings retrieval in this case?
```
---

     
 
MachineLearning -  [ [D] How do I reduce LLM inferencing time? ](https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/) , 1690189139.0
```
I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface l
ibrary, and I am running the model on AWS ml.g4dn.12xlarge which has 4x**nvidia t4**, which gives a total 64GB of GPU me
mory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins
 for big queries.

The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in 
a conversational way. I've extracted the main parts of the notebook and put it up [here](https://colab.research.google.c
om/drive/1uFNkZ6FI0qffwRpW6ubfdq0HrCqcqVUi?usp=sharing).

Where can I make changes to speed up the transaction. Is there
 any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give a
n answer in less than 5 seconds. Are there any other areas I can optimise?

I appreciate any help you can provide. Thank
s!
```
---

     
 
MachineLearning -  [ [P] TruLens-Eval is an open source project for eval & tracking LLM experiments. ](https://www.reddit.com/r/MachineLearning/comments/1542fbt/p_trulenseval_is_an_open_source_project_for_eval/) , 1689790263.0
```
Hey [r/MachineLearning](https://www.reddit.com/r/MachineLearning/),

The team at TruEra recently released an open source
 project for evaluation & tracking of LLM applications called [TruLens-Eval](https://github.com/truera/trulens/tree/main
/trulens_eval). We’ve specifically targeted retrieval-augmented QA as a core use case and so far we’ve seen it used for 
comparing different models and parameters, prompts, vector-db configurations and query planning strategies. I’d love to 
get your feedback on it.

The core idea behind the project is feedback functions. Analogous to labeling functions, feedb
ack functions are models used to score the text produced by LLMs. We already have a variety of out-of-the-box feedback f
unctions to use for eval including relevance, language match, sentiment and moderation that can be applied to inputs, ou
tputs or intermediate steps of your application.

On top of eval, there’s also built-in tracking of cost and latency.

W
e made it easy to integrate with different setups using connectors for langchain, llama-index + an option to use it with
out a framework.

[Langchain Quickstart Colab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-
trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/langchain_quickstart_colab.ipynb)

[Llama-Index Quickstart Co
lab](https://colab.research.google.com/github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/c
olab/quickstarts/llama_index_quickstart_colab.ipynb)

[No Framework Quickstart Colab](https://colab.research.google.com/
github/truera/trulens/blob/releases/rc-trulens-eval-0.5.0/trulens_eval/examples/colab/quickstarts/no_framework_quickstar
t_colab.ipynb)

Last, the project comes with a streamlit dashboard for visualization of your experiments and associated 
metrics.

[TruLens dashboard for comparing different app versions](https://preview.redd.it/q68b1l27pycb1.jpg?width=1233&
format=pjpg&auto=webp&s=cfb1704624a8b6642b249a32d0afee85ea9f62d9)

Please let us know what you use this for or if you ha
ve feedback! And thanks to all contributors to this project and the open source community!
```
---

     
 
MachineLearning -  [ Alternativ to langchain [D] ](https://www.reddit.com/r/MachineLearning/comments/15175na/alternativ_to_langchain_d/) , 1689516377.0
```
Im currently learning hiw to use langchain but i heard that its bad so i want to know what are som alternatives i need m
emory and agents so that it can search online run code and so on so what is the best alternativ or is langchain the best
 option
```
---

     
 
MachineLearning -  [ '[N]' '[D]' Langchain? What is it?? ](https://www.reddit.com/r/MachineLearning/comments/150mzax/n_d_langchain_what_is_it/) , 1689454973.0
```
want to know more about Langchain  
Check out [https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf](https:
//nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf)
```
---

     
 
MachineLearning -  [ [D] The Problem With LangChain ](https://www.reddit.com/r/MachineLearning/comments/14zlaz6/d_the_problem_with_langchain/) , 1689352833.0
```
https://minimaxir.com/2023/07/langchain-problem/

tl;dr it's needlessly complex, and I provide code examples to demonstr
ate such.

A few weeks ago when I posted about creating a LangChain alternative to /r/MachineLearning, most of the comme
nts replied 'what exactly is the issue with LangChain', so I hope this provides more clarity!
```
---

     
 
MachineLearning -  [ [D] 📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1) ](https://www.reddit.com/r/MachineLearning/comments/14xww89/d_the_learning_corner_andrew_ng_free_ai_courses/) , 1689187280.0
```
📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1)

This is a list of some of the best Ai Free courses by Andrew NG
, we will release the second part of the list on our next newsletter installment (link)

* [**Generative AI with Large L
anguage Models**](https://www.deeplearning.ai/courses/generative-ai-with-llms/?utm_campaign=gaia-launch&utm_content=2545
85614&utm_medium=social&utm_source=linkedin&hss_channel=lcp-18246783)
* [**LangChain: Chat With Your Data**](https://www
.deeplearning.ai/short-courses/langchain-chat-with-your-data/)
* [**LangChain for LLM Application Development**](https:/
/learn.deeplearning.ai/langchain)
* [**How Diffusion Models Work**](https://learn.deeplearning.ai/diffusion-model)
```
---

     
 
MachineLearning -  [ [P] langchain-lite alternative ](https://www.reddit.com/r/MachineLearning/comments/14xf9xb/p_langchainlite_alternative/) , 1689140460.0
```
Although langchain is an impressive library, I tend to find it is…

* a little unintuitive, at least for non-trivial exa
mples or examples that don’t have a predefined chains/templates
* related, it's overly prescriptive; and the various lev
els of abstraction don't resonate with me
* related, can be difficult to debug or understand what’s happening in interme
diate steps of the chain or what’s it’s actually sending OpenAI

So, I built a “langchain-lite” package called `llm-work
flow`

https://github.com/shane-kercheval/llm-workflow

The value proposition is basically:

* easily build up a sequenc
e of tasks (e.g. prompt-template -> chat) called a workflow, where the output of one task serves as the input to the nex
t task in the workflow
* **track history**; understand what's happening in each of the tasks; **aggregate token usage, c
osts, etc. across the workflow**

So a workflow can be anything from `prompt -> chat -> response` to `prompt -> web-sear
ch -> web-scraping -> vector-database & retrieval -> modified prompt -> chat -> response`.

Here's an example of a 'prom
pt enhancer' workflow, where the user provides a prompt, one model enhances/improves the prompt, and the second model an
swers the question based on the enhanced prompt.

```python
prompt_enhancer = OpenAIChat(...)
chat_assistant = OpenAICha
t(...)

def prompt_template(user_prompt: str) -> str:
    return 'Improve the user's request, below, by expanding the re
quest ' \
        'to describe the relevant python best practices and documentation ' \
        f'requirements that shou
ld be followed:\n\n```{user_prompt}```'

def prompt_extract_code(_) -> str:
    # `_` signals that we are ignoring the i
nput (from the previous task)
    return 'Return only the primary code of interest from the previous answer, '\
        
'including docstrings, but without any text/response.'

workflow = Workflow(tasks=[
    prompt_template,      # modifies
 the user's prompt
    prompt_enhancer,      # returns an improved version of the user's prompt
    chat_assistant,     
  # returns the chat response based on the improved prompt
    prompt_extract_code,  # prompt to ask the model to extrac
t only the relevant code
    chat_assistant,       # returns only the relevant code from the model's last response
])
pr
ompt = 'create a function to mask all emails from a string value'
response = workflow(prompt)
```

The `response` is: `d
ef mask_email_addresses(string): .....`

We can view the history, which includes the prompts/responses/tokens/etc. for e
ach interaction:

```python
print(workflow.history())
```

Output:

```
[
    ExchangeRecord(prompt='Improve the user's 
request, below, by ...', response='Create a Python function that adheres to best practice...', timestamp='2023-07-12 04:
45:04.703', cost=0.00063, total_tokens=333, prompt_tokens=58, response_tokens=275),
    ExchangeRecord(prompt='Create a 
Python function that adheres ...', response='Sure! Here\'s an example of a Python function that adh...', timestamp='2023
-07-12 04:45:14.696', cost=0.00149, total_tokens=820,  prompt_tokens=292, response_tokens=528),
    ExchangeRecord(promp
t='Return only the primary code of intere...', response='```python\nimport re\n\ndef mask_email_addresses(strin...', tim
estamp='2023-07-12 04:45:18.875', cost=0.00167, total_tokens=1051, prompt_tokens=850, response_tokens=201)
]
```

We can
 also summarize costs/tokens/etc.

```python
print(workflow.sum('cost'))             # 0.0034
print(workflow.sum('total_
tokens'))     # 1961
print(workflow.sum('prompt_tokens'))    # 1104
print(workflow.sum('response_tokens'))  # 857
```

M
ore examples can be found here: https://github.com/shane-kercheval/llm-workflow/tree/main/examples

Feedback welcome.
```
---

     
 
MachineLearning -  [ [D] What have been your use cases for LLM autonomous agents? ](https://www.reddit.com/r/MachineLearning/comments/14w817y/d_what_have_been_your_use_cases_for_llm/) , 1689026848.0
```
I've been using GPT for completions on a daily basis for a while now - code completion and search-like chatting, basical
ly. I've recently been playing around with both ChatGPT plugins and LangChain for autonomous-agent-like behavior, and al
though the idea of the LLM interacting with the environment through API calls or code interpretation seems promising, in
 practice I haven't found such a useful and usable case for it like completions yet.

LangChain's OpenAPI toolkit with i
ts planner/controller agent duo seems to get lost 90% of the time, making it unusable. This happens even with an /api en
dpoint telling it exactly how to interact with the API and prompt templates suggesting that this endpoint be used to get
 the API specs. Maybe I'm just not getting it right...

As for ChatGPT plugins, other than web search for more updated r
esults I haven't really found a use case where I could not do the same thing with completions. Code Interpreter shaves o
ff a few seconds vs completions and running whatever script it produces locally, but it's not very useful in face of com
pliance or privacy requirements of not uploading stuff into OpenAI. For example I wanted to speed up a work related vide
o and add a separate audio track to it. I couldn't upload the video to OpenAI as it contained internal work stuff, so I 
just used completions for an ffmpeg script to do the job and ran it locally. Same thing with transforming or plotting CS
V data - can't really update customer data to OpenAI, so just get the script and run it locally.

Anyway, I can *think o
f* a lot of cool use cases for autonomous agents and the like, but I haven't been able to *actually use* it in my daily 
routine, unlike text completion. Have you been using autonomous agents successfully and regularly?
```
---

     
 
MachineLearning -  [ [D] Hacking LangChain for Fun and Profit ](https://www.reddit.com/r/MachineLearning/comments/14w0ht7/d_hacking_langchain_for_fun_and_profit/) , 1689010315.0
```
[https://blog.kevinhu.me/2023/07/10/hacking-langchain-for-fun-and-profit/](https://blog.kevinhu.me/2023/07/10/hacking-la
ngchain-for-fun-and-profit/)

I'm starting a series of blogs to delve into LangChain. Hope this helps anyone who's inter
ested in LLM and building with LangChain.
```
---

     
 
MachineLearning -  [ [D] - Are there any AI benchmarks that involve successful longterm problem solving when running as a ](https://www.reddit.com/r/MachineLearning/comments/14v4l2o/d_are_there_any_ai_benchmarks_that_involve/) , 1688924349.0
```
 Even the most powerful LLMs, such as gpt4, seem to get lost or fall into loops when being run as autonomous agents like
 as part of langchain or autogpt. Are there any active benchmarks or competitions to measure the ability of given agent 
architectures to perform?
```
---

     
 
MachineLearning -  [ [R] Chat with documents using LangChain and OpenAI ](https://www.reddit.com/r/MachineLearning/comments/14pkxir/r_chat_with_documents_using_langchain_and_openai/) , 1688395253.0
```
Over the past few months, I've been captivated by the flood of apps claiming to be the ultimate 'ChatGPT for your docume
nts' on Product Hunt. The question that lingered in my mind was, 'How do these apps actually work?' Curiosity led me dow
n an exciting path of discovery, and I stumbled upon a framework that I think is revolutionizing the world of app develo
pment in the context of Large Language Models - LangChain

I learned that developing a 'ChatGPT for your documents' is e
asily achievable through three broad workflows combined with access to OpenAI API. In fact, I went ahead and prototyped 
such a system on streamlit. 

Step 1 - The Setup: Store your documents as embeddings.
In the first step, use Document Lo
aders (at least 100 are available), provided by LangChain to convert anything from a simple Word document to an AWS S3 d
irectory into Documents. Then, using Document Transformers and Text Embedding Models, you transform your documents into 
embeddings. Finally, store these embeddings in a vector store for searches later on. It's a one-time setup that sets the
 foundation for your Q&A system. 💡🛠️

Step 2 - Establish Context: Find relevant documents.
LangChain's Text Embedding mo
del converts user queries into vectors. These vectors are used by LangChain's retriever to search the vector store and r
etrieve the most relevant documents. You can control the search boundaries based on relevance scores or the desired numb
er of documents. It's all about finding the right context for your Q&A system. 🎯💬

Step 3 - Chat Away: Get answers from 
LLMs.
Now comes the fun part! You pass the user's query and the established context to the Language Models (LLMs). The L
LMs respond with precise answers, taking into account the provided context. It's like having a conversation with your do
cuments. 🤩🗨️


By building these three workflows, a service that acts like a Q&A for a restricted set of documents can b
e set up. Of course, this is just an overview of the approach and all the complex steps of app development will still re
main, I remain fascinated by how the good folks at LangChain have made things simpler. 

What do you think? Have you tri
ed LangChain to build something? Is there any other framework that is equally fascinating?

#llm #openai #chatgpt #docum
ents #generativeai #langchain
```
---

     
