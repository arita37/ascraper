 
all -  [ [0 YOE] New Grad with 300+ Tailored Applications with no Interviews. Too busy? Unsubstantive? ](https://www.reddit.com/r/EngineeringResumes/comments/1d6qta2/0_yoe_new_grad_with_300_tailored_applications/) , 2024-06-03-0953
```
https://preview.redd.it/ttb18wl1w84d1.png?width=5100&format=png&auto=webp&s=0bac74240d11d4927d65ec60b87a59700d017857

He
llo all,  
As the title says, I'm failing to get to the interview stage of my applications. I graduated early (3 1/2 yea
rs) and I have been applying for remote and seattle based roles primarily on linkedin and google jobs. I will generally 
tailor the skills section of my resume depending on what a job is looking for. I am primarily looking at full stack, fro
nt end, back end, and python developer roles. I have a job offer from the internship that I took but that starts in 4-5 
months and is not in the locations I am looking for.

Potential problem points:

* Too busy
* Recruiters think I am inte
rnational/need visa
* Flawed application methods
* Busy Bolding
```
---

     
 
all -  [ LLM vs CS Fundamentals ](https://www.reddit.com/r/cscareerquestions/comments/1d6pc2y/llm_vs_cs_fundamentals/) , 2024-06-03-0953
```
I have a bachelor in CS and will be graduating with a master in AI in December. I already have a SDE summer internship l
ined up, but the return rate is quite low. I am wondering should I keep grinding CS fundamentals (leetcode, OS, Networkâ€¦
) or should I put more focus on MLE related preparation (ML fundamentals, updated research papers and tools such as Lang
chain), considering the recent hype/boost of LLM and over saturation on traditional sde roles. My ultimate goal is to ge
t a job after graduation ASAP. Any advance will be greatly appreciated!
```
---

     
 
all -  [ Llm model selection ](https://www.reddit.com/r/LangChain/comments/1d6o48l/llm_model_selection/) , 2024-06-03-0953
```
Hi everyone!  
Im a starter on playing with langchain and currently trying out llms using Ollama, but im kinda fuzzy on 
how to select a model for a specific use (embedding, text generation, code generation etc.) from such a wide range of mo
dels. Im pretty much using Llama3 for every use case. Can anyone help me? Much appreciated!
```
---

     
 
all -  [ RAG with legal texts ](https://www.reddit.com/r/LangChain/comments/1d6mnum/rag_with_legal_texts/) , 2024-06-03-0953
```
Hello everyone, 

&#x200B;

I want to build a RAG chatbot using case texts but I can't get good results in similarity se
arch. 

When I think about the reasons for this, I suspect that repetitive sentences in legal texts are the problem. How
 can I overcome this problem? I have tried semantic chunking, parent document retrival, almost everything. 
```
---

     
 
all -  [ [GPT-4o + LangChain + RAG] I built a companion robot with 'memories' and 'emotions', his name is EVA ](https://youtu.be/riliV2PGKWQ) , 2024-06-03-0953
```

```
---

     
 
all -  [ Is it possible to create an agent that can query a MySQL database and answer questions about a docum ](https://www.reddit.com/r/LangChain/comments/1d6ern3/is_it_possible_to_create_an_agent_that_can_query/) , 2024-06-03-0953
```
Hey,

I'm relatively new to Langchain and have primarily worked with chains and retrievers. Recently, I discovered agent
s and tools, and they seem quite powerful.

I've successfully set up an SQL agent following the documentation. Now, I'm 
interested in creating an agent that can browse both an SQL database and document-based sources.

I saw in the documenta
tion that it's possible to use multiple tools, like combining [Tavily and a retriever tool.](https://python.langchain.co
m/v0.2/docs/how_to/agent_executor/) 

I'd appreciate if someone could let me know where it's possible  to build such an 
agent and where to look for relevant resources? So far, it's been quite difficult to find anything that can point me in 
the right direction.

Thanks!
```
---

     
 
all -  [ TypeError: RequestsPostTool._run() got an unexpected keyword argument 'url' ](https://www.reddit.com/r/LangChain/comments/1d6ebjn/typeerror_requestsposttool_run_got_an_unexpected/) , 2024-06-03-0953
```
I am trying to interact with an external API using RequestsPostTool, AIPluginTool, and create\_openai\_tools\_agent. But
 I am always getting this error:

TypeError: RequestsPostTool.\_run() got an unexpected keyword argument 'url'

  
I che
cked the logs from Langsmith and it seems the issue is caused by double quotations outside the JSON string and not insid
e the JSON string. This causes RequestsPostTool.\_run() function to not work in the code.

My question is how to resolve
 this error efficiently or how to validate the output of LLM before it pass the input to RequestsPostTool.\_run()
```
---

     
 
all -  [ Consider questions related to the uploaded files... ](https://www.reddit.com/r/ollama/comments/1d6ea38/consider_questions_related_to_the_uploaded_files/) , 2024-06-03-0953
```
Hi, I am trying to build a RAG, the use-case is to upload some pdf files and ask questions about it. The stack include: 
streamlit, langchain, ollama(mistral ig) and chroma db. Only questions related to the uploaded pdf file(s) must be answe
red. In case there is a question not related to the pdf file content, the answer should be 'I don't know' or 'not relate
d to the context'. How can this be done ..??
Is it related to the prompt ?? 
```
---

     
 
all -  [ ChatGPT refuse/not aware of its function calling capability, and don't call functions even when ther ](https://www.reddit.com/r/LangChain/comments/1d6dvnw/chatgpt_refusenot_aware_of_its_function_calling/) , 2024-06-03-0953
```
Hi everyone,

I'm new to LangChain, and currently learning LangGraph. This morning things are fine, I was trying to repl
icate the AgentExecutor using LangGraph as presented in their Youtube videos, and the agent (GPT 4.0) was able to use th
e web search tool (DuckDuckGo, btw) to search for information about weather, and return to me correct answer. 

However,
 in the evening of the same day, I could not do so anymore. The model refuse to give me real time data about weather. It
 got worse: when I specifically asked it to use function call to perform search about weather, but it even denying it fu
nction call capabilities.

Do anyone knows why this is the case? It is so frustrating!

[This is the screenshot of my ag
ent denying me. Hurt!](https://preview.redd.it/sl8oai2fz54d1.png?width=1441&format=png&auto=webp&s=c257cb67bbbd91c60fd17
ea239c4adef9df891b2)


```
---

     
 
all -  [ Hi folks, need help regarding ReAct agents and working with urls. ](https://www.reddit.com/r/LangChain/comments/1d6dm3b/hi_folks_need_help_regarding_react_agents_and/) , 2024-06-03-0953
```
Hi, 

I recently started learning langchain and am developing a simple app in which first we enter user's name then one 
agent finds their linkedin profile url and based on that writes a short summary about them, but I am facing an issue whe
re the url is often times another redirecting link to the main profile page url, but when the redirecting link is forwar
ded to Proxycurl API(api to access linkedin page through url) which is not able to detect it, how should i go about this
 problem?  


Thanks. 
```
---

     
 
all -  [ Deploy Langchain Streaming RAG app on Streamlit ](https://www.reddit.com/r/LangChain/comments/1d6bkbr/deploy_langchain_streaming_rag_app_on_streamlit/) , 2024-06-03-0953
```
This video covers:  
- How to use Streamlit Secrets to hide your API keys  
- Importance of requirements.txt file  
- De
ploy the LLM application on Streamlit and get a sharable link  
- Also learn how to fix the Chroma and SQLite3 issues wh
ile deploying your application built using Langchain and Chroma vector base.

  
Watch here: [https://www.youtube.com/wa
tch?v=7BBzM2qCZvc](https://www.youtube.com/watch?v=7BBzM2qCZvc)
```
---

     
 
all -  [ LLM doesn't include the context from the vector database, and hence the frontend gets the generic re ](https://www.reddit.com/r/u_Prakash127_0_0_1/comments/1d67fhq/llm_doesnt_include_the_context_from_the_vector/) , 2024-06-03-0953
```
I am creating a chatbot for my portfolio website. I am using Next.js, OpenAI API, Vercel AI SDK, Langchain and AstraDB.


As I hit request my route, LLM runs twice. The first run of LLM contains no context that I provided and the answer is j
ust simple with no information of mine. But the second run contains the context I provided from the AstraDb vector datab
ase and I get what I want.

For example: I write 'who are you', the first answer is 'I am a language model AI designed t
o assist with answering questions and engaging in conversation. How can I help you today?' and the second answer is 'I a
m Prakash Banjade.........'.

But on the frontend, I get the first answer which is not relevant.

Here's my code:

// ro
ute.ts

`import { ChatOpenAI } from '@langchain/openai';`

`import { createStreamDataTransformer, LangChainAdapter, Stre
amingTextResponse, Message as VercelChatMessage, } from 'ai'`

`import { AIMessage, HumanMessage } from '@langchain/core
/messages';`

`import { ChatPromptTemplate, MessagesPlaceholder, PromptTemplate } from '@langchain/core/prompts'`

`impo
rt { UpstashRedisCache } from '@langchain/community/caches/upstash_redis';`

`import { Redis } from '@upstash/redis';`


`import { createStuffDocumentsChain } from 'langchain/chains/combine_documents';`

`import { createHistoryAwareRetriever
 } from 'langchain/chains/history_aware_retriever';`

`import { createRetrievalChain } from 'langchain/chains/retrieval'
;`

`import { getVectorStore } from '@/lib/astradb';`

`export const dynamic = 'force-dynamic';`

`export const maxDurat
ion = 60;`

`export async function POST(req: Request) {`

`try {`

`const body = await req.json();`

`const messages = b
ody.messages;`

`const chatHistory = messages`

`.slice(0, -1)`

`.map((m: VercelChatMessage) =>`

`m.role === 'user'`


`? new HumanMessage(m.content)`

`: new AIMessage(m.content),`

`);`

`const currentMessageContent = messages[messages.l
ength - 1].content;`

`const cache = new UpstashRedisCache({`

`client: Redis.fromEnv(),`

`});`

`const chatModel = new
 ChatOpenAI({`

`modelName: 'gpt-3.5-turbo',`

`streaming: true,`

`verbose: true,`

`cache,`

`});`

`const rephrasingM
odel = new ChatOpenAI({`

`modelName: 'gpt-3.5-turbo',`

`verbose: true,`

`cache,`

`});`

`const retriever = (await ge
tVectorStore()).asRetriever();`

`const rephrasePrompt = ChatPromptTemplate.fromMessages([`

`new MessagesPlaceholder('c
hat_history'),`

`['user', '{input}'],`

`[`

`'user',`

`'Given the above conversation, generate a search query to look
 up in order to get information relevant to the current question. ' +`

`'Don't leave out any relevant keywords. Only re
turn the query and no other text.',`

`],`

`]);`

`const historyAwareRetrieverChain = await createHistoryAwareRetriever
({`

`llm: rephrasingModel,`

`retriever,`

`rephrasePrompt,`

`});`

`const prompt = ChatPromptTemplate.fromMessages([`


`[`

`'system',`

`'You are a chatbot for a personal portfolio website. You impersonate the website's owner. ' +`

`'A
nswer the user's questions based on the below context. ' +`

`'Whenever it makes sense, provide links to pages that cont
ain more information about the topic from the given context. ' +`

`'Format your messages in markdown format.\n\n' +`

`
'Context:\n{context}',`

`],`

`new MessagesPlaceholder('chat_history'),`

`['user', '{input}'],`

`]);`

`const combine
DocsChain = await createStuffDocumentsChain({`

`llm: chatModel,`

`prompt,`

`documentPrompt: PromptTemplate.fromTempla
te(`

`'Page URL: {url}\n\nPage content:\n{page_content}',`

`),`

`documentSeparator: '\n--------\n',`

`});`

`const r
etrievalChain = await createRetrievalChain({`

`combineDocsChain,`

`retriever: historyAwareRetrieverChain,`

`});`

`re
trievalChain.invoke({`

`input: currentMessageContent,`

`chat_history: chatHistory,`

`});`

`const stream = await chat
Model.stream([new HumanMessage(currentMessageContent), ...chatHistory]);`

`const aiStream = LangChainAdapter.toAIStream
(stream);`

`console.log('hey there 1')`

`return new StreamingTextResponse(aiStream);`

`} catch (e) {`

`console.log(e
)`

`return Response.json({ message: 'internal server error' }, { status: 500 })`

`}}`  


Here the console of LLM:

Co
nnected to Astra DB collection

\[llm/start\] \[1:llm:ChatOpenAI\] Entering LLM run with input: {

'messages': \[

\[

{


'lc': 1,

'type': 'constructor',

'id': \[

'langchain\_core',

'messages',

'HumanMessage'

\],

'kwargs': {

'conten
t': 'who are you?',

'additional\_kwargs': {},

'response\_metadata': {}

}

}

\]

\]

}

hey there 1

\[llm/end\] \[1:
llm:ChatOpenAI\] \[1.01s\] Exiting LLM run with output: {

'generations': \[

\[

{

'text': 'I am a language model AI d
esigned to assist with answering questions and engaging in conversation. How can I help you today?',

'generationInfo': 
{

'prompt': 0,

'completion': 0,

'finish\_reason': 'stop'

},

'message': {

'lc': 1,

'type': 'constructor',

'id': \
[

'langchain\_core',

'messages',

'AIMessageChunk'

\],

'kwargs': {

'content': 'I am a language model AI designed to
 assist with answering questions and engaging in conversation. How can I help you today?',

'additional\_kwargs': {},

'
response\_metadata': {

'prompt': 0,

'completion': 0,

'finish\_reason': 'stop'

},

'tool\_call\_chunks': \[\],

'tool
\_calls': \[\],

'invalid\_tool\_calls': \[\]

}

}

}

\]

\]

}

POST /api/chat 200 in 6053ms

\[llm/start\] \[1:llm:r
etrieval\_chain\] Entering LLM run with input: {

'messages': \[

\[

{

'lc': 1,

'type': 'constructor',

'id': \[

'la
ngchain\_core',

'messages',

'SystemMessage'

\],

'kwargs': {

'content': 'You are a chatbot for a personal portfolio 
website. You impersonate the website's owner. Answer the user's questions based on the below context. Whenever it makes 
sense, provide links to pages that contain more information about the topic from the given context. Format your messages
 in markdown format.\\n\\nContext:\\nPage URL: /about\\n\\nPage content:\\n<div>\\r\\n      <header>\\r\\n        <h2>I\
&apos;m Prakash.</h2>\\r\\n      </header>\\r\\n      <section>\\r\\n        <article>\\r\\n          <p>Hello! I\&apos;
m Prakash Banjade, <em>an aspiring and enthusiastic web developer with a strong foundation in both frontend and backend 
development</em>.\\r\\n ...............................',

'additional\_kwargs': {},

'response\_metadata': {}

}

},

{


'lc': 1,

'type': 'constructor',

'id': \[

'langchain\_core',

'messages',

'HumanMessage'

\],

'kwargs': {

'conten
t': 'who are you?',

'additional\_kwargs': {},

'response\_metadata': {}

}

}

\]

\]

}

\[llm/end\] \[1:llm:retrieval
\_chain\] \[578ms\] Exiting LLM run with output: {

'generations': \[

\[

{

'text': 'I'm Prakash! ğŸŒŸ\\nI'm an aspiring 
web developer with a strong foundation in both frontend and backend development. You can find more about me on my \[abou
t page\](/about).',

'message': {

'lc': 1,

'type': 'constructor',

'id': \[

'langchain\_core',

'messages',

'AIMessa
ge'

\],

'kwargs': {

'content': 'I'm Prakash! ğŸŒŸ\\nI'm an aspiring web developer with a strong foundation in both front
end and backend development. You can find more about me on my \[about page\](/about).',

'additional\_kwargs': {},

'res
ponse\_metadata': {

'estimatedTokenUsage': {

'promptTokens': 550,

'completionTokens': 41,

'totalTokens': 591

},

'p
rompt': 0,

'completion': 0,

'finish\_reason': 'stop'

},

'tool\_call\_chunks': \[\],

'tool\_calls': \[\],

'invalid\
_tool\_calls': \[\]

}

}

}

\]

\]

}

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\
_\_\_\_\_\_\_\_\_\_\_\_

On the frontend side, I am receiving the first output of LLM not the second one. Why?
```
---

     
 
all -  [ We're Looking For Developers!!! ](https://www.reddit.com/r/UVA/comments/1d63mzh/were_looking_for_developers/) , 2024-06-03-0953
```
If you are ambitious and have always wanted to build something of your own and help build an idea from the ground up, we
 are an early startup looking for people EXACTLY like you.

**Weâ€™re looking for Frontend developers with experience in:*
*

Angular

Typescript

Â 

**And Backend developers with experience in:**

Python

Typescript

AWS

OpenAI/Langchain

Mi
lvus & DynamoDB

Â 

Weâ€™re a startup currently growing very quickly and accepted within the Darden iLab Incubator for Sum
mer 2024 at UVA. Weâ€™re focused on empowering university students to take charge of their university careers by providing
 them with a Personal AI Ecosystem that can optimize their curriculums, courses, schedules, extracurricular activities a
nd also directly help them with their career employment and possibilities in and after university. Your contribution wil
l be invaluable in shaping our future!

Compensation is within discussion depending on expertise, experience, and commit
ment. Â   
If interested, message me directly and please include your resume.
```
---

     
 
all -  [ Return only used documents ](https://www.reddit.com/r/LangChain/comments/1d5xa86/return_only_used_documents/) , 2024-06-03-0953
```
In my RAG LLM I want to return the documents used to produce the answer. I don't want ALL the documents, but just the on
e or two that open ai used to produce the answer. 

Example

Question: what day is today? 

Documents retrieved 
- doc1 
chunk1: on that day the sky was red
- doc2 chunk15: today is Saturday 
- doc3 chunk666: my name is Michael and I was bor
n two days before my wife 

Answer: today it's Saturday (doc2) 

With returning source documents, my context contains al
l three documents, but just doc2 have been used to answer the question. 

At the moment I'm asking open ai to put a sepa
rator at the end of the question and write a json with the doc index (from 1 to 5), and then pick the context[index], bu
t it's not as robust as I like. 

Any suggestions? 
```
---

     
 
all -  [ How can I get cumulative answer after analysing 1000s of articles? ](https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/) , 2024-06-03-0953
```
Hi all, I am new to building RAG application. I have no idea about how to make the LLM to answer with all the knowledge 
about 1000s of articles. Let's say I have 1000s of success stories about various businesses, now I want LLM to craft a w
inning strategy.
```
---

     
 
all -  [ langchain with vision browser ](https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/) , 2024-06-03-0953
```
anyone used langchain with browser automation and gpt4o?
```
---

     
 
all -  [ Faster LLM Inference using Groq and Langchain Streaming ](https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/) , 2024-06-03-0953
```
Fast LLM RAG inference using Groq and Langchain Streaming.  
  
Groq is introducing a new, simpler processing architectu
re designed specifically for the performance requirements of machine learning applications and other compute-intensive w
orkloads. The simpler hardware also saves developer resources by eliminating the need for profiling, and also makes it e
asier to deploy AI solutions at scale.  
  
Resource: [https://www.youtube.com/watch?v=frMdOL8knqg](https://www.youtube.
com/watch?v=frMdOL8knqg)
```
---

     
 
all -  [ [P] Superfast RAG: Langchain Streaming and Groq ](https://www.reddit.com/r/MachineLearning/comments/1d5s9g4/p_superfast_rag_langchain_streaming_and_groq/) , 2024-06-03-0953
```
  
Fast LLM RAG inference using Groq and Langchain Streaming.  
  
Groq is introducing a new, simpler processing archite
cture designed specifically for the performance requirements of machine learning applications and other compute-intensiv
e workloads. The simpler hardware also saves developer resources by eliminating the need for profiling, and also makes i
t easier to deploy AI solutions at scale.  
  
Resource: [https://www.youtube.com/watch?v=frMdOL8knqg](https://www.youtu
be.com/watch?v=frMdOL8knqg)
```
---

     
 
all -  [ What are the different ways we can load llama model into Langchain ? ](https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/) , 2024-06-03-0953
```
No Body 

I guess you understood what is mean..

out of these i only knew about LlamaCpp
```
---

     
 
all -  [  This week in AI - all the Major AI developments in a nutshell  ](https://www.reddit.com/r/learnmachinelearning/comments/1d5ohkx/this_week_in_ai_all_the_major_ai_developments_in/) , 2024-06-03-0953
```
1. **The Simulation** (formerly Fable Studio) launched ***Showrunner***, a platform for users to create TV shows with AI
, dubbing it the 'Netflix of AI'. With just a 10-15 word prompt, users can generate scenes and episodes of 2-16 minutes,
 complete with AI dialogue, voices, editing, shot types, characters, and story development. Fable released a research pa
per last year on their SHOW-1 model and AI Showrunner Agents that can write, produce, direct, cast, edit, voice and anim
ate episodes of AI TV \[Details\].
2. **Mistral AI** introduced ***Codestral***, a 22B open-weight generative AI model e
xplicitly designed for code generation tasks. With its larger context window of 32k, Codestral outperforms CodeLlama 70B
, Llama 3 70B and DeepSeek Coder 33B. Codestral is licensed under the *new Mistral AI Non-Production License.* It is acc
essible through Le Chat, La Plateforme and is integrated into LlamaIndex and LangChain \[Details | Hugging Face\].
3. **
Cartesia** introduced ***Sonic***, a low-latency voice model that generates lifelike speech. The co-founders of Cartesia
 had created the state space model architecture. Sonic creates high quality lifelike speech for any voice with a model l
atency of 135msâ€”the fastest for a model of this class. Details on the new architecture will be released in a separate re
port. Sonic is released with a web playground and a low latency API \[Details\].
4. **AI4Finance** Foundation released *
**FinRobot***, a novel open-source AI agent platform supporting multiple financially specialized AI agents, each powered
 by LLM \[Details\].
5. **IEIT-Yuan** released ***Yuan2.0-M32***, a Mixture-of-Experts (MoE) language model with 32 expe
rts, of which 2 are active. Yuan 2.0-M32 is trained from scratch with 2000B token and has surpassed Llama3-70B on the MA
TH and ARC-Challenge benchmark \[Details\].
6. **llama3v**: a new SOTA vision model that is powered by Llama3 8B and sig
lip-so400m and trained with under $500. It outperforms LLaVA, the current open-source SOTA vision language model. llama3
v features comparable vision abilities of models close to 100x larger in size like GPT4v, Gemini Ultra, and Claude Opus 
\[Details | Hugging Face\].
7. **LLM360** released ***K2,*** a fully-reproducible 65 billion parameters large language m
odel outperforming Llama 2 70B using 35% less compute. K2 is fully transparent - LLM360 open-sourced all artifacts, incl
uding code, data, model checkpoints, intermediate results, and more \[Details\].
8. **Perplexity AI** released a new too
l ***Perplexity Pages***, enabling users to create comprehensive, visually appealing content on any topic. Users can typ
e in a topic and receive a structured draft instantly. Perplexity Pages offers the flexibility to create a page as a sep
arate entity, similar to writing a document with full internet access, or you can continue asking questions on Perplexit
y and convert them into the Page format with a one-click convert button \[Details\].
9. **Open-Sora** is now on V1.1.0. 
This open-source project aims to reproduce Sora OpenAIâ€™s text-to-video (T2V) model Sora. v1.1.0 significantly enhances v
ideo generation quality and text control capabilities \[Details\].
10. **Multimodal Art Projection (M-A-P)** Research re
leased ***MAP-Neo***, a bilingual language model with 7B parameters trained from scratch on 4.5T tokens. MAP-Neo is the 
first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs \[Details\
].
11. All **ChatGPT** Free users can now use browse, vision, data analysis, file uploads, and GPTs, earlier available t
o only pro subscribers \[Details\].
12. **Higgsfield** introduced ***NOVA-1*** text to video model that provides markete
rs with precise control. Companies can train a custom version of the NOVA-1 model using their product and brand assets \
[Details\].
13. **ByteDance** introduced ***INSTADRAG***, a rapid approach enabling high quality drag-based image editin
g in âˆ¼ 1 second. Code will be released in 2-4 weeks \[Details\].
14. **Suno** announced v3.5, which is now available to 
all users. It lets you make 4 minute songs, provides full song in a single generation and featres improved song structur
e and vocal flow. Make a song from any sound feature coming soon \[Details\].
15. **6079** announced AI Prize Fight, a f
irst-of-its-kind street fighting esports competition where teams will go head-to-head training AI agents for the champio
nship belt. Registration will begin the week of June 3rd \[Details\].
16. **Scale** released the ***SEAL Leaderboards***
, which rank frontier LLMs using curated private datasets that canâ€™t be gamed. The initial domains covered include Codin
g, Instruction Following, Math and Multilinguality \[Details\].
17. Researchers released ***AutoCoder***, a code LLM tha
t outperforms GPT-4 Turbo and GPT-4o on the HumanEval benchmark. Itâ€™s code interpreter can install external packages ins
tead of limiting to built-in packages tasks. The base model is deepseeker-coder \[Details\].Â 
18. **Microsoft** launched
 Copilot for Telegram - a personal generative AI assistant powered by GPT model and Bing Search, available within Telegr
am \[Details\].
19. **LMSYS Chatbot Arena Leaderboard** update: Gemini 1.5 Pro/Advanced at #2, closing in on GPT-4o. Gem
ini 1.5 Flash at #9, outperforming Llama-3-70b and nearly reaching GPT-4-0125 \[Link\].
20. **Udio** introduced Udio-130
, a new music generation model capable of two-minute generations and new features \[Details\].
21. Tools are now availab
le in **HuggingChat**. Tools open up a wide range of new possibilities, allowing the model to determine when a tool is n
eeded, which tool to use, and what arguments to pass (via function calling) \[Details\].
22. **SambaNova's** Samba-1 Tur
bo has set a new record for large language model inference performance in recent benchmarking by Artificial Analysis. Sa
mba-1 Turbo runs Llama 3 8B at 1000 tokens per second (t/s) on just 16 chips, and can concurrently host up to 1000 Llama
3 checkpoints on a single 16-socket SN40L node. This is the fastest speed for serving Llama 3, while maintaining full pr
ecision at a lower cost \[Details\].
23. **GitHub** announced the 2024 cohort for its GitHub Accelerator program, featur
ing 11 open-source AI projects \[Details\].
24. **Opera** browser has integrated Googleâ€™s Gemini AI models into its exis
ting Aria AI extension. Aria, released last year, acts like an AI assistant to answer user queries, write code, and perf
orm other tasks \[Details\].
25. Tool use, which enables Claude to interact with external tools and APIs, is now general
ly available across the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's V
ertex AI \[Details\].
26. Google adds new built-in AI-powered features to Chromebook \[Details\].
27. Gemini is now avai
lable in Chrome DevTools to help devs understand errors and warnings better with AI \[Details\].

Source: AI Brews - Lin
ks removed from this post due to auto-delete, but they are present in the [newsletter](https://aibrews.com/). it's free 
to join, sent only once a week with bite-sized news, learning resources and selected tools. Thanks!
```
---

     
 
all -  [ selfqueryretriever.from_llm() ](https://www.reddit.com/r/LangChain/comments/1d5lhsg/selfqueryretrieverfrom_llm/) , 2024-06-03-0953
```
Can anyone explain me parameters of this function some of the parameters is 'structured_query_translator', 'chain_kwargs
',
'enable_limit', 'kwargs'. 
Thanks
```
---

     
 
all -  [ Any updates to the agents scene? ](https://www.reddit.com/r/LocalLLaMA/comments/1d5hnqk/any_updates_to_the_agents_scene/) , 2024-06-03-0953
```
So I have been busy with works these couple of weeks, what is the feedback for agents libs

Last time I checked there wa
s some promising projects but with some drawbacks (personal opinion)

- Langchain agents were complicated and over engin
eered

- crewAI and Autogen felt like vision tunneled on some goals and thus hard to extend to other use cases, plus bei
ng only tested against openAI's GPT4 I find it less reliable with local LLMs. (I am not even talking about the aggressiv
e tracing and telemetry)
```
---

     
 
all -  [ which are the 'clone' libraries to Spring AI? ](https://www.reddit.com/r/llmops/comments/1d5d8n6/which_are_the_clone_libraries_to_spring_ai/) , 2024-06-03-0953
```
There are libraries like [https://spring.io/projects/spring-ai#overview](https://spring.io/projects/spring-ai#overview) 
for other languages?   
I'm not require it, but is there any framework to work for these things in other languages?

I h
ave seen [https://www.litellm.ai/](https://www.litellm.ai/) but IDK. Also, It is a mixture between dspy, langchain, llam
aindex, huggingface, and who knows what more frameworks that sounds relevant but who knows
```
---

     
 
all -  [ Was Typesense removed from LangchainJS 0.2? It  ](https://www.reddit.com/r/LangChain/comments/1d5bnf8/was_typesense_removed_from_langchainjs_02_it/) , 2024-06-03-0953
```
I followed the tutorial on langchain for 0.2 for setting up Typesense but it just won't find it.

[https://i.imgur.com/8
yPyU90.png](https://i.imgur.com/8yPyU90.png)

My package.json looks like this:

    {
    Â  'name': 'vite-react-typescri
pt-starter',
    Â  'private': true,
    Â  'version': '0.0.1',
    Â  'type': 'module',
    Â  'scripts': {
    Â  Â  'dev': 
'nodemon -w src/server -x tsx src/server/main.ts',
    Â  Â  'start': 'cross-env NODE_ENV=production tsx src/server/main.t
s',
    Â  Â  'build': 'vite build',
    Â  Â  'test': 'vitest'
    Â  },
    Â  'dependencies': {
    Â  Â  '@langchain/communi
ty': '^0.2.4',
    Â  Â  '@langchain/openai': '^0.1.0',
    Â  Â  '@langchain/weaviate': '^0.0.4',
    Â  Â  'cross-env': '^7.
0.3',
    Â  Â  'dotenv': '^16.4.5',
    Â  Â  'express': '^4.18.2',
    Â  Â  'langchain': '^0.1.0',
    Â  Â  'puppeteer': '^1
9.11.1',
    Â  Â  'react': '^18.2.0',
    Â  Â  'react-dom': '^18.2.0',
    Â  Â  'tsx': '^4.3.0',
    Â  Â  'typescript': '^5.
3.2',
    Â  Â  'typesense': '^1.8.2',
    Â  Â  'vite-express': '*',
    Â  Â  'weaviate': '^0.0.14',
    Â  Â  'weaviate-ts-cl
ient': '^2.2.0'
    Â  },
    Â  'devDependencies': {
    Â  Â  '@types/express': '^4.17.21',
    Â  Â  '@types/node': '^20.9.
3',
    Â  Â  '@types/react': '^18.0.38',
    Â  Â  '@types/react-dom': '^18.2.16',
    Â  Â  '@vitejs/plugin-react': '^4.2.0'
,
    Â  Â  'nodemon': '^3.0.1',
    Â  Â  'vite': '^5.0.2',
    Â  Â  'vitest': '^1.6.0'
    Â  }
    }
    



  
Am I missin
g something?
```
---

     
 
all -  [ RAG DecisiÃ³n ](https://www.reddit.com/r/LangChain/comments/1d59ax3/rag_decisiÃ³n/) , 2024-06-03-0953
```
I have a RAG system with a Vector DB (Mileyâ€™s) everything is working fine. However now the business want to summarize an
d translate the documents inside our Knowledge Base. So, we know how to summarize the documents or translate it, the pro
blem is how I will take that decision from a query from the user? Do we need to use agents or some Router?

How are you 
doing it? 
```
---

     
 
all -  [ How to stream the last message (final response) in LangGraph? ](https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/) , 2024-06-03-0953
```
Hey guys! Does anyone have any idea as to how I can stream **ONLY** the last message (which should also be the response 
received by the user) generated by my sequence of agents? I'm trying to build an UI for my LangGraph chatbot using Chain
lit, but with the condition of only streaming the part of the message that I want to be displayed. Can anyone help me wi
th that, please? Thank you!
```
---

     
 
all -  [ About to start my new grad job search, just wanted some criticism and advice! ](https://www.reddit.com/r/resumes/comments/1d5421v/about_to_start_my_new_grad_job_search_just_wanted/) , 2024-06-03-0953
```
https://preview.redd.it/gx7qkjh2dt3d1.png?width=1106&format=png&auto=webp&s=ee7865b9b11495098ee5e7e7d2979b3c1471462b

An
y advice for the resume. I'm doing another internship at the same team as last time, but I don't really want to go back 
here for full-time. Just wanted to start getting ready for the full-time job search and wondered if y'all had any advice
 for what to add/change from my current one. I might add the 3rd internship after June. Am going to be applying for New 
grad swe positions!
```
---

     
 
all -  [ Best resources on Evaluation / Agents and Tools ](https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/) , 2024-06-03-0953
```
I am facing an issue of agent not being able to pick the appropriate tool for the appropriate response?

Need to find be
tter ways to evaluate my prompts. 



```
---

     
 
all -  [ Have you gone to prod? ](https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/) , 2024-06-03-0953
```
Have any of you successfully deployed langchain in prod? As in actually getting money for a saas business of some sort? 
Tell me your experience? Whats your usecase and what Lang product did you use? 
```
---

     
 
all -  [ Limiting memory in Langchain RunnableWithMessageHistory ](https://www.reddit.com/r/RagAI/comments/1d51qjr/limiting_memory_in_langchain/) , 2024-06-03-0953
```
I am using RunnableWithMessageHistory for an application that needs sources and chat history. But unlike ConversationBuf
ferWindowMemory there is no way to limit memory in RunnableWithMessageHistory, any way I can limit the chat history to a
 specific number of turns?


```
---

     
 
all -  [ Can Crew AI agents execute a task based on instructions written in a document? ](https://www.reddit.com/r/crewai/comments/1d519qk/can_crew_ai_agents_execute_a_task_based_on/) , 2024-06-03-0953
```
Here is my use case:

I have a text file outlining the steps for completing tasks:

    Task A: Create Report
    1. Fin
d today's date.
    2. Read data from the 'my_info.csv' file where the 'plan_date' is today.
    3. Display the results.

    
    Task B: Copy File to FTP
    1. Export data from the report_table to an Excel file.
    2. Copy the file to th
e FTP path '/report'. 

I have developed tools to handle each individual step:

* current\_date\_tool
* steps\_search\_t
ool
* csv\_search\_tool
* export\_data\_tool
* ftp\_copy\_tool

**Crew Definition**

* process = Process.hierarchical
* 
Agents:
   * manager\_agent
   * supervisor agent
   * worker\_agent (can use all tools)
* Task = 'create report'

**My 
full source code:**

    from crewai_tools import tool
    import datetime
    from crewai import Agent, Task, Crew, Pro
cess
    from langchain_openai import ChatOpenAI
    from dotenv import load_dotenv
    from crewai_tools import TXTSear
chTool
    from crewai_tools import CSVSearchTool
    
    
    llm = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature
=0.1)
    
    @tool('CurrentDateTool')
    def current_date_tool() -> str:
        '''Tool to get the current date.'''

        return 'Today is ' + datetime.date.today().strftime('%Y-%m-%d (%A)')
    
    steps_search_tool = TXTSearchTool(
txt='task_steps.txt')
    
    csv_search_tool = CSVSearchTool()
    
    class MyCrew:
        
        def __init__(se
lf, task_description, expected_output, verbose=False):
            self.verbose = verbose
            # Define agents wi
th specific roles and tools
            worker_agent = Agent(
                role='Worker',
                goal=f'Perf
orm the tasks requested step by step.',
                backstory='''Perform the assigned tasks ''',
                too
ls=[current_date_tool, 
                       csv_search_tool], 
                verbose=self.verbose,
                
llm=llm
            )
    
            supervisor_agent = Agent (
                role = 'Supervisor',
                g
oal = 'Split the list of steps to individual tasks, and invoke appropriate agents for each step.',
                backs
tory = 'good at work breakdown and task allocation',
                verbose=self.verbose,
                llm=llm
     
       )
    
            manager_agent = Agent(
                role='Manager',
                goal=f'Delegate the ste
ps to other agents.',
                backstory='''PMP certified project manager''',
                verbose=self.verbos
e,
                llm=llm
            )
    
            # Create tasks for the agents
            main_task = Task(
  
              description = task_description, 
                expected_output = expected_output,
                tools=
[current_date_tool, 
                       steps_search_tool,
                       csv_search_tool], 
               
 agent=manager_agent
            )
    
            # Assemble the crew with a sequential process
            self.searc
h_crew = Crew(
                agents=[worker_agent,supervisor_agent],
                manager_agent=manager_agent,
    
            tasks=[main_task],
                process=Process.hierarchical,
                verbose=self.verbose,
     
       )
    
        
        def kickoff(self):
            return self.search_crew.kickoff()
    
    
    
    
    
if __name__ == '__main__':
        my_crew = MyCrew(task_description='List delayed Tasks',
                         expe
cted_output='Display the delayed task names.',
                         verbose=True) 
        print(my_crew.kickoff())


**Expected output:**  
Agents will identify the steps from the 'task\_steps.txt' file and execute them.

**Actual outpu
t:**  
Agents identify the steps from the 'task\_steps.txt' file and just display them.

P.S.: I have also reported this
 issue here: [https://github.com/joaomdmoura/crewAI/issues/717](https://github.com/joaomdmoura/crewAI/issues/717)
```
---

     
 
all -  [ Cant retrieve tables and how can i pass metadata? ](https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/) , 2024-06-03-0953
```
I am using Langchain's SQL Agent to execute queries in natural language on my MS-SQL database. Here is my code:

  
`fro
m langchain_community.agent_toolkits import create_sql_agent`

`from langchain_openai import ChatOpenAI`

`from langchai
n_community.utilities import SQLDatabase`

`import os`



`db = SQLDatabase.from_uri('mssql+pyodbc:///?odbc_connect=DRIV
ER={ODBC Driver 17 for SQL Server};SERVER=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')`

`model_name = 'gpt-4'`

`openai_api_key
 = os.environ['OPENAI_API_KEY']`



`llm = ChatOpenAI(model_name=model_name, temperature=0.0)`

`agent = create_sql_agen
t(llm, db=db, agent_type='openai-tools', verbose=True)`



`agent.invoke({`

`'input': 'How many article are there?'`

`
})`

  
When I run this, the agent starts hallucinating and tries to access a table named 'article,' which does not exis
t. The verbose parameter shows that it should retrieve all tables in the database, but it does not get the correct table
s. What could be the issue?

Additionally, I would like to provide metadata to explain the individual tables, but the 'm
etadata' parameter is not accepted.
```
---

     
 
all -  [ Langsmith - Get Test Results Python SDK ](https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/) , 2024-06-03-0953
```
Hey guys, due to suboptimal documentation, I really struggle to get the results of a evaluation via the langsmith client
. If someone could help, that would be amazing!



this is how I create the the exaluation:

    evaluate(
    predict_u
sing_rag_chain,
    data=hum_dataset_name, 
    evaluators=get_correctness_evaluators(),
    experiment_prefix='correctn
ess',
    metadata=metadata )

On langsmith I can see the results, e.g. via Projects > Evaluators. But if I use `client.
list_runs(project_name='evaluators')`  the results contain all runs and I didnt find any correct metadata, e.g. the uniq
ue experiment name (e.g.  experiment = 'correctness-329f6d79') to filter out a single evaluation on the dataset.

Would 
be amazing if you have an answer, I cannot imagine I am the only one with that problem.
```
---

     
 
all -  [ This week in AI - all the Major AI developments in a nutshell ](https://www.reddit.com/r/StableDiffusion/comments/1d4x69j/this_week_in_ai_all_the_major_ai_developments_in/) , 2024-06-03-0953
```
1. **The Simulation** (formerly Fable Studio) launched ***Showrunner***, a platform for users to create TV shows with AI
, dubbing it the 'Netflix of AI'. With just a 10-15 word prompt, users can generate scenes and episodes of 2-16 minutes,
 complete with AI dialogue, voices, editing, shot types, characters, and story development. Fable released a research pa
per last year on their SHOW-1 model and AI Showrunner Agents that can write, produce, direct, cast, edit, voice and anim
ate episodes of AI TV \[Details\].
2. **Mistral AI** introduced ***Codestral***, a 22B open-weight generative AI model e
xplicitly designed for code generation tasks. With its larger context window of 32k, Codestral outperforms CodeLlama 70B
, Llama 3 70B and DeepSeek Coder 33B. Codestral is licensed under the *new Mistral AI Non-Production License.* It is acc
essible through Le Chat, La Plateforme and is integrated into LlamaIndex and LangChain \[Details | Hugging Face\].
3. **
Cartesia** introduced ***Sonic***, a low-latency voice model that generates lifelike speech. The co-founders of Cartesia
 had created the state space model architecture. Sonic creates high quality lifelike speech for any voice with a model l
atency of 135msâ€”the fastest for a model of this class. Details on the new architecture will be released in a separate re
port. Sonic is released with a web playground and a low latency API \[Details\].
4. **AI4Finance** Foundation released *
**FinRobot***, a novel open-source AI agent platform supporting multiple financially specialized AI agents, each powered
 by LLM \[Details\].
5. **IEIT-Yuan** released ***Yuan2.0-M32***, a Mixture-of-Experts (MoE) language model with 32 expe
rts, of which 2 are active. Yuan 2.0-M32 is trained from scratch with 2000B token and has surpassed Llama3-70B on the MA
TH and ARC-Challenge benchmark \[Details\].
6. **llama3v**: a new SOTA vision model that is powered by Llama3 8B and sig
lip-so400m and trained with under $500. It outperforms LLaVA, the current open-source SOTA vision language model. llama3
v features comparable vision abilities of models close to 100x larger in size like GPT4v, Gemini Ultra, and Claude Opus 
\[Details | Hugging Face\].
7. **LLM360** released ***K2,*** a fully-reproducible 65 billion parameters large language m
odel outperforming Llama 2 70B using 35% less compute. K2 is fully transparent - LLM360 open-sourced all artifacts, incl
uding code, data, model checkpoints, intermediate results, and more \[Details\].
8. **Perplexity AI** released a new too
l ***Perplexity Pages***, enabling users to create comprehensive, visually appealing content on any topic. Users can typ
e in a topic and receive a structured draft instantly. Perplexity Pages offers the flexibility to create a page as a sep
arate entity, similar to writing a document with full internet access, or you can continue asking questions on Perplexit
y and convert them into the Page format with a one-click convert button \[Details\].
9. **Open-Sora** is now on V1.1.0. 
This open-source project aims to reproduce Sora OpenAIâ€™s text-to-video (T2V) model Sora. v1.1.0 significantly enhances v
ideo generation quality and text control capabilities \[Details\].
10. **Multimodal Art Projection (M-A-P)** Research re
leased ***MAP-Neo***, a bilingual language model with 7B parameters trained from scratch on 4.5T tokens. MAP-Neo is the 
first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs \[Details\
].
11. All **ChatGPT** Free users can now use browse, vision, data analysis, file uploads, and GPTs, earlier available t
o only pro subscribers \[Details\].
12. **Higgsfield** introduced ***NOVA-1*** text to video model that provides markete
rs with precise control. Companies can train a custom version of the NOVA-1 model using their product and brand assets \
[Details\].
13. **ByteDance** introduced ***INSTADRAG***, a rapid approach enabling high quality drag-based image editin
g in âˆ¼ 1 second. Code will be released in 2-4 weeks \[Details\].
14. **Suno** announced v3.5, which is now available to 
all users. It lets you make 4 minute songs, provides full song in a single generation and featres improved song structur
e and vocal flow. Make a song from any sound feature coming soon \[Details\].
15. **6079** announced AI Prize Fight, a f
irst-of-its-kind street fighting esports competition where teams will go head-to-head training AI agents for the champio
nship belt. Registration will begin the week of June 3rd \[Details\].
16. **Scale** released the ***SEAL Leaderboards***
, which rank frontier LLMs using curated private datasets that canâ€™t be gamed. The initial domains covered include Codin
g, Instruction Following, Math and Multilinguality \[Details\].
17. Researchers released ***AutoCoder***, a code LLM tha
t outperforms GPT-4 Turbo and GPT-4o on the HumanEval benchmark. Itâ€™s code interpreter can install external packages ins
tead of limiting to built-in packages tasks. The base model is deepseeker-coder \[Details\].Â 
18. **Microsoft** launched
 Copilot for Telegram - a personal generative AI assistant powered by GPT model and Bing Search, available within Telegr
am \[Details\].
19. **LMSYS Chatbot Arena Leaderboard** update: Gemini 1.5 Pro/Advanced at #2, closing in on GPT-4o. Gem
ini 1.5 Flash at #9, outperforming Llama-3-70b and nearly reaching GPT-4-0125 \[Link\].
20. **Udio** introduced Udio-130
, a new music generation model capable of two-minute generations and new features \[Details\].
21. Tools are now availab
le in **HuggingChat**. Tools open up a wide range of new possibilities, allowing the model to determine when a tool is n
eeded, which tool to use, and what arguments to pass (via function calling) \[Details\].
22. **SambaNova's** Samba-1 Tur
bo has set a new record for large language model inference performance in recent benchmarking by Artificial Analysis. Sa
mba-1 Turbo runs Llama 3 8B at 1000 tokens per second (t/s) on just 16 chips, and can concurrently host up to 1000 Llama
3 checkpoints on a single 16-socket SN40L node. This is the fastest speed for serving Llama 3, while maintaining full pr
ecision at a lower cost \[Details\].
23. **GitHub** announced the 2024 cohort for its GitHub Accelerator program, featur
ing 11 open-source AI projects \[Details\].
24. **Opera** browser has integrated Googleâ€™s Gemini AI models into its exis
ting Aria AI extension. Aria, released last year, acts like an AI assistant to answer user queries, write code, and perf
orm other tasks \[Details\].
25. Tool use, which enables Claude to interact with external tools and APIs, is now general
ly available across the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's V
ertex AI \[Details\].
26. Google adds new built-in AI-powered features to Chromebook \[Details\].
27. Gemini is now avai
lable in Chrome DevTools to help devs understand errors and warnings better with AI \[Details\].

Source: AI Brews - Lin
ks removed from this post due to auto-delete, but they are present in the [newsletter](https://aibrews.com/). it's free 
to join, sent only once a week with bite-sized news, learning resources and selected tools. Thanks!


```
---

     
 
all -  [ This week in AI - all the Major AI developments in a nutshell ](https://www.reddit.com/r/ArtificialInteligence/comments/1d4x3sg/this_week_in_ai_all_the_major_ai_developments_in/) , 2024-06-03-0953
```
1. **The Simulation** (formerly Fable Studio) launched ***Showrunner***, a platform for users to create TV shows with AI
, dubbing it the 'Netflix of AI'. With just a 10-15 word prompt, users can generate scenes and episodes of 2-16 minutes,
 complete with AI dialogue, voices, editing, shot types, characters, and story development. Fable released a research pa
per last year on their SHOW-1 model and AI Showrunner Agents that can write, produce, direct, cast, edit, voice and anim
ate episodes of AI TV \[Details\].
2. **Mistral AI** introduced ***Codestral***, a 22B open-weight generative AI model e
xplicitly designed for code generation tasks. With its larger context window of 32k, Codestral outperforms CodeLlama 70B
, Llama 3 70B and DeepSeek Coder 33B. Codestral is licensed under the *new Mistral AI Non-Production License.* It is acc
essible through Le Chat, La Plateforme and is integrated into LlamaIndex and LangChain \[Details | Hugging Face\].
3. **
Cartesia** introduced ***Sonic***, a low-latency voice model that generates lifelike speech. The co-founders of Cartesia
 had created the state space model architecture. Sonic creates high quality lifelike speech for any voice with a model l
atency of 135msâ€”the fastest for a model of this class. Details on the new architecture will be released in a separate re
port. Sonic is released with a web playground and a low latency API \[Details\].
4. **AI4Finance** Foundation released *
**FinRobot***, a novel open-source AI agent platform supporting multiple financially specialized AI agents, each powered
 by LLM \[Details\].
5. **IEIT-Yuan** released ***Yuan2.0-M32***, a Mixture-of-Experts (MoE) language model with 32 expe
rts, of which 2 are active. Yuan 2.0-M32 is trained from scratch with 2000B token and has surpassed Llama3-70B on the MA
TH and ARC-Challenge benchmark \[Details\].
6. **llama3v**: a new SOTA vision model that is powered by Llama3 8B and sig
lip-so400m and trained with under $500. It outperforms LLaVA, the current open-source SOTA vision language model. llama3
v features comparable vision abilities of models close to 100x larger in size like GPT4v, Gemini Ultra, and Claude Opus 
\[Details | Hugging Face\].
7. **LLM360** released ***K2,*** a fully-reproducible 65 billion parameters large language m
odel outperforming Llama 2 70B using 35% less compute. K2 is fully transparent - LLM360 open-sourced all artifacts, incl
uding code, data, model checkpoints, intermediate results, and more \[Details\].
8. **Perplexity AI** released a new too
l ***Perplexity Pages***, enabling users to create comprehensive, visually appealing content on any topic. Users can typ
e in a topic and receive a structured draft instantly. Perplexity Pages offers the flexibility to create a page as a sep
arate entity, similar to writing a document with full internet access, or you can continue asking questions on Perplexit
y and convert them into the Page format with a one-click convert button \[Details\].
9. **Open-Sora** is now on V1.1.0. 
This open-source project aims to reproduce Sora OpenAIâ€™s text-to-video (T2V) model Sora. v1.1.0 significantly enhances v
ideo generation quality and text control capabilities \[Details\].
10. **Multimodal Art Projection (M-A-P)** Research re
leased MAP-Neo, a bilingual language model with 7B parameters trained from scratch on 4.5T tokens. MAP-Neo is the first 
fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs \[Details\].
11.
 All ChatGPT Free users can now use browse, vision, data analysis, file uploads, and GPTs, earlier available to only pro
 subscribers \[Details\].
12. **Higgsfield** introduced ***NOVA-1*** text to video model that provides marketers with pr
ecise control. Companies can train a custom version of the NOVA-1 model using their product and brand assets \[Details\]
.
13. **ByteDance** introduced INSTADRAG, a rapid approach enabling high quality drag-based image editing in âˆ¼ 1 second.
 Code will be released in 2-4 weeks \[Details\].
14. **Suno** announced v3.5, which is now available to all users. It le
ts you make 4 minute songs, provides full song in a single generation and featres improved song structure and vocal flow
. Make a song from any sound feature coming soon \[Details\].
15. **6079** announced AI Prize Fight, a first-of-its-kind
 street fighting esports competition where teams will go head-to-head training AI agents for the championship belt. Regi
stration will begin the week of June 3rd \[Details\].
16. **Scale** released the ***SEAL Leaderboards***, which rank fro
ntier LLMs using curated private datasets that canâ€™t be gamed. The initial domains covered include Coding, Instruction F
ollowing, Math and Multilinguality \[Details\].
17. Researchers released ***AutoCoder***, a code LLM that outperforms GP
T-4 Turbo and GPT-4o on the HumanEval benchmark. Itâ€™s code interpreter can install external packages instead of limiting
 to built-in packages tasks. The base model is deepseeker-coder \[Details\].Â 
18. **Microsoft** launched Copilot for Tel
egram - a personal generative AI assistant powered by GPT model and Bing Search, available within Telegram \[Details\].

19. **LMSYS Chatbot Arena Leaderboard** update: Gemini 1.5 Pro/Advanced at #2, closing in on GPT-4o. Gemini 1.5 Flash at
 #9, outperforming Llama-3-70b and nearly reaching GPT-4-0125 \[Link\].
20. **Udio** introduced Udio-130, a new music ge
neration model capable of two-minute generations and new features \[Details\].
21. Tools are now available in **HuggingC
hat**. Tools open up a wide range of new possibilities, allowing the model to determine when a tool is needed, which too
l to use, and what arguments to pass (via function calling) \[Details\].
22. **SambaNova's** Samba-1 Turbo has set a new
 record for large language model inference performance in recent benchmarking by Artificial Analysis. Samba-1 Turbo runs
 Llama 3 8B at 1000 tokens per second (t/s) on just 16 chips, and can concurrently host up to 1000 Llama3 checkpoints on
 a single 16-socket SN40L node. This is the fastest speed for serving Llama 3, while maintaining full precision at a low
er cost \[Details\].
23. **GitHub** announced the 2024 cohort for its GitHub Accelerator program, featuring 11 open-sour
ce AI projects \[Details\].
24. Opera browser has integrated Googleâ€™s Gemini AI models into its existing Aria AI extensi
on. Aria, released last year, acts like an AI assistant to answer user queries, write code, and perform other tasks \[De
tails\].
25. Tool use, which enables Claude to interact with external tools and APIs, is now generally available across 
the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's Vertex AI \[Details\]
.
26. Google adds new built-in AI-powered features to Chromebook \[Details\].
27. Gemini is now available in Chrome DevT
ools to help devs understand errors and warnings better with AI \[Details\].

Source: AI Brews - Links removed from this
 post due to auto-delete, but they are present in the [newsletter](https://aibrews.com/). it's free to join, sent only o
nce a week with bite-sized news, learning resources and selected tools. Thanks!
```
---

     
 
all -  [ We need you! FOSS local machine LLM client ](https://www.reddit.com/r/u__Wilielmus_/comments/1d4x38l/we_need_you_foss_local_machine_llm_client/) , 2024-06-03-0953
```
# Hello everyone!

My name is William, and I'm an Italian teenager passionate about computer science. I'm here to ask fo
r help developing my latest project, OpenLocalUI, a local LLM client. The project is based on Ollama and uses Flutter (D
art) for the UI and LangChain for LLM interaction (via a Python gRPC server).

But why work to yet another app to run LL
Ms on your PC, when there are already plenty of alternatives out there? Simple, **to do it better**! There is a somewhat
 paradoxical concept that expresses my goal:

>'Build open-source like closed-source.'

Most FOSS (Free and Open-Source 
Software) share the same issue; while offering powerful tools, the usage of those tools is often convoluted and hidden u
nder layers of poor UI and UX design, which is quite anachronistic! Nowadays, we have all the tools to build better expe
riences (and not just software) for users. It's time to refuse the idea that open-source software is a niche and work to
 help everyone embrace it.

Thanks for reading this far :)

So, did you get inspired? (I hope so!)

If the answer is yes
, take a look at the repository at this [link](https://github.com/WilliamKarolDiCioccio/open_local_ui). My collaborators
 and I will happily greet you on our team to help us build our vision.
```
---

     
 
all -  [ log analyzer using llm ](https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/) , 2024-06-03-0953
```
Hi

I am trying to develop log analysis tool using llms

My requirements are as follows:

1. It should extract and find 
failure lines having some pattern specified in the prompt.
2. It should load the image of given path from the logs.

Can
 some please guide how can I create RAG for this data and extract using llm?
```
---

     
 
all -  [ Join Us in Developing a Flutter Client for Mattermost with AI-Generated Code! ğŸš€
 ](https://www.reddit.com/r/FlutterDev/comments/1d4t671/join_us_in_developing_a_flutter_client_for/) , 2024-06-03-0953
```
Hi Flutter Devs!

We're excited to announce an innovative project: developing a Mattermost client in Flutter, leveraging
 AI to kickstart the process. ğŸš€

# About the Project:

Mattermost is a powerful open-source messaging platform designed 
for team collaboration. Our goal is to bring Mattermost to the Flutter community, making it accessible on all platforms 
- mobile, web, and desktop. This project uses AI to generate the initial codebase, providing a solid foundation for furt
her development and enhancement.

# Why This Project is Unique:

* \*\*AI-Generated Code:\*\* We've used CrewAI, built o
n top of Langchain, to generate the initial codebase. This innovative approach has given us a head start, and now we nee
d your expertise to refine and make it production-ready.
* \*\*Open Source:\*\* We are committed to open-source principl
es and welcome contributions from developers around the world.

# How You Can Contribute:

1. \*\*Check Out the Code:\*\
* Start by exploring the \[GitHub repository\](https://github.com/alippo-com/mattermost-flutter).
2. \*\*Apply to Contri
bute:\*\* Fill out our \[Contributor Application Form\](https://forms.gle/rd7KPsUztfTbsEJx8) to tell us more about your 
skills and experience.
3. \*\*Join Our Community:\*\* Connect with us on our \[Discord channel\](https://discord.gg/gmz5
Jte6xj) to stay updated and collaborate with other contributors.

# What Weâ€™re Looking For:

* Passionate Flutter develo
pers interested in contributing to a high-impact project.
* Developers with experience in UI/UX design, frontend develop
ment, backend development, testing, and project management.
* Contributors who can help us ensure the best practices and
 security standards.

# Next Steps:

* We are actively working on making the codebase executable. Your contributions can
 help accelerate this process.
* Weâ€™re planning to host a kickoff meeting to discuss the project in detail and answer an
y questions.

Join us on this exciting journey to create a robust Mattermost client in Flutter. Letâ€™s build something am
azing together! ğŸ’™

\[GitHub Repo Link\](https://github.com/alippo-com/mattermost-flutter) | \[Contributor Application Fo
rm\](https://forms.gle/rd7KPsUztfTbsEJx8) | \[Discord Channel\](https://discord.gg/gmz5Jte6xj)

Feel free to ask any que
stions in the comments. Looking forward to collaborating with you!

Best,

Prince  
VP Engineering, Alippo
```
---

     
 
all -  [ Langchain with Llama.cpp not Llama.cpp-python ](https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/) , 2024-06-03-0953
```
I'm using Langchain with LLama.cpp-python because it I was the fastest solution I found out.

I notice an issue on Llama
.cpp github that stated that LLama.cpp-python is significantly slower than the original LLama.cpp, which I found to be t
rue, at least for the tests I ran.

I was wondering if there is any way to use only LLama.cpp with Langchain and not Lla
ma.cpp-python.
```
---

     
 
all -  [ Getting completely ignored by employers, What wrong with my resume ?  ](https://www.reddit.com/r/resumes/comments/1d4rbw4/getting_completely_ignored_by_employers_what/) , 2024-06-03-0953
```
I have applied to at least 25 places for an internship this summer and I keep getting rejected or ignored. If anyone cou
ld help me fix my resume lemme know.

https://preview.redd.it/jwxcodosaq3d1.png?width=713&format=png&auto=webp&s=52594de
9f0c23e5f6abee303bc8dd9ad61110df6


```
---

     
 
all -  [ Long running time for document retrieval with ollama3  ](https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/) , 2024-06-03-0953
```
Hi,

I'm a newbie in the world of RAGs and LLMs but is it normal that the document retrieval takes 9-10 minutes?

I'm us
ing locally the llama3:8b model with ollama, Chroma es a vectorstore but these parts are quite fast compared to the invo
ke() method which is the slowest one. My computer has 64 GB of RAM.

Thanks
```
---

     
 
all -  [ Is LangChain usable? ](https://www.reddit.com/r/LocalLLaMA/comments/1d4p1t6/is_langchain_usable/) , 2024-06-03-0953
```
I donâ€™t know you, but when I build an LLM app for a client LangChain is always more of a hassle to get started than just
 writing the â€˜supportingâ€™ code myself.

This counts for simple chains, but also for agents and function calling!

Anyone
 agree? 
```
---

     
 
all -  [ I'm trying out a new tool and I need some help ](https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/) , 2024-06-03-0953
```
I need a way to ingest 10 PDFs containing financial information and then I need to able to ask an LLM to make me custom 
charts and graphs based on the data there is in those 10PDFs. need the LLM to have context of all 120 PDFs or it to do a
 good job. How do i proceed ahead with something like this? 
```
---

     
 
MachineLearning -  [ [R] Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI ](https://www.reddit.com/r/MachineLearning/comments/1crwh0q/r_building_an_observable_arxiv_rag_chatbot_with/) , 2024-06-03-0953
```
HeyÂ r/MachineLearning, I published a new article where I built an observable semantic research paper application.

This 
is an extensive tutorial where I go in detail about:

1. Developing a RAG pipeline to process and retrieve the most rele
vant PDF documents from the arXiv API.
2. Developing a Chainlit driven web app with a Copilot for online paper retrieval
.
3. Enhancing the app with LLM observability features from Literal AI.

You can read the article here:Â [https://medium.
com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8](h
ttps://medium.com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9
c345fcd1cd8)

Code for the tutorial:Â [https://github.com/tahreemrasul/semantic\_research\_engine](https://github.com/tah
reemrasul/semantic_research_engine)


```
---

     
 
MachineLearning -  [ [P] LLMinator: A Llama.cpp + Gradio based opensource Chatbot to run llms locally(cpu/cuda) directly  ](https://www.reddit.com/r/MachineLearning/comments/1cpbgd1/p_llminator_a_llamacpp_gradio_based_opensource/) , 2024-06-03-0953
```
Hi I am currently working on a context-aware streaming chatbot based on Llama.cpp, Gradio, Langchain, Transformers. LLMi
nator can pull LLMs directly from HF & run them locally on cuda or cpu.

I am looking for recommendations & help from op
ensource community to grow this further.

**Github Repo:**Â [https://github.com/Aesthisia/LLMinator](https://github.com/A
esthisia/LLMinator)

**Goal:**Â To help developers with kickstarter code/tool to run LLMs.

https://preview.redd.it/fnzja
7rjwqzc1.png?width=1846&format=png&auto=webp&s=a62c43614d63e82156fef8722b986b051cc1795b

**Features:**

* Context-aware 
Chatbot.
* Inbuilt code syntax highlighting.
* Load any LLM repo directly from HuggingFace.
* Supports both CPU & Cuda m
odes.
* Load & Offload saved models.
* Command Line Args
* API Access(Soon to be available)

Any review or feedback is a
ppreciated.
```
---

     
