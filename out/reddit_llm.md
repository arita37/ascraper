 
all -  [ Need help processing your data before embedding it? ](https://www.reddit.com/r/LangChain/comments/16iv7v9/need_help_processing_your_data_before_embedding_it/) , 2023-09-15-0909
```
Hey,  


We just published a playground to help developers test out different pre-processing configurations for their da
ta. This includes loaders, selectors and splitters. It uses parts of Langchain as well as some custom loaders and splitt
ers built by Neum AI. (All open source) Feel free to try it out here: [https://neumai-playground.streamlit.app/](https:/
/neumai-playground.streamlit.app/)

If you want to see an overview, check out this video: [https://www.youtube.com/watch
?v=n3L680vmGJo&t=5s](https://www.youtube.com/watch?v=n3L680vmGJo&t=5s)  


Repo:  [NeumTry/pre-processing-playground (gi
thub.com)](https://github.com/NeumTry/pre-processing-playground)   


What else would you like to be able to do in the p
layground?   

```
---

     
 
all -  [ Using LangChain to generate ROS (Robotic Operating System) ](https://www.reddit.com/r/LangChain/comments/16iv2j1/using_langchain_to_generate_ros_robotic_operating/) , 2023-09-15-0909
```
Me and my team at RoboCoach Inc. have used LangChain and GPT3.5 to capture the details of a robotic design and to automa
tically implement all ROS (Robot Operating System) packages for the robotic project. This is the tool:

[https://github.
com/RoboCoachTechnologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

Demo: [https://www.youtube.com/w
atch?v=H2QaeelkReU](https://www.youtube.com/watch?v=H2QaeelkReU)

ROScribe is an open source project and we welcome all 
of you to use it and be part of this community. If you liked the tool, you can send us a video recording of your use-cas
e and we will put it on our github. We will credit all contributors at every release.
```
---

     
 
all -  [ Using GPT and LangChain to build robotic projects ](https://www.reddit.com/r/ChatGPT/comments/16iv0vr/using_gpt_and_langchain_to_build_robotic_projects/) , 2023-09-15-0909
```
Me and my team have used LangChain and GPT3.5 to capture the details of a robotic design and to automatically implement 
all ROS (Robot Operating System) packages for the robotic project. This is the tool:

[https://github.com/RoboCoachTechn
ologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

Demo: [https://www.youtube.com/watch?v=H2QaeelkReU
](https://www.youtube.com/watch?v=H2QaeelkReU)

ROScribe is an open source project and we welcome all of you to use it a
nd be part of this community. If you liked the tool, you can send us a video recording of your use-case and we will put 
it on our github. We will credit all contributors at every release.  
```
---

     
 
all -  [ [P] Ways to speed up llama-2 summarization on sagemaker? ](https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/) , 2023-09-15-0909
```
 

I'm currently working on a project to give a quick summary of long articles/conversations.

I'm running llama-2-7b-ch
at-hf with 4bit quantization on a g5.2xlarge instance on sagemaker.

The method I'm using is map\_reduce (option 2)from 
this webpage [https://python.langchain.com/docs/use\_cases/summarization](https://python.langchain.com/docs/use_cases/su
mmarization))

Of everything I've tried this is the only one that's been able to do decent summaries in a reasonable amo
unt of time. However with really long articles (10,000+ words) it takes \~6 minutes before giving an output.

I tried ru
nning this same thing on a g5.12xlarge instance which has 4 A10G gpus but it hasn't reduced the time by any noticeable a
mount.

Is there anything else I could be doing to speed this up?
```
---

     
 
all -  [ Step-by-step tutorial on creating your own Notion chatbot using LangChain, OpenAI GPT, FAISS and Str ](https://www.reddit.com/r/LangChain/comments/16ite4d/stepbystep_tutorial_on_creating_your_own_notion/) , 2023-09-15-0909
```
&#x200B;

https://i.redd.it/srbnmwfd9aob1.gif

If you have ever wanted to chat directly with your own Notion data, right
 in Notion, have a look at this step-by-step tutorial on how to do it, using LangChain, OpenAI GPT, and Streamlit! üí™

It
's now live on the Streamlit: [https://blog.streamlit.io/build-your-own-notion-chatbot/](https://blog.streamlit.io/build
-your-own-notion-chatbot/)

Let me know what you think!
```
---

     
 
all -  [ Build your own Notion chatbot using Streamlit, LangChain and OpenAI ](https://www.reddit.com/r/StreamlitOfficial/comments/16itah3/build_your_own_notion_chatbot_using_streamlit/) , 2023-09-15-0909
```
&#x200B;

https://i.redd.it/3rzmszvq8aob1.gif

If you have ever wanted to chat directly with your own Notion data, right
 in Notion, follow my step-by-step tutorial on how to do it, using LangChain, OpenAI GPT, and Streamlit! üí™

It's now liv
e on the Streamlit: [https://blog.streamlit.io/build-your-own-notion-chatbot/](https://blog.streamlit.io/build-your-own-
notion-chatbot/)

Let me know what you think!
```
---

     
 
all -  [ [Hiring] ($20-40/hr) Experienced LangChain Developers ](https://www.reddit.com/r/forhire/comments/16ipz4a/hiring_2040hr_experienced_langchain_developers/) , 2023-09-15-0909
```
**NOTE:** No agencies and please answer each question below

**Preface**: I work on different AI projects using Langchai
n and could use some help. Please only apply if you have worked with Langchain. Go ahead and message me the answers to t
he below questions and Ill get back shortly.

**Questions:**

1. How much experience with Python and/or Javascript?
2. T
ell me about your experience with Langchain/GPT applications
3. Do you have experience with web application development?

4. Please provide your LinkedIn and resumeThanks!
```
---

     
 
all -  [ [Hiring] ($20-40/hr) Experienced LangChain Developers ](https://www.reddit.com/r/forhire/comments/16ipz47/hiring_2040hr_experienced_langchain_developers/) , 2023-09-15-0909
```
**NOTE:** No agencies and please answer each question below

**Preface:** I have some different AI projects using OpenAI
 and could use some help. Please only apply if you have worked with Langchain. Go ahead and message me the answers to th
e below questions and Ill get back shortly.

**Questions:**

1. How much experience with Python and/or Javascript?
2. Te
ll me about your experience with Langchain/GPT applications
3. Do you have experience with web application development?

4. Please provide your LinkedIn and resumeThanks!
```
---

     
 
all -  [ I created my first ever side project - A gpt4 based document editor that generates text and images ](https://www.reddit.com/r/nextjs/comments/16ipk1h/i_created_my_first_ever_side_project_a_gpt4_based/) , 2023-09-15-0909
```
Hi Everyone,

As someone with a fulltime job and not that great coding skills its been difficult to ever get out a worki
ng side project. I recently joined buildspace season 4 - a 6 week online building challenge - and finally managed to get
 this over the line. Only have a handful of users and not really sure if this product is super useful so would love to h
ave some feedback.

**What is it:** A very simple and easy to use AI document editor that uses GPT-4 to generate text an
d images. The text generated is based off your previous text and documents so theoritcally it should be in your own voic
e.

**The idea behind it:** I wanted to start to reimagine documents and what they can be used for. Right now my project
 is only really useful for writing related tasks, but my idea in the beginning was to always include AI agents somehow t
o make documents 'alive' and complete tasks for you while youre away. If you're interested in that kind of stuff do foll
ow my journey to continue building this on twitter ([www.twitter.com/thetansen](https://www.twitter.com/thetansen)).

**
The tech:** Its using nextJs 13 but still using the pages directory as I've built this off of Vercels Platforms template
 which you can find here ([https://vercel.com/templates/next.js/platforms-starter-kit](https://vercel.com/templates/next
.js/platforms-starter-kit)), so it became a bit of a mismatch. For calling gpt4 im using langchain to call gpt-4  and pi
necone as my vector db to hold all the document data to pass in.For the text editor I'm using editorJS.

&#x200B;

**Che
ck it out here:**  [www.typenotes.ai](https://www.typenotes.ai)
```
---

     
 
all -  [ Chat with your database ](https://www.gettingstarted.ai/tutorial-on-how-to-convert-natural-language-text-to-sql-using-langchain/) , 2023-09-15-0909
```
Hey üëã I just published a post about converting natural language to SQL using LangChain:

I‚Äôd love to read your comments 
and feedback!

(For the pros out there, if there are technical or content improvements pls share!)
```
---

     
 
all -  [ Searching for chunking algorithms and repo ](https://www.reddit.com/r/LangChain/comments/16in3e6/searching_for_chunking_algorithms_and_repo/) , 2023-09-15-0909
```
Hi everyone! 

I'm still experiencing with my own implementation of rag, and I deployed my custom chunking function (hon
estly don't like the methods on LangChain) . 

Anyway, I'm searching for alternative methods, algoritms (NLP or not) and
 models... There are lots of info and different implementation on RAG, but as I can see noone put much effort to augment
 chunking quality. 

Also, there are other approach than this one I'm currently using? bi-encoder (instructor) - > cross
-encoder (reranking) - > LLM 


Can someone share some resources, repo, lib or existing implementation of different chun
king methods? 
(or simply discuss here some idea, though or approach) 

*Thanks in advance for you time!!*
```
---

     
 
all -  [ The rollercoaster journey behind launching the HelpKit AI Notion Chatbot ](https://www.reddit.com/r/SaaS/comments/16imj0g/the_rollercoaster_journey_behind_launching_the/) , 2023-09-15-0909
```
Hey folks!

Today I want to talk with you about the journey behind launching HelpKit AI. It wasn't a smooth sailing! 

H
elpKit is a solo founded and fully bootstrapped SaaS tool that turns your Notion docs into a professional help center an
d documentation site.

Since HelpKit is already hosting hundreds of customers Notion knowledge bases it only made sense 
to supercharge them with a custom AI trained chatbot. So far the results have been amazing.

And now, we just finally [l
aunched today on Product Hunt](https://www.producthunt.com/posts/helpkit-ai) as well! The public beta is out since two w
eeks and we have onboarded more than 15 customers on the add-on and the AI bot held 2000+ successful conversations.The l
aunch was planned two months ago but some things stopped me from releasing it.

If you are curious about the background,
 here it is. Let me explain why the journey to the launch was a bit rougher than expected. There were two big issues: Th
e UX and building on top of AI.

&#x200B;

**The UX Hurdle**

First and foremost, I was stuck with developing a great us
er experience. I have only come across a handful of products that were sort of implementing the same concept and I reall
y did not like their UX implementation. Everything felt clunky and just did not fit into the concept of an AI enabled kn
owledge base system.

You see our AI chatbot needs to be integrated into HelpKit‚Äôs two layouts: Help Center and Document
ation and also work well on the widget and mobile.Quite a tricky task to get right everywhere! I brainstormed for a few 
days, tried out some implementations but none of them felt natural for a user in my opinion.

I even spent a whole week 
building an interface only to then throw away the entire feature code branch and start from scratch.What I needed was a 
break. So I took a weekend break, spent some time at the beach and came back refreshed with some new ideas (that strange
ly all came to me during my Sunday evening shower).

I realised that the most intuitive way to present the option to cha
t with an AI powered chatbot assistant is when the user is already searching for something. So this way, should our norm
al search not be able to deliver an instant search result, users can be ‚Äúcatched‚Äù and still have their problem resolved 
by the AI.

In terms of the UI, I decided to go with a slick right sidebar interface for the chatbot on the help center 
layout and a nicely integrated chat window within the search command bar of the documentation layout. Within the HelpKit
 embeddable widget as well as on mobile phones, HelpKit AI will show a full-screen chatbot interface to the user.

Overa
ll, the HelpKit public beta has been running for 2 weeks and users as well as customers are really satisfied with the gr
eat user experience. Which‚Ä¶ also obviously makes me super happy „ÉÑ

&#x200B;

**Building on top of AI**

HelpKit AI is my
 first real touchpoint developing a product with Large Language Models (LLMs). After doing some simple warm-up Hello Wor
ld AI tests, everything seemed so simple.

Unfortunately I had to soon find out that I sincerely underestimated the comp
lexity involved in developing a conversational AI chatbot that closely mirrors human interaction.

Following a considera
ble period of experimentation with a plethora of existing tools, it's become apparent that the majority merely repurpose
 around 10 lines of Langchain code, presenting it as a fully-fledged product.The outcomes of these efforts are, at their
 best are 'meh'.

Some OK, but not great.I nearly fell into the same trap, having developed a feature that was 90% compl
ete before acknowledging the subpar and cluttered results, as well as my limited comprehension of this new technology.


Engaging with LLMs presents an entirely unique and novel paradigm.Consequently, I revisited the initial plans and invest
ed a lot of more time immersing myself in the intricacies of LLMs, AI User Experience, and a slew of way too complex res
earch papers, all in an effort to better understand how to construct tools around LLMs.

Interestingly, due to the novel
ty of this field, there's no definitive roadmap to a successful implementation. The process is characterized by a great 
deal of experimentation. You really need a flexible approach and swift adaptation to the frequent and rapid enhancements
 being made to these tools. As an engineer being used to having deterministic outcomes I just couldn‚Äôt believe the quirk
iness of testing out bunch of prompts to find out what works the best.

In the end everything finally clicked and I know
 exactly what I was doing and how I can make HelpKit AI as best as possible.

&#x200B;

**Wrapping up**

So that‚Äôs my li
ttle background story of building HelpKit AI and some of the struggles that I had. The biggest takeaway lesson from me h
ere was to realize that sometimes you need to stop being so harsh on yourself and accept that some things are more diffi
cult than others. You might need a little bit more time than you thought.

The beautiful thing for us Indiehackers is th
at we don‚Äôt have any pressuring project manager sitting behind our back pressuring us to release something despite the q
uality but somehow we still tend pressure ourselves even harder into it.

Take a step back, breath, learn more and then 
come back stronger.In case you are interested you can find the [HelpKit AI landing page here](https://www.helpkit.so/hel
pkit-ai/) and I also recorded a little [Youtube video demoing HelpKit AI](https://www.youtube.com/watch?v=RhWrzh9pk-c) y
ou can check out.

&#x200B;

That's it!

&#x200B;

Hope this was useful to some of you reading this and also thinking ab
out embarking on the journey of building a big new feature for your product.
```
---

     
 
all -  [ I am unable to import csv_agents in langchain ](https://www.reddit.com/r/LangChain/comments/16im8h7/i_am_unable_to_import_csv_agents_in_langchain/) , 2023-09-15-0909
```
I am building a web application to query data from CSV files and tried importing csv langchain agent using this command,
 which was taken from langchain documentation:

'from langchain.agents import create\_csv\_agent'

However, this module 
is just not getting imported and I am getting an error whenever I use 'create\_csv\_agent' function. I am using VSCode t
o run my code by the way. Any idea why this keeps happening?
```
---

     
 
all -  [ I built an AI Agent (BondAI) that actually works and has a friendly API for easy integration into ot ](https://www.reddit.com/r/AI_Agents/comments/16il2ss/i_built_an_ai_agent_bondai_that_actually_works/) , 2023-09-15-0909
```
üì¢ Hello AI agent builders!

I'm thrilled to introduce you to **BondAI**, an AI Agent framework and CLI, with a lightweig
ht yet robust API making integration into your own applications straightforward and easy.

**Repository:** [**https://gi
thub.com/krohling/bondai**](https://github.com/krohling/bondai)

# ‚ö°Ô∏èExamples

Here's an example of buying/selling Stock
s with [Alpaca Markets](https://alpaca.markets/). I strongly recommend using Paper Trading btw!

    from bondai import 
Agent
    from bondai.tools.alpaca_markets import CreateOrderTool, GetAccountTool, ListPositionsTool
    
    task = '''
I want you to sell off all of my existing positions.
    Then I want you to buy 10 shares of NVIDIA with a limit price o
f $456.'''
    
    Agent(tools=[
      CreateOrderTool(),
      GetAccountTool(),
      ListPositionsTool()
    ]).run(
task)

[**Here's an example**](https://github.com/krohling/bondai/tree/main/examples/online-research) of BondAI doing on
line research and [**here's a home automation example**](https://github.com/krohling/bondai/tree/main/examples/home-auto
mation).

# üîç What is BondAI?

**BondAI** is a framework crafted for the smooth integration and customization of Convers
ational AI Agents. Leveraging the power of OpenAI's [**function calling support**](https://openai.com/blog/function-call
ing-and-other-api-updates), it sidesteps the hurdles often encountered in building a Conversational Agent, offering solu
tions such as:

* Memory management
* Error handling
* Integrated semantic search
* A rich array of pre-existing tools
*
 Ease of crafting custom tools

Moreover, it offers a **CLI interface** that promises an impressive command line agent e
xperience, available to anyone with an OpenAI API Key!

# üèóÔ∏è Why build BondAI?

I am convinced that AI agents hold the f
uture. Despite their phenomenal problem-solving abilities, the existing tooling often fell short in performing simple ta
sks, and the frameworks appeared unnecessarily complicated. This spurred the birth of **BondAI**, aiming to address thes
e shortcomings and offer a more optimized environment for agent implementations.

I am keen on hearing your feedback on 
**BondAI**'s functionality and any suggestions for improvements!

# üõ†Ô∏è Installation & Usage

Get started with BondAI wit
h a simple: pip install bondai  
The CLI tool offers a ready-to-use agent experience packed with several default tools. 
You can also integrate it with various tools such as Google Search, Alpaca Markets, and LangChain Tools to execute a myr
iad of tasks effectively. Detailed guides and examples for usage are available in the README.

# üîß APIs and Custom Tools


The BondAI framework offers flexible APIs to build your agent and create custom tools for a personalized experience. I
t follows a straightforward implementation approach, making the tool creation process hassle-free for developers.

Examp
les of included Tools:

* Google and Duck Duck Go Search
* Semantic Search for Files and Websites
* Alpaca Markets
* Gma
il Integration
* Easily import tools from LangChain!

# üêã Docker Container

For a secure environment, especially while u
sing tools with file system access, running **BondAI** within a docker container is highly recommended. Follow the steps
 in the REAME to easily build and run the **BondAI** container.

üöÄ Join the mission; contribute to BondAI! And please sh
are feedback/ideas in the comments!
```
---

     
 
all -  [ Hybrid similarity scores? EG, jaccard + cosine ](https://www.reddit.com/r/datascience/comments/16ij333/hybrid_similarity_scores_eg_jaccard_cosine/) , 2023-09-15-0909
```
Hello,

I'm making my way around the langchain circuit and practicing with langsmith. I am no stranger to accuracy tests
, I don't mind harmonic mean jokes because that's exactly what an f1 is.

Is there an analogous approach to similarity s
cores? For example, jaccard doesn't capture the magnitude or direction of the vectors, while cosine doesn't consider the
 order, frequency, or the context of the words.

Can i combine these scores into a hybrid accuracy score?
```
---

     
 
all -  [ TheBloke/Llama-2-7b does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt  ](https://www.reddit.com/r/deeplearning/comments/16ihzn8/theblokellama27b_does_not_appear_to_have_a_file/) , 2023-09-15-0909
```
Hey everyone!

As you can guess from the title, this is the error I get. I only changed the model in AutoModelForCausalL
M, Older version was 

&#x200B;

&#x200B;

`'''`

`model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-c
hat-hf',`

`device_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

`'''`

&#x200B;

However, si
nce my GPU is NVIDIA GeForce RTX 2080 TI, it answers a simple question in 20 mins. Then I changed it to: 

`model = Auto
ModelForCausalLM.from_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',`

`model_file = 'llama-2-7b-chat.q4_K_M.gguf',`

`devi
ce_map ='auto',`

`torch_dtype = torch.float16,`

`use_auth_token = True)`

&#x200B;

However, this is not working, and 
giving the error. Below is the full code, if it is needed to solve.

&#x200B;

&#x200B;

from langchain.document\_loader
s import JSONLoader

from langchain.text\_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTe
xtSplitter

from langchain.embeddings import HuggingFaceEmbeddings

from langchain.vectorstores import Chroma

from lang
chain import HuggingFacePipeline

from langchain.chains import ConversationalRetrievalChain

from langchain.memory impor
t ConversationBufferMemory

from langchain.embeddings.openai import OpenAIEmbeddings

from langchain.embeddings.huggingf
ace import HuggingFaceEmbeddings

from langchain.chat\_models import ChatOpenAI

import os

import sys

import huggingfa
ce\_hub

from huggingface\_hub import notebook\_login

import torch

import transformers

from transformers import AutoT
okenizer, AutoModelForCausalLM, pipeline

from torch import cuda, bfloat16

import chromadb

from pathlib import Path

f
rom pprint import pprint

import json

from loader import JSONLoader

from [langchain.prompts.chat](https://langchain.pr
ompts.chat) import PromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate

import j
son

from langchain.docstore.document import Document

&#x200B;

def parse\_json(json\_data):

'''Parse JSON data into a
 Python dictionary.'''

return json.loads(json\_data)

&#x200B;

def create\_doc(json\_data):

'''Create a Document obje
ct from JSON data.'''

data = parse\_json(json\_data)

content\_value = ''

&#x200B;

\# Collect values of keys that con
tain 'item' in their name

for key, value in data.items():

if 'item' in key.lower():

content\_value += value + '\\n' 




&#x200B;

return Document(page\_content=content\_value, metadata={'company': data\['company'\]})

&#x200B;

&#x200B;


\##embed\_model\_id = 'BAAI/bge-base-en' ## CHANGE

&#x200B;

embed\_model\_id = 'sentence-transformers/all-mpnet-base-
v2'

&#x200B;

&#x200B;

&#x200B;

device = f'cuda:{cuda.current\_device()}' if cuda.is\_available() else 'cpu' ## NVIDI
A GeForce RTX 2080 TI

&#x200B;

embed\_model = HuggingFaceEmbeddings(

model\_name=embed\_model\_id,

model\_kwargs={'d
evice': device},

encode\_kwargs={'device': device, 'batch\_size': 32}

)

&#x200B;

docs = \[\]

&#x200B;

&#x200B;

fo
r file in os.listdir('lessdata'):

if file.endswith('.json'):

file\_path = './lessdata/'+file

with open(file\_path) as
 file:

json\_data = [file.read](https://file.read)()

document = create\_doc(json\_data)

docs.append(document)

&#x200
B;

&#x200B;

document\_splitter = RecursiveCharacterTextSplitter(separators=\['\\n'\], chunk\_size = 500, chunk\_overla
p = 100)

document\_chunks = document\_splitter.split\_documents(docs)

&#x200B;

&#x200B;

vectordb = Chroma.from\_docu
ments(document\_chunks,embedding=embed\_model, persist\_directory='./database')

&#x200B;

\##vectordb.persist()

'''

v
ectordb = Chroma.from\_documents(document\_chunks,embedding=embed\_model, persist\_directory='./database')

vectordb.per
sist('./database')

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;

\### PLEASE DO NOT TOUCH THE VSCODE

&#x200B;


&#x200B;

tokenizer = AutoTokenizer.from\_pretrained('meta-llama/Llama-2-7b-chat-hf', use\_auth\_token = True,)

&#x20
0B;

&#x200B;

model = AutoModelForCausalLM.from\_pretrained('TheBloke/Llama-2-7b-Chat-GGUF',

model\_file = 'llama-2-7b
-chat.q4\_K\_M.gguf',

device\_map ='auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;


&#x200B;

&#x200B;

'''

model = AutoModelForCausalLM.from\_pretrained('meta-llama/Llama-2-7b-chat-hf',

device\_map =
'auto',

torch\_dtype = torch.float16,

use\_auth\_token = True)

&#x200B;

&#x200B;

'''

&#x200B;

&#x200B;

&#x200B;


pipe = pipeline('text-generation',

model = model,

tokenizer = tokenizer,

device\_map='auto',

max\_new\_tokens = 512
,

min\_new\_tokens = 1,

top\_k = 5) ##see it 

&#x200B;

\## In vectorstore, take top 5 closest vectors-inputs-context
s, whatever you wanna call.

&#x200B;

llm = HuggingFacePipeline(pipeline=pipe, model\_kwargs= {'temperature':0.7})

&#x
200B;

memory = ConversationBufferMemory(memory\_key='chat\_history', input\_key='question', output\_key='answer', retur
n\_messages=True)

&#x200B;

system\_template = r''' 

Given a context, use your knowledge and answer the question. Be f
lexible, and try everything to answer in the format asked by query.

 \----

{context}

\----

'''

&#x200B;

&#x200B;


user\_template = 'Question:\`\`\`{question}\`\`\`'

&#x200B;

messages = \[

SystemMessagePromptTemplate.from\_template(
system\_template),

HumanMessagePromptTemplate.from\_template(user\_template)

\]

&#x200B;

&#x200B;

qa\_prompt = Chat
PromptTemplate.from\_messages(messages)

&#x200B;

&#x200B;

&#x200B;

jsonExpert = ConversationalRetrievalChain.from\_l
lm(llm = llm, 

retriever=vectordb.as\_retriever(search\_kwargs = {'k': 1}), ## whats it

verbose = True, memory = memor
y, combine\_docs\_chain\_kwargs={'prompt': qa\_prompt},

return\_source\_documents = True

)

&#x200B;

\##retriever ret
urns 1 output object.

&#x200B;

chat\_history = \[\]

query = 'Consider the financials and progress of companies who is
 in the tech business.'

result = jsonExpert({'question': query}, {'chat\_history': chat\_history})

\#result = jsonExpe
rt({'question': query})

&#x200B;

&#x200B;

sources = result\['source\_documents'\]\[0\]

print(result\['answer'\])

pp
rint(sources)

pprint(memory)
```
---

     
 
all -  [ The rollercoaster journey behind launch the HelpKit AI Notion Chatbot ](https://www.reddit.com/r/EntrepreneurRideAlong/comments/16ieqkw/the_rollercoaster_journey_behind_launch_the/) , 2023-09-15-0909
```
Hey folks!

Today I want to talk with you about the journey behind launching HelpKit AI. HelpKit is a solo founded and f
ully bootstrapped SaaS tool that turns your Notion docs into a professional help center and documentation site.

Since H
elpKit is already hosting hundreds of customers Notion knowledge bases it only made sense to supercharge them with a cus
tom AI trained chatbot. So far the results have been amazing.

And now, we just finally [launched today on Product Hunt]
(https://www.producthunt.com/posts/helpkit-ai) as well! The public beta is out since two weeks and we have onboarded mor
e than 15 customers on the add-on and the AI bot held 2000+ successful conversations.The launch was planned two months a
go but some things stopped me from releasing it.

If you are curious about the background feel free to read on.Now, let 
me explain why the journey to the launch was a bit rougher than expected. There were two big issues: The UX and building
 on top of AI.

**The UX Hurdle**

First and foremost, I was stuck with developing a great user experience. I have only 
come across a handful of products that were sort of implementing the same concept and I really did not like their UX imp
lementation. Everything felt clunky and just did not fit into the concept of an AI enabled knowledge base system.

You s
ee our AI chatbot needs to be integrated into HelpKit‚Äôs two layouts: Help Center and Documentation and also work well on
 the widget and mobile.Quite a tricky task to get right everywhere! I brainstormed for a few days, tried out some implem
entations but none of them felt natural for a user in my opinion.

I even spent a whole week building an interface only 
to then throw away the entire feature code branch and start from scratch.What I needed was a break. So I took a weekend 
break, spent some time at the beach and came back refreshed with some new ideas (that strangely all came to me during my
 Sunday evening shower).

I realised that the most intuitive way to present the option to chat with an AI powered chatbo
t assistant is when the user is already searching for something. So this way, should our normal search not be able to de
liver an instant search result, users can be ‚Äúcatched‚Äù and still have their problem resolved by the AI.

In terms of the
 UI, I decided to go with a slick right sidebar interface for the chatbot on the help center layout and a nicely integra
ted chat window within the search command bar of the documentation layout. Within the HelpKit embeddable widget as well 
as on mobile phones, HelpKit AI will show a full-screen chatbot interface to the user.

Overall, the HelpKit public beta
 has been running for 2 weeks and users as well as customers are really satisfied with the great user experience. Which‚Ä¶
 also obviously makes me super happy „ÉÑ

&#x200B;

**Building on top of AI**

HelpKit AI is my first real touchpoint deve
loping a product with Large Language Models (LLMs). After doing some simple warm-up Hello World AI tests, everything see
med so simple.

Unfortunately I had to soon find out that I sincerely underestimated the complexity involved in developi
ng a conversational AI chatbot that closely mirrors human interaction.

Following a considerable period of experimentati
on with a plethora of existing tools, it's become apparent that the majority merely repurpose around 10 lines of Langcha
in code, presenting it as a fully-fledged product.The outcomes of these efforts are, at their best are 'meh'.

Some OK, 
but not great.I nearly fell into the same trap, having developed a feature that was 90% complete before acknowledging th
e subpar and cluttered results, as well as my limited comprehension of this new technology.

Engaging with LLMs presents
 an entirely unique and novel paradigm.Consequently, I revisited the initial plans and invested a lot of more time immer
sing myself in the intricacies of LLMs, AI User Experience, and a slew of way too complex research papers, all in an eff
ort to better understand how to construct tools around LLMs.

Interestingly, due to the novelty of this field, there's n
o definitive roadmap to a successful implementation. The process is characterized by a great deal of experimentation. Yo
u really need a flexible approach and swift adaptation to the frequent and rapid enhancements being made to these tools.
 As an engineer being used to having deterministic outcomes I just couldn‚Äôt believe the quirkiness of testing out bunch 
of prompts to find out what works the best.

In the end everything finally clicked and I know exactly what I was doing a
nd how I can make HelpKit AI as best as possible.

&#x200B;

**Wrapping up**

So that‚Äôs my little background story of bu
ilding HelpKit AI and some of the struggles that I had. The biggest takeaway lesson from me here was to realize that som
etimes you need to stop being so harsh on yourself and accept that some things are more difficult than others. You might
 need a little bit more time than you thought.

The beautiful thing for us Indiehackers is that we don‚Äôt have any pressu
ring project manager sitting behind our back pressuring us to release something despite the quality but somehow we still
 tend pressure ourselves even harder into it.

Take a step back, breath, learn more and then come back stronger.In case 
you are interested you can find the [HelpKit AI landing page here](https://www.helpkit.so/helpkit-ai/) and I also record
ed a little [Youtube video demoing HelpKit AI](https://www.youtube.com/watch?v=RhWrzh9pk-c) you can check out.That's it!


Hope this was useful to some of you reading this and also thinking about embarking on the journey of building a big ne
w feature for your product.
```
---

     
 
all -  [ What are your best practices when using Embeddings, RAG, and Retrieval? ](https://www.reddit.com/r/LangChain/comments/16idhfw/what_are_your_best_practices_when_using/) , 2023-09-15-0909
```
Hi there,

Recently started building LLM applications, While talking to developers in the field, I got overwhelmed by al
l the tools and services available.

* Different embedding algorithms: For some ada-002 is SOTA, for others not
* Embedd
ing pipeline providers
* Chunking and cleaning
* Injecting up-to-date Knowledge Bases (RAG)
* Indexing
* Retrieval

(I w
ill not even start with 10s of different vector DB providers)

I'd love to collect **best practices for common pain poin
ts.** Can we create a high-quality thread with the following?

&#x200B;

1. **What is your tool stack for LLM applicatio
ns?**
2. **What problems did you experience?**
3. **How did you solve it? (if it's solved, otherwise 'looking for a solu
tion')**

&#x200B;
```
---

     
 
all -  [ How to use multiple toolkits wit agents ](https://www.reddit.com/r/LangChain/comments/16iatr5/how_to_use_multiple_toolkits_wit_agents/) , 2023-09-15-0909
```
I need to use the Vector Store Toolkit and SQL Toolkit.

Is there a method that allows me to combine both toolkits for u
se in Agent.

Any ideas?
```
---

     
 
all -  [ Loading a Sitemap ](https://www.reddit.com/r/LangChain/comments/16i7cne/loading_a_sitemap/) , 2023-09-15-0909
```
Hello everyone, I am having issues loading this particular sitemap and I cannot figure out why.  
this is it  
[https://
www.condoauthorityontario.ca/sitemap\_index.xml](https://www.condoauthorityontario.ca/sitemap_index.xml)  


nothing hap
pens when I try to load it like so   


&#x200B;

https://preview.redd.it/91lttnqu25ob1.png?width=1204&format=png&auto=w
ebp&s=06ca937519ced4628b1a706b6bf5d82a04374685
```
---

     
 
all -  [ LLMs and Data warehousing ](https://www.reddit.com/r/LangChain/comments/16i5wms/llms_and_data_warehousing/) , 2023-09-15-0909
```
I was thinking whether Large Language Models (LLMs) could replace Data Warehousing, considering that the end result of b
oth is information retrieval. What are your thoughts?
```
---

     
 
all -  [ The Problem With LangChain ](https://minimaxir.com/2023/07/langchain-problem/) , 2023-09-15-0909
```

```
---

     
 
all -  [ New formatting to improve readability - how did I do?? ](https://www.reddit.com/r/resumes/comments/16i0adt/new_formatting_to_improve_readability_how_did_i_do/) , 2023-09-15-0909
```
Got some valuable feedback on here recently about poor readability, so I've made changes and would love more harsh feedb
ack!  


I also dropped by Overview section at the top since it took up a lot of room and I've heard they're unnecessary
.   


Welcome any and all comments! Thanks so much.

&#x200B;

https://preview.redd.it/ysifuqsxh3ob1.png?width=734&form
at=png&auto=webp&s=b2d9f8edbd632f440e180529f7468f139c5d24e8
```
---

     
 
all -  [ Struggling with langchain for Web Research on Safety Tech Companies ](https://www.reddit.com/r/LangChain/comments/16hzyl6/struggling_with_langchain_for_web_research_on/) , 2023-09-15-0909
```
I've been working on a project where I utilise langchain to retrieve information about safety tech companies from variou
s websites (like LinkedIn, Crunchbase, YCombinator, and Huggingface etc..).

I'm able to get some results but it feels k
inda tame and limited, I'm trying to figure out ways to:

&#x200B;

1. **Web Retrieval Scope**: expand my search to cove
r more parts of the internet for a broader and more comprehensive dataset.
2. **Result Export**: After the retrieval and
 processing, I want to be able to sort and export the results to an Excel sheet. Each row representing a company, with t
he columns containing specific information such as the company's name, CEO, description, and so on  
.

If anyone has ex
perience with this kinda thing or similar tools and can provide insights or suggestions, I'd greatly appreciate it. I'm 
keen on getting better at this and using it more frequently . 
```
---

     
 
all -  [ Improving the performance of RAG over 10m+ documents ](https://www.reddit.com/r/LangChain/comments/16hz0nr/improving_the_performance_of_rag_over_10m/) , 2023-09-15-0909
```
What has the biggest leverage to improve the performance of RAG when operating at scale?

When I was working for a Legal
Tech startup and we had to ingest millions of litigation documents into a single vector database collection, we figured 
out that you can increase the retrieval results significantly by using an open source embedding model (sentence-transfor
mers/sentence-t5-xxl) instead of OpenAI ADA.

What other techniques do you see besides swapping the model?

We are build
ing VectorFlow an open-source vector embedding pipeline and want to know what other features we should build next after 
adding open-source Sentence Transformer embedding models. Check out our Github repo:¬†[https://github.com/dgarnitz/vector
flow](https://github.com/dgarnitz/vectorflow)¬†to install VectorFlow locally or t*ry it out in the playground (*[https://
app.getvectorflow.com/](https://app.getvectorflow.com/)).
```
---

     
 
all -  [ Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought ](https://www.reddit.com/r/LangChain/comments/16hrq3a/finetuning_a_gpt35_react_agent_on_better_chain_of/) , 2023-09-15-0909
```
Has anyone fine-tuned gpt\_3.5 using ReACT Agent on better Chan of Thought? How was the output as compared to an non-tra
ined gpt3.5?
```
---

     
 
all -  [ Recursive character text splitter ](https://www.reddit.com/r/node/comments/16hp24q/recursive_character_text_splitter/) , 2023-09-15-0909
```
I've been using langchain in a project, but I've recently started to migrate off it. However, the [text splitters](https
://github.com/langchain-ai/langchainjs/blob/main/langchain/src/text_splitter.ts) provided were quite useful, although it
 doesn't make sense to keep this rather large dependency for that sake. Are there any alternative npm modules that provi
de the RecursiveCharacterTextSplitter?
```
---

     
 
all -  [ Langsmith alternative ](https://www.reddit.com/r/LangChain/comments/16ho366/langsmith_alternative/) , 2023-09-15-0909
```
Hey guys,

I've tried using Langsmith but found it to be quite convoluted. Do any of you know some great alternatives? W
ould be happy about any suggestions
```
---

     
 
all -  [ Advice for langchain architecture: Location reviews for {business} ](https://www.reddit.com/r/LangChain/comments/16hnasv/advice_for_langchain_architecture_location/) , 2023-09-15-0909
```
Hello, I've been working my way around the gpt tools world, and have built 5 or 6 personal projects using different aspe
cts of tools (personal custom python script, embedding, langchain agents and tools, autogpt - have not fine tuned yet as
 I have not been able to justify the use case). I run them all through streamlit. But now I am building a production ver
sion and I am still in the weeds.

&#x200B;

TLDR: What tools should I be using? What data structures for agents and dat
a should I be using? How do i store data to make it available to the LLM? I'm sorry this turned into a novel, but maybe 
it will be edifying for others.

&#x200B;

Details:

I like my pure python / bard hacky python, for what it does. I'm tr
ying to recreate it using langchain. Here's how my script works:

\- Takes business name input from user (streamlit)

\-
 reads all initial\_prompt\_x.txt - handles formatting, questions, etc. for each review subsection

\- replace placehold
er strings with inputs

\- get results from bard

\- read filter\_prompt.txt - handles fact-checking (bard is live-data,
 which is why i did all this)

\- print final result

&#x200B;

This outputs a structured review based on different cate
gories/features that is pretty good, but it's total BS. But it is kind of langchain framework already. It has some funda
mental flaws, the core problem being, even though the data ARE live, we can't expect an LLM to know which products are c
urrently available.

&#x200B;

\*\*Goal\*\*: break down my tasks using lanchain agents and tools. Not sure if I should b
e embedding or not. Here is my pseudocode:

\- Take input (as before)

\- Use templates instead of manually constructing
 prompts with python. Use micro-prompts for ea

\- Initialize agent, llm, tools (internet browse, youtubesearch, date / 
site parser). \*\*question \*\* Should I be using use other tools? like SERP?

\- Look up website, parse to obtain produ
ct availability

\- Result storage, \*\*question\*\*. How do i store this this data? A hacky version is to store it loca
lly, and then run a prompt / template to perform tasks based on those objects. That is a bad answer. Should I be embeddi
ng all these sets? It's basically a few thousand PDFs.

\- perform data-augmented task on availability

\- assemble resu
lts into final product

&#x200B;

Does this all sound right? I could add more steps, like specifically getting reviews f
rom yelp / google / foursquare, and embedding those as well, rather than just relying on internet search? 

&#x200B;

&#
x200B;
```
---

     
 
all -  [ Help needed for langchain create_pandas_dataframe_agent with Open AI function ](https://www.reddit.com/r/LangChain/comments/16hlioz/help_needed_for_langchain_create_pandas_dataframe/) , 2023-09-15-0909
```
I‚Äôm using **create_pandas_dataframe_agent** (using OpenAI Function as agent type) with a df .

But I‚Äôm not able to make 
the memory work that resides in my agent. Ultimate goal is to built a chatbot which can query database and have a memory
 of previous conversations.

For example, Issue is agent forget the context although memory is there in 'history' parame
ter of the memory. I'm using ConversationSummaryBufferMemory which keeps conversation in summary form.

> Human: What is
 the ESG score of Mastercard?

> AI: The ESG score of Mastercard is 83.

> Human: What is the L1 score of this company?


> AI: Can you specify which company you are referring? 

Please note that, previous conversations are saved in 'history
' but agent is not able to relate while asking questions. What should be my prompt? Sharing my sample code:

**Defined L
LM for Agent and for Memory**

llm_code = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k')

llm_context = ChatO
penAI(temperature=0.5, model_name='gpt-3.5-turbo-16k')

**Defined Memory**

memory = ConversationSummaryBufferMemory(llm
=llm_context, max_token_limit=10)

**Defined Agent**

openai__agent = 
        
create_pandas_dataframe_agent(
        

        llm_code,
        
        df1,
        
        prefix=prefix.format(chat_history=memory.load_memory_variables(
{})['history']),
        
        verbose=True,
        
        handle_parsing_errors=True,
        
        agent_exec
utor_kwargs={'memory': memory,
                       'handle_parsing_errors' : True},
        
        agent_type=Agent
Type.OPENAI_FUNCTIONS
)
Here is my Prompt and Prefix that is fed into the Agent with memory

prompt = ''' You are a help
ful assistant that can answer questions based on the given data(table, chat_history) and rules.You are working with a pa
ndas dataframe in Python. The name of the dataframe is df. You should use the tools below to answer the question posed o
f you:

    Rules:
    A)Only use the factual information from the available data to answer the question.
    B)If you d
on't have enough information to answer the question, say 'I don't know'.
    C)Provide answers without mentioning the sp
ecific source of the information.


   < Last few messages between you and user > :

    {chat_history}
    '''
prefix =
 PromptTemplate( input_variables=['chat_history'], template=prompt )

P.S - I want to use 'create_pandas_dataframe_agent
' with [AgentType as OpenAI.Functions.] and not as Zero Shot, since Open AI agent type is faster and better in reasoning
.
```
---

     
 
all -  [ Kendra retriever and Conversation Chain ](https://i.redd.it/7wtup8hul0ob1.jpg) , 2023-09-15-0909
```
using Amazonkendra Retriever but unable to pass to the Conversation Chain

referring to this github repo for chat_histor
u memory implementation as i am using amazon lex for chat.
[https://github.com/aws-samples/conversational-ai-llms-with-a
mazon-lex-and-sagemaker](https://github.com/aws-samples/conversational-ai-llms-with-amazon-lex-and-sagemaker)
```
---

     
 
all -  [ O fluxo de trabalho como full-stack focado √° volta de OpenAI ChatGPT (Part 3) ](https://www.reddit.com/r/devpt/comments/16hkvys/o_fluxo_de_trabalho_como_fullstack_focado_√°_volta/) , 2023-09-15-0909
```
Ol√° Devs,

Eu tenho feito uma s√©rie de posts em rela√ß√£o ao fluxo de AI para trabalhar como *software developer* ([part 2
](https://www.reddit.com/r/devpt/comments/13oi66l/o_fluxo_de_trabalho_como_fullstack_focado_%C3%A1_volta/)). Nestes √∫lti
mos meses tem havido imensas mudan√ßas no que apareceu no mercado e queria dar um update:

# Motivation:

**Automation do
esn't work -** Eu estava a tentar automatizar, mas n√£o resulta. √â demasiado (e.g langchain flow).

**Models and limitati
ons -** Os modelos dentro do IDE s√£o limitados.

**Github Copilot:**

https://preview.redd.it/ktru973cd0ob1.png?width=17
40&format=png&auto=webp&s=41a695544881f93e5c8a0a1066c2000ffe9f57dc

Isto √© o primeiro modelo do github copilot. Funciona
 bem para completar fun√ß√µes.

**Github Chat:**

https://preview.redd.it/hyl1qinmd0ob1.png?width=1386&format=png&auto=web
p&s=8efbeca469e139fd56f5ce9b9037816fe0cf9b9d

Funciona bem para coisas mais abrangentes mas fechadas. N√£o consegue ver a
 'big picture'. √â um bocado '**meh**'

**GPT-4 superior reasoning skills:**

A principal raz√£o para ter feito este novo 
fluxo √© porque via me constantemente a entrar dentro do ChatGPT e resolver o problema que o copilot Chat n√£o conseguia.


# New approach:

O que mudou isto foi mesmo a feature '**Advance Data Analysis/code interpreter**'. Essencialmente por 
tr√°s tem um ecosistema de python para analysis, o que √© optimo porque consegue concentrar muito mais contexto do que o m
odelo √© suposto conseguir. Resolve tamb√©m o problema de estar preso em **setembro de 2021**.

https://preview.redd.it/jb
erfe42e0ob1.png?width=2536&format=png&auto=webp&s=82dfcb5a94c187bf5167bb441a686b282afc7de2

1- **Setting the environment
.**

* Advance Data Analysis/code interpreter
* [Professor synapse](https://github.com/ProfSynapse/Synapse_CoR) \- Simul
a 'auto-gpt tasks'. Util para guiar o que fazer.

2- **Load Codebase and possible documentation.**

* Basta dar zip ao c
√≥digo todo, que ele consegue extrair.
* Ir ao Github e ir buscar documenta√ß√£o se necess√°rio (e.g nextjs, prisma)

3- **L
oad the task. Generate the code**

4- **Go back to IDE and refactor what is needed**. Em termos de testes continua igual
.

Obrigado,
```
---

     
 
all -  [ Has anyone tried running a Llama2/Lang Flow setup? ](https://www.reddit.com/r/LocalLLaMA/comments/16hj5od/has_anyone_tried_running_a_llama2lang_flow_setup/) , 2023-09-15-0909
```
Inspired by a post by the Floneum dev I was looking into alternatives to text generation. I found Lang Flow which is a G
UI for LangChain. As far as I can tell it is a node based system to integrate LangChain functionality in a node based sy
stem.

It seems to have Llama2 model support but I haven't been able to find much in the way of guides/tutorials on how 
to set up such a system. I come from a design background and have used a bit of ComfyUI for SD and use node based workfl
ows a lot in my design work.

Does anyone have an expertise with this workflow, any suggestions before I get stuck in? T
hanks.
```
---

     
 
all -  [ Top 50 Udemy Paid Courses For Free With Certificate ](https://www.reddit.com/r/Udemy/comments/16hia2p/top_50_udemy_paid_courses_for_free_with/) , 2023-09-15-0909
```
**Courses for 13 September 2023**

Note¬†: Coupons might expire anytime, so enroll as soon as possible to get the courses
 for FREE.

* Aprende MongoDB desde cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/2675/)
* Aprende Docker, Compos
e y Swarm[REDEEM OFFER](https://idownloadcoupon.com/udemy/2674/)
* Ethically Hack the Planet Part 1[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/2673/)
* Complete Accounting + Tallyprime + Tally ERP9 + GST (4 in 1)[REDEEM OFFER](https://
idownloadcoupon.com/udemy/2672/)
* Google My Business. How to Master Powerful Tool for Company[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2671/)
* Geometry Basics to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/2670/)
* Sup
ply Chain Analytics Decoded: The Beginner‚Äôs Handbook[REDEEM OFFER](https://idownloadcoupon.com/udemy/2669/)
* Practical 
MongoDB + PHP: For Absolute Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2668/)
* Self-Care for YOUREDEEM O
FFER
* Learn Big Data Hadoop: Hands-On for Beginner[REDEEM OFFER](https://idownloadcoupon.com/udemy/2666/)
* Java And C+
+ And PHP Crash Course For Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2665/)
* 4 Practice Tests for any C
++ Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/2664/)
* Complete Windows 11 with Microsoft Copilot Mas
terclass[REDEEM OFFER](https://idownloadcoupon.com/udemy/2663/)
* Python And Flask Framework Complete Course For Beginne
rs[REDEEM OFFER](https://idownloadcoupon.com/udemy/2662/)
* Excellent Human Resources (HR) Management ( HRM) Generalist[
REDEEM OFFER](https://idownloadcoupon.com/udemy/2661/)
* Excellence in Digital Marketing (Advanced Learning Classes)[RED
EEM OFFER](https://idownloadcoupon.com/udemy/2660/)
* Personal Finance Education, Planning, Investing & Management[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2659/)
* CSS, JavaScript And Python Complete Course[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2658/)
* 2023 Gesti√≥n √Ågil de Proyectos con Scrum: Curso AGILE[REDEEM OFFER](https://idownloadcou
pon.com/udemy/2657/)
* Bootstrap 5 Essentials: A Comprehensive Guide 2023[REDEEM OFFER](https://idownloadcoupon.com/udem
y/2656/)
* The Ultimate Sass & Less Course: Boost Your Web Skills 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2
655/)
* Executive Diploma in Marketing Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/2654/)
* Write Html & 
Css 5 Times Faster With Vs Code & Emmet 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2653/)
* Become a PHP Pro: 
A Step-by-Step Guide for Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2652/)
* Workshops und Seminare 
professionell vorbereiten und leiten[REDEEM OFFER](https://idownloadcoupon.com/udemy/2651/)
* Introduction to Bar Graphs
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2650/)
* Introduction to Histogram and Frequency¬†Polygon[REDEEM OFFER](
https://idownloadcoupon.com/udemy/2649/)
* Pros and Cons of MNCs : A Comparative Study[REDEEM OFFER](https://idownloadco
upon.com/udemy/2648/)
* Writing Clear and Concise Reports: Tips and Strategies[REDEEM OFFER](https://idownloadcoupon.com
/udemy/2647/)
* Mastering the Art of Speech Writing[REDEEM OFFER](https://idownloadcoupon.com/udemy/2646/)
* Crafting Yo
ur Career: Expert Tips for a Winning Resume[REDEEM OFFER](https://idownloadcoupon.com/udemy/2645/)
* The Ultimate Guide 
to Private and Public Sector[REDEEM OFFER](https://idownloadcoupon.com/udemy/2644/)
* An In-depth Study of Antivirus Sof
tware[REDEEM OFFER](https://idownloadcoupon.com/udemy/2643/)
* Linear Equation Part- 2 Linear Equations in two¬†Variables
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2642/)
* MAKE MONEY ONLINE: Mindset Training + Real-Life Examples[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2641/)
* Master Python using ChatGPT[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/2640/)
* How to Make Money Online for Beginners: Follow PROVEN STEPSREDEEM OFFER
* Quantity Surveying With Rate 
Analysis And Take Off-Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2638/)
* Effective Delegation ‚Äì Principl
es and practical concepts[REDEEM OFFER](https://idownloadcoupon.com/udemy/2637/)
* Digital Marketing Foundation CDMA | C
DMP Pathway Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/2636/)
* Programming the Microcontroller using Mi
kroC PRO for PIC[REDEEM OFFER](https://idownloadcoupon.com/udemy/2635/)
* Microsoft Excel ‚Äì Excel from Beginner to Advan
ced level[REDEEM OFFER](https://idownloadcoupon.com/udemy/2634/)
* Simulation of Electronic Circuits by Proteus in Arabi
c[REDEEM OFFER](https://idownloadcoupon.com/udemy/2633/)
* AI-Driven Cybersecurity[REDEEM OFFER](https://idownloadcoupon
.com/udemy/2632/)
* Learning the Professional Design Program Edraw Max in Arabic[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/2631/)
* Learn International Trade Negotiation Tricks In Just 2 Days[REDEEM OFFER](https://idownloadcoupon.com/
udemy/2630/)
* Ultimate Quantum Jump BluePrint[REDEEM OFFER](https://idownloadcoupon.com/udemy/2629/)
* Master LangChain
 with No-Code tools: Flowise and LangFlow[REDEEM OFFER](https://idownloadcoupon.com/udemy/2628/)
* Azure Virtual Network
 Connectivity Options[REDEEM OFFER](https://idownloadcoupon.com/udemy/2627/)
* Business Administration Executive Certifi
cation[REDEEM OFFER](https://idownloadcoupon.com/udemy/2626/)
* Microsoft PowerPoint Masterclass For Beginners[REDEEM OF
FER](https://idownloadcoupon.com/udemy/2625/)
* Dart and Flutter: The Ultimate Mobile App Development Course[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/2624/)

GET MORE FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](https://www.re
ddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ Top 50 Udemy Paid Courses For Free With Certificate | Hurry Don‚Äôt Miss | Wednesday, September 13, 20 ](https://www.reddit.com/r/udemyfreeebies/comments/16hi8n7/top_50_udemy_paid_courses_for_free_with/) , 2023-09-15-0909
```
**Courses for 13 September 2023**

Note¬†: Coupons might expire anytime, so enroll as soon as possible to get the courses
 for FREE.

* Aprende MongoDB desde cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/2675/)
* Aprende Docker, Compos
e y Swarm[REDEEM OFFER](https://idownloadcoupon.com/udemy/2674/)
* Ethically Hack the Planet Part 1[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/2673/)
* Complete Accounting + Tallyprime + Tally ERP9 + GST (4 in 1)[REDEEM OFFER](https://
idownloadcoupon.com/udemy/2672/)
* Google My Business. How to Master Powerful Tool for Company[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2671/)
* Geometry Basics to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/2670/)
* Sup
ply Chain Analytics Decoded: The Beginner‚Äôs Handbook[REDEEM OFFER](https://idownloadcoupon.com/udemy/2669/)
* Practical 
MongoDB + PHP: For Absolute Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2668/)
* Self-Care for YOUREDEEM O
FFER
* Learn Big Data Hadoop: Hands-On for Beginner[REDEEM OFFER](https://idownloadcoupon.com/udemy/2666/)
* Java And C+
+ And PHP Crash Course For Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2665/)
* 4 Practice Tests for any C
++ Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/2664/)
* Complete Windows 11 with Microsoft Copilot Mas
terclass[REDEEM OFFER](https://idownloadcoupon.com/udemy/2663/)
* Python And Flask Framework Complete Course For Beginne
rs[REDEEM OFFER](https://idownloadcoupon.com/udemy/2662/)
* Excellent Human Resources (HR) Management ( HRM) Generalist[
REDEEM OFFER](https://idownloadcoupon.com/udemy/2661/)
* Excellence in Digital Marketing (Advanced Learning Classes)[RED
EEM OFFER](https://idownloadcoupon.com/udemy/2660/)
* Personal Finance Education, Planning, Investing & Management[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2659/)
* CSS, JavaScript And Python Complete Course[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2658/)
* 2023 Gesti√≥n √Ågil de Proyectos con Scrum: Curso AGILE[REDEEM OFFER](https://idownloadcou
pon.com/udemy/2657/)
* Bootstrap 5 Essentials: A Comprehensive Guide 2023[REDEEM OFFER](https://idownloadcoupon.com/udem
y/2656/)
* The Ultimate Sass & Less Course: Boost Your Web Skills 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2
655/)
* Executive Diploma in Marketing Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/2654/)
* Write Html & 
Css 5 Times Faster With Vs Code & Emmet 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2653/)
* Become a PHP Pro: 
A Step-by-Step Guide for Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2652/)
* Workshops und Seminare 
professionell vorbereiten und leiten[REDEEM OFFER](https://idownloadcoupon.com/udemy/2651/)
* Introduction to Bar Graphs
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2650/)
* Introduction to Histogram and Frequency¬†Polygon[REDEEM OFFER](
https://idownloadcoupon.com/udemy/2649/)
* Pros and Cons of MNCs : A Comparative Study[REDEEM OFFER](https://idownloadco
upon.com/udemy/2648/)
* Writing Clear and Concise Reports: Tips and Strategies[REDEEM OFFER](https://idownloadcoupon.com
/udemy/2647/)
* Mastering the Art of Speech Writing[REDEEM OFFER](https://idownloadcoupon.com/udemy/2646/)
* Crafting Yo
ur Career: Expert Tips for a Winning Resume[REDEEM OFFER](https://idownloadcoupon.com/udemy/2645/)
* The Ultimate Guide 
to Private and Public Sector[REDEEM OFFER](https://idownloadcoupon.com/udemy/2644/)
* An In-depth Study of Antivirus Sof
tware[REDEEM OFFER](https://idownloadcoupon.com/udemy/2643/)
* Linear Equation Part- 2 Linear Equations in two¬†Variables
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2642/)
* MAKE MONEY ONLINE: Mindset Training + Real-Life Examples[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2641/)
* Master Python using ChatGPT[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/2640/)
* How to Make Money Online for Beginners: Follow PROVEN STEPSREDEEM OFFER
* Quantity Surveying With Rate 
Analysis And Take Off-Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2638/)
* Effective Delegation ‚Äì Principl
es and practical concepts[REDEEM OFFER](https://idownloadcoupon.com/udemy/2637/)
* Digital Marketing Foundation CDMA | C
DMP Pathway Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/2636/)
* Programming the Microcontroller using Mi
kroC PRO for PIC[REDEEM OFFER](https://idownloadcoupon.com/udemy/2635/)
* Microsoft Excel ‚Äì Excel from Beginner to Advan
ced level[REDEEM OFFER](https://idownloadcoupon.com/udemy/2634/)
* Simulation of Electronic Circuits by Proteus in Arabi
c[REDEEM OFFER](https://idownloadcoupon.com/udemy/2633/)
* AI-Driven Cybersecurity[REDEEM OFFER](https://idownloadcoupon
.com/udemy/2632/)
* Learning the Professional Design Program Edraw Max in Arabic[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/2631/)
* Learn International Trade Negotiation Tricks In Just 2 Days[REDEEM OFFER](https://idownloadcoupon.com/
udemy/2630/)
* Ultimate Quantum Jump BluePrint[REDEEM OFFER](https://idownloadcoupon.com/udemy/2629/)
* Master LangChain
 with No-Code tools: Flowise and LangFlow[REDEEM OFFER](https://idownloadcoupon.com/udemy/2628/)
* Azure Virtual Network
 Connectivity Options[REDEEM OFFER](https://idownloadcoupon.com/udemy/2627/)
* Business Administration Executive Certifi
cation[REDEEM OFFER](https://idownloadcoupon.com/udemy/2626/)
* Microsoft PowerPoint Masterclass For Beginners[REDEEM OF
FER](https://idownloadcoupon.com/udemy/2625/)
* Dart and Flutter: The Ultimate Mobile App Development Course[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/2624/)

GET MORE FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](https://idownl
oadcoupon.com/)
```
---

     
 
all -  [ Can you teach an agent how to interpret information returned by the tool function? ](https://www.reddit.com/r/LangChain/comments/16ha0da/can_you_teach_an_agent_how_to_interpret/) , 2023-09-15-0909
```
I built a function that returns SQL results retrieved from a database. However, even if the function returns the correct
 information, the agent sometimes interprets it wrong.
How can I teach the agent to properly interpret the information r
eturned by the tool?
```
---

     
 
all -  [ What are other LLM's with executable API? ](https://www.reddit.com/r/LangChain/comments/16h6zmm/what_are_other_llms_with_executable_api/) , 2023-09-15-0909
```
One thing I like about GPT models is that I don't need to maintain or own a heavy infrastructure to run the model. I can
 make a call to their API and have the embeddings and inferences done. What other similar LLM's I can use where I can ma
ke an API call and get the outcomes rather than downloading huge models and maintaining on local infra?
```
---

     
 
all -  [ What ancillary services are you paying for? ](https://www.reddit.com/r/LangChain/comments/16h4vvp/what_ancillary_services_are_you_paying_for/) , 2023-09-15-0909
```
i.e. serpapi etc

And what benefit are you getting from it / what are you using it for
```
---

     
 
all -  [ Is there a way to dynamically use grammar ](https://www.reddit.com/r/Langchaindev/comments/16h4gqn/is_there_a_way_to_dynamically_use_grammar/) , 2023-09-15-0909
```
My code is below. I want to initialize the model without the grammar parameters. However, when I ask for a detailed step
 by step plan I would like that returned as a list. What is the best way to do this without having to create a new insta
nce of llamacpp?   



```
import os
import sys
import argparse
from langchain.llms import LlamaCpp
import chromadb
impo
rt json
import uuid
import re
import datetime
from langchain.chains import LLMChain
from langchain.memory import Convers
ationBufferMemory
from langchain.prompts import PromptTemplate

# Load the configuration values from the JSON file
with 
open('model_config.json', 'r') as config_file:
    config = json.load(config_file)

class TemporaryNetworkError(Exceptio
n):
    def __init__(self, message='A temporary network error occurred'):
        super().__init__(message)

class Chrom
aVectorStore:
    def __init__(self, collection_name='chroma_collection'):
        # Get the current date and time
     
   current_datetime = datetime.datetime.now()
        formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')
   
     collection_name_time = f'{formatted_datetime}_{collection_name}'

        self.chroma_client = chromadb.Client()
  
      self.chroma_client = chromadb.PersistentClient(path='./')
        self.collection = self.chroma_client.create_coll
ection(name=collection_name_time)

    def store(self, result):
        unique_id = str(uuid.uuid4())  # Generate a uniq
ue ID for the result
        # Convert result to string if it's not already
        print(type(result))
        print(re
sult)
        result_str = str(result) if not isinstance(result, str) else result
        self.collection.add(documents=
[result], ids=[unique_id])

class AutonomousAgent:
    def __init__(self, prompt_path, model_path):
        self.prompt_
path = prompt_path
        self.model_path = model_path
        self.plan = []
        self.results = []
        self.pr
ompt = ''
        self.llama = LlamaCpp(
            model_path=args.model_path,
            n_gpu_layers=config['n_gpu_
layers'],
            n_batch=config['n_batch'],
            n_threads=config['n_threads'],
            f16_kv=config['f
16_kv'],
            n_ctx=config['n_ctx'],
            max_tokens=config['max_tokens'],
            temperature=config[
'temperature'],
            verbose=config['verbose'],
            use_mlock=config['use_mlock'],
            echo=True

        )
        self.chroma_vector_store = ChromaVectorStore()

    def extract_steps(self, text):
        # Remove co
ntent between ``` ```
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)

        pattern = r'(\d+)\.\s(.*?)
(?=\d+\.|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        steps_with_numbers = [(int(match[0]), match[
1].strip()) for match in matches if match[1].strip() != '']
        steps_with_numbers.sort(key=lambda x: x[0])
        
steps = [step[1] for step in steps_with_numbers]
        return steps

    def fetch_prompt(self):
        with open(sel
f.prompt_path, 'r') as file:
            self.prompt = file.read()

    def get_plan(self):
        prompt = f'''Give a 
detailed step by step plan to complete the following task. Do not include any programming code in your response. Do not 
include examples. You must return a numbered list interperable by Python. The format for a numbered list is 1. Step 1 2.
 Step 2 3. This is a more detailed step.

            {self.prompt}
            '''
        result = self.llama(prompt)

        self.plan = self.extract_steps(result)
        print('The plan is: ' + ', '.join(self.plan))

    def execute_pl
an(self):
        for step in self.plan:
            retry_count = 0
            while retry_count < 3:
                
try:
                    result = self.llama(step)
                    self.results.append((step, result))
             
       self.chroma_vector_store.store(result)
                    break
                except TemporaryNetworkError:
  
                  retry_count += 1
                    if retry_count == 3:
                        sys.exit(1)

    def
 archive_results(self):
        if not os.path.exists('output'):
            os.makedirs('output')
        current_datet
ime = datetime.datetime.now()
        formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')
        filename = 
f'output/{formatted_datetime}_results.txt'

        with open(filename, 'w') as file:
            for step, result in se
lf.results:
                file.write(f'Query: {step}\nResult: {result}\n\n')

if __name__ == '__main__':
    parser = 
argparse.ArgumentParser(description='Autonomous agent that executes a plan based on a prompt.')
    parser.add_argument(
'--prompt_path', type=str, default='prompt.md', help='Path to the prompt file.')
    parser.add_argument('--model_path',
 type=str, required=True, help='Path to the language model file.')
    args = parser.parse_args()

    agent = Autonomou
sAgent(args.prompt_path, args.model_path)
    agent.fetch_prompt()
    agent.get_plan()
    agent.execute_plan()
    age
nt.archive_results()
```
```
---

     
 
all -  [ Langchain and embeddings: Attribution ](https://www.reddit.com/r/LangChain/comments/16h1f9y/langchain_and_embeddings_attribution/) , 2023-09-15-0909
```
Hi,
I'm using langchain, embeddings and the openai API to 'talk to my pdf documents'. When I want to verify the response
 I must open the pdf manually and use the search function. How can I generate source attributions like. Document 'xy.pdf
', Page 24, Line 3.
Is there a 'out of the box' solution or do I need to implement it by myself?
```
---

     
 
all -  [ LangChain and GPT Tokens ](https://www.reddit.com/r/LangChain/comments/16h0x6a/langchain_and_gpt_tokens/) , 2023-09-15-0909
```
I was planning on using LangChain in a recent project. Basically, I have hundreds of documents worth of text from a text
book, and I wanted to create a 'chatbot' which could return information to questions which could be found in the textboo
k. However, I realized that OpenAI doesn't offer free credits for the API anymore, so I was wondering: how many tokens w
ill it take to do all of this? Will all of the pages of the textbook count as tokens in the prompt, or will only the que
stion I ask count? I don't want to run it once and accidentally waste like 50 dollars worth of tokens.
```
---

     
 
all -  [ [P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with ](https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/) , 2023-09-15-0909
```
Hey all, we just released our new project/paper and we thought you all might find it useful!

Our project (Kani) is a su
per lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in c
allable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one li
ne (the `@ai_function()` decorator) to turn any function into an AI-callable function!

Kani works with any model and ha
s built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt e
ngineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly custo
mizable.

Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. [https://colab
.research.google.com/github/zhudotexe/kani/blob/main/examples/colab\_examples.ipynb](https://colab.research.google.com/g
ithub/zhudotexe/kani/blob/main/examples/colab_examples.ipynb)  

If you're interested in learning more check out our lin
ks below!  
Paper: [https://arxiv.org/abs/2309.05542](https://arxiv.org/abs/2309.05542)  
GitHub: [https://github.com/zh
udotexe/kani](https://github.com/zhudotexe/kani)  
Docs: [https://kani.readthedocs.io/](https://kani.readthedocs.io/)
```
---

     
 
MachineLearning -  [ [D] Data Extraction using fine-tuned LLM? ](https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/) , 2023-09-15-0909
```
Hey Reddit,

I'm working on a tool to pull data from highly irregular Excel files. I've gotten reasonable results which 
is extremely fast with standard Python coding, but it's far from perfect due to the lack of standardized templates. 

In
terestingly, when I tested ChatGPT-4 on a sample table, it did a decent job at data extraction. However, relying solely 
on GPT-4 has its downsides like token limits and slow processing speed (and data privacy issues). Plus, splitting the Ex
cel sheet to fit within these limits results in loss of context and data.

I'm considering fine-tuning a language model 
to post-process data that was in a Pandas DataFrame (perhaps converted to JSON). Has anyone had success with this approa
ch or have alternative recommendations? I've tried Langchain, but it wasn't helpful.

I have figured out to extract the 
relevant columns, but the post-processing part is where I am considering using an LLM which understands the domain and w
hat needs to be extracted based on the examples I feed it.

Looking forward to your thoughts! And would be happy to answ
er any additional questions.
```
---

     
 
MachineLearning -  [ [D] Chains and Agents ](https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/) , 2023-09-15-0909
```
I think there's a lot of confusion around AI agents today and it's mainly because of lack of definition and using the wr
ong terminology.

We've been talking to many companies who are claiming they're working on agents but when you look unde
r the hood, they are really just chains.

I just listened to the Latent Space pod with¬†Harrison Chase (Founder of Langch
ain) and I really liked how he thinks about chains vs agents.

Chains: sequence of tasks in a more rigid order, where yo
u have more control, more predictability.  
Agents: handling the edge-cases, the long-tail of things that can happen.

A
nd the most important thing is that it's not an OR question but an AND one: you can use them in the same application by 
starting with chains -> figuring our the edge-cases -> using agents to deal with them.

https://preview.redd.it/l59sc4sr
i0nb1.png?width=3127&format=png&auto=webp&s=1f3f8730c48687eaabf1f554deb181cf35b96036
```
---

     
 
MachineLearning -  [ [P] FalkorDB - a fast Graph Database - Knowledge Graph as RAG ](https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/) , 2023-09-15-0909
```
We're building a fast low latency Graph Database called FalkorDB that will also support Vector search.  
It's based on R
edis and can be used both as a stand alone database or a module for existing Redis.  
It feels like that is going to be 
the most optimized way to serve Knowledge as RAG, would love to get your feedback.  
[https://github.com/FalkorDB/falkor
db](https://github.com/FalkorDB/falkordb)  


It already supports LlamIndex and Langchain:  
[https://python.langchain.c
om/docs/use\_cases/more/graph/graph\_falkordb\_qa](https://python.langchain.com/docs/use_cases/more/graph/graph_falkordb
_qa)  
[https://gpt-index.readthedocs.io/en/latest/examples/index\_structs/knowledge\_graph/FalkorDBGraphDemo.html](http
s://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/FalkorDBGraphDemo.html)

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Is there anything LangChain can do better than using LLMs directly (either through a website or  ](https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/) , 2023-09-15-0909
```
I haven't used ChatGPT a lot or any other LLMs, I've been reading about  Langchain and its use cases, and I'm having tro
uble wrapping my head  around exactly what it does. From what I understand, its an alternative  interface for LLMs, allo
wing for easy switching between them, and makes  some work for specific use cases easier. If I wanted to write an app or
  script to interact with LLMs and do other tasks, how would LangChain be  better than just making API call(s) to an LLM
, getting back the result  as a string, and doing whatever with it?
```
---

     
 
MachineLearning -  [ Apache Airflow vs. LangChain and LlamaHub for LLM data pipeline [D] ](https://www.reddit.com/r/MachineLearning/comments/160lexg/apache_airflow_vs_langchain_and_llamahub_for_llm/) , 2023-09-15-0909
```
I‚Äôm looking for recommendations, suggestions, and/or good documentation that outlines which data pipeline would be best 
to ingest my private data (which will then be split into chunks/nodes for vector embeddings and so forth). Thank you in 
advance!
```
---

     
 
MachineLearning -  [ [P] LLM Apps Are Mostly Data Pipelines ](https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/) , 2023-09-15-0909
```
My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster
](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.

It contains a complete 
implementation

* with scraping context data from a docs website
* chunking it, getting embeddings via the openAI API
* 
loading it into pinecone
* and finally a simple Q&A interface with streamlit on top of it

**Here's a quick summary:**


* LangChain and LlamaIndex are great tools for quick exploration
* But aren't perfect for production-grade use
* I think
 we all know the 'LangChain is pointless' debate, but there's a lot of real meat to it, and Pat describes a few of them 
(a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)
* LLM applications are all about movin
g data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps
* A bunch of dat
a engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.
* Meltan
o is one such tool and Pat implemented the above described pipeline with it

**FWIW**: The GitHub project that comes wit
h the post is super easy to run and super modular. I just tested it and was able to modify everything for my own applica
tion within 30 mins.
```
---

     
 
MachineLearning -  [ [P] pgml-chat: A command-line tool for deploying low-latency knowledge-based chatbots ](https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/) , 2023-09-15-0909
```
We've created an open source chat bot builder, on top of PostgresML. This tool makes it easy to ingest documents and set
 a system prompt for a chatbot with knowledge of your content. The innovation is in the simplicity and efficiency, rathe
r than the functionality.

PostgresML runs open source embedding models alongside pgvector in Postgres to implement chat
 bot prompt creation without any network calls, which makes it \~4x faster than competing architectures. It can also do 
text generation with that prompt (and no additional network hops) using any open source model from HuggingFace, but it a
lso integrates with the GPT-4 API if you'd like to use that instead. 

The full writeup including some benchmarks for co
mpeting architectures is here:  [https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-kno
wledge-based-chatbots-part-I](https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-knowle
dge-based-chatbots-part-I)

You can chat with a deployment that has access to our blogs and documentation content it in 
\[our Discord\]([https://discord.com/channels/1013868243036930099/1013868243536072868](https://discord.com/channels/1013
868243036930099/1013868243536072868)), where it answers questions addressed to @PgBot.

&#x200B;

* The source code for 
the bot builder and server is only a few hundred lines of Python [https://github.com/postgresml/postgresml/tree/master/p
gml-apps/pgml-chat#readme](https://github.com/postgresml/postgresml/tree/master/pgml-apps/pgml-chat#readme)
* The chat a
pp is so small, because it's delegates all the vector db and embedding generation options to our Python client SDK, whic
h is available for anyone to build other apps with: [https://pypi.org/project/pgml/](https://pypi.org/project/pgml/)
* T
he Python client SDK is so small, because it's just a wrapper around the Rust client SDK: [https://github.com/postgresml
/postgresml/tree/master/pgml-sdks/rust/pgml](https://github.com/postgresml/postgresml/tree/master/pgml-sdks/rust/pgml). 
Currently we also support JS/Typescript SDKs as well, all generated from the same safe and efficient underlying Rust imp
lementation, using some fancy Rust macros.
* The Rust client SDK is also pretty simple though, because it just delegates
 everything to the Postgres database extension, which is where everything is computed in a single GPU accelerated proces
s, without having to load any ML models, data, or dependencies on client apps, effectively eliminating all the typical M
L data<->model network hops. Which makes it faster, simpler and safer.

This lays out what we think a is a better approa
ch to AI application architecture compared to libraries like LangChain or LlamaIndex, that focus on glueing together dis
parate data stores, algorithms, models over the network.  

```
---

     
 
MachineLearning -  [ [P] My apprehension about LangChain and why you don‚Äôt need LangChain for building a RAG bot. ](https://www.reddit.com/r/MachineLearning/comments/15ry3z4/p_my_apprehension_about_langchain_and_why_you/) , 2023-09-15-0909
```
A lot of you might be giving me a mouthful just by reading the title of this blog. But to each their own, and probably y
ou might be just riding the hype train. Initially, I was quite fascinated by the work being done on LangChain and using 
it. And so I thought I would give it a try, but when I was installing it, I saw it downloading loads and loads of other 
libraries and most of which were not useful for what I was trying to build.

Checkout the entire blog post at [https://t
hevatsalsaglani.medium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f](https://thevatsalsaglani.med
ium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f)
```
---

     
 
deeplearning -  [ How to find 'custom' datasets for LLM ](https://www.reddit.com/r/deeplearning/comments/16bj3hg/how_to_find_custom_datasets_for_llm/) , 2023-09-15-0909
```
Hey folks,

I've been digging everywhere, including here, for LLMs and custom applications. So, I read many things, lear
ned from ppl here. Its time to try something. I will try implement Llama v2 - Langchain - Chroma combination. But also I
 want to upload a dataset so that I can try my model on that. 

I find some datasets big enough (for now, 2-5 gb is ok) 
however they are table-style. I want something more texty, I mean I could use 'American Stories' or 'Arxiv' however I be
lieve that they are already used by Llama to train. 

&#x200B;

Is there any suggestions or sources that you can provide
 ? Thanks!
```
---

     
