 
all -  [ List of FREE and Best Selling Discounted Courses ](https://www.reddit.com/r/udemyfreebies/comments/1fih9sq/list_of_free_and_best_selling_discounted_courses/) , 2024-09-17-0910
```
# Udemy Free Courses for 17 September 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get th
e courses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14928/)Machine Learning using Python Programmin
g
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14927/)Building Full Stack Python Web Apps Backed By Google Sheets

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14926/)Curso Completo de Linux Ubuntu
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/14925/)Complete web development course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8974/)
Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10198/)Jav
a Spring Boot: Professional eCommerce Project Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12239/)Com
plete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14529/)\[N
EW\] 2024: The Generative AI Lifecycle: A Primer
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/6709/)NLP – Buildin
g your own chatbots using AI
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/13966/)Mastering Power BI: Your Ultimat
e PL-300 Practice Tests 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12759/)\[NEW\] 2024:Mastering Generativ
e AI-From LLMs to Applications
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12369/)Build Instagram clone – React 
TailwindCSS Firebase
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14530/)\[NEW\]Mastering Retrieval Augmented Gen
eration (RAG) IN LLMs
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1606/)E-Commerce con ASP.NET Core | React | Cl
ean Architecture
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8098/)Complete Machine Learning,NLP Bootcamp MLOPS 
& Deployment
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14924/)ChatGPT for Business Analysts
* The Complete Gui
de to Instagram Marketing for Businesses
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/11483/)
* [REDEEM OFFER ](ht
tps://idownloadcoupon.com/udemy/9706/)Scrum Master Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/111
41/)Advanced Scrum Master Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1724/)Outstanding | Python P
rogramming with Examples in One Day
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10091/)Executive Diploma in Huma
n Resources Strategy
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1719/)The Pandas Bootcamp | Data Analysis with 
Pandas Python3
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/4827/)Exam Test for Python OCR: Optical Character Rec
ognition OCR
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/2106/)Learn C# Programming with Examples in ONE DAY
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/11983/)Research Methodologies in Strategy and Product Development
* [RE
DEEM OFFER ](https://idownloadcoupon.com/udemy/11942/)Adobe Premiere Pro CC Essential Video Editing Zero To Hero
* [REDE
EM OFFER ](https://idownloadcoupon.com/udemy/11840/)Blender Essential: From Beginner to 3D Masterclass
* [REDEEM OFFER ]
(https://idownloadcoupon.com/udemy/13077/)Complete Video Editing Mastery with Cyberlink PowerDirector
* [REDEEM OFFER ](
https://idownloadcoupon.com/udemy/1672/)Success Exam | Python NLTK : Natural Language ToolKit | NLP
* [REDEEM OFFER ](ht
tps://idownloadcoupon.com/udemy/7174/)Master Adobe Illustrator: Design Awesome Logos and Graphics
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/12315/)The Complete T-Shirt Design Toolkit: PS, AI
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/9862/)Data Structures Algorithm DSA | Python+Javascript LEETCODE
* Advance MS Excel VBA for Beginner to Adv
anced
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/2643/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/4834
/)Python Numpy Data Analysis for Data Scientist | AI | ML | DL
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9668/
)Professional Diploma in Advertising and Public Relations
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14922/)Pro
fessional Diploma in Administration Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12683/)Python Mastery
 with Tabnine: AI-Enhanced Coding Efficiency
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5752/)Complete Responsi
ve Web Development: 4 courses in 1
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7903/)Cómo Crear un Blog con Inte
ligencia Artificial 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7512/)Oracle Java Certification Exam OCA 1Z
0-808 Preparation Part2
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14569/)Professional Certificate in Marketing
 and Advertising
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7812/)Máster en Comercio Electrónico con WordPress 
2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9846/)Java 21 Programming Masterclass: Fundamentals for Beginne
rs
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7902/)Crea una Página Web con Elementor Pro y el Tema Hello 2024

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11374/)The Complete Photo Editing Masterclass With Adobe and Canva
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10280/)Essentials User Experience Design Adobe XD UI UX Design
* [RED
EEM OFFER ](https://idownloadcoupon.com/udemy/12274/)Mergers and Acquisitions: M
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/6546/)Ultimate Character Design Course with Adobe Illustrator
* Cómo Crear un Blog con WordPress Para Princ
ipiantes 2024
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/7901/)
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/6292/)Yoga For a Healthy Back
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11557/)Fast-track to Google Sheets
 Mastery Weekend Crash Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8609/)PowerShell Regular Expressions: 
Regex Master Class
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7698/)PowerShell Functions Master Class
* [REDEEM
 OFFER ](https://idownloadcoupon.com/udemy/14921/)Use ChatGPT And Ai To Make Money With Affiliate Marketing
* [REDEEM OF
FER ](https://idownloadcoupon.com/udemy/14920/)Wireless Wonders: Mastering ESP32 OTA (Over the Air) Updates
* [REDEEM OF
FER ](https://idownloadcoupon.com/udemy/14919/)Excel Intermedio
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/161/
)Ubuntu Network Server
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11052/)Docker Basics Unleashed
* [REDEEM OFFE
R ](https://idownloadcoupon.com/udemy/2272/)TypeScript para principiantes desde 0
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/11367/)Deep Learning Python Project: CNN based Image Classification
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/8768/)أساسيات الذكاء الاصطناعي: مقدمة عن تقنيات الذكاء الاصطناعي
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/14892/)Make a Web Template Responsive Using HTML5
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8274/)G
oogle Analytics 4 (GA4) Certification. How to Pass the Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7904/)Có
mo Crear un Embudo de Ventas con WordPress Desde Cero 2024
* Upgrade Your Social Media Presence with ChatGPT
* [REDEEM O
FFER](https://idownloadcoupon.com/udemy/9689/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7915/)Linux Security 
Checkup: Quick Audit Essentials
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10953/)Ethical Hacking: Post-Exploit
ation
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8729/)Chief Executive Officer (CEO) Program
* [REDEEM OFFER ](
https://idownloadcoupon.com/udemy/4754/)Linux Command Line Arsenal
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7
922/)Build 20 JavaScript Projects in 20 Day with HTML, CSS & JS
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9688
/)Reputation Management: Take Control of Your Company’s Image
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10218/
)Augmented Reality Certification ( AR Foundation, Vuforia )
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8763/)Wi
ndows Endpoint Security
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/14918/)Logo Design Essentials: Photoshop
* [
REDEEM OFFER ](https://idownloadcoupon.com/udemy/14916/)American English Consonants for Chinese Professionals
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/14915/)600 AEM Interview Questions Practice Test
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/12204/)Python Project: Build a PDF File Handling Tool from Scratch
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/12392/)Word Stress of American English
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12386/)
Construction Methodology of Steel
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12677/)Advanced Program in Product
 Development and Management

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ Problem with OllamaEmbeddings and PGVector.from_documents ](https://www.reddit.com/r/LangChain/comments/1fih5yc/problem_with_ollamaembeddings_and_pgvectorfrom/) , 2024-09-17-0910
```
I started developing with LangChain and Vectorstores.

It is working for OpenAI but not for Ollama. Error is `404 page n
ot found`

Any Idea anyone?

Commandline output:

    $python script.py
    Uploading pdf started.
    docs loaded
    e
mbeddings_from_documents executed
    Error in embeddings_from_documents_ollama: 404 page not found
    embeddings_from_
documents_ollama executed
    Processing done

script.py:

    from langchain_ollama import OllamaEmbeddings
    from la
ngchain_openai.embeddings import OpenAIEmbeddings
    from langchain_community.document_loaders import PyPDFLoader
    f
rom langchain.text_splitter import CharacterTextSplitter
    from langchain_postgres.vectorstores import PGVector
    
 
   from secret_key import openai_key  # only for personal secret key
    
    import os
    
    os.environ['OPENAI_API_
KEY'] = openai_key
    
    # Postgress Database Connection details
    HOST = 'localhost'
    DATABASE = 'vectordb'
   
 USER = 'testuser'
    PWD = 'testpwd'
    PORT = 6432
    DRIVER = 'psycopg'
    
    CONNECTION_STRING = PGVector.conn
ection_string_from_db_params(DRIVER, HOST, PORT, DATABASE, USER, PWD, )
    
    FILE_NAME = 'data/budget_speech.pdf'
  
  COLLECTION_NAME = 'Book: Budget Speech'
    
    
    def pdf_content_into_documents():
        loader = PyPDFLoader(F
ILE_NAME)
        documents = loader.load_and_split()
        text_splitter = CharacterTextSplitter(chunk_size=2000, chu
nk_overlap=100)
        docs = text_splitter.split_documents(documents)
        return docs
    
    
    def embeddings
_from_documents(docs):
        embeddings = OpenAIEmbeddings()
        # # create the store
        PGVector.from_docume
nts(
            embedding=embeddings,
            documents=docs,
            collection_name=COLLECTION_NAME,
        
    connection=CONNECTION_STRING,
            pre_delete_collection=True,
        )
    
    
    def embeddings_from_do
cuments_ollama(docs):
        try:
            embeddings = OllamaEmbeddings(
                model='all-minilm',
      
          base_url='http://localhost:11434',
            )
            # # create the store
            PGVector.from_do
cuments(
                embedding=embeddings,
                documents=docs,
                collection_name=COLLECTIO
N_NAME,
                connection=CONNECTION_STRING,
                pre_delete_collection=True,
            )
        
except Exception as e:
            print(f'Error in embeddings_from_documents_ollama: {e}')
    
    
    def load_pdf_i
nto_db():
        docs = pdf_content_into_documents()
        print('docs loaded')
        embeddings_from_documents(doc
s)
        print('embeddings_from_documents executed')
        embeddings_from_documents_ollama(docs)
        print('emb
eddings_from_documents_ollama executed')
    
    
    def ask_question(query):
        embeddings = OpenAIEmbeddings()

    
        # load the store for searching
        pgvector_docsearch = PGVector(
            embeddings=embeddings,
  
          collection_name=COLLECTION_NAME,
            connection=CONNECTION_STRING,
            use_jsonb=True,
       
 )
    
        searched_docs = pgvector_docsearch.search(query, 'mmr', k=1)
        # searched_docs = pgvector_docsearc
h.similarity_search(query, k=4)
        result = searched_docs[0].page_content
        print(result)
    
    
    if __
name__ == '__main__':
        print('Uploading pdf started.')
        load_pdf_into_db()
    
     #   print('Searching 
based on query.')
     #   ask_question(query='What is the name of the Prime Minister ?')
    
        print('Processing
 done')
```
---

     
 
all -  [ İnput Guardrails ](https://www.reddit.com/r/LangChain/comments/1fieice/input_guardrails/) , 2024-09-17-0910
```
How do you use input guardrails in your project? I have no idea how to implement them in a project. Do you use an LLM or
 are there specific tools to hide sensitive data? How is the workflow?
```
---

     
 
all -  [ Confused between AI SDK and LangChain ](https://www.reddit.com/r/LangChain/comments/1fie8ul/confused_between_ai_sdk_and_langchain/) , 2024-09-17-0910
```
I'm new to building RAG applications. I came across the AI SDK from Vercel and LangChain. How are they different when th
ey both provide abstractions to make inferences from an LLM?

```
---

     
 
all -  [ Understanding the Power BI toolkit and agent ](https://www.reddit.com/r/LangChain/comments/1fidecq/understanding_the_power_bi_toolkit_and_agent/) , 2024-09-17-0910
```
I am trying to work with the Power BI toolkit and agent. I want to be able to allow users to ask questions to a selected
 Power BI dataset and extract relevant data out. After going through the documentation, it seems the only metadata about
 the dataset I have to input is the list of table names. How will the model know about the relationships between the tab
les, or about any existing measures within those table names?

  
Is it even worth using the Power BI toolkit for my use
 case, or is it too underdeveloped, and would I be better off trying to leverage an LLM differently?
```
---

     
 
all -  [ Issues Integrating create_pandas_dataframe_agent with Hugging Face Inference Endpoint ](https://www.reddit.com/r/LangChain/comments/1fic5b6/issues_integrating_create_pandas_dataframe_agent/) , 2024-09-17-0910
```
Hello,

I'm currently working on a project using LangChain. Specifically, I'm trying to connect the create\_pandas\_data
frame\_agent function to a Hugging Face Inference Endpoint, but I keep encountering errors. Is it impossible to use this
 combination? No matter what I try, the issue persists.

Has anyone successfully done this or have any insights on how t
o resolve it?

    from langchain_community.llms import HuggingFaceEndpoint
    from langchain_community.chat_models.hug
gingface import ChatHuggingFace
    
    llm = HuggingFaceEndpoint(
        endpoint_url=hf_endpoint_url,
        max_ne
w_tokens=4500,
        temperature=0.5,
    )
    
    # Create the pandas dataframe agent
    agent = create_pandas_dat
aframe_agent(
        llm=llm,
        df=df,
        agent_type='openai-tools',
        allow_dangerous_code=True,
    
    verbose=True
    )
    
    agent.run({'input': 'Q'})

https://preview.redd.it/vzip08dat7pd1.png?width=1304&format=p
ng&auto=webp&s=3702ce3aec7a27cee750dadf576a0fbdbbefafbb

error : 

    TypeError: InferenceClient.text_generation() got 
an unexpected keyword argument 'tools'
```
---

     
 
all -  [ Interactive AI Agents Market Landscape Map (Sep 2024) ](https://www.reddit.com/r/AI_Agents/comments/1fibklp/interactive_ai_agents_market_landscape_map_sep/) , 2024-09-17-0910
```
'Hey, AI Agents enthusiasts! Check out the interactive AI Agents Market Landscape Map (Sept 2024).'

you can play with i
t here: [https://aiagentsdirectory.com/landscape](https://aiagentsdirectory.com/landscape)

https://preview.redd.it/i5jr
o3too7pd1.png?width=1319&format=png&auto=webp&s=91ff194bff623a634d76259220b9d8c706b11448


```
---

     
 
all -  [ Has anyone used LangGraph to build agentic pipelines to assist writing? ](https://www.reddit.com/r/WritingWithAI/comments/1fiaqbk/has_anyone_used_langgraph_to_build_agentic/) , 2024-09-17-0910
```
I'm looking to experiment with augmenting my writing with a 'handmade' agentic workflow with lots of HiL. I've written s
ome short stories manually filtering and collating paragraphs from ChatGPT models I fine-tuned. 

Anyone here tried out 
LangGraph for this kind of thing?

  
[https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/7/essay-write
r](https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/7/essay-writer)

[https://langchain-ai.github.io/
langgraph/tutorials/multi\_agent/multi-agent-collaboration/](https://langchain-ai.github.io/langgraph/tutorials/multi_ag
ent/multi-agent-collaboration/)
```
---

     
 
all -  [ How do I stream the response? ](https://www.reddit.com/r/LangChain/comments/1fi6v8q/how_do_i_stream_the_response/) , 2024-09-17-0910
```
Hello,

Can anyone help me stream the data? This is my function

    def generate_answer(retriever, query):
        prom
pt = ChatPromptTemplate.from_template(template)
        rag_chain_from_docs = (
            RunnablePassthrough.assign(c
ontext=(lambda x: format_docs(x['context'])))
            | prompt
            | llm
            | StrOutputParser()
   
     )
    
        rag_chain_with_source = RunnableParallel(
            {'context': retriever, 'question': RunnablePas
sthrough()}
        ).assign(answer=rag_chain_from_docs)
    
        return rag_chain_with_source.invoke(query)
    
```
---

     
 
all -  [ [1 YoE, Unemployed, ML Engineer, UK] ](https://www.reddit.com/r/resumes/comments/1fi6b9z/1_yoe_unemployed_ml_engineer_uk/) , 2024-09-17-0910
```
Hi any review of my CV would be helpful thank you. I'm aware of some possible problems that may be present already:

* G
ap between education and previous employment. This is because of massive burnout after finishing degree most likely rela
ted to very recently diagnosed ADHD.
* It looks like there is a lack of traditional ML in my skillset however outside of
 my tutoring I haven't been working on any projects since I finished my education.
* Second role is essentially a contin
uation of the first role working directly with the client - i'm worried the short length of the role will put hiring man
agers off.

I'm looking for roles in London or remotely.

To be honest I'm not sure where to start with my CV, I imagine
 I will need to undertake a couple of projects to showcase more of my skills and help to improve my coverage. I don't re
ally know if I am making the most of what experience I do have so any help would be appreciated.

https://preview.redd.i
t/qzk4m8qmn6pd1.png?width=5100&format=png&auto=webp&s=c893451adf8703b6bbf147b4c2cbea39c70300db


```
---

     
 
all -  [ When to split an agent into multiple agents? ](https://www.reddit.com/r/LangChain/comments/1fi4nb0/when_to_split_an_agent_into_multiple_agents/) , 2024-09-17-0910
```
I am building a synthetic legal research team. The goal is to given a query it will search the web, previous judgements 
and case files. So far I am thinking of two approach.

1. Have a multi agent system with separate agent for planning, se
parate agent for drafting and separate agent for using tools to find documents.

2. Have 1 ReAct style agent to plan and
 execute as it likes.

Considering the list of tools is not large(3-4) which approach should be better?

I am currently 
trying approach 1 but it's hard building such system with LangGraph because then there needs to be an additional supervi
sor agent and there needs to be some decision making on when do we want to replan.

While in the approach 2 it would be 
much simpler.
```
---

     
 
all -  [ Need Help with LangChain AgentExecutor - LLM Keeps Repeating Actions and Unnecessarily Using Tools ](https://www.reddit.com/r/LangChain/comments/1fi3myq/need_help_with_langchain_agentexecutor_llm_keeps/) , 2024-09-17-0910
```
I'm relatively new to using LangChain and have been working on a project where I use a custom Python tool to query and f
ilter data, then send it back along with context loaded from Pinecone. Sometimes I need the LLM to analyze both the cont
ext and answer the query. I've been using **AgentExecutor** to handle this, but the results aren't quite what I'm expect
ing.

Here’s a specific issue I'm facing:

1. **Repeating Actions**: The context I'm loading from Pinecone is perfect, b
ut when I check the 'thought process' of the LLM, it keeps repeating the same action, even after it has already found th
e result. It feels like it’s stuck in a loop.
2. **Unnecessary Tool Usage**: Sometimes, the agent doesn’t need to use th
e tool (e.g., when I’m asking a question from a PDF and the context is already retrieved), but it still uses the tool to
 answer the question. Ideally, I want it to analyze the context first and not invoke the tool unnecessarily.

# Example:


I have a custom Python tool with an input parameter that needs to be generated by the LLM. For example, for a question
 like *'Have we used Stripe before?'*, the tool should be called with 'Stripe' as the parameter. The tool then uses **pa
ndas** to query the data and return results. Based on that result and the context provided (from Pinecone), the agent sh
ould answer the question.

The problem is that **AgentExecutor** isn't behaving as expected—sometimes it's calling the t
ool when it shouldn't, or it repeats actions unnecessarily, even after getting the right data.

I’m currently using the 
**Groq API** and have multiple PDFs in my setup for **Retrieval-Augmented Generation (RAG)**. Most tutorials I’ve watche
d haven’t covered this kind of use case, and I’m unsure how to optimize the agent’s behavior.

If anyone has experience 
with **LangChain's AgentExecutor** or has solved similar issues, I’d appreciate your guidance. PLEASE HELP ME!!!!
```
---

     
 
all -  [ How Can I use for RAG and Custom Tool together to retrieve info and generate the output ](https://www.reddit.com/r/Rag/comments/1fi3m85/how_can_i_use_for_rag_and_custom_tool_together_to/) , 2024-09-17-0910
```
I'm relatively new to using LangChain and have been working on a project where I use a custom Python tool to query and f
ilter data, then send it back along with context loaded from Pinecone. Sometimes I need the LLM to analyze both the cont
ext and answer the query. I've been using **AgentExecutor** to handle this, but the results aren't quite what I'm expect
ing.

Here’s a specific issue I'm facing:

1. **Repeating Actions**: The context I'm loading from Pinecone is perfect, b
ut when I check the 'thought process' of the LLM, it keeps repeating the same action, even after it has already found th
e result. It feels like it’s stuck in a loop.
2. **Unnecessary Tool Usage**: Sometimes, the agent doesn’t need to use th
e tool (e.g., when I’m asking a question from a PDF and the context is already retrieved), but it still uses the tool to
 answer the question. Ideally, I want it to analyze the context first and not invoke the tool unnecessarily.

# Example:


I have a custom Python tool with an input parameter that needs to be generated by the LLM. For example, for a question
 like *'Have we used Stripe before?'*, the tool should be called with 'Stripe' as the parameter. The tool then uses **pa
ndas** to query the data and return results. Based on that result and the context provided (from Pinecone), the agent sh
ould answer the question.

The problem is that **AgentExecutor** isn't behaving as expected—sometimes it's calling the t
ool when it shouldn't, or it repeats actions unnecessarily, even after getting the right data.

I’m currently using the 
**Groq API** and have multiple PDFs in my setup for **Retrieval-Augmented Generation (RAG)**. Most tutorials I’ve watche
d haven’t covered this kind of use case, and I’m unsure how to optimize the agent’s behavior.

If anyone has experience 
with **LangChain's AgentExecutor** or has solved similar issues, I’d appreciate your guidance. PLEASE HELP MEEEE!!!!!!!!

```
---

     
 
all -  [ Why we no longer use LangChain for building our AI agents ](https://www.octomind.dev/blog/why-we-no-longer-use-langchain-for-building-our-ai-agents?ref=dailydev) , 2024-09-17-0910
```

```
---

     
 
all -  [ Join r/AIQuality: A Community for AI Evaluation and Output Quality ](https://www.reddit.com/r/LangChain/comments/1fi2dmp/join_raiquality_a_community_for_ai_evaluation_and/) , 2024-09-17-0910
```
If you're focused on output quality and evaluation in LLMs, I’ve created [r/AIQuality](https://www.reddit.com/r/AIQualit
y/) —a community dedicated to those of us working to build reliable, hallucination-free systems.

Personally, I’ve faced
 constant challenges with evaluating my RAG pipeline. Should I use DSPy to build it? Which retriever technique works bes
t? Should I switch to a different generator model? And most importantly, how do I truly know if my model is improving or
 regressing? These are the questions that make evaluation tough, but crucial.

With RAG and LLMs evolving rapidly, there
 wasn't a space to dive deep into these evaluation struggles—until now. That’s why I created this community: to share in
sights, explore cutting-edge research, and tackle the real challenges of evaluating LLM/RAG systems.

If you’re navigati
ng similar issues and want to improve your evaluation process, join us. [https://www.reddit.com/r/AIQuality/](https://ww
w.reddit.com/r/AIQuality/)
```
---

     
 
all -  [ This would be a good place to get started on AI agents.
 ](https://www.reddit.com/r/LangChain/comments/1fi24dq/this_would_be_a_good_place_to_get_started_on_ai/) , 2024-09-17-0910
```
Here is the course outline of the [free SmythOS AI agent engineer certification course.](https://academy.smythos.com/cou
rses/ai-agent-engineer) It covers everything from introduction to LLMs to more advanced topics like RAG. I think it is a
 good palce to start if you want to sharpen your AI agent development skills

Course Outline

1. **Introduction to LLMs,
 AI agents and the SmythOS studio**

1. **Advanced Prompting and Data Handling**

1. **Integration Components and API Ma
stery**

1. **Data Pools, Agents, and Advanced Features**

1. **Advanced Concepts and Real-World Applications**
```
---

     
 
all -  [ [Student] 0 YoE Machine Learning grad student applying for jobs, receiving no callbacks  ](https://www.reddit.com/r/EngineeringResumes/comments/1fhyns2/student_0_yoe_machine_learning_grad_student/) , 2024-09-17-0910
```
I'm mainly applying for entry level data science and machine learning roles. My undergrad major is completely unrelated,
 so I don't have any related internships. I looked at the wiki and tried my best to follow the given advice. I'm not too
 sure if my bullet points correctly reflect star format, since some results were hard to quantify. Another problem I'm u
nsure about is the extra white space since I lack experience and am not too sure how to fill it. Is there anything else 
glaring wrong with this resume? Thanks for all the help.

https://preview.redd.it/1qlr6wdtg4pd1.png?width=5100&format=pn
g&auto=webp&s=b062c7d8a796cffd9be97953149f311f74af007e


```
---

     
 
all -  [  Tutorial: Easily Integrate GenAI into Websites with RAG-as-a-Service ](https://www.reddit.com/r/LangChain/comments/1fhylp2/tutorial_easily_integrate_genai_into_websites/) , 2024-09-17-0910
```
Hello developers,

I recently completed a project that demonstrates how to integrate generative AI into websites using a
 RAG-as-a-Service approach. For those looking to add AI capabilities to their projects without the complexity of setting
 up vector databases or managing tokens, this method offers a streamlined solution.

Key points:

* Used Cody AI's API f
or RAG (Retrieval Augmented Generation) functionality
* Built a simple 'WebMD for Cats' as a demonstration project
* Uti
lized Taipy, a Python framework, for the frontend
* Completed the basic implementation in under an hour

The tutorial co
vers:

1. Setting up Cody AI
2. Building a basic UI with Taipy
3. Integrating AI responses into the application

This ap
proach allows for easy model switching without code changes, making it flexible for various use cases such as product fi
nders, smart FAQs, or AI experimentation.

If you're interested in learning more, you can find the full tutorial here: [
https://medium.com/gitconnected/use-this-trick-to-easily-integrate-genai-in-your-websites-with-rag-as-a-service-2b956ff7
91dc](https://medium.com/gitconnected/use-this-trick-to-easily-integrate-genai-in-your-websites-with-rag-as-a-service-2b
956ff791dc)

I'm open to questions and would appreciate any feedback, especially from those who have experience with Tai
py or similar frameworks.

Thank you for your time.
```
---

     
 
all -  [ Embedding model benchmark code with AutoRAG ](https://www.reddit.com/r/LangChain/comments/1fhyenj/embedding_model_benchmark_code_with_autorag/) , 2024-09-17-0910
```
Hello. I think there are many people who are looking for a great embedding model. Here is the one of the easiest way to 
do benchmarking using [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG).

# 1. Prepare Dataset

For benchmarking em
bedding model, I used the [RAG Benchmark Data](https://huggingface.co/datasets/allganize/RAG-Evaluation-Dataset-KO) by A
llganize. I had to undertake specific steps to prepare the data. Here’s a brief outline of the process:

1. **Corpus Cre
ation**:
   * Downloaded PDFs of the original documents.
   * Parsed the PDFs using Naver OCR model to convert them into
 text.
2. **QA Data Creation**:
   * Identified retrieval gt (correct paragraph) from labeled Allganize data.
   * Steps
 involved:
      1. OCR the PDFs into text.
      2. Treat each PDF page as a chunk and assign unique doc\_ids.
      3.
 Label the correct chunk ID for questions.
      4. Assign unique qid for each question and map to retrieval gt and the 
best answer. As a result, I amde a dataset with 720 chunks and 114 QA pairs.

# 2. Make AutoRAG YAML file

I made an YAM
L file for benchmarking each embedding model. It includes all embedding models with six different metrics and five diffe
rent top-k setting.

    node_lines:
    - node_line_name: retrieve_node_line
      nodes:
        - node_type: retrieva
l
          strategy:
            metrics: [retrieval_f1, retrieval_recall, retrieval_precision,
                      r
etrieval_map, retrieval_mrr, retrieval_ndcg]
          top_k: [1, 3, 5, 10, 50]
          modules:
            - module_
type: vectordb
              embedding_model:
              - openai
              - openai_embed_3_small
              
- openai_embed_3_large
              - upstage_embed
              - cohere_embed
              - ko-sroberta-multitask 
# jhgan/ko-sroberta-multitask
              - KoSimCSE-roberta # BM-K/KoSimCSE-roberta
              - paraphrase-multil
ingual-mpnet-base-v2
              - paraphrase-multilingual-MiniLM-L12-v2
              - multilingual-e5-large-instruc
t

# 3. Add embedding models to AutoRAG

Here is the [`main.py`](http://main.py) model to execute embedding model benchm
ark. Don't forget to install AutoRAG by `pip install AutoRAG`

    import os
    import autorag
    import click
    fro
m autorag.evaluator import Evaluator
    from dotenv import load_dotenv
    from llama_index.embeddings.cohere import Co
hereEmbedding
    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
    from llama_index.embeddings.up
stage import UpstageEmbedding
    root_path = os.path.dirname(os.path.realpath(__file__))
    data_path = os.path.join(r
oot_path, 'data')
    u/click.command()
    @click.option('--config', type=click.Path(exists=True), default=os.path.join
(root_path, 'config',
                                                                             'embedding_benchmark.
yaml'))
    @click.option('--qa_data_path', type=click.Path(exists=True), default=os.path.join(data_path, 'qa_v4.parquet
'))
    @click.option('--corpus_data_path', type=click.Path(exists=True),
                  default=os.path.join(data_pa
th, 'ocr_corpus_v3.parquet'))
    @click.option('--project_dir', type=click.Path(exists=False), default=os.path.join(roo
t_path, 'benchmark'))
    def main(config, qa_data_path, corpus_data_path, project_dir):
        load_dotenv()
        a
utorag.embedding_models['ko-sroberta-multitask'] = autorag.LazyInit(HuggingFaceEmbedding,
                              
                                               model_name='jhgan/ko-sroberta-multitask')
        autorag.embedding_model
s['KoSimCSE-roberta'] = autorag.LazyInit(HuggingFaceEmbedding,
                                                         
               model_name='BM-K/KoSimCSE-roberta')
        autorag.embedding_models['paraphrase-multilingual-mpnet-base-
v2'] = autorag.LazyInit(
            HuggingFaceEmbedding, model_name='sentence-transformers/paraphrase-multilingual-mpn
et-base-v2')
        autorag.embedding_models['paraphrase-multilingual-MiniLM-L12-v2'] = autorag.LazyInit(
            H
uggingFaceEmbedding, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        autorag.embedding
_models['multilingual-e5-large-instruct'] = autorag.LazyInit(
            HuggingFaceEmbedding, model_name='intfloat/mul
tilingual-e5-large-instruct')
        autorag.embedding_models['upstage_embed'] = autorag.LazyInit(UpstageEmbedding)
   
     autorag.embedding_models['cohere_embed'] = autorag.LazyInit(CohereEmbedding, model_name='embed-multilingual-v3.0',

                                                                    api_key=os.getenv('COHERE_API_KEY'))
        if not 
os.path.exists(project_dir):
            os.makedirs(project_dir)
        evaluator = Evaluator(qa_data_path, corpus_dat
a_path, project_dir=project_dir)
        evaluator.start_trial(config)
    if __name__ == '__main__':
        main()

An
d done! You can check out the benchmarking result by dashboard and files. Also, if you run the whole code or just want t
o check detailed result, the repo is [here](https://github.com/Marker-Inc-Korea/AutoRAG-example-korean-embedding-benchma
rk). With AutoRAG, you can make a benchmarking of embedding model like this easily. Finally, AutoRAG is not only for emb
edding model. It optimizes whole RAG process with YAML file. You can select what is best RAG modules for your own datase
t. So check this out! [AutoRAG repo here](https://github.com/Marker-Inc-Korea/AutoRAG). For more details, check this [bl
og post](https://medium.com/@autorag/making-benchmark-of-different-embedding-models-1c327a0dae1f).
```
---

     
 
all -  [ Am i doing something terribly wrong? ](https://www.reddit.com/r/datascience/comments/1fhxr6h/am_i_doing_something_terribly_wrong/) , 2024-09-17-0910
```
Good Morning/Afternoon Everyone,

My name is Kashish and i have been trying to get a job almost an year in the UK. My re
sume is shown here and i agree that this was not the first resume of mine, this one is the one i made 2 weeks ago. But i
 have been struggling to get interviews. I have gotten like 3 interviews in the entire 10 months of applying. Truly now 
i am starting to question that am i truly doing something wrong ?? I have tried to quantify as much as i can. Trying to 
show business impact and how profitable they can be. Trying to create relevant projects and even deploying them on cloud
. Any sort of responses or tips would be highly appreciated.

Thank you so much for reading this.

[Apologies for the te
rrible screenshot quality.](https://preview.redd.it/lrhvvxorh4pd1.png?width=585&format=png&auto=webp&s=7c28a8a9df26be1e9
77ca12e5f50048018cb67db)


```
---

     
 
all -  [ LangGraph (JS) + Checkpointers - how to stream tool/node outputs (as each token arrives from the LLM ](https://www.reddit.com/r/LangChain/comments/1fhrji9/langgraph_js_checkpointers_how_to_stream_toolnode/) , 2024-09-17-0910
```
I've been using LangGraph and \`.streamEvents\` (v2) to stream the tokens generated inside each LangGraph node, but this
 doesn't seem to work with \`Checkpointers\` in LangGraph. 

Any know how to go about this? Basically, I want to transit
ion to using Checkpointers, to save the current state, but also stream token-by-token everything/anything that is occurr
ing inside any of my LangGraph nodes. At this stage I'm not sure where/what feature I need to be investigating (or wheth
er this is even possible with Checkpointers in use ??)   
u/hwchase17 - would greatly appreciate your thoughts!

NOTE: I
'm using LangGraph JS
```
---

     
 
all -  [ [3 YoE, Grad Student, Data Scientist, United States] ](https://i.redd.it/21o6oexxv1pd1.jpeg) , 2024-09-17-0910
```
Hi,
I have 3-9 month graduation window. (Got done with my course credit requirements early)

I am desperately applying t
o jobs at the moment. I have a low hit rate on my applications. 
I am working on that by networking and self improvement
. 

I would love to know if something on my resume is holding me back. 

Additionally, any helpful tips are appreciated 
and yes, you can roast my resume. :)
```
---

     
 
all -  [ Roast my resume please ](https://www.reddit.com/r/learnmachinelearning/comments/1fhn4bj/roast_my_resume_please/) , 2024-09-17-0910
```
I've been using this resume to apply for internship positions in the field, but I haven't received any interviews. Can y
ou tell me what I might be doing wrong? Here are my thoughts

* The resume might be too complicated.
* There's no object
ive or skills section.'

Should I use less 'potentially complicated keywords', and remove some bullets to add the other 
sections or is it fine this way?

https://preview.redd.it/gqjr9vbne1pd1.png?width=657&format=png&auto=webp&s=d76acf91aa9
5b42ed018ef23e778faef6945ceff


```
---

     
 
all -  [ Open AI and Langchain ](https://www.reddit.com/r/LangChain/comments/1fhigl5/open_ai_and_langchain/) , 2024-09-17-0910
```
Hello  
I am beginner in this field, and i am using it for research purposes

I have watched tutorial that use Langchain
 and open ai, and after trying to apply the same code with the same example i can't get an answer, is that because i am 
not subscribed to OpenAi?


```
---

     
 
all -  [ I created and deployed an AI video generator using Manim ](https://www.reddit.com/r/manim/comments/1fhg1jd/i_created_and_deployed_an_ai_video_generator/) , 2024-09-17-0910
```
I’ve always struggled with understanding marketing terms and metrics, but as a freelance web developer, I had to dive in
to analytics numbers anyway. It took me a while to really get a good feel for those numbers. So, I thought, why not crea
te a tool that explains business metrics through explainer videos?

I decided to use Manim since I’d played around with 
it before, and it’s great for visualizing graphs and charts in videos. The catch was I only had about 15 days to build t
he prototype. Somehow, I got it done and launched it on Product Hunt under the name 'Happy Insights.'

For the technical
 side: I use LangChain to generate the video configuration, which basically defines the elements in the video (text plac
ement, size, animations, graphs, etc.). Then, this configuration is passed to the animator, which uses Manim to create t
he animation.

I deployed it on AWS Lambda using Step Functions. To speed things up, the video is rendered in multiple s
egments and stitched together at the end with ffmpeg.

Honestly, making dynamic animations with Manim wasn’t fun. It’s a
 bit of a nightmare structurally, and I had to use a bunch of hacks to get it to work for what I needed. So now I’m expl
oring better ways to create dynamic videos.

Here’s a sample video it generates from a report: [https://happyinsights.io
/video-player/?id=7HIAwJfjNDc2qLDcn1yv](https://happyinsights.io/video-player/?id=7HIAwJfjNDc2qLDcn1yv)

Feel free to tr
y it out here: https://happyinsights.io/report — but heads up, it's super slow right now.

In the meantime, my friends a
nd I are working on a new version, and you can check it out here: [https://happyinsights.io](https://happyinsights.io)
```
---

     
 
all -  [ Does LangChain support Opensource models deployed on a private server, specially using it as csv age ](https://www.reddit.com/r/LangChain/comments/1fhams2/does_langchain_support_opensource_models_deployed/) , 2024-09-17-0910
```
Most of the resources online is only for openai models? where you give it api key. But what about something like llama 3
.1 hosted privately ?
```
---

     
 
all -  [ How to do Indexing and Chunking of hierarchical data ](https://www.reddit.com/r/Rag/comments/1fh9j4r/how_to_do_indexing_and_chunking_of_hierarchical/) , 2024-09-17-0910
```
Suppose I have a hierarchical folder and subfolder structure and each subfolder may contain some other subfolder or file
s. Now, my questions are - 

1) How do I load such hierarchical data? Do I use Langchain's directoryLoader? If yes, how 
do I exclude certain folders for data loading?

2) If the user's question can be answered with the help of multiple file
s, what should be my chunking and retrieval strategy to get the best chunks when retrieved?
```
---

     
 
all -  [ Resume Review - 1.4 YOE Software Engineer (Mostly in Flutter) Looking for a switch but not getting i ](https://i.redd.it/z0u8er39zxod1.jpeg) , 2024-09-17-0910
```
Hi guys, As the title says I've been working as a Software engineer at a Fintech for the last 1 year and 5 months (first
 3 months were internship) and I'm looking to switch but not getting any interview callbacks. Can you guys please sugges
t changes to my resume and help a fellow dev out ?
```
---

     
 
all -  [ What is the best approach for Parsing and Retrieving Code Context Across Multiple Files in a Hierarc ](https://www.reddit.com/r/LocalLLM/comments/1fh8gn7/what_is_the_best_approach_for_parsing_and/) , 2024-09-17-0910
```
I want to implement a Code-RAG system on a code directory where I need to:

* Parse and load all the files from folders 
and subfolders while excluding specific file extensions.
* Embed and store the parsed content into a vector store.
* Ret
rieve relevant information based on user queries.

However, I’m facing two major challenges:

**File Parsing and Loading
:** What’s the most efficient method to parse and load files in a hierarchical manner (reflecting their folder structure
)? Should I use Langchain’s directory loader, or is there a better way? I came across the Tree-sitter tool in Claude-dev
’s repo, which is used to build syntax trees for source files—would this be useful for hierarchical parsing?

**Cross-Fi
le Context Retrieval:** If the relevant context for a user’s query is spread across multiple files located in different 
subfolders, how can I fine-tune my retrieval system to identify the correct context across these files? Would reranking 
resolve this, or is there a better approach?

**Query Translation:** Do I need to use Something like Multi-Query or RAG-
Fusion to achieve better retrieval for hierarchical data?

\[I want to understand how tools like [continue.dev](http://c
ontinue.dev/) and [claude-dev](https://github.com/saoudrizwan/claude-dev) work\]
```
---

     
 
all -  [ LangChain vs LlamaIndex ](https://www.reddit.com/r/LangChain/comments/1fh7hes/langchain_vs_llamaindex/) , 2024-09-17-0910
```
I am beginner, trying to embed my input nlq and I came across LangChain and LlamaIndex terms. Trying to understand how t
o use LangChain or Llama Index to build my RAG idea. I have few questions to start my work.

1. Can anyone help me under
stand LangChain vs LlamaIndex?

2. Are these two different from each other?

3. How to evaluate a model whether it suits
 my needs. For example i want to embed my input and output to a vector db and retrieve it. Do I need to prefer retrieval
 based models or any model would fit?

4. All vector DB's have their own way to use the model, for example if I want to 
use chromaDB and train the model locally can I directly use chromaDB's implementation of using models. Or is there a cor
rect way to use the model to train and retrieve?
```
---

     
 
all -  [ What is the best approach for Parsing and Retrieving Code Context Across Multiple Files in a Hierarc ](https://www.reddit.com/r/LLMDevs/comments/1fh51g5/what_is_the_best_approach_for_parsing_and/) , 2024-09-17-0910
```
I want to implement a Code-RAG system on a code directory where I need to:

* Parse and load all the files from folders 
and subfolders while excluding specific file extensions.
* Embed and store the parsed content into a vector store.
* Ret
rieve relevant information based on user queries.

However, I’m facing two major challenges:

**File Parsing and Loading
:** What’s the most efficient method to parse and load files in a hierarchical manner (reflecting their folder structure
)? Should I use Langchain’s directory loader, or is there a better way? I came across the Tree-sitter tool in Claude-dev
’s repo, which is used to build syntax trees for source files—would this be useful for hierarchical parsing?

**Cross-Fi
le Context Retrieval:** If the relevant context for a user’s query is spread across multiple files located in different 
subfolders, how can I fine-tune my retrieval system to identify the correct context across these files? Would reranking 
resolve this, or is there a better approach?

**Query Translation:** Do I need to use Something like Multi-Query or RAG-
Fusion to achieve better retrieval for hierarchical data?

\[I want to understand how tools like [continue.dev](http://c
ontinue.dev/) and [claude-dev](https://github.com/saoudrizwan/claude-dev) work\]
```
---

     
 
all -  [ [1 YoE, Recent Graduate/Data Analyst Internship, Data Analyst/Scientist/Engineer, Europe/Spain] ](https://www.reddit.com/r/resumes/comments/1fgukb2/1_yoe_recent_graduatedata_analyst_internship_data/) , 2024-09-17-0910
```
https://preview.redd.it/zjb4zgowytod1.png?width=850&format=png&auto=webp&s=3bbbfc89746e78009f3c4e5642004b300dcf61d6


```
---

     
 
all -  [ Interactive Ai agents market landscape map ](https://i.redd.it/0paxh1akisod1.png) , 2024-09-17-0910
```
You can play with here https://aiagentsdirectory.com/landscape
```
---

     
 
all -  [ How to select the right LLM model for your use case? ](https://www.reddit.com/gallery/1fgn7jh) , 2024-09-17-0910
```
☕️ Coffee Break Concepts' Vol.12 -> How to select the right LLM Model for your use case?

When you begin any client proj
ect, one of the most frequently asked questions is, “Which model should I use?” There isn’t a straightforward answer to 
this; it’s a process. In this coffee break concept, we’ll explain that process so that next time your client asks you th
is question, you can share this document with them. 😁

This document deep dives into:
1. Core Principles of model select
ion
2. Steps to Achieve Model Accuracy
3. Cost vs Latency analysis
4. Practical example from Open AI team
5. Overall Sum
mary

Explore our comprehensive ‘Mastering LLM Interview Prep Course’ for more insightful content like this. 

Course Li
nk: https://www.masteringllm.com/course/llm-interview-questions-and-answers?utm_source=reddit&utm_medium=coffee_break&ut
m_campaign=openai_model
50% off using Coupon Code: LLM50 (Limited time)

Start your journey towards mastering LLM today!


#llm #genai #generativeai #openai #langchain #agents #modelselection
```
---

     
 
all -  [ A fully automated and AI generated podcast on GenAI ](https://www.reddit.com/r/LangChain/comments/1fgmk2o/a_fully_automated_and_ai_generated_podcast_on/) , 2024-09-17-0910
```
I am launching a new experiment: a podcast that is fully automated and powered by Generative AI. That's right—the hosts 
of this podcast don't exist in real life. However, they are highly skilled at breaking down complex topics from various 
sources and presenting them in a short, digestible format.

The episodes focus on how engineering teams in big tech comp
anies are using Generative AI to solve novel use cases, as well as on Generative AI research in academia.

The first rel
ease features 10 episodes, including some exciting ones like:
- How Uber engineering uses GenAI for mobile testing.
- Ho
w OpenAI's latest reasoning models work.
- How Box uses Amazon Q to power Box AI.
- How DoorDash uses LLMs to enrich it'
s SKUs.

The episodes are semi-automated and fully powered using NotebookLM from Google, Riverside.fm and Spotify.

The 
content for these episodes is sourced from various engineering blogs, case studies, and arXiv papers. Sit back, relax, a
nd enjoy some unique insights into how engineering teams are leveraging GenAI, narrated and powered by GenAI. Now availa
ble on Apple Podcasts & Spotify!

Spotify - https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439
App
le - https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164
```
---

     
 
MachineLearning -  [ [P] Review and suggest ideas for my chatbot ](https://www.reddit.com/r/MachineLearning/comments/1fb2mwl/p_review_and_suggest_ideas_for_my_chatbot/) , 2024-09-17-0910
```
Ok, so I am currently trying to build support chatbot with following technicalities 
1. FastAPI for web server(Need to m
ake it faster)
2. Qdrant as Vector Data Base(Found it to be the fastest amongst Chromadb, Elastic Search and Milvus)
3. 
MongoDB for storing all the data and feedback.
4. Semantic chunking with max token limit of 512.
5. granite-13b-chat-v2 
as the LLM(I know it's not good but I have limited options available)
6. The data is structured as well as unstructured.
 Thinking of having involving GraphRAG with current architecture.
7. Multiple data sources stored in multiple collection
s of vector database because I have implemented an access control.
8. Using mongoengine currently as a ORM. If you know 
something better please suggest.
9. Using all-miniLM-l6-v2 as vector embedding currently but planning to use stella_en_4
00M_v5.
10. Using cosine similarity to retrieve the documents.
11. Using BLEU, F1 and BERT score for automated evaluatio
n based on golden answer.
12. Using top_k as 3.
13. Currently using basic question answering prompt but want to improve 
it. Any tips? Also heard about Automatic Prompt Evaluation.
14. Currently using custom code for everything. Looking to u
se Llamaindex or Langchain for this. 
15. Right now I am not using any AI Agent, but I want to know your opinions. 
16. 
It's a simple RAG framework and I am working on improving it.
17. I haven't included reranker but I am planning to do so
 too.

I think I mentioned pretty much everything I am using for my project. So please share your suggestions, comments 
and reviews for the same. Thank you!!
```
---

     
 
MachineLearning -  [ [P] Lessons from Retrieval Augmented Generation ](https://www.reddit.com/r/MachineLearning/comments/1f9tvg7/p_lessons_from_retrieval_augmented_generation/) , 2024-09-17-0910
```
I implemented Rag in my organization and just wrote a blog about what we learned here:   
[https://www.b-yond.com/post/t
ransforming-telco-troubleshooting-our-journey-building-telcogpt-with-rag](https://www.b-yond.com/post/transforming-telco
-troubleshooting-our-journey-building-telcogpt-with-rag)

Hoping it would be helpful for those in this area. Covers rag 
evaluation (ragas), sql db, langchain agents vs chains, weaviate vector db, hybrid search, reranking, and more.

Some ad
ditional insights on ranking and hybrid search here:

[https://www.linkedin.com/posts/drzohaib\_transforming-telco-troub
leshooting-our-journey-activity-7232072089837486081--Le1?utm\_source=share&utm\_medium=member\_android](https://www.link
edin.com/posts/drzohaib_transforming-telco-troubleshooting-our-journey-activity-7232072089837486081--Le1?utm_source=shar
e&utm_medium=member_android)
```
---

     
 
deeplearning -  [ Month of August in AI ](https://www.reddit.com/r/deeplearning/comments/1f6zfz0/month_of_august_in_ai/) , 2024-09-17-0910
```
🔍 I**nside this Issue:**

* 🤖 La*test Breakthroughs: *This month it’s all about A*gents, LangChain RAG, and LLMs evaluat
ion challenges.*
* 🌐 AI Monthly News: Discover how these stories are revolutionizing industries and impacting everyday l
ife: E*U AI Act, California’s Controversial SB1047 AI regulation act, Drama at OpenAI, and possible funding at OpenAI by
 Nvidia and Apple.*
* 📚 Editor’s Special: This covers the interesting talks, lectures, and articles we came across recen
tly.

Follow me on Twitter and LinkedIn at [**RealAIGuys**](https://twitter.com/RealAIGuys) and [**AIGuysEditor**](https
://www.linkedin.com/in/vishal-rajput-999164122/) to get insight on new AI developments.

>**Please don't forget to subsc
ribe to our Newsletter:** [**https://medium.com/aiguys/newsletter**](https://medium.com/aiguys/newsletter)

# Latest Bre
akthroughs

Are Agents just simple rules? Are Agents just enhanced reasoning? The answer is yes and no. Yes, in the sens
e that agents have simple rules and can sometimes enhance reasoning capabilities compared to a single prompt. But No in 
the sense that agents can have a much more diverse functionality like using specific tools, summarizing, or even followi
ng a particular style. In this blog, we look into how to set up these agents in a hierarchal manner just like running a 
small team of Authors, researchers, and supervisors.

[**How To Build Hierarchical Multi-Agent Systems?**](https://mediu
m.com/aiguys/how-to-build-hierarchical-multi-agent-systems-dc26b19201d2?sk=90958e39e1a28f5030872a90f8e3f3da)

**TextGrad
**. It is a powerful framework performing automatic “differentiation” via text. **It backpropagates textual feedback pro
vided by LLMs to improve individual components of a compound AI system.** In this framework, LLMs provide rich, general,
 natural language suggestions to optimize variables in computation graphs, ranging from code snippets to molecular struc
tures. TextGrad showed effectiveness and generality across various applications, from question-answering and molecule op
timization to radiotherapy treatment planning.

[**TextGrad: Improving Prompting Using AutoGrad**](https://medium.com/ai
guys/textgrad-controlling-llm-behavior-via-text-2a82e2073d10?sk=3633a9aa63b884c97469bce659265921)

The addition of RAG t
o LLMs was an excellent idea. It helped the LLMs to become more specific and individualized. Adding new components to an
y system leads to more interactions and its own sets of problems. Adding RAG to LLMs leads to several problems such as h
ow to retrieve the best content, what type of prompt to write, and many more.

In this blog, we are going to combine the
 **LangChain RAG with DSPy**. We deep dive into how to evaluate the RAG pipeline quantitatively using **RAGAs** and how 
to create a system where instead of manually tweaking prompts, we let the system figure out the best prompt.

[**How To 
Build LangChain RAG With DSPy?**](https://medium.com/aiguys/how-to-build-langchain-rag-with-dspy-ce9154fbafaa?sk=b41d104
05f84c767cf9cd6a58d1ebac0)

As the field of natural language processing (NLP) advances, the evaluation of large language
 models (LLMs) like GPT-4 becomes increasingly important and complex. Traditional metrics such as accuracy are often ina
dequate for assessing these models’ performance because they fail to capture the nuances of human language. In this arti
cle, we will explore why evaluating LLMs is challenging and discuss effective methods like BLEU and ROUGE for a more com
prehensive evaluation.

[**The Challenges of Evaluating Large Language Models**](https://medium.com/aiguys/the-challenge
s-of-evaluating-large-language-models-ec2eb834a349)

# AI Monthly News

# AI Act enters into force

On 1 August 2024, th
e European Artificial Intelligence Act (AI Act) enters into force. The Act aims to foster responsible artificial intelli
gence development and deployment in the EU. The AI Act introduces a uniform framework across all EU countries, based on 
a forward-looking definition of AI and a risk-based approach:

* **Minimal risk:** most AI systems such as spam filters 
and AI-enabled video games face no obligation under the AI Act, but companies can voluntarily adopt additional codes of 
conduct.
* **Specific transparency risk:** systems like chatbots must clearly inform users that they are interacting wit
h a machine, while certain AI-generated content must be labelled as such.
* **High risk:** high-risk AI systems such as 
AI-based medical software or AI systems used for recruitment must comply with strict requirements, including risk-mitiga
tion systems, high-quality of data sets, clear user information, human oversight, etc.
* **Unacceptable risk:** for exam
ple, AI systems that allow “social scoring” by governments or companies are considered a clear threat to people’s fundam
ental rights and are therefore banned.

**EU announcement:** [**Click here**](https://commission.europa.eu/news/ai-act-e
nters-force-2024-08-01_en)

https://preview.redd.it/nwyzfzgm4cmd1.png?width=828&format=png&auto=webp&s=c873db37ca0dadd5b
510bea70ac9f633b96aaea4

# California AI bill SB-1047 sparks fierce debate, Senator likens it to ‘Jets vs. Sharks’ feud


**Key Aspects of SB-1047:**

* Regulation Scope: Targets “frontier” AI models, defined by their immense computational t
raining requirements (over 10²⁶ operations) or significant financial investment (>$100 million).
* Compliance Requiremen
ts: Developers must implement safety protocols, including the ability to immediately shut down, cybersecurity measures, 
and risk assessments, before model deployment.
* Whistleblower Protections: Encourages reporting of non-compliance or ri
sks by offering protection against retaliation.
* Safety Incident Reporting: Mandates reporting AI safety incidents with
in 72 hours to a newly established Frontier Model Division.
* Certification: Developers need to certify compliance, pote
ntially under penalty of perjury in earlier drafts, though amendments might have altered this.

**Pros:**

* Safety Firs
t: Prioritizes the prevention of catastrophic harms by enforcing rigorous safety standards, potentially safeguarding aga
inst AI misuse or malfunction.
* Incentivizes Responsible Development: By setting high standards for AI model training, 
the company encourages developers to think critically about the implications of their creations.
* Public Trust: Enhance
s public confidence in AI by ensuring transparency and accountability in the development process.

**Cons:**

* Innovati
on Stagnation: Critics argue it might stifle innovation, especially in open-source AI, due to the high costs and regulat
ory burdens of compliance.
* Ambiguity: Some definitions and requirements might be too specific or broad, leading to leg
al challenges or unintended consequences.
* Global Competitiveness: There’s concern that such regulations could push AI 
development outside California or the U.S., benefiting other nations without similar restrictions.
* Implementation Chal
lenges: The practicalities of enforcing such regulations, especially the “positive safety determination,” could be compl
ex and contentious.

**News Article:** [**Click here**](https://www.thenation.com/article/society/sb-1047-ai-big-tech-fi
ght/)

**Open Letter:** [**Click here**](https://safesecureai.org/open-letter)

https://preview.redd.it/ib96d7nk4cmd1.pn
g?width=828&format=png&auto=webp&s=0ed5913b5dae72e203c8592393e469d9130ed689

# MORE OpenAI drama

OpenAI co-founder John
 Schulman has left the company to join rival AI startup Anthropic, while OpenAI president and co-founder Greg Brockman i
s taking an extended leave until the end of the year. Schulman, who played a key role in creating the AI-powered chatbot
 platform ChatGPT and led OpenAI’s alignment science efforts, stated his move was driven by a desire to focus more on AI
 alignment and hands-on technical work. Peter Deng, a product manager who joined OpenAI last year, has also left the com
pany. With these departures, only three of OpenAI’s original 11 founders remain: CEO Sam Altman, Brockman, and Wojciech 
Zaremba, lead of language and code generation.

**News Article:** [**Click here**](https://techcrunch.com/2024/08/05/ope
nai-co-founder-leaves-for-anthropic/)

https://preview.redd.it/0vdjc18j4cmd1.png?width=828&format=png&auto=webp&s=e9de60
4c26aed3e47b50df3bdf114ef61f967080

# Apple and Nvidia may invest in OpenAI

Apple, which is planning to integrate ChatG
PT into iOS, is in talks to invest. Soon after, [*Bloomberg* also](https://www.bloomberg.com/news/articles/2024-08-29/nv
idia-has-held-discussions-about-joining-openai-s-funding-round?srnd=homepage-americas) reported that Apple is in talks b
ut added that Nvidia “has discussed” joining the funding round as well. The round is reportedly being led by Thrive Capi
tal and would value OpenAI at more than $100 billion.

**News Article:** [**Click here**](https://www.theverge.com/2024/
8/29/24231626/apple-nvidia-openai-invest-microsoft)

https://preview.redd.it/ude6jguh4cmd1.png?width=828&format=png&auto
=webp&s=3603cbca0dbb1be3e6d0efcf06c3a698428bbdd6

# Editor’s Special

* The AI Bubble: Will It Burst, and What Comes Aft
er?: [**Click here**](https://www.youtube.com/watch?v=91SK90SahHc&t=317s)
* Eric Schmidt Full Controversial Interview on
 AI Revolution (Former Google CEO): [**Click here**](https://www.youtube.com/watch?v=mKVFNg3DEng)
* AI isn’t gonna keep 
improving [**Click here**](https://www.youtube.com/watch?v=Y8Ym7hMR100)
* General Intelligence: Define it, measure it, b
uild it: [**Click here**](https://www.youtube.com/watch?v=nL9jEy99Nh0)
```
---

     
 
deeplearning -  [ Creating a project on NLP ](https://www.reddit.com/r/deeplearning/comments/1ey2e85/creating_a_project_on_nlp/) , 2024-09-17-0910
```
So me and my friend completed the ML and DL specialization by AndrewNg, and were just gonna get started on a project. We
 decided to make a academic assistant. So basically what this does is a user can upload a PDF,text file or any other sup
ported media and the can ask questions related to it's contents. The main objective being making learning quick given la
rger documents.

The pipeline we decided is pretty standard for such a project.

1. Split the text into chunks
2. Genera
te embeddings of the chunks
3. Store the chunks in a vector DB
4. Find the top K similar chunks to the query 
5. Retriev
e context and feed it into a LLM for an answer.

So I looked up for a library and framework to use and decided on langch
ain. We haven't decided on an LLM yet but want to run it locally so no OpenAI please. 

Since this is gonna be out first
 AI project confidence is low. I would really appreciate any heads up on the issues we may face, any suggestions on libr
aries,frameworks or models will be really helpful as well. 

Appreciate any resourceful comment 😊
```
---

     
