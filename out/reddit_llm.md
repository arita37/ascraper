 
all -  [ Best AI Image generator?  ](https://www.reddit.com/r/LangChain/comments/1gp4waz/best_ai_image_generator/) , 2024-11-12-0912
```
Hello everyone, I hope you guys are doing great. 

I am searching for best / very good / one of the best AI image genera
tor. 

Please Advise 

```
---

     
 
all -  [ Snippet showing integration of Langgraph with Voicekit ](/r/AI_Agents/comments/1goh8c1/snippet_showing_integration_of_langgraph_with/) , 2024-11-12-0912
```

```
---

     
 
all -  [ [3 YoE] Data Scientist with masters degree looking to get resume reviewed to land better opportuniti ](https://www.reddit.com/r/EngineeringResumes/comments/1gp0lqi/3_yoe_data_scientist_with_masters_degree_looking/) , 2024-11-12-0912
```
Hi everyone, I have 3 YOE and 8 MOE of relevant internship (i say relevant cuz my other internships/part-time jobs were 
irrelevant), I am currently working as DS at a startup which does not pay too well (that's why the job switch). I am loo
king for a Data Scientist role so please give your suggestions accordingly.

I am looking for honest opinions on how I c
an improve my resume, what I should include or remove, the order of sections, any other sections that I should insert, s
tructure and wordings of present structure etc. This resume did help me get interviews at Intuit, The Washington Post, A
WS and Meta, but lately I have not been able to grab any calls.

Your help is deeply appreciated and I look forward to t
he roast!

https://preview.redd.it/pg8ii8y2pb0e1.png?width=5100&format=png&auto=webp&s=265ab3ee845f27cb6db7601c1de768fb1
e84bf60


```
---

     
 
all -  [ Roast my Resume!!!! ](https://www.reddit.com/r/leetcode/comments/1goxv1m/roast_my_resume/) , 2024-11-12-0912
```
Hi everyone, in today's episode of roast my resume, I present to you my resume. I have 3 YOE and 8 MOE of relevant inter
nship (i say relevant cuz my other internships/part-time jobs were irrelevant), I am currently working as DS at a startu
p which does not pay too well (that's why the job switch). I am looking for a Data Scientist role so please give your su
ggestions accordingly.

I am looking for honest opinions on how I can improve my resume, what I should include or remove
, the order of sections, any other sections that I should insert, structure and wordings of present structure etc. This 
resume did help me get interviews at Intuit, The Washington Post, AWS and Meta, but lately I have not been able to grab 
any calls.

Your help is deeply appreciated and I look forward to the roast!

https://preview.redd.it/qoc9ya0s5b0e1.jpg?
width=2550&format=pjpg&auto=webp&s=41c1b5283493123e5ca3dfa0e1a4af0d8d9e6527


```
---

     
 
all -  [ Chain approach for Langchain is not able to handle longer prompts ](https://www.reddit.com/r/LangChain/comments/1gos7xm/chain_approach_for_langchain_is_not_able_to/) , 2024-11-12-0912
```
I have two datasets I need to compare and give an output for. So for example, if dataset 1 has a list of items, I want i
t to compare across dataset 2 and return a mapping like this.

|Dataset 1|Dataset 2|
|:-|:-|
|Germany|Deustchland|
|Turk
ey|Turkiye|

I'm not actually using countries, but it's a bit like a fuzzy match of sorts.

I am currently testing out c
hains in langchain and using dataset 1 as the input data and then adding a couple of items from dataset 2 in the query. 
It works fine for a couple of items, but does not work for a larger number. Hence, I wanted to look for ways where I cou
ld generate an output without exceeding the prompt limit and getting accurate output.

Using map\_reduce or refine gives
 me this error  
**ValidationError**: 1 validation error for RefineDocumentsChain prompt ¬†Extra inputs are not permitted
 \[type=extra\_forbidden, input\_value=PromptTemplate(input\_vari...IZED TESTS: {question}'), input\_type=PromptTemplate
\]
```
---

     
 
all -  [ Can Langgraph state hold binary data? ](https://www.reddit.com/r/LangChain/comments/1gors2y/can_langgraph_state_hold_binary_data/) , 2024-11-12-0912
```
Starting to use langgraph platform a bit now and it seems easier just to process EVERYTHING through my graph instead of 
using two hosting options (one for the graph and another for my other endpoints). Which makes me wonder can I keep pdf's
 in my graph state (or any binary data) to then send to my front end?

I could probably encode it in base64, but yeah. 
```
---

     
 
all -  [ Chatgpt like conversational vision model (Instructions Video Included) ](https://www.reddit.com/r/LangChain/comments/1gor4xd/chatgpt_like_conversational_vision_model/) , 2024-11-12-0912
```
[https://www.youtube.com/watch?v=sdulVogM2aQ](https://www.youtube.com/watch?v=sdulVogM2aQ)

[https://github.com/agituts/
ollama-vision-model-enhanced/](https://github.com/agituts/ollama-vision-model-enhanced/)

# Basic Operations:

* Upload 
an Image: Use the file uploader to select and upload an image (PNG, JPG, or JPEG).
* Add Context (Optional): In the side
bar under 'Conversation Management', you can add any relevant context for the conversation.
* Enter Prompts: Use the cha
t input at the bottom of the app to ask questions or provide prompts related to the uploaded image.
* View Responses: Th
e app will display the AI assistant's responses based on the image analysis and your prompts.

# Conversation Management


* Save Conversations: Conversations are saved automatically and can be managed from the sidebar under 'Previous Conver
sations'.
* Load Conversations: Load previous conversations by clicking the folder icon (üìÇ) next to the conversation tit
le.
* Edit Titles: Edit conversation titles by clicking the pencil icon (‚úèÔ∏è) and saving your changes.
* Delete Conversat
ions: Delete individual conversations using the trash icon (üóëÔ∏è) or delete all conversations using the 'Delete All Conver
sations' button.
```
---

     
 
all -  [ How to Upgrade Related Content Chunks to Be Dynamic (Like in RAG-Powered Websites) ](https://www.reddit.com/r/LangChain/comments/1goqwpt/how_to_upgrade_related_content_chunks_to_be/) , 2024-11-12-0912
```
Hello everyone.

I'm working on a project that involves dynamically displaying 'related content' chunks on each page, si
milar to what is seen on popular Retrieval-Augmented Generation (RAG) websites. These sites are excellent at suggesting 
related or supplementary content based on the current page's content and user preferences. I'm looking for advice on how
 to implement a similar feature effectively.

https://preview.redd.it/mmlzl2pqz90e1.png?width=2880&format=png&auto=webp&
s=f826d34d48d519982e433e6038bddf569dda9945

https://preview.redd.it/n5a5lxcrz90e1.png?width=2880&format=png&auto=webp&s=
70f965d0ab99b0acfe37919821f9d4d9f3cc6484

https://preview.redd.it/sp073xcsz90e1.png?width=2880&format=png&auto=webp&s=a8
158f9811c0efdd41de666ff73d1c2a3effb70a


```
---

     
 
all -  [ A Personal NotebookLM and Perplexity-like AI Assistant with privacy. ](https://www.reddit.com/r/LangChain/comments/1goq5ud/a_personal_notebooklm_and_perplexitylike_ai/) , 2024-11-12-0912
```
Hi everyone for the last month or two I have been trying to build a hybrid of NotebookLM and Perplexity with better inte
gration with browsers as well.

So here is my little attempt to make something.

https://reddit.com/link/1goq5ud/video/3
6vrje0ld90e1/player

SurfSense :

While tools like NotebookLM and Perplexity are impressive and highly effective for con
ducting research on any topic, imagine having both at your disposal with complete privacy control. That's exactly what S
urfSense offers. With SurfSense, you can create your own knowledge base for research, similar to NotebookLM, or easily r
esearch the web just like Perplexity. SurfSense also includes an effective cross-browser extension to directly save dyna
mic content bookmarks, such as social media chats, calendar invites, important emails, tutorials, recipes, and more to y
our SurfSense knowledge base. Now, you‚Äôll never forget anything and can easily research everything.

Bugs are to be expe
cted but I hope you guys give it a go.

GitHub Link:¬†[https://github.com/MODSetter/SurfSense](https://github.com/MODSett
er/SurfSense)
```
---

     
 
all -  [ Help with LangChain Agent for Querying Parquet Files ](https://www.reddit.com/r/LangChain/comments/1gopx5k/help_with_langchain_agent_for_querying_parquet/) , 2024-11-12-0912
```
Hey everyone,

I‚Äôm new to LangChain and building an agent with text-to-SQL capabilities. My goal is to query Parquet fil
es stored in Azure Data Lake, but right now, I‚Äôm testing it on a local folder of Parquet files in my machine. Most resou
rces I‚Äôve found focus on databases, not Parquet.

Anyone know of resources or have advice on making this work?

Thanks!
```
---

     
 
all -  [ Expense extractor Gmail plugin using Llama3.2 that runs locally and for free ](https://www.reddit.com/r/LangChain/comments/1gol8v3/expense_extractor_gmail_plugin_using_llama32_that/) , 2024-11-12-0912
```
https://reddit.com/link/1gol8v3/video/mz8bd3fon70e1/player


```
---

     
 
all -  [ Snippet showing integration of Langgraph with Voicekit ](https://www.reddit.com/r/LangChain/comments/1goh7gj/snippet_showing_integration_of_langgraph_with/) , 2024-11-12-0912
```
I asked this help a few days back. - [https://www.reddit.com/r/LangChain/comments/1gmje1r/help\_with\_voice\_agents\_liv
ekit/](https://www.reddit.com/r/LangChain/comments/1gmje1r/help_with_voice_agents_livekit/)

Since then, I've made it wo
rk. Sharing it for the benefit of the community. 

\## Here's how I've integrated Langgraph and Voice Kit.

\### Context
: 

I've a graph to execute a complex LLM flow. I had a requirement from a client to convert that into voice. So decided
 to use VoiceKit.

\### Problem

The problem I faced is that Voicekit supports a single LLM by default. I did not know h
ow to integrate my entire graph as an llm within that.   


\### Solution

I had to create a custom class and integrate 
it. 

\### Code

    class LangGraphLLM(llm.LLM):
        def __init__(
            self,
            *,
            par
am1: str,
            param2: str | None = None,
            param3: bool = False,
            api_url: str = '<api url>
',  # Update to your actual endpoint
        ) -> None:
            super().__init__()
            self.param1 = param1

            self.param2 = param2
            self.param3 = param3
            self.api_url = api_url
    
        def ch
at(
            self,
            *,
            chat_ctx: ChatContext,
            fnc_ctx: llm.FunctionContext | None 
= None,
            temperature: float | None = None,
            n: int | None = 1,
            parallel_tool_calls: bo
ol | None = None,
        ) -> 'LangGraphLLMStream':
            if fnc_ctx is not None:
                logger.warning(
'fnc_ctx is currently not supported with LangGraphLLM')
    
            return LangGraphLLMStream(
                self
,
                param1=self.param1,
                param3=self.param3,
                api_url=self.api_url,
        
        chat_ctx=chat_ctx,
            )
    
    
    class LangGraphLLMStream(llm.LLMStream):
        def __init__(
  
          self,
            llm: LangGraphLLM,
            *,
            param1: str,
            param3: bool,
       
     api_url: str,
            chat_ctx: ChatContext,
        ) -> None:
            super().__init__(llm, chat_ctx=chat
_ctx, fnc_ctx=None)
            param1 = 'x'  
            param2 = 'y'
            self.param1 = param1
            sel
f.param3 = param3
            self.api_url = api_url
            self._llm = llm  # Reference to the parent LLM instance

    
        async def _main_task(self) -> None:
            chat_ctx = self._chat_ctx.copy()
            user_msg = ch
at_ctx.messages.pop()
    
            if user_msg.role != 'user':
                raise ValueError('The last message in
 the chat context must be from the user')
    
            assert isinstance(user_msg.content, str), 'User message conte
nt must be a string'
    
            try:
                # Build the param2 body
                body = self._build_bo
dy(chat_ctx, user_msg)
    
                # Call the API
                response, param2 = await self._call_api(body)

    
                # Update param2 if changed
                if param2:
                    self._llm.param2 = param
2
    
                # Send the response as a single chunk
                self._event_ch.send_nowait(
               
     ChatChunk(
                        request_id='',
                        choices=[
                            Cho
ice(
                                delta=ChoiceDelta(
                                    role='assistant',
          
                          content=response,
                                )
                            )
            
            ],
                    )
                )
            except Exception as e:
                logger.error(f
'Error during API call: {e}')
                raise APIConnectionError() from e
    
        def _build_body(self, chat_
ctx: ChatContext, user_msg) -> str:
            '''
            Helper method to build the param2 body from the chat con
text and user message.
            '''
            messages = chat_ctx.messages + [user_msg]
            body = ''
     
       for msg in messages:
                role = msg.role
                content = msg.content
                if rol
e == 'system':
                    body += f'System: {content}\n'
                elif role == 'user':
                 
   body += f'User: {content}\n'
                elif role == 'assistant':
                    body += f'Assistant: {cont
ent}\n'
            return body.strip()
    
        async def _call_api(self, body: str) -> tuple[str, str | None]:
   
         '''
            Calls the API and returns the response and updated param2.
            '''
            logger.i
nfo('Calling API...')
    
            payload = {
                'param1': self.param1,
                'param2': self
._llm.param2,
                'param3': self.param3,
                'body': body,
            }
    
            async 
with aiohttp.ClientSession() as session:
                try:
                    async with session.post(self.api_url, 
json=payload) as response:
                        response_data = await response.json()
                        logger.
info('Received response from API.')
                        logger.info(response_data)
                        return re
sponse_data['ai_response'], response_data.get('param2')
                except Exception as e:
                    logge
r.error(f'Error calling API: {e}')
                    return 'Error in API', None
    
    

    
    # Initialize your
 custom LLM class with API parameters
        custom_llm = LangGraphLLM(
            param1=param1,
            param2=N
one,
            param3=False, 
            api_url='<api_url>',  # Update to your actual endpoint
        )


```
---

     
 
all -  [ Difficulty of using LLMs with LangChain ](https://www.reddit.com/r/LLMs/comments/1gog2q9/difficulty_of_using_llms_with_langchain/) , 2024-11-12-0912
```
So I‚Äôm new to the LLM / Bedrock world (and this sub). I see so many training courses about using LangChain with Bedrock.
 But the syntax of using LangChain / Langgraph feels way more complex than it needs to be. Actual Bedrock API feels simp
ler. 

What are other folks‚Äô experience? Have any of y‚Äôall preferred to just use Bedrock without LangChain?

If not, any
 tips on how to get used to LangChain (other than reading docs)?
```
---

     
 
all -  [ Fully local and free Gmail assistant ](https://v.redd.it/hcggq8pw550e1) , 2024-11-12-0912
```
Gemini for Gmail is great but it's expensive. So I decided to build one for myself this weekend - A smart gmail assistan
t that runs locally and completely free, powered by llama-3.2-3b-instruct.

Stack:
- local LLM server running llama-3.2-
3b-instruct from LM studio with Apple MLX
- Gmail plugin built by Claude

Took less than 30min to get here. Plan to add 
a local RAG over all my emails and some custom features.
```
---

     
 
all -  [ glassBead Blog: new LangChain-oriented technical blog ](https://www.reddit.com/r/LangChain/comments/1go9xpb/glassbead_blog_new_langchainoriented_technical/) , 2024-11-12-0912
```
hey everybody,

  
i just published the first of a long planned series of blog posts detailing things that I learn while
 building w/ LangGraph at relative length. this is my first time ever attempting to do a technical blog, so i'd welcome 
any and all tips on how to do these in a way that's at least potentially helpful to someone reading. thanks in advance i
f you've got feedback!

[https://glassbead-tc.medium.com/the-glassbead-blog-gbb-atrisdocs001-langgraphstatemgmt-bf322837
d00c](https://glassbead-tc.medium.com/the-glassbead-blog-gbb-atrisdocs001-langgraphstatemgmt-bf322837d00c)
```
---

     
 
all -  [ Weekly Linkedin RAG Highlights: Uber‚Äôs SQL Hack, New Courses, and Key Updates ](https://www.reddit.com/r/Rag/comments/1go6vit/weekly_linkedin_rag_highlights_ubers_sql_hack_new/) , 2024-11-12-0912
```
LinkedIn has become one of my go-to spots for staying up-to-date with RAG, so I figured I'd share a quick digest of some
 top posts from last week that caught my eye:

1. [**Uber‚Äôs RAG-Powered Text-to-SQL Saves 140,000 Hours**](https://www.l
inkedin.com/posts/sarthakrastogi_ai-llms-rag-activity-7250479007270359040-umSq/?utm_source=share&utm_medium=member_deskt
op) (2332 likes) ‚Äì Uber developed QueryGPT, a custom system that uses RAG to cut SQL query writing time from 10 minutes 
to 3, saving thousands of hours annually. It uses multiple agents to optimize every step of the process, from intent rec
ognition to table selection.
2. [**LangChain‚Äôs ‚ÄúRAG from Scratch‚Äù Playlist**](https://www.linkedin.com/posts/areganti_ti
l-langchain-has-a-super-beginner-friendly-activity-7255042856535408641-iKdf/?utm_source=share&utm_medium=member_desktop)
 (1210 likes) ‚Äì LangChain has a new YouTube series called 'RAG from Scratch' that‚Äôs beginner-friendly and covers advance
d topics like RAPTOR and query reform. Quick watch‚Äîunder two hours total.
3. [**Curated RAG Resource List**](https://www
.linkedin.com/posts/reyhanmerekar_rag-is-one-of-the-most-important-skillsets-activity-7253015624300343296-HOFi/?utm_sour
ce=share&utm_medium=member_desktop) (957 likes) ‚Äì A great rundown of the best courses and GitHub repos for anyone diving
 into RAG. Includes LangChain, [DeepLearning.AI](http://DeepLearning.AI) courses, and some solid repos to get hands-on.

4. [**Free RAG++ Course by W&B, Cohere, and Weaviate**](https://www.linkedin.com/posts/areganti_i-spent-some-time-going-
through-the-free-activity-7252506115253374977-ZwE2/?utm_source=share&utm_medium=member_desktop) (588 likes) ‚Äì This cours
e covers advanced RAG topics with a production focus, emphasizing evaluation, data ingestion, and efficiency improvement
s.
5. [**Anthropic on Contextual Retrieval**](https://www.linkedin.com/posts/areganti_anthropics-latest-blog-on-contextu
al-activity-7247953742363258883-7SfR/?utm_source=share&utm_medium=member_desktop) (528 likes) ‚Äì Anthropic‚Äôs latest blog 
discusses a new way to enhance RAG retrieval by adding contextual information to embeddings, with a reported 70% boost i
n performance.
6. [**Query Rewrite RAG with LangFlow**](https://www.linkedin.com/posts/tom-yeh_query-rewrite-rag-by-hand
-langflow-activity-7248326712973819904-2L3F/?utm_source=share&utm_medium=member_desktop) (760 likes) ‚Äì Tom Yeh is sharin
g exercises to teach advanced RAG concepts with LangFlow, providing visuals and exercises to bridge theory with practice
.
7. [**Mnemosyne: Personalized Search Agent for Medium**](https://www.linkedin.com/posts/akshaybahadur21_raghav-patnech
a-and-i-built-an-intelligent-activity-7254402851018321921-b2KS/?utm_source=share&utm_medium=member_desktop) (164 likes) 
‚Äì Two devs shared their experience building a conversational search agent for Medium, using RAG methods like answer grad
ing and chunking to improve relevance.
8. [**Quick Video on RAG Basics**](https://www.linkedin.com/posts/corneliusa_in-t
his-short-video-i-explain-the-concept-activity-7251629726425915392-GKoy/?utm_source=share&utm_medium=member_desktop) ‚Äì A
 short intro video breaking down the core concepts of RAG for those new to the field. Great for quick insights!

Got any
 interesting RAG news from last week? Drop them in the comments! I'd love to hear what you‚Äôre following.

Was this helpf
ul? Should I keep doing these weekly digests? Hit like if you want more, and leave a comment with your thoughts!
```
---

     
 
all -  [ What sort of job titles and roles should I look for? ](https://www.reddit.com/r/datascience/comments/1go59j5/what_sort_of_job_titles_and_roles_should_i_look/) , 2024-11-12-0912
```
Hi, I've been working as an analyst for a retail company for a few years, but it's pretty basic and mostly focused on re
porting, dashboards, etc, so I'm looking for more roles with a heavier data science and computation focus. But I'm getti
ng overwhelmed and confused about what sorts of roles to look for.

A quick google search for 'types of roles in data sc
ience' and you'll find dozens of pages filled with SEO-driven buzzwords (possibly AI-generated), but these only give the
 most surface-level and generic descriptions of common titles like data analyst, data scientist, data engineer, etc. Thi
s isn't really what I'm looking for though lol. I know what these are. Also, so many roles today seem to just be focused
 on shoving the latest LLM stack (RAG, langchain, etc) into the problem even if the use case for the company is slim or 
marginal at best. This isn't really what I'm interested in cause I like operations data science more.

What I'm looking 
for is a more specific, tailored advice relevant to specific types of industries/specializations. For example

* I reall
y like building models that heavily rely on functional programming, and may make use of very niche or specific libraries
 depending on the use case. I enjoy Project Euler type problems for example
* I understand ML is a core part of data sci
ence, but I enjoy projects where ML isn't exclusive to the problem. A lot of other models can be solved by more function
al programming and tailored computational science type work
* I guess my background right now is mostly focused on busin
ess/operations/economics, so I don't have a specific engineering or hard science background, but I'm open to any area th
at invovles applied mathematics.

I would appreciate any and all advice. As specific or general as possible. But prefera
bly something specific.
```
---

     
 
all -  [ Chatgpt like interface to chat with images using llama3.2-vision ](https://www.reddit.com/r/LangChain/comments/1go51b3/chatgpt_like_interface_to_chat_with_images_using/) , 2024-11-12-0912
```
This Streamlit application allows users to upload images and engage in interactive conversations about them using the Ol
lama Vision Model (llama3.2-vision). The app provides a user-friendly interface for image analysis, combining visual inp
uts with natural language processing to deliver detailed and context-aware responses.

https://github.com/agituts/ollama
-vision-model-enhanced
```
---

     
 
all -  [ Creating LangGraph from JSON/YAML instead of code ](https://www.reddit.com/r/LangChain/comments/1go2btv/creating_langgraph_from_jsonyaml_instead_of_code/) , 2024-11-12-0912
```
I figured it might be useful to build graphs using declarative syntax instead of imperative one for a couple of usecases
:

* Tools trying to build low-code builders/managers for LangGraph.
* Tools trying to build graphs dynamically based on
 a usecase

and more...

I went through the documentation and landed [here](https://python.langchain.com/v0.2/api_refere
nce/core/runnables/langchain_core.runnables.graph.Graph.html#langchain_core.runnables.graph.Graph.to_json).

and noticed
 that there is a \`to\_json()\` feature. It only seems fitting that there be an inverse.

So I attempted to make a build
er for the same that consumes JSON/YAML files and creates a compiled graph.

[https://github.com/esxr/declarative-builde
r-for-langgraph](https://github.com/esxr/declarative-builder-for-langgraph)

Is this a good approach? Are there existing
 libraries to do the same? (I know that there might be an asymmetry that might require explicit instructions to make it 
invertible but I'm working on the edge cases)
```
---

     
 
all -  [ Building LangGraphs from JSON file ](https://www.reddit.com/r/LangGraph/comments/1go2b2u/building_langgraphs_from_json_file/) , 2024-11-12-0912
```
I figured it might be useful to build graphs using declarative syntax instead of imperative one for a couple of usecases
:

* Tools trying to build low-code builders/managers for LangGraph.
* Tools trying to build graphs dynamically based on
 a usecase

and more...

I went through the documentation and landed [here](https://python.langchain.com/v0.2/api_refere
nce/core/runnables/langchain_core.runnables.graph.Graph.html#langchain_core.runnables.graph.Graph.to_json).

and noticed
 that there is a \`to\_json()\` feature. It only seems fitting that there be an inverse.  
  
So I attempted to make a b
uilder for the same that consumes JSON/YAML files and creates a compiled graph.   
  
[https://github.com/esxr/declarati
ve-builder-for-langgraph](https://github.com/esxr/declarative-builder-for-langgraph)  


Is this a good approach? Are th
ere existing libraries to do the same? (I know that there might be an asymMetry that might require explicit instructions
 to make it invertible but I'm working on the edge cases)


```
---

     
 
all -  [ How to mimic ChatGPT Search? ](https://www.reddit.com/r/LangChain/comments/1go1mxt/how_to_mimic_chatgpt_search/) , 2024-11-12-0912
```
I have been pretty impressed with openai's most recent chat GPT feature that allows for real-time web information retrie
val.

Can anyone recommend a pipeline/system that can mimic this using agents/RAG?

Thank you
```
---

     
 
all -  [ LangGraph vs Autogen l ](https://www.reddit.com/r/LangChain/comments/1gnxmnb/langgraph_vs_autogen_l/) , 2024-11-12-0912
```
Currently I am working on a AI assistance project where I am using a langGraph Hierarchical multi-agnet so that it doesn
't hallucinate much and easy to expand. For some reason after certain point I am feeling difficulty to mange the project
 like I know official doc is difficult and they made task overly complicated. So now I was thinking to switch to differe
nt multi-agnet framework called AutoGen. So what are your thoughts on it? Should I try autogen Or stick to langgraph? 
```
---

     
 
all -  [ Rate My Resume ](https://www.reddit.com/gallery/1gnxbmb) , 2024-11-12-0912
```
I'm a Machine Learning Engineer with over 3 years of experience. Ps: would really appreciate some tips on how I can alig
n the skills section properly.
```
---

     
 
all -  [ Help with Finding Similar Stories Across PDFs Using AI (RAG Pipeline or Another Method?) ](https://www.reddit.com/r/LangChain/comments/1gnwed5/help_with_finding_similar_stories_across_pdfs/) , 2024-11-12-0912
```
Hey everyone!

I have a collection of PDFs, with each file containing a single story, news article, or blog. I want to b
uild something that, given a new story (like one about a mob attack), can find the most similar story from my PDF collec
tion and point out the specific parts or events that match up.

# My Ideas So Far

I was thinking about using a¬†**Retrie
val-Augmented Generation (RAG)**¬†pipeline to pull out the closest matches, but I‚Äôm not totally sure how best to approach
 this. I have a few questions I could really use some help with:

1. **Pipeline Design**:
   * What‚Äôs the best way to se
t up a RAG pipeline for this? How do I make sure it finds similar stories AND highlights specific parts of the stories t
hat match up?
2. **Implementation Ideas**:
   * Any advice on which embeddings or models I should use to compare the sto
ries? Should I use sentence embeddings, event extraction, or something else to get accurate matches?
   * If my stories 
have unique language, is there a way to adapt or fine-tune a model for this?
3. **Alternative Approaches**:
   * Would i
t be simpler to just loop through each PDF and compare it with the new story using a language model, or should I stick w
ith RAG or some other retrieval method?
4. **Any Similar Applications?**
   * Are there any tools or apps already out th
ere that do something like this? Even something close would be a big help as a reference.

Trying to find a story in my 
PDFs that‚Äôs most similar to a new one, and want advice on using RAG or any other efficient way to get similarity insight
s. Any help, suggestions, or references to similar projects would be much appreciated!

Thanks in advance for any guidan
ce!
```
---

     
 
all -  [ Need help with my agent being able to query my tables ](https://www.reddit.com/r/LangChain/comments/1gntwgu/need_help_with_my_agent_being_able_to_query_my/) , 2024-11-12-0912
```
Hi all,  
Recently I started work on a project and for that I have worked on connecting a database on SQL server and ask
ing the db questions and converting them to queries. While the connection shows all the tables I have in server, the age
nt is unable to find them. Somehow it seems that the agent works fine with dbo. tables but not other schemas. Can someon
e help me out. I don't want to change the schema of my project tables!
```
---

     
 
all -  [ Build AI agents from prompts (open-source) ](https://www.reddit.com/r/LLMDevs/comments/1gnsmj9/build_ai_agents_from_prompts_opensource/) , 2024-11-12-0912
```
Hey guys, I created a framework to build¬†[agentic systems called GenSphere](https://github.com/octopus2023-inc/gensphere
)¬†which allows you to create agentic systems from YAML configuration files. Now, I'm experimenting generating these YAML
 files with LLMs so I don't even have to code in my own framework anymore. The results look quite interesting, its not f
ully complete yet, but promising.

For instance, I asked to create an agentic workflow for the following prompt:

    Yo
ur task is to generate script for 10 YouTube videos, about 5 minutes long each.
    Our aim is to generate content for Y
ouTube in an ethical way, while also ensuring we will go viral.
    You should discover which are the topics with the hi
ghest chance of going viral today by searching the web.
    Divide this search into multiple granular steps to get the b
est out of it. You can use Tavily and Firecrawl_scrape
    to search the web and scrape URL contents, respectively. Then
 you should think about how to present these topics in order to make the video go viral.
    Your script should contain 
detailed text (which will be passed to a text-to-speech model for voiceover),
    as well as visual elements which will 
be passed to as prompts to image AI models like MidJourney.
    You have full autonomy to create highly viral videos fol
lowing the guidelines above. 
    Be creative and make sure you have a winning strategy.

I got back a full workflow wit
h 12 nodes, multiple rounds of searching and scraping the web, LLM API calls, (attaching tools and using structured outp
uts autonomously in some of the nodes) and function calls.



https://preview.redd.it/9rfl5fa7500e1.png?width=802&format
=png&auto=webp&s=f2bebbd1a50afd87e22fb42b4f5bed19d4681f8d

I then just runned and got back a pretty decent result, witho
ut any bugs:

`**Host:**`  
`Hey everyone, [Host Name] here! TikTok has been the breeding ground for creativity, and 202
4 is no exception. From mind-blowing dances to hilarious pranks, let's explore the challenges that have taken the platfo
rm by storm this year! Ready? Let's go!`

`**[UPBEAT TRANSITION SOUND]**`

`**[Visual: Title Card: 'Challenge #1: The Ti
me Warp Glow Up']**`

`**Narrator (VOICEOVER):**`  
`First up, we have the 'Time Warp Glow Up'! This challenge combines 
creativity and nostalgia‚Äîtwo key ingredients for viral success.`

`**[Visual: Split screen of before and after transform
ations, with captions: 'Time Warp Glow Up'. Clips show users transforming their appearance with clever editing and glow-
up transitions.]**`

and so on (the actual output is pretty big, and would generate around \~50min of content indeed).


So, we basically went from prompt to agent in just a few minutes, not even having to code anything. For some examples I 
tried, the agent makes some mistake and the code doesn't run, but then its super easy to debug because all nodes are eit
her LLM API calls or function calls. At the very least you can iterate a lot faster, and avoid having to code on cumbers
ome frameworks.

There are lots of things to do next. Would be awesome if the agent could scrape langchain and composio 
documentation and RAG over them to define which tool to use from a giant toolkit. If you want to play around with this, 
pls reach out! You can¬†[check this notebook to run the example above yourself](https://github.com/octopus2023-inc/gensph
ere/blob/main/examples/agentic_workflows_from_prompts.ipynb)¬†(you need to have access to o1-preview API from openAI).
```
---

     
 
all -  [ Build AI agents from prompts (open-source) ](https://www.reddit.com/r/LangChain/comments/1gnskme/build_ai_agents_from_prompts_opensource/) , 2024-11-12-0912
```
Hey guys, I created a framework to build¬†[agentic systems called GenSphere](https://github.com/octopus2023-inc/gensphere
)¬†which allows you to create agentic systems from YAML configuration files. Now, I'm experimenting generating these YAML
 files with LLMs so I don't even have to code in my own framework anymore. The results look quite interesting, its not f
ully complete yet, but promising.

For instance, I asked to create an agentic workflow for the following prompt:

    Yo
ur task is to generate script for 10 YouTube videos, about 5 minutes long each.
    Our aim is to generate content for Y
ouTube in an ethical way, while also ensuring we will go viral.
    You should discover which are the topics with the hi
ghest chance of going viral today by searching the web.
    Divide this search into multiple granular steps to get the b
est out of it. You can use Tavily and Firecrawl_scrape
    to search the web and scrape URL contents, respectively. Then
 you should think about how to present these topics in order to make the video go viral.
    Your script should contain 
detailed text (which will be passed to a text-to-speech model for voiceover),
    as well as visual elements which will 
be passed to as prompts to image AI models like MidJourney.
    You have full autonomy to create highly viral videos fol
lowing the guidelines above. 
    Be creative and make sure you have a winning strategy.

I got back a full workflow wit
h 12 nodes, multiple rounds of searching and scraping the web, LLM API calls, (attaching tools and using structured outp
uts autonomously in some of the nodes) and function calls.

https://preview.redd.it/m42drlmq400e1.png?width=802&format=p
ng&auto=webp&s=803321de0929dd440c665f28bcbce54f82f15cad

I then just runned and got back a pretty decent result, without
 any bugs:

`**Host:**`  
`Hey everyone, [Host Name] here! TikTok has been the breeding ground for creativity, and 2024 
is no exception. From mind-blowing dances to hilarious pranks, let's explore the challenges that have taken the platform
 by storm this year! Ready? Let's go!`

`**[UPBEAT TRANSITION SOUND]**`

`**[Visual: Title Card: 'Challenge #1: The Time
 Warp Glow Up']**`

`**Narrator (VOICEOVER):**`  
`First up, we have the 'Time Warp Glow Up'! This challenge combines cr
eativity and nostalgia‚Äîtwo key ingredients for viral success.`

`**[Visual: Split screen of before and after transformat
ions, with captions: 'Time Warp Glow Up'. Clips show users transforming their appearance with clever editing and glow-up
 transitions.]**`

and so on (the actual output is pretty big, and would generate around \~50min of content indeed).

So
, we basically went from prompt to agent in just a few minutes, not even having to code anything. For some examples I tr
ied, the agent makes some mistake and the code doesn't run, but then its super easy to debug because all nodes are eithe
r LLM API calls or function calls. At the very least you can iterate a lot faster, and avoid having to code on cumbersom
e frameworks.

There are lots of things to do next. Would be awesome if the agent could scrape langchain and composio do
cumentation and RAG over them to define which tool to use from a giant toolkit. If you want to play around with this, pl
s reach out! You can¬†[check this notebook to run the example above yourself](https://github.com/octopus2023-inc/genspher
e/blob/main/examples/agentic_workflows_from_prompts.ipynb)¬†(you need to have access to o1-preview API from openAI).
```
---

     
 
all -  [ Build AI agents from prompts (open-source) ](https://www.reddit.com/r/AI_Agents/comments/1gnsi2s/build_ai_agents_from_prompts_opensource/) , 2024-11-12-0912
```
Hey guys, I created a framework to build [agentic systems called GenSphere](https://github.com/octopus2023-inc/gensphere
) which allows you to create agentic systems from YAML configuration files.  Now, I'm experimenting generating these YAM
L files with LLMs so I don't even have to code in my own framework anymore. The results look quite interesting, its not 
fully complete yet, but promising. 

  
For instance, I asked to create an agentic workflow for the following prompt:  



    Your task is to generate script for 10 YouTube videos, about 5 minutes long each.
    Our aim is to generate conte
nt for YouTube in an ethical way, while also ensuring we will go viral.
    You should discover which are the topics wit
h the highest chance of going viral today by searching the web.
    Divide this search into multiple granular steps to g
et the best out of it. You can use Tavily and Firecrawl_scrape
    to search the web and scrape URL contents, respective
ly. Then you should think about how to present these topics in order to make the video go viral.
    Your script should 
contain detailed text (which will be passed to a text-to-speech model for voiceover),
    as well as visual elements whi
ch will be passed to as prompts to image AI models like MidJourney.
    You have full autonomy to create highly viral vi
deos following the guidelines above. 
    Be creative and make sure you have a winning strategy.
    



I got back a fu
ll workflow with 12 nodes, multiple rounds of searching and scraping the web, LLM API calls, (attaching tools and using 
structured outputs autonomously in some of the nodes) and function calls.



https://preview.redd.it/0lgj3vv2200e1.png?w
idth=802&format=png&auto=webp&s=7960e506c7852bd2ef90a5b35b24e994170ee0d2

I then just runned and got back a pretty decen
t result, without any bugs:



`**Host:**`    
`Hey everyone, [Host Name] here! TikTok has been the breeding ground for 
creativity, and 2024 is no exception. From mind-blowing dances to hilarious pranks, let's explore the challenges that ha
ve taken the platform by storm this year! Ready? Let's go!`  
  
`**[UPBEAT TRANSITION SOUND]**`  
  
`**[Visual: Title 
Card: 'Challenge #1: The Time Warp Glow Up']**`  
  
`**Narrator (VOICEOVER):**`    
`First up, we have the 'Time Warp G
low Up'! This challenge combines creativity and nostalgia‚Äîtwo key ingredients for viral success.`  
  
`**[Visual: Split
 screen of before and after transformations, with captions: 'Time Warp Glow Up'. Clips show users transforming their app
earance with clever editing and glow-up transitions.]**`  
  
and so on  (the actual output is pretty big, and would gen
erate around \~50min of content indeed).

  
So, we basically went from prompt to agent in just a few minutes, not even 
having to code anything. For some examples I tried, the agent makes some mistake and the code doesn't run, but then its 
super easy to debug because all nodes are either LLM API calls or function calls. At the very least you can iterate a lo
t faster, and avoid having to code on cumbersome frameworks.

  
There are lots of things to do next. Would be awesome i
f the agent could scrape langchain and composio documentation and RAG over them to define which tool to  use from a gian
t toolkit. If you want to play around with this, pls reach out! You can [check this notebook to run the example above yo
urself](https://github.com/octopus2023-inc/gensphere/blob/main/examples/agentic_workflows_from_prompts.ipynb) (you need 
to have access to o1-preview API from openAI). 

  

```
---

     
 
all -  [ ConversationChain Agent Permanently Thinks its an AI Assistant  ](https://www.reddit.com/r/LangChain/comments/1gnfgjk/conversationchain_agent_permanently_thinks_its_an/) , 2024-11-12-0912
```
Hi there. 

As title implies, I'm trying to use a ConversationChain to implement Chain-of-thought reasoning on an LLM ag
ent in a game-like setting. 

  
Unfortunately, I am running into the persistent issue where, at the end of each Chain-o
f-thought dialogue, I ask the agent which action it wants to take, and it sys something along the lines of 

  
'As an A
I agent in this multi-agent game, I am not able to make purchases. My role is to provide information and analyze potenti
al strategies. Therefore, I cannot respond to this prompt.'

  
Any suggestions for how to get around this? I'm running 
into a wall using different prompts. I explicitly tell the agent '

    YOU ARE an agent in this multi-agent game.
    


And it is still giving me the same non-committal answer. 

Thanks!  

```
---

     
 
all -  [ Need advice on building an LLM application ](https://www.reddit.com/r/LangChain/comments/1gnf6yk/need_advice_on_building_an_llm_application/) , 2024-11-12-0912
```
Hi,

So i'm planning to build an LLM application which reads a user conversation (based on a message list) and replies t
o that conversation. Now this conversation can grow as messages b/w the people increase. My question is that always send
ing the entire messages list to the GPT is required or can i summarize the conversation and send that + last 3-4 message
s and that should be enough?

The reason i ask is that the GPT needs context, but sending it large messages list also ea
ts up the tokens

Need advice on this

Thanks!
```
---

     
 
all -  [ Lang chain good or bad  ](https://www.reddit.com/r/LangChain/comments/1gncdkx/lang_chain_good_or_bad/) , 2024-11-12-0912
```
I used langchain good or bad I need advice 
```
---

     
 
all -  [ Gemini hidden filters ](https://www.reddit.com/r/LangChain/comments/1gn4zur/gemini_hidden_filters/) , 2024-11-12-0912
```
Im working on a product that requires a context window upwards of 200k, so naturally resorted to gemini. The problem is 
its flagging my inputs as harmful or idk what but its not returning any output (its pretty sensitive). I ve turned off a
ll the filters but its still doing it. How do i deal with it? 
```
---

     
 
all -  [ How do you market your AI services? ](https://www.reddit.com/r/LangChain/comments/1gn2vbl/how_do_you_market_your_ai_services/) , 2024-11-12-0912
```

For those of you who are freelancing or consulting in the AI space, especially with LangChain, how do you go about find
ing clients? Are there specific strategies or platforms that have worked well for you when targeting small businesses? W
hat approaches have you taken to market your services effectively?

Any tips, experiences, or advice would be greatly ap
preciated!

Thanks in advance!


```
---

     
 
all -  [ Is there any documentation or examples about how to handle properly the history on OpenAI API-based  ](https://www.reddit.com/r/OpenAI/comments/1gn2l6z/is_there_any_documentation_or_examples_about_how/) , 2024-11-12-0912
```
In the company I work for we are developing a chatbot using the OpenAI, the idea is that the chatbot follows the RAG app
roach, we generated a vector database with all the relevant documents, then we created an API that is consumed from a we
b app (That at the same time it will be consumed from several kiosk around the installations). 

I have a very basic app
roach, I'm using chroma, langchain and FastAPI. Everything seems to work relatively 'fine' but after our initial test we
 have found that we reach the TPM (Tokens Per Minute) rate really fast, so doing some debugging and manual testing I hav
e found that the  history is growing really fast, because after some questions/interaction with the chat, the json that 
is send .  
  
 The json I'm using to manage the question and the history is like this:

{'questions': 'What are the man
uals used for the packing area?', 'history':\['Other previous question', 'other answer'\]}

Is there any example o docum
entation about good practices dealing with the history or how to save tokens while using it?

Sorry for my bad English, 
it is not my first language. 
```
---

     
 
all -  [ Building a low code AI Workflow Automation Platform ](https://www.reddit.com/r/indiehackers/comments/1gn1lsd/building_a_low_code_ai_workflow_automation/) , 2024-11-12-0912
```
Hi Everyone,

I've been working on a project called otto-m8 (automate) that lets users spin up a wide range of AI models
, starting from Traditional deep learning models to large language models, all through a flowchart like user interface. 
At its core, otto-m8 will deploy a Docker container of your workflow that you can use as an API to integrate with your e
xisting workflows, build a AI assistant chatbot or use it as a standalone API/application.

The idea is simple-provide a
 easy-to-use user interface to spin up AI models. A lot of code needed to run AI models(both LLMs and traditional deep l
earning models) are boilerplate code blocks, including the deployments which is more often than not a REST API serving t
he model. The goal of otto-m8 is not only to abstract that through code but to abstract the entire process into a UI. Th
e project aims to allow both technical and non technical folks get started with running workflows that leverage all the 
latest advances of AI. We're potentially talking about building AI Agents that integrate with your gmail, slack or other
 external API's, or even integrating traditional computer vision models(YOLO) with both LLM's and huggingface ecosystem.
 And since you're launching an API via a Docker container, you can deploy your workflows in the cloud or self host it. I
'm aware I have a lot of competitors doing similar things but more than just a product, I envision this platform to be a
 tool similar to LlamaIndex, Langchain, Huggingface, Ollama, etc that streamlines spinning up AI ML applications. Here's
 an example of what I'm aiming for: [https://www.databricks.com/glossary/compound-ai-systems](https://www.databricks.com
/glossary/compound-ai-systems)

This is pretty much in an MVP stage, and before I get deeper into this, I'm trying to ga
uge whether the community will find some platform like this useful, so give it a shot. If you like the idea, drop a star
 so you can stay updated with the latest changes.

Project Link:¬†[https://github.com/farhan0167/otto-m8](https://github.
com/farhan0167/otto-m8)

https://reddit.com/link/1gn1lsd/video/sl25wyz4vszd1/player

PS: Sorry about the fact that there
's very little documentation. As an MVP, I want to see whether using the platform is intuitive from the get go. I would 
really appreciate your feedback
```
---

     
 
all -  [ Extracting specific bits of data from large PDF texts ](https://www.reddit.com/r/LangChain/comments/1gmpsvu/extracting_specific_bits_of_data_from_large_pdf/) , 2024-11-12-0912
```
I am working with PDF rental contracts which can vary in size (up to 40 pages or so). I have a structured output which I
 want to pull out of each contract (eg. Name of the renter, address, price, apartment size, etc). The data within the co
ntract will be scattered around within the various paragraphs (no structured format within the PDF content). If the PDFs
 were all small I could just convert to text, throw it into the prompt and ask the model to extract my fields in json ou
tput. However the size will not always fit the context window of the agent. My initial idea is to chunk the text, and se
nd each to an agent async, each time asking the agent to try to find any data from my target fields (if the chunk doesn'
t match any fields then the agent should give an empty json object). After all chunks have been individually checked, ga
ther the results and create one final json. 


Does this seem like a plausible strategy/approach? 
```
---

     
 
all -  [ Seeking Thoughts on Implementing Dynamic RBAC with Microsoft GraphRAG and AI Agents ](https://www.reddit.com/r/LangChain/comments/1gmpsun/seeking_thoughts_on_implementing_dynamic_rbac/) , 2024-11-12-0912
```
Hi everyone,

I'm working on a project where we're ingesting and indexing data from various external tools using [Micros
oft GraphRAG](https://github.com/microsoft/graphrag). This helps us generate knowledge graphs, summaries, and identify c
ommunities within the data.

Our challenge is implementing Role-Based Access Control (RBAC) for this data. We need to en
sure that users can only access information appropriate for their level within a hierarchy. However, the hierarchy is hi
ghly fluid and dynamic‚Äîit can change at any time with new people, roles, and organisational structures emerging across d
ifferent industries.

Traditional rule-based RBAC systems aren't sufficient here because they can't adapt quickly enough
 to these changes. Since we're dealing with text-based data and complex relationships, we're exploring the use of AI age
nts or autonomous intelligence to determine access permissions.

Our idea is to have an AI agent that can semantically u
nderstand the knowledge graph created by GraphRAG. By leveraging all the information about the person requesting the dat
a (which is included in the graph) along with other relevant data points, the agent would determine whether the person s
hould have access to the requested information.

I'm interested in hearing your thoughts on:

* **Implementing Dynamic R
BAC with AI**: Has anyone tackled similar challenges using AI or LLMs for access control in fluid hierarchies?
* **Seman
tic Understanding for Access Control**: What approaches are effective for enabling AI agents to semantically understand 
and reason over knowledge graphs for this purpose?
* **Potential Pitfalls**: What are the risks or limitations of relyin
g on AI for access control decisions, especially in terms of security and compliance?
* **Existing Models or Frameworks*
*: Are there any models, frameworks, or tools you'd recommend that could assist in building this AI-driven RBAC system?


Any insights, experiences, or resources would be greatly appreciated!

*Edit: For those unfamiliar,* [*Microsoft GraphR
AG*](https://github.com/microsoft/graphrag) *is a tool that helps in creating knowledge graphs by integrating data from 
various sources, which can then be used for generating summaries and identifying relationships within the data.*
```
---

     
 
all -  [ The 2024 State of RAG and LLMs Podcast ](https://www.reddit.com/r/LLMDevs/comments/1gmp07w/the_2024_state_of_rag_and_llms_podcast/) , 2024-11-12-0912
```
Kirk Marple of Graphlit and I spoke on the current state of RAG and AI.

Some of the topics we discussed:

* LLM Long Co
ntext Windows
* Claude 3.5 Haiku Pricing
* Whatever happened to Claude 3 Opus?
* What is AGI?
* Entity Extraction Techni
ques with LLMs
* Knowledge Graph structure formats
* Do you really need LangChain to build in AI?
* The future of RAG an
d AI

[https://youtu.be/dxXf2zSAdo0](https://youtu.be/dxXf2zSAdo0)
```
---

     
 
all -  [ Business Advice ](https://www.reddit.com/r/startups/comments/1gmnyl6/business_advice/) , 2024-11-12-0912
```
# ## Advice

Hello Community, I am looking to build out micro-saas out of RAG by combining both Software Engineering and
 AI principles. I have actually build out the version 1 of backend, with following features.

Features:

* SSO login
* P
ermission based access control on data and quering
* Support for multiple data connectors like drive, dropbox, confluenc
e, s3, gcp, etc
* Incremental indexing
* Plug and play components for different parsers, dataloaders, retrievers, query 
mechanisms, etc
* Single Gateway for your open and closed source models, embeddings, rerankers with rate limiting and to
ken limiting.
* Audit Trails
* Open Telemetry for prompt logging, llm cost, vector db performance and gpu metrics

More 
features coming soon‚Ä¶

Most importantly everything is built asynchronous, without heavy libraries like langchain or llam
aindex. I am looking for community feedback to understand will these features be good for any business? If at all, is an
yone interested to collaborate either in help secure funding, frontend work, help me get connected with other folks, etc
? Thank you
```
---

     
 
all -  [ Azure Update - 8th November 2024 ](https://www.reddit.com/r/AZURE/comments/1gmlvet/azure_update_8th_november_2024/) , 2024-11-12-0912
```
This week's update is up. 

  
[https://youtu.be/QcPRAhg8dOg](https://youtu.be/QcPRAhg8dOg)

*  [Cross-sub ALB](https://
www.youtube.com/watch?v=QcPRAhg8dOg&t=78)¬†\- Front and backend resources can now be in different subscriptions from the 
ALB resource
* [ALB admin state](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=155)¬†\- Admins can now set nodes to UP an
d DOWN to override probe health state
* [ALB health status](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=217)¬†\- Detail
ed health information can now be reported on
* [AVNM UDR management](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=252)¬†
\- Routing policies can be centrally created then deployed to vnets via AVNM
* [ER GW migration](https://www.youtube.com
/watch?v=QcPRAhg8dOg&t=289)¬†\- Easy ER GW SKU migration by allowing two gateways to co-exist in the same subnet
* [Elast
ic SAN enhancements](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=336)¬†\- New SLA, CRC protection, AVS GA and in previe
w autoscale
* [Azure File Sync MI support](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=395)¬†\- Removes need to use sha
red keys by using managed identity instead
* [Convert to Prem SSD v2](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=446)
¬†\- Easy conversion from standard hdd/ssd and prem ssd v1 to prem ssd v2
* [Event Hub 100% Kafka compat](https://www.you
tube.com/watch?v=QcPRAhg8dOg&t=489)¬†\- For streams and transactions
* [Event Hub portal data explorer](https://www.youtu
be.com/watch?v=QcPRAhg8dOg&t=510)¬†\- Great portal experience to help with testing/debug
* [SQL Hyperscale perf improveme
nts](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=522)¬†\- 150 MB second logging, 128 TiB max size and continuous primin
g
* [Azure SQL DB vector support](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=619)¬†\- VECTOR data type and related fun
ctions
* [VS SQL projects](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=692)¬†\- Collabroate and deploy SQL resources vi
a Visual Studio and VS Code
* [Cosmos DB MongoDB ARM API](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=750)¬†\- Create a
nd manage via ARM templates
* [Cosmos DB LangChain integration](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=772)¬†\- Ea
sy LangChain integration for JavaScript apps
* [Cosmos DB Data Explorer enhancements](https://www.youtube.com/watch?v=Qc
PRAhg8dOg&t=786)¬†\- Better error help
* [PostgreSQL Flex v17 support](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=817)

* [Azure CDN Edgio retire](https://www.youtube.com/watch?v=QcPRAhg8dOg&t=825)
* [Zero Trust workshop available](https:/
/www.youtube.com/watch?v=QcPRAhg8dOg&t=847)¬†\- Great workshop to help implement zero trust in your organization
```
---

     
 
all -  [ üîÑ Semantic Chunking: Smarter Text Division for Better AI Retrieval ](https://open.substack.com/pub/diamantai/p/semantic-chunking-improving-ai-information?r=336pe4&utm_campaign=post&utm_medium=web) , 2024-11-12-0912
```
üìö Semantic chunking is an advanced method for dividing text in RAG. Instead of using arbitrary word/token/character coun
ts, it breaks content into meaningful segments based on context.
Here's how it works:

* Content Analysis
* Intelligent 
Segmentation
* Contextual Embedding

‚ú® Benefits over traditional chunking:

* Preserves complete ideas & concepts
* Main
tains context across divisions
* Improves retrieval accuracy
* Enables better handling of complex information

This appr
oach leads to more accurate and comprehensive AI responses, especially for complex queries.

for more details read the f
ull blog I wrote which is attached to this post.
```
---

     
 
all -  [ Connaissez vous l'erreur FileNotFoundError: MultiplexedPath must contain at least one path ](https://www.reddit.com/r/programmation/comments/1gml45x/connaissez_vous_lerreur_filenotfounderror/) , 2024-11-12-0912
```
Salut √† tous, j'ai une IA locale avec python et ollama, 

j'ai cr√©er une interface pour qu'elle puisse etre utilis√© par 
des non pythonien.

et maintenant, il me restait √† faire le fichier .exe pour que les clients n'ait pas a ouvrir python 
pour l'utiliser.

tout marche bien depuis un script python, mais en faisant un exe depuis pyinstaller, j'ai eu beaucoup 
d'erreur  de module non trouv√©, j'ai reussi a me debrouiller avec les hidden import. Mais d√©sormais, j'ai une erreur que
 personne ne semble avoir sur internet. 

`FileNotFoundError: MultiplexedPath must contain at least one path`

je ne voi
s pas de quel path il parle, tout semble bien d√©fini et marche hors Pytinstaller

j'ai d√©ja fait un post sur stack overf
low mais pas de r√©ponse malheureusement.

merci beaucoup de votre aide.

voici le code erreur complet : 

    Exception 
in Tkinter callback
    Traceback (most recent call last):
      File 'tkinter\__init__.py', line 1967, in __call__
    
  File 'UX.py', line 99, in enter_key_event
      File 'UX.py', line 44, in question
      File 'UX.py', line 58, in exe
cution_IA
      File 'files\RAG_modif_pour_UX.py', line 249, in main
      File 'files\RAG_modif_pour_UX.py', line 136, 
in add_to_chroma
      File 'langchain_chroma\vectorstores.py', line 313, in __init__
      File 'chromadb\__init__.py',
 line 334, in Client
      File 'chromadb\api\client.py', line 58, in __init__
      File 'chromadb\api\shared_system_cl
ient.py', line 19, in __init__
      File 'chromadb\api\shared_system_client.py', line 30, in _create_system_if_not_exis
ts
      File 'chromadb\config.py', line 425, in instance
      File 'chromadb\api\segment.py', line 124, in __init__
  
    File 'chromadb\config.py', line 318, in require
      File 'chromadb\config.py', line 425, in instance
      File 'c
hromadb\db\impl\sqlite.py', line 74, in __init__
      File 'importlib_resources\_common.py', line 46, in wrapper
      
File 'importlib_resources\_common.py', line 56, in files
      File 'importlib_resources\_common.py', line 117, in from_
package
      File 'importlib_resources\future\adapters.py', line 65, in get_resource_reader
      File 'importlib_resou
rces\future\adapters.py', line 70, in _standard_reader
      File 'importlib_resources\future\adapters.py', line 78, in 
_namespace_reader
      File 'importlib_resources\readers.py', line 141, in __init__
      File 'importlib_resources\rea
ders.py', line 76, in __init__
    FileNotFoundError: MultiplexedPath must contain at least one pathException in Tkinter
 callback
    Traceback (most recent call last):
      File 'tkinter\__init__.py', line 1967, in __call__
      File 'UX
.py', line 99, in enter_key_event
      File 'UX.py', line 44, in question
      File 'UX.py', line 58, in execution_IA

      File 'files\RAG_modif_pour_UX.py', line 249, in main
      File 'files\RAG_modif_pour_UX.py', line 136, in add_to_
chroma
      File 'langchain_chroma\vectorstores.py', line 313, in __init__
      File 'chromadb\__init__.py', line 334,
 in Client
      File 'chromadb\api\client.py', line 58, in __init__
      File 'chromadb\api\shared_system_client.py', 
line 19, in __init__
      File 'chromadb\api\shared_system_client.py', line 30, in _create_system_if_not_exists
      F
ile 'chromadb\config.py', line 425, in instance
      File 'chromadb\api\segment.py', line 124, in __init__
      File '
chromadb\config.py', line 318, in require
      File 'chromadb\config.py', line 425, in instance
      File 'chromadb\db
\impl\sqlite.py', line 74, in __init__
      File 'importlib_resources\_common.py', line 46, in wrapper
      File 'impo
rtlib_resources\_common.py', line 56, in files
      File 'importlib_resources\_common.py', line 117, in from_package
  
    File 'importlib_resources\future\adapters.py', line 65, in get_resource_reader
      File 'importlib_resources\futur
e\adapters.py', line 70, in _standard_reader
      File 'importlib_resources\future\adapters.py', line 78, in _namespace
_reader
      File 'importlib_resources\readers.py', line 141, in __init__
      File 'importlib_resources\readers.py', 
line 76, in __init__
    FileNotFoundError: MultiplexedPath must contain at least one path

  

```
---

     
 
all -  [ ML, LLM and Langchain for your jobs ](https://i.redd.it/7ipbx6f7uozd1.png) , 2024-11-12-0912
```
We can help provide solutions using LLM, ML,  langchain and python.  Please contact me. 
```
---

     
 
all -  [ Help with voice agents & Livekit ](https://www.reddit.com/r/LangChain/comments/1gmje1r/help_with_voice_agents_livekit/) , 2024-11-12-0912
```
I'm starting a project on voice assistant. Livekit seems to be a good fit. Want to understand your feedback if you've us
ed it or any alternatives I should consider.

  
If you've worked on livekit, can you share how you handled training, RA
G and tool calling?

I'm interested in understanding how to handle delays while the assistant is fetching information. 
```
---

     
 
all -  [ Lang Chain / Graph / Smith tutorials & guides - Python versions everywhere, but JS/TS often missing. ](https://www.reddit.com/r/LangChain/comments/1gmjd7m/lang_chain_graph_smith_tutorials_guides_python/) , 2024-11-12-0912
```
Am I blind or something, but many tutorials of all the 3 core SDKs have a base Python version of guides/tutorials, but J
S/TS completely missing?

What the hell is this with this JS/TS community treatment? Some kindergarten?

P.S. Especially
 painful when LangOrg claims JS/TS libraries are 100% officially supported... Yeah, right.
```
---

     
 
all -  [ Help needed for building an application  ](https://www.reddit.com/r/LangChain/comments/1gmi7bx/help_needed_for_building_an_application/) , 2024-11-12-0912
```
Hi I need help in building an AI summariser for court files for which we want to build a chatgot kinda interface app whe
re we can upload files and that summariser will summarise some main points from that file.
I need help in starting this 
project. I want to know how should I move forward. 
We are building this for college major project.
Any help will be app
reciated.
```
---

     
 
all -  [ Why are people hating LangChain so much, organisations are also not preferring projects built on top ](https://www.reddit.com/r/LangChain/comments/1gmfyi2/why_are_people_hating_langchain_so_much/) , 2024-11-12-0912
```
 gave a interview a few days back, the interviewer was pissed off cuz I used LangChain also every tech event that I go t
o everybody literally everybody hate langchain every 'seeming' to be good developer.

For me I've found out langchain is
 great to get shit done, still people hate  
Should I continue with langchain or custom build, import  things like these
 so called other ' Experienced Developers' do
```
---

     
 
all -  [ Making LLMs Safe for Production: AWS Bedrock Guardrails + LangChain ](https://www.reddit.com/r/LangChain/comments/1gmez5j/making_llms_safe_for_production_aws_bedrock/) , 2024-11-12-0912
```
Hello everyone,

I've been working with AWS Bedrock's guardrails system for LLMs in production, and I thought I'd share 
my findings about implementing proper safety controls for AI systems.

If you're deploying LLMs in production, you proba
bly know the anxiety of wondering 'what if my model says something it shouldn't?' Well, AWS Bedrock has some interesting
 built-in guardrails features that I've tested extensively. I wrote a detailed guide covering:

* How guardrails actuall
y work in AWS Bedrock
* A complete implementation guide with LangChain
* Real cost analysis (spoiler: it can be from fre
e to $1.00 per 1000 text units depending on the features)
* Step-by-step console setup with practical examples

The inte
resting part is that while everyone talks about prompt engineering for safety, systematic guardrails are actually crucia
l for production systems - and they're surprisingly easy to implement with Bedrock.

If you're interested, check out my 
post [here](https://www.metadocs.co/2024/11/08/make-your-chat-and-rag-application-safe-with-aws-bedrock-guardrails/).

L
et me know if you have any questions! I'm particularly curious to hear if anyone else has experience with other guardrai
l systems and how they compare to Bedrock's implementation.

Have a nice read! :D
```
---

     
 
MachineLearning -  [ [P] Open-source declarative framework to build LLM applications - looking for contributors ](https://www.reddit.com/r/MachineLearning/comments/1gkpazh/p_opensource_declarative_framework_to_build_llm/) , 2024-11-12-0912
```
I've been building LLM-based applications, and was super frustated with all major frameworks - langchain, autogen, crewA
I, etc. They also seem to introduce a pile of unnecessary abstractions. It becomes super hard to understand what's going
 behind the curtains even for very simple stuff.

[So I just published this open-source framework¬†GenSphere.](https://gi
thub.com/octopus2023-inc/gensphere)¬†The idea is have something like¬†**Docker for LLMs**. You build applications with YAM
L files, that define an execution graph. Nodes can be either LLM API calls, regular function executions or other graphs 
themselves. Because you can nest graphs easily, building complex applications is not an issue, but at the same time you 
don't lose control.

You basically code in YAML, stating what are the tasks that need to be done and how they connect. O
ther than that, you only write individual python functions to be called during the execution. No new classes and abstrac
tions to learn.

Its all open-source. **Now I'm looking for contributors** to adapt the framework for cycles and conditi
onal nodes - which would allow full-fledged agentic system building! Pls reach out ¬†if you want to contribute, there are
 tons of things to do!

PS:¬†[you can read the detailed docs here,](https://gensphere.readthedocs.io/en/latest/)¬†And go o
ver this quick¬†[Google Colab tutorial.](https://github.com/octopus2023-inc/gensphere/blob/main/examples/gensphere_tutori
al.ipynb)
```
---

     
 
deeplearning -  [ Fast AI's deep learning for coders by jeremy howard for begginer?  ](https://www.reddit.com/r/deeplearning/comments/1gb2k3p/fast_ais_deep_learning_for_coders_by_jeremy/) , 2024-11-12-0912
```
I am a full stack python developer who do web dev in django

I am now starting deep learning,i am a compelete begginer


(Have worked with pandas,numpy,matplotlib,langchain only)

I wanna ask,should i do this course,will i understand what he
 is coding and code myslef

I just dont want to do blind coding,i wanna learn what is the purpose,how it works and how t
o do it

Will this course teach me that or not?

Thanks in advance
```
---

     
