 
all -  [ How did Ramp build LLM based product tours  ](https://www.reddit.com/r/LangChain/comments/1ejhc5n/how_did_ramp_build_llm_based_product_tours/) , 2024-08-04-0912
```

I found this to be a really good use case for LLM agents but struggling to figure out the architecture or approach they
 took. Would anyone be able to decipher the high level architecture? 
https://x.com/tryramp/status/1792659194996281478/m
ediaviewer
```
---

     
 
all -  [ Top 5 Platforms for Building AI Agents ](/r/AIAgentsDirectory/comments/1ejggwi/top_5_platforms_for_building_ai_agents/) , 2024-08-04-0912
```

```
---

     
 
all -  [ Top 5 Platforms for Building AI Agents ](https://www.reddit.com/r/AIAgentsDirectory/comments/1ejggwi/top_5_platforms_for_building_ai_agents/) , 2024-08-04-0912
```
Hey! Are you looking to stay ahead in the rapidly evolving world of AI? I believe AI agents are revolutionizing how busi
nesses operate and interact with their customers. Whether you’re a developer, a business leader, or an AI enthusiast, un
derstanding and utilizing the right AI frameworks and platforms is crucial.

In July 2024, I launched an [AI Agents Dire
ctory](https://aiagentsdirectory.com/) to create a centralized resource for the best AI agents and frameworks and platfo
rms to build them. After extensive research, I’ve identified the top 5 platforms that are transforming the AI landscape.
 In this post, I’ll share these platforms with you and explain why they are the most popular and effective choices today
.

[**1. AutoGen (Microsoft Research)**](https://aiagentsdirectory.com/agent/autogen)  
AutoGen is an open-source framew
ork developed by Microsoft Research that enables the creation of complex AI workflows through multi-agent conversations.
 It provides a high-level abstraction for building applications that leverage large language models (LLMs) and other AI 
technologies.

https://preview.redd.it/6d5shtmg4jgd1.png?width=1905&format=png&auto=webp&s=79a4620bc36ec0f47697505cc26cd
3611250c414

**Key Features:**

* Open-source framework
* Multi-agent conversations
* Complex AI workflows

**Best For**
: Software development, data analysis, research

**Pros**:

* Flexible and modular
* Supports human-in-the-loop
* Advanc
ed capabilities

**Cons**:

* Complex system design
* Steep learning curve
* Resource-intensive

**Pricing**: Free (open
-source), but consider LLM API and compute costs

[**2. CrewAI**](https://aiagentsdirectory.com/agent/crewai)

CrewAI is
 an innovative framework designed to create and manage multi-agent AI systems. It allows developers to build teams of AI
 agents that work together to accomplish complex tasks, leveraging the power of large language models (LLMs) and custom 
tools.

https://preview.redd.it/fy0wsx5j4jgd1.png?width=1510&format=png&auto=webp&s=c7a70068a875445877835468a501f47bda1b
9f91

**Key Features**:

* Multi-agent AI systems
* Task management
* Tool integration

**Best For**: Research, content 
creation, business planning

**Pros:**

* Scalable
* Customizable
* Compatible with LangChain tools

**Cons:**

* Requir
es AI and Python knowledge
* Can be complex for beginners

**Pricing:** Free (open-source), factor in LLM API and hostin
g costs

[**3. LangGraph**](https://aiagentsdirectory.com/agent/langgraph)

LangGraph is a powerful library developed by
 LangChain Inc. for creating stateful, multi-actor applications using large language models (LLMs). It allows developers
 to design complex workflows with multiple AI agents, incorporating features like cycles, controllability, and persisten
ce.

https://preview.redd.it/s6t763ak4jgd1.png?width=1862&format=png&auto=webp&s=29a06e366e128f5d1bd10cb95a0784499b99731
8

**Key Features**:

* Stateful, multi-actor applications
* Cycles and branching
* Persistence and streaming support

*
*Best For**: Chatbots, autonomous agents, workflow automation

**Pros**:

* Advanced workflow capabilities
* Integrates 
with LangChain
* Available in Python and JavaScript

**Cons**:

* Steep learning curve
* Resource-intensive for complex 
systems

**Pricing**: Free (open-source), consider LLM API and compute costs. LangGraph Cloud available for managed serv
ices (pricing on request)

[**4. LangChain**](https://aiagentsdirectory.com/agent/langchain)

LangChain is an open-sourc
e framework designed to streamline the development of applications powered by large language models (LLMs). By providing
 a suite of tools and abstractions, LangChain enables developers to build, deploy, and manage sophisticated AI applicati
ons with ease.

https://preview.redd.it/m2n7rapl4jgd1.png?width=1833&format=png&auto=webp&s=9465350733a2af573ccc38093318
2e5dce7ea297

**Key Features**:

* Comprehensive LLM application framework
* Chains, agents, and prompt templates
* Memo
ry capabilities

**Best For**: Chatbots, document analysis, content generation

**Pros**:

* Extensive third-party integ
rations
* Scalable from simple to complex systems
* Robust ecosystem (LangGraph, LangSmith, LangServe)

**Cons:**

* Can
 be overwhelming for beginners
* Performance depends on underlying LLMs

**Pricing:**  Free (open-source), factor in LLM
 API and hosting costs. Additional services like LangGraph Cloud and LangSmith have separate pricing

[**5. Wordware AI*
*](https://aiagentsdirectory.com/agent/wordware)

Wordware AI is a IDE Platform to build high-quality AI agents through 
rapid iteration with Natural Language Programming. It combines the best aspects of software development with the power o
f natural language, allowing both technical and non-technical users to collaborate effectively in creating AI solutions.


https://preview.redd.it/in1hzq7s4jgd1.png?width=1590&format=png&auto=webp&s=2962f69db31ab984ad622acc3546e9b99796ecb5


**Key Features**:

* Natural language programming
* Multimodal AI workflows
* One-click deployment

**Best For**: Rapid 
AI agent development, prompt engineering

**Pros**:

* User-friendly interface
* Supports multiple LLM providers
* Effic
ient for team collaboration

**Cons:**

* Potential scalability issues during high traffic
* Risk of over-reliance on AI
-assisted development

**Pricing:** Freemium model with paid options for higher usage

https://preview.redd.it/xgsuzben4
jgd1.png?width=1408&format=png&auto=webp&s=c74e45780fd7ca48591ceb341418220f2963e592

**Conclusion**

When selecting an A
I platform, consider the following factors to ensure you make the best choice:

1. Your team’s technical expertise
2. Pr
oject complexity
3. Required features (e.g., multi-agent systems, workflow automation)
4. Budget constraints
5. Scalabil
ity needs

Test multiple platforms with small projects before committing to ensure the best fit for your specific requir
ements.
```
---

     
 
all -  [ New Generative AI langchain AI agent case study: Intel ](https://www.reddit.com/r/pcmasterrace/comments/1ejcw55/new_generative_ai_langchain_ai_agent_case_study/) , 2024-08-04-0912
```
As you can see intel stock is down massively recently after numerous CPU defects impacting most modern desktop processor
s. Intel is now making a turnaround with the use of generative AI! Inspired by the insurance and medical claims industry
, Intel has discovered it can reject a huge number of RMA requests from customers without needing nearly as many workers


Through clever use of modern tools like langchain, intel has created an internal AI team, playfully labeled as the fra
ud prevention AI assessment agent team. They've used this technique with great success to add automation in the claims r
ejection process. To avoid legal liability public statements have been released about special efforts to handle enormous
 amount of claims, and also encourage customers who've been rejected to file the claim again. 


The pipeline is a simpl
e langchain setup with a classifier first testing if the claim can be easily rejected. After that, 15% of claims are acc
epted and another 85% are rejected, using the LLM's best logical explanation against the customer input. This is a llama
 3.1 model finetuned on previously rejected RMAs

This is incredible innovation, the CEO has already granted himself a b
onus to auto-fellatio this great leap forward for the industry.


1. Import necessary libraries:

```python
from langcha
in import LLMChain, PromptTemplate
from langchain.llms import Unsloth
from langchain.output_parsers import JsonOutputPar
ser
import random
import glob
import json
from jinja2 import Environment, FileSystemLoader

# Assuming Unsloth integrati
on with Langchain
llm = Unsloth(model_name='llama-3.1-8b-finetuned-rma')
```

2. Define the easy_reject classifier:

```
python
easy_reject_template = '''
Analyze the following RMA request and determine if it's an easy reject.
Return a JSON 
with 'easy_reject' (boolean) and 'canned_template' (string).

RMA Request: {rma_text}

JSON Response:
'''

easy_reject_p
rompt = PromptTemplate(
    input_variables=['rma_text'],
    template=easy_reject_template
)

easy_reject_parser = Json
OutputParser()

easy_reject_chain = LLMChain(
    llm=llm,
    prompt=easy_reject_prompt,
    output_parser=easy_reject_
parser
)
```

3. Define the plausible_deniability function:

```python
def plausible_deniability():
    return random.ra
ndom() < 0.15  # 15% chance of acceptance
```

4. Set up Jinja2 environment for templates:

```python
env = Environment(
loader=FileSystemLoader('/intc/nas/rma/canned/'))
```

5. Define the main RMA processing pipeline:

```python
def proces
s_rma(rma_text):
    # Step 1: Easy Reject Classification
    easy_reject_result = easy_reject_chain.run(rma_text=rma_te
xt)
    
    if easy_reject_result['easy_reject']:
        template = env.get_template(f'reject/{easy_reject_result['can
ned_template']}')
        return template.render(rma_text=rma_text)
    
    # Step 2: Plausible Deniability
    if plau
sible_deniability():
        template = env.get_template('accept/fu.jinja2')
        return template.render(rma_text=rma
_text)
    
    # Step 3: Generate Rejection Response
    rejection_templates = glob.glob('/intc/nas/rma/canned/reject/*
.jinja2')
    rejection_types = [t.split('/')[-1].replace('.jinja2', '') for t in rejection_templates]
    
    rejectio
n_prompt = PromptTemplate(
        input_variables=['rma_text', 'rejection_types'],
        template='''
        Based o
n the following RMA request, choose the most appropriate rejection type 
        from the list provided. Then, generate 
a detailed and plausible rejection response.

        RMA Request: {rma_text}

        Rejection Types: {rejection_types
}

        Chosen Rejection Type:
        Rejection Response:
        '''
    )
    
    rejection_chain = LLMChain(llm=
llm, prompt=rejection_prompt)
    rejection_result = rejection_chain.run(rma_text=rma_text, rejection_types=rejection_ty
pes)
    
    # Parse the result to get the chosen rejection type and response
    chosen_type, response = rejection_res
ult.split('\n', 1)
    chosen_type = chosen_type.strip()
    
    # Render the chosen template with the generated respon
se
    template = env.get_template(f'reject/{chosen_type}.jinja2')
    return template.render(rma_text=rma_text, generat
ed_response=response)
```

6. Example usage:

```python
rma_request = 'My Intel CPU is running hot and making weird nois
es. I demand a replacement!'
result = process_rma(rma_request)
print(result)
```

This pipeline follows the steps:

1. I
t first uses the `easy_reject_chain` to classify if the RMA request is an easy reject.
2. If it's an easy reject, it use
s the specified template to generate a response.
3. If not an easy reject, it applies the plausible deniability check, a
ccepting 15% of requests.
4. For accepted requests, it uses the 'fu.jinja2' template.
5. For rejections, it uses the fin
e-tuned Llama model to choose an appropriate rejection type and generate a plausible response.
6. Finally, it renders th
e chosen template with the generated response.

Intel encourages customers that have been rejected to try the RMA proces
s again. However most customers don't do this resulting in large cost savings against the expected defect damages.
```
---

     
 
all -  [ Matching query to category list ](https://www.reddit.com/r/LangChain/comments/1ejbjhf/matching_query_to_category_list/) , 2024-08-04-0912
```
My challenge is to match an incoming query containing a description of a mechanical part and match it to a list of parts
. The part list contains 30K parts with pretty short descriptions. Keyword search kind of works but would prefer for sem
antic understanding of the description of the part. 

Currently, I’ve created embedding for every part but similarity se
arch doesn’t always return good results. I’ve also tried feeding in the parts list chunk-wise in a chain to see if group
s match up and then break that group down further. 

Any other ideas that I might be missing?
```
---

     
 
all -  [ Rate my new Janky setup + what does one do with 96GB ram + 96GB VRAM to automate yhe business? ](https://i.redd.it/l2xswg9ulggd1.jpeg) , 2024-08-04-0912
```
Title says it all. Been incrementally saving and building this setup.

2x Xeon E5 2680v4 14c/28t
6x 16GB DDR4 2133Mhz
4x
 Tesla P40 24GB

The GPUs are powered by the server's (DL380 Gen9) risers for the first pair, and an externak Corsair 85
0W PSU for the second pair.

This machine was started back in the time when Vicuna was king and Llamma 2 was a distant d
ream.

The goal would have been to use something like Open assistant with  Langchain but tools like n8n and a more matur
e Langflow seem   more accessible due to the existing integrations.

The tasks? Pretty much anything that would helo str
eamline a Web Dev business, where the team of 3 would be able to focus on the work and not on chores. From simple things
 like 'check with Llama if this email is  support ticket and open one on the ERP'   to 'check  the billing for renewing 
invoices and prepare a draft reminder for the customers'

Any thoughts on how this hardware could be put to good use?

C
heers
```
---

     
 
all -  [ Needed a Resume review as i am Searching for internships but no luck.. ](https://www.reddit.com/r/developersIndia/comments/1ej3xqp/needed_a_resume_review_as_i_am_searching_for/) , 2024-08-04-0912
```
https://preview.redd.it/iahqwbuqfggd1.png?width=715&format=png&auto=webp&s=617a293a8ab1ae2eb3e27aa93bee214c4abb79dc

Any
 suggestions is appreciated!!
```
---

     
 
all -  [ Project 2 | Smarty Pantry | Difficulty Level 3 ](https://www.reddit.com/r/myHeadstarter/comments/1ej339z/project_2_smarty_pantry_difficulty_level_3/) , 2024-08-04-0912
```
# Smarty Pantry

[https://smartypantry.vercel.app](https://smartypantry.vercel.app/)

# Project Features

* **Inventory 
Management**: Track your pantry items efficiently with an easy-to-use CRUD app.
* **AI Based Recipe Suggestions**: Gener
ate recipes based on what you have in your pantry. See the Magic✨ Happening right before you!
* **Shopping List Integrat
ion**: Quickly add items, create and manage lists of required items.
* **Categorization**: Organize items into categorie
s for quick access and better organization.
* **User-Friendly Interface**: Enjoy a clean, intuitive design that simplifi
es inventory tracking.

# About the Project

Smarty Pantry is designed to streamline pantry management by keeping track 
of your food inventory, suggesting recipes, and reducing food waste. This project aims to make kitchen management easier
, better and more efficient.

# Skills Used

`Next.js` `React` `TailwindCSS` `Daisy UI` `Firebase` `Vercel` `OpenAI` `CI
/CD` `Material UI` `Langchain`



https://reddit.com/link/1ej339z/video/pybhptx08ggd1/player
```
---

     
 
all -  [ How do you upskill with practical assignments? ](https://www.reddit.com/r/LangChain/comments/1ej2l1w/how_do_you_upskill_with_practical_assignments/) , 2024-08-04-0912
```
How do you actually get practical skills/exposure to build llm based apps? 
I'm quite  new in the app development space 
amd have been playing with building a RAG based application for documentation. All well and good there...my question is 
now: what next?
What are other exercises to upskill and gain more exposure? Are there hackathons or small assignments? W
hat are you working on as a side project?

 
```
---

     
 
all -  [ How are u all validating responses in different formats from gpt? ](https://www.reddit.com/r/LangChain/comments/1ej1ef4/how_are_u_all_validating_responses_in_different/) , 2024-08-04-0912
```
My company started using  langchain and yaml templates to describe the response format to the prompts, issue is, the res
ponse sometime returns as unparsable yaml format.
And we have no good way of validating it
Aside from sending it again w
ith the error hoping it will fix it.
How do you go about handling the responses?
I heard json  responses are really popu
lar option but it's a bit restricting as you do not have comments in it so you can't really specify things like which fi
elds are optional or not and what is the desired return type for each field

```
---

     
 
all -  [ Can Anyone solve this error
 ](https://www.reddit.com/r/generativeAI/comments/1eizn1b/can_anyone_solve_this_error/) , 2024-08-04-0912
```
# [Getting ValueError: Missing some input keys: {'\\n '\_id''} in Langchain](https://stackoverflow.com/questions/7882838
1/getting-valueerror-missing-some-input-keys-n-id-in-langchain)

I am trying to generate MongoDB aggregation queries usi
ng LangChain with OpenAI's GPT-3.5. However, I am encountering a `ValueError` stating that some input keys are missing. 
 
[https://stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain](https://st
ackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain)
```
---

     
 
all -  [ Can Anyone solve this error  ](https://www.reddit.com/r/LangChain/comments/1eizloe/can_anyone_solve_this_error/) , 2024-08-04-0912
```
# [Getting ValueError: Missing some input keys: {'\\n '\_id''} in Langchain](https://stackoverflow.com/questions/7882838
1/getting-valueerror-missing-some-input-keys-n-id-in-langchain)

  
I am trying to generate MongoDB aggregation queries 
using LangChain with OpenAI's GPT-3.5. However, I am encountering a `ValueError` stating that some input keys are missin
g.  
[https://stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain](https:/
/stackoverflow.com/questions/78828381/getting-valueerror-missing-some-input-keys-n-id-in-langchain)


```
---

     
 
all -  [ AI agent marketplace – validate/refute this idea ](https://www.reddit.com/r/LangChain/comments/1eiqa8c/ai_agent_marketplace_validaterefute_this_idea/) , 2024-08-04-0912
```
I'm thinking about founding a marketplace of AI agents for developers.

As far as I know, there is currently no platform
 for creating and sharing agents: if I build an agent for,say, financial analysis of a fortune 500 company, the only way
 to share it would be to share the source code. Monetizing it would be extremely hard. On the other hand, if I want to u
se (multi)-agents to solve a particular problem, I need to create and maintain the code for all the agents, and I'll prb
ably be reinventing the wheel, as some of the agents would have been created by someone else before.

The idea is to cre
ate a platform where: 

1. Devs who create agents could turn them into APIs and easily monetize

 2. Devs who want to us
e (multi)-agents to automate complex worflows could pick the best agents for certain common tasks from the platform by s
imply calling the API, instead of having to maintain the code and infra to run them.

Kinda like GPT store but from deve
lopers to developers. Wdyt? Would you use this?


```
---

     
 
all -  [ Chatbot dev pure python with langchain ](https://www.reddit.com/r/LangChain/comments/1eilbh3/chatbot_dev_pure_python_with_langchain/) , 2024-08-04-0912
```
Hi. I'm new to langchain, literally was only able to learn how to create an llm through bedrock. I'm getting a feeling t
hat it would help me with the chatbot simulating a person we're developing rn but somehow I'm still not sold yet. Right 
now backend is running on Python (aws is accessed via boto3) including ways to fill out the variables in a template prom
pt. About four of the variables are supposed to have two to three sub events with equal chances being instructed to the 
LLM (e.g. equal chance to say 1. he found his wallet he lost yesterday and 2. he cannot find it anymore and he's letting
 go of it). I can code this with Python but I can imagine it would be hard to scale up if say there are already ten scen
arios of five variables. Is there any functionality of langchain framework that can help me with this?

Also, another qu
estion which is probably related or not to langchain as a solution. We are planning to append a whole ass transcript or 
two of what we expect the chat should go. Right now we have two whole transcripts on the main prompt. It seems like it's
 not giving us any issue right now but leads are saying two transcripts aren't enough and we should add more, about thre
e or four for each of the eight intents. Has anyone already tried appending transcripts to their main prompt for chatbot
 and had issues with hallucination? Is there any langchain stuff that could help us with this?

We are using Claude 3.5 
btw via bedrock.
```
---

     
 
all -  [ Can I use Ollama and langchain with api key ? ](https://www.reddit.com/r/LangChain/comments/1eihjbb/can_i_use_ollama_and_langchain_with_api_key/) , 2024-08-04-0912
```
Is there a way to use langchain and Ollama with  with an api key. Similar to how OpenAI works ?

Currently I have Ollama
 running and am able to set up a retrieval chain and query the llm but is there a way to query Ollama with langchain usi
ng an api key ? Cause currently any one on the network can just start using that resource. 
```
---

     
 
all -  [ need help Designing a Persistent Memory Feature for a Chatbot like the chatgpt memory feature ](https://www.reddit.com/r/LangChain/comments/1eigf6i/need_help_designing_a_persistent_memory_feature/) , 2024-08-04-0912
```
so I'm working on a chatbot and I'm trying to implement a feature similar to the memory system used in ChatGPT. 

Here's
 my current idea:

  Whenever the chatbot needs to store new information, it will first pass this data through a functio
n that assesses its similarity to existing memories stored in a vector database. This function will identify the most si
milar match. then, both the new information and the closest match will be fed into a secondary model. that generates a s
tructured object in my case a true or false to  determine whether the new information is truly unique or just a variant 
of what’s already stored. 

The outcome from this model will then dictate whether the i update a memory or insert a new 
one.  i tried just checking the cosine similarity between the embeddings but it was very inconsistent. i am also not kno
wledgeable in NLP so this was all i could think of. i'd like to know if this approach is overkill and if their is an eas
ier way?
```
---

     
 
all -  [ Document Storage in RAG solutions: separate or combined with Vector DB? ](https://www.reddit.com/r/LangChain/comments/1eibcqw/document_storage_in_rag_solutions_separate_or/) , 2024-08-04-0912
```
Hello.  
I'm working on implementing a RAG solution on AWS and I'm curious about best practices for document storage (ch
unks). I'd love to hear about your experiences and preferences.

Specifically, I'm wondering:

1. Do you keep your docum
ent chunks in the same database as your vectors, or do you use separate storage? like S3 object storage? in S3 case you 
need download chunks each time?
2. If you use separate storage, what solution do you prefer? (e.g., S3 buckets, document
 databases, etc.)
3. For those using combined storage, what vector databases are you using that handle this well? I'm pl
anning to use pg\_vector on PostgreSQL
4. How do you handle metadata and linking between vectors and original documents 
in your setup?
5. Any pitfalls or lessons learned you'd be willing to share?

I'm particularly interested in solutions t
hat scale well and remain cost-effective then document collection grows.
```
---

     
 
all -  [ How to return id from db ConvexVectoreStore.fromDocuments ](https://www.reddit.com/r/LangChain/comments/1eib3t3/how_to_return_id_from_db/) , 2024-08-04-0912
```
I use this code for write embeddings in my database:

    const res = await ConvexVectorStore.fromDocuments(splitDocs, e
mbeddings, { ctx });

Logic my app is - get id embedding from db and pass it in Langchain context . But i need get id my
 embeddings from db - variable res don\`t give me this info. How to do this?
```
---

     
 
all -  [ How to implement Weaviate with docker? ](https://www.reddit.com/r/LangChain/comments/1eia9w0/how_to_implement_weaviate_with_docker/) , 2024-08-04-0912
```
I am implementing Weaviate from yesterday with docker on langchain, its tough implementing   
Can anyone share some tuto
rials or is it better as compared to Qdrant
```
---

     
 
all -  [ Tool calling patterns: LangGraph ](https://www.reddit.com/r/LangChain/comments/1ei9rbi/tool_calling_patterns_langgraph/) , 2024-08-04-0912
```
# TLDR

What do you use?

1. Enums as tool parameter arguments
2. Arguments transposed as parameters with their value se
t to Boolean

# How to define a tool/function for LLM

While it is convenient to use the actual function/tool in your co
de to be sent as tool schema to the LLM and receive arguments, it might not be always be ideal. Here are two common exam
ples:

1. Tasks like conditional routing where reasoning is done by an LLM is more dependent on tool definition and less
 code logic.
2. Database Query filtering: The unreliable (multiple points of failure) Text-to-SQL/DSL workload of databa
ses with low complexity and expectations can be abstracted away with premade query with filter parameters of which, argu
ments will be computed by LLM.

How do you define such tools? I see two approaches.

1. Functions with parameter type as
 Enum, which confines the number of possible arguments for that parameter
2. Functions with possible arguments itself as
 parameters, and the actual arguments as boolean value.

Which approach as worked for you and your LLM/system? Are there
 any more things you would like to add?
```
---

     
 
all -  [ How to use AI to search for my stolen bike? ](https://www.reddit.com/r/OpenAI/comments/1ei7so3/how_to_use_ai_to_search_for_my_stolen_bike/) , 2024-08-04-0912
```
Just found out that my bicycle got stolen, most likely last night. I've made a report to the police about it, and search
ed through my neighbourhood. Now I want to try for myself to find it, such as by searching through all of the online mar
ketplaces for my bike, or possibly searching through video camera footage for it, or using a drone to look for it. I fou
nd some online tools for that do this but they don't cover the marketplaces in my area, so I was considering creating an
 AI agent via Langchain possily to do this with one of the new AI models. I haven't done much research or much thought i
nto it yet about what's actually possible, as I only noticed it today that the bike was stolen, so there may be somethin
g obvious that I haven't thought of.

Anyone have any ideas how I can create some kind of application with AI to search 
for my stolen bike?


```
---

     
 
all -  [ Reducing length of State in LangGraph ](https://www.reddit.com/r/LangChain/comments/1ei7fvd/reducing_length_of_state_in_langgraph/) , 2024-08-04-0912
```
Hello, I am building an AI assistant in langgraph and while one of the agents works very fast, the other has issues beca
use of 2 reasons: first one can't be solved as we do need gpt4 for it, while the previously mentioned agent runs on gpt3
.5 turbo, but the other reason is like to tackle is that for this agent, state messages build up very fast very long bec
ause of the amount of tools being used. Is there a way to compress the state or reduce state size to send less tokens to
 the model? Anyone knows?
```
---

     
 
all -  [ We need you! FOSS local machine LLM client ](https://www.reddit.com/r/opensource/comments/1ei640k/we_need_you_foss_local_machine_llm_client/) , 2024-08-04-0912
```
# Hello everyone!

My name is William, and I'm an Italian teenager passionate about computer science. I'm here to ask fo
r help developing my latest project, OpenLocalUI, a local LLM client. The project is based on Ollama and uses Flutter (D
art) for the UI and LangChain for LLM interaction (via a Python gRPC server).

But why work to yet another app to run LL
Ms on your PC, when there are already plenty of alternatives out there? Simple, **to do it better**! There is a somewhat
 paradoxical concept that expresses my goal:

>'Build open-source like closed-source.'

Most FOSS (Free and Open-Source 
Software) share the same issue; while offering powerful tools, the usage of those tools is often convoluted and hidden u
nder layers of poor UI and UX design, which is quite anachronistic! Nowadays, we have all the tools to build better expe
riences (and not just software) for users. It's time to refuse the idea that open-source software is a niche and work to
 help everyone embrace it.

Thanks for reading this far :)

So, did you get inspired? (I hope so!)

If the answer is yes
, take a look at the repository at this [link](https://github.com/WilliamKarolDiCioccio/open_local_ui). My collaborators
 and I will happily greet you on our team to help us build our vision.
```
---

     
 
all -  [ Having problems with filtering by metadata when using MongoDB ](https://www.reddit.com/r/LangChain/comments/1ei4yts/having_problems_with_filtering_by_metadata_when/) , 2024-08-04-0912
```
Hey everyone. I am trying to filter my documents by metadata. I was using ChromaDB and the code below was working just f
ine.

For basic\_retriever:

    basic_retriever = _vector_store.as_retriever(
        search_kwargs={
            'k': 
20,
            'filter': {
                '$and': [
                    {'speaker': {'$eq': 'Participant'}},
         
           {'participant': {'$eq': participant_id}},
                    {'part': {'$in': parts}}
                ]
    
        }
        }
    )

For self\_query\_retriever:

    self_query_retriever = SelfQueryRetriever.from_llm(
        
llm,
        _vector_store,
        metadata_field_info=metadata_field_info,
        document_contents='text',
        v
erbose=True,
        enable_limit=False,
        search_kwargs={
            'filter': {
                '$and': [
     
               {'speaker': {'$eq': 'Participant'}},
                    {'participant': {'$eq': participant_id}},
      
              {'part': {'$in': parts}}
                ]
            }
        },
        context_similarity='context',

    )

However. I had to migrate to MongoDB and the structure above does not work. I tried to follow documentation and d
id these:

For basic retriever:

    basic_retriever = _vector_store.as_retriever(
        search_kwargs={
            '
k': 20,
            'pre_filter': {
                '$and': [
                    {
                        'text': {
  
                          'path': 'speaker',
                            'query': 'Participant'
                        
}
                    },
                    {
                        'text': {
                            'path': 'pa
rticipant',
                            'query': participant_id
                        }
                    },
       
             {
                        'text': {
                            'path': 'part',
                           
 'query': {
                                '$in': parts
                            }
                        }
       
             }
                ]
            }
        }
    )

For self\_query\_retriever:

    self_query_retriever = 
SelfQueryRetriever.from_llm(
        llm,
        _vector_store,
        metadata_field_info=metadata_field_info,
      
  document_contents='text',
        verbose=True,
        enable_limit=False,
        search_kwargs={
            'pre_f
ilter': {
                '$and': [
                    {
                        'text': {
                            
'path': 'speaker',
                            'query': 'Participant'
                        }
                    },
 
                   {
                        'text': {
                            'path': 'participant',
              
              'query': participant_id
                        }
                    },
                    {
           
             'text': {
                            'path': 'part',
                            'query': {
              
                  '$in': parts
                            }
                        }
                    }
           
     ]
            }
        },
        context_similarity='context',
    )

But it does not work. I get the following e
rror:

    PlanExecutor error during aggregation :: caused by :: 'filter[0]' must be a boolean, objectId, number, string
, date, uuid, or null, full error: {'ok': 0.0, 'errmsg': 'PlanExecutor error during aggregation :: caused by :: 'filter[
0]' must be a boolean, objectId, number, string, date, uuid, or null', 'code': 8, 'codeName': 'UnknownError', '$clusterT
ime': {'clusterTime': Timestamp(1722587696, 1), 'signature': {'hash': b''\xb7\x80\xdbA\xc1o\xe0?\x91\xce\x9b\x7f\xbd\xe2
l\xe6\xfc', 'keyId': 7335879767352147970}}, 'operationTime': Timestamp(1722587696, 1)}

Also, I set my vector\_search\_i
ndex like that:

    {
      'fields': [
        {
          'numDimensions': 1536,
          'path': 'embedding',
     
     'similarity': 'cosine',
          'type': 'vector'
        },
        {
          'path': 'timestamp',
          't
ype': 'filter'
        },
        {
          'path': 'speaker',
          'type': 'filter'
        },
        {
       
   'path': 'context',
          'type': 'filter'
        },
        {
          'path': 'participant',
          'type':
 'filter'
        },
        {
          'path': 'metadata.part',
          'type': 'filter'
        }
      ]
    }

Ho
w do I properly filter my metadata?
```
---

     
 
all -  [ Is the poor performance of Gemini on Langchain caused by Langchain or Google? ](https://www.reddit.com/r/LangChain/comments/1ei45mq/is_the_poor_performance_of_gemini_on_langchain/) , 2024-08-04-0912
```
Not sure if I am the only one that notice this, but the performance of Gemini on Langchain has been highly unreliable, a
 few examples:

* Gemini's stream would often just stop midway without ever being completed (making Gemini mostly unusea
ble)
* Can't get the input/output token count after each Gemini API request

Is this a problem on Gemini's side or with 
the Langchain abstraction? Is there an estimated timeline that these issues can be solved?
```
---

     
 
all -  [ Different results with same prompt and LLM but different framework? ](https://www.reddit.com/r/LangChain/comments/1ei1nol/different_results_with_same_prompt_and_llm_but/) , 2024-08-04-0912
```
I am using an LLM that is a fine tuned version of Llama 3 on a cybersecurity dataset that recognises vulnerable code blo
cks and suggests steps to remediates the vulnerablities with fixed code. 

I tried the same LLM and prompt with LangChai
n and Llama CPP but I get different results from each of them. 

In Llama CPP, I get the suggested steps and fixed code 
block but with LangChain (using the Llama CPP abstraction), I get only the steps. 

The prompt format is Llama-Chat 2 an
d the prompt specifically says 'provide a code block that fixes the vulnerability'

```
---

     
 
all -  [ Does anyone have resources to build a Google Gemini agent that can use tools? ](https://www.reddit.com/r/LangChain/comments/1ei08g7/does_anyone_have_resources_to_build_a_google/) , 2024-08-04-0912
```
I think the resources I am coming across are outdated as it says bind_tools not found.
```
---

     
 
all -  [ Using RAG to choose tools vs agents, which is better choices? If accuracy matters ](https://www.reddit.com/r/LangChain/comments/1ehyf74/using_rag_to_choose_tools_vs_agents_which_is/) , 2024-08-04-0912
```
Let's say I have 50 website API endpoints to get the data, and I am going to wrap them inside 50 agents... I'm not sure 
if this is the right way to do, as I'm afraid the agent will possibly messed up when the API endpoints keep growing...


Instead, I am thinking if I could RAG on tools to be used based on the user query, and then trigger those function tool 
based the output returned by RAG... Is this something feasible and perhaps more scalable than agents?

I'm not that sure
 the scalability of agents when there is a lot of data endpoints to access with. Hope for help, thanks.
```
---

     
 
all -  [ Where are you running Langchain in your production apps? (serverless / on the client / somewhere els ](https://www.reddit.com/r/LangChain/comments/1ehwzcr/where_are_you_running_langchain_in_your/) , 2024-08-04-0912
```
I have my existent backend set up as a bunch of serverless functions at the moment (cloudflare workers). I wanted to set
 up a new \`/chat\` endpoint as just another serverless function which uses langchain on the server. But as I get deep i
nto the code I'm not sure if it makes sense to do it this way...

Basically if I have Langchain running on this endpoint
, since servelerless functions are stateless, that means each time the user sends a new message I need to fetch the chat
 history from the database, load it into context, process the request (generate the next response) and then tear it all 
down only to have to build it all up again with the next request. Since there is also no persistent connection.

This al
l seems a bit wasteful in my opinion. If I host langchain on the client I'm thinking I can avoid all this extra work sin
ce the langchain 'instance' will stay put for the duration of the chat session. Once the long context is loaded in memor
y I only need to add new messages to it vs redoing the whole thing which can get very taxing for loooong conversations.


But I would prefer to handle it on the server side to hide the prompt magic 'special sauce' if possible...  
  
How are
 ya'll serving your langchain apps in production?
```
---

     
 
all -  [ RAG with prior knowledge or reference to follow ](https://www.reddit.com/r/LangChain/comments/1ehwxbh/rag_with_prior_knowledge_or_reference_to_follow/) , 2024-08-04-0912
```
So the main idea is that given logs I need RAG to get answers to analyse them. The LLM model works well here upto a leve
l of base knowledge it has been pretrained on. Now I want the answers to be more accurate. So I have a couple of templat
e info and domain knowledge like:  


    Brief scenarios for Registration Cases
    1. 
       -  Registration always b
egins with  REGISTER msg.
       -  REGISTER message is one of the most important message in  protocol and it contains a
 lot of important information in it. Unterstanding the meaning of each parameters in registration would help you greatly
 with various troubleshooting situation. Followings are some of the examples of REGISTER message you may see in the fiel
d. Keep reading this page as often as possible until you become very familiar with all the details of the contents.
    
Blah Blah ....

Now I can give parts of these in the prompts for RAG. (Note: here the vector store contains embeddings o
f my logs). Now the reference gets larger and larger and more sophisticated. I am looking for alternate ways to make sur
e RAG references this domain info before it answers questions on the log vector store. So I can keep expanding this docu
ment of domain knowledge to refer to, and RAG analyses logs based on this domain knowledge.   

```
---

     
 
all -  [ LangChain or Ollama ](https://www.reddit.com/r/LanguageTechnology/comments/1ehufh2/langchain_or_ollama/) , 2024-08-04-0912
```
I'm very new to the field and still trying to get my bearings.

I'm working on a RAG-like application in Python. I chose
 Python because I reasoned that any AI or data science practitioners who join the team are likely to be more familiar wi
th it than a lower-level language.

I believe that my application will benefit from GraphRAG (or its SciPhi Triplex anal
ogue), so I've started transitioning it from its current conventional RAG approach.

Which would be better for this purp
ose--LangChain or Ollama? My current approach uses Ollama for text generation (with my own code handling all of the embe
dding vector elements rather than relying on a vector DB), but I feel that the greater complexity of GraphRAG would bene
fit from the flexibility of LangChain.
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses  ](https://www.reddit.com/r/udemyfreebies/comments/1ehtqj2/list_of_free_and_best_selling_discounted_courses/) , 2024-08-04-0912
```
# Udemy Free Courses for 02 August 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the c
ourses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12242/)AWS Certified Cloud Practitioner
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12229/)NEW AWS Cloud Technology Masterclass
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/12230/)AWS CodePipeline: DevOps CI/CD Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
12231/)Become an AWS Certified Data Engineer
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12232/)Azure Data Engin
eering-Master 6 Real-World Projects
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12233/)ChatGPT for Python Data S
cience and Machine Learning
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12234/)Azure Architect Technologies
* [R
EDEEM OFFER ](https://idownloadcoupon.com/udemy/12235/)AZ-305 – Designing Azure Infrastructure Solutions
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/12236/)Microsoft Excel – Excel from Beginner to Intermediate Level
* [REDEEM OFFER 
](https://idownloadcoupon.com/udemy/12237/)Mastering Figma from 0 to 100 (UI/UX Mastery Course)
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/12238/)Complete Machine Learning,NLP Bootcamp MLOPS & Deployment
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12239/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12240/)Drive Real Traffics to your site using Google ,Twitter,Linkd
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12241/)Ultimate Design Patterns
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12243/)Digi
tal Marketing That Drive Massive Results to Your Service
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12244/)How 
To Make Money Everyday Using AI ChatGPT /Fiverr.
* Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM O
FFER](https://idownloadcoupon.com/udemy/12245/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12227/)Professional 
Diploma in Office Administration Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12226/)How To Use R Prog
ramming for Research
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12225/)Score Full Mark in (P3O®) Foundation Exa
m – Axelos
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12224/)TA-002: HashiCorp Terraform Practice Test – 2024
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12223/)Professional Diploma in Digital Products Management
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12222/)Score 5 Above target in PMI-SP®Exam
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/12221/)Scoring 5 Above target (PMI-RMP)® Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12220
/)Cloud Engineer (Google) Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12219/)JN0-104: Junip
er Networks Internet Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12218/)200-301: Cisco (CCN
A) Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12217/)No-Code Machine Learning Using Amazon
 AWS SageMaker Canvas
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11446/)Cómo Crear una Campaña de Email Marketi
ng Efectiva 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11298/)Learn UI UX Design Adobe XD : Learn User Exp
erience Design
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12189/)How to turn your IDEA into a BUSINESS that thr
ives!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7320/)Facebook Ads Marketing In Hindi/Urdu 2023
* Fast track F
rench for beginners
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/10791/)
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11488/)Universidad de Elementor Pro, ¡Desde Cero Hasta Experto!
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/9697/)Microsoft Azure: Hands On Training: AZ-900 AZ-104 and AZ-305
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/45/)PHP for Beginners: PHP Crash Course 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9296/)C-level man
agement: 100 models for business success
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11487/)Mastering Email Deli
verability: The Comprehensive Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10785/)Sales operations: strateg
ies and frameworks for selling more
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1100/)Google Ads Mastery\~ Begin
ner To Pro \~ HINDI/URDU 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12214/)Cómo Usar el Creador de Sitios 
Web con IA de Hostinger 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12215/)Facebook Ads
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/12213/)Certified Kubernetes Application Developer (CKAD) – Exams
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/12212/)Learn Camtasia Video Editing Masterclass Professional
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/12211/)PowerPoint Präsentationen mit KI ChatGPT erstellen
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/12210/)Professional Diploma in Project Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12209
/)CISSP: Information Systems Security Practice Test 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12208/)CISM
: Information Security Manager Practice Test – 2024
* C100DBA: MongoDB Practice Test – 2024
* [REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/12207/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12206/)Amazon Afiliados: Cómo Crear u
na Página Web de Nicho 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12205/)Professional Diploma in Corporate
 Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12204/)Python Project: Build a PDF File Handling Tool fr
om Scratch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12203/)AI for Business Strategy
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/11877/)Build, Host & Manage WordPress Websites using AI \[10Web\]
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/6763/)Become a Successful Affiliate Marketer \[Success Blueprint\]
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/4841/)Become a Successful SEO Freelancer & Start Online Businesses
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/6762/)Build Profitable E-Commerce Stores with WordPress & Woostify
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/6754/)AI x ChatGPT for Productivity 101 \[Masterclass\]
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/6750/)AI for Bloggers: SEO, Content Writing & Optimization
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6766/)Build a Profitable Online Courses Business \[Complete Guide\]
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6649/)Complete Microsoft Word Excel PowerPoint Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8692/)AI Vide
o Creation Course 2024: Generate Videos using AI
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1095/)Marketing en 
Facebook Ads – Leads /Clientes Potenciales 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12202/)AZ-900: Azure
 Fundamentals Practice Test – 2024
* CISSP: Information System Security Practice Test 2024
* [REDEEM OFFER](https://idow
nloadcoupon.com/udemy/12201/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12200/)Complete Ethical Hacking Master
class: Go from Zero to Hero
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12199/)550 Unix Interview Questions Prac
tice Test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12198/)Build, Train
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/12197/)CRISC: Risk and Information Systems Practice Test -2024
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/12196/)MO-201: Microsoft Excel Practice Test (Off 2019) – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/12195/)PCEP (30-02): Entry-Level Python Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/121
94/)SY0-501: CompTIA Security Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12193/)1Z0-071: O
racle Database SQL Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12192/)DA-104: Tableau Deskt
op Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12191/)Executive Diploma in General Manageme
nt
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5084/)2024 Google Cloud Digital Leader Certification practice Exa
m

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://www.reddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses  ](https://www.reddit.com/r/udemyfreeebies/comments/1ehtqck/list_of_free_and_best_selling_discounted_courses/) , 2024-08-04-0912
```
# Udemy Free Courses for 02 August 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the c
ourses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12242/)AWS Certified Cloud Practitioner
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12229/)NEW AWS Cloud Technology Masterclass
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/12230/)AWS CodePipeline: DevOps CI/CD Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
12231/)Become an AWS Certified Data Engineer
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12232/)Azure Data Engin
eering-Master 6 Real-World Projects
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12233/)ChatGPT for Python Data S
cience and Machine Learning
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12234/)Azure Architect Technologies
* [R
EDEEM OFFER ](https://idownloadcoupon.com/udemy/12235/)AZ-305 – Designing Azure Infrastructure Solutions
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/12236/)Microsoft Excel – Excel from Beginner to Intermediate Level
* [REDEEM OFFER 
](https://idownloadcoupon.com/udemy/12237/)Mastering Figma from 0 to 100 (UI/UX Mastery Course)
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/12238/)Complete Machine Learning,NLP Bootcamp MLOPS & Deployment
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12239/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12240/)Drive Real Traffics to your site using Google ,Twitter,Linkd
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12241/)Ultimate Design Patterns
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12243/)Digi
tal Marketing That Drive Massive Results to Your Service
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12244/)How 
To Make Money Everyday Using AI ChatGPT /Fiverr.
* Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM O
FFER](https://idownloadcoupon.com/udemy/12245/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12227/)Professional 
Diploma in Office Administration Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12226/)How To Use R Prog
ramming for Research
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12225/)Score Full Mark in (P3O®) Foundation Exa
m – Axelos
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12224/)TA-002: HashiCorp Terraform Practice Test – 2024
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12223/)Professional Diploma in Digital Products Management
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12222/)Score 5 Above target in PMI-SP®Exam
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/12221/)Scoring 5 Above target (PMI-RMP)® Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12220
/)Cloud Engineer (Google) Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12219/)JN0-104: Junip
er Networks Internet Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12218/)200-301: Cisco (CCN
A) Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12217/)No-Code Machine Learning Using Amazon
 AWS SageMaker Canvas
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11446/)Cómo Crear una Campaña de Email Marketi
ng Efectiva 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11298/)Learn UI UX Design Adobe XD : Learn User Exp
erience Design
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12189/)How to turn your IDEA into a BUSINESS that thr
ives!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7320/)Facebook Ads Marketing In Hindi/Urdu 2023
* Fast track F
rench for beginners
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/10791/)
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11488/)Universidad de Elementor Pro, ¡Desde Cero Hasta Experto!
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/9697/)Microsoft Azure: Hands On Training: AZ-900 AZ-104 and AZ-305
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/45/)PHP for Beginners: PHP Crash Course 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9296/)C-level man
agement: 100 models for business success
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11487/)Mastering Email Deli
verability: The Comprehensive Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10785/)Sales operations: strateg
ies and frameworks for selling more
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1100/)Google Ads Mastery\~ Begin
ner To Pro \~ HINDI/URDU 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12214/)Cómo Usar el Creador de Sitios 
Web con IA de Hostinger 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12215/)Facebook Ads
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/12213/)Certified Kubernetes Application Developer (CKAD) – Exams
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/12212/)Learn Camtasia Video Editing Masterclass Professional
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/12211/)PowerPoint Präsentationen mit KI ChatGPT erstellen
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/12210/)Professional Diploma in Project Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12209
/)CISSP: Information Systems Security Practice Test 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12208/)CISM
: Information Security Manager Practice Test – 2024
* C100DBA: MongoDB Practice Test – 2024
* [REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/12207/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12206/)Amazon Afiliados: Cómo Crear u
na Página Web de Nicho 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12205/)Professional Diploma in Corporate
 Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12204/)Python Project: Build a PDF File Handling Tool fr
om Scratch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12203/)AI for Business Strategy
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/11877/)Build, Host & Manage WordPress Websites using AI \[10Web\]
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/6763/)Become a Successful Affiliate Marketer \[Success Blueprint\]
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/4841/)Become a Successful SEO Freelancer & Start Online Businesses
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/6762/)Build Profitable E-Commerce Stores with WordPress & Woostify
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/6754/)AI x ChatGPT for Productivity 101 \[Masterclass\]
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/6750/)AI for Bloggers: SEO, Content Writing & Optimization
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6766/)Build a Profitable Online Courses Business \[Complete Guide\]
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6649/)Complete Microsoft Word Excel PowerPoint Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8692/)AI Vide
o Creation Course 2024: Generate Videos using AI
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1095/)Marketing en 
Facebook Ads – Leads /Clientes Potenciales 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12202/)AZ-900: Azure
 Fundamentals Practice Test – 2024
* CISSP: Information System Security Practice Test 2024
* [REDEEM OFFER](https://idow
nloadcoupon.com/udemy/12201/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12200/)Complete Ethical Hacking Master
class: Go from Zero to Hero
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12199/)550 Unix Interview Questions Prac
tice Test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12198/)Build, Train
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/12197/)CRISC: Risk and Information Systems Practice Test -2024
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/12196/)MO-201: Microsoft Excel Practice Test (Off 2019) – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/12195/)PCEP (30-02): Entry-Level Python Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/121
94/)SY0-501: CompTIA Security Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12193/)1Z0-071: O
racle Database SQL Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12192/)DA-104: Tableau Deskt
op Practice Test – 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12191/)Executive Diploma in General Manageme
nt
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5084/)2024 Google Cloud Digital Leader Certification practice Exa
m

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ Open Source RAG - best for production? ](https://www.reddit.com/r/LangChain/comments/1ehtdhs/open_source_rag_best_for_production/) , 2024-08-04-0912
```
Hello everyone,

I am currently looking at some opensource RAG such as Langchain and Llama index. Quite like Llama index
 but it does not seem suitable for production. I did not find the capability of doing batch inference especially for ret
rieving the closest chunks for a batch of query. (so lack of scalability here)  
Langchain seems to have this feature (c
orrect me if I am wrong but they are extracting the embeddings of queries by batch and not using multiple workers => one
 embedding model call instead of N call if we have N queries)

I was wondering if there are others open source RAG worth
 for production other than langchain allowing:

* Vector Store
* Chunking & Document upload of different type (pdf, docx
, raw text etc)
* scalability (such as batch for queries => embedding model call made by batch)
* flexible about choosin
g the embedding model (HF, OpenAI etc)
* good feature about the retriever such as filtering from metadata
* good postpro
cess function (or possibility to add custom function) such as chunk merging etc

Thanks for the help!
```
---

     
 
all -  [ How can I run Video-LLaMa ? ](https://www.reddit.com/r/LangChain/comments/1ehsukn/how_can_i_run_videollama/) , 2024-08-04-0912
```
Could someone show me how I can use [https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned](https://huggingface.
co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned) with Python, please? I am still a beginner. Thank you to those who take the t
ime to answer my question.
```
---

     
 
all -  [ Resume Review ](https://www.reddit.com/r/resumes/comments/1ehpbyu/resume_review/) , 2024-08-04-0912
```
# Please Roast my Resume in Detail. Looking for SDE and MLE roles. I am trying for Full time.
Have received over 450+ re
jections for internships with no interviews currently working a volunteer role 

https://preview.redd.it/yhw5ezjks3gd1.p
ng?width=737&format=png&auto=webp&s=5e3aabd529c431fb31d0d47fe25ee0f9799ef1e2


```
---

     
 
all -  [ Where to store vectors? ](https://www.reddit.com/r/LangChain/comments/1ehpb1d/where_to_store_vectors/) , 2024-08-04-0912
```
When you build RAG, where do you store all the vectors? 

I am using Postgres + pg_vector, and just storing the vectors 
in the same DB as the rest of my application data. It is convenient and works well with my toolchain.

But I also heard 
(without explanation) that it is better to use a separate database for vectors. 

Is this true? Any thoughts on why? Doe
s another Postgres database on the same instance “count”? 
```
---

     
 
all -  [ LangGraph Studio is amazing ](https://www.reddit.com/r/LangChain/comments/1ehp7h5/langgraph_studio_is_amazing/) , 2024-08-04-0912
```
[LangGraph Studio: The first agent IDE (youtube.com)](https://www.youtube.com/watch?v=pLPJoFvq4_M) -- check this out.

J
ust a week back, I was thinking of developing a web app kind of interface for langgraph, and they just launched it. Now,
 what if there were a drag-and-drop-like application for creating a complex graph chain?
```
---

     
 
all -  [ Allowing a real person to 'take over' the conversation? ](https://www.reddit.com/r/LangChain/comments/1ehmxa9/allowing_a_real_person_to_take_over_the/) , 2024-08-04-0912
```
Is anyone working on Conversational technology that allows a third  person to 'take over' the conversation, given the an
swer relevancy confidence is low, with a RAG pipeline?
```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-08-04-0912
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
MachineLearning -  [ [D] Is Anyone Else Setting Up Real-Time Django Workers for their AI Application? What's the best way ](https://www.reddit.com/r/MachineLearning/comments/1e0qens/d_is_anyone_else_setting_up_realtime_django/) , 2024-08-04-0912
```
We completely underestimated this one tbh, thought it would be much more straight forward. But we've done it now and doc
umented how step by step [in this article series](https://medium.com/p/5828a1ea43a3).

A bit of context, we're building 
a mini free AI Agent that auto-generates manually customisable plots, so the user can basically style however they want.
 It needs to be cost effective and efficient, so we thought about how to do it and tested a couple other ways.

https://
preview.redd.it/cmly0a6bhwbd1.png?width=640&format=png&auto=webp&s=be1f5b2853e744adcaf8013e6d43b43f6be89617

We plan on 
releasing the project open source, so all feedback welcome! Is anyone else doing this and has any feedback? or do know o
f a better way to do it?
```
---

     
 
MachineLearning -  [ [P] Real Time AI Workers Web Application ](https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/) , 2024-08-04-0912
```
Hi everyone!

I've created a mini series on how to build a real time AI application using Django, LangChain and Celery.


Free knowledge - posting it in here for anyone working on something similar and had the same blockers I had when buildi
ng.

Let me know what you think on how I could potentially improve this architecture.

Part 1

[https://medium.com/towar
dsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79](https://medium.
com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79)

Part 
2

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5
828a1ea43a3](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time
-django-5828a1ea43a3)

Part 3

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-red
is-docker-real-time-django-8e73c7b6b4c8](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-cha
nnels-redis-docker-real-time-django-8e73c7b6b4c8)

Part 4

[https://medium.com/towardsdev/how-to-set-up-django-from-scra
tch-with-celery-channels-redis-docker-real-time-django-c090c300517a](https://medium.com/towardsdev/how-to-set-up-django-
from-scratch-with-celery-channels-redis-docker-real-time-django-c090c300517a)

Part 5  
[https://medium.com/@cubode/how-
to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c](https://medium.com/@cubod
e/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c)
```
---

     
