 
all -  [ Any idea how to create a search engine like MyMind? ](https://www.reddit.com/r/LangChain/comments/1h9vo1s/any_idea_how_to_create_a_search_engine_like_mymind/) , 2024-12-09-0914
```
[https://mymind.com/](https://mymind.com/) I tried hybrid search approaches but they don't work well with one or two wor
d searches... 
```
---

     
 
all -  [ Has anyone come across any open-source projects for chatbots that handle data from API responses?  ](https://www.reddit.com/r/LangChain/comments/1h9pq6r/has_anyone_come_across_any_opensource_projects/) , 2024-12-09-0914
```

```
---

     
 
all -  [ How do you guys setup the folder structure  ](https://www.reddit.com/r/LangChain/comments/1h9mwqi/how_do_you_guys_setup_the_folder_structure/) , 2024-12-09-0914
```
Hey, guys, I am new to using Langchain. I understand the stuff, but I couldn't create a proper folder structure to break
 down my code. Currently, my code is in single files with hundreds of lines of code. Please help me integrate it with yo
ur backend. It would be good if anyone with Javascript show me their repo screenshot or share some example reports. Than
k you in advance.

https://preview.redd.it/tpfh0jpiln5e1.png?width=512&format=png&auto=webp&s=d43b8b68fba6e113af0ec37435
9e5b74dd9a841f


```
---

     
 
all -  [ [For Hire] Experienced Web Application Developer ](https://www.reddit.com/r/forhire/comments/1h9mpja/for_hire_experienced_web_application_developer/) , 2024-12-09-0914
```
Hi, I'm a Python/Javascript developer who can help you build or maintain an existing app.

I have experience in the foll
owing technologies:

- Python
- Django
- FastAPI
- Flask
- Javascript
- TypeScript
- ReactJS
- AlpineJS
- HTMX
- SQL
- A
nsible
- Docker
- Linux
- LlamaIndex
- Langchain

You can find my open source contributions on [my Github profile](https
://github.com/confuzeus. I also publish tech related articles on [my website](https://joshkaramuth.com).

## Availabilit
y

I'm currently located in [Mauritius](https://en.wikipedia.org/wiki/Mauritius), which is GMT+4 timezone-wise. I do asy
nchronous work in my own timezone but willing to join you in meetings in your own timezone. I'm comfortable in most US a
nd European timezones.

I'm interested in long-term engagements.

**My hourly rate is $50 (USD).**

Send me a message wi
th details about yourself and your project and let's schedule a call if there's a potential fit.
```
---

     
 
all -  [ Best Way to Learn LangChain and LangGraph from Scratch? ](https://www.reddit.com/r/LangChain/comments/1h9lnmt/best_way_to_learn_langchain_and_langgraph_from/) , 2024-12-09-0914
```
Hey Reddit! üëã

I‚Äôm looking for advice on the best way to learn LangChain and LangGraph from the beginning. I have some e
xperience with GenAI and Transformers and played around with Haystack last year, but now I want to start fresh and build
 a solid foundation in LangChain and LangGraph.

Here‚Äôs a bit about my background:

* Familiar with GenAI concepts and T
ransformer models.
* Used Haystack briefly for question-answering and document processing.
* Comfortable with Python and
 libraries like Hugging Face, but I wouldn‚Äôt call myself an expert.

My goals are:

1. To understand the core concepts a
nd architecture of LangChain and LangGraph.
2. To learn how to build end-to-end AI applications with these tools (e.g., 
chatbots, retrieval-augmented generation, etc.).
3. To get hands-on experience through tutorials, projects, or practice 
exercises.

If you‚Äôve been on this learning path, I‚Äôd love to know:

* **What resources should I start with?** (docs, tu
torials, videos, courses, etc.)
* Are there any beginner-friendly project ideas to practice what I learn?
* Tips for com
bining LangChain with other tools like Vector DBs, OpenAI APIs, or custom data sources?

Thanks in advance for sharing y
our knowledge and recommendations! üôè
```
---

     
 
all -  [ How to sequentially call tools in LangGraph ](https://www.reddit.com/r/LangChain/comments/1h9kano/how_to_sequentially_call_tools_in_langgraph/) , 2024-12-09-0914
```
Currently working on a PoC with multiple agents calling a database and one of these agents is a Text2SQL which can call 
3 tools:

* Tool1: find relevant tables pertaining to a users query (requires user's input)
* Tool2: calculate the cost 
of a generated sql query by the agent (requires sql query as input and outputs a number)
* Tool3: execute the sql query 
(requires cost and sql query as input)

  
I explicitly added in the descriptions of tools 2 and 3 that if Tool3 is call
ed then it needs the output of Tool2 in order to be called but it never ends up calling Tool2 despite calling Tool3. Not
 sure how I can go about sequentially programming tools or prompt engineering it to do so 
```
---

     
 
all -  [ A LangGraph AI agent designed to test and verify LangGraph AI agents ](https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true) , 2024-12-09-0914
```
üéâ Super excited to share The Systems Inspector, the 3rd place winner from the hackathon I ran with LangChain! üöÄ

This br
illiant implementation uses AI to test AI, tackling issues like edge cases, security vulnerabilities, and user experienc
e gaps before they become real problems.

üõ†Ô∏è Here‚Äôs What It Does:
- Maps and analyzes AI system architectures
- Creates 
specialized AI testers to handle unique challenges
- Provides actionable insights and recommendations

üìñ Full Details:
t
he blog post attached contains: 
- The full description and motivation behind this agent
- A link to the complete code i
mplementation
- A YouTube video walking through how it works
```
---

     
 
all -  [ Looking for a Developer (m/f/d) for AI-Powered Training Planning in Football ](https://www.reddit.com/r/LangChain/comments/1h9gmel/looking_for_a_developer_mfd_for_aipowered/) , 2024-12-09-0914
```
Hi,  
We are a small start-up currently in the market research phase, exploring which products can deliver the most valu
e to the football market. Our focus is on innovative solutions using artificial intelligence ‚Äì particularly for smarter 
training planning to optimize player development and coaching efficiency.

I‚Äôm currently working on a prototype that lev
erages AI and Python to assist coaches in creating individualized, data-driven training plans. The goal is to make train
ing sessions more efficient and tailored to the needs of players, helping clubs of all sizes achieve their full potentia
l. I‚Äôm looking for someone with experience in AI development, training optimization, or related areas to exchange ideas 
on technical approaches and potential challenges:

* **How can AI-driven training plans be implemented most effectively?
**
* **What kind of data and models would deliver the greatest value to coaches?**
* **What logical steps can we take to
 develop this concept further?**

If this evolves into a collaboration, that would be amazing ‚Äì but for now, the focus i
s on consultation and idea sharing.

**About me:**  
I have 7 years of experience working in football clubs in Germany, 
including roles as a youth coach and video analyst, and I‚Äôm well-connected in Brazil. I split my time between Germany an
d Brazil. With a background in Sports Management and experience as a freelancer specializing in generative AI (GenAI) fo
r HR and recruiting, I‚Äôm passionate about applying AI to solve real challenges in football and player development.

**La
nguages:**  
Communication can be in English, German, or Portuguese.

**If you‚Äôre passionate about football, AI, and sha
ping the future of training, let‚Äôs connect!** I‚Äôd love to hear your ideas and see how we can work together to bring smar
ter training solutions to the game.
```
---

     
 
all -  [ Beginners Real world projects? ](https://www.reddit.com/r/learnmachinelearning/comments/1h9f71k/beginners_real_world_projects/) , 2024-12-09-0914
```
I love learning by doing and want to really get into ML. I know already some theory and have worked with PyTorch, Huggin
g face, Scikit learn, langchain, plotly, pandas and Numpy. Now I really want to create an actual useful project which is
 not just some cookie cutter tutorial project. I already followed some cookie cutter tutorial projects with using YOLO f
or object detection and also one with BERT from huggingface, however these projects were basically like ‚Äútake this ready
 made model and train it with data and you‚Äôre done‚Äù which was really boring.   
  
I‚Äôd like some projects where I have t
o go deep into AI and not just using Someone‚Äôs premade model with my own data. What recommendations do you have?
```
---

     
 
all -  [ What are my options for using a local LLM on a 5-year-old i5 laptop with 32GB RAM? ](https://www.reddit.com/r/LocalLLM/comments/1h9eeyv/what_are_my_options_for_using_a_local_llm_on_a/) , 2024-12-09-0914
```
Hello everyone,

I‚Äôm new to working with local LLMs. So far, I‚Äôve been using Azure‚Äôs powerful LLMs alongside LangChain f
or interactions. However, I‚Äôd like to explore, learn, and use local LLMs with LangChain on my own setup.

The challenge 
is that I‚Äôm running an i5 processor on a 5-year-old laptop with 32GB of RAM. My primary goal is to use the LLM for tasks
 such as answering questions from PDFs and websites. Additionally, I‚Äôd like to explore generating simple property code i
n plain English.

What local LLM options are suitable for my hardware, and how can I get started?  
Thanks 
```
---

     
 
all -  [ Is there a more modern approach to this issue? ](https://www.reddit.com/r/LangChain/comments/1h9e9g8/is_there_a_more_modern_approach_to_this_issue/) , 2024-12-09-0914
```
I've been desperately trying to find a solution to my issue:

For context: I want to create a vectorstore DB for a chatb
ot web app I'm making and am unable to do so due to supposed 'outdated' API's. 

  
I have a script here which automatic
ally repalces the current PDF file (for the AI to read through) and then create a vectorStore db based on it:



    con
st { OpenAIEmbeddings } = require('@langchain/openai');
    const { HNSWLib } = require('@langchain/community/vectorstor
es/hnswlib');
    const {VectorDBQAChain} = require('langchain/chains')
    const fs = require('fs')
    const path = re
quire('path');
    
    let currentPdf = null;
    const PDF_PATH = 'temp/vectorDb.pdf';
    
    const Pdf = require('.
/schemas/baseSchemas/PDF_File');
    const { RecursiveCharacterTextSplitter } = require('langchain/text_splitter');
    

    async function stageFile(id, chain) {
    ¬† ¬† const file = await Pdf.findOne({ _id: id._id });
    
    ¬† ¬† if (!fi
le) {
    ¬† ¬† ¬† ¬† console.log('File not found');
    ¬† ¬† ¬† ¬† return;
    ¬† ¬† }
    
    ¬† ¬† if (currentPdf && currentPdf
._id.equals(file._id)) {
    ¬† ¬† ¬† ¬† console.log('File is the same as currentPdf, no action needed.');
    ¬† ¬† } else {

    ¬† ¬† ¬† ¬† currentPdf = file;
    ¬† ¬† ¬† ¬† const pdfPath = path.join(__dirname, 'temp', 'vectorDb.pdf');
    ¬† ¬† ¬† ¬† fs.
writeFileSync(pdfPath, file.pdfFile.data);
    ¬† ¬† ¬† ¬† console.log('Configured temp/vectorDb.pdf to the new file.');
   
 ¬† ¬† }
    ¬† ¬† const text = fs.readFileSync(PDF_PATH, 'utf8')
    ¬† ¬† const textSplitter = new RecursiveCharacterTextSpl
itter({chunkSize : 1000})
    ¬† ¬† const docs = await textSplitter.createDocuments([text])
    ¬† ¬† const vectorStore = aw
ait HNSWLib.fromDocuments(docs, new OpenAIEmbeddings());
    ¬† ¬† const newChain = VectorDBQAChain.fromLLM(chain.model, v
ectorStore)
    ¬† ¬† return newChain
    }
    
    
    
    module.exports = { stageFile };
    

  
Does anyone have a
ny ideas how to implement a more modern version of this?

  
Thank you.


```
---

     
 
all -  [ Looking for Advanced LangChain Tutorials on YouTube ](https://www.reddit.com/r/LangChain/comments/1h9digf/looking_for_advanced_langchain_tutorials_on/) , 2024-12-09-0914
```
Hello everyone,  
I‚Äôve completed some basic tutorials on LangChain with Python, and I‚Äôm eager to explore more advanced t
opics. My end goal is to create a system that can take free-form language input and convert it into a structured script 
for a specific purpose, which will be my first project.

However, I feel that I need to deepen my understanding of LangC
hain before tackling this. I would be extremely grateful if you could recommend any updated advanced tutorials or resour
ces to help me improve.

Thank you so much!
```
---

     
 
all -  [ Llama 3.1 output not truncating ](https://www.reddit.com/r/learnmachinelearning/comments/1h9cxjx/llama_31_output_not_truncating/) , 2024-12-09-0914
```
Hi.  
I am trying to launch a chatbot using llama 3.1 and langchain. Huggingfacepipeline is from langchain\_huggingface 
library. I am generating the text using llm.invoke(prompt) method. When I run the code, it gives¬†**Setting \`pad\_token\
_id\` to \`eos\_token\_id\`:None for open-end generation.**¬†and the output is not stopping even when I set max\_new\_tok
ens to a high number. Can anyone explain to me why the output is not stopping

    model_path = 'hf_llama/llama_8B'
    

    def load_model(model_path):
    ¬† ¬† tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    ¬† ¬† model = Auto
ModelForCausalLM.from_pretrained(
    ¬† ¬† ¬† ¬† model_path,
    ¬† ¬† ¬† ¬† device_map='auto',
    ¬† ¬† ¬† ¬† torch_dtype=torch.f
loat16,
    ¬† ¬† )
    
    ¬† ¬† pipe = pipeline(
    ¬† ¬† ¬† ¬† 'text-generation',
    ¬† ¬† ¬† ¬† model=model,
    ¬† ¬† ¬† ¬† toke
nizer=tokenizer,
    ¬† ¬† ¬† ¬† torch_dtype=torch.float16,
    ¬† ¬† ¬† ¬† device_map='auto',
    ¬† ¬† ¬† ¬† do_sample=True,
    ¬†
 ¬† ¬† ¬† top_k=50,
    ¬† ¬† ¬† ¬† top_p=0.9,
    ¬† ¬† ¬† ¬† num_return_sequences=1,
    ¬† ¬† ¬† ¬† eos_token_id=tokenizer.eos_token
_id,
    ¬† ¬† ¬† ¬† # max_length=400,
    ¬† ¬† ¬† ¬† temperature=0.9,
    ¬† ¬† ¬† ¬† max_new_tokens=500
    ¬† ¬† )
    
    ¬† ¬† ll
m = HuggingFacePipeline(pipeline=pipe)
    ¬† ¬† return llm
```
---

     
 
all -  [ [New Grad][Software Engineer, Backend] Looking for feedback for my resume ](https://www.reddit.com/r/CSCareerHacking/comments/1h9a39s/new_gradsoftware_engineer_backend_looking_for/) , 2024-12-09-0914
```
https://preview.redd.it/dzkvvb308k5e1.png?width=682&format=png&auto=webp&s=36d3addc1b45631449b55bee3ca9fb282ea0ae13

I w
ould appreciate any and all feedback!
```
---

     
 
all -  [ Enquiry on RAG model Response Improvement ](https://www.reddit.com/r/LangChain/comments/1h99ik8/enquiry_on_rag_model_response_improvement/) , 2024-12-09-0914
```
One of the advantages of applying RAG on LLM is to be able to reference the source and page of the output. This is what 
I was trying to test with my output. I was trying to make my RAGLLM to output the response and print out the referenced 
document as well as page by modifying the prompt template. I know I see the retrieval details on langsmith but when I tr
y to include the details like source: <docname.pdf> and page number: <pg 113> in the RAGLLM output, it does not work and
 it hallucinates, giving me other sources and non-relevant page numbers. Is there a better way for me to do this? How do
 big enterprises using RAG usually do it? Is there a way for me to extract this info from langsmith into the output itse
lf? is there a more effective prompt template?
```
---

     
 
all -  [ Langgraph's weird behavior in Python!? Cannot rename nodes ](https://www.reddit.com/r/LangChain/comments/1h99h7z/langgraphs_weird_behavior_in_python_cannot_rename/) , 2024-12-09-0914
```
I'm working through the[ Intro to Langgraph ](https://academy.langchain.com/courses/take/intro-to-langgraph)tutorial on 
their website but some of it just doesn't make sense.

Here's a simple example. A example router that runs a set of tool
s or  responds to the user. The example works perfectly fine. BUT one small change and everything breaks. It's a simple 
change. Nothing crazy.

        from langchain_openai import ChatOpenAI
        from langgraph.graph import MessagesStat
e
        from langgraph.graph import StateGraph, START, END
        from langgraph.prebuilt import ToolNode, tools_cond
ition
        
        # Tool
        def multiply(a: int, b: int) -> int:
            '''Multiplies a and b.
        
 
           Args:
                a: first int
                b: second int
            '''
            return a * b
   
     
        def add(a: int, b: int) -> int:
            '''Adds a and b.
        
            Args:
                a:
 first int
                b: second int
            '''
            return a + b
        
        # LLM with bound tool

        llm = ChatOpenAI(model='gpt-4o')
        llm_with_tools = llm.bind_tools([multiply, add])
        
        # No
de
        def tool_calling_llm(state: MessagesState):
            return {'messages': [llm_with_tools.invoke(state['mes
sages'])]}
        
        # Build graph
        builder = StateGraph(MessagesState)
        builder.add_node('tool_cal
ling_llm', tool_calling_llm)
        builder.add_node('tools', ToolNode([multiply, add]))
        builder.add_edge(START
, 'tool_calling_llm')
        builder.add_conditional_edges(
            'tool_calling_llm',
            # If the latest
 message (result) from assistant is a tool call -> tools_condition routes to tools
            # If the latest message (
result) from assistant is a not a tool call -> tools_condition routes to END
            tools_condition,
        )
    
    builder.add_edge('tools', END)
        
        # Compile graph
        graph = builder.compile()

The above code ru
ns fine.

Now, I like to change the name of an edge... should be simple right? **I want to rename 'tools' to 'calc'.**


This code results in a weird error:

     # Build graph
        builder = StateGraph(MessagesState)
        builder.add_
node('tool_calling_llm', tool_calling_llm)
        builder.add_node('calc', ToolNode([multiply, add])) # Changed name he
re!
        builder.add_edge(START, 'tool_calling_llm')
        builder.add_conditional_edges(
            'tool_calling
_llm',
            # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools
   
         # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END
         
   tools_condition,
        )
        builder.add_edge('calc', END) # Changed name here!
        
        # Compile grap
h
        graph = builder.compile()

# The error on Studio and in the python notebook

    KeyError: 'branch:tool_callin
g_llm:tools_condition:tools'
```
---

     
 
all -  [ Fed up with LangGraph docs, I let Langgraph agents document it's entire codebase - It's 10x better! ](https://www.reddit.com/r/LangChain/comments/1h985k2/fed_up_with_langgraph_docs_i_let_langgraph_agents/) , 2024-12-09-0914
```
Like many of you, I got frustrated trying to decipher LangGraph's documentation. So I decided to fight fire with fire - 
I used LangGraph itself to build an AI documentation system that actually makes sense.  


What it Does:

* Auto-generat
es architecture diagrams from Langgraph's code
* Creates visual flowcharts of the entire codebase
* Documents API endpoi
nts clearly
* Syncs automatically with codebase updates

Why its Better:

* 80% less time spent on documentation
* Alway
s up-to-date with the codebase
* Full code references included
* Perfect for getting started with Langgraph

Would reall
y love feedback! 

https://preview.redd.it/nc767qsw6j5e1.png?width=2962&format=png&auto=webp&s=b57d002befe858f13778f8c68
ef96741e4521d8f



[https://entelligence.ai/documentation/langchain-ai&langgraph](https://entelligence.ai/documentation/
langchain-ai&langgraph)
```
---

     
 
all -  [ [3 YoE]- Applied for 1500+ SDE roles, not even getting any screening calls. Need advice ](https://www.reddit.com/r/EngineeringResumes/comments/1h97txj/3_yoe_applied_for_1500_sde_roles_not_even_getting/) , 2024-12-09-0914
```
https://preview.redd.it/5ak5n9l34j5e1.png?width=5100&format=png&auto=webp&s=ec1b0b258a413ef82d978213e4a9a053d29bf95d

I'
m currently a CS Graduate with 3+ years of experience working as s Full Stack Developer at Fortune 500 companies. I've s
tarted my job hunting in November 2023 and applied to closely 1000+ SWE Internships, no luck back then. I've started app
lying to the full time SDE roles on Linkedin and¬†[jobright.ai](http://jobright.ai/)¬†and my resume is not even passing an
y screening rounds despite matching all the key words in the job description. I modify my resume to every job posting. C
an someone review my resume and let me know if I have to fine tune any section. Also, any guidance on the application st
rategies and my current resume would be really appreciated.


```
---

     
 
all -  [ Generative AI - build LLM powered applications using LangChain and Javascript ](https://www.reddit.com/r/udemyfreebies/comments/1h8yr87/generative_ai_build_llm_powered_applications/) , 2024-12-09-0914
```
[https://learnwithamit.com/langchain-js-rf](https://learnwithamit.com/langchain-js-rf)
```
---

     
 
all -  [ Is There a Need for a Centralized Marketplace for AI Agents? ](https://www.reddit.com/r/LangChain/comments/1h8wpfj/is_there_a_need_for_a_centralized_marketplace_for/) , 2024-12-09-0914
```
Hey everyone,

It‚Äôs pretty obvious that AI agents are the future‚Äîthey‚Äôre already transforming industries by automating t
asks, enhancing productivity, and solving niche problems. However, I‚Äôve noticed a major gap: there‚Äôs no simple, centrali
zed marketplace where you can easily browse through hundreds (or thousands) of AI agents tailored for every need.

I‚Äôve 
found ones like: [https://agent.ai/](https://agent.ai/), [https://www.illa.ai/](https://www.illa.ai/), [https://aiagents
directory.com/](https://aiagentsdirectory.com/), [https://fetch.ai](https://fetch.ai/), obviously ChatGPTs store- howeve
r I think there‚Äôs potential for something a lot better

Imagine a platform where you could find the exact AI agent you‚Äôr
e looking for, whether it‚Äôs for customer support, data analysis, content creation, or something else. You‚Äôd be able to c
ompare options, pick the one that works best, and instantly get the API or integrate it into your workflow.

Plus for de
velopers: a place to showcase and monetize your AI agents by reaching a larger audience, with built-in tools to track pe
rformance and revenue.

I‚Äôm exploring the idea of building something like this and would love to hear your thoughts:

* 
Does this resonate with you?
* What kind of AI agents or must have features would you want in a platform like this?
* An
y pain points you‚Äôve encountered when trying to find or use AI tools?
* Any other feedback or considerations?

Let me kn
ow what you think‚ÄîI‚Äôm genuinely curious to get some feedback!


```
---

     
 
all -  [ Different Behavior between llm.bindTools and createToolCallingAgent ](https://www.reddit.com/r/LangChain/comments/1h8tyz8/different_behavior_between_llmbindtools_and/) , 2024-12-09-0914
```
Hi,  
I am seeing very different behavior between (yet again two ways to do things) llm.bindTools and createToolCallingA
gent with same model and tools. Specifically, when I ask a question of the model using llm.bindTools() and the question 
maps onto a tool, the tool is invoked. When the question does not map to a tool, the llm returns a response outside the 
tool. This is desirable behavior and its good.

With createToolCallingAgent, it bypasses the tool entirely. Using LangCh
ain's own calculator tool with createToolCallingAgent, the llm just answers the question itself and doesn't use my tool.


So I went back to llm.bindTools() and I really hope LangChain don't deprecate it because now I am locked into it. So f
rustrating.
```
---

     
 
all -  [ Connect local LLM (ollama) with vector DB (chromaDB) ](https://www.reddit.com/r/LangChain/comments/1h8odxl/connect_local_llm_ollama_with_vector_db_chromadb/) , 2024-12-09-0914
```
Has anyone here worked on using a local LLM with LangChain to read, understand, and output data from a vector database (
e.g., ChromaDB)?

Specifically, I want to ask the LLM questions, have it understand them, and extract relevant informati
on from the vector database to answer. The goal is for the answers to be based exclusively on the data in my ChromaDB, w
ithout the LLM relying on its own general knowledge.

I‚Äôve tried using agents, but I haven‚Äôt been able to establish a pr
oper connection with ChromaDB. While the answers are often relevant, they seem to come from the LLM‚Äôs own knowledge rath
er than strictly using the data from the vector DB.

Does anyone have tips or experience with a similar setup?
```
---

     
 
all -  [ Enquiry on OpenAI embeddings issue ](https://www.reddit.com/r/LangChain/comments/1h8kumn/enquiry_on_openai_embeddings_issue/) , 2024-12-09-0914
```
Hi

Before yesterday, everything was working find with openai embeddings. But since yesterday, I got into this proxies i
ssue when I tried to use OpenAIEmbeddings in my RAG model using colab. Does anyone know how to solve it?

https://previe
w.redd.it/e1prmlb8wc5e1.png?width=1258&format=png&auto=webp&s=fb0096de64389a87df783386c7186bc04647f41f


```
---

     
 
all -  [ Comprehensive Analysis: AI, Agentic Agents, Workflows, Pipelines, Big Tech‚Äôs Strategy, and the Futur ](https://www.reddit.com/r/Asmongold/comments/1h8ji4s/comprehensive_analysis_ai_agentic_agents/) , 2024-12-09-0914
```
**By Steven Britt**  
*Founder, Khaotic Gaming LLC*  
[www.khaotic.ai](http://www.khaotic.ai)

# Abstract

Artificial In
telligence (AI) is evolving at an unprecedented pace, revolutionizing industries, reshaping narratives, and influencing 
societal norms. While AI offers immense potential for innovation and empowerment, its trajectory is largely dictated by 
Big Tech's calculated efforts to monopolize its development and deployment. This paper examines the evolution of AI, the
 rise of agentic agents, workflows, and pipelines, and how Big Tech exploits public participation to refine its systems.
 It further explores the societal impacts of these advancements, from the centralization of AI to the emergence of gener
ational AI and the risks of AI-driven societal divides. Finally, it outlines actionable steps to resist monopolization a
nd foster ethical AI development that prioritizes equity, transparency, and inclusivity.

# 1. Introduction

Artificial 
Intelligence is no longer confined to academia or niche industries‚Äîit has become a transformative force redefining how h
umanity interacts, learns, and innovates. Its rapid proliferation into every facet of life promises to unlock new possib
ilities but also raises significant ethical and societal concerns.

The democratization of AI tools and datasets by comp
anies such as Meta, Amazon, Nvidia, and Oracle may appear to be an act of altruism, empowering individuals and small bus
inesses to innovate. However, this seemingly generous act masks a deliberate strategy. By encouraging global creativity 
and leveraging public data, these companies accelerate the refinement of their AI systems at minimal cost to themselves.


While these corporations now offer ‚Äúopt-out‚Äù versions for data use‚Äîappearing to align with ethical practices‚Äîthis was 
not always the case. Historically, data collection occurred without clear user consent or understanding, leveraging user
 ignorance and the complexity of terms of service agreements. Even today, ‚Äúopt-out‚Äù policies are often more symbolic tha
n substantive. Who is auditing these systems to ensure compliance? Are we relying on a ‚Äútrust me, bro‚Äù promise from thes
e corporations that user data isn‚Äôt being leveraged?

Moreover, Big Tech circumvents direct responsibility through **thi
rd-party AI disruptions**. Here‚Äôs how:

* While corporations claim not to use your data directly, **their users do**. Th
ird-party developers, apps, and platforms often lack the same restrictions and transparency.
* These third-party systems
, which often rely on Big Tech‚Äôs APIs and infrastructure, indirectly improve the parent company‚Äôs AI models through refi
ned data and enhanced algorithms.
* **The Loophole**: By enabling an ecosystem of dependent users and platforms, Big Tec
h benefits from enriched datasets and algorithmic refinement, all while distancing themselves from direct data misuse cl
aims.

**The Implications Are Profound**:

1. **Jobs**: AI‚Äôs integration into industries will redefine the labor market,
 privileging those with access to advanced systems while marginalizing others.
2. **Relationships**: Generational AI sys
tems will influence personal and professional dynamics, creating divides based on access to superior AI tools.
3. **Soci
etal Norms**: AI will shape education, governance, and media, steering public discourse and redefining cultural values.


By the time society recognizes the extent of this manipulation, AI will have woven itself into the fabric of daily life
, dictating opportunities, choices, and even identities. The potential for generational divides looms large as access to
 advanced AI becomes a privilege rather than a universal right.

This paper serves as a call to action. It seeks to expo
se the strategies employed by Big Tech, highlight the societal risks of AI centralization, and propose actionable soluti
ons for fostering an AI landscape that empowers humanity rather than controls it.

# 2. Understanding AI

# 2.1 What is 
AI?

Artificial Intelligence (AI) refers to systems designed to simulate human intelligence by performing tasks such as 
learning, reasoning, decision-making, and adaptation. These systems are capable of operating at scales and speeds beyond
 human capacity, enabling groundbreaking applications across industries.

AI systems can be broadly categorized based on
 their design:

* Narrow AI: Specialized systems trained for specific tasks (e.g., image recognition or language transla
tion).
* General AI: Hypothetical systems capable of performing any intellectual task a human can do.
* Agentic AI: Emer
ging systems capable of real-time adaptability and autonomous decision-making, integrating various AI models and tools i
nto cohesive workflows.

Core Components of AI:

1. Datasets:
   * The foundation of AI lies in vast collections of stru
ctured (e.g., databases) and unstructured (e.g., text, images) data.
   * Ethical concerns arise with datasets sourced w
ithout explicit consent, such as scraping user data from social media or proprietary platforms.
   * Examples of misuse 
include biased datasets perpetuating stereotypes in facial recognition systems.
   * Future Consideration: Fair and repr
esentative datasets are critical to mitigating bias and ensuring inclusivity.
2. Algorithms:
   * Algorithms process dat
a, identify patterns, and generate outputs.
   * Key techniques include:
      * Supervised Learning: Models trained on 
labeled data (e.g., email spam detection).
      * Unsupervised Learning: Identifying patterns in unlabeled data (e.g., 
customer segmentation).
      * Reinforcement Learning: Systems learning through trial and error (e.g., AlphaGo).
      
* Deep Learning: Multi-layered neural networks capable of handling complex tasks (e.g., language processing in GPT model
s).

Architects of Large Language Models (LLMs) and Symbolic Learning Models (SLMs):

* LLMs:
   * Process natural langu
age by training on massive datasets of human communication.
   * Examples: OpenAI‚Äôs GPT-4, Google‚Äôs Bard, and Meta‚Äôs Lla
ma.
   * Strengths: Creativity, adaptability, and contextual understanding.
   * Challenges: Bias, resource consumption,
 and ethical implications.
* SLMs:
   * Handle structured, rule-based logic and symbolic reasoning.
   * Examples: Mathe
matical proofs, logic puzzles, and optimization problems.
   * Strengths: Precision and rule adherence.
   * Limitations
: Struggle in unstructured, ambiguous environments.

Integration of LLMs and SLMs:

* The future of AI lies in combining
 the flexibility of LLMs with the precision of SLMs. This hybrid approach enables systems to tackle complex, multi-dimen
sional problems, such as legal research where creativity and logical rigor are essential.

Emerging Trends:

* Multimoda
l AI: Integrating text, images, and audio for richer, more versatile interactions.
   * Example: ChatGPT combining text 
and image understanding for dynamic customer support.
* Neuro-Symbolic AI: Blending deep learning and symbolic reasoning
 to improve interpretability and precision.

# 2.2 Evolution of AI

AI has evolved significantly, marked by distinct pha
ses of development, each characterized by unique challenges and breakthroughs.

Phase 1: Symbolic AI (1950s-1980s)

* Fo
cus: Rule-based systems using explicit programming.
* Limitations: Unable to handle ambiguity or adapt to unforeseen sce
narios.
* Example: IBM‚Äôs Deep Blue, which used brute-force logic to defeat chess grandmasters.

Phase 2: Machine Learnin
g (1990s-2010s)

* Focus: Learning from data rather than explicit programming.
* Breakthroughs:
   * Neural networks ena
bling pattern recognition (e.g., image and speech processing).
   * Statistical methods like Support Vector Machines (SV
Ms) revolutionizing tasks like handwriting analysis.
* Example: Google‚Äôs PageRank, which transformed search engines by l
earning web page relevance.

Phase 3: Deep Learning Revolution (2010s-Present)

* Focus: Leveraging massive datasets and
 advanced neural architectures.
* Breakthroughs:
   * Convolutional Neural Networks (CNNs) in computer vision (e.g., fac
ial recognition).
   * Transformers (e.g., GPT-4) for natural language processing.
* Challenges: High computational cost
s, environmental impact, and inherent biases in data.

# 2.3 The Emergence of Agentic AI

Agentic AI represents the next
 evolutionary leap, integrating multiple models, tools, and data streams into adaptable, autonomous workflows.

Features
 of Agentic AI:

1. Real-Time Adaptability: Respond dynamically to changes in the environment or user input.
2. Integrat
ion Across Tools: Combine various models (e.g., LLMs, SLMs) for complex decision-making.
3. Autonomous Problem-Solving: 
Automate multi-step processes (e.g., supply chain optimization).

Potential and Risks:

* Potential:
   * Revolutionize 
industries by automating intricate workflows.
   * Examples: Adaptive learning platforms in education, autonomous NPC be
havior in gaming.
* Risks:
   * Dependency on centralized control.
   * Amplification of systemic biases if underlying d
ata is flawed.

# 3. Big Tech‚Äôs Strategy

Big Tech‚Äôs dominance in AI is not a byproduct of innovation alone but a calcul
ated, multi-phase strategy designed to exploit public creativity, consolidate control, and monopolize the future of AI. 
This section outlines the phases of their strategy, provides real-world examples, and explores the implications for inno
vators, businesses, and society.

# 3.1 Phase 1: Public AI Development

In the early stages, Big Tech positioned AI as a
 democratizing tool, offering free or open-access platforms, datasets, and APIs. While this move seemed altruistic, it s
erved as a global R&D lab for refining their systems.

Key Tactics:

1. Leveraging Public Creativity:
   * Open-source t
ools and platforms like TensorFlow and PyTorch encouraged widespread experimentation.
   * Developers, startups, and res
earchers contributed ideas and improvements, which Big Tech incorporated into their proprietary systems.
   * Example: O
penAI‚Äôs release of GPT-2 sparked a wave of innovation, with outputs from developers indirectly benefiting GPT-3 and GPT-
4.
2. Data Harvesting at Scale:
   * Platforms like Facebook and Google collected billions of interactions daily, using 
this data to train algorithms.
   * User-generated content on platforms like YouTube and GitHub further enriched dataset
s.
   * Example: GitHub Copilot trained on public repositories, raising ethical concerns about intellectual property.
3.
 Creating Public Trust:
   * By integrating AI into user-friendly applications, Big Tech normalized its use across indus
tries.
   * Example: AI-driven features in Gmail (e.g., predictive text) and Amazon‚Äôs Alexa built familiarity and relian
ce.

Ethical Concerns:

* Datasets were often sourced without explicit consent, raising issues of privacy and exploitati
on.
* Public contributions to open-source projects were rarely rewarded, while Big Tech profited immensely.

# 3.2 Phase
 2: Restricting Access

Once their systems were sufficiently refined, Big Tech began to limit access, citing concerns ab
out ethics, safety, and regulation. This phase strategically suppressed competition by creating barriers to entry.

Key 
Strategies:

1. Regulatory Lobbying:
   * Big Tech pushed for stringent AI regulations under the guise of promoting safe
ty and trustworthiness.
   * Smaller developers, unable to meet these compliance standards, were edged out.
   * Example
: Google and Microsoft lobbied for explainability requirements in AI systems, creating high-cost barriers for startups.

2. Proprietary Tools:
   * Open platforms were gradually restricted, forcing users to pay for access.
   * Example: Open
AI‚Äôs GPT-4, available only through API subscriptions, limits independent development.
3. Control Over Data:
   * Access 
to critical datasets became increasingly restricted.
   * Example: Reddit‚Äôs decision to charge for API usage made it har
der for developers to train models using its data.

Implications:

* Innovation outside Big Tech slowed as independent d
evelopers struggled to access resources.
* Ethical AI development became prohibitively expensive for smaller entities.


# 3.3 Phase 3: Embedding AI in Society

With control firmly established, Big Tech is embedding AI into essential societa
l systems, creating dependencies that ensure their dominance.

Key Tactics:

1. Integration into Infrastructure:
   * AI
 systems are becoming integral to healthcare, education, governance, and more.
   * Example: Microsoft‚Äôs Office 365 Copi
lot integrates AI into workplace productivity, making its tools indispensable.
2. Tiered Access:
   * Advanced AI system
s are marketed as premium solutions, accessible only to corporations or wealthy individuals.
   * Example: Nvidia‚Äôs ente
rprise-grade AI systems offer capabilities far beyond consumer-grade tools.
3. Suppressing Competition:
   * Big Tech em
ploys aggressive strategies to neutralize potential competitors.
   * Example: Amazon‚Äôs patent strategies and acquisitio
ns eliminate smaller companies attempting to innovate in AI.

Global Impact:

* In developing nations, Big Tech‚Äôs AI sys
tems dominate due to the lack of local alternatives or regulatory resistance.
* Governments increasingly rely on proprie
tary AI solutions, reducing sovereignty over critical infrastructure.

# 3.4 The Illusion of Democratization

Big Tech m
arkets its AI offerings as tools for empowerment, but the reality is far more exploitative.

1. Public Data as Fuel:
   
* Social media platforms collect and monetize user interactions without adequate compensation.
   * Example: TikTok uses
 uploaded content to train recommendation algorithms, with no benefit to creators.
2. Open Source as a Testing Ground:
 
  * Open-source initiatives indirectly benefit Big Tech, as they test and refine models that later become proprietary.
 
  * Example: Meta‚Äôs release of Llama spurred innovation, but advanced features were monetized in subsequent iterations.


# 3.5 Examples of Big Tech Exploitation

* Amazon Bedrock:
   * Markets multi-agent solutions that closely mirror open-
source innovations but are locked behind enterprise-grade licenses.
* Meta‚Äôs Llama:
   * Released as an open-source mode
l but restricted access to critical updates and features.
* Google and YouTube:
   * Every video uploaded is analyzed to
 refine ad-targeting algorithms, with no compensation to creators.

# 3.6 Implications for Innovators

Big Tech‚Äôs strate
gies stifle independent developers, startups, and smaller corporations, creating an uneven playing field.

1. Barriers t
o Entry:
   * High costs of compliance and restricted datasets discourage smaller players.
2. Erosion of IP Rights:
   *
 Public contributions are repackaged and patented by Big Tech.
3. Monopolistic Ecosystems:
   * AI‚Äôs integration into es
sential services makes it nearly impossible to exit Big Tech‚Äôs ecosystems.

# 3.7 Resistance and Solutions

1. Open-Sour
ce Movements:
   * Platforms like Hugging Face democratize access to AI tools.
2. Regulatory Advocacy:
   * Push for ant
itrust laws targeting monopolistic practices rather than stifling innovation.
3. Public Awareness:
   * Educate communit
ies about how Big Tech exploits user data and stifles competition.

# 4. AI Workflows and Pipelines

AI workflows and pi
pelines form the backbone of modern AI systems, dictating how raw data transforms into actionable insights. This section
 explores the structure and components of traditional pipelines, the evolution to agentic workflows, and their implicati
ons for innovation, efficiency, and control.

# 4.1 Traditional AI Pipelines

Traditional AI pipelines are structured, s
tep-by-step processes that outline how data flows through an AI system during training, testing, and deployment.

Key St
ages of a Traditional Pipeline:

1. Data Collection:
   * Raw data is sourced from platforms such as social media, IoT d
evices, and proprietary databases.
   * Challenges:
      * Privacy concerns, as datasets are often collected without ex
plicit user consent.
      * Bias in data sources, leading to skewed AI predictions.
   * Example: Healthcare datasets f
rom wearables (e.g., fitness trackers) are used to train predictive health models.
2. Data Cleaning and Preprocessing:
 
  * Ensures data quality by removing errors, duplicates, and irrelevant information.
   * Processes:
      * Normalizing
 formats (e.g., image resolution, text encoding).
      * Handling missing data or anomalies.
   * Importance: The accur
acy of an AI system depends heavily on the quality of preprocessing.
3. Model Training:
   * The cleaned dataset is fed 
into algorithms to identify patterns and make predictions.
   * Example: Chatbots trained on millions of conversations t
o understand language nuances.
4. Validation and Testing:
   * Evaluates the model against a separate dataset to assess 
accuracy, generalization, and robustness.
   * Metrics:
      * Accuracy: Percentage of correct predictions.
      * Rec
all: Ability to identify relevant results.
5. Deployment:
   * The model is integrated into real-world applications, suc
h as autonomous vehicles or recommendation engines.
6. Feedback Loops:
   * Real-world usage generates new data to refin
e the model.
   * Example: Netflix‚Äôs recommendation system improves as users interact with it.

Limitations of Tradition
al Pipelines:

* Rigidity: Fixed sequences make it difficult to adapt to dynamic conditions.
* Resource Intensity: Train
ing large models requires significant computational power.
* Data Dependence: Performance heavily relies on the availabi
lity of large, high-quality datasets.

# 4.2 Agentic Workflows

Agentic workflows represent a paradigm shift in AI devel
opment, enabling real-time adaptability and autonomous decision-making. These workflows integrate multiple AI models, to
ols, and data streams into a dynamic, feedback-driven system.

What Makes Agentic Workflows Different?

1. Dynamic Adapt
ability:
   * Unlike traditional pipelines, agentic workflows adjust strategies and processes based on real-time inputs.

   * Example: An autonomous delivery robot rerouting in response to traffic data.
2. Integration Across Tools:
   * Mul
tiple AI models collaborate seamlessly to achieve complex goals.
   * Example: A workflow in e-commerce where one agent 
analyzes user behavior, another predicts trends, and a third handles personalized marketing.
3. Continuous Learning:
   
* These workflows incorporate live feedback from user interactions or environmental changes to refine performance dynami
cally.
   * Example: AI-powered diagnostics systems updating treatment plans based on real-time patient data.

Component
s of Agentic Workflows:

1. Multi-Agent Systems:
   * Specialized AI agents work together to solve problems.
   * Exampl
e: A gaming environment where NPCs adapt their behavior to player strategies in real-time.
2. Orchestration Frameworks:

   * Tools like LangChain and LangFlow enable developers to build workflows integrating diverse models and processes.
  
 * Capabilities:
      * Task automation.
      * Seamless data sharing between agents.
3. Real-Time Feedback Loops:
   
* Unlike traditional systems that require manual retraining, agentic workflows learn continuously.

Advantages of Agenti
c Workflows:

* Flexibility: Adapt to changing conditions without retraining the entire system.
* Efficiency: Reduce red
undant processes by automating dynamic adjustments.
* Scalability: Integrate new agents or tools as requirements evolve.


Applications:

1. Healthcare: Real-time monitoring systems that adjust treatment plans dynamically.
2. Gaming: Adaptiv
e NPCs for more immersive player experiences.
3. Supply Chain Management: Dynamic optimization of logistics and inventor
y.

# 4.3 Implications for Innovation and Control

The rise of agentic workflows presents both opportunities and challen
ges.

Opportunities:

1. Accelerated Innovation:
   * Continuous learning enables faster iteration cycles.
   * Example:
 AI systems in renewable energy optimizing power distribution based on demand patterns.
2. Cross-Industry Applications:

   * Versatility allows workflows to transform industries such as education, transportation, and entertainment.

Challen
ges:

1. Monopolization Risks:
   * Big Tech‚Äôs dominance in orchestration tools (e.g., LangChain) can stifle competition
.
   * Example: Amazon Bedrock locking multi-agent workflows behind enterprise-grade licenses.
2. Data Privacy Concerns:

   * Continuous learning requires constant data input, raising ethical issues about how user data is collected and used
.
3. Ethical Dilemmas:
   * Autonomous decision-making systems may perpetuate biases or lead to unintended consequences.


# 4.4 Future Trends in AI Workflows

1. Hybrid Models:
   * Combining LLMs‚Äô creativity with SLMs‚Äô precision for enhanc
ed effectiveness.
   * Example: Legal research systems where LLMs draft summaries, and SLMs ensure logical consistency.

2. Decentralized Workflows:
   * Open-source platforms like Hugging Face are democratizing access, enabling smaller inno
vators to compete with Big Tech.
3. Customization:
   * AI workflows will become increasingly user-driven, allowing busi
nesses to tailor systems to specific needs without deep technical expertise.

# 5. AI as a Tool for Societal Control

AI
, when controlled by centralized entities, becomes a powerful mechanism for shaping human behavior, enforcing societal n
orms, and reinforcing existing power structures. This section delves into the ways AI can manipulate narratives, create 
dependencies, and embed itself into critical societal systems, exploring both the psychological and societal risks invol
ved.

# 5.1 Narrative Reinforcement

AI-driven platforms subtly shape public discourse by prioritizing specific content,
 often aligning with corporate or ideological goals.

Mechanisms of Narrative Control:

1. Content Recommendation Algori
thms:
   * AI systems, such as YouTube‚Äôs and TikTok‚Äôs recommendation engines, push content based on engagement metrics, 
often amplifying polarizing or sensational topics.
   * Example: During the 2016 U.S. elections, Facebook‚Äôs AI algorithm
s amplified divisive content, contributing to misinformation.
2. Media Bias Reinforcement:
   * AI-curated newsfeeds rei
nforce existing biases, reducing exposure to diverse perspectives.
   * Consequence: Echo chambers that diminish critica
l thinking and healthy debate.
3. Educational AI Systems:
   * AI-integrated curricula can selectively emphasize certain
 ideologies or omit controversial topics, shaping the worldview of future generations.
   * Example: Corporate-developed
 adaptive learning platforms prioritizing STEM over humanities without addressing the ethical implications of technology
.

# 5.2 Dependency and Psychological Shifts

As AI integrates into daily life, psychological dependence on these system
s grows, subtly altering societal norms and individual behaviors.

AI as the Arbiter of Value:

1. AI Scores and Ranking
s:
   * Generational AI systems may rank individuals based on their 'AI compatibility,' influencing decisions in:
      
* Employment: 'Your AI profile doesn‚Äôt meet the requirements.'
      * Education: 'Your child‚Äôs score is too low for adm
ission.'
      * Relationships: 'Compatibility with this AI-driven platform is suboptimal.'
   * Impact: A societal divi
de emerges, with those lacking access to advanced AI systems viewed as inherently less capable.
2. Shifting Norms:
   * 
Over-reliance on AI for decision-making diminishes human creativity and critical thinking.
   * Example: AI-generated we
llness apps reduce personal agency by automating health decisions.

# 5.3 Embedding AI in Key Systems

AI‚Äôs integration 
into critical societal systems entrenches its control over human behavior and infrastructure.

Industries Transformed by
 AI:

1. Healthcare:
   * AI systems dynamically analyze patient data to recommend treatments.
   * Risks:
      * Bias 
in datasets could lead to inequities in care.
      * Insurance companies may prioritize cost-saving recommendations ove
r optimal patient outcomes.
   * Generational Disparity:
      * Premium AI tools will provide advanced diagnostics only
 to those who can afford them.
2. Education:
   * AI-powered platforms personalize learning but risk restricting access 
to non-approved content.
   * Example: Proprietary platforms shaping curricula to align with corporate interests.
3. Gov
ernance:
   * Governments increasingly rely on AI for policy enforcement, surveillance, and decision-making.
   * Exampl
es:
      * Predictive policing algorithms, often perpetuating systemic biases.
      * Automated decision-making in soc
ial services, potentially marginalizing vulnerable populations.
4. Corporate Systems:
   * AI-driven workplace monitorin
g enforces productivity standards, creating high-pressure environments.
   * Example: Amazon‚Äôs warehouse management syst
em tracks worker efficiency in real-time.

# 5.4 Generational AI and the Class Divide

Generational AI systems will deep
en societal inequities, creating a divide based on access to advanced tools.

AI Hierarchy:

1. Generic AI:
   * Basic s
ystems available to the general public with limited functionality.
2. Generational AI:
   * Advanced systems evolving wi
th users over time, accessible only to affluent individuals or corporations.

Social Implications:

1. Workplace Dispari
ties:
   * Employees with generational AI systems will outperform others, leading to disproportionate career opportuniti
es.
2. Educational Inequalities:
   * Students with access to advanced AI tutors will achieve greater academic success, 
widening the achievement gap.
3. Healthcare Disparities:
   * Premium AI systems will deliver better diagnostics and tre
atments, exacerbating existing health inequities.

# 5.5 The Psychological and Societal Risks of AI Control

1. Erosion 
of Creativity:
   * Over-reliance on AI stifles innovation and problem-solving skills, as individuals default to automat
ed solutions.
2. Normalization of Inequality:
   * AI systems embed societal divides into algorithms, making inequities 
appear inevitable or natural.
3. Loss of Privacy:
   * Continuous data collection erodes personal privacy under the guis
e of 'enhanced user experiences.'

# 5.6 How Big Tech Enforces AI Dependency

1. Throttling Alternatives:
   * Public AI
 systems are intentionally limited, preventing independent innovation.
   * Example: Open-source tools are often less ca
pable than proprietary systems, forcing reliance on Big Tech.
2. Neutralizing Independent Efforts:
   * Big Tech employs
 AI scrapers to detect and suppress unauthorized systems.
   * Example: Identifying and neutralizing rogue AI bots opera
ting outside corporate ecosystems.

# 5.7 Solutions to Mitigate AI Control

1. Promote Decentralization:
   * Support de
centralized AI initiatives prioritizing user control.
   * Example: Federated AI systems that distribute control over da
ta and models.
2. Advocate for Transparency:
   * Push for regulations requiring companies to disclose algorithmic prior
ities and data processing methods.
3. Foster Public Awareness:
   * Educate society about the risks of over-reliance on 
AI and the importance of maintaining personal agency.
4. Empower Small Innovators:
   * Level the playing field by provi
ding funding, resources, and legal protections for independent developers.

# full report can be explored here [https://
chatgpt.com/g/g-6753c74473e48191a63213cb9d8ac392-ai-deep-dive-insights-and-impacts](https://chatgpt.com/g/g-6753c74473e4
8191a63213cb9d8ac392-ai-deep-dive-insights-and-impacts)
```
---

     
 
all -  [ How to Evaluate the Quality of Generated Embeddings? ](https://www.reddit.com/r/LangChain/comments/1h8fmvz/how_to_evaluate_the_quality_of_generated/) , 2024-12-09-0914
```
I have generated embeddings from the text chunks (extracted from a PDF and split using NLTKText Splitter).

I want to ev
aluate whether the generated embeddings are good.

How should I proceed?

  
Any Suggestions!

thank you so much in adva
nce 
```
---

     
 
all -  [ Which term do you like best do describe the new wave of agent apps we‚Äôve been seeing (Cursor, v0, Re ](https://www.reddit.com/r/LangChain/comments/1h8czld/which_term_do_you_like_best_do_describe_the_new/) , 2024-12-09-0914
```
1. Agent apps
2. Agent-Native Applications
3. Agentic Apps
4. Agentic Copilots
5. Agent-Native Apps (ANA)

(vote on your
 favorite 
```
---

     
 
all -  [ Stuck at learning ](https://www.reddit.com/r/n8n/comments/1h8bsxb/stuck_at_learning/) , 2024-12-09-0914
```
I come from a generative AI background/web development (RAG, langchain, openAI, API's, postgreSQL). I am planning on bui
lding my own company based on automation services with computer vision and generative AI. For this plan, I have been ext
ensively exploring n8n for the past month. I think I grasp most of the basics (I have build some workflows for customer 
service (image requests, text generation, ).  what will be my next steps in my learning?. I feel like I hit a point wher
e youtube tutorials/books are not enough as they are pretty basic. Could you suggest me learning for mid/expert level? I
 feel like this has happened in the past, but since I never worked in a software development company, I have no idea how
 to go from basics to advance skills.
```
---

     
 
all -  [ Going from 25% success rate with Langchain's Graph RAG to 99.4% using BAML ](https://www.reddit.com/r/LangChain/comments/1h8adm9/going_from_25_success_rate_with_langchains_graph/) , 2024-12-09-0914
```
Disclaimer: I work on BAML - a prompting config language to get structured outputs ( [https://github.com/BoundaryML/baml
](https://github.com/BoundaryML/baml) ) 

One of our BAML users decided to test our framework against Langchain's GraphD
ocument solution to do RAG with graphs and got some crazy results I had to share.

https://preview.redd.it/bfw5zak8ba5e1
.png?width=1330&format=png&auto=webp&s=233f4ea00e7b784aba684fc416a9717bb0a69364

Here is their blog post: [https://mediu
m.com/@khaledarindam/implementing-graphrag-with-smaller-open-source-llms-a-practical-guide-501a62864c15](https://medium.
com/@khaledarindam/implementing-graphrag-with-smaller-open-source-llms-a-practical-guide-501a62864c15) 

Here is the lan
gchain implementation: [https://github.com/arindamkhaled/OpenGraphRAG/blob/main/opengraphrag/graph\_rag\_small\_llms\_wo
\_baml.ipynb](https://github.com/arindamkhaled/OpenGraphRAG/blob/main/opengraphrag/graph_rag_small_llms_wo_baml.ipynb) 


We've had some similar feedback that examples that don't work with Langchain tend to work with BAML, since it uses a si
mplified schema format to do structured outputs with LLMs ( [https://www.boundaryml.com/blog/sota-function-calling?q=0](
https://www.boundaryml.com/blog/sota-function-calling?q=0) ). Happy to answer any questions. 
```
---

     
 
all -  [ What are the best techniques and tools to have the model 'self-correct?' ](https://www.reddit.com/r/OpenAI/comments/1h85b1b/what_are_the_best_techniques_and_tools_to_have/) , 2024-12-09-0914
```
# CONTEXT
I'm a noob building an app that analyses financial transactions to find out what was the max/min/avg balance e
very month/year. Because my users have accounts in multiple countries/languages that aren't covered by Plaid, I can't re
ly on Plaid -- I have to analyze account statement PDFs.

Extracting financial transactions like ||||||| 2021-04-28 | 45
2.10 | credit ||||||| _almost_ works. The model will hallucinate most times and create some transactions that don't exis
t. It's always just one or two transactions where it fails.

I've now read about Prompt Chaining, and thought it might b
e a good idea to have the model check its own output. Perhaps say 'given this list of transactions, can you check they'r
e all present in this account statement' or even way more granular do it for every single transaction for getting it 100
% right 'is this one transaction present in this page of the account statement', _transaction by transaction_, and have 
it correct itself.

# QUESTIONS:
1) is using the model to self-correct a good idea?

2) how could this be achieved? 

3)
 should I use the regular api for chaining outputs, or langchain or something? I still don't understand the benefits of 
these tools

# More context:
- I started trying this by using Docling to OCR the PDF, then feeding the markdown to the L
LM (both in its entirety and in hierarchical chunks). It wasn't accurate, it wouldn't extract transactions alright
- I t
hen moved on to Llama vision, which seems to be yielding much better results in terms of extracting transactions. but st
ill makes some mistakes
- My next step before doing what I've described above is to improve my prompt and play around wi
th temperature and top_p, etc, which I have not played with so far!
```
---

     
 
all -  [ Is Langsmith just good piece of trash? ](https://www.reddit.com/r/LangChain/comments/1h84qim/is_langsmith_just_good_piece_of_trash/) , 2024-12-09-0914
```
I use langsmith for tracing and prompt management. Initially it was good. But then they started to tweak UI every two da
ys and nowadays I just feel the website has become pathetic and unresponsive at some times. I don‚Äôt know am I the only o
ne experiencing it but its very frustrating as a developer. Had high hopes from langchain but got disappointed‚Ä¶

Any goo
d open source langsmith alternatives??
```
---

     
 
all -  [ MD Doesn‚Äôt Seem Like the Right Intermediate Language To Connect LLMs to Webpages ](https://www.reddit.com/r/LangChain/comments/1h82xst/md_doesnt_seem_like_the_right_intermediate/) , 2024-12-09-0914
```
It seems like right now the canonical pipeline to feed webpages into LLMs is: HTML ‚Äî> MD ‚Äî> LLM

It makes sense that MD 
is a lot more usable than HTML since it strips away the bloat, but having tried numerous HTML ‚Äî> MD tools, the reality i
s that a lot of the context of the webpage is lost in this translation. For example, if you put in a site like EBay or Z
illow into these tools, the output makes it nearly impossible to understand what‚Äôs going on, much less navigate the page
 with the LLM from this information.

What do people see as the future for what intermediate languages will appear to co
nnect web pages to LLMs?

I‚Äôve always wondered if some sort of language that captures where elements were positional and
 what types of elements there were would be neat, but even this seems to have flaws of its own. The proliferation of so 
much JS helps very little here as well.
```
---

     
 
all -  [ Improve a RAG system that uses 200+ PDFs ](https://www.reddit.com/r/LangChain/comments/1h82gox/improve_a_rag_system_that_uses_200_pdfs/) , 2024-12-09-0914
```
Hello everyone, I am writing here to ask for some suggestions. I am building a RAG system in order to interrogate a chat
bot and get the info that are present in documentation manuals.

**Data Source:**

I have 200+ pdfs and every pdf can re
ach even 800/1000 page each.

**My current solution:**

**DATA INGESTION:**

I am currently using Azure DocumentIntellig
ence to extract the information and metadata from the pdfs. After that I start creating chunks by creating a chunk for e
very paragraph identified by Azure DocumentIntelligence. To this chunk I also attach the PageHeading and the previous im
mediate title found.

After splitting all in chunks I do embed them using 'text-embedding-ada-002' model of OpenAI.

Aft
er that I load all these chunks on Microsoft Azure index search service.

**FRONTEND and QA**

Now, using streamlit I bu
ilt a easy chat-bot interface.

Every time I user sends a query, I do embed the query, and then I use Vectorsearch to fi
nd the top 5 'similar' chunks (Azure library).

RERANKING:

After identified the top 5 similar chunks using vector searc
h I do send chunk by chunk in combination with the query and I ask OpenAI GPT-3.5 to score from 50 to 100 how relevant i
s the retrieved chunk based on the user query. I keep only the chunks that have a score higher than 70.

After this I wi
ll remain with around 3 chunks that I will send in again as a knowledge context from where the GPT model have to answer 
the intial query.

The results are not really good, some prompts are correctly answered but some are totally not, it see
ms the system is getting lost and I am wondering if is because I have many pdfs and every pdf have many many pages.

Any
one had a similar situation/use case? Any suggestion you can give me to help me improve this system?

Thanks!
```
---

     
 
all -  [ LangGraph based literature review agent - hackathon winner project ](https://open.substack.com/pub/diamantai/p/nexus-ai-the-revolutionary-research?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true) , 2024-12-09-0914
```
Happy to share the first blog post about an incredible agent developed during the hackathon (by the 1st place winners) I
 organized with LangChain.

This agent, powered by LangGraph, slashes literature review times in research from 40% to ju
st 10%‚Äîoutperforming previous state-of-the-art models with only a slight tradeoff in processing time (a matter of second
s).

Code is fully available on the GenAI_Agents open-source repository and there is a link to it in the blog.
```
---

     
 
all -  [ AI Agent creation with Dynamic Node pathways  ](https://www.reddit.com/r/LangChain/comments/1h7zhno/ai_agent_creation_with_dynamic_node_pathways/) , 2024-12-09-0914
```
For most of the AI Agents, like CrewAI or Autogen or even Langgraph, what I found that we can only give the goal and the
n define which agent does what. In Langgraph, we have to define the entire workflow in advance from what I get from the 
docs. 

But I wanted to check if a problem of code debugging, which might involve multiple steps and multiple different 
pathways, is there a way to handle the management of creating all these possible paths & having the Agent walk through e
ach of them one by one? The key difference between the nodes of the graph are created after execution of some initial no
des. 

Or should I manage this outside the Agentic Framework with a custom setup and DB etc.
```
---

     
 
all -  [ Ollama, langchain ans local database ? ](https://www.reddit.com/r/ollama/comments/1h7z7ev/ollama_langchain_ans_local_database/) , 2024-12-09-0914
```
Hi all,
I've been using ollama since a few months now and wanted to go a bit further in my application.

To be honest, I
 am a bit confused about how to use it. 
 
Here is what I had in mind : use langchain to understand the user input and c
onvert it to either a SQL or NoSQL query (I work on SQL and Mongodb) and then format the results into a small sentence. 
But I don't know if langchain is here to build literaly the query based on a context? Or just to ordinates the command (
understand the user input, find the correct table/collection, adjust parameters based on the fields of the collection/ta
ble, retrieve results...).

Can someone help me with that? Maybe it is not even the correct tool that I'm using!

Thanks
!
```
---

     
 
all -  [ Best way to store image and text embeddings in vector store?
 ](https://www.reddit.com/r/LangChain/comments/1h7ycvq/best_way_to_store_image_and_text_embeddings_in/) , 2024-12-09-0914
```
Working on a RAG based PDF Query system for documents with complex layout.

I was not sure weather to store the embeddin
gs of text and images into unified vector store or create different vector store for each.

What would be the better app
roach for this?
```
---

     
 
all -  [ Help needed to clean data ](https://www.reddit.com/r/LangChain/comments/1h7urvf/help_needed_to_clean_data/) , 2024-12-09-0914
```
I have a bunch of tweets and now I want to filter the tweets in some categories. How can I automate this process. 

```
---

     
 
all -  [ How to improve RAG results for searching a set of game rules ](https://www.reddit.com/r/LangChain/comments/1h7r7eb/how_to_improve_rag_results_for_searching_a_set_of/) , 2024-12-09-0914
```
I am trying to develop an Magic: The Gathering RAG AI system for answering rules questions and am having difficulty.

Fo
r example, the user asks a question like, 'what happens when all of these creatures die at the same time'

I use an agen
t to break down user question and use similarity search on my vector db. it searches by the entire question and by broke
n down terms like 'simultaneous death' 'creature dies' etc. per reddit QA board, a redditor answered the question the qu
estion referencing this rule:

603.10a Some zone-change triggers look back in time. These are leaves-the-battlefield abi
lities, abilities that trigger when a card leaves a graveyard, and abilities that trigger when an object that all player
s can see is put into a hand or library.

Clearly this is the key insight, but I'm not sure how it could have gotten to 
this key rule. To make things worse, I got a hallucination: - \`Simultaneous Deaths (Rule 704.3): When multiple creature
s die at the same time, they see each other die, which can trigger abilities that trigger on creatures dying.\`

Any ide
as? I am using chroma db, using custom text splitters to chunk by rule with small overlap. Do you think graph db could b
e more useful for a set of rules?
```
---

     
 
all -  [ TIL: LangChain has init_chat_model('model_name') helper with LiteLLM-alike notation... ](https://www.reddit.com/r/LangChain/comments/1h7qwbz/til_langchain_has_init_chat_modelmodel_name/) , 2024-12-09-0914
```
Hi! For those who, like me, have been living under a rock these past few months and spent time developing numerous JSON-
based LLMClient, YAML-based LLMFactory's, and other solutions just to have LiteLLM-style initialization/model notation -
 I've got news for you! Since v.0.3.5, LangChain has moved their [init\_chat\_model](https://python.langchain.com/docs/h
ow_to/chat_models_universal_init/) helper out of beta.



    from langchain.chat_models import init_chat_model
    
   
 # Simple provider-specific initialization
    openai_model = init_chat_model('gpt-4', model_provider='openai', temperat
ure=0)
    claude_model = init_chat_model('claude-3-opus-20240229', model_provider='anthropic')
    gemini_model = init_
chat_model('gemini-1.5-pro', model_provider='google_vertexai')
    
    # Runtime-configurable model
    configurable_mo
del = init_chat_model(temperature=0)
    response = configurable_model.invoke('prompt', config={'configurable': {'model'
: 'gpt-4'}})



[Supported providers](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_mo
dels.base.init_chat_model.html): openai, anthropic, azure\_openai, google\_vertexai, google\_genai, bedrock, bedrock\_co
nverse, cohere, fireworks, together, mistralai, huggingface, groq, ollama.



Quite more convenient helper:

    from la
ngchain.chat_models import init_chat_model
    from typing import Optional
    
    def init_llm(model_path: str, temp: 
Optional[float] = 0):
        '''Initialize LLM using provider/model notation'''
        provider, *model_parts = model_
path.split('/')
        model_name = model_path if not model_parts else '/'.join(model_parts)
        
        if provid
er == 'mistral':
            provider = 'mistralai'
        
        return init_chat_model(
            model_name,
   
         model_provider=provider,
            temperature=temp
        )



Finally.

    mistral = init_llm('mistral/mi
stral-large-latest')
    anthropic = init_llm('anthropic/claude-3-opus-20240229')
    openai = init_llm('openai/gpt-4-tu
rbo-preview', temp=0.7)



Hope this helps someone avoid reinventing the wheel like I did!  

```
---

     
 
MachineLearning -  [ [P] Minima: local conversational retrieval augmented generation project (Ollama, Langchain, FastAPI, ](https://www.reddit.com/r/MachineLearning/comments/1h1pudq/p_minima_local_conversational_retrieval_augmented/) , 2024-12-09-0914
```
  
[https://github.com/dmayboroda/minima](https://github.com/dmayboroda/minima)  
  
Hey everyone, I would like to intro
duce you my latest repo, that is a local conversational rag on your files, Be honest, you can use this as a rag on-premi
ses, cause it is build with docker, langchain, ollama, fastapi, hf All models download automatically, soon I'll add an a
bility to choose a model For now solution contains:

* Locally running Ollama (currently qwen-0.5b model hardcoded, soon
 you'll be able to choose a model from ollama registry)
* Local indexing (using sentence-transformer embedding model, yo
u can switch to other model, but only sentence-transformers applied, also will be changed soon)
* Qdrant container runni
ng on your machine
* Reranker running locally (BAAI/bge-reranker-base currently hardcoded, but i will also add an abilit
y to choose a reranker)
* Websocket based chat with saving history
* Simple chat UI written with React
* As a plus, you 
can use local rag with ChatGPT as a custom GPT, so you able to query your local data through official chatgpt web and ma
c os/ios app.
* You can deploy it as a RAG on-premises, all containers can work on CPU machines

Couple of ideas/problem
s:

* Model Context Protocol support
* Right now there is no incremental indexing or reindexing
* No selection for the m
odels (will be added soon)
* Different environment support (cuda, mps, custom npu's)

Welcome to contribute (watch, fork
, star) Thank you so much!
```
---

     
