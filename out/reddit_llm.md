 
all -  [ Build a LangGraph Customer Support Bot ](https://www.reddit.com/r/copilotkit/comments/1hn14x4/build_a_langgraph_customer_support_bot/) , 2024-12-27-0913
```
Curious if anyone has gone through this LangGraph tutorial and if so, added CopilotKit?   
[https://langchain-ai.github.
io/langgraph/tutorials/customer-support/customer-support/](https://langchain-ai.github.io/langgraph/tutorials/customer-s
upport/customer-support/)
```
---

     
 
all -  [ ai frameworks vs customs ai agents? ](https://www.reddit.com/r/AI_Agents/comments/1hn1066/ai_frameworks_vs_customs_ai_agents/) , 2024-12-27-0913
```
I‚Äôve recently gotten into AI agents, but I‚Äôm not sure where to start.

Some people say that frameworks like LangChain an
d LlamaIndex have too many abstractions and not great for production environments. I came across Pydantic AI, and it loo
ks interesting, but it‚Äôs new, so I‚Äôm not sure if it‚Äôs any good.

Others say frameworks are a waste of time and that the 
best way is to build everything from scratch.

What do you guys think I should do, and how can I learn this stuff?
```
---

     
 
all -  [ Comparing PDF with JSON data ](https://www.reddit.com/r/LangChain/comments/1hmw5an/comparing_pdf_with_json_data/) , 2024-12-27-0913
```
Hi everyone, I'm new to Langchain and this is my first post here. I'm looking to write a script that compares informatio
n from a PDF file against data from a JSON file. The PDF is a one-page export from Adobe Illustrator, designed for produ
ct packaging, and the data is unstructured. I want to identify discrepancies between the two, including typos, differenc
es in values, upper/lower case differences, and spaces, and return coordinates of rectangles where are those erroros

Ca
n anyone recommend an approach for this task and share some tips and tricks? I'm just starting out with Langchain and wo
uld appreciate any guidance.

Any help or advice would be greatly appreciated. 
```
---

     
 
all -  [ [Opern Source]: Open AI Realtime with Langchain powered RAG to talk to your PDF ](https://www.reddit.com/r/OpenSourceeAI/comments/1hmuk90/opern_source_open_ai_realtime_with_langchain/) , 2024-12-27-0913
```
Hi Everyone, we are proud to share the release of our open source voice-to-voice Proof of concept where you can upload y
our documents and ask questions related to them.

You can upload your documents and interact with them through our dashb
oard.üìä.

Based on OpenAI Realtime AND langchain

Powered by [Supabase](https://www.linkedin.com/company/supabase/)  \+ [
Qdrant](https://www.linkedin.com/company/qdrant/)  \+ [NextJs](https://www.linkedin.com/company/nextjs/)

Github repo: [
https://github.com/actualize-ae/voice-chat-pdf](https://github.com/actualize-ae/voice-chat-pdf)

Link to Playground: [ht
tps://talk-to-docs.vercel.app/](https://talk-to-docs.vercel.app/)

Demo Video: [https://vimeo.com/1039742928?share=copy]
(https://vimeo.com/1039742928?share=copy)

**If you like the concept or have feedback please feel free to contribute a s
tar and share feedback :)**

Architecture Diagram:

https://preview.redd.it/g29cnxdk5g6e1.png?width=2050&format=png&auto
=webp&s=3abdc714f810565c163d7aba3d5c4cebcf666b55


```
---

     
 
all -  [ Injustice at the NVIDIA Hackathon: Let‚Äôs Support Francisco Angulo de Lafuente ](https://www.reddit.com/r/LangChain/comments/1hmuj9i/injustice_at_the_nvidia_hackathon_lets_support/) , 2024-12-27-0913
```
Greetings, I hope this space can help bring attention to an important issue. I kindly ask for your support in sharing th
is news: Francisco Angulo de Lafuente, known on Twitter as @**Francisco\_Ecofa**, won a hackathon organized by NVIDIA wi
th an incredibly complex project named **NEBULA**.

This project introduces an innovative way to optimize neural network
s using light reflections and basic principles of quantum computing instead weigths. However, despite his outstanding ac
hievement, Francisco was stripped of the prize without clear or detailed explanations.

It‚Äôs crucial that this situation
 is clarified and that NVIDIA acts transparently. I would greatly appreciate your help in spreading this news to ensure 
fairness.

Thank you for your support. üôè
```
---

     
 
all -  [ Looking for a Python Library to Manage Prompt Versioning and Performance Locally ](https://www.reddit.com/r/LangChain/comments/1hmue25/looking_for_a_python_library_to_manage_prompt/) , 2024-12-27-0913
```
Hi everyone,

I'm searching for a Python library that can help manage versioning and performance tracking of prompts loc
ally during development. Ideally, the system should:

* Run on localhost
* Save prompt metrics and versions in YAML or J
SON
* Provide a UI for creating and managing prompts
* Allow consuming the created prompts both through the UI and via c
ode

Does anyone know of an existing library that fits these requirements or have suggestions on how to implement this?


Thanks in advance!
```
---

     
 
all -  [ CS Masters (UCL maybe?) ](https://www.reddit.com/r/cscareerquestionsuk/comments/1hmrk8c/cs_masters_ucl_maybe/) , 2024-12-27-0913
```
Hi all, some background: I'm a career switcher. Have an undergrad law degree from SOAS and an LLM from KCL (intellectual
 property law). 

Moved back to Singapore after graduating (not willingly, I couldn't get a training contract to qualify
 to practise English law, and this was when there was no graduate visa due to Theresa May reasons). I got qualled in Sin
gapore, practised commercial litigation for 3 years, realised I didn't like law very much, ditched it, learned to code, 


For some reason I did a data science bootcamp, then figured out I hated Jupyter notebooks, so I found a job as a data 
engineer. No idea how I convinced them that I could figure Scala out but 4 interviews later I got my current role as a S
cala Data Engineer and have been working in it for the last 9 months. 

I'm not exactly doing data engineering work per 
se, it's been all about building and maintaining a system for other data engineers to configure spark scala pipelines wi
th yaml/json and my code handles it (my fingers are still sore from the 300 pages of documentation). 

Recently, work fi
gured out I learned langchain when they weren't looking so they started getting me write python to throw AI into everyth
ing. I am having fun at work, but I'm looking ahead.

Separately, I do a bunch of random projects in my free time as wel
l, here's my personal GitHub:

https://github.com/Shredmetal

Here's where I'm at right now:

1. I want to move back to 
the UK, and honestly, while I can build a pile of stuff, my fundamentals in data structures and algorithms could use wor
k, like, a lot of work. I go play leetcode for fun when I'm not working on some project and pay for LC premium for edito
rials and explanations on how the solution works under the hood (python abstracts away a lot of stuff)

2. I suspect a l
ot of jobs are closed off to me because they see 'bootcamp' and go lol no.

3. I am considering a CS degree of some sort
. I'm not getting any younger, so a 3-year undergrad degree is out of the question.

4. Therefore, I'm wondering if a CS
 masters is the way forward, or if there are other computing degrees worth pursuing in order to actually seek employment
 in the UK.

Advice? Thanks!
```
---

     
 
all -  [ How to send information from frontend app to backend python agent through livekit server? ](/r/WebRTC/comments/1hmr11d/how_to_send_information_from_frontend_app_to/) , 2024-12-27-0913
```

```
---

     
 
all -  [ Supabase Auth with SSR + RAGüöÄ ](https://www.reddit.com/r/nextjs/comments/1hmqynm/supabase_auth_with_ssr_rag/) , 2024-12-27-0913
```
Remember that simple AI chat template I shared earlier? Well, it just got a major upgrade! I'm excited to announce that 
we've added document chat capabilities (RAG) while keeping true to our core principle: keeping things simple and straigh
tforward.

What's New in v1.7.0:

# üéâ Document Chat (RAG) Features:

https://preview.redd.it/g4aez3jjb79e1.png?width=255
4&format=png&auto=webp&s=f29ace8a181e210bbdd0766287c77556f4e002a2

* Chat with your documents using our simple RAG imple
mentation
* Upload PDFs and DOCX files with ease
* Smart document processing using LlamaCloud
* Vector storage with Pine
cone
* Interactive split-screen interface
* Click-to-navigate source references
* Contextual embeddings for improved rel
evancy

# üöÄ Core Features:

* Supabase Auth with SSR
* Multiple AI model support (GPT-3.5, GPT-4, Claude AI Sonnet)
* Ef
ficient chat history with pagination
* Enhanced chat interface with streaming responses
* Document viewer with source hi
ghlighting

# üìë Smart Document Processing Pipeline:

We've implemented a robust document processing flow that circumvent
s serverless function limitations:

1. Client directly uploads document to Supabase Storage
2. API route fetches the doc
ument from Supabase Storage and sends to LlamaCloud
3. Background polling checks LlamaCloud processing status every 10 s
econds
4. Once processing is complete, we:
   * Download processed markdown from LlamaCloud
   * Generate contextual emb
eddings
   * Store in Pinecone
   * Ready for semantic search and chat!

Why this approach? Serverless functions have a 
4.5MB payload limit, which can be restrictive for larger documents. By uploading directly to Supabase Storage first, we 
can handle documents of much larger size while maintaining a smooth user experience. However, there are still limits on 
how long a process can run. An example would be Cloudflare have a 100s cutoff timer. It is generally recommended to host
 your own server somewhere handle uploading using this.

https://preview.redd.it/grntfq1qa79e1.png?width=336&format=png&
auto=webp&s=abf6770a809b5f8baee8c3e81911fa096367cb83

Who It's For:

* Developers who need both chat and document QA cap
abilities
* Teams looking to build document-aware chatbots
* Anyone who wants to implement RAG without reaching for tool
s that overcomplicates everything ( I'm talking about you Langchain...)

The Goal: To provide a starting point for proje
cts that require authentication, AI chat, and document chat capabilities. It's completely free, as we don't believe in c
harging $299 for templates (looking at you, Shitfast).

Check out the project on GitHub: [https://github.com/ElectricCod
eGuy/SupabaseAuthWithSSR](https://github.com/ElectricCodeGuy/SupabaseAuthWithSSR)

Note: The project is functional and r
eady to use, but we're currently cleaning up the codebase and working on improving the documentation. If you'd like to c
ontribute, especially with the documentation or how-to guide in the README, feel free to jump in!

https://reddit.com/li
nk/1hmqynm/video/pqleduora79e1/player


```
---

     
 
all -  [ Supabase Auth with SSR + RAGüöÄ ](https://www.reddit.com/r/Supabase/comments/1hmpblw/supabase_auth_with_ssr_rag/) , 2024-12-27-0913
```
Hey Supabase community! üëã

Remember that simple AI chat template I shared earlier? Well, it just got a major upgrade! I'
m excited to announce that we've added document chat capabilities (RAG) while keeping true to our core principle: keepin
g things simple and straightforward.

What's New in v1.7.0:

# üéâ Document Chat (RAG) Features:

https://preview.redd.it/
g4aez3jjb79e1.png?width=2554&format=png&auto=webp&s=f29ace8a181e210bbdd0766287c77556f4e002a2

* Chat with your documents
 using our simple RAG implementation
* Upload PDFs and DOCX files with ease
* Smart document processing using LlamaCloud

* Vector storage with Pinecone
* Interactive split-screen interface
* Click-to-navigate source references
* Contextual 
embeddings for improved relevancy

# üöÄ Core Features:

* Supabase Auth with SSR
* Multiple AI model support (GPT-3.5, GP
T-4, Claude AI Sonnet)
* Efficient chat history with pagination
* Enhanced chat interface with streaming responses
* Doc
ument viewer with source highlighting

# üìë Smart Document Processing Pipeline:

We've implemented a robust document proc
essing flow that circumvents serverless function limitations:

1. Client directly uploads document to Supabase Storage
2
. API route fetches the document from Supabase Storage and sends to LlamaCloud
3. Background polling checks LlamaCloud p
rocessing status every 10 seconds
4. Once processing is complete, we:
   * Download processed markdown from LlamaCloud
 
  * Generate contextual embeddings
   * Store in Pinecone
   * Ready for semantic search and chat!

Why this approach? S
erverless functions have a 4.5MB payload limit, which can be restrictive for larger documents. By uploading directly to 
Supabase Storage first, we can handle documents of much larger size while maintaining a smooth user experience. However,
 there are still limits on how long a process can run. An example would be Cloudflare have a 100s cutoff timer. It is ge
nerally recommended to host your own server somewhere handle uploading using this.

https://preview.redd.it/grntfq1qa79e
1.png?width=336&format=png&auto=webp&s=abf6770a809b5f8baee8c3e81911fa096367cb83

Who It's For:

* Developers who need bo
th chat and document QA capabilities
* Teams looking to build document-aware chatbots
* Anyone who wants to implement RA
G without reaching for tools that overcomplicates everything ( I'm talking about you Langchain...)

The Goal: To provide
 a starting point for projects that require authentication, AI chat, and document chat capabilities. It's completely fre
e, as we don't believe in charging $299 for templates (looking at you, Shitfast).

Check out the project on GitHub: [htt
ps://github.com/ElectricCodeGuy/SupabaseAuthWithSSR](https://github.com/ElectricCodeGuy/SupabaseAuthWithSSR)

Note: The 
project is functional and ready to use, but we're currently cleaning up the codebase and working on improving the docume
ntation. If you'd like to contribute, especially with the documentation or how-to guide in the README, feel free to jump
 in!

https://reddit.com/link/1hmpblw/video/pqleduora79e1/player
```
---

     
 
all -  [ Complete Generative AI Course With Langchain and Huggingface review by krish naik ](https://www.reddit.com/r/u_Specialist-Light8348/comments/1hmo45t/complete_generative_ai_course_with_langchain_and/) , 2024-12-27-0913
```
Complete Generative AI Course With Langchain and Huggingface review by krish naik
```
---

     
 
all -  [ Tables in PDF | GraphRAG ](https://www.reddit.com/r/LangChain/comments/1hmnim4/tables_in_pdf_graphrag/) , 2024-12-27-0913
```
I am working on a GraphRAG tool. My PDF contains tables too. I can create regular chunks out of the rest of the text bas
ed on a markup splitter. Now how do I consider the tables in the PDF and importantly, their position in the PDF too?  
F
or example, I dont want the tables to be separately read and embedded as text, but I want them to be embedded as present
 in their respective sections of the PDF.
```
---

     
 
all -  [ ChatOllama doesn't call Tool ](https://www.reddit.com/r/LangChain/comments/1hmkz59/chatollama_doesnt_call_tool/) , 2024-12-27-0913
```
Hi everyone, I am currently working on migrating to ChatOllama and following one of LangChain's [tutorials](https://pyth
on.langchain.com/docs/integrations/chat/ollama/#tool-calling). 

    from typing import List
    
    from langchain_oll
ama import ChatOllama
    from typing_extensions import TypedDict
    
    
    def validate_user(user_id: int, addresse
s: List) -> bool:
        '''Validate user using historical addresses.
    
        Args:
            user_id: (int) the
 user ID.
            addresses: Previous addresses.
        '''
        return True
    
    
    llm = ChatOllama(
   
     model='llama3.1:70b-instruct-fp16',
        base_url='http://localhost:11434/',
        temperature=0,
    ).bind_t
ools([validate_user])
    
    result = llm.invoke(
        'Could you validate user 123? They previously lived at '
   
     '123 Fake St in Boston MA and 234 Pretend Boulevard in '
        'Houston TX.'
    )
    result.tool_calls

However
, I am not getting the expected output. This is the output I got:

`[]`

Instead of the expected output:

    [{'name': 
'validate_user',
      'args': {'addresses': '['123 Fake St, Boston, MA', '234 Pretend Boulevard, Houston, TX']',
      
 'user_id': '123'},
      'id': '40fe3de0-500c-4b91-9616-5932a929e640',
      'type': 'tool_call'}]

  
Does anyone know
 what might cause the model to not call the tool, resulting in an empty result.tool\_calls array?
```
---

     
 
all -  [ Chroma client hosting with docker container ](https://www.reddit.com/r/LangChain/comments/1hmkf8n/chroma_client_hosting_with_docker_container/) , 2024-12-27-0913
```
I'm trying to run chromadb  on a docker container as a service and trying to access it locally or through a docker conta
iner I'm only able to create Collection and upload data to the collection

Issue: while I'm trying to query the db as a 
'persistent_clinet' im able to query it but I'm not able to access the same through 'http_client'

I'm getting the follo
wing error 

'HTTPError: 400 Client Error: Bad Request for url: http://localhost:8000/api/v1/collections/cfda7a8f-3cc7-4
7b4-877b-775d3f39dfe
3/query'

'Exception:-('error':'InvalidArgumentError','message';'Expected where to have exactly one
 operator, got )')'



Docker commands used to run as a container:

1.docker pull chromadb/chroma

2.docker run-d --rm--
name chromadb -p 8000:8000 -v ~/chroma:/chroma/chroma-e IS_PERSISTENT-TRUE-e ANONYMIZED_TELEMETRY=TRUE chromadb/chroma:l
atest
```
---

     
 
all -  [ AI code editor that works with LangChain and LangGraph? ](https://www.reddit.com/r/LangChain/comments/1hmiz5j/ai_code_editor_that_works_with_langchain_and/) , 2024-12-27-0913
```
Are there AI code editors that work with LangChain and LangGraph? For example, one can describe the use case, specify th
e use of LangChain/LangGraph, and then the editor will write the initial code for you.
```
---

     
 
all -  [ Are my projects good enough for ML Intern roles? ](https://www.reddit.com/r/learnmachinelearning/comments/1hmdn3m/are_my_projects_good_enough_for_ml_intern_roles/) , 2024-12-27-0913
```
https://preview.redd.it/0va6cae6h39e1.jpg?width=2550&format=pjpg&auto=webp&s=6f49c02de60a74483d7d640dca4aafb69a13933b


```
---

     
 
all -  [ Ways to summarize with RAG ](https://www.reddit.com/r/LangChain/comments/1hm9cvv/ways_to_summarize_with_rag/) , 2024-12-27-0913
```
‚ÄúRAG is not designed to summarize entire book‚Äù - you may wanted to write this comment which is quite ok, I dove into ful
l internet resources, trying to find most sophisticated method to summarize user uploaded file using rag, imagine simple
 scenario, user uploads pdf book, and later asks question: ‚Äúwho are main characters in this book?‚Äù, what is approaches y
ou have used to get near good results? 
```
---

     
 
all -  [ What do you think of Groq? ](https://www.reddit.com/r/LangChain/comments/1hm7i83/what_do_you_think_of_groq/) , 2024-12-27-0913
```
What are your experiences with Groq? What are its pros, cons, and limitations? Thanks.
```
---

     
 
all -  [ prompt format question ](https://www.reddit.com/r/LangChain/comments/1hm7how/prompt_format_question/) , 2024-12-27-0913
```
I found the following code from a YouTube tutorial video. My question is regarding the structure of the prompt. In parti
cular, how does one know that he/she has to specify two MessagePlaceHolders()'s? This is a tutorial about getting data f
rom yfinance.

    from langchain.agents import AgentExecutor, create_tool_calling_agent
    from langchain_groq import 
ChatGroq
    from langchain.prompts import ChatPromptTemplate
    from langchain_core.prompts import MessagesPlaceholder

    
    tools = [
    ¬† ¬† ¬† ¬† ¬†company_information,
    ¬† ¬† ¬† ¬† ¬†last_dividend_and_earnings_date,
    ¬† ¬† ¬† ¬† ¬†stock_s
plits_history,
    ¬† ¬† ¬† ¬† ¬†summary_of_mutual_fund_holders,
    ¬† ¬† ¬† ¬† ¬†summary_of_institutional_holders, 
    ¬† ¬† ¬† ¬† 
¬†stock_grade_updrages_downgrades,
    ¬† ¬† ¬† ¬† ¬†stock_news
    ]
    
    prompt = ChatPromptTemplate.from_messages(
    
¬† ¬† [
    ¬† ¬† ¬† ¬† (
    ¬† ¬† ¬† ¬† ¬† ¬† 'system',
    ¬† ¬† ¬† ¬† ¬† ¬† 'You are a helpful assistant. Try to answer user query usi
ng available tools.',
    ¬† ¬† ¬† ¬† ),
    ¬† ¬† ¬† ¬† MessagesPlaceholder(variable_name='messages'),
    ¬† ¬† ¬† ¬† MessagesPlac
eholder(variable_name='agent_scratchpad'),
    ¬† ¬† ]
    )
    
    llama3 = ChatGroq(api_key=groq_api_key, model='llama
3-8b-8192', temperature=0)
    
    finance_agent = create_tool_calling_agent(llama3, tools, prompt)
    
    finance_ag
ent_executor = AgentExecutor(agent=finance_agent, tools=tools, verbose=True)
    

  

```
---

     
 
all -  [ Does anyone know of any github projects that use ChatHuggingFace with tool-use? ](https://www.reddit.com/r/huggingface/comments/1hm2k7v/does_anyone_know_of_any_github_projects_that_use/) , 2024-12-27-0913
```
It'd be a load of help. I've tried everything on the Langchain documentation (for a Langgraph project i've been trying t
o build), but it simply does not work. Tool-use creates the strangest of issues. If there's anything that's built alread
y, it'd be a lot easier to work.
```
---

     
 
all -  [ Open AI Realtime with langchain powered RAG POC ](https://www.reddit.com/r/LangChain/comments/1hm1e1m/open_ai_realtime_with_langchain_powered_rag_poc/) , 2024-12-27-0913
```
Hi Everyone, we are proud to share the release of our open source voice-to-voice Proof of concept where you can upload y
our documents and ask questions related to them.

You can upload your documents and interact with them through our dashb
oard.üìä.

Based on OpenAI Realtime AND langchain

Powered by [Supabase](https://www.linkedin.com/company/supabase/)  \+ [
Qdrant](https://www.linkedin.com/company/qdrant/)  \+ [NextJs](https://www.linkedin.com/company/nextjs/)

Github repo: [
https://github.com/actualize-ae/voice-chat-pdf](https://github.com/actualize-ae/voice-chat-pdf)

If you like the concept
 or have feedback please feel free to contribute a star and share feedback :)

Video: [https://vimeo.com/1039742928?shar
e=copy](https://vimeo.com/1039742928?share=copy)

Architecture Diagram:

https://preview.redd.it/g29cnxdk5g6e1.png?width
=2050&format=png&auto=webp&s=3abdc714f810565c163d7aba3d5c4cebcf666b55
```
---

     
 
all -  [ Parsing Error and no green lines highlight ](https://www.reddit.com/r/n8n/comments/1hm0pdr/parsing_error_and_no_green_lines_highlight/) , 2024-12-27-0913
```
Hello everyone, I'm reaching out for some help with two issues I'm experiencing with my AI models. As a novice user, ple
ase bear with me if my questions seem silly!

**Issue 1: Parsing Error with Llama 3.2**

I've noticed that when I use th
e Llama 3.2 model, I'm getting parsing errors. However, this issue doesn't seem to occur with the QWEN 2.5 coder. Can an
yone help me understand why this is happening?

**Issue 2: Colored Lines not Displaying**

I've noticed that the dotted 
lines connecting these models are not displaying in green color even after execution. Is there a setting or configuratio
n issue here? Any guidance on how to resolve this would be greatly appreciated.

Thank you in advance for your help and 
patience!

https://preview.redd.it/83vykiyqxz8e1.png?width=1738&format=png&auto=webp&s=2d034e3ee8bb6b2cdbc2bac787b7398e1
a2a86fe


```
---

     
 
all -  [ Is it possible to create a multi agent system without any framework? ](https://www.reddit.com/r/LangChain/comments/1hlz3rb/is_it_possible_to_create_a_multi_agent_system/) , 2024-12-27-0913
```
The question is self explanatory.
```
---

     
 
all -  [ Preventing Assistant from Sending Messages Before Tool Calls in LangGraph ](https://www.reddit.com/r/LangChain/comments/1hly6u7/preventing_assistant_from_sending_messages_before/) , 2024-12-27-0913
```
Hey everyone,

I'm building a chatbot using LangGraph with the gpt-4o model and integrating it with several tools to int
eract with our internal APIs. The chatbot is designed to respond with a defined structured format to be rendered in fron
t end later.

I'm encountering an issue where the model sometimes streams a preliminary/opening message to the user *bef
ore* executing a tool call. This leads to multiple messages being sent for a single user query, which our current front-
end cannot handle.

For example:

* User: Detail for product A
* AI: let me search for you ... *<- this is the prelimina
ry/opening message I wanted to prevent*
* (AI executing tool)
* AI: Here is the detail for product A

**What I've Tried:
**

* I've tried adding instructions to the assistant prompt to refrain from sending any preliminary messages before too
l execution.
* I also added instruction to emphasize direct tool execution in the tool descriptions.

However, both of t
hese approaches not working as expected.

I want to ask are there any method in langgraph to prevent this? Thanks
```
---

     
 
all -  [ What's not working? ](https://www.reddit.com/r/LangChain/comments/1hlwx2a/whats_not_working/) , 2024-12-27-0913
```
Why is RAG not working well for you currently?
```
---

     
 
all -  [ Resume analysis for MLE roles (0-2 year experience) ](https://www.reddit.com/r/learnmachinelearning/comments/1hlv9bw/resume_analysis_for_mle_roles_02_year_experience/) , 2024-12-27-0913
```
Hello everyone, I am a student at university in the US about to graduate. I have a decent offer for SWE and I trying to 
interview for MLE roles. Would really appreciate advice/suggestions on resume. Please be as unfiltered and honest as pos
sible. I want to understand what my resume is lacking. TIA.

https://preview.redd.it/pkma7dlsux8e1.png?width=1238&format
=png&auto=webp&s=0062df3c4a7e2532a976bfe6f02bab47b2a42ee7


```
---

     
 
all -  [ LangChain In Your Pocket (Generative AI Book, Packt published) : Free Audiobook ](https://www.reddit.com/r/datascience/comments/1hlup8w/langchain_in_your_pocket_generative_ai_book_packt/) , 2024-12-27-0913
```
Hi everyone,

It's been almost a year now since I published my debut book

>‚ÄúLangChain In Your Pocket : Beginner‚Äôs Guide
 to Building Generative AI Applications using LLMs‚Äù

https://preview.redd.it/lgtj9570ix8e1.png?width=934&format=png&auto
=webp&s=8b2a0e87914072d5125551adf830b731afcb293e

And what a journey it has been. The book saw major milestones becoming
 a¬†**National and even International Bestseller in the AI category**. So to celebrate its success, I‚Äôve released the Fre
e Audiobook version of ‚ÄúLangChain In Your Pocket‚Äù making it accessible to all users free of cost. I hope this is useful.
 The book is currently rated at 4.6 on amazon India and 4.2 on amazon com, making it amongst the top-rated books on Lang
Chain and is published by Packt as well

More details : [https://medium.com/data-science-in-your-pocket/langchain-in-you
r-pocket-free-audiobook-dad1d1704775](https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audio
book-dad1d1704775)

# Table of Contents

* Introduction
* Hello World
* Different LangChain Modules
* Models & Prompts
*
 Chains
* Agents
* OutputParsers & Memory
* Callbacks
* RAG Framework & Vector Databases
* LangChain for NLP problems
* 
Handling LLM Hallucinations
* Evaluating LLMs
* Advanced Prompt Engineering
* Autonomous AI agents
* LangSmith & LangSer
ve
* Additional Features

**Edit :** Unable to post direct link (maybe Reddit Guidelines), hence posted medium post with
 the link.
```
---

     
 
all -  [ Free Audiobook : LangChain In Your Pocket (Packt published) ](https://www.reddit.com/r/OpenAI/comments/1hluk3m/free_audiobook_langchain_in_your_pocket_packt/) , 2024-12-27-0913
```
Hi everyone,

It's been almost a year now since I published my debut book

>‚ÄúLangChain In Your Pocket : Beginner‚Äôs Guide
 to Building Generative AI Applications using LLMs‚Äù

https://preview.redd.it/lgtj9570ix8e1.png?width=934&format=png&auto
=webp&s=8b2a0e87914072d5125551adf830b731afcb293e

And what a journey it has been. The book saw major milestones becoming
 a¬†**National and even International Bestseller in the AI category**. So to celebrate its success, I‚Äôve released the Fre
e Audiobook version of ‚ÄúLangChain In Your Pocket‚Äù making it accessible to all users free of cost. I hope this is useful.
 The book is currently rated at 4.6 on amazon India and 4.2 on amazon com, making it amongst the top-rated books on Lang
Chain and is published by Packt.

More details : [https://medium.com/data-science-in-your-pocket/langchain-in-your-pocke
t-free-audiobook-dad1d1704775](https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audiobook-da
d1d1704775)

# Table of Contents

* Introduction
* Hello World
* Different LangChain Modules
* Models & Prompts
* Chains

* Agents
* OutputParsers & Memory
* Callbacks
* RAG Framework & Vector Databases
* LangChain for NLP problems
* Handlin
g LLM Hallucinations
* Evaluating LLMs
* Advanced Prompt Engineering
* Autonomous AI agents
* LangSmith & LangServe
* Ad
ditional Features

**Edit :** Unable to post direct link (maybe Reddit Guidelines), hence posted medium post with the li
nk.
```
---

     
 
all -  [ LangChain In Your Pocket : Free Audiobook ](https://www.reddit.com/r/learnmachinelearning/comments/1hlui47/langchain_in_your_pocket_free_audiobook/) , 2024-12-27-0913
```
Hi everyone,

It's been almost a year now since I published my debut book

>‚ÄúLangChain In Your Pocket : Beginner‚Äôs Guide
 to Building Generative AI Applications using LLMs‚Äù (Packt Published)

https://preview.redd.it/lgtj9570ix8e1.png?width=9
34&format=png&auto=webp&s=8b2a0e87914072d5125551adf830b731afcb293e

And what a journey it has been. The book saw major m
ilestones becoming a¬†**National and even International Bestseller in the AI category**. So to celebrate its success, I‚Äôv
e released the Free Audiobook version of ‚ÄúLangChain In Your Pocket‚Äù making it accessible to all users free of cost. I ho
pe this is useful. The book is currently rated at 4.6 on amazon India and 4.2 on amazon com, making it amongst the top-r
ated books on LangChain.

More details : [https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-a
udiobook-dad1d1704775](https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audiobook-dad1d17047
75)

# Table of Contents

* Introduction
* Hello World
* Different LangChain Modules
* Models & Prompts
* Chains
* Agent
s
* OutputParsers & Memory
* Callbacks
* RAG Framework & Vector Databases
* LangChain for NLP problems
* Handling LLM Ha
llucinations
* Evaluating LLMs
* Advanced Prompt Engineering
* Autonomous AI agents
* LangSmith & LangServe
* Additional
 Features

**Edit :** Unable to post direct link (maybe Reddit Guidelines), hence posted medium post with the link.
```
---

     
 
all -  [ Free Audiobook : LangChain in your Pocket ](https://www.reddit.com/r/Rag/comments/1hluhi8/free_audiobook_langchain_in_your_pocket/) , 2024-12-27-0913
```
Hi everyone,

It's been almost a year now since I published my debut book

>‚ÄúLangChain In Your Pocket : Beginner‚Äôs Guide
 to Building Generative AI Applications using LLMs‚Äù

https://preview.redd.it/lgtj9570ix8e1.png?width=934&format=png&auto
=webp&s=8b2a0e87914072d5125551adf830b731afcb293e

And what a journey it has been. The book saw major milestones becoming
 a¬†**National and even International Bestseller in the AI category**. So to celebrate its success, I‚Äôve released the Fre
e Audiobook version of ‚ÄúLangChain In Your Pocket‚Äù making it accessible to all users free of cost. I hope this is useful.
 The book is currently rated at 4.6 on amazon India and 4.2 on amazon com, making it amongst the top-rated books on Lang
Chain.

More details : [https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audiobook-dad1d1704
775](https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audiobook-dad1d1704775)

# Table of Co
ntents

* Introduction
* Hello World
* Different LangChain Modules
* Models & Prompts
* Chains
* Agents
* OutputParsers 
& Memory
* Callbacks
* RAG Framework & Vector Databases
* LangChain for NLP problems
* Handling LLM Hallucinations
* Eva
luating LLMs
* Advanced Prompt Engineering
* Autonomous AI agents
* LangSmith & LangServe
* Additional Features

**Edit 
:** Unable to post direct link (maybe Reddit Guidelines), hence posted medium post with the link.
```
---

     
 
all -  [ LangChain In Your Pocket free Audiobook ](https://www.reddit.com/r/LangChain/comments/1hlug9s/langchain_in_your_pocket_free_audiobook/) , 2024-12-27-0913
```
Hi everyone,

It's been almost a year now since I published my debut book

>‚ÄúLangChain In Your Pocket : Beginner‚Äôs Guide
 to Building Generative AI Applications using LLMs‚Äù (Packt published)

https://preview.redd.it/lgtj9570ix8e1.png?width=9
34&format=png&auto=webp&s=8b2a0e87914072d5125551adf830b731afcb293e

And what a journey it has been. The book saw major m
ilestones becoming a¬†**National and even International Bestseller in the AI category**. So to celebrate its success, I‚Äôv
e released the Free Audiobook version of ‚ÄúLangChain In Your Pocket‚Äù making it accessible to all users free of cost. I ho
pe this is useful. The book is currently rated at 4.6 on amazon India and 4.2 on amazon com, making it amongst the top-r
ated books on LangChain.

More details : [https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-a
udiobook-dad1d1704775](https://medium.com/data-science-in-your-pocket/langchain-in-your-pocket-free-audiobook-dad1d17047
75)

# Table of Contents

* Introduction
* Hello World
* Different LangChain Modules
* Models & Prompts
* Chains
* Agent
s
* OutputParsers & Memory
* Callbacks
* RAG Framework & Vector Databases
* LangChain for NLP problems
* Handling LLM Ha
llucinations
* Evaluating LLMs
* Advanced Prompt Engineering
* Autonomous AI agents
* LangSmith & LangServe
* Additional
 Features

**Edit :** Unable to post direct link (maybe Reddit Guidelines), hence posted medium post with the link.
```
---

     
 
all -  [ Langachain Agent & Tool ](https://www.reddit.com/r/LangChain/comments/1hlt3c1/langachain_agent_tool/) , 2024-12-27-0913
```
I have a context like

```

issuer is  somebank. Rate is 1.0% year 1; 2.0% year 2 onwards. Maturity date is 20/01/2023. 
Coupon frequency is semi-annual long first coupon. Trade date is 20/11/2015. calendar is London, Newyork. Counterparty i
s some bank. Etc‚Ä¶

```

From here i need to get Rate; Maturity Date; Trade date and construct a table. So in langchain w
hich agent and tool will be helpful to construct the table. Or if i have descriptions correctly which langchain agent an
d tool will do correctly?
```
---

     
 
all -  [ Build AI Agents with SwarmEx (GitHub) ](https://www.reddit.com/r/elixir/comments/1hlhu1n/build_ai_agents_with_swarmex_github/) , 2024-12-27-0913
```
[https://github.com/nrrso/swarm\_ex](https://github.com/nrrso/swarm_ex)  
Found this really cool library while searching
 for alternatives to Langchain Elixir. While Langchain (Elixir) is cool, I felt like an abstraction layer of doing thing
s in parallel would be nice and found this.

The thing about Elixir is the actor model/message passing lends itself quit
e naturally to agents. I have also worked with Langraph on Python land and it is not as elegant, especially having to re
ason about your code 6 months from now.
```
---

     
 
all -  [ How to add a prompt with instructions to my code ?  ](https://www.reddit.com/r/LangChain/comments/1hlhqxv/how_to_add_a_prompt_with_instructions_to_my_code/) , 2024-12-27-0913
```
    how to enable the ai here to follow instructions from the prompt : 
    here is my code : 
    # Helper Functions
  
  def load_documents(directory: str):
    ¬† ¬† '''
    ¬† ¬† Load documents from the specified directory.
    ¬† ¬† '''
    ¬†
 ¬† loader = DirectoryLoader(directory, glob='./*.pdf')
    ¬† ¬† documents = loader.load()
    ¬† ¬† return documents
    
 
   
    def split_documents(documents, chunk_size=2000, chunk_overlap=500):
    ¬† ¬† '''
    ¬† ¬† Split documents into sma
ller chunks for vectorization.
    ¬† ¬† '''
    ¬† ¬† text_splitter = CharacterTextSplitter(
    ¬† ¬† ¬† ¬† chunk_size=chunk_s
ize,
    ¬† ¬† ¬† ¬† chunk_overlap=chunk_overlap
    ¬† ¬† )
    ¬† ¬† return text_splitter.split_documents(documents)
    
    

    def setup_vectorstore(documents, embeddings, persist_directory: str):
    ¬† ¬† '''
    ¬† ¬† Create or load a FAISS ve
ctorstore.
    ¬† ¬† '''
    ¬† ¬† if not os.path.exists(persist_directory):
    ¬† ¬† ¬† ¬† os.makedirs(persist_directory)
    
¬† ¬† vectorstore = FAISS.from_documents(
    ¬† ¬† ¬† ¬† documents=documents,
    ¬† ¬† ¬† ¬† embedding=embeddings
    ¬† ¬† )
    
¬† ¬† return vectorstore
    
    
    def create_chat_chain(vectorstore):
    ¬† ¬† '''
    ¬† ¬† Create a conversational ret
rieval chain using Ollama with Llama 3.2.
    ¬† ¬† '''
    ¬† ¬† llm = Ollama(model='llama3.2:latest')
    ¬† ¬† retriever = 
vectorstore.as_retriever()
    ¬† ¬† memory = ConversationBufferMemory(
    ¬† ¬† ¬† ¬† #llm=llm,
    ¬† ¬† ¬† ¬† memory_key='chat
_history',
    ¬† ¬† ¬† ¬† return_messages=True,
    ¬† ¬† ¬† ¬† output_key='answer' ¬†# Explicitly specify the output key
    ¬† 
¬† )
    ¬† ¬† chain = ConversationalRetrievalChain.from_llm(
    ¬† ¬† ¬† ¬† llm=llm,
    ¬† ¬† ¬† ¬† retriever=retriever,
    ¬† ¬†
 ¬† ¬† chain_type='stuff',
    ¬† ¬† ¬† ¬† memory=memory,
    ¬† ¬† ¬† ¬† verbose=True,
    ¬† ¬† ¬† ¬† return_source_documents=True ¬†
# Allows retrieving source documents
    ¬† ¬† )
    ¬† ¬† return chain
    
    
    # Main Streamlit Application
    def m
ain():
    ¬† ¬† # Page Configuration
    ¬† ¬† st.set_page_config(
    ¬† ¬† ¬† ¬† page_title='Multi Doc Chat',
    ¬† ¬† ¬† ¬† pag
e_icon='üìö',
    ¬† ¬† ¬† ¬† layout='centered'
    ¬† ¬† )
    
    ¬† ¬† st.title('üìö Multi Documents Chatbot')
    
    ¬† ¬† # In
itialize embeddings and vectorstore
    ¬† ¬† embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-Min
iLM-L6-v2')
    ¬† ¬† persist_directory = 'vector_db_dir'
    
    ¬† ¬† if 'vectorstore' not in st.session_state:
    ¬† ¬† ¬†
 ¬† # Specify your directory path here
    ¬† ¬† ¬† ¬† documents = load_documents(path of file)
    ¬† ¬† ¬† ¬† text_chunks = spl
it_documents(documents)
    ¬† ¬† ¬† ¬† st.session_state.vectorstore = setup_vectorstore(text_chunks, embeddings, persist_di
rectory)
    
    ¬† ¬† if 'chat_chain' not in st.session_state:
    ¬† ¬† ¬† ¬† st.session_state.chat_chain = create_chat_cha
in(st.session_state.vectorstore)
    
    ¬† ¬† if 'chat_history' not in st.session_state:
    ¬† ¬† ¬† ¬† st.session_state.ch
at_history = []
    
    ¬† ¬† # Display chat history
    ¬† ¬† for message in st.session_state.chat_history:
    ¬† ¬† ¬† ¬† wi
th st.chat_message(message['role']):
    ¬† ¬† ¬† ¬† ¬† ¬† st.markdown(message['content'])
    
    ¬† ¬† # Input and response h
andling
    ¬† ¬† user_input = st.chat_input('Ask AI...')
    ¬† ¬† if user_input:
    ¬† ¬† ¬† ¬† st.session_state.chat_history
.append({'role': 'user', 'content': user_input})
    
    ¬† ¬† ¬† ¬† with st.chat_message('user'):
    ¬† ¬† ¬† ¬† ¬† ¬† st.markd
own(user_input)
    
    ¬† ¬† ¬† ¬† with st.chat_message('assistant'):
    ¬† ¬† ¬† ¬† ¬† ¬† response = st.session_state.chat_cha
in({'question': user_input})
    ¬† ¬† ¬† ¬† ¬† ¬† assistant_response = response['answer']
    ¬† ¬† ¬† ¬† ¬† ¬† st.markdown(assista
nt_response)
    ¬† ¬† ¬† ¬† ¬† ¬† st.session_state.chat_history.append({'role': 'assistant', 'content': assistant_response})

    
    
    # Run the application
    if __name__ == '__main__':
    ¬† ¬† main()
```
---

     
 
all -  [ Seeking Guidance for Building a RAG-Powered Chatbot with LangChain and Llama ](https://www.reddit.com/r/Rag/comments/1hlg5jp/seeking_guidance_for_building_a_ragpowered/) , 2024-12-27-0913
```
I‚Äôm developing a RAG system for the company where I‚Äôm doing my internship. The goal is to use it as a chatbot for the us
ers of the enterprise platform, answering questions based on manuals and documentation. This will help save the IT depar
tment‚Äôs time by avoiding repetitive queries.

Although I‚Äôve read a lot about RAG, I feel like I‚Äôve fallen into an endles
s pit of documentation, so I‚Äôm seeking some guidance.

So far, I‚Äôm considering using LangChain, PostgreSQL with Pgvector
 as the vector database, and Llama as the language model. Do you think this setup is viable?

I‚Äôd really appreciate any 
advice or recommendations you could share.
```
---

     
 
all -  [ Arch (0.1.7) üöÄ - accurate multi-turn intent detection especially for follow-up questions in RAG. Plu ](https://i.redd.it/se5dhprlet8e1.jpeg) , 2024-12-27-0913
```
https://github.com/katanemo/archgw - an intelligent gateway for agents. Engineered with (fast) LLMs for the secure handl
ing, rich observability, and seamless integration of prompts with functions/APIs - all outside business logic.

Disclaim
er: I am work here and this was a big release that simplifies a lot for developers. Ask me anything
```
---

     
 
all -  [ Multi AI Agent framework for Time series, Text and visual data ](https://www.reddit.com/r/LangChain/comments/1hlfq0k/multi_ai_agent_framework_for_time_series_text_and/) , 2024-12-27-0913
```
I am trying to create a multi-AI agent which retrieves time series, text and visual data what are the frameworks that an
yone can suggest me to build this one, I have seen langgraph, crewAI and autogen being the most popular out there. But a
re they really good for multi model multi-AI agent systems?
```
---

     
 
all -  [ 'Fetching 30 files' during start - why? ](https://www.reddit.com/r/OpenWebUI/comments/1hlfidk/fetching_30_files_during_start_why/) , 2024-12-27-0913
```
Whenever I start Open WebUI (in a docker container), it fetches some files from somewhere. Here's a piece of log:

`open
-webui  | WARNI [langchain_community.utils.user_agent] USER_AGENT environment variable not set, consider setting it to i
dentify your requests.`

`Fetching 30 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 385978.90it/s]`

`open-webui  | INFO: 
    Started server process [1]`

What are those files and how to disable that?

I'd like to run OpenWebUI with Ollama wi
th no internet connection, but it gets stuck when it cannot fetch that stuff (tested by disabling network).
```
---

     
 
all -  [ Diving into the Hype and Reality of AI Agent Frameworks - What Are People Saying? ](https://i.redd.it/35jmcq7f9t8e1.jpeg) , 2024-12-27-0913
```


I've been doing a deep dive into the burgeoning world of AI agent frameworks like Langchain, AutoGPT, and others, and 
wanted to share a summary of the user sentiment I've been picking up across the web, particularly here on Reddit and oth
er tech forums. It's a fascinating space, and the conversations are buzzing!

The Overall Vibe: A Mix of Excitement and 
Cautious Optimism

Generally, there's a strong sense of excitement and anticipation surrounding these frameworks. People
 are clearly intrigued by the potential of building truly autonomous AI agents that can reason, plan, and act in the rea
l world. The idea of AI handling complex tasks with minimal human intervention is definitely captivating.

The Good (Wha
t People Are Hyped About):

Automation Potential: This is the biggest draw. Users are excited about the possibilities of
 automating repetitive tasks, complex workflows, and even creative processes. Think coding assistants that go beyond sim
ple completions, personal research assistants, or even automated business processes.

Democratization of AI: Frameworks 
like Langchain, with their relatively accessible APIs and abstractions, are seen as tools that can empower developers (a
nd even technically savvy non-developers) to build sophisticated AI applications without needing a PhD in machine learni
ng.

Rapid Prototyping and Experimentation: These frameworks make it easier to quickly build and test out different agen
t architectures and workflows. The modular nature and pre-built components are a big plus for rapid iteration.

Novel Ap
plication Ideas: Discussions are brimming with creative ideas for how these agents could be used. From building personal
ized learning platforms to creating intelligent smart home ecosystems, the possibilities seem endless.

Integration with
 Powerful Models: The ability to easily integrate with powerful language models like GPT-3/4 and other specialized AI mo
dels is a major selling point. Users appreciate the ability to leverage state-of-the-art AI without having to train ever
ything from scratch.

Active Development and Community: Many frameworks have active and growing communities, which is a 
huge plus for troubleshooting, sharing ideas, and contributing to the development of the tools.

The Not-So-Good (Concer
ns and Skepticism):

Complexity and Learning Curve: While aiming for accessibility, many users find the frameworks compl
ex to get started with. Understanding the different components, chains, agents, and memory management can be challenging
, especially for beginners.

Debugging and Troubleshooting: When things go wrong, debugging these complex agent systems 
can be difficult. Understanding the flow of information and identifying the root cause of errors can be time-consuming.


Reliability and Consistency: A common concern is the reliability and consistency of these agents. Sometimes they work b
rilliantly, and other times they produce unexpected or nonsensical results. This unpredictability is a barrier for deplo
ying them in critical applications.

'Hallucinations' and Factuality: Because many of these frameworks rely on large lan
guage models, the issue of 'hallucinations' (generating incorrect or fabricated information) is a significant concern. U
sers are wary of relying on agents for tasks where factual accuracy is paramount.

Security Concerns: As these agents ga
in more autonomy and potentially access sensitive data or external tools, security becomes a major worry. Discussions ar
ound access control, sandboxing, and preventing malicious use are frequent.

Resource Intensive: Running complex agents 
can be computationally expensive, especially when interacting with powerful language models. Users are mindful of the co
st implications for development and deployment.

Ethical Considerations: The potential for misuse, bias, and unintended 
consequences with autonomous agents is a recurring theme in discussions. Users are grappling with the ethical implicatio
ns of deploying these powerful technologies.

The 'Demo vs. Reality' Gap: There's a feeling that some of the impressive 
demos don't always translate directly into real-world, robust applications. Bridging this gap is a key challenge.

The F
uture (Where People See This Going):

Despite the challenges, the overall sentiment is optimistic about the future of AI
 agent frameworks. Users believe that as the technology matures, these frameworks will become more reliable, easier to u
se, and capable of tackling increasingly complex problems. There's a sense of being on the cusp of a significant shift i
n how we interact with and leverage AI.

Key Takeaways from User Sentiment:

High potential, early stage: Everyone agree
s there's something powerful here, but it's still relatively early days.

Usability is key: Making these frameworks more
 accessible and easier to debug is crucial for wider adoption.

Focus on reliability and safety: Addressing the concerns
 around hallucinations, security, and ethical implications is paramount for building trust.

Practical applications are 
the goal: While the theoretical possibilities are exciting, users are eager to see more concrete examples of real-world 
value.

What are your thoughts? Have you been experimenting with AI agent frameworks? What are your biggest excitements 
and concerns? Share your experiences in the comments below!



```
---

     
 
all -  [ RA.Aid v0.10.0 - Web research, interactive chat, and more ](https://www.reddit.com/r/LocalLLaMA/comments/1hlf7tz/raaid_v0100_web_research_interactive_chat_and_more/) , 2024-12-27-0913
```
Hey all,

Following up on: [https://www.reddit.com/r/LocalLLaMA/comments/1hczbla/aider\_langchain\_a\_match\_made\_in\_h
eaven/](https://www.reddit.com/r/LocalLLaMA/comments/1hczbla/aider_langchain_a_match_made_in_heaven/)

Just wanted to sh
are an update on RA.Aid v0.10.0. If you haven't come across RA.Aid before, it's our community's open-source autonomous A
I dev agent. It works by placing AI into a ReAct loop, much like windsurf, cursor, devin, or [aide.dev](http://aide.dev)
, but it's completely free and under the Apache License 2.0.

What's New?

* Web Research: RA.Aid can now pull informati
on from the web, making it smarter and more relevant to your coding needs.
* Interactive Chat Mode: With the --chat flag
, you can now guide RA.Aid directly, asking questions or redirecting tasks.
* Ctrl-C Interrupt: You can interrupt its pr
ocess anytime to give feedback or change direction, or just exit.

Why RA.Aid?

* Community Built: This project thrives 
on our collective efforts. Let's make this our dev agent.
* Open Source: No paywalls here, just open collaboration for a
ll.
* Versatile: From refactoring to feature implementation, RA.Aid is there for you.

Contribute or Check it Out:

* Ex
plore RA.Aid:¬†[https://github.com/ai-christianson/RA.Aid](https://github.com/ai-christianson/RA.Aid)
* Contribute: Wheth
er it's code, ideas, or bug reports, your input shapes RA.Aid.
* Feedback: Got thoughts? Let's discuss them in the issue
s.

Let's keep building RA.Aid together into something truly useful for the developer community.

Happy coding! üíª‚ú®üéâ
```
---

     
 
all -  [ Roast my resume for Gen AI/ ML based roles. Genuinely needed ](https://www.reddit.com/r/developersIndia/comments/1hlecai/roast_my_resume_for_gen_ai_ml_based_roles/) , 2024-12-27-0913
```
https://preview.redd.it/6qeiz7d11t8e1.png?width=674&format=png&auto=webp&s=161278aa43310409a13f382c4354a9846efe5231

Ple
ase review my resume and roast the fuck out of it but be genuine
```
---

     
 
all -  [ How to handle complexe rag locally ? ](https://www.reddit.com/r/Rag/comments/1hlcdy6/how_to_handle_complexe_rag_locally/) , 2024-12-27-0913
```
Complex multiple files rag
Hello, I'm working on a project related to build a streamlit chat application that allows use
rs ( project holders ) to boost their projects across different stages and help them prepare for presenting their projec
ts within a startup programm,  I have for this rag app , 40 pdfs ( 40 projects ) and a guide.pdf ( cookbook) , this guid
e shows the different stages and phases the project passes by and how to get financement and support from different enti
ties and banks, I used langchain + faiss + ollama + llama 3.2 + hugging face embedding for this project ( data is very p
rivate ) ! The app dosent work well since I want the assistant to follow the rules provided in the guide and consider th
e details of each project to guide the user since the user is a project owner while Leveraging the llama 3.2 capabilitie
s to suggest solution that matches the guide and stages and also to zoom on the corresponding project.
Thank you
```
---

     
 
all -  [ Complex multiple files rag ](https://www.reddit.com/r/LangChain/comments/1hlc16g/complex_multiple_files_rag/) , 2024-12-27-0913
```
Hello, I'm working on a project related to build a streamlit chat application that allows users ( project holders ) to b
oost their projects across different stages and help them prepare for presenting their projects within a startup program
m,  I have for this rag app , 40 pdfs ( 40 projects ) and a guide.pdf ( cookbook) , this guide shows the different stage
s and phases the project passes by and how to get financement and support from different entities and banks, I used lang
chain + faiss + ollama + llama 3.2 + hugging face embedding for this project ( data is very private ) ! The app dosent w
ork well since I want the assistant to follow the rules provided in the guide and consider the details of each project t
o guide the user since the user is a project owner while Leveraging the llama 3.2 capabilities to suggest solution that 
matches the guide and stages and also to zoom on the corresponding project.
Thank you
```
---

     
 
MachineLearning -  [ [P] Minima: local conversational retrieval augmented generation project (Ollama, Langchain, FastAPI, ](https://www.reddit.com/r/MachineLearning/comments/1h1pudq/p_minima_local_conversational_retrieval_augmented/) , 2024-12-27-0913
```
  
[https://github.com/dmayboroda/minima](https://github.com/dmayboroda/minima)  
  
Hey everyone, I would like to intro
duce you my latest repo, that is a local conversational rag on your files, Be honest, you can use this as a rag on-premi
ses, cause it is build with docker, langchain, ollama, fastapi, hf All models download automatically, soon I'll add an a
bility to choose a model For now solution contains:

* Locally running Ollama (currently qwen-0.5b model hardcoded, soon
 you'll be able to choose a model from ollama registry)
* Local indexing (using sentence-transformer embedding model, yo
u can switch to other model, but only sentence-transformers applied, also will be changed soon)
* Qdrant container runni
ng on your machine
* Reranker running locally (BAAI/bge-reranker-base currently hardcoded, but i will also add an abilit
y to choose a reranker)
* Websocket based chat with saving history
* Simple chat UI written with React
* As a plus, you 
can use local rag with ChatGPT as a custom GPT, so you able to query your local data through official chatgpt web and ma
c os/ios app.
* You can deploy it as a RAG on-premises, all containers can work on CPU machines

Couple of ideas/problem
s:

* Model Context Protocol support
* Right now there is no incremental indexing or reindexing
* No selection for the m
odels (will be added soon)
* Different environment support (cuda, mps, custom npu's)

Welcome to contribute (watch, fork
, star) Thank you so much!
```
---

     
