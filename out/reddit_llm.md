 
all -  [ [0 YOE, Unemployed , Machine Learning/Data Science, India] ](https://www.reddit.com/r/resumes/comments/1hc0c61/0_yoe_unemployed_machine_learningdata_science/) , 2024-12-12-0914
```
https://preview.redd.it/pbevskapi96e1.png?width=1170&format=png&auto=webp&s=6c61dfd3845cd82bc1ca6eeac19c00a2049231a8

ht
tps://preview.redd.it/wz65kahqi96e1.png?width=1070&format=png&auto=webp&s=b368ed92fd9cb957c2a0e1d6f4dee03f1bbbc58d

I am
 a 3rd year student pursuing BTech. I need feedback for applying to internships. As of now, I am not getting shortlisted
. What kind of projects do I need to add or showcase which will catch the attention. am i missing something here
```
---

     
 
all -  [ Conversational avatar  ](https://www.reddit.com/r/LangChain/comments/1hbxlfs/conversational_avatar/) , 2024-12-12-0914
```
Has anyone tried creating this kind of project? 
```
---

     
 
all -  [ Local tool calling agents using LangChain and Ollama are inexplicably poorly performing ](https://www.reddit.com/r/LocalLLaMA/comments/1hbx96u/local_tool_calling_agents_using_langchain_and/) , 2024-12-12-0914
```
Hi all,

Has anyone tried to create tool calling agents with LangChain and Ollama?  My attempts have been almost univers
ally unsuccessful.  Problems include:

1. Losing the ability to chat

2. Calling tools when it is not appropriate

3. Ca
lling tools on non-sensical inputs

The same agents work fine on, e.g., openai.

I have encountered this on a variety of
 models on Ollama.  Oddly enough, llama3-groq-tool-use:8b is the lone model that seems to work reasonably.

Has anyone e
ncountered this and determined the cause?

Here's a draft notebook/blog where I have some experiments: [https://colab.re
search.google.com/drive/1DngmKINhV95iKVVGF7YC5\_K7oiujMT6q?usp=sharing](https://colab.research.google.com/drive/1DngmKIN
hV95iKVVGF7YC5_K7oiujMT6q?usp=sharing)
```
---

     
 
all -  [ We built a frontend framework for LangGraph ](https://www.reddit.com/r/LangChain/comments/1hbw7yj/we_built_a_frontend_framework_for_langgraph/) , 2024-12-12-0914
```
At [CopilotKit](https://github.com/CopilotKit/CopilotKit), we build components & tools that help developers build in-app
 AI assistants (like Chatbots). Over the last few months we've been working to support deeper in-app Agent integrations.
  

  
So we collaborated with the LangChain team, to build a toolset that helps users integrate their LangGraph agents 
into full-stack apps with full support across the LangGraph ecosystem (Python, JS, Cloud, Studio, etc). 



Our new [Co-
Agents release](https://www.copilotkit.ai/blog/build-full-stack-apps-with-langgraph-and-copilotkit) contains tools that 
allow you to: 

\- Stream an agent's intermediate state (to the frontend) 

\- Share real-time state between the agent &
 the application 

\- Allow the Agent to take actions in your application 

\- Human-in-the-loop to steer and correct ag
ents (built with LangGraph breakpoints) 

\- Agentic Generative UI 

In our new release we support LangGraph JS, Python,
 LangGraph Platform (Cloud) and LangGraph Studio. 

  
You can build an Agentic Application in just a few minutes with L
angGraph & Co-Agents and we have great demos and [tutorials](https://go.copilotkit.ai/ai-travel-demo-video) to guide you
. 

  
We're fully open-source (MIT), get started here: 

[https://github.com/CopilotKit/CopilotKit](https://github.com/
CopilotKit/CopilotKit)

https://preview.redd.it/rwy3ec0ho86e1.png?width=993&format=png&auto=webp&s=e910313e67dfeecf90661
d36816d2298952e1b7a
```
---

     
 
all -  [ LangChain Academy New Course: Introduction to LangSmith ](https://www.youtube.com/watch?v=KcGoJPK-0tY) , 2024-12-12-0914
```

```
---

     
 
all -  [ Stripe agent toolkit useful? ](https://www.reddit.com/r/LangChain/comments/1hbtz8f/stripe_agent_toolkit_useful/) , 2024-12-12-0914
```
Anyone using the Stripe agent toolkit https://github.com/stripe/agent-toolkit? 

I've been trying to automate payments (
with human in the loop confirmation) for customer support using the langchain part of their agent, but only 10 tools are
 so exposed.   
Anyone extended/using it?
```
---

     
 
all -  [ [For Hire] Programmer/Web Developer/IT Consultant (Python, PHP, AI, etc.) ](https://www.reddit.com/r/forhire/comments/1hbsdu1/for_hire_programmerweb_developerit_consultant/) , 2024-12-12-0914
```
To get in contact, please message me, I don't use the chat thing and might miss you or reply very late. Then we can swit
ch to email/discord/telegram or whatever else. Apologies for starting with this, but many missed it when it was lower.


I'm a programmer/web developer with 15 years of professional experience. I am available for all sorts of programming and
 web development tasks.

I also offer consulting services. If you need something done, but don't know how exactly, I can
 help. I'm an excellent researcher and I communicate well. I will work with you to find the best solution for your probl
em.

My services include, but are not limited to:

* websites

* desktop applications

* AI integration (chatGPT API, la
ngchain, whatever else turns up)

* integration with APIs and other webservices

* all kinds of scripts

* task automati
on

* website optimization

* debugging

* plugins for existing software

* bots (Reddit, Telegram, etc)

* code audits


If you're looking for someone to take care of a variety of different tasks, I can offer continuous support.

My preferr
ed environment is Python with Django, but I work with anything Python or PHP based. I have no problem with learning new 
technologies that are needed for the project.

Rate is $60/h.

Portfolio:

https://bdabkowski.yum.pl

Satisfied customer
s:

https://www.reddit.com/r/testimonials/comments/2e8gqy/pos_uqui_need_a_backend_web_dev_look_no_further/

https://www.
reddit.com/r/testimonials/comments/7fsdze/pos_hiring_uqui_was_an_example_of_how_it_should/

https://www.reddit.com/r/tes
timonials/comments/80pu9l/pos_uqui_great_work_detailed_and_fast/

https://www.reddit.com/r/testimonials/comments/b0nx68/
uqui_is_a_hardworking_intelligent_honest_apps/

https://www.reddit.com/r/testimonials/comments/j3mz3p/uqui_is_a_great_we
b_development_consultant_with/

https://www.reddit.com/r/testimonials/comments/v40ay3/pos_uqui_is_a_great_backend_dev_to
_work_with/

Please note: I am not a designer. To make it clear, it means zero aesthetic sense.
```
---

     
 
all -  [ Which tool are you using to build Ai Agents? ](https://i.redd.it/p2j1smaff76e1.jpeg) , 2024-12-12-0914
```
As mentioned in the title, Curious to know which tool is the most effective. 

I'm using Langchain and my own custom too
ls as of now for creatingagents in my currentprojects. Used flowise before and did not try N8N completely.
```
---

     
 
all -  [ Need advice on hosting LLM on GPU in production ! ](https://www.reddit.com/r/LangChain/comments/1hbqtss/need_advice_on_hosting_llm_on_gpu_in_production/) , 2024-12-12-0914
```
I currently have A40 single GPU of 48GB VRAM. I want to host Qwen2.5 14B Instruct AWQ model in it. I tried hosting it us
ing Nvidia Triton + VLLM backend. I want to use this model for RAG application. Due to some concerns, My prompt to the R
AG is so high (\~20 lines). The GPU Utilization is around 80-90% for a single hit and it is taking around 4-5 sec to res
pond. But, When there are concurrent requests to the same API, the latency is spiking up. Even if there two concurrent r
equests, time taken to respond is around 7-9 sec. I want to scale this application for 500 users. I need advice on below
 areas.   
1. How much GPU should I need to use? Should I use a single GPU or Multi GPU for this task?  
2. What serving
 platform should I have to use other than Nvidia-Triton + VLLM backend to achieve greater throughput?  
I'm new to this.
 Could you please help me out?
```
---

     
 
all -  [ Beyond table parsing in RAG: table data understanding ](https://www.reddit.com/r/LangChain/comments/1hbq78j/beyond_table_parsing_in_rag_table_data/) , 2024-12-12-0914
```
Proper parsing of tables in RAG is really important. As we looked at this problem we wanted to do something that provide
s true understanding of tables across the complete RAG flow - from parsing through retrieval. Excited to share this new 
functionality available with Vectara, and curious to hear what you all think, and how to further improve this.

[https:/
/www.vectara.com/blog/table-data-understanding](https://www.vectara.com/blog/table-data-understanding)
```
---

     
 
all -  [ Looking for Resources to Learn AI Agents and Build a Roadmap with LangChain ](https://www.reddit.com/r/LangChain/comments/1hbps28/looking_for_resources_to_learn_ai_agents_and/) , 2024-12-12-0914
```
Hi everyone,
I'm diving into the world of AI and looking to focus on building AI agents using LangChain. I'm interested 
in understanding the roadmap, best practices, and any recommended tutorials, courses, or documentation that could help m
e get started.

Are there any must-read resources, GitHub repositories, or online communities you'd recommend? If you've
 worked with LangChain, I'd love to hear about your learning journey and tips.

Thanks in advance for your help!
```
---

     
 
all -  [ Not getting shortlisted by resume off campus. Roast my resume. ](https://www.reddit.com/r/developersIndia/comments/1hboym6/not_getting_shortlisted_by_resume_off_campus/) , 2024-12-12-0914
```
I am a final-year undergraduate at a tier 1 engineering college. Despite securing an offer from a tier 1 software compan
y through an on-campus process (which required no resume shortlisting, only a competitive programming round followed by 
interviews), I am struggling to get my resume shortlisted off-campus. Even startups on platforms like Wellfound/LinkedIn
, offering unpaid or low-paying roles, are not considering my application. Any suggestion is highly appreciated.

https:
//preview.redd.it/wc8daf8ei66e1.png?width=1190&format=png&auto=webp&s=d8f8707af1031ae8e8dd4d814a8ccf6f427cb682


```
---

     
 
all -  [ What’s Your Biggest Challenge with Automation? ](https://www.reddit.com/r/LangChain/comments/1hbnird/whats_your_biggest_challenge_with_automation/) , 2024-12-12-0914
```
Hi guys, I’ve been working on a SaaS of mine called [Wellows.com](http://wellows.com/), designed to simplify workflow au
tomation using just natural language prompts. The idea came from my own frustration with how complex and time-consuming 
automation can be setting up workflows, syncing tools, and managing repetitive tasks shouldn’t take hours.

Here’s where
 we’re at:

* The platform is in its final development stages, and we’re focusing on building something that works for r
eal teams with real challenges.
* I’ve seen SaaS teams struggle to automate critical tasks like onboarding new users, sy
ncing data across tools, and generating usage reports. Our goal is to eliminate that pain.

Here’s what I’ve learned so 
far from this journey:

1. **Understanding pain points is key.** Every team’s struggles with automation are unique. I’ve
 been speaking with SaaS teams to learn where workflows break down and what’s stopped them from automating more.
2. **Si
mple wins.** The feedback I’ve received highlights that people don’t want another complex tool they want an intuitive so
lution that saves them time, not one that eats it up.
3. **Collaboration is everything.** Working closely with early tes
ters has shown me that user input is invaluable. Their insights have helped shape features that address real-world probl
ems, not just hypothetical ones.

**Here’s what’s next:**  
We’re gearing up to launch soon and are actively looking for
 feedback to refine the platform further. If you’re struggling with a task that’s tough to automate or if you’ve been he
sitant to dive into automation, let’s talk. I’d love to hear about your experiences and brainstorm solutions together.


So tell me, what’s the #1 task your team struggles to automate?
```
---

     
 
all -  [ Slick agent tracing via Pydantic Logfire with zero instrumentation for common scenarios… ](https://i.redd.it/rfb97v4wx46e1.jpeg) , 2024-12-12-0914
```

Disclaimer: I don’t work for Pydantic Logfire. But I do help with dev relations for Arch(Gateway)

If you are building 
agents and want rich agent (prompt + tools + LLM) observability, imho Pydantic logfire offers the most simple setup and 
visually appealing experience - especially when combined with https://github.com/katanemo/archgw

archgw is an intellige
nt gateway for agents that offers fast⚡️function calling, rich LLM tracing (source events) and guardrails 🧱 so that deve
lopers can focus on what matters most.

With zero lines of application code and rich out-of-the-box tracing for agents (
prompt, tools call, LLM) via Arch and Logfire. 

Checkout the demo here: https://github.com/katanemo/archgw/tree/main/de
mos/weather_forecast

```
---

     
 
all -  [ RAG Semi_structured data processing  ](https://www.reddit.com/r/LangChain/comments/1hbirst/rag_semi_structured_data_processing/) , 2024-12-12-0914
```
I'm creating a rag pipeline for semi and Unstructured pdf documents.For parsing the pdf I'm using Pymupdf4llm and the fi
nal format of text is markdown 

Main issues:
1.chunking: what is the best chucking strategy to split them by their head
ers and I have tables which I don't want to split them 


2. Tables handling: if my table is continuing in 3 pages then 
the header is not maintained in all pages and it is not able to answer it correctly 

If I'm maintaining the previous pa
ge context of 30% in this page then when answering it is considering that chunk and while returning it is giving that pa
ge as the answer page and confusing from which page the actual answer is really from

3.Complex tables analysis:While th
e questions are from a complex table whicj contains all numbers and very less text data in it ,so while retrievering it 
is considering the chunks where it find the same numbers but llm is every time answering differently and not able to sol
ve it.




Please help me out 

Using: Pymupdf4llm,Langchain,Langgraph,python,Groq,llama 3.1 70b model
```
---

     
 
all -  [ Best practices for rag ](https://www.reddit.com/r/LLMDevs/comments/1hbes3d/best_practices_for_rag/) , 2024-12-12-0914
```
Hi llmdevs! Any suggestions on best practices for rag? For a beginner? I have been playing around with rag for about a m
onth now, and what all knowledge i have so far is what is given by openai and Claude that helped me with my project. I a
m not getting desired results back so iam assuming there are issues with my setup.

I've tried llamaindex and langchain 
and their default chucking embedding tools (along with custom chucking with cosine similarity as suggested by openai). A
nd worked with faiss and qdrant so far as my vector stores along with llama various versions and openai.

My use case ha
s to do with public sec filings (and one day private financial data from my company, if my setup works).

If it were you
, how would go about setting up the stack? Any help is greatly appreciated. Will answer any missing pieces of informatio
n. 
```
---

     
 
all -  [ Need help: Infinite Loop on RNEventSource with Server-Sent Events (SSE) - Only Receiving “attempt: 1 ](https://www.reddit.com/r/reactnative/comments/1hbepuo/need_help_infinite_loop_on_rneventsource_with/) , 2024-12-12-0914
```
I am working on a React Native expo managed project using RNEventSource to handle Server-Sent Events (SSE) from a langch
ain endpoint. My backend is correctly streaming data (confirmed via Postman), but the frontend gets stuck in an infinite
 loop of the same response, only receiving:

    LOG  Open SSE connection.
    LOG  Stream Data: {'attempt': 1, 'run_id'
: '1efb7463-0ff8-60c3-bd10-17ccc210899f'}
    WARN  Unexpected Data: {'run_id':'1efb7463-0ff8-60c3-bd10-17ccc210899f','a
ttempt':1}
    LOG  Stream Data: {'attempt': 1, 'run_id': '1efb7463-0ff8-60c3-bd10-17ccc210899f'}
    WARN  Unexpected D
ata: {'run_id':'1efb7463-0ff8-60c3-bd10-17ccc210899f','attempt':1'}
    ...

Code:  


    const askDogy = async (reques
t) => {
      const url = `${assitantBaseUrl}/threads/${threadId}/runs/stream`
      const requestBody = JSON.stringify(
{
        assistant_id: assistantID,
        input: {
          messages: [{ role: 'user', content: request }],
        
},
        stream_mode: ['messages'],
      })
    
      const options = {
        body: requestBody,
        method: '
POST',
        headers: {
          'Content-Type': 'application/json',
          Accept: 'text/event-stream',
        }
,
      }
    
      eventSourceRef.current = new RNEventSource(url, options)
    
      eventSourceRef.current.addEvent
Listener('open', () => {
        console.log('Open SSE connection.')
      })
    
      eventSourceRef.current.addEvent
Listener('message', (event) => {
        console.log('Raw Event:', event)
        try {
          const data = JSON.pars
e(event.data)
          console.log('Parsed Data:', data)
    
          if (data.content) {
            console.log('AI
 Reply Content:', data.content)
            setChatResponse('Bot', data.content, true)
          } else {
            co
nsole.warn('Unexpected Data:', data)
          }
        } catch (error) {
          console.error('Error parsing event 
data:', error)
        }
      })
    
      eventSourceRef.current.addEventListener('error', (error) => {
        conso
le.error('Stream error:', error)
    
            if (error.status === 409) {
              console.log('Conflict detect
ed, creating a new thread...')
              // Create a new thread and retry
              tempThreadId = await createT
hread()
              if (!tempThreadId)
                throw new Error('Failed to create a new thread after conflict')

              setThreadId(tempThreadId)
    
              // Retry the stream with the new thread ID
              con
sole.log('Retrying with new thread ID:', tempThreadId)
              await askDogy(request) // Recursive call with the n
ew thread
            } else {
              handleStopStream()
            }
      })
    }

  
**Debugging Observation
s:**

* I receive the same attempt: 1 data repeatedly with no progress.
* The backend should send incremental updates, b
ut the frontend logs do not show progress.

**Questions:**

* Is there a known issue with RNEventSource or its compatibi
lity with React Native?
* Could there be something specific I need to handle in RNEventSource to parse incremental updat
es?
* Any other npm package/library I can use to handle server sent events in react native/expo?

**Things I've tried:**


* Verified backend compliance with the SSE spec.
* Ensured RNEventSource initialization includes proper headers and me
thod.
* Added maximum retries and timeout logic in case of backend failures (now removed).
* Tested backend with Postman
 and it streams correctly.

  
Thanks in advance. Link to [stackoverflow post](https://stackoverflow.com/questions/79270
017/infinite-loop-on-rneventsource-with-server-sent-events-sse-only-receiving-a)
```
---

     
 
all -  [ [For Hire] Experienced AI/Full Stack & DevOps Developer – Seeking Challenging, High-Impact Projects! ](https://www.reddit.com/r/forhire/comments/1hbbhib/for_hire_experienced_aifull_stack_devops/) , 2024-12-12-0914
```
🚀 **Your All-in-One Solution for AI/ML, Full Stack Development, and DevOps!**

👋 Hi, I’m Sheryar, an experienced AI/ML E
ngineer, Full Stack Developer, and DevOps Specialist. I’m here to help turn your ideas into scalable, high-performance s
olutions!

💻 **Full Stack Development Expertise**  
🔹 Stunning UIs: React/Angular  
🔹 Robust APIs: Node.js, NestJS  
🔹 S
eamless Payment Integration: Stripe  
🔹 Cloud Infrastructure: AWS, GCP

🤖 **AI & Machine Learning**  
🔹 Smart Chatbots: 
Built with LangChain  
🔹 Custom AI Models: NLP, Automation

⚙️ **DevOps Solutions**  
🔹 CI/CD Pipelines: GitHub Actions,
 Jenkins  
🔹 Containerization: Docker, Kubernetes  
🔹 Infrastructure as Code: Terraform, Ansible  
🔹 Monitoring Tools: P
rometheus, Grafana

🌟 **Recent Projects**  
🚗 **Ride-Sharing**: Real-time tracking & payments  
📦 **Logistics**: Multi-s
top delivery optimization  
🛒 **E-Commerce**: Scalable Kubernetes clusters

💰 **Rates**: $20–$25/hour (negotiable)  
📧 *
*Let’s talk!** DM me to discuss your project!  
GitHub: [storm1033](https://github.com/storm1033)

**Let’s build somethi
ng amazing together!** 🌐✨

# 🌟 Let's Build Something Amazing Together! 🌟

# 👋 Hi, I'm Sheryar!

An AI/ML Engineer, Full 
Stack Developer, and DevOps Specialist. I help transform ideas into scalable, high-performance solutions. Whether you're
 looking to build a robust app, deploy intelligent AI systems, or streamline your infrastructure, I’ve got you covered!


# 🚀 What I Do Best:

# Full Stack Development

From sleek, user-friendly interfaces to powerful backends, I create seam
less web applications:

* **Stunning UIs**: React | Angular
* **Robust APIs**: Node.js | NestJS
* **Seamless Payment Int
egrations**: Stripe
* **Cloud Infrastructure**: AWS | GCP

# AI & Machine Learning

Unlock the potential of AI to elevat
e your product with intelligent, data-driven features:

* **AI Chatbots**: Powered by LangChain
* **Tailored AI Models**
: NLP, Automation, and more

# DevOps Excellence

I automate, optimize, and ensure reliability at scale:

* **CI/CD Pipe
lines**: GitHub Actions | Jenkins
* **Containerization**: Docker | Kubernetes
* **Infrastructure as Code**: Terraform | 
Ansible
* **Monitoring**: Prometheus | Grafana

# 🌟 Featured Projects

Here’s a glimpse of what I’ve worked on recently:


* **Ride-Sharing App**: Real-time vehicle tracking, seamless payments
* **Logistics Platform**: Multi-stop delivery ro
ute optimization
* **E-Commerce Platform**: Scalable Kubernetes clusters handling high traffic

# 💡 Let’s Collaborate!


* 💰 **Rate**: $20–$25/hour (negotiable depending on the project)
* 📩 **Reach Out**: DM me to discuss your project!

📍 **
GitHub**: [storm1033](https://github.com/storm1033)

**Let's turn your ideas into scalable, impactful solutions!** 🌐✨
```
---

     
 
all -  [ What is your go-to way of calling LLMs ?  ](https://www.reddit.com/r/node/comments/1hba5qq/what_is_your_goto_way_of_calling_llms/) , 2024-12-12-0914
```
For once, nodejs is not the main area of experimentation, we are a bit behind python for tooling. Still, what do y'all u
se for interfacing with llms ? For validating structured data ?

I know people hate on langchain, but there has to be so
mething better than raw openai package?
```
---

     
 
all -  [ How do you go about building a cursor/codeium clone ](https://www.reddit.com/r/LangChain/comments/1hb5yzl/how_do_you_go_about_building_a_cursorcodeium_clone/) , 2024-12-12-0914
```
So I want to build a similar UI like cursor. But I don’t want this for code. What I want is a dashboard/canvas on one si
de and a chat interface on another where the user can add stuff to chat from the dashboard and the AI can answer them. W
ould love to know how you guys think this can be built 
```
---

     
 
all -  [ Using Ollama and getting validation-error at invoke-function ](https://www.reddit.com/r/LangChain/comments/1hb55e6/using_ollama_and_getting_validationerror_at/) , 2024-12-12-0914
```
I am currently trying out Ollama for the first time and following a few tutorials (for example this one: https://python.
langchain.com/docs/integrations/llms/ollama/). Even though ollama is working perfectly fine in the terminal, the moment 
I try to use it in VSC through langchain, I get a Validation-Error, that tells me, my Input should be json and a diction
ary. Can anybody help me with this/do you have any idea what I am doing wrong? I have already reinstalled llama and the 
models

https://preview.redd.it/c2zxcn4zn16e1.png?width=1162&format=png&auto=webp&s=80f65b2155fb74a3f5c02e9038a78e65c254
4d80

https://preview.redd.it/a3zgindzn16e1.png?width=1107&format=png&auto=webp&s=b4af5d820386520ebd53892e92c965a9aa5313
46

  
  

```
---

     
 
all -  [ Using Ollama in Langchain and getting validation-error at invoke-function ](https://www.reddit.com/r/ollama/comments/1hb55c4/using_ollama_in_langchain_and_getting/) , 2024-12-12-0914
```
I am currently trying out Ollama for the first time and following a few tutorials (for example this one: https://python.
langchain.com/docs/integrations/llms/ollama/). Even though ollama is working perfectly fine in the terminal, the moment 
I try to use it in VSC through langchain, I get a Validation-Error, that tells me, my Input should be json and a diction
ary. Can anybody help me with this/do you have any idea what I am doing wrong? I have already reinstalled llama and the 
models

https://preview.redd.it/c2zxcn4zn16e1.png?width=1162&format=png&auto=webp&s=80f65b2155fb74a3f5c02e9038a78e65c254
4d80

https://preview.redd.it/a3zgindzn16e1.png?width=1107&format=png&auto=webp&s=b4af5d820386520ebd53892e92c965a9aa5313
46


```
---

     
 
all -  [ Voice agent companies - how are you monitoring and evaluating your calls? ](https://www.reddit.com/r/LangChain/comments/1hb0gyc/voice_agent_companies_how_are_you_monitoring_and/) , 2024-12-12-0914
```
We’re building [Roark Analytics](https://roark.ai/) (voice agent performance analytics) and are curious how other compan
ies monitor and evaluate their calls to improve agent performance.

* Are you tracking metrics like sentiment, intent ac
curacy, or call success rates?
* How are you identifying issues or areas for improvement?
* Do you analyze calls in real
-time or focus on post-call insights?

We’d love to learn more about the tools or strategies you’re using (or wish exist
ed) to monitor and evaluate your voice agents effectively.
```
---

     
 
all -  [ Looking for suggestions on AI courses around LLMs  ](https://www.reddit.com/r/developersPak/comments/1hb04r1/looking_for_suggestions_on_ai_courses_around_llms/) , 2024-12-12-0914
```
So, I used to do AI, mainly Deep Learning back in 2020, 2021 when LLMs were not a thing, I worked on a bunch of freelanc
e projects related to debugging, fine tuning etc so I'm comfortable with NLP, computer vision and stuff. I moved to full
stack webdev in 2023 and then to blockchain web dev so Ive been very disconnected with the new things. 

Im looking for 
any suggestions on systematic pathways to work on production ready llm based apps, I know the basics like langchain and 
RAG but Im completely blank on optimisations, best practices, agents, chains, etc. Can anyone here suggest a course or s
omething? 
```
---

     
 
all -  [ I asked a mobster what he thinks about langchain ](https://www.reddit.com/gallery/1hazuut) , 2024-12-12-0914
```
Loose lips sink ships 👀
```
---

     
 
all -  [ Hierarchical chunking ](https://www.reddit.com/r/LangChain/comments/1hazl77/hierarchical_chunking/) , 2024-12-12-0914
```
Hello everyone,

I’m currently working on a project involving the creation of a chatbot based on RAG (Retrieval-Augmente
d Generation). For the RAG part, I want to implement hierarchical chunking, where the text is chunked hierarchically, wi
th each leaf node containing a concise summary of its hierarchy. I'm not sure if this has already been implemented, so I
’m asking for any resources, articles, or existing implementations related to hierarchical chunking. Any help would be g
reatly appreciated!
```
---

     
 
all -  [ ChatPDF and PDF.ai are making millions using open source tech... here's the code ](https://www.reddit.com/r/SideProject/comments/1hazgkb/chatpdf_and_pdfai_are_making_millions_using_open/) , 2024-12-12-0914
```
# Why 'copy' an existing product?

The best SaaS products weren’t the first of their kind - think Slack, Shopify, Zoom, 
Dropbox, or HubSpot. They didn’t invent team communication, e-commerce, video conferencing, cloud storage, or marketing 
tools; they just made them better.



# What is a 'Chat with PDF' SaaS?

These are AI-powered PDF assistants that let yo
u upload a PDF and ask questions about its content. You can summarize articles, extract key details from a contract, ana
lyze a research paper, and more. To see this in action or dive deeper into the tech behind it, check out this [YouTube v
ideo.](https://www.youtube.com/watch?v=ih9PBGVVOO4)



# Let's look at the market

Made possible by advances in AI like 
ChatGPT and Retrieval-Augmented Generation (RAG), PDF chat tools started gaining traction in early 2023 and have seen co
nsistent growth in market interest, which is currently at an all-time high (source:[google trends](https://trends.google
.com/trends/explore?date=today%205-y&q=pdf%20chat,pdf%20ai&hl=en-GB))

Keywords like 'chat PDF' and 'PDF AI' get between
 1 to 10 million searches every month (source:keyword planner), with a broad target audience that includes researchers, 
students, and professionals across various industries.

Leaders like [PDF.ai](http://PDF.ai) and ChatPDF have already ga
ined millions of users within a year of launch, driven by the growing market demand, with paid users subscribing at arou
nd $20/month.



# Alright, so how do we build this with open source?

The core tech for most PDF AI tools are based on 
the same architecture. You generate text embeddings (AI-friendly text representations; usually via OpenAI APIs) for the 
uploaded PDF’s chapters/topics and store them in a vector database (like Pinecone).

Now, every time the user asks a que
stion, a similarity search is performed to find the most similar PDF topics from the vector database. The selected topic
 contents are then sent to an LLM (like ChatGPT) along with the question, which generates a contextual answer!

Here are
 some of the best open source implementations for this process:

* [GPT4 & LangChain Chatbot for large PDF docs](https:/
/github.com/mayooear/gpt4-pdf-chatbot-langchain) by Mayo Oshin
* [MultiPDF Chat App](https://github.com/alejandro-ao/ask
-multiple-pdfs) by Alejandro AO
* [PDFToChat](https://github.com/Nutlope/pdftochat) by Hassan El Mghari

Worried about b
uilding signups, user management, payments, etc.? Here are my go-to open-source SaaS boilerplates that include everythin
g you need out of the box:

* [SaaS Boilerplate](https://github.com/ixartz/SaaS-Boilerplate) by Remi Wg
* [Open SaaS](ht
tps://github.com/wasp-lang/open-saas) by wasp-lang



# A few ideas to stand out from the noise:

Here are a few strateg
ies that could help you differentiate and achieve product market fit (based on the pivot principles from The Lean Startu
p by Eric Ries):

1. **Narrow down your target audience for a personalized UX:** For instance, an exam prep assistant fo
r students with study notes and quiz generator; or a document due diligence and analysis tool for lawyers.
2. **Add uniq
ue features to increase switching cost:** You could autogenerate APIs for the uploaded PDFs to enable remote integration
s (eg. support chatbot knowledge base); or build in workflow automation features for bulk analyses of PDFs.
3. **Offer p
latform level advantages:** You could ship a native mobile/desktop apps for a more integrated UX; or (non-trivial) offer
 private/offline support by replacing the APIs with local open source deployments (eg. llama for LLM, an embedding model
 from the MTEB list, and FAISS for vector search).

**TMI?** I’m an ex-AI engineer and product lead, so don’t hesitate t
o reach out with any questions!

**P.S.** I've started a free weekly [newsletter](https://saaswithcode.substack.com/p/is
sue-1-launch-a-saas-like-chatpdf) to share open-source/turnkey resources behind popular products (like this one). If you
’re a founder looking to launch your next product without reinventing the wheel, please subscribe :)
```
---

     
 
all -  [ ChatPDF and PDF.ai are making millions using open source tech... here's the code ](https://www.reddit.com/r/EntrepreneurRideAlong/comments/1haykyq/chatpdf_and_pdfai_are_making_millions_using_open/) , 2024-12-12-0914
```
# Why 'copy' an existing product?

The best SaaS products weren’t the first of their kind - think Slack, Shopify, Zoom, 
Dropbox, or HubSpot. They didn’t invent team communication, e-commerce, video conferencing, cloud storage, or marketing 
tools; they just made them better.



# What is a 'Chat with PDF' SaaS?

These are AI-powered PDF assistants that let yo
u upload a PDF and ask questions about its content. You can summarize articles, extract key details from a contract, ana
lyze a research paper, and more. To see this in action or dive deeper into the tech behind it, check out this [YouTube v
ideo.](https://www.youtube.com/watch?v=ih9PBGVVOO4)



# Let's look at the market

Made possible by advances in AI like 
ChatGPT and Retrieval-Augmented Generation (RAG), PDF chat tools started gaining traction in early 2023 and have seen co
nsistent growth in market interest, which is currently at an all-time high (source: google trends)

Keywords like 'chat 
PDF' and 'PDF AI' get between 1 to 10 million searches every month (source:keyword planner), with a broad target audienc
e that includes researchers, students, and professionals across various industries.

Leaders like PDF.ai and ChatPDF hav
e already gained millions of users within a year of launch, driven by the growing market demand, with paid users subscri
bing at around $20/month.



# Alright, so how do we build this with open source?

The core tech for most PDF AI tools a
re based on the same architecture. You generate text embeddings (AI-friendly text representations; usually via OpenAI AP
Is) for the uploaded PDF’s chapters/topics and store them in a vector database (like Pinecone).

Now, every time the use
r asks a question, a similarity search is performed to find the most similar PDF topics from the vector database. The se
lected topic contents are then sent to an LLM (like ChatGPT) along with the question, which generates a contextual answe
r!

Here are some of the best open source implementations for this process:

* [GPT4 & LangChain Chatbot for large PDF d
ocs](https://github.com/mayooear/gpt4-pdf-chatbot-langchain) by Mayo Oshin
* [MultiPDF Chat App](https://github.com/alej
andro-ao/ask-multiple-pdfs) by Alejandro AO
* [PDFToChat](https://github.com/Nutlope/pdftochat) by Hassan El Mghari

Wor
ried about building signups, user management, payments, etc.? Here are my go-to open-source SaaS boilerplates that inclu
de everything you need out of the box:

* [SaaS Boilerplate](https://github.com/ixartz/SaaS-Boilerplate) by Remi Wg
* [O
pen SaaS](https://github.com/wasp-lang/open-saas) by wasp-lang



# A few ideas to stand out from the noise:

Here are a
 few strategies that could help you differentiate and achieve product market fit (based on the pivot principles from The
 Lean Startup by Eric Ries):

1. **Narrow down your target audience for a personalized UX:** For instance, an exam prep 
assistant for students with study notes and quiz generator; or a document due diligence and analysis tool for lawyers.
2
. **Add unique features to increase switching cost:** You could autogenerate APIs for the uploaded PDFs to enable remote
 integrations (eg. support chatbot knowledge base); or build in workflow automation features for bulk analyses of PDFs.

3. **Offer platform level advantages:** You could ship a native mobile/desktop apps for a more integrated UX; or (non-tr
ivial) offer private/offline support by replacing the APIs with local open source deployments (eg. llama for LLM, an emb
edding model from the MTEB list, and FAISS for vector search).



**TMI?** I’m an ex-AI engineer and product lead, so do
n’t hesitate to reach out with any questions!

**P.S.** I've started a free weekly [newsletter](https://saaswithcode.sub
stack.com/p/issue-1-launch-a-saas-like-chatpdf) to share open-source/turnkey resources behind popular products (like thi
s one). If you’re a founder looking to launch your next product without reinventing the wheel, please subscribe :)
```
---

     
 
all -  [ ChatPDF and PDF.ai are making millions using open source tech... here's the code ](https://www.reddit.com/r/SaaS/comments/1hayenp/chatpdf_and_pdfai_are_making_millions_using_open/) , 2024-12-12-0914
```
# Why 'copy' an existing product?

The best SaaS products weren’t the first of their kind - think Slack, Shopify, Zoom, 
Dropbox, or HubSpot. They didn’t invent team communication, e-commerce, video conferencing, cloud storage, or marketing 
tools; they just made them better.



# What is a 'Chat with PDF' SaaS?

These are AI-powered PDF assistants that let yo
u upload a PDF and ask questions about its content. You can summarize articles, extract key details from a contract, ana
lyze a research paper, and more. To see this in action or dive deeper into the tech behind it, check out this [YouTube v
ideo.](https://www.youtube.com/watch?v=ih9PBGVVOO4)



# Let's look at the market

Made possible by advances in AI like 
ChatGPT and Retrieval-Augmented Generation (RAG), PDF chat tools started gaining traction in early 2023 and have seen co
nsistent growth in market interest, which is currently at an all-time high (source:[google trends](https://trends.google
.com/trends/explore?date=today%205-y&q=pdf%20chat,pdf%20ai&hl=en-GB))

Keywords like 'chat PDF' and 'PDF AI' get between
 1 to 10 million searches every month (source:keyword planner), with a broad target audience that includes researchers, 
students, and professionals across various industries.

Leaders like [PDF.ai](http://PDF.ai) and ChatPDF have already ga
ined millions of users within a year of launch, driven by the growing market demand, with paid users subscribing at arou
nd $20/month.



# Alright, so how do we build this with open source?

The core tech for most PDF AI tools are based on 
the same architecture. You generate text embeddings (AI-friendly text representations; usually via OpenAI APIs) for the 
uploaded PDF’s chapters/topics and store them in a vector database (like Pinecone).

Now, every time the user asks a que
stion, a similarity search is performed to find the most similar PDF topics from the vector database. The selected topic
 contents are then sent to an LLM (like ChatGPT) along with the question, which generates a contextual answer!

Here are
 some of the best open source implementations for this process:

* [GPT4 & LangChain Chatbot for large PDF docs](https:/
/github.com/mayooear/gpt4-pdf-chatbot-langchain) by Mayo Oshin
* [MultiPDF Chat App](https://github.com/alejandro-ao/ask
-multiple-pdfs) by Alejandro AO
* [PDFToChat](https://github.com/Nutlope/pdftochat) by Hassan El Mghari

Worried about b
uilding signups, user management, payments, etc.? Here are my go-to open-source SaaS boilerplates that include everythin
g you need out of the box:

* [SaaS Boilerplate](https://github.com/ixartz/SaaS-Boilerplate) by Remi Wg
* [Open SaaS](ht
tps://github.com/wasp-lang/open-saas) by wasp-lang



# A few ideas to stand out from the noise:

Here are a few strateg
ies that could help you differentiate and achieve product market fit (based on the pivot principles from The Lean Startu
p by Eric Ries):

1. **Narrow down your target audience for a personalized UX:** For instance, an exam prep assistant fo
r students with study notes and quiz generator; or a document due diligence and analysis tool for lawyers.
2. **Add uniq
ue features to increase switching cost:** You could autogenerate APIs for the uploaded PDFs to enable remote integration
s (eg. support chatbot knowledge base); or build in workflow automation features for bulk analyses of PDFs.
3. **Offer p
latform level advantages:** You could ship a native mobile/desktop apps for a more integrated UX; or (non-trivial) offer
 private/offline support by replacing the APIs with local open source deployments (eg. llama for LLM, an embedding model
 from the MTEB list, and FAISS for vector search).



**TMI?** I’m an ex-AI engineer and product lead, so don’t hesitate
 to reach out with any questions!

**P.S.** I've started a free weekly [newsletter](https://saaswithcode.substack.com/p/
issue-1-launch-a-saas-like-chatpdf) to share open-source/turnkey resources behind popular products (like this one). If y
ou’re a founder looking to launch your next product without reinventing the wheel, please subscribe :)
```
---

     
 
all -  [ Best way to run SWE-bench on my LangGraph agents framework? ](https://www.reddit.com/r/LangChain/comments/1hax1nz/best_way_to_run_swebench_on_my_langgraph_agents/) , 2024-12-12-0914
```
I build an agentic framework in LangGraph. What's the easiest way to benchmark it on SWE-bench? 
```
---

     
 
all -  [ How can I pass dataframe as an input in Langgrah? ](https://www.reddit.com/r/LangChain/comments/1hau2yy/how_can_i_pass_dataframe_as_an_input_in_langgrah/) , 2024-12-12-0914
```
I tried to pass a dataframe that does not work, and also there is a main problem, that is could not validate in the stat
e schema.

Then I tried to pass the DataFrame as a Dict, but that also did not work. Interestingly that did not throw an
 error, but the agent was not using this \`data\_dict\`, it generates some sample DataFrame randomly. 

    graph.invoke
(
            {'messages': [HumanMessage(
    content
    =prompt)], 'data_dict': data_dict}, 
            
    config
 
   =thread
        )

  

```
---

     
 
all -  [ Converting hand drawn floor plan to professional
 ](https://www.reddit.com/r/LangChain/comments/1hasrtn/converting_hand_drawn_floor_plan_to_professional/) , 2024-12-12-0914
```
So, was hoping for some thoughts. I am trying to see if there is a way to convert hand drawn floor maps, kinda like: [ht
tps://www.reddit.com/r/floorplan/comments/1aepd6n/are\_there\_any\_tools\_that\_can\_magically\_turn\_my/](https://www.r
eddit.com/r/floorplan/comments/1aepd6n/are_there_any_tools_that_can_magically_turn_my/)

Into something more like: [http
s://cubicasa-wordpress-uploads.s3.amazonaws.com/uploads/2019/07/simple-stylish-1024x991.png](https://cubicasa-wordpress-
uploads.s3.amazonaws.com/uploads/2019/07/simple-stylish-1024x991.png)

Stable Diffusion models tend to hallucinate too m
uch to generate something even midly resembling the original drawn layout.

So I tried to go for a programmatic approach
, once I have a semi decent computer generated mimic of the hand drawn image I could iterate with an agent to add labels
, making refinements.

I tried:

1. Pass the image to an LLM with instructions to return drawing instructions for pycair
o or shapely. (failed, even GPT4o failed pretty badly in the instructions. Almost like it could understand the image but
 did not have spatial understanding (would love anyone's understanding of this))
2. Tried ezdxf for CAD drawing since i 
thought maybe the issue was with the LLM generating pycairo instructions. (also failed, even worse than the pycairo inst
ructions)
3. Now on to converting it to a SVG as a vectorized representation using VTrace which can more easily detect l
ines, polygons, etc. Feed this into (via translating function) pycairo to get a set of instructions that need to be foll
owed to draw this. Next pass the instructions to an LLM to edit back and forth until a good product is achieved. HOWEVER
, I am still unsure whether the LLM will actually be able to understand or provide helpful feedback to edit the instruct
ions for drawing (can it even?)

So reaching out, anyone run into anything similar? any open source models attempt to em
ulate what I am doing? any thoughts on the process? or any models etc that can help here.

Thanks
```
---

     
 
all -  [ Document Priority Retriever ](https://www.reddit.com/r/LangChain/comments/1has712/document_priority_retriever/) , 2024-12-12-0914
```
I am implementing a rag system that has a bunch of files and pdfs, and I am facing a challenge.

I have 10 pdfs with a r
ecap of the year, one file by year so 10 years in total. All those files has the revenue , clients and others, it is bas
ically a executive summary of the year. 

I have used semantic search to embedding it , but the problem is , when I say 
something like what was the revenue of the year, it is taking a top k an old year documents instead of last year. If I s
pecified in the query the year, for example: what was 2023 revenue, it works, but in the first example is there a way to
 prioritize the most recent documents when doing the retriever?

I don't want to filter out by tag, because if the infor
mation asked is not in the most recent file than it should look for the others. Is there a way to easily do it ?
```
---

     
 
all -  [ How to connect to different schema other than public in langraph postgres checkpoint saver ](https://www.reddit.com/r/LangGraph/comments/1harmg6/how_to_connect_to_different_schema_other_than/) , 2024-12-12-0914
```
[https://langchain-ai.github.io/langgraph/concepts/persistence/#using-in-langgraph](https://langchain-ai.github.io/langg
raph/concepts/persistence/#using-in-langgraph)
```
---

     
 
all -  [  [Hiring] Currently working on a RAG + Big Data platform/marketplace and looking for developers  ](https://www.reddit.com/r/LangChain/comments/1harh82/hiring_currently_working_on_a_rag_big_data/) , 2024-12-12-0914
```
I'm currently building a RAG + Big data platform/marketplace. Think what home depot is for home builders, but we offer o
ff-the-shelf AI analytics. The startup's name is Analytics Depot and will be the one stop for all things analytics for r
eal estate, law, finance, insurance, oil and gas, supply chain, ecommerce etc.. 

We do not cater to enterprise customer
s. We cater B2C and B2Small business owners.  
  
The key areas we are focusing on is UI & UX, Data sources (more the me
rrier), Serving the right models for the right profession, and payment/token system. Eventually we will have a marketpla
ce where people can offer their own pipelines and get paid.

If you have built A-Z data pipelines in any of these indust
ries, DM me. I'd love to discuss how we can work together.
```
---

     
 
all -  [ Launched On Product Hunt: Here's the reason why I built it ](https://www.reddit.com/r/u_wait-a-minut/comments/1haq3z4/launched_on_product_hunt_heres_the_reason_why_i/) , 2024-12-12-0914
```
Over the past year of building AI-enabled SaaS applications, I kept hitting the same wall. Going from a Jupyter notebook
 full of AI RAG techniques to something usable in my app was a nightmare. I'm sure if anyone here has taking a look at l
lama-index or langchain cookbook sections you might understand what I'm talking about.

I came to the conclusion that th
is is the problem:  
\- Notebooks are great for testing ideas, but they’re not meant for building applications around th
em.  
\- I had to manually dissect notebooks, build a proof-of-concept API server, integrate it into my app, and pray it
 worked.  
\- The feedback loop was \*painfully\* long—and most of the time, I canned the project because it didn’t quit
e fit.

This frustration comes from a gap in roles:

1. Data Scientists/AI Devs want notebooks to experiment with method
s and techniques—but it's not their main focus to also create an API for other applications to use.
2. App Developers ju
st want simple APIs to test and integrate quickly to see if it actually enhances their app.

This is where KitchenAI com
es in. A tool that bridges this gap by transforming your AI Jupyter notebooks into production-ready API server in minute
s.

But why??  
\- Shorter Development Cycles  
Test, iterate, and deploy AI techniques faster and cut the feedback loop
 in half.  
\- Vendor and Framework Agnostic  
Use the libraries you’re comfortable with, no lock-ins.  
\- Plugin Archi
tecture  
Extend functionality with plugins for evaluation frameworks, observability, prompt management, and more.  
\- 
Open Source and Local-First  
Built on trusted technologies like Django, so you stay in control—no 3rd-party dependencie
s required.  
\- Docker-Ready  
Share your API server as a lightweight container for easy collaboration.

We’ve released
 KitchenAI as an Apache-licensed open-source tool, so anyone can use it. Up next is a managed cloud version with deeper 
integrations, metrics, analytics, and workflows for teams with more complex needs. One short term goal is to go straight
 from colab to a KitchenAI cloud hosted API so development can be absolutely seamless.

Give it a spin and a star: [http
s://github.com/epuerta9/kitc...](https://github.com/epuerta9/kitchenai)

The product hunt profile as well, a demo video 
is included: [https://www.producthunt.com/posts/kitchenai-2?utm\_source=other&utm\_medium=social](https://www.producthun
t.com/posts/kitchenai-2?utm_source=other&utm_medium=social)
```
---

     
 
all -  [ Do you know any examples of public or easy access RAGs chatbots using OpenAI API? ](https://www.reddit.com/r/OpenAI/comments/1hapw3c/do_you_know_any_examples_of_public_or_easy_access/) , 2024-12-12-0914
```
Hello everybody, this is my first post here. 

In the company I work for we are developing a proof of concept of a chatb
ot for internal use capable to answer almost any question related to the use of the products we sell (at least that is w
hat we are aiming for). 

We are using the RAG approach, feeding the chatbot with all the documentation in PDF we have (
manuals, logs, Support files, release notes, etc...). 

For this, we are using Langchain, ChromaDB and the OpenAI API, t
he DB was made using the text-embedding-3-large and playing with the temp parameters and changing between the models 4O 
and 4O-mini, cleaning the PDFs to quit irrelevant text, set up the metadata for every document in the BD, etc...

In gen
eral, the results are regular, the chatbot can anwer questions about the products with good approach, but when the user 
ask about the steps to perform certain task the chatbot usually hallucinates even when the instruccions can be found in 
the documentation. 

So, I'm wondering if you guys know any 'public' chatbot based on OpenAI and that follows the RAG ap
proach. We would like to evaluate if the chatbot we are aiming is viable or we would need  to find another way.

Sorry i
f there's any type, English is not my first language. 
```
---

     
 
all -  [ How to do agentic RAG with the plan-and-execute methodology? ](https://www.reddit.com/r/Rag/comments/1hap12s/how_to_do_agentic_rag_with_the_planandexecute/) , 2024-12-12-0914
```
I want to combine [agentic RAG](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_agentic_rag.i
pynb) with [plan and execute](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/plan-and-execute/p
lan-and-execute.ipynb) agents. I've built the [multi-vector agentic RAG workflow](https://colab.research.google.com/driv
e/1-tw-vgIgJMcXbdbSQwdhUTpsc663wMcw#scrollTo=7e22e20c-aac6-4c9d-b3c8-5822296b3ecf) in langgraph on some PDFs with tables
 by following the agentic RAG tutorial, but I am quite new to langgraph and as of yet have been unable to integrate the 
plan-and-execute method in my agentic RAG workflow.

In particular, here is the problem I want to solve. I am able to ca
lculate 'light dues', 'port dues' and 'vehicle dues' separately (i.e., in 3 different runs) in my agentic RAG workflow. 
But I want to be able to calculate all these charges in one shot - i.e., if I ask the agent, 'what are the total charges
 for a given vessel', it should be able to plan that in order to calculate the total charges it needs to calculate these
 3 individual charges (so it has 3 intermediate tasks), then calculate each of them (either one by one or in parallel), 
and then sum them up to present the final answer (the total charges) which is the fourth task.

How do I accomplish this
?

[Here](https://colab.research.google.com/drive/1vlkrUxj1fMxCJFe12Myh414AYxa79SRB) is my attempt, but there are issues
 with the node definitions and/one edge interaction:

>
```
---

     
 
all -  [ Launched an Open Source Tool on Product Hunt. Want to share why I built it. ](https://www.reddit.com/r/webdev/comments/1haoavw/launched_an_open_source_tool_on_product_hunt_want/) , 2024-12-12-0914
```
Over the past year of building AI-enabled SaaS applications, I kept hitting the same wall. Going from a Jupyter notebook
 full of AI RAG techniques to something usable in my app was a nightmare. I'm sure if anyone here has taking a look at l
lama-index or langchain cookbook sections you might understand what I'm talking about.  
  
I came to the conclusion tha
t this is the problem:  
\- Notebooks are great for testing ideas, but they’re not meant for building applications aroun
d them.  
\- I had to manually dissect notebooks, build a proof-of-concept API server, integrate it into my app, and pra
y it worked.  
\- The feedback loop was \*painfully\* long—and most of the time, I canned the project because it didn’t 
quite fit.  
  
This frustration comes from a gap in roles:  
1. Data Scientists/AI Devs want notebooks to experiment wi
th methods and techniques—but it's not their main focus to also create an API for other applications to use.  
2. App De
velopers just want simple APIs to test and integrate quickly to see if it actually enhances their app.

This is where Ki
tchenAI comes in. A tool that bridges this gap by transforming your AI Jupyter notebooks into production-ready API serve
r in minutes.  
  
But why??  
\- Shorter Development Cycles  
Test, iterate, and deploy AI techniques faster and cut th
e feedback loop in half.  
\- Vendor and Framework Agnostic  
Use the libraries you’re comfortable with, no lock-ins.  

\- Plugin Architecture  
Extend functionality with plugins for evaluation frameworks, observability, prompt management, 
and more.  
\- Open Source and Local-First  
Built on trusted technologies like Django, so you stay in control—no 3rd-pa
rty dependencies required.  
\- Docker-Ready  
Share your API server as a lightweight container for easy collaboration. 
 
  
We’ve released KitchenAI as an Apache-licensed open-source tool, so anyone can use it. Up next is a managed cloud v
ersion with deeper integrations, metrics, analytics, and workflows for teams with more complex needs. One short term goa
l is to go straight from colab to a KitchenAI cloud hosted API so development can be absolutely seamless.  
  
Give it a
 spin and a star: [https://github.com/epuerta9/kitc...](https://github.com/epuerta9/kitchenai)

The product hunt profile
 as well, a demo video is included: [https://www.producthunt.com/posts/kitchenai-2?utm\_source=other&utm\_medium=social]
(https://www.producthunt.com/posts/kitchenai-2?utm_source=other&utm_medium=social)
```
---

     
 
all -  [ Alternatives to run localLLM on private network  ](https://www.reddit.com/r/LocalLLaMA/comments/1han8mb/alternatives_to_run_localllm_on_private_network/) , 2024-12-12-0914
```
noobie question here:
I've been working with Langchain + localLLMs (using APIs) for a week now and I wondering If there'
s a way to deploy my agents on a private network (like the one from a company). Is there a way to do it with localLLM so
 other people on the network can acess?
```
---

     
 
all -  [ Visual Agents is Self-Aware Software: A Brief Intro ](https://youtu.be/iiDWPlrors4?si=Qnx7KDdU3KMq2JUS) , 2024-12-12-0914
```
Built on top of langchain in part.
```
---

     
 
all -  [ Building Recommendation System with RAG ](https://www.reddit.com/r/LangChain/comments/1hak0ml/building_recommendation_system_with_rag/) , 2024-12-12-0914
```
I like to build a recommendation system with RAG and wanted to hear others thoughts. I want to give recommendations base
d on multiple quizzes students take. For example, students would take 2-3 tests and based on those results, recommend qu
estions that they need to solve to improve their skills.

Here my data would be the following. For each test: testId, qu
estion number, choice selected(A,B,C,D), O/X (correct/incorrect) and category that the question belongs to.

My thinking
 is: I would feed these data into a vectorstore. Now when student has take 3 tests, I would feed this and based on those
 3 tests, I will do some kind of similiarity search and recommend questions that other students got wrong/correct and ge
t those test+question number out.

Would something like this be possible with RAG?
```
---

     
 
all -  [ GenAI and?? ](https://www.reddit.com/r/learnmachinelearning/comments/1haj5p5/genai_and/) , 2024-12-12-0914
```
Background: I have been working as a GenAI Engineer from mid of 2023 and basically this is what I have started my career
 with. I knew python and then as things came out I was doing development and learning the frameworks like Langchain, Lan
gGraph, Streamlit, Chainli, LlamaIndex, Haystack and what not.. I know a bit about Azure as we did deployments on azure.



After 1.5 year of experience in this domain, I think this is something that should not be your only skill. I want to 
learn something that will complement GenAI. I have exploring few options like DevOps, WebDevelopment ( the path is too l
ong, HTML, CSS, Javascript and goes the list goes on). What do you think I should learn/focus so that in some time I’ll 
standout from the crowd?



```
---

     
 
MachineLearning -  [ [P] Minima: local conversational retrieval augmented generation project (Ollama, Langchain, FastAPI, ](https://www.reddit.com/r/MachineLearning/comments/1h1pudq/p_minima_local_conversational_retrieval_augmented/) , 2024-12-12-0914
```
  
[https://github.com/dmayboroda/minima](https://github.com/dmayboroda/minima)  
  
Hey everyone, I would like to intro
duce you my latest repo, that is a local conversational rag on your files, Be honest, you can use this as a rag on-premi
ses, cause it is build with docker, langchain, ollama, fastapi, hf All models download automatically, soon I'll add an a
bility to choose a model For now solution contains:

* Locally running Ollama (currently qwen-0.5b model hardcoded, soon
 you'll be able to choose a model from ollama registry)
* Local indexing (using sentence-transformer embedding model, yo
u can switch to other model, but only sentence-transformers applied, also will be changed soon)
* Qdrant container runni
ng on your machine
* Reranker running locally (BAAI/bge-reranker-base currently hardcoded, but i will also add an abilit
y to choose a reranker)
* Websocket based chat with saving history
* Simple chat UI written with React
* As a plus, you 
can use local rag with ChatGPT as a custom GPT, so you able to query your local data through official chatgpt web and ma
c os/ios app.
* You can deploy it as a RAG on-premises, all containers can work on CPU machines

Couple of ideas/problem
s:

* Model Context Protocol support
* Right now there is no incremental indexing or reindexing
* No selection for the m
odels (will be added soon)
* Different environment support (cuda, mps, custom npu's)

Welcome to contribute (watch, fork
, star) Thank you so much!
```
---

     
