 
all -  [ Looking for LLM application templates for travel itinerary maker with web search and prompt memory ](https://www.reddit.com/r/LLMDevs/comments/1c4zo1n/looking_for_llm_application_templates_for_travel/) , 2024-04-16-0910
```
I'm interested in developing an LLM application for generating travel itineraries that incorporates web search capabilit
ies and the ability to remember and build upon previous prompts, similar to ChatGPT's conversation memory.

From my init
ial research, it seems like Langchain's AutoGPT library could be a good fit, as it enables LLMs to autonomously interact
 with other tools and databases. However, I'm not certain if this is the optimal approach.

Are there any existing open-
source application templates, starter codebases, or tutorials that would be recommended for this type of project? Ideall
y I'm looking for something that demonstrates best practices for prompt engineering, web search integration, and persist
ent memory across conversations.

Any guidance or examples from those with experience building similar applications woul
d be much appreciated. Links to relevant Github repos, papers, or technical guides would also be very helpful.
```
---

     
 
all -  [ Embedding and Finetuning on code? ](https://www.reddit.com/r/LangChain/comments/1c4uxrf/embedding_and_finetuning_on_code/) , 2024-04-16-0910
```
Hey guys, I was wondering what might be the best way to fine-tune a model on code or maybe use RAG for a code database. 
As far as I understand the more prevalent embedding methods function the best with natural language. I might be totally 
wrong but I think it has something to do with the complex relations between functions etc. in the source code of a proje
ct that makes embedding code and fine tuning harder.

Any comments?
```
---

     
 
all -  [ Using LangChain to teach an LLM to write like you ](https://medium.com/firebird-technologies/using-langchain-to-teach-an-llm-to-write-like-you-aab394d54792) , 2024-04-16-0910
```

```
---

     
 
all -  [ Any Suggestions for idea to built a RAG chatbot in a Hackathon? ](https://www.reddit.com/r/LangChain/comments/1c4t5ks/any_suggestions_for_idea_to_built_a_rag_chatbot/) , 2024-04-16-0910
```
So guys
My team has participated in a hackathon and we require Ideas to built a RAG chatbot on.
Your suggestions might h
elp us alot….Thanks

```
---

     
 
all -  [ Burr: an OS framework for building and debugging AI apps faster (manage memory, persist state, monit ](https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/) , 2024-04-16-0910
```
[https://github.com/dagworks-inc/burr](https://github.com/dagworks-inc/burr)

**TL;DR** We created Burr to make it easie
r to build and debug AI applications that carry state/make complex decisions. It is similar in concept to Langgraph, and
 works with any framework you want (Langchain, etc...). It comes with OS telemetry. We're looking for users, contributor
s, and feedback.

**The problem(s):** A lot of tools in the LLM space (DSPY, superagents, etc...) end up burying what yo
u actually want to see behind a layer of complexity and prompt manipulation. While making applications that make decisio
ns naturally requires complexity, we wanted to make it easier to logically model, view telemetry, manage state, etc... w
hile not imposing any restrictions on what you can do or how to interact with LLM APIs. 

**We built Burr** to solve the
se problems. With Burr, you represent your application as a state machine of python functions/objects and specify transi
tions/state manipulation between them. We designed it with the following capabilities in mind:

1. Manage application me
mory: Burr's state abstraction allows you to prune memory/feed it to your LLM (in whatever way you want)
2. Persist/relo
ad state: Burr allows you to load from any point in an application's run so you can debug/restart from failure
3. Monito
r application decisions: Burr comes with a telemetry UI that you can use to debug your app in real-time
4. Integrate wit
h your favorite tooling: Burr is just stitching together python primitives -- classes + functions, so you can write what
ever you want. Use langchain and dive into the OpenAI/other APIs when you need.
5. Gather eval data: Burr has logging ca
pabilities to ensure you capture data for fine-tuning/eval

It is meant to be a lightweight python library (zero depende
ncies), with a host of plugins. You can get started by running: `pip install 'burr[start]' && burr` \-- this will start 
the telemetry server with a few demos (click on *demos* to play with a chatbot + watch telemetry at the same time).

The
n, check out the following resources:

1. [Burr's documentation/getting started](https://burr.dagworks.io/getting_starte
d/)
2. [Multi-agent-collaboration example using LCEL](https://github.com/DAGWorks-Inc/burr/tree/main/examples/multi-agen
t-collaboration/lcel)
3. [Fairly complex control-flow example that uses AI + human feedback to draft an email](https://g
ithub.com/DAGWorks-Inc/burr/tree/main/examples/web-server)

**We're really excited** about the initial reception and are
 hoping to get more feedback/OS users/contributors -- feel free to DM me or comment here if you have any questions, and 
happy developing!

PS -- the name *Burr* is a play on the project we OSed called [Hamilton](https://github.com/dagworks-
inc/hamilton) that you may be familiar with. They actually work nicely together!

&#x200B;

&#x200B;
```
---

     
 
all -  [ Courses/books to get into Generative AI (GenAI)? Looking to get familiar with tools like Langchain,  ](https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/) , 2024-04-16-0910
```
Anyone has any recommendation for course/book/tutorial, free or paid? I have a decent idea about deep learning concepts.
 But, my current job is in backend with python, so naturally looking to expand my skillset! Thanks.   


I just want eno
ugh to get a custom chatbot with guardrails up and running on my system. I tried with ollama but am stuck at generating 
embedding for my dataset 
```
---

     
 
all -  [ Adding metadata to chunks ](https://www.reddit.com/r/LangChain/comments/1c4rvge/adding_metadata_to_chunks/) , 2024-04-16-0910
```
Is there any tutorials of a way to define metadata data to specific chunks to better compare documents so that there is 
less contamination with RAG
```
---

     
 
all -  [ Courses/books to get into Generative AI (GenAI)? Looking to get familiar with tools like Langchain,  ](https://www.reddit.com/r/developersIndia/comments/1c4rsz0/coursesbooks_to_get_into_generative_ai_genai/) , 2024-04-16-0910
```
Anyone has any recommendation for course/book/tutorial, free or paid? I have a decent idea about deep learning concepts.
 But, my current job is in backend with python, so naturally looking to expand my skillset! Thanks.
```
---

     
 
all -  [ [For Hire] Programmer/Web Developer/IT Consultant (Python, PHP, AI, etc.) ](https://www.reddit.com/r/forhire/comments/1c4qchs/for_hire_programmerweb_developerit_consultant/) , 2024-04-16-0910
```
To get in contact, please message me, I don't use the chat thing and might miss you or reply very late. Then we can swit
ch to email/discord/telegram or whatever else. Apologies for starting with this, but many missed it when it was lower.


I'm a programmer/web developer with 14 years of professional experience. I am available for all sorts of programming and
 web development tasks.

I also offer consulting services. If you need something done, but don't know how exactly, I can
 help. I'm an excellent researcher and I communicate well. I will work with you to find the best solution for your probl
em.

My services include, but are not limited to:

* websites

* desktop applications

* AI integration (chatGPT API, la
ngchain, whatever else turns up)

* integration with APIs and other webservices

* all kinds of scripts

* task automati
on

* website optimization

* debugging

* plugins for existing software

* bots (Reddit, Telegram, etc)

* code audits


If you're looking for someone to take care of a variety of different tasks, I can offer continuous support.

My preferr
ed environment is Python with Django, but I work with anything Python or PHP based. I have no problem with learning new 
technologies that are needed for the project.

Rate is $50/h.

Portfolio:

https://bdabkowski.yum.pl

Satisfied customer
s:

https://www.reddit.com/r/testimonials/comments/2e8gqy/pos_uqui_need_a_backend_web_dev_look_no_further/

https://www.
reddit.com/r/testimonials/comments/7fsdze/pos_hiring_uqui_was_an_example_of_how_it_should/

https://www.reddit.com/r/tes
timonials/comments/80pu9l/pos_uqui_great_work_detailed_and_fast/

https://www.reddit.com/r/testimonials/comments/b0nx68/
uqui_is_a_hardworking_intelligent_honest_apps/

https://www.reddit.com/r/testimonials/comments/j3mz3p/uqui_is_a_great_we
b_development_consultant_with/

https://www.reddit.com/r/testimonials/comments/v40ay3/pos_uqui_is_a_great_backend_dev_to
_work_with/

Please note: I am not a designer. To make it clear, it means zero aesthetic sense.
```
---

     
 
all -  [ setting up an idiot proof sandbox for students on a cluster. ](https://www.reddit.com/r/LocalLLaMA/comments/1c4p5fl/setting_up_an_idiot_proof_sandbox_for_students_on/) , 2024-04-16-0910
```
I'll be teaching text analysis using LLMs to a class. This will be complex forms of entity recognition and some rag (e.g
. find the metaphors in a text, identify possible connotations). Rather than have them find trivial entities in lots of 
data, I will have them looking at very small chunks of text and seeing how things like chaning prompts/llms/parameters e
ffects results. This gives them an idea of how things do/don't work in detail...which seems a responsible foundation bef
ore they run off and try to do topic modelling on 1500 policy document crap PDFs in 15 languages (no kidding).

For a bu
nch of reasons we will be using local installs rather than cloud APIs. I will start them on their own laptops with openw
ebui/ollama stacks with v small models so they can see how things work for simple tasks. I want them to see larger model
s (mixtral 8x22, command-r) since those are required for some of the more complex entities. Those will be hosted on a cl
uster that has a bunch of resources. 

what is the best way to install for that cluster so that I can manage it and the 
admin folks won't freak out? It is a pretty typical setup with a mitt full of a100s. 

they don't want to give me root (
go figure), they don't like gradio or cloudflared etc., they can be convinced to open a port for use internal to the uni
.

so far the best option I can see, for ease of use and the likelihood that the hardware will shift under the install b
etween runs, is the binary of ollama on the cluster, a port open to the uni and something like [bionicgpt](https://githu
b.com/bionic-gpt/bionic-gpt) for remote management.

my concern is that I'm not sure how well that will support

1. stud
ent first contact using openwebui (for those who think python is a snake) when a handful of students are constantly chan
ging which model is being used.
2. student exploration using something like langflow (sweet cause it says it does not re
quire python and makes langchain somewhat approachable, not so sweet because it actually does require understanding to r
eally make it work the minute you do something interesting)...this one stumps me cause it can call ollama or llamacpp fo
r both embedding and prompt handling and I don't know if/how it handles switching the model active in the back end
3. st
udent thrashing, using setups like [crew.ai](https://crew.ai)

my concerns, right now, are how do back ends like ollama 
handle multiple clients? how do they handles switching between models. what do they do when they are called by the same 
flow for embedding (one model) and then querying (another model) etc.

if anybody has experience with setting up such a 
fun but somewhat idiot proof sandbox, I'd be pleased to hear.

thank you
```
---

     
 
all -  [ Calender Management system using LlamaIndex or Langchain ](https://www.reddit.com/r/LangChain/comments/1c4nsa5/calender_management_system_using_llamaindex_or/) , 2024-04-16-0910
```
Calendar Integration for Deadline Management: Develop a feature that
enables the system to interact with a user's calend
ar to manage tasks and
deadlines efficiently. The system should be capable of adding tasks, setting
reminders, and intel
ligently scheduling activities without conflicts. Implement an
intelligent scheduling feature that, upon receiving a tas
k addition command, first
queries the user's calendar for existing commitments. It should analyse the
calendar to identi
fy time slots, check for conflicts, and evaluate deadline
proximity to schedule tasks optimally. This requires integrati
on with calendar
APIs, parsing date and time information, and applying logic to decide the most
appropriate timing for n
ew tasks.

I need to implement above task and develop a natural language interface which can access calender and can sch
edule appointments, delete them and make priority list. I need to implement this with all RAG capabilities (I thought of
 llamaindex or Langchain). 
I have LLM Api key which has only 3000 request limitation, model information 
meta.llama2-70
b-chat-v1. For frontend I can use streamlit. How can I use Langchain or llamaindex for this management system. If there 
are resources which can help me implementing it please do share.

```
---

     
 
all -  [ Your Experience: Best Chunking Technique for complex PDFs ](https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/) , 2024-04-16-0910
```
Hi,

I am experimenting with different chunking techniques like RecursiveCharacterSplitter or [Unstructured.IO](https://
Unstructured.IO) chunking with 'by\_title'. Theoretically I think the second option to chunk by title will be the most p
romising one.

But I would be interested of your experiences? The PDFs I am using are all complex and many come with a c
ompletely different structure, so manually checking for every PDF is no choice. 

Happy to discuss with your experiences
!
```
---

     
 
all -  [ Are you hungry for tech meetups? Join us for Cloud Native Lisbon Meetup #14 on April 18th in Lisbon! ](https://www.reddit.com/r/devpt/comments/1c4mxpk/are_you_hungry_for_tech_meetups_join_us_for_cloud/) , 2024-04-16-0910
```
📢 Cloud Native fans, **we're back!** ☁️  
Register link here: [https://www.meetup.com/cloudnativelx/events/300325033/](h
ttps://www.meetup.com/cloudnativelx/events/300325033/) 🔗  


**On the agenda:**  


🎤 '*Deploy LangChain applications on
 AWS with LangServe*' ️by [João Galego](https://www.linkedin.com/in/ACoAAAUp-sQBFZ55uKVqPbQV7WNOA1YRQW831JI), Solutions 
Architect at AWS  


🎤 '*Kubernetes management the GitOps way: Manage Cloud Native apps with ArgoCD*' by [Jake Page](htt
ps://www.linkedin.com/in/ACoAAAiXf7AB2jiUx6LpOC0J89kvrZeqLdtS6mo), Developer Relations Engineer at Glasskube  


Plus th
e usual networking, snacks, and drinks. 🍻🍕  


🗓️ April 18th  
⏰ 18:30  
📍[grow.inc SPACES](https://www.linkedin.com/com
pany/growinc-spaces/) Lisbon.  


https://preview.redd.it/v44hs1b8gnuc1.png?width=669&format=png&auto=webp&s=542e70649bc
e118102f8e3897af27fa61d6fd1f0
```
---

     
 
all -  [ [Feedback] Launch your SaaS in days and not weeks ](https://www.reddit.com/r/microsaas/comments/1c4k95g/feedback_launch_your_saas_in_days_and_not_weeks/) , 2024-04-16-0910
```
Last month I have been spending time in building a solution to help founders launch their SaaS MVP without knowing the i
ntricate tech details and having to start from scratch. The idea was can founders quickly iterate over their MVP without
 rebuilding everything from scratch.

Founders can start from scratch and add features as they grow / need basis. They c
an skip features that they don't want.

I am seeking 10 people to try out free of cost in return for feedback. Let me kn
ow in comments if interested and I will share with you.

Features:

1. Social logins (Google OAuth)
2. Admin panel
3. St
ripe / Paypal integration
4. SEO / Blog / Newsletter support
5. MongoDB / Supabase
6. Email support (Mailgun)
7. Tailwin
d CSS
8. AI ready: Langchain & GPT wrapper
```
---

     
 
all -  [ RAG and LangChain Source code ](https://www.reddit.com/r/LangChain/comments/1c4jl1c/rag_and_langchain_source_code/) , 2024-04-16-0910
```
I often heard that there are problems with navigating through LangChain and that working with the source code directly b
rings most benefits which is very hard work though. I thought it makes sense to maybe fine tune a model on the code and 
use RAG to interact with the source code and understand it better. Any feedback on whether this is a good idea or even p
ossible? The source code might be around 5 million tokens all in all. 
```
---

     
 
all -  [ Any tips on how to build a RAG model for csv using LlamaIndex? ](https://www.reddit.com/r/LocalLLaMA/comments/1c4iz3d/any_tips_on_how_to_build_a_rag_model_for_csv/) , 2024-04-16-0910
```
i'm building a rag model for csv files and i'm choosing models for the generation part that can also perform calculation
s - like i

Prompt: 'What are the  total sales in year 2023? ' 

by calculating the sum of monthly sales which is presen
t in the csv file and answer 

Answer: 'The total sales in year 2023 is XXXX'

But the major setback I'm facing is the m
odel cant calculate for the responses and the answers are pretty bad, so I appreciate any materials or articles that may
 help my use case.

Already created a small rag model for pdf files, since it is a text based use case I had no issues b
uilding it. But for the csv files the datatypes are important and numerical data needed to perform calculations like the
 above mentioned

So I appreciate any kind of help based on this topic, since I can't find any materials for LLamaIndex 
framework. For the time being I'm gonna look into Langchain examples and try to replicate the same using LlamaIndex 
```
---

     
 
all -  [ [Feedback] Ship your SaaS in days and not weeks ](https://www.reddit.com/r/SideProject/comments/1c4imw3/feedback_ship_your_saas_in_days_and_not_weeks/) , 2024-04-16-0910
```
Last month I have been spending time in building a solution to help founders launch their SaaS MVP without knowing the i
ntricate tech details and having to start from scratch. The idea was can founders quickly iterate over their MVP without
 rebuilding everything from scratch.

Founders can start from scratch and add features as they grow / need basis. They c
an skip features that they don't want. 

I am seeking 10 people to try out  free of cost in return for feedback. Let me 
know in comments if interested and I will share with you. 

Features:  
1. Social logins (Google OAuth)  
2. Admin panel
  
3. Stripe / Paypal integration  
4. SEO / Blog / Newsletter support  
5. MongoDB / Supabase  
6. Email support (Mailg
un)  
7. Tailwind CSS  
8. AI ready: Langchain & GPT wrapper  


&#x200B;

&#x200B;
```
---

     
 
all -  [ What are the best SQL agents ](https://www.reddit.com/r/LangChain/comments/1c4ij67/what_are_the_best_sql_agents/) , 2024-04-16-0910
```
We've been trying pandas dataframe agent and have been experiencing some problems in productions. Are there better alter
natives?
```
---

     
 
all -  [ Starting Out: Key Vespa Docs for Hybrid Search (Keyword + Vector) ](https://www.reddit.com/r/vespa_ai/comments/1c4i4bw/starting_out_key_vespa_docs_for_hybrid_search/) , 2024-04-16-0910
```
a common project is to do hybrid search (keyword + vector) over your own text documents.

there isn't a single dummy's g
uide on how to do it. langchain has an integration with pyvespa, but i haven't tried it.

pyvespa is vespa's python libr
ary, which is designed for prototyping. it does not have the full functionality, but should be enough for a small person
al project.

if you aren't using langchain, you will have to figure out how to run vespa from various pages in their doc
s.

the key ones i found useful when i was starting out were the following:

[https://docs.vespa.ai/en/vespa-quick-start
.html](https://docs.vespa.ai/en/vespa-quick-start.html) (starting a vespa instance on docker)

[https://docs.vespa.ai/en
/tutorials/text-search.html](https://docs.vespa.ai/en/tutorials/text-search.html) (keyword search)

[https://docs.vespa.
ai/en/tutorials/text-search-semantic.html](https://docs.vespa.ai/en/tutorials/text-search-semantic.html) (vector search,
 partial explanation)

[https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html](https://pyvespa.readthedo
cs.io/en/latest/getting-started-pyvespa.html) (hybrid search, with pyvespa)

to set up and run vespa, you can either:

*
 use pyvespa; or
* write the schema and services (query profile, optional) files yourself from scratch. for example, the
se define the fields, data types, relevance scoring, etc.

i haven't used langchain, but langchain probably provides for
 data ingestion.

otherwise, you will have to write code yourself for preparing the data to be fed into vespa. the data 
and vectors need to be in json or jsonl with a particular format.
```
---

     
 
all -  [ I have a nosql database of profiles where each profile has multiple json documents, how can I create ](https://www.reddit.com/r/LangChain/comments/1c4hc9j/i_have_a_nosql_database_of_profiles_where_each/) , 2024-04-16-0910
```
I know how to create RAG for sql databases, pdfs, and other text documents, the nosql thing is a bit confusing to me so 
any assistance is appreciated!
```
---

     
 
all -  [ Need Help - Trying To Create A Chatbot That Recommends Personalized Video Games ](https://www.reddit.com/r/learnpython/comments/1c4h188/need_help_trying_to_create_a_chatbot_that/) , 2024-04-16-0910
```
Hello everyone! Before I start discussing about my project, I want to apologize in advance for any naive questions or in
correct use of terms, as I'm new to the field of machine learning and chatbots.

Now, onto my question: I'm attempting t
o create a web app using React and Python (Flask) that integrates a chatbot designed to recommend personalized video gam
es to users based on their queries. To elaborate, users will either talk about their all-time favorite video games, the 
genres/tags they are fond of, or provide a short description of their demographic profile (e.g., based on age and gender
 - the chatbot will go on to recommend the user video games from different genres that it thinks he/she will enjoy. Ther
e are some studies on the correlation between video games genres and gender/age of a person. I'm thinking of feeding my 
chatbot this kind of data from these sources, if possible).  Once the chatbot understands the query, it will make a call
 to an external API of a video game database to retrieve games that match the criteria. 

So to reiterate, what I'm tryi
ng to do is to create a chatbot that understands user input, and based on the context extracted from that input, make ca
lls to the external video games database API (such as RAWG), or to the knowledge base then to the external API, and fetc
h the suitable types of games that the chatbot see suitable to recommend.

One framework I've seen capable of perhaps ac
hieving this, using JS and Python, is LangChain. Is it possible to accomplish all of this using LangChain? And is LangCh
ain the right way to achieve this? If yes, how should I approach this? What factors should I consider while trying to im
plement my chatbot? What advice do you have for a beginner like me? Is there any other information I should add to my po
st? Or if not, what other APIs or frameworks can you recommend me looking into and eventually use?

Thank you a lot to e
veryone who took their time to read this and help me out!
```
---

     
 
all -  [ Render charts? ](https://www.reddit.com/r/LangChain/comments/1c4gy1a/render_charts/) , 2024-04-16-0910
```
I’m working on a chat-style bot and need to be able to display charts for trends etc. Any tips for going about this?
```
---

     
 
all -  [ Multi-Agent Movie scripting using LangGraph  ](https://www.reddit.com/r/LangChain/comments/1c4b665/multiagent_movie_scripting_using_langgraph/) , 2024-04-16-0910
```
Checkout this tutorial on how to generate movie scripts using Multi-Agent Orchestration where the user inputs the movie 
scene, LLM creates which agents to create and then these agents follo the scene description to say dialogues. https://yo
utu.be/Vry2-h81_I0?si=0KknmT8CfAhTucht
```
---

     
 
all -  [ Attach an image via langchain ](https://www.reddit.com/r/LangChain/comments/1c48nlo/attach_an_image_via_langchain/) , 2024-04-16-0910
```
I couldn't figure out how to attach an image to Ollama via langchain. I was able to send an image to llava using direct 
Ollama connection and JavaScript. Unfortunately, when I switched to langchain, the 'images' field is always blank - {

 
 'role': 'user',

  'content': 'describe the image',

  'images': \[\]

}. Thanks for any suggestions!
```
---

     
 
all -  [ What are your favorite LLM libraries, tools, and repositories? ](https://www.reddit.com/r/LocalLLaMA/comments/1c46f6h/what_are_your_favorite_llm_libraries_tools_and/) , 2024-04-16-0910
```
Hi there!

I love lurking on GitHub and exploring different repositories, but there are just so many to choose from and 
life is too short for checking out all of them.

So, I'm curious to hear from you all:

What are your favorite libraries
 and frameworks? Are there any you consider must-haves and can't work without anymore? Which is worth the learning curve
? 

Here are some repositories I've checked out that I thought were pretty cool:

**Tutorials**

- **Notebooks and Tutor
ials for LLMs**: An amazing collection that explains virtually all important concepts regarding large language models. 

  - [mlabonne's LLM course](https://github.com/mlabonne/llm-course)

- **Microsoft LLM/AI Libraries**: A tutorial/worksh
op that covers Microsoft’s LLM/AI libraries and frameworks, including integration of popular libraries like LangChain in
to the MS Copilot stack.
  - [Miyagi GitHub](https://github.com/Azure-Samples/miyagi)
  - [Copilot Workshop](https://cop
ilotwksp.com/)

- **Sample LLM Libraries**: Various samples for different LLM libraries. 
 - [tylerprogramming/ai](https
://github.com/tylerprogramming/ai)

**Backend**

Run your LLM locally. I guess everyone uses those and no explanation ne
eded:

* https://github.com/ollama/ollama
* https://github.com/lmstudio-ai
* https://github.com/ggerganov/llama.cpp

Vec
tor Store

* https://github.com/chroma-core/chroma


**Low-Code Frameworks**: Great for quick prototyping as you can cre
ate apps by connecting nodes. Like Reaktor just for LLMs

- [Dify](https://github.com/langgenius/dify)

- [Flowise](http
s://github.com/FlowiseAI/Flowise)

- [Promptflow](https://github.com/microsoft/promptflow)

**Python Frameworks:**

- **
Jack of all Trades**: Described by some as a collection of demos with no consistent codebase or overarching logic, it ca
n be incredibly useful if your use case fits the tools LangChain provides. If you need to work around some of the stuff 
and dig in deep... well good luck to you! 
  - [LangChain GitHub](https://github.com/langchain-ai/langchain)

- **RAG Fr
ameworks**: Customization for your RAG use cases.
  - [LlamaIndex](https://github.com/run-llama/llama_index)
  - [Haysta
ck by Deepset AI](https://github.com/deepset-ai/haystack)
  - [MemGPT](https://github.com/cpacker/MemGPT)

- **Agent Fra
meworks**: Create agents that operate autonomously.
  - [Autogen by Microsoft](https://github.com/microsoft/autogen)
  -
 For a more abstracted approach to agents, check out [CrewAI](https://github.com/joaomdmoura/crewAI)

**.NET/C# Framewor
ks:**

- **Semantic Kernel**: Basically Microsoft LangChain, also available for Python and Java.
  - [Microsoft Semantic
 Kernel](https://github.com/microsoft/semantic-kernel)
  - [Semantic Kernel Docs](https://github.com/MicrosoftDocs/seman
tic-kernel-docs)
  - [Semantic Kernel + LMStudio](https://github.com/elbruno/semantickernel-localLLMs)
  - [Semantic Ker
nel + Ollama](https://github.com/BLaZeKiLL/Codeblaze.SemanticKernel)
  - [LangChain .NET](https://github.com/tryAGI/Lang
Chain) - Still early in development, but promising.

**Misc/Application**

Pretty cool projects if you need some inspira
tion for your own agent app.

- **Agent Applications**:
  - [MetaGPT](https://github.com/geekan/MetaGPT)
  - [AIlice](ht
tps://github.com/myshell-ai/AIlice)
  - [babyagi](https://github.com/yoheinakajima/babyagi)
  - [AutoGPT](https://github
.com/Significant-Gravitas/AutoGPT)
  - [EvoNinja](https://github.com/polywrap/evo.ninja)

And I'm pretty sure I'm missin
g plenty of other cool repos, so I'm looking forward seeing what stuff you guys use!

Thanks!
```
---

     
 
all -  [ [request] did someone managed to build a React app calling AutoGen with API or webSocket? ](https://www.reddit.com/r/AutoGenAI/comments/1c44htx/request_did_someone_managed_to_build_a_react_app/) , 2024-04-16-0910
```
Creating and coding WebApps that calls the APIs of OpeAI / LLama / Mistral / Langchain etc. is a given for the moment bu
t the more I'm using AutoGen Studio the more I want to use it in a 'real world' situation.  
i'm not diving deep enough 
I think to know how to put in place the sceario/workflow : 

\- the user asks/prompts the system from the frontend (reac
t) 

\- the backend sends the request to Autogen

\- Autogen runs the requests and sends back the answer  


did anyone 
of you know how to do that? should I use FastAPI or something else?  

```
---

     
 
all -  [ Better Alternatives to stuff chain in langchain? ](https://www.reddit.com/r/LangChain/comments/1c3yiyw/better_alternatives_to_stuff_chain_in_langchain/) , 2024-04-16-0910
```
At work we have use some use cases related to extracting information from pdf documents which was earlier being done by 
some regex and RPA combinations, I was tasked with using 'GenAI' to optimise the solution for all kind of pdf(s), soo th
e current approach I took is reading all the documents using pydf2 , making extracting the text from them and converting
 them to docs using langchain and passing them through a prompt  in which I tell gpt which information to extract from t
he 'text' using stuff chain, as I am very new to this and this approach might be scaled to production , I want to ask if
 I can do something better in this?
```
---

     
 
all -  [ Confused on how to use the SequenceChain in LCEL ](https://www.reddit.com/r/LangChain/comments/1c3vfwy/confused_on_how_to_use_the_sequencechain_in_lcel/) , 2024-04-16-0910
```
Hi,  
I'm very new to langchain and am enjoying poking around stuff.   
While building a small project, I'm stuck at a t
ask. I'm trying to implement a SequenceChain in LCEL. The output of prompt1 | LLM should be passed to prompt2 | LLM. 

H
ere is my code:

    llm=Ollama(model='llama2')
    
    prompt2=ChatPromptTemplate.from_messages(
        [
           
 ('system','You are a helpful assistant. Please response to the user queries in a rude way'),
            ('user','Quest
ion:{question}')
        ],
    )
    
    prompt3=ChatPromptTemplate.from_messages(
        [
            ('system','Yo
u are a text tone evaluator bot. Your job is to go through the user input and list out all the sentiments and tones of t
he input in 2 separate comma separated lists'),
            ('user','{inputText}')
        ],
    )
    chain1 = prompt2
|llm
    chaintest = {'inputText': chain1} | RunnablePassthrough.assign(analysis= prompt3 | llm)
    chaintest.invoke({'
question': 'hello world'})

  
  
Now everything seems to work fine, but i want to get the original \`question\`, \`inpu
tText\` and \` analysis\` in the response. Currently with this i'm not sure how to get all 3. 

The SequenceChain from t
he docs is an older way to build stuff i've read, and people have moved to LCEL and hence i'm trying to use that. I can'
t follow along the docs regarding this. 

should i use the \`itemgetter\` package to pick the key? 

Any help will be ap
preciated. Thanks!
```
---

     
 
all -  [ Need Help - Trying To Create A Chatbot That Recommends Personalized Video Games ](https://www.reddit.com/r/LangChain/comments/1c3r25a/need_help_trying_to_create_a_chatbot_that/) , 2024-04-16-0910
```
Hello everyone! Before I start discussing about my project, I want to apologize in advance for any naive questions or in
correct use of terms, as I'm new to the field of machine learning and chatbots.

Now, onto my question: I'm attempting t
o create a web app using React and Python (Flask) that integrates a chatbot designed to recommend personalized video gam
es to users based on their queries. To elaborate, users will either talk about their all-time favorite video games, the 
genres/tags they are fond of, or provide a short description of their demographic profile (e.g., based on age and gender
 - the chatbot will go on to recommend the user video games from different genres that it thinks he/she will enjoy. Ther
e are some studies on the correlation between video games genres and gender/age of a person. I'm thinking of feeding my 
chatbot this kind of data from these sources, if possible).  Once the chatbot understands the query, it will make a call
 to an external API of a video game database to retrieve games that match the criteria. 

Is it possible to accomplish t
his using LangChain? And is LangChain the right way to achieve this? If yes, how should I approach this? What factors sh
ould I consider while trying to implement my chatbot? What advice do you have for a beginner like me? Is there any other
 information I should add to my post? 

Thank you a lot to everyone who took their time to read this and help me out!
```
---

     
 
all -  [ Is there any tool for for manual proofreading of video transcriptions, with ability to check origina ](https://www.reddit.com/r/LanguageTechnology/comments/1c3qfii/is_there_any_tool_for_for_manual_proofreading_of/) , 2024-04-16-0910
```
I was hoping for some advice on whether there are already available tools to achieve what I need.  
I am quite inexperie
nced and just starting with natural language processing.

The project is related to musical learning and musical improvi
sation. There is no team, just myself, and it is non-profit, so resources and skills available are quite limited.  
I am
 learning Python for data analysis, I know some Javascript and Langchain, and I could spend a few hundred USD on APIs ca
lls and other expenses, but that's all.  
  
I need to manually process the transcriptions from around  200 video interv
iews with experts and musicians.   
A total of \~350 hours.  
They are full interviews' text in English, tagged with the
 speakers names and time tags, and they contain many spelling mistakes.  
Spelling issues are about domain specific term
s (names of people, techniques and quite unusual musical terms in various languages). I am very familiar with the topics
, so I can correct 90% or more of the spellings without checking the actual audio, but not all of them.  
  
I need to p
rocess this manually, to produce:

1. Corrected transcriptions
2. A list of all domain terms mentioned 

This would allo
w me to implement a website and a chatbot with retrieval augmented generation, both showing pop-up info for the domain t
erms, to make it easier for non specialists to understand the text. 

If there was an **ideal tool**, it would have the 
following features:

1. text editing
2. correcting all instances of a spelling mistake in one operation
3. a dictionary 
of domain terms which can be exported
4. dictionary support for expressions (entities which are more than one word, 'Ant
ionio Vivaldi' )
5. Ideally, an ability to add terms to the dictionary quickly, and adding aliases for a term (other ter
ms or spelling meaning the same thing, 'Vivaldi' as alias for 'Antonion Vivaldi')
6. fuzzy matching from the dictionary 
terms, highlighting in the text  potential matches from the list
7. Ability to scrub an audio file to a specific time ta
g. 

  
Part of the above can obviously be done with Visual studio (with the vs spell checker plugin), or many good text
 editors, but not all.

I toyed with the idea to create the tool myself as a web interface, and make it available to oth
ers, but my skills are limited right now, it would take me too long. 

If you had a similar task, how would you approach
 it?  
Is there any tool which does most or all of the above? 

Thanks so much for any advice.
```
---

     
 
all -  [ Langchain CSV/pandasDataframeAgent  ](https://www.reddit.com/r/LangChain/comments/1c3kpto/langchain_csvpandasdataframeagent/) , 2024-04-16-0910
```
Hii, I am trying to develop a data analysis agent, and using langchain CSV agent with local llm mistral through Ollama.


I am a beginner in this field. Can someone suggest me how can I plot charts using agents.

I developed a simple agent w
hich is able to answer simple queries like , how many rows in dataframe, list all transaction realated to xyz, etc.

Tha
nk you!
```
---

     
 
all -  [ Dynamic Agent Tool creation ](https://www.reddit.com/r/LangChain/comments/1c3ikus/dynamic_agent_tool_creation/) , 2024-04-16-0910
```
Anyone know how to create a tool dynamically (from a json) that can be used with the React agents? I can see its possibl
e in the js version, but I cant get it to work with python. 

&#x200B;

I would like to be able to have the user send in
 the tools they have in a list of dictionaries of the form {'name' ... , 'args': \['inp1', 'inp2'\], 'url'} (simplified,
 i could make the input whatever)  


The url would be an api that takes in the arguments the users provide.  
```
---

     
 
all -  [ I made a simple invoice RAG app using Haystack 2, Docker & LLama2 ](https://www.reddit.com/r/LangChain/comments/1c3h6un/i_made_a_simple_invoice_rag_app_using_haystack_2/) , 2024-04-16-0910
```
I have been using Langchain for almost a year, mostly for hobby projects, with mixed results.

After hearing a lot of po
sitive sentiment around haystack I decided to build a simple RAG app to get a feel for it. I could not find many working
 examples using haystack 2, most code that I found was for v1 & out of date.

This might be useful to someone following 
the same path as a starting point: https://github.com/jfagan/llm-rag-invoice-haystack

All of the examples in the code r
efer to invoices but this can be used for any type of PDF documents. You would just need to change the prompts to suit y
our use case

I am going try and improve this by implementing table extraction (thinking of using Camelot) & some sort o
f structured image parsing mechanism.
```
---

     
 
all -  [ I come with a realization you do not want to hear ](https://www.reddit.com/r/LangChain/comments/1c3esbn/i_come_with_a_realization_you_do_not_want_to_hear/) , 2024-04-16-0910
```
After hundreds of hours struggling to find solutions to real-world problems with AI such as making API requests to custo
m API so that the LLMs have data to base their answers or even real-time voice enable support agents, I have come to thi
s conclusion:

# Langchain tools are pointless and extremely convoluted, do not waste your time with them!

All agents a
re a pre-prompt that makes whatever little context you have left for your actual prompt just extremely inaccurate, The s
ame goes with output parsers, it's all just very dumb and makes the development experience awful.  


If you wanna solve
 any real-world problems this year, stop catering to some convoluted objects that ask for some other specific object as 
input.  


yuo are better off just using Fstrings, I have made 10x more progress just using a simple llmchain with strin
gs than I ever did in months trying to use all these dumb 'features' that in reality all they do is take up context and 
reduce accuracy.
```
---

     
 
all -  [ LLMs can rephrase retrieved information. How do you handle it? ](https://www.reddit.com/r/LangChain/comments/1c35xlu/llms_can_rephrase_retrieved_information_how_do/) , 2024-04-16-0910
```
For example, rephrasing code can often introduce unintended noise. How do you evaluate the RAG if it rephrases results?


How can one ensure mininal rephrasing?

```
---

     
 
all -  [ How do you handle unstructured data? ](https://www.reddit.com/r/LangChain/comments/1c34qaf/how_do_you_handle_unstructured_data/) , 2024-04-16-0910
```
I have a requirement to handle unstructured data: images, tables, graphs and of course text. I tried using unstructured.
io and gpt-4-turbo to test on tables. Doing well.   
I am quite confused on how to approach for images and graphs.  
Was
 recommended to use finetuned LLaVA model. How should I finetune it? Provide it with images? Is that sane thing to do fo
r prod-level?
```
---

     
 
all -  [ Question about Tailoring Conversational Responses  ](https://www.reddit.com/r/LangChain/comments/1c312zy/question_about_tailoring_conversational_responses/) , 2024-04-16-0910
```
I have a typical ConversationalRetrievalChain  RAG that uses a vector db for sources. The prompt is nothing crazy and do
es include 'don't use any knowledge outside of the provided context' to help prevent confabulation. 

But when I say 'hi
' to it, it responds with an answer informed by some of the stored vectors: 'The answer to 'hi' was 'hello''. 

Is there
 a way to get it to be conversational when not asking it stuff directly related to its defined role and directions? 
```
---

     
 
all -  [ Langchain with Flutter ](https://www.reddit.com/r/FlutterDev/comments/1c2zkld/langchain_with_flutter/) , 2024-04-16-0910
```
It’s possible and has good performance to use langchain with flutter apps or is better to use backend?

```
---

     
 
all -  [ best architecture for a financial agent. ](https://www.reddit.com/r/LangChain/comments/1c2zhvu/best_architecture_for_a_financial_agent/) , 2024-04-16-0910
```
I have been experimenting with various financial agent architectures. Currently, I am using an agent with several financ
ial tools that call different financial API endpoints from the data provider. These APIs cover almost all fundamental fi
nancial data for a particular stock. However, as the number of tools increases, it becomes difficult for the agent to id
entify the right tool for answering user queries, sometimes leading to inaccurate answers and making the approach somewh
at inefficient.

I have all the data stored in a database that gets updated regularly. To solve this problem, I have two
 alternative approaches in mind:

1. Using a single tool to convert the user query into SQL using an LLM with the databa
se schema and directly querying the database with the generated query.
2. Creating a vector embedding collection for eac
h stock that contains all the data I have for a stock, then using a retriever to query the vector database collections. 
 


Please provide your insights on the following:

1. Which approach would be more suitable for the financial agent, an
d why?
2. What are the advantages and disadvantages of each approach?
```
---

     
 
all -  [ How do actually save a document output to local disc for langgraph?  ](https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb) , 2024-04-16-0910
```
I’m following along with this example of a multi agent hierarchical system. The end output should be a document written 
to disc. I can output the conversation to txt and can see that a document “has been finished and saved to disc”, but tha
t’s just what the agent says but I can see any code that actually says to save to disc. 
I have supergraph.stream, but a
gain, that just outputs the conversation. How do I output the actually document they made? 

Thanks!


```
---

     
 
all -  [ How to use multiple tools at once ](https://www.reddit.com/r/LangChain/comments/1c2vqzk/how_to_use_multiple_tools_at_once/) , 2024-04-16-0910
```
How can I get my LLM to use multiple tools (not just one out of many) to answer my user query?
```
---

     
 
all -  [ LLM Newb, looking for help ](https://i.redd.it/mwux4unid6uc1.jpeg) , 2024-04-16-0910
```
Hello, looking for some help

This is my first time working with an LLM, I am trying to build a super simple project to 
gain some experience, just trying to build the simplest python script that uses an LLM that I can. 

\-I was using MSVS 
2022, it kept giving me a hard time saying that it couldnt find what I was trying to import (for example, import torch, 
never worked, or import langchain) Does anyone know why? Or is it best if I just avoid MSVS all together? 

Since then I
 have learned how to use Jupyter notebook, and have made it past that issue.

\- I am following tutorials, and they keep
 coming up with outdated models. This (and others I have tried) model keeps giving a huge error, from what I can tell it
 is because it is no longer supported. Does anyone know a more up to date model that I can use? Or can you see anything 
else wrong with this code that may be causing it not to run. 



Thanks for the help, I know I am very novice here, othe
r than this, small coding projects are really my main experience.  (CSE 100, leetcode, etc) I know that this is a big st
ep, but I am trying to follow this tutorial to dip my toes in just a little bit. Any tips to help me get past this obsta
cle and get my first program to run? 


```
---

     
 
all -  [ Best vector database for large scale data, besides qdrant and pinecone ](https://www.reddit.com/r/LangChain/comments/1c2t59t/best_vector_database_for_large_scale_data_besides/) , 2024-04-16-0910
```
Had test in prod, pinecone is too slow

Qdrant does not perform well when large amount (kilos) of collections is created
.

So I am searching for other great options.

I want at least those features.

1. open source and self hosted
2. Vector
s can be offloaded to disk because there is too much data to store in RAM.
3. Capability to store 10k-100k collections w
ithout much overhead.
4. in active development and support
5. fare performance, latency acceptable when the collections 
to be queried is not cached at RAM
```
---

     
 
all -  [ Hello, looking for some help ](https://www.reddit.com/r/LLMDevs/comments/1c2ndao/hello_looking_for_some_help/) , 2024-04-16-0910
```
This is my first time working with an LLM, I am trying to build a super simple project to gain some experience, just try
ing to build the simplest python script that uses an LLM that I can. 

\-I was using MSVS 2022, it kept giving me a hard
 time saying that it couldnt find what I was trying to import (for example, import torch, never worked, or import langch
ain) Does anyone know why? Or is it best if I just avoid MSVS all together? 

Since then I have learned how to use Jupyt
er notebook, and have made it past that issue.

\- I am following tutorials, and they keep coming up with outdated model
s. This (and others I have tried) model keeps giving a huge error, from what I can tell it is because it is no longer su
pported. Does anyone know a more up to date model that I can use? Or can you see anything else wrong with this code that
 may be causing it not to run. 

&#x200B;

Thanks for the help, I know I am very novice here, other than this, small cod
ing projects are really my main experience.  (CSE 100, leetcode, etc) I know that this is a big step, but I am trying to
 follow this tutorial to dip my toes in just a little bit. Any tips to help me get past this obstacle and get my first p
rogram to run? 

https://preview.redd.it/d9n0fg43t4uc1.png?width=789&format=png&auto=webp&s=c3d50fff4d54984be0f9da5eaeb6
98a6b9abfa71
```
---

     
 
all -  [ Best embedded models for transcriptions/spoken language? ](https://www.reddit.com/r/LangChain/comments/1c2l33u/best_embedded_models_for_transcriptionsspoken/) , 2024-04-16-0910
```
Hello I would like to know which embedded model would be best suited for transcriptions of mostly recorded zoom sessions
 / spoken language. I would like to ask specific questions about topics that were covered. Getting detailed answers and 
summaries.

Currently I am using:

Salesforce/SFR-Embedding-Mistral -> which is pretty slow on my Macbook M1 Pro

mixedb
read-ai/mxbai-embed-large-v1

Are there better models suited for my task?
```
---

     
 
MachineLearning -  [ [D] How to get the source documents from the retrieved context for RAG?  ](https://www.reddit.com/r/MachineLearning/comments/1bvoc1t/d_how_to_get_the_source_documents_from_the/) , 2024-04-16-0910
```
I'm not using Lanchain but only making API calls to an LLM service provider. The retriever is connected to a vector DB, 
and I would like to know what the LLM refers to WITHIN that retrieved context whenever it provides an answer, similar to
 how return_source_documents works in Langchain.

I'm using AzureOpenAI. I couldn't find much in their docs that related
 to returning the source documents. Any help will be greatly appreciated!

```
---

     
 
MachineLearning -  [ [P] RAG pipeline to query the ML Engineering Open Book ](https://www.reddit.com/r/MachineLearning/comments/1bu4wyx/p_rag_pipeline_to_query_the_ml_engineering_open/) , 2024-04-16-0910
```
I built a quick RAG implementation using Langchain to make it easy to query the [ML Engineering Open Book](https://githu
b.com/stas00/ml-engineering) by [Stas Bekman](https://twitter.com/StasBekman). The Multi-Vector retriever gave pretty go
od results and was quite easy to set up too. 

Github link - [https://github.com/shreyansh26/RAG-ML-Engg-Open-Book](http
s://github.com/shreyansh26/RAG-ML-Engg-Open-Book)

Hope this is useful for folks!
```
---

     
 
MachineLearning -  [ [Project] FinancialAdvisorGPT : LLM+RAG Boilerplate Project ](https://www.reddit.com/r/MachineLearning/comments/1btlpgd/project_financialadvisorgpt_llmrag_boilerplate/) , 2024-04-16-0910
```
FinancialAdvisorGPT is a boilerplate project designed for RAG (Retriever-Augmented Generation) and LLM (Large Language M
odel) applications in financial analysis. Built on a technology stack including MongoDB, MongoDB VectorDB, Chroma, FastA
PI, Langchain, and React submodule for UI, it offers a framework for developers to implement and customize RAG+LLM proje
cts. Leveraging parallelized data pipelines, FinancialAdvisorGPT processes and integrates various data sources such as s
tock data, news, SEC filings, and local PDFs.

Github project includes long documentation on how the project is structur
ed, how LLM+RAG works for specific task : [https://github.com/mburaksayici/FinancialAdvisorGPT](https://github.com/mbura
ksayici/FinancialAdvisorGPT)
```
---

     
 
MachineLearning -  [ [Project] Picachain, image search made simple. ](https://www.reddit.com/r/MachineLearning/comments/1bt7epv/project_picachain_image_search_made_simple/) , 2024-04-16-0910
```
I am working on creating something for image search, basically something like langchain for images. Probably add videos 
too.

Currently supports chromaDB. Working on pinecone and other vector dbs. [https://github.com/d1pankarmedhi/picachain
](https://github.com/d1pankarmedhi/picachain)

Will you use something like this? What else should I add? Feel free to ad
d your views.

Appreciate your feedback or any feature ideas :)

&#x200B;
```
---

     
 
deeplearning -  [ Tengyu Ma on Voyage AI - Weaviate Podcast #91! ](https://www.reddit.com/r/deeplearning/comments/1bjft8i/tengyu_ma_on_voyage_ai_weaviate_podcast_91/) , 2024-04-16-0910
```
**Voyage AI** is the newest giant in the embedding, reranking, and search model game!

I am SUPER excited to publish our
 latest Weaviate podcast with Tengyu Ma, Co-Founder of Voyage AI and Assistant Professor at Stanford University!

We beg
an the podcast with a deep dive into everything embedding model training and contrastive learning theory. Tengyu deliver
ed a **masterclass** in everything from scaling laws to multi-vector representations, neural architectures, representati
on collapse, data augmentation, semantic similarity, and more! I am beyond impressed with Tengyu's extensive knowledge a
nd explanations of all these topics.

The next chapter dives into a case study Voyage AI did **fine-tuning an embedding 
model for the LangChain documentation.** This is an absolutely fascinating example of the role of continual fine-tuning 
with very new concepts (for example, very few people were talking about chaining together LLM calls 2 years ago), as wel
l as the data efficiency advances in fine-tuning.

We concluded by discussing ML systems challenges in serving an embedd
ings API. Particularly the challenge of detecting if a request is for batch or query inference and the optimizations tha
t go into either say \~100ms latency for a query embedding or maximizing throughput for batch embeddings.

I hope you fi
nd the podcast interesting, more than happy to discuss any of these topics with you or answer any questions about the co
ntent in the podcast! Thank you so much!

YouTube: [https://www.youtube.com/watch?v=xPdyivfheqI](https://www.youtube.com
/watch?v=xPdyivfheqI)

Spotify: [https://spotifyanchor-web.app.link/e/u6XPLYfF7Hb](https://spotifyanchor-web.app.link/e/
u6XPLYfF7Hb)
```
---

     
