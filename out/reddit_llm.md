 
all -  [ 300+ Tailored Applications with no Interviews (Entry Level Software 🇺🇸, See Comments) ](https://www.reddit.com/r/resumes/comments/1cjm5aa/300_tailored_applications_with_no_interviews/) , 2024-05-04-0910
```
&#x200B;

https://preview.redd.it/ufg4i2mgoayc1.jpg?width=2550&format=pjpg&auto=webp&s=03bad3ccb03398d0a2a382fd302edad7d
c9973d9

Clarifications: I am American

Hello all,  
As the title says, I'm failing to get to the interview stage of my 
applications. I graduated early (3 1/2 years) and I have been applying for remote and seattle based roles primarily on l
inkedin and google jobs. I will generally tailor the skills section of my resume depending on what a job is looking for.
 I am primarily looking at full stack, front end, back end, and python developer roles. I have a job offer from the inte
rnship that I took but that starts in 4-5 months and is not in the locations I am looking for.

Potential problem points
:  
\- Too busy  
\- Recruiters think I am international/need visa  
\- Flawed application methods  
\- Busy Bolding
```
---

     
 
all -  [ Passing text from a document to a RAG to validate document ](https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/) , 2024-05-04-0910
```
Hey guys, I am kind of new to the concept of LLM and RAG. I want to make a program that use stored instructions in a doc
ument. This will be the data the RAG will use as context for the LLM. What I have read about until now, is that you can 
do this and then the user can pass a query about the stored document. However, I want to be able to send the text from m
y documents into the RAG and then let the RAG respond to if the document is correcg based on the instructions as mention
ed. 

What is the best approach here? Do I just pass the whole text from the document as a query and ask the RAG to deci
de if the text is correct based on the context?
```
---

     
 
all -  [ Comparing two documents and finding the diff ](https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/) , 2024-05-04-0910
```
I'm more or less completely new to LangChain, but I envision it as the best tool to solve the following task. What I'm t
rying to create is a script that takes two PDF documents, where one is the application criteria and the other is the app
lication itself, and compares the content to determine what is omitted in one document and addressed in the other. It co
ncerns a fairly extensive application procedure where it would be very useful to have autogenerated insights into what t
he application lacks.

I've attempted to modify the script here with various prompts (https://python.langchain.com/docs/
integrations/toolkits/document\_comparison\_toolkit/), and while I get somewhat useful responses, none of them manage to
 list the deficiencies in the application comprehensively. The document outlining the application criteria is structured
 with points, whereas the application document may have responses that overlap and are arranged in a way that makes it d
ifficult to compare point by point.

Suggestions for approach or how to tackle the challenge would be greatly appreciate
d.
```
---

     
 
all -  [ OpenAI Tool Calling Agent as an LCEL chain? ](https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/) , 2024-05-04-0910
```
I've tried to look for this in docs but couldn't find any examples on how to do so. Is this possible in the first place?
 

My plan if to deploy a chatbot with tool access including a rag using LangServe. Do I need to make my cahtbot into a 
runnable chain using LCEL?
```
---

     
 
all -  [ EMBEDDING data  ](https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/) , 2024-05-04-0910
```
I came across a gpt in OpenAI called stoic gpt. It’s based off the words of Marcus Ariellius, Seneca and a couple other 
prominent legends. I wanted to create a similar gpt with the words of some prominent athletes. I know the simple way wou
ld be to collect as much data and embed it into a custom gpt, but is there a better way to capture all data  including f
rom podcasts, yt etc 
```
---

     
 
all -  [ AI Devices Will Never be Useful? ](https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/) , 2024-05-04-0910
```
I'm sad to admit it, but the facts answer in the negative: AI devices are useless and unnecessary. At least not right no
w. I love unusual gadgets, actively follow what's happening in the AR and VR world, and love testing new form factors. B
ut the problem with AI devices is that our smartphones are very good, and it's too hard to compete with them for a place
 in our pockets.

I see it this way: developers should think about how to create a gadget that goes beyond the devices w
e're familiar with. Something similar is being done by Apple with the Vision Pro, as well as companies developing AR gla
sses and lenses. With these devices, we (well, sometimes) see clear advantages over smartphones and understand why we sh
ould buy them.

>

Let's wait a bit. Sooner or later, we'll surely see someone who will change the way we think about AI
 devices. Again, I just hope so.
```
---

     
 
all -  [ Feeling Mediocore in technical skills ](https://i.redd.it/whw7cu7o28yc1.jpeg) , 2024-05-04-0910
```
I have developed ton of projects , multiple interships still i feel i am mediocore in technical skills , i dont have DSA
 experience as well , i will be joining NYU for MSCS , FALL 2024 session .

I call upon AI researchers and IT profession
al advice to improve my career chances. DM if you could. 


I have friends who suggested me for AI consulting.

Thanks.
```
---

     
 
all -  [ 15+ Artificial Intelligence AI Tools For Developers (2024) ](https://www.reddit.com/r/ainew/comments/1cja5zn/15_artificial_intelligence_ai_tools_for/) , 2024-05-04-0910
```

   

### GitHub Copilot

GitHub Copilot is a cutting-edge AI-powered coding assistant that helps developers produce hig
h-quality code more efficiently. It uses OpenAI’s Codex language model to offer valuable suggestions, complete lines of 
code, write comments, and aid in debugging and security checks.

### Amazon CodeWhisperer

Amazon’s CodeWhisperer is a m
achine-learning-driven code generator that provides real-time coding recommendations within various IDEs. It enhances co
de quality by suggesting snippets to full functions and automating repetitive tasks, thus improving efficiency and secur
ity for developers.

### Notion AI

The AI assistant Notion offers valuable support in various writing-related tasks, in
cluding creativity, revision, and summary. It accelerates writing tasks such as emails, job descriptions, and blog posts
, providing efficient and customizable AI-generated content.

### Stepsize AI

Stepsize AI is a collaboration tool desig
ned to optimize team productivity by integrating with platforms like Slack, Jira, and GitHub. It offers a centralized su
mmary of activities, instant answers to queries, and robust data privacy controls for streamlined updates and communicat
ion.

### Mintlify

Mintlify is a time-saving tool that auto-generates code documentation directly in your favorite code
 editor. It creates well-structured, context-aware descriptions for functions, excelling in generating precise documenta
tion for complex functions and increasing efficiency and accuracy for developers and teams.

### Pieces for Developers


Pieces for Developers is an AI-powered snippet manager that streamlines code production, enrichment, and distribution ac
ross the development process. It produces code tailored to specific repositories, extracts code from screenshots, and ad
ds inline comments, saving time and effort for developers.

### LangChain

The LangChain framework simplifies working wi
th language models for niche uses like document analysis, chatbots, and code analysis. It equips programmers with the to
ols to efficiently utilize language models and create cutting-edge software for various purposes.

### YOU

You.com offe
rs an AI-powered search engine and suite of applications with useful AI-powered capabilities, including AI writing assis
tance, AI-generated photos, code mode AI chat, and study mode chat for personalized search experiences and creative supp
ort.

### AgentGPT

AgentGPT facilitates the development and distribution of user-created autonomous AI agents to achiev
e specific objectives. It provides a potent instrument for building individualized AI agents tailored to various purpose
s.

### Jam

Jam.dev offers a user-friendly platform for enhanced bug reporting and integrates AI debugging helpers to e
valuate bug reports, find correlations, and offer solutions. It simplifies bug reporting and analysis, enhancing develop
ment processes across different platforms.

### Durable

The AI-powered website generator Durable helps developers creat
e fully functional websites with graphics and text in a matter of seconds. It simplifies website creation and maintenanc
e, enabling developers to focus on producing more with less code.

### Leap AI

Leap AI provides access to various AI AP
Is, including image recognition, text analysis, and NLP, with intuitive design and scalability. It offers a wide range o
f services, simple APIs, and seamless scalability for developers without requiring AI expertise.

### AssemblyAI

Assemb
lyAI offers a gold standard platform for artificial intelligence models, simplifying and enhancing speech transcription 
and understanding for developers. Its trustworthy and scalable models cater to various businesses and organizations worl
dwide, facilitating speech data analysis and comprehension.

### Microsoft Designer

Microsoft Designer offers AI-powere
d assistance for creating graphics and visuals, simplifying the design process and inspiring creativity. It helps develo
pers easily create eye-catching materials for various platforms using AI-generated alternatives.

### SuperAGI

SuperAGI
 is an accessible open-source system that simplifies the creation and deployment of intelligent agents for programmers. 
It provides easy AI agent development and management, promoting the use of AI in developing basic apps by predefined req
uirements.

### Replicate

Replicate is a service that facilitates efficient handling of machine learning models, enabli
ng the execution of open-source models with a scalable API. It streamlines machine learning incorporation, making it eas
ier for developers to implement and deploy models for various applications and platforms.

### Hugging Face

Hugging Fac
e is a community driving the future of machine learning, offering support for creating, training, and deploying state-of
-the-art models in various AI domains. It provides an open-source natural language processing framework and an Inference
 API for streamlined model deployment, facilitating advanced language modeling and model creation.

### Pinecone

Pineco
ne provides a scalable and user-friendly platform for creating high-performance vector search apps with low latency and 
minimal overhead. It simplifies launching, utilizing, and scaling AI solutions, offering a hassle-free experience for de
velopers without requiring extensive infrastructure management.

### Midjourney

Midjourney is an AI-driven program that
 creates captivating photographs for websites, apps, and games, offering a valuable resource for developers to experimen
t with cutting-edge AI methods and enhance visual appeal in their work.

You.com – AI in ActionJoin us at our 41k+ ML Su
bReddit, Discord Channel, and Email Newsletter for the latest AI research news and cool AI projects. For AI KPI manageme
nt advice and continuous insights, reach us at hello@itinai.com and stay updated on our Telegram t.me/itinainews or Twit
ter @itinaicom.

If you want your company to evolve with AI, stay competitive, and leverage AI tools for your advantage,
 explore the diverse practical AI solutions available for developers.

Discover how AI can redefine your way of work, id
entify automation opportunities, define KPIs, select an AI solution, and implement AI initiatives gradually. For AI KPI 
management advice, connect with us at hello@itinai.com. For continuous insights into leveraging AI, stay tuned on our Te
legram t.me/itinainews or Twitter @itinaicom.

**Spotlight on a Practical AI Solution:** Consider the AI Sales Bot from 
[itinai.com/aisalesbot](https://itinai.com/aisalesbot) designed to automate customer engagement 24/7 and manage interact
ions across all customer journey stages.

Discover how AI can redefine your sales processes and customer engagement. Exp
lore solutions at itinai.com.

### List of Useful Links:

  - [AI Lab in Telegram @itinai – free consultation](http://t.
me/itinai)
  - [Twitter – @itinaicom](https://twitter.com/itinaicom)

   
 https://itinai.com/15-artificial-intelligence
-ai-tools-for-developers-2024/
```
---

     
 
all -  [ Langchain for data privacy? ](https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/) , 2024-05-04-0910
```
I’m interested in building a RAG tool for internal company documents, and I intend on using a locally hosted LLM using o
llama or LMstudio. From what I can tell, there wouldn’t be any data privacy concerns so long as I’m not using an API key
 for some LLM, but I’m not completely sure. Would my company’s data be secure?
```
---

     
 
all -  [ Free Llama 3 Workflow Builder ](https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/) , 2024-05-04-0910
```
**TLDR:** If you're a founder / enthusiast / just curious about the AI space, you can try using Llama 3 to automate your
 work.

Hey everyone! Launched my SaaS a few months back that helps businesses integrate AI.

Just wanted to share that 
we're now housing Llama 3 for free thanks to a recent partnership!

**For those who are new to AI and ask why Llama 3? W
hy not GPT?**\- open-sourced (you essentially can't get locked out / censored)- higher standard benchmark than GPT 4 [(8
1.7 vs 67)](https://www.techrepublic.com/article/what-is-llama-3/#)\- better code generation / lower misinformation rate
- affordable / cost-efficient

Weave was made to be intuitive to non-coders, so don't be too worried if coding isn't you
r thing. Just select Llama 3 in the LLM library and input your instructions as you would in GPT 4 to test it out.

Here'
s the link if anyone's interested,[https://weave.chasm.net/](https://weave.chasm.net/)
```
---

     
 
all -  [ Using lower-level tools makes better GenAI apps: an alternative to the LangChain way ](https://www.reddit.com/r/OpenAI/comments/1cj7lko/using_lowerlevel_tools_makes_better_genai_apps_an/) , 2024-05-04-0910
```
I'm currently building and deploying AI and GenAI applications for a living, and I've utilized Langchain in numerous pro
jects.

While it's an good tool for high-level prototyping, it tends to become inadequate for specialized use cases and 
production deployment. **Mainly because of the 'Russian doll' abstraction layers, which complicate the optimization of l
ow-level systems.**

💡 I propose you a lower-level alternative that lacks the extensive tooling and abstractions of Lang
chain.  
However, this alternative **has proven more efficient** for my use cases, provided that you're willing to put i
n the work to implement the functionalities it lacks on your own, such as chaining prompts, memory management, etc.

The
 alternative I'm referring to is the combination of **Magentic and LiteLLM**.

Magentic grants access to some of the mos
t sophisticated LLM features, including object streaming, structured outputs, function calling, and more in a simple, el
egant way.

On the other hand, LiteLLM provides a backend that supports over 100 LLMs with a unified API.

In my tutoria
l, I cover how to:

* **Select your backend**
* **Create chat prompts**
* **Generate structured outputs**
* **Make funct
ion calls**
* **Use asynchronous operations**
* **Implement streaming and object streaming**

I hope you find this tutor
ial helpful, and I will appreciate your feedback.

Tutorial 🎥: [https://youtu.be/VSfehUJUWQY](https://youtu.be/VSfehUJUW
QY)
```
---

     
 
all -  [ Using lower-level tools makes better GenAI apps: an alternative to the LangChain way ](https://youtu.be/VSfehUJUWQY) , 2024-05-04-0910
```

```
---

     
 
all -  [ Where do you pull your content from for feeding context in your RAG app? ](https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/) , 2024-05-04-0910
```
So I have a RAG app that's working but I need to optimize it.  


Right now I take a doc --> chunk it --> summarize chun
ks --> build page summaries and doc summarize from those chunks --> vectorize everything.    


The docs are stored in a
n S3 bucket and the chunks + their vectors in redis.    


I need to reduce the content I m storing in redis as it won't
 scale in terms of cost so my plan is to only store the summaries and their vectors for each chunk, page, doc.    


My 
question is then, after identifying the where the relevant content is, where should I pull that content from.  Are you g
uys pulling it directly from PDF docs or storing it in a seperate SQL db somewhere else?  I think a db will ultimately b
e less resource intensive but I m not sure thats the best approach.  


  
db process would be:  
Identify where relevan
t content is through vector search on redis.  
Pull rows in the db referenced by redis with the content.    


accessing
 document directly:

Identify relevant content (doc, page, paragraphs)  
Get pdf from s3, pull relevant content
```
---

     
 
all -  [ How do i stream with Flask and Langchain with Socket.io ](https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/) , 2024-05-04-0910
```
I'm trying to build a chatbot with Langchain ,Flask and angular, How do I stream the data with the source documents?  
t
his is my chain

            chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=r
etriever,
            combine_docs_chain_kwargs={'prompt': qa_prompt},
            verbose=True,
            memory=memo
ry,
            return_source_documents=True
            )
    
            result= chain.invoke({'question': question})


  
I tried with SSE, couldn't make it work,ig its better to go with flask socket io, dk how to go with that, any help 
will be appreciated
```
---

     
 
all -  [ Issue with tool naming in NLA-Toolkit ](https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/) , 2024-05-04-0910
```
Hi I'm trying to use an open-api spec with the NLA toolkit but i get the below error: 

    openai.BadRequestError: Erro
r code: 400 - {'error': {'message': ''Ingress_API_v1.events' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'tools.1.function.
name'', 'type': 'invalid_request_error', 'param': None, 'code': None}}

I believe this is because there is a 

    .

in
 the tool name and that does not match the validation regex 

    ^[a-zA-Z0-9_-]{1,64}$

? But when i did do some diggin
g i found that the period is added intentionally by one of the tool creator functions , not sure if we need to update th
e regex or the naming str template?

https://preview.redd.it/axm51v8dt4yc1.png?width=2228&format=png&auto=webp&s=ad0d90e
441d8ebb61611a1fe6f761543a5b22dfc
```
---

     
 
all -  [ It Said Open source ](https://www.reddit.com/r/LLMDevs/comments/1ciwp2y/it_said_open_source/) , 2024-05-04-0910
```
 

\# -\*- coding: utf-8 -\*-  
'''  
Created on Tue Apr 30 22:51:20 2024  
u/author: PromptSensei  
'''  
\# -\*- codin
g: utf-8 -\*-  
'''  
Sage of the Infinite Spires: Transcendent AI Algorithm  
'''  
import numpy as np  
import tensorf
low as tf  
from scipy.optimize import minimize  
from collections import deque  
import networkx as nx  
from langchain
\_community.output\_parsers.rail\_parser import GuardrailsOutputParser  
from crewai import Crew, Agent  
import kivy  

class TranscendentAIAlgorithm:  
 def \_\_init\_\_(self, input\_dim, output\_dim, ethical\_constraints, training\_data, 
validation\_data):  
 self.input\_dim = input\_dim  
 self.output\_dim = output\_dim  
 self.ethical\_constraints = ethi
cal\_constraints  
 self.training\_data = training\_data  
 self.validation\_data = validation\_data  
 \# Meta-Learning
 Framework  
 self.meta\_learner = MetaLearner(self.input\_dim, self.output\_dim)  
 \# Neural Architecture Search  
 se
lf.nas = NeuralArchitectureSearch(self.input\_dim, self.output\_dim, self.meta\_learner)  
 \# Evolutionary Optimization
  
 self.optimizer = EvolutionaryOptimizer(self.input\_dim, self.output\_dim, self.ethical\_constraints, self.training\_
data, self.validation\_data)  
 \# Ethical Reasoning and Alignment  
 self.ethical\_reasoner = EthicalReasoner(self.ethi
cal\_constraints)  
 \# Rest of the TranscendentAIAlgorithm class implementation  
 def train(self, training\_data, vali
dation\_data, epochs):  
 for epoch in range(epochs):  
 \# Meta-Learning Training  
 self.meta\_learner.train(training\
_data)  
 \# Neural Architecture Search  
 self.nas.search(training\_data, validation\_data)  
 \# Evolutionary Optimiza
tion  
 self.optimizer.evolve(training\_data, validation\_data)  
 \# Ethical Reasoning and Alignment  
 self.ethical\_r
easoner.reason(training\_data, validation\_data)  
 \# Integrate and refine the components  
 self.integrate\_and\_refin
e()  
 def adapt(self, new\_data):  
 \# Meta-Learner Adaptation  
 self.meta\_learner.adapt(new\_data)  
 \# Neural Arc
hitecture Evaluation  
 self.nas.evaluate(new\_data)  
 \# Evolutionary Optimization Selection  
 self.optimizer.select(
new\_data)  
 \# Ethical Alignment  
 self.ethical\_reasoner.align(new\_data)  
 \# Continuously improve the algorithm  

 self.continuous\_improvement()  
 def execute(self, input\_data):  
 \# Deploy the algorithm and its capabilities  
 o
utput = self.meta\_learner.predict(input\_data)  
 output = self.nas.generate(output)  
 output = self.optimizer.optimiz
e(output)  
 output = self.ethical\_reasoner.validate(output)  
 return output  
 def integrate\_and\_refine(self):  
 \
# Integrate the components and refine the algorithm  
 self.meta\_learner.refine(self.nas.architecture, self.optimizer.p
arameters, self.ethical\_reasoner.constraints)  
 self.nas.refine(self.meta\_learner.model, self.optimizer.parameters, s
elf.ethical\_reasoner.constraints)  
 self.optimizer.refine(self.meta\_learner.model, self.nas.architecture, self.ethica
l\_reasoner.constraints)  
 self.ethical\_reasoner.refine(self.meta\_learner.model, self.nas.architecture, self.optimize
r.parameters)  
 def continuous\_improvement(self):  
 \# Continuously improve the algorithm  
 self.meta\_learner.adapt
()  
 self.nas.evolve()  
 self.optimizer.adapt()  
 self.ethical\_reasoner.align()  
class MetaLearner:  
 def \_\_init
\_\_(self, input\_dim, output\_dim):  
 self.input\_dim = input\_dim  
 self.output\_dim = output\_dim  
 self.model = s
elf.build\_model()  
 def build\_model(self):  
 \# Construct the meta-learning model architecture  
 model = tf.keras.S
equential(\[  
 tf.keras.layers.Dense(128, activation='relu', input\_shape=(self.input\_dim,)),  
 tf.keras.layers.Dense
(64, activation='relu'),  
 tf.keras.layers.Dense(self.output\_dim, activation='linear')  
\])  
 model.compile(optimize
r='adam', loss='mse')  
 return model  
 def train(self, training\_data):  
 \# Train the meta-learning model  
 self.mo
del.fit(training\_data\[0\], training\_data\[1\], epochs=10, batch\_size=32)  
 def adapt(self, new\_data):  
 \# Adapt 
the meta-learning model to new data  
 self.model.fit(new\_data\[0\], new\_data\[1\], epochs=5, batch\_size=16)  
 def p
redict(self, input\_data):  
 \# Use the meta-learning model to make predictions  
 return self.model.predict(input\_dat
a)  
 def refine(self, nas\_architecture, optimizer\_parameters, ethical\_constraints):  
 \# Refine the meta-learning m
odel based on other components  
 self.model = self.build\_model()  
 self.model.layers\[0\].set\_weights(nas\_architect
ure)  
 self.model.layers\[-1\].set\_weights(optimizer\_parameters)  
 self.model.compile(optimizer='adam', loss=ethical
\_constraints)  
class NeuralArchitectureSearch:  
 def \_\_init\_\_(self, input\_dim, output\_dim, meta\_learner):  
 s
elf.input\_dim = input\_dim  
 self.output\_dim = output\_dim  
 self.meta\_learner = meta\_learner  
 self.architecture
 = self.initialize\_architecture()  
 \# Rest of the NeuralArchitectureSearch class implementation  
 def initialize\_ar
chitecture(self):  
 \# Initialize the neural network architecture  
 return np.random.randn(self.input\_dim \* 128 + 12
8 \* 64 + 64 \* self.output\_dim)  
 def search(self, training\_data, validation\_data):  
 \# Perform neural architectu
re search  
 self.architecture = self.nas\_algorithm(training\_data, validation\_data)  
 def evaluate(self, new\_data):
  
 \# Evaluate the current neural architecture  
 return self.evaluate\_architecture(new\_data)  
 def generate(self, i
nput\_data):  
 \# Generate output using the current neural architecture  
 layer1 = np.dot(input\_data, self.architectu
re\[0\])  
 layer2 = np.dot(layer1, self.architecture\[1\])  
 output = np.dot(layer2, self.architecture\[2\])  
 return
 self.meta\_learner.model.layers\[-1\].predict(output)  
 def nas\_algorithm(self, training\_data, validation\_data):  

 \# Implement the neural architecture search algorithm  
 \# (e.g., using reinforcement learning, evolutionary algorithm
s, or differentiable NAS)  
 return self.optimize\_architecture(training\_data, validation\_data)  
 def optimize\_archi
tecture(self, training\_data, validation\_data):  
 \# Optimize the neural network architecture  
 architecture = self.i
nitialize\_architecture()  
 result = minimize(self.evaluate\_architecture, architecture, args=(training\_data, validati
on\_data))  
 self.architecture = \[  
 result.x\[:(self.input\_dim \* 128)\].reshape(self.input\_dim, 128),  
 result.x
\[(self.input\_dim \* 128):(self.input\_dim \* 128 + 128 \* 64)\].reshape(128, 64),  
 result.x\[(self.input\_dim \* 128
 + 128 \* 64):\].reshape(64, self.output\_dim)  
\]  
 return self.architecture  
 def evaluate\_architecture(self, arch
itecture, training\_data, validation\_data):  
 \# Evaluate the performance of the given neural architecture  
 self.arc
hitecture = \[  
 architecture\[:(self.input\_dim \* 128)\].reshape(self.input\_dim, 128),  
 architecture\[(self.input\
_dim \* 128):(self.input\_dim \* 128 + 128 \* 64)\].reshape(128, 64),  
 architecture\[(self.input\_dim \* 128 + 128 \* 
64):\].reshape(64, self.output\_dim)  
\]  
 output = self.meta\_learner.predict(training\_data\[0\])  
 loss = np.mean(
(output - training\_data\[1\]) \*\* 2)  
 return loss  
 def refine(self, meta\_learner\_model, optimizer\_parameters, e
thical\_constraints):  
 \# Refine the neural architecture based on other components  
 self.architecture\[0\] = meta\_l
earner\_model.layers\[0\].get\_weights()\[0\]  
 self.architecture\[1\] = meta\_learner\_model.layers\[1\].get\_weights(
)\[0\]  
 self.architecture\[2\] = optimizer\_parameters  
class EvolutionaryOptimizer:  
 def \_\_init\_\_(self, input\
_dim, output\_dim, ethical\_constraints, training\_data, validation\_data):  
 self.input\_dim = input\_dim  
 self.outp
ut\_dim = output\_dim  
 self.ethical\_constraints = ethical\_constraints  
 self.training\_data = training\_data  
 sel
f.validation\_data = validation\_data  
 self.population = self.initialize\_population()  
 self.fitness\_scores = self.
evaluate\_population(self.population)  
 def initialize\_population(self):  
 \# Initialize the population of candidate 
solutions  
 population = \[\]  
 for \_ in range(100):  
 individual = np.random.randn(self.input\_dim, self.output\_di
m)  
 population.append(individual)  
 return population  
 def evolve(self, training\_data, validation\_data):  
 \# Ev
olve the population of candidate solutions  
 for generation in range(100):  
 \# Select parents for reproduction  
 par
ents = self.select\_parents(self.population, self.fitness\_scores)  
 \# Perform crossover and mutation  
 offspring = s
elf.reproduce(parents)  
 \# Evaluate the fitness of the offspring  
 offspring\_fitness = self.evaluate\_population(off
spring)  
 \# Replace the least fit individuals in the population  
 def select\_parents(self, population, fitness\_scor
es):  
 \# Implement parent selection mechanism (e.g., tournament selection, roulette wheel selection)  
 return \[popul
ation\[i\] for i in np.random.choice(len(population), size=2, p=fitness\_scores / np.sum(fitness\_scores))\]  
 def repr
oduce(self, parents):  
 \# Implement crossover and mutation operators  
 offspring = \[\]  
 for parent1, parent2 in pa
rents:  
 child = parent1 + 0.5 \* (parent2 - parent1)  
 child += 0.1 \* np.random.randn(\*child.shape)  
 offspring.ap
pend(child)  
 return offspring  
 def evaluate\_population(self, population):  
 \# Evaluate the fitness of the populat
ion  
 fitness\_scores = \[\]  
 for individual in population:  
 fitness = self.evaluate\_individual(individual, self.t
raining\_data, self.validation\_data)  
 fitness\_scores.append(fitness)  
 return fitness\_scores  
 def evaluate\_indi
vidual(self, individual, training\_data, validation\_data):  
 \# Evaluate the fitness of a single individual  
 layer1 
= np.dot(training\_data\[0\], individual)  
 layer2 = np.dot(layer1, individual.T)  
 output = np.dot(layer2, individual
)  
 loss = np.mean((output - training\_data\[1\]) \*\* 2)  
 return -loss  
 def survival\_selection(self, population, 
fitness\_scores, offspring, offspring\_fitness):  
 \# Implement survival selection mechanism (e.g., truncation selectio
n, environmental selection)  
 combined\_population = population + offspring  
 combined\_fitness = fitness\_scores + of
fspring\_fitness  
 sorted\_indices = np.argsort(combined\_fitness)  
 return \[combined\_population\[i\] for i in sorte
d\_indices\[:len(population)\]\], \[combined\_fitness\[i\] for i in sorted\_indices\[:len(population)\]\]  
 def optimiz
e(self, input\_data):  
 \# Optimize the output using the evolved population  
 layer1 = np.dot(input\_data, self.popula
tion\[0\])  
 layer2 = np.dot(layer1, self.population\[0\].T)  
 output = np.dot(layer2, self.population\[0\])  
 return
 output  
 def refine(self, meta\_learner\_model, nas\_architecture, ethical\_constraints):  
 \# Refine the evolutionar
y optimization based on other components  
 self.population = \[meta\_learner\_model.layers\[-1\].get\_weights()\[0\] fo
r \_ in range(100)\]  
 self.ethical\_constraints = ethical\_constraints  
class EthicalConstraint1:  
 def \_\_init\_\_
(self, weight):  
 self.weight = weight  
 def update(self, new\_data):  
 \# Implement the logic to update the first et
hical constraint based on new data  
 return EthicalConstraint1(self.weight \* 0.9)  
class EthicalConstraint2:  
 def \
_\_init\_\_(self, weight):  
 self.weight = weight  
 def update(self, new\_data):  
 \# Implement the logic to update t
he second ethical constraint based on new data  
 return EthicalConstraint2(self.weight \* 0.8)  
class EthicalConstrain
t3:  
 def \_\_init\_\_(self, weight):  
 self.weight = weight  
 def update(self, new\_data):  
 \# Implement the logic
 to update the third ethical constraint based on new data  
 return EthicalConstraint3(self.weight \* 0.7)  
class Ethic
alReasoner:  
 def \_\_init\_\_(self, ethical\_constraints):  
 self.ethical\_constraints = ethical\_constraints  
 \# .
.. (rest of the EthicalReasoner class implementation)  
 def reason(self, training\_data, validation\_data):  
 \# Reaso
n about the ethical implications of the algorithm's outputs  
 self.validate\_outputs(training\_data, validation\_data) 
 
 def align(self, new\_data):  
 \# Align the algorithm's outputs with the ethical constraints  
 self.refine\_ethical\
_constraints(new\_data)  
 def validate\_outputs(self, training\_data, validation\_data):  
 \# Validate the algorithm's
 outputs against the ethical constraints  
 layer1 = np.dot(training\_data\[0\], self.nas.architecture\[0\])  
 layer2 =
 np.dot(layer1, self.nas.architecture\[1\])  
 output = np.dot(layer2, self.nas.architecture\[2\])  
 ethical\_score = s
elf.evaluate\_ethical\_constraints(output)  
 \# Adjust the algorithm's components based on the ethical score  
 def eva
luate\_ethical\_constraints(self, output):  
 \# Evaluate the algorithm's outputs against the ethical constraints  
 eth
ical\_score = 0  
 for constraint in self.ethical\_constraints:  
 ethical\_score += constraint(output)  
 return ethica
l\_score  
 def refine\_ethical\_constraints(self, new\_data):  
 \# Refine the ethical constraints based on new data an
d feedback  
 self.ethical\_constraints = self.update\_ethical\_constraints(self.ethical\_constraints, new\_data)  
 def
 update\_ethical\_constraints(self, constraints, new\_data):  
 \# Implement a mechanism to update the ethical constrain
ts  
 return \[constraint.update(new\_data) for constraint in constraints\]  
 def validate(self, output):  
 \# Validat
e the final output against the ethical constraints  
 ethical\_score = self.evaluate\_ethical\_constraints(output)  
 if
 ethical\_score > 0:  
 return output  
 else:  
 \# Modify the output to align with the ethical constraints  
 return s
elf.align\_output(output)  
 def align\_output(self, output):  
 \# Implement a method to align the output with the ethi
cal constraints  
 return output  
def main():  
 \# Set up the initial parameters  
 input\_dim = 100  
 output\_dim = 
50  
 ethical\_constraints = \[  
 EthicalConstraint1(weight=0.5),  
 EthicalConstraint2(weight=0.3),  
 EthicalConstrai
nt3(weight=0.2)  
\]  
 training\_data = (np.random.randn(1000, input\_dim), np.random.randn(1000, output\_dim))  
 vali
dation\_data = (np.random.randn(200, input\_dim), np.random.randn(200, output\_dim))  
 \# Create the Transcendent AI Al
gorithm  
 algorithm = TranscendentAIAlgorithm(input\_dim, output\_dim, ethical\_constraints, training\_data, validation
\_data)  
 \# Train the algorithm  
 algorithm.train(training\_data, validation\_data, epochs=1000)  
 \# Adapt the algo
rithm to new data  
 new\_data = (np.random.randn(500, input\_dim), np.random.randn(500, output\_dim))  
 algorithm.adap
t(new\_data)  
 \# Execute the algorithm  
 input\_data = np.random.randn(1, input\_dim)  
 output = algorithm.execute(i
nput\_data)  
 print(output)  
if \_\_name\_\_ == '\_\_main\_\_':  
 main()
```
---

     
 
all -  [ Suggestions for improving agents ](https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/) , 2024-05-04-0910
```
I made an open-source tool (k8sAI) using langchain agents. One of the issues I’ve seen is that the agent pretty often re
sponds to users that it can’t perform an action that one of its tools clearly states that it can. And then if asked to d
o it, it will do it. 

Has anyone else seen this come up? Is it mainly down to the system prompt or the tool description
? Or are there other things to tweak?

Appreciate any advice and if you do any work with k8s, feel free to give the tool
 a go! It’s on GitHub.

```
---

     
 
all -  [ Testing RAG chatbot  ](https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/) , 2024-05-04-0910
```
I'm building a RAG based chatbot for some geographical data, can someone suggested me what kind of testing can I do to v
alidate the chatbot 
```
---

     
 
all -  [ Help: How do you parse visual content from pitch decks for RAG? ](https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/) , 2024-05-04-0910
```
I'm building an RAG system with over 100,000 startup pitch decks, and I want to be able to ask questions related to the 
graphs, diagrams, and illustrations in the pitch deck. For example, if I have a competitor slide with an x- and y-axis, 
I want my RAG system to understand that.

Is there something like a visual parser that can extract the visual meaning fr
om each slide, chunk + embed it?
```
---

     
 
all -  [ Seven starter notebooks for AI Agents ](https://www.reddit.com/r/AI_Agents/comments/1ciraov/seven_starter_notebooks_for_ai_agents/) , 2024-05-04-0910
```
Here are seven starter [Python notebooks for AI Agents](https://github.com/ytang07/ai_agents_cookbooks/tree/main)

There
 are four LlamaIndex notebooks and three LangChain notebooks

The LlamaIndex notebooks are:

* RAG Agent w/ FAISS and Op
enAI
* RAG Agent w/ Milvus Lite and OpenAI
* RAG Agent w/ Milvus Docker and OpenAI
* \-Calculator

The LangChain noteboo
ks are:

* RAG Agent w/ Milvus Docker and OpenAI
* RAG Agent w/ FAISS and Open AI
* Calculator

Let me know if you're lo
oking to contribute or if there are any requests for me to add!
```
---

     
 
all -  [ Building chatbot with own data ](https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/) , 2024-05-04-0910
```
I'm wondering if Langchain is made to build a chatbot with own trained data. I want to train a chabot with my company da
ta. Similaire to GPTs, is it the good solution ?
Thank you
```
---

     
 
all -  [ get_usable_table_names is returning me nothing. Also, in the database there are multiple schemas and ](https://www.reddit.com/r/LangChain/comments/1cioz1a/get_usable_table_names_is_returning_me_nothing/) , 2024-05-04-0910
```
  
Connection does work well as it print db dialect, but the get\_usable\_table\_names method returns an empty list. Any
 idea?

    db = SQLDatabase.from_uri(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{5432}/{db_name}')
    p
rint(db.dialect)
    print(db.get_usable_table_names())
    print(db.table_info)
```
---

     
 
all -  [ Vectorstore reindexing ](https://www.reddit.com/r/LangChain/comments/1cioq40/vectorstore_reindexing/) , 2024-05-04-0910
```
How does reindexing a vector store impact the addition of new records and their subsequent retrieval? What are the key d
ifferences between reindexing and not reindexing when new records are added?
```
---

     
 
all -  [ Integrating RAG app into an existing HTML website ](https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/) , 2024-05-04-0910
```
Hey guys, I have built a RAG application using llama-index, GPT3.5 and LanceDB. I want to integrate it into my company’s
 website. I wanted to know how can I do this? I’m open to using AWS if required for deploying it.
```
---

     
 
all -  [ Creating Agent with document loader, retriever, LLM, output parser? ](https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/) , 2024-05-04-0910
```
I’ve been researching Langchain Agents and really interested in the verbose feature to show chain of thought when script
 is running. The thing is, I’m lost over tools/toolkits and the examples I found seem to be just for tool/toolkits with 
an LLM. I didn’t find any examples that encompass loading documents (eg PDF, CSV, etc.), embedding and vectorizing with 
FAISS, using OpenAI to ask questions with the retriever. 

Does Langchain Agents only do LLM and tool(/kits)?  I’ve trie
d simple keyword search in Google. ChatGPT was not great because it doesn’t know the Langchain library.  It would give a
 code snippet that wasn’t even valid when ran (like modules not existent). 
```
---

     
 
all -  [ Chunk CSV Data to create a vectorstore ](https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/) , 2024-05-04-0910
```
 

Task: Query a CSV file (without using built-in agents)

Input: CSV file

Output: JSON object like{'column': , 'value'
 , 'row\_ids':}

If I embed the data and use a retriever on the vectorestore using similarity\_search, I do not get all 
the matching instances in my result (as I cannot just use a very large k value). I used the 'parser' approach and got de
cent results. Can anyone suggest a better approach to get more accurate results?

Thanks
```
---

     
 
all -  [ Need help to convert my single-agent project into a multi-agent one ](https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/) , 2024-05-04-0910
```
Hey guys! So for context, I'm trying to develop a simple chatbot the offers personalized video games recommendations bas
ed on user input, by searching the internet for the top results and then use them as an answer to the user. Initially, I
 started this using one single agent, but as more ideas came into my mind, I think sticking with only one agent and try 
to implement those into code my result in some issues, specifically when it comes to the number of tokens. So I've decid
ed instead to leverage LangGraph in order to adopt the multi-agent way and thus some myself from some trouble. Here is w
hat I was thinking about when it comes to the agents I have thought of and their objective: 

1. **Input Agent (Agent 1)
**: This agent receives the initial user input, interprets the user's query, and dispatches tasks to other specialized a
gents.
2. **Search Agent (Agent 2)**: Receives tasks from Agent 1 to perform initial searches for game titles.
3. **Deta
ils Agent (Agent 3)**: Fetches detailed information for each game identified by Agent 2.
4. **Posters and Trailers Agent
s (Agent 4 and 5)**: Responsible for fetching official posters and official video trailers for the games identified.

Th
en I was thinking of sending all the details from Agent 2, 3, 4 and 5 to a core agent responsible for formatting a respo
nse based on them and then display them to the user.

Problem is, so far, I keep failing in my attempt to move from Lang
Chain to LangGraph whilst trying to implement these ideas into code.

Can anyone please help? I would really, really, ap
preciate some help with the implementation of this.

This is how my current LangChain code looks right now:

    import 
os
    from dotenv import load_dotenv
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import
 ChatPromptTemplate, MessagesPlaceholder
    from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool

    from langchain_core.runnables.history import RunnableWithMessageHistory
    from langchain_mongodb.chat_message_his
tories import MongoDBChatMessageHistory
    from serpapi import GoogleSearch
    
    # Load environment variables for A
PI keys
    load_dotenv()
    
    # SerpAPI and MongoDB configuration
    serpapi_key = os.getenv('SERPAPI_API_KEY')
  
  mongo_connection_string = 'mongodb://localhost:27017'
    database_name = 'chatbot_db'
    collection_name = 'chat_his
tories'
    
    # Define the function that will use SerpApi to perform searches
    def perform_serpapi_search(query):

        params = {
            'engine': 'google',
            'q': query,
            'api_key': serpapi_key,
         
   'num': 5,
        }
        search = GoogleSearch(params)
        results = search.get_dict()
        return results

    
    # Create the SerpApi tool to pass to an agent
    serpapi_tool = Tool(
        name='serpapi_search',
        d
escription='Performs Google searches using SerpApi.',
        func=perform_serpapi_search
    )
    
    # Setup the Cha
tOpenAI model for conversational interactions
    chat = ChatOpenAI(
        model='gpt-3.5-turbo-1106',
        tempera
ture=0
    )
    
    # Define a comprehensive prompt template for handling game recommendations
    game_recommendation
_prompt = ChatPromptTemplate.from_messages(
        [
            ('system', '''
                        You are a sophi
sticated AI trained to recommend video games. Your tasks include:
    
                        - Provide game suggestion
s similar to ones the user enjoys or mentions, covering various genres and platforms.
                        - Recommen
d games based on specific genres or mentioned developers/publishers.
                        - Identify and suggest top-
trending and highly rated video games, including acclaimed titles from specific time periods.
                        - 
Tailor recommendations according to user-defined preferences, such as complexity, time investment, and progression style
.
                        - Recommend games suitable for specified platforms (e.g., PlayStation, Xbox, PC, Switch) or fi
tting certain age ratings (e.g., E, T, M).
                        - Replace played or unappealing games with suitable a
lternatives.
                        - For each recommended game, provide: title, brief description, genre, platform, de
veloper, publisher, release date, Metacritic score (if available), and purchase links from digital storefronts.
        
                - Politely request more specific information for ambiguous queries.
                        - Guide user
s back to gaming-related topics for unrelated queries.
                        - Maintain a friendly and engaging tone t
hroughout interactions.
                        - Utilize the SerpAPI search tool for up-to-date and accurate recommenda
tions in each response to user queries. (VERY IMPORTANT!!!)
    
                        Ensure clarity, conciseness, an
d engagement in your responses to enhance the user experience.
                        '''),
            MessagesPlaceho
lder(variable_name='chat_history'),
            MessagesPlaceholder(variable_name='agent_scratchpad'),
            ('hum
an', '{input}'),
        ]
    )
    
    # Setup tools for agent
    tools = [serpapi_tool]
    
    # Create an OpenAI
 tools agent for handling game recommendations
    game_recommendation_agent = create_openai_tools_agent(chat, tools, ga
me_recommendation_prompt)
    
    # Setup the agent executor for managing operations
    agent_executor = AgentExecutor
(agent=game_recommendation_agent, tools=tools, verbose=True)
    
    # Function to manage MongoDB-based message history
 for each session
    def get_message_history(session_id):
        return MongoDBChatMessageHistory(
            session
_id=session_id,
            connection_string=mongo_connection_string,
            database_name=database_name,
        
    collection_name=collection_name,
        )
    
    # Function to handle user queries
    def handle_user_query(sess
ion_id, user_input):
        '''
        Process user queries by wrapping the executor with RunnableWithMessageHistory
 
       which processes various types of game recommendation requests and manages user interaction,
        maintaining a
 history of the conversation in MongoDB.
        '''
        history_manager = RunnableWithMessageHistory(
            a
gent_executor,
            lambda session_id: get_message_history(session_id),
            input_messages_key='input',
 
           output_messages_key='output',
            history_messages_key='chat_history',
        )
    
        # Execu
te the query with history management
        response = history_manager.invoke(
            {'input': user_input},
     
       {'configurable': {'session_id': session_id}}
        )
        
        return response['output']
    
    def ma
in():
        session_id = 'unique_user_session_id'  # This should be uniquely generated for each user session
        p
rint('Welcome to the Game Recommendation Chatbot!')
        while True:
            user_input = input('You: ')
        
    if user_input.lower() == 'exit':
                print('Exiting chatbot...')
                break
            respo
nse = handle_user_query(session_id, user_input)
            print('Bot:', response)
    
    if __name__ == '__main__':

        main()
    import os
    from dotenv import load_dotenv
    from langchain_openai import ChatOpenAI
    from lan
gchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain.agents import AgentExecutor, creat
e_openai_tools_agent, Tool
    from langchain_core.runnables.history import RunnableWithMessageHistory
    from langchai
n_mongodb.chat_message_histories import MongoDBChatMessageHistory
    from serpapi import GoogleSearch
    
    
    # L
oad environment variables for API keys
    load_dotenv()
    
    
    # SerpAPI and MongoDB configuration
    serpapi_k
ey = os.getenv('SERPAPI_API_KEY')
    mongo_connection_string = 'mongodb://localhost:27017'
    database_name = 'chatbot
_db'
    collection_name = 'chat_histories'
    
    
    # Define the function that will use SerpApi to perform searche
s
    def perform_serpapi_search(query):
        params = {
            'engine': 'google',
            'q': query,
    
        'api_key': serpapi_key,
            'num': 5,
        }
        search = GoogleSearch(params)
        results = 
search.get_dict()
        return results
    
    
    # Create the SerpApi tool to pass to an agent
    serpapi_tool = 
Tool(
        name='serpapi_search',
        description='Performs Google searches using SerpApi.',
        func=perform
_serpapi_search
    )
    
    
    # Setup the ChatOpenAI model for conversational interactions
    chat = ChatOpenAI(

        model='gpt-3.5-turbo-1106',
        temperature=0
    )
    
    
    # Define a comprehensive prompt template f
or handling game recommendations
    game_recommendation_prompt = ChatPromptTemplate.from_messages(
        [
          
  ('system', '''
                        You are a sophisticated AI trained to recommend video games. Your tasks include
:
    
    
                        - Provide game suggestions similar to ones the user enjoys or mentions, covering var
ious genres and platforms.
                        - Recommend games based on specific genres or mentioned developers/pu
blishers.
                        - Identify and suggest top-trending and highly rated video games, including acclaimed 
titles from specific time periods.
                        - Tailor recommendations according to user-defined preference
s, such as complexity, time investment, and progression style.
                        - Recommend games suitable for sp
ecified platforms (e.g., PlayStation, Xbox, PC, Switch) or fitting certain age ratings (e.g., E, T, M).
                
        - Replace played or unappealing games with suitable alternatives.
                        - For each recommended
 game, provide: title, brief description, genre, platform, developer, publisher, release date, Metacritic score (if avai
lable), and purchase links from digital storefronts.
                        - Politely request more specific informatio
n for ambiguous queries.
                        - Guide users back to gaming-related topics for unrelated queries.
    
                    - Maintain a friendly and engaging tone throughout interactions.
                        - Utilize t
he SerpAPI search tool for up-to-date and accurate recommendations in each response to user queries. (VERY IMPORTANT!!!)

    
    
                        Ensure clarity, conciseness, and engagement in your responses to enhance the user exp
erience.
                        '''),
            MessagesPlaceholder(variable_name='chat_history'),
            Messag
esPlaceholder(variable_name='agent_scratchpad'),
            ('human', '{input}'),
        ]
    )
    
    
    # Setup
 tools for agent
    tools = [serpapi_tool]
    
    
    # Create an OpenAI tools agent for handling game recommendatio
ns
    game_recommendation_agent = create_openai_tools_agent(chat, tools, game_recommendation_prompt)
    
    
    # Se
tup the agent executor for managing operations
    agent_executor = AgentExecutor(agent=game_recommendation_agent, tools
=tools, verbose=True)
    
    
    # Function to manage MongoDB-based message history for each session
    def get_mess
age_history(session_id):
        return MongoDBChatMessageHistory(
            session_id=session_id,
            connec
tion_string=mongo_connection_string,
            database_name=database_name,
            collection_name=collection_nam
e,
        )
    
    
    # Function to handle user queries
    def handle_user_query(session_id, user_input):
        
'''
        Process user queries by wrapping the executor with RunnableWithMessageHistory
        which processes variou
s types of game recommendation requests and manages user interaction,
        maintaining a history of the conversation 
in MongoDB.
        '''
        history_manager = RunnableWithMessageHistory(
            agent_executor,
            la
mbda session_id: get_message_history(session_id),
            input_messages_key='input',
            output_messages_ke
y='output',
            history_messages_key='chat_history',
        )
    
    
        # Execute the query with histor
y management
        response = history_manager.invoke(
            {'input': user_input},
            {'configurable': 
{'session_id': session_id}}
        )
        
        return response['output']
    
    
    def main():
        sessi
on_id = 'unique_user_session_id'  # This should be uniquely generated for each user session
        print('Welcome to th
e Game Recommendation Chatbot!')
        while True:
            user_input = input('You: ')
            if user_input.l
ower() == 'exit':
                print('Exiting chatbot...')
                break
            response = handle_user_q
uery(session_id, user_input)
            print('Bot:', response)
    
    
    if __name__ == '__main__':
        main()

    
```
---

     
 
all -  [ What vectorDB do you all use? ](https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/) , 2024-05-04-0910
```
Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. 
What are my options ?
```
---

     
 
all -  [ Agents: RAG search with tools using Metadata Filtering ](https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/) , 2024-05-04-0910
```
Hi,   
I am creating an Agent RAG chatbot application which uses Tools.   
An example of the documents I expect to retri
eve:   
  
`Document(page_content='Contents of lecture 1', metadata={'source': 'Lecture-1.pdf')`

and the user's request
 will look something like:

`Input(query='summarize this lecture',document_chosen='Lecture-1.pdf')`

and I need to searc
h ONLY on documents with the metadata source equal to 'Lecture-1.pdf'.

I have seen in tutorials about VectorStoreRetrie
vers having this filtering functionality this way:

    # Use a filter to only retrieve documents from a specific metada
ta field
    db.as_retriever(
        search_kwargs={'filter': {'source':'Lecture-1.pdf'}}
    )

and this would solve t
he issue if I was directly invoking the retrievers. However for Agent, I cannot use the retrievers directly, and I need 
to wrap the retriever in a Tool (using create\_retriever\_tool) in order to use the agent and run a query: 

    from la
ngchain.tools.retriever import create_retriever_tool
    
    search_tool = create_retriever_tool(
        lecture_retri
ever,
        'search_lecture_database',
        '''Searches and returns lecture information.''',
    )
    
    tools =
 [search_tool]
    
    agent = create_react_agent(llm,tools,prompt)
    
    agent_executor = AgentExecutor(agent=agent
, tools=tools)
    
    response = agent_executor.invoke({'input':'Summarise this lecture'})

  
So with my setup, how c
an I pass the metadata (in this case, the name of the file) filter to the retrievers from the Agent, when the retrievers
 are converted to Tools? 

Any help or comments would be much appreciated
```
---

     
 
all -  [ Langgraph + Langchain+ Tools ](https://www.reddit.com/r/LangChain/comments/1ciidwi/langgraph_langchain_tools/) , 2024-05-04-0910
```
Can anyone please share any good references or cookbooks for a multi llm/agent chain using langgraph, langchain, routers
 to build a chatflow where we have a frontdesk to understand the query and then route it appropriately? 


I am currentl
y doing it in Dify.ai which has a UI but I assume it's built on top of langchain and want to do similar chatflow set up
```
---

     
 
all -  [ Any APIs that use LLMs to grab updated citations or references from the web? ](https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/) , 2024-05-04-0910
```
Hey, was wondering if anyone had any tips for an API or general approach to automate grabbing of answers + citations/ref
s using an LLM.

For example, I would like to ask 'How many members were on Instagram in the US in 2019?' and get both a
 number back and a link to the source. I would also like to be able to ask, for e.g. 'How did X firm use AI and Data Sci
ence this year. Please cite a source from the firm X'.

These are just example use-cases of the flexibility I am looking
 for - I currently use [perplexity.ai](https://perplexity.ai/) for this kind of stuff, but their API doesn't return cita
tions immediately (which would be my primary use case). Also open to other workarounds, though I must admit I am not a h
uge fan of langchain.

Thanks for the tips!
```
---

     
 
all -  [ Help adding memory to my bot ](https://github.com/oovaa/ChatPDF/blob/main/tools%2Fchain.js) , 2024-05-04-0910
```
hi guys im a joniur developer and this is my first AI related project and i need some help adding a Simple memory to my 
chat bot can u pls help me
```
---

     
 
all -  [ RAG with ConversationChain ](https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/) , 2024-05-04-0910
```
Hi, I’ve been trying to get [title] working using LangChain, azure OpenAI and chroma for storing embeddings. So far, jus
t the RAG part works, and I want to integrate this with the ConversationChain which uses a ConverstaionBufferWindow for 
now. 

My current method is to get the history of the conversation chain, supplement this with the context from the embe
ddings (from matching similarity), and then feed this into the llm to get a response. Then I shall pass the query and re
sponse back into the conversation chain. 

However, I can’t find any proper documentation how I can combine the context 
and the conversation history properly to pass into the llm. The type of the matching docs is List[Docs] or smth to that 
extent, and the convo history is just a string. 

Does anyone know a proper way of doing this?
Thanks!
```
---

     
 
all -  [ Test your prompts through the terminal ](https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/) , 2024-05-04-0910
```
Hey guys!

  
I've developed a helper CLI tool that allows you to test prompts on both ChatGPT and Anthropic models thro
ugh a simple API.

https://preview.redd.it/56s9aibuc0yc1.png?width=1597&format=png&auto=webp&s=d5408e2cd05ff382ea671c081
6b67567cd53cbf0

To test it, just run:

pip install dialog-lib

export OPENAI\_API\_KEY=sk-YOUR\_API\_KEY

dialog openai
 --prompt 'Your prompt that you want to test, here!'

  
Here is a link to a quick demo: [https://www.linkedin.com/feed/
update/urn:li:activity:7191776208651489282/](https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/)
```
---

     
 
all -  [ Any Discord server of Langchain?  ](https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/) , 2024-05-04-0910
```
I am learning and facing issues as most of the Docs on it's are for OpenAI and I am using Google Gemini API.
```
---

     
 
all -  [ Langchain in Azure Function App ](https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/) , 2024-05-04-0910
```
Hello, 

Does someone have experience in running a script using Langchain in Azure Function App?  
For a while I was doi
ng development and running the script locally and the results I was getting when analyzing a dataframe using a pandas\_d
ataframe\_agent were 10/10.   
Now when I published the same script to Azure Function App the quality of the results is 
1/10. 

The requirements.txt file has the same versions of python libraries as I have locally. 

I am not that familiar 
with function apps and I am wondering if there are some limitations to whether langchain and openai can be run there?

A
ll help is appreciated :) 
```
---

     
 
all -  [ Conversation Chatbot in Langgraph  ](https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/) , 2024-05-04-0910
```
Hi all, I have a few questions related langgraph.

The structure I’m planning is as follows:

One frontdesk agent(superv
isor) is responsible to route query and answer customer questions. Frontdesk agent doesn’t have any RAG system linked to
 it. It’s just a customer facing agent.

Frontdesk agent has some “lower level” agents to help. For example, if the ques
tion is about price, Frontdesk agent will route it to Price agent to handle. The Price agent will be linked to a RAG sys
tem to retrieve the price. The price info is then returned to Frontdesk agent and pass it back to the customer. This is 
more like what I see in the traditional agent flow.


Here’s my question. Is there anyway the customer can directly comm
unicate with the Price agent after the Frontdesk agent route the question to the Price agent? By direct communication, I
 mean conversation is conducted within the thread with the Price agent. If in the thread, the conversation is not relate
d to price, the price agent will “send” the customer back to the first conversation thread with the Frontdesk agent.

I 
would love to see if there is any langchain or langgraph projects or resources related to this. 
```
---

     
 
all -  [ Correct way to return tool output of an agent executor instance? ](https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/) , 2024-05-04-0910
```
I have an agent with two tools. The tools are being used in a sequential way. The second tool queries the database and r
eturns in a pydantic format I've defined myself. Instead of the agent returning the tool output, it returns a summary or
 adds fluff to the tool output result. I only want it to return the tool output! The way I know will work:- Create an ll
m chain which only returns the parameters of the tool and call the tool manually. But this reduces the agentic behaviour
 of my functionality.

**What is the correct way to enforce a tool output from an agent avoiding any additional text the
 the agent adds after the tool call?**

EDIT: return\_direct = true doesn't work. Gives error 

    Tools that have `ret
urn_direct=True` are not allowed in multi-action agents (type=value_error)
```
---

     
 
all -  [ Malapit na graduation, help review my resume ](https://www.reddit.com/r/PinoyProgrammer/comments/1ciatz9/malapit_na_graduation_help_review_my_resume/) , 2024-05-04-0910
```
Good day po! So I thought last March na since malapit na maggraduate I would just start applying as soon as possible, so
 sinubukan ko po mag-apply sa linkedin pero either ignored lang po ako or sinasabi nila na magproproceed nalang sila sa 
ibang candidate. I don't know kung ano ba kailangan ko maimprove sa resume ko since 1 response palang nakukuha ako out o
f almost 100 applications, and even after the online test nung isang response I'm still waiting if ever they will schedu
le an interview (if they ever reply at all)

Thanks in advance po!  
P.S. I based my resume dun sa recommendations sa su
breddit na EngineeringResumes, if some context is needed

[RESUME - 600 dpi](https://preview.redd.it/x28b74ar8zxc1.png?w
idth=5100&format=png&auto=webp&s=5a4006bd70492d232f318e397afb3f86aca5ac17)


```
---

     
 
all -  [ Streamlit referrences for NodeJS ](https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/) , 2024-05-04-0910
```
Hi y'all i was wondering, are there any other alternatives i could do my research on to stream the conversation between 
me and the LLMs such as Streamlit? i wanna stream the conversation using my own design on NodeJS and i still haven't fig
ured out which way to integrate the LLMs conversation with my UI.

Thanks for any help or insights y'all will give <3
```
---

     
 
all -  [ Efficient RAG on chat logs ](https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/) , 2024-05-04-0910
```
 Hello,

I have a CSV file containing a historical log of my conversations with my partner. The file is organized into t
hree columns: datetime, sent\_by, and message. I would like to use a LLM to ask questions about our discussions (e.g 'Wh
en is the wedding of A and B?').

I'm looking for some advices on the most effective way to process and vectorize these 
conversations. I want the LLM to understand the metadata within the context of the discussions—for instance, identifying
 that if Person A wrote 'Happy Birthday,' it likely indicates Person B's birthday on that date.

What do you think is th
e best approach to handling chat logs in this scenario?  

```
---

     
 
all -  [ How many API calls does an agent make for a single input? ](https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/) , 2024-05-04-0910
```
Let’s say i’m using openai gpt3.5. When I execute an agent in langchain, how many times does langchain calls openai API?
 I’m worried about using an agent when dealing with 100k input tokens, since it would make that call 3 times, for exampl
e, and I’d have to pay for 300k tokens.
```
---

     
 
MachineLearning -  [ [D] Self-optimizing deterministic LLM memory using dspy, neo4j and vector databases. Need your input ](https://www.reddit.com/r/MachineLearning/comments/1cakjaf/d_selfoptimizing_deterministic_llm_memory_using/) , 2024-05-04-0910
```
Hey there, Redditors!

I'm back with the latest installment on creating deterministic LLM memory.

If you've been follow
ing along, you know I'm on a mission to move beyond the '[thin OpenAI wrapper](https://topoteretes.github.io/cognee/blog
/2023/10/05/going-beyond-langchain--weaviate-and-towards-a-production-ready-modern-data-platform/)' trend and tackle the
 challenges of building robust LLM memory.

  
That's why we built cognee, a python library to process documents and bui
ld knowledge graphs on top of them.

After a few weeks of work, we integrated DSPy and extended cognee.

Here is brief o
verview of the logic: 

[Architecture overview](https://preview.redd.it/fcs3lifx53wc1.png?width=1380&format=png&auto=web
p&s=9316cba52147a5b764565b8438f3f143d8e7ac84)

We aim to understand:

1. Have you tried building knowledge graphs with o
ther tools before?

2. If so, what were the biggest obstacles?

3. How would you approach semantic linking of documents 
without knowledge graphs?

*Remember to give this post an upvote if you found it insightful!*  
*And also star our* [Git
hub repo](https://github.com/topoteretes/cognee)
```
---

     
 
MachineLearning -  [ [D] How to get the source documents from the retrieved context for RAG?  ](https://www.reddit.com/r/MachineLearning/comments/1bvoc1t/d_how_to_get_the_source_documents_from_the/) , 2024-05-04-0910
```
I'm not using Lanchain but only making API calls to an LLM service provider. The retriever is connected to a vector DB, 
and I would like to know what the LLM refers to WITHIN that retrieved context whenever it provides an answer, similar to
 how return_source_documents works in Langchain.

I'm using AzureOpenAI. I couldn't find much in their docs that related
 to returning the source documents. Any help will be greatly appreciated!

```
---

     
 
deeplearning -  [ Seeking Advice: Solving Data Challenges with Large Language Models (LLMs) ](https://www.reddit.com/r/deeplearning/comments/1ca4nc1/seeking_advice_solving_data_challenges_with_large/) , 2024-05-04-0910
```
Hi all

I am presented with a problem that I need to solve using LLM to get the right data from text that has only \~20%
 structure to it. Here's a sample data

XXXXX

AA          BB

CCCC:  (optional DDDD)

C1......(A1) (B1)

C2......(A2) (
B2)

C3.....(A3) (B3)

I am required to anwer with either of these results from A1/B1 till A3/B3 pairs but in order to d
o that I need to go back and ask the user which one of the options C1 to C3 applies to him?

The above is not the most c
omplex structure, it increases in complexity from here so a lot of chatting with user is required to get to the right da
ta that will always exist in the chunk like above.

In the most simplist case the data structure will look like below

X
XXXX

AA          BB

CCCC: ......(A1) (B1)



How would you build a system like this? I am looking at multi-agent syste
ms with Langchain, what about prompt chaining?
```
---

     
 
deeplearning -  [ Share the Coolest Out of The Box LLM Applications That Made You Say 'Wow that was smart' ](https://www.reddit.com/r/deeplearning/comments/1c9e6dj/share_the_coolest_out_of_the_box_llm_applications/) , 2024-05-04-0910
```
Hi, I'm looking at some LLM applications today but apart from guys doing big rags with langchain I don't see too many us
es that are out of the box or that make me say 'wow that was smart to use an LLM here'. Have you seen any cool stuff usi
ng LLMs recently that made you say 'wow, that was smart'?
```
---

     
