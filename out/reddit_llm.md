 
all -  [ Launched an Open Source Tool on Product Hunt. Want to share why I built it. ](https://www.reddit.com/r/webdev/comments/1haoavw/launched_an_open_source_tool_on_product_hunt_want/) , 2024-12-10-0914
```
Over the past year of building AI-enabled SaaS applications, I kept hitting the same wall. Going from a Jupyter notebook
 full of AI RAG techniques to something usable in my app was a nightmare. I'm sure if anyone here has taking a look at l
lama-index or langchain cookbook sections you might understand what I'm talking about.  
  
I came to the conclusion tha
t this is the problem:  
\- Notebooks are great for testing ideas, but theyâ€™re not meant for building applications aroun
d them.  
\- I had to manually dissect notebooks, build a proof-of-concept API server, integrate it into my app, and pra
y it worked.  
\- The feedback loop was \*painfully\* longâ€”and most of the time, I canned the project because it didnâ€™t 
quite fit.  
  
This frustration comes from a gap in roles:  
1. Data Scientists/AI Devs want notebooks to experiment wi
th methods and techniquesâ€”but it's not their main focus to also create an API for other applications to use.  
2. App De
velopers just want simple APIs to test and integrate quickly to see if it actually enhances their app.

This is where Ki
tchenAI comes in. A tool that bridges this gap by transforming your AI Jupyter notebooks into production-ready API serve
r in minutes.  
  
But why??  
\- Shorter Development Cycles  
Test, iterate, and deploy AI techniques faster and cut th
e feedback loop in half.  
\- Vendor and Framework Agnostic  
Use the libraries youâ€™re comfortable with, no lock-ins.  

\- Plugin Architecture  
Extend functionality with plugins for evaluation frameworks, observability, prompt management, 
and more.  
\- Open Source and Local-First  
Built on trusted technologies like Django, so you stay in controlâ€”no 3rd-pa
rty dependencies required.  
\- Docker-Ready  
Share your API server as a lightweight container for easy collaboration. 
 
  
Weâ€™ve released KitchenAI as an Apache-licensed open-source tool, so anyone can use it. Up next is a managed cloud v
ersion with deeper integrations, metrics, analytics, and workflows for teams with more complex needs. One short term goa
l is to go straight from colab to a KitchenAI cloud hosted API so development can be absolutely seamless.  
  
Give it a
 spin and a star: [https://github.com/epuerta9/kitc...](https://github.com/epuerta9/kitchenai)

The product hunt profile
 as well, a demo video is included: [https://www.producthunt.com/posts/kitchenai-2?utm\_source=other&utm\_medium=social]
(https://www.producthunt.com/posts/kitchenai-2?utm_source=other&utm_medium=social)
```
---

     
 
all -  [ Alternatives to run localLLM on private network  ](https://www.reddit.com/r/LocalLLaMA/comments/1han8mb/alternatives_to_run_localllm_on_private_network/) , 2024-12-10-0914
```
noobie question here:
I've been working with Langchain + localLLMs (using APIs) for a week now and I wondering If there'
s a way to deploy my agents on a private network (like the one from a company). Is there a way to do it with localLLM so
 other people on the network can acess?
```
---

     
 
all -  [ Visual Agents is Self-Aware Software: A Brief Intro ](https://youtu.be/iiDWPlrors4?si=Qnx7KDdU3KMq2JUS) , 2024-12-10-0914
```
Built on top of langchain in part.
```
---

     
 
all -  [ Building Recommendation System with RAG ](https://www.reddit.com/r/LangChain/comments/1hak0ml/building_recommendation_system_with_rag/) , 2024-12-10-0914
```
I like to build a recommendation system with RAG and wanted to hear others thoughts. I want to give recommendations base
d on multiple quizzes students take. For example, students would take 2-3 tests and based on those results, recommend qu
estions that they need to solve to improve their skills.

Here my data would be the following. For each test: testId, qu
estion number, choice selected(A,B,C,D), O/X (correct/incorrect) and category that the question belongs to.

My thinking
 is: I would feed these data into a vectorstore. Now when student has take 3 tests, I would feed this and based on those
 3 tests, I will do some kind of similiarity search and recommend questions that other students got wrong/correct and ge
t those test+question number out.

Would something like this be possible with RAG?
```
---

     
 
all -  [ GenAI and?? ](https://www.reddit.com/r/learnmachinelearning/comments/1haj5p5/genai_and/) , 2024-12-10-0914
```
Background: I have been working as a GenAI Engineer from mid of 2023 and basically this is what I have started my career
 with. I knew python and then as things came out I was doing development and learning the frameworks like Langchain, Lan
gGraph, Streamlit, Chainli, LlamaIndex, Haystack and what not.. I know a bit about Azure as we did deployments on azure.



After 1.5 year of experience in this domain, I think this is something that should not be your only skill. I want to 
learn something that will complement GenAI. I have exploring few options like DevOps, WebDevelopment ( the path is too l
ong, HTML, CSS, Javascript and goes the list goes on). What do you think I should learn/focus so that in some time Iâ€™ll 
standout from the crowd?



```
---

     
 
all -  [ [For Hire] Experienced AI/Full Stack & DevOps Developer â€“ Seeking Challenging, High-Impact Projects! ](https://www.reddit.com/r/forhire/comments/1hairsl/for_hire_experienced_aifull_stack_devops/) , 2024-12-10-0914
```
Your All-in-One Solution for AI/ML, Full Stack, & DevOps!

ğŸ‘‹ Hi, Iâ€™m Sheryar, a seasoned AI/ML Engineer, Full Stack Deve
loper, and DevOps Expert. Let's transform your ideas into powerful, scalable solutions!

ğŸ’» **Full Stack Expertise**  
ğŸ”¹ 
Beautiful UIs: React/Angular  
ğŸ”¹ Powerful APIs: Node.js, NestJS  
ğŸ”¹ Payment Integration: Stripe  
ğŸ”¹ Cloud Hosting: AWS, 
GCP

ğŸ¤– **AI & Machine Learning**  
ğŸ”¹ Intelligent Chatbots: Powered by LangChain  
ğŸ”¹ Tailored AI Models: NLP, Automation


âš™ï¸ **DevOps Excellence**  
ğŸ”¹ CI/CD Pipelines: GitHub Actions, Jenkins  
ğŸ”¹ Containerization: Docker, Kubernetes  
ğŸ”¹ Infr
astructure as Code: Terraform, Ansible  
ğŸ”¹ Monitoring: Prometheus, Grafana

ğŸŒŸ **Recent Projects**  
ğŸš— Ride-Sharing: Real
-time tracking & payments  
ğŸ“¦ Logistics: Optimized multi-stop delivery  
ğŸ”¹ E-Commerce: Scalable Kubernetes clusters

ğŸ’° *
*Rate**: $20â€“$25/hour (negotiable)  
ğŸ“§ DM me to discuss your project!  
GitHub: [storm1033](https://github.com/storm1033
)

Letâ€™s create something amazing together! ğŸŒâœ¨
```
---

     
 
all -  [ Humanized AI agent of service support. LANGCHAIN+RAG. ](https://www.reddit.com/r/LangChain/comments/1hahyqe/humanized_ai_agent_of_service_support_langchainrag/) , 2024-12-10-0914
```
Hello everyone, how are you?  
For some time now, I've been self-studying the development of an AI for customer support 
services.

One challenge I've been facingâ€”and it seems to be a common issueâ€”is the humanization of the AI. But let's put
 that aside for now.

My current idea is: is using LangChain + RAG a good approach to keep moving forward?

I'm organizi
ng all the company's information, such as departments, types of service, when the AI should transfer to another departme
nt, and its behaviors, into a markdown file. However, I feel that its performance isn't as good compared to another AI I
â€™ve implemented purely in Node.js, with all the context embedded directly in the prompt.

If you have any ideas on how I
 can proceed or what I should study, Iâ€™d appreciate it. Also, if thereâ€™s something I need to change in my mindset regard
ing the current LangChain + RAG project, feel free to share.

Edit: Forgot to share more info.  
I'm using LANGCHAIN+RAG
+Multiquery.

The user says something, which is then rephrased into 5 different variations. Based on these variations, s
imilarity is searched, and a response is returned accordingly.
```
---

     
 
all -  [ Problem with code tracking in Langsmith in Colab ](https://www.reddit.com/r/Langchaindev/comments/1hafzbo/problem_with_code_tracking_in_langsmith_in_colab/) , 2024-12-10-0914
```
Hey guys, 

I have a problem with tracking in Langsmith in the following code (using Colab): 

    from langchain_core.d
ocuments import Document
    from langchain.chains.combine_documents import create_stuff_documents_chain
    from langch
ain_community.document_loaders import WebBaseLoader
    from langchain.text_splitter import CharacterTextSplitter
    fr
om langchain.prompts import ChatPromptTemplate
    from langchain_community.vectorstores.faiss import FAISS
    from lan
gchain_openai import AzureOpenAIEmbeddings
    import logging
    from langchain.chains import create_retrieval_chain
  
  from langsmith import Client
    
    
    from langchain_core.messages import HumanMessage, AIMessage
    from langch
ain_core.prompts import MessagesPlaceholder
    
    
    
    def get_document_from_web(url):
    Â  logging.getLogger('
langchain_text_splitters.base').setLevel(logging.ERROR)
    Â  loader = WebBaseLoader(url)
    Â  docs = loader.load()
   
 Â  splitter = CharacterTextSplitter(
    Â  Â  Â  chunk_size=400,
    Â  Â  Â  chunk_overlap=20
    Â  Â  Â  )
    Â  splitDocs = 
splitter.split_documents(docs)
    Â  return splitDocs
    
    
    
    def create_db(docs):
    Â  Â  embeddings = Azure
OpenAIEmbeddings(
    Â  Â  Â  Â  model='text-embedding-3-large',
    Â  Â  Â  Â  azure_endpoint='https://langing.openai.azure.c
om/openai/deployments/Embed-test/embeddings?api-version=2023-05-15',
    Â  Â  Â  Â  openai_api_key='xxx',
    Â  Â  Â  Â  opena
i_api_version='2023-05-15'
    Â  Â  )
    Â  Â  vectorStore = FAISS.from_documents(docs, embeddings)
    Â  Â  return vectorS
tore
    
    def create_chain(vectorStore):
    Â  Â  prompt = ChatPromptTemplate.from_messages([
    Â  Â  Â  Â  ('system', 
'Answet the quistion based on the following context: {context}'),
    Â  Â  Â  Â  MessagesPlaceholder(variable_name='chat_hi
story'),
    Â  Â  Â  Â  ('human', '{input}')
    Â  Â  ])
    
    
    
    
    Â  Â  #chain = prompt | model
    Â  Â  chain =
 create_stuff_documents_chain(llm=model,
    Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â prompt=prompt)
    
    Â  Â  retriever 
= vectorStore.as_retriever(search_kwargs = {'k':3})
    Â  Â  retriever_chain = create_retrieval_chain(
    Â  Â  Â  Â  retrie
ver,
    Â  Â  Â  Â  chain
    Â  Â  )
    Â  Â  return retriever_chain
    
    def process_chat(chain, question,chat_history):

    Â  response = chain.invoke({
    Â  Â  'input': question,
    Â  Â  'chat_history': chat_history
    Â  Â  })
    Â  return
 response['answer']
    
    chat_history = []
    
    
    if __name__ == '__main__':
    Â  docs =get_document_from_we
b('https://docs.smith.langchain.com/evaluation/concepts')
    Â  vectoreStore = create_db(docs)
    Â  chain = create_chai
n(vectoreStore)
    Â  while True:
    Â  Â  user_input = input('You: ')
    Â  Â  if user_input.lower() == 'exit':
    Â  Â  Â 
 Â  break
    Â  Â  response = process_chat(chain, user_input, chat_history)
    Â  Â  chat_history.append(HumanMessage(conte
nt= user_input))
    Â  Â  chat_history.append(AIMessage(content = response))
    Â  Â  print('Bot:', response)
    
    
  
  

Everything is runing well but I do not see it in Langsmith, does anyone have any idea why?  

  
Thanks a looot for 
any tips 




```
---

     
 
all -  [ Job Opening ](https://www.reddit.com/r/submarines/comments/1hadjq8/job_opening/) , 2024-12-10-0914
```
As a former Navy Nuclear Electronics Technician (EWS/EDPO) who served aboard the USS TOLEDO, I founded VeteranAI with a 
clear mission: revolutionizing the VA disability claims process by fixing problems veterans have. VeteranAI is partnerin
g directly with veteran service organizations to streamline and improve the VA disability process. We're currently seeki
ng a Backend Developer to join our mission. Why Submariners? Having served alongside some of the most dedicated and skil
led professionals in the military, I know firsthand the unique problem-solving abilities and work ethic submariners brin
g to any challenge.

  
The ideal candidate will be responsible for developing and maintaining server-side logic and int
egrating user-facing elements crafted by front-end developers. You will play a crucial role in delivering high-quality s
oftware solutions that ensure the functionality and efficiency of our applications. This role requires a strong understa
nding of RESTful architecture, FastAPI, LangChain, and other AI tooling. Knowledge of the VA disability process is highl
y valued.

  
Job Type: Full-time

Location: Remote

Pay: $135,000.00 per year

Start Date: Mid January

Send resume or 
questions: [team@veteranai.co](mailto:team@veteranai.co)

Duties

1.  Design and Implement Backend Systems: Architect sc
alable and efficient backend solutions using appropriate technologies and best practices.
2.  Translate Problems to Code
: Analyze complex requirements and develop robust, maintainable code solutions to address them effectively.
3.  Collabor
ate Across Teams: Work closely with team members to drive project success and ensure seamless integration of components.


  
Experience

*  Proven experience as a Backend Engineer or similar role in application development.
*  Proficiency i
n Python, FastAPI, and RESTful architecture.
*  Experience with AI tooling such as LangChain and vector stores.
*  Knowl
edge of Docker, AWS, Redis, and PostgreSQL.
*  Familiarity with version control systems like Git.
*  Strong problem-solv
ing skills and the ability to work independently and as part of a team.
*  Knowledge of the VA disability process is hig
hly desirable.

  
Benefits:

* Dental insurance 
* Flexible schedule 
* Health insuranceÂ  
* Paid time off
* Vision ins
urance
* 401k

Compensation Package: 

*  RSU / Stock options 
* Salaried 
```
---

     
 
all -  [ Developing Memory Aware Chatbots with LangChain, LangGraph, Gemini and MongoDB. ](https://cckeh.hashnode.dev/building-chatbots-with-memory-capabilities-a-comprehensive-tutorial-with-langchain-langgraph-gemini-ai-and-mongodb) , 2024-12-10-0914
```
In this step by step guide you will learn:

1. How to create a chatbot using LangChain, Gemini.
2. Handle Chat History u
sing LangGraph and MongoDB.
```
---

     
 
all -  [ 2025 Master LangGraph and LangChain with Ollama- Agentic\ RAG ](https://freewebcart.com/2025-master-langgraph-and-langchain-with-ollama-agenticrag/) , 2024-12-10-0914
```

```
---

     
 
all -  [ What's the best way to replicate a langgraph flow to do the same calculation, but for multiple diffe ](https://www.reddit.com/r/LangChain/comments/1hab667/whats_the_best_way_to_replicate_a_langgraph_flow/) , 2024-12-10-0914
```
I have the following agent workflow to do a calculation:

`# Graph`

`from langgraph.graph import END, StateGraph, START
`

`from langgraph.prebuilt import ToolNode`



`# Define a new graph`

`workflow = StateGraph(AgentState)`



`# Define
 the nodes we will cycle between`

`workflow.add_node('agent', agent)  # agent`

`retrieve = ToolNode([retriever_tool])`


`workflow.add_node('retrieve', retrieve)  # retrieval`

`workflow.add_node('rewrite', rewrite)  # Re-writing the quest
ion`

`workflow.add_node(`

`'generate', generate`

`)  # Generating a response after we know the documents are relevant
`

`# Call agent node to decide to retrieve or not`

`workflow.add_edge(START, 'agent')`



`# Decide whether to retriev
e`

`workflow.add_conditional_edges(`

`'agent',`

`# Assess agent decision`

`tools_condition,`

`{`

`# Translate the 
condition outputs to nodes in our graph`

`'tools': 'retrieve',`

`END: END,`

`},`

`)`



`# Edges taken after the \`a
ction\` node is called.`

`workflow.add_conditional_edges(`

`'retrieve',`

`# Assess agent decision`

`grade_documents,
`

`)`

`workflow.add_edge('generate', END)`

`workflow.add_edge('rewrite', 'agent')`



`# Compile`

`graph = workflow.
compile()`

  
And here is the flow diagram:

https://preview.redd.it/h9mvbao82u5e1.png?width=662&format=png&auto=webp&s
=43e6c3bcae27e18267e1b931e7ee39c99310b03e

For example, the user question would be, 'What is the cost of books?', and th
e agent will do a search in the vector DB for the total cost of books and return a response.

I have the same type of ca
lculation to be done for 3 different things (say, calculate cost of books, cost of pens and cost of blackboards, and to 
find the total cost incurred we just sum these 3 up). I want to be able to repeat/replicate the retrieve-rewrite-generat
e part of the workflow for the 3 calculations, connect them to the main agent node, and then combine the 3 generate node
s into a 'totalCost' node to reach the \_end\_ node. How do I do that?  


The user question would be, 'What is the tota
l cost of this classroom', and I want the agent to break it down into 3 questions: 'What is the cost of books?', 'What i
s the cost of pens?' and 'What is the cost of blackboards?', and then do the vector DB querying for each of these questi
ons, get responses for each of these queries, sum them all up and give the final response.
```
---

     
 
all -  [ How to Efficiently Handle 1K+ SQL Records for a Text-to-SQL Use Case? ](https://www.reddit.com/r/LangChain/comments/1haae1o/how_to_efficiently_handle_1k_sql_records_for_a/) , 2024-12-10-0914
```
I am working on a text-to-SQL use case for a client, where I need to handle over 1K+ SQL records. The challenge arises a
s these records exceed the context window of the Llama-3.3 model provided by Groq. Additionally, I need to generate a gr
aphical representation of this data, and Iâ€™m considering using Plotly JSON for this purpose.

Is there an efficient way 
to handle this large dataset, send the data to the frontend, and generate the required graphical representation without 
overwhelming the context window or compromising performance? Suggestions or best practices would be highly appreciated!
```
---

     
 
all -  [ [For Hire] Frontend and Backend Developer with the top and latest development technologies for a gre ](https://www.reddit.com/r/forhire/comments/1ha9i3f/for_hire_frontend_and_backend_developer_with_the/) , 2024-12-10-0914
```
Hi Redditors,

I'm Emad a Full-stack Web developer/engineer with 8 years of experience, and I'm looking for new projects
 to start working on, please take a look at my portfolio here [https://www.sx-portfolio.com](https://www.sx-portfolio.co
m) (let me know if you need more examples or direct links to live websites in the PM)

**Here is my skill set:**

**For 
Frontend:**

* HTML / CSS
* JS / ESNext
* Webpack / Gulp / Grunt / Gatsby
* React (With Redux, Zustand, or MobX)
* Next.
js
* Vuejs (With VueX)
* Angular
* TypeScript

**For Backend:**

* Node.js
* Python
* Express.js
* MongoDB
* Mongoose
* 
Nest.js
* GraphQL
* Meteor (with Apollo and React)
* TypeScript

**For AI-based projects:**

* Python
* Langchain
* Fast
API
* Uvicorn
* Pydantic

**For Desktop Apps:**

* Electron

**For Mobile Apps (iOS and Android):**

* React Native
* Ex
po

**For Design:**

* Photoshop
* Illustrator

**Here is my Resume:**  [My resume link!](http://www.sx-portfolio.com/we
bsite-resources/My%20resume.pdf)

**And here are some testimonials from my clients :)**

* [Slips](https://www.reddit.co
m/r/testimonials/comments/agfmwf/pos_swordx10_is_a_brilliant_developer_and_a/)
* [VidSync](https://www.reddit.com/r/test
imonials/comments/5gvz3d/pos_uswordx10_excellent_frontend_dev/)
* [Las Cruces Directory](https://www.reddit.com/r/testim
onials/comments/5hyks4/uswordx10_is_awesome/)
* [SigurenZalog](https://www.reddit.com/r/testimonials/comments/5jsfqf/pos
_quality_web_design_from_uswordx10/)
* [Bitlounge](https://www.reddit.com/r/testimonials/comments/5lh2pz/pos_uswordx10_t
op_fontend_devdesigner/)
* [Foxul](https://www.reddit.com/r/testimonials/comments/5l3p8j/pos_quality_web_coding_from_usw
ordx10/)
* [LootTicket](https://www.reddit.com/r/testimonials/comments/5nfh1j/pos_uswordx10_is_an_amazing_front_end_dev/
)

**My Pricing:**

I work hourly for $35/hr and my fixed prices depend on your project's complexity.

Don't worry about
 the price, just PM me with your project and I'm sure we can figure out something that goes with your budget. :)

If you
 have any questions don't hesitate to PM me and I will be more than happy to answer you :) and here is my portfolio agai
n if you need my contact details [www.sx-portfolio.com](https://www.sx-portfolio.com) (Click the red handle in the top-r
ight or pm me for it)
```
---

     
 
all -  [ What are the best techniques and tools to have the model 'self-correct?' ](https://www.reddit.com/r/Rag/comments/1ha9643/what_are_the_best_techniques_and_tools_to_have/) , 2024-12-10-0914
```
# CONTEXT
I'm a noob building an app that analyses financial transactions to find out what was the max/min/avg balance e
very month/year. Because my users have accounts in multiple countries/languages that aren't covered by Plaid, I can't re
ly on Plaid -- I have to analyze account statement PDFs.

Extracting financial transactions like ||||||| 2021-04-28 | 45
2.10 | credit ||||||| _almost_ works. The model will hallucinate most times and create some transactions that don't exis
t. It's always just one or two transactions where it fails.

I've now read about Prompt Chaining, and thought it might b
e a good idea to have the model check its own output. Perhaps say 'given this list of transactions, can you check they'r
e all present in this account statement' or even way more granular do it for every single transaction for getting it 100
% right 'is this one transaction present in this page of the account statement', _transaction by transaction_, and have 
it correct itself.

# QUESTIONS:
1) is using the model to self-correct a good idea?

2) how could this be achieved? 

3)
 should I use the regular api for chaining outputs, or langchain or something? I still don't understand the benefits of 
these tools

# More context:
- I started trying this by using Docling to OCR the PDF, then feeding the markdown to the L
LM (both in its entirety and in hierarchical chunks). It wasn't accurate, it wouldn't extract transactions alright
- I t
hen moved on to Llama vision, which seems to be yielding much better results in terms of extracting transactions. but st
ill makes some mistakes
- My next step before doing what I've described above is to improve my prompt and play around wi
th temperature and top_p, etc, which I have not played with so far!
```
---

     
 
all -  [ Event-Driven Patterns for AI Agents ](https://www.reddit.com/r/LangChain/comments/1ha8mrc/eventdriven_patterns_for_ai_agents/) , 2024-12-10-0914
```
I've been diving deep into multi-agent systems lately, and one pattern keeps emerging: high latency from sequential tool
 execution is a major bottleneck. I wanted to share some thoughts on this and hear from others working on similar proble
ms. This is somewhat of a langgraph question, but also a more general architecture of agent interaction question.

# The
 Context Problem

For context, I'm building [potpie.ai](https://potpie.ai/), where we create knowledge graphs from codeb
ases and provide tools for agents to interact with them. I'm currently integrating langgraph along with crewai in our ag
ents. One common scenario we face an agent needs to gather context using multiple tools - For example, in order to get t
he complete context required to answer a userâ€™s query about the codebase, an agent could call:

* A keyword index query 
tool
* A knowledge graph vector similarity search tool
* A code embedding similarity search tool.

Each tool requires th
e same inputs but gets called sequentially, adding significant latency.

# Current Solutions and Their Limits

Yes, you 
can parallelize this with something like LangGraph. But this feels rigid. Adding a new tool means manually updating the 
DAG. Plus it then gets tied to the exact defined flow and cannot be dynamically invoked. I was thinking there has to be 
a more flexible way. Let me know if my understanding is wrong. 

# Thinking Event-Driven

I've been pondering the idea o
f event-driven tool calling, by having tool consumer groups that all subscribe to the same topic.

    # Publisher patte
rn for tool groups
    @tool
    def gather_context(project_id, query):
        context_request = {
            'project
_id': project_id,
            'query': query
        }
        publish('context_gathering', context_request)
        
  
  
    @subscribe('context_gathering')
    async def keyword_search(message):
        return await process_keywords(mess
age)
    
    @subscribe('context_gathering')
    async def docstring_search(message):
        return await process_docs
trings(message)

This could extend beyond just tools - bidirectional communication between agents in a crew, each reacti
ng to events from others. A context gatherer could immediately signal a reranking agent when new context arrives, while 
a verification agent monitors the whole flow.

There are many possible benefits of this approach:

# Scalability

* Hori
zontal scaling - just add more tool executors
* Load balancing happens automatically across tool instances
* Resource ut
ilization improves through async processing

# Flexibility

* Plug and play - New tools can subscribe to existing topics
 without code changes
* Tools can be versioned and run in parallel
* Easy to add monitoring, retries, and error handling
 utilising the queues

# Reliability

* Built-in message persistence and replay
* Better error recovery through dedicate
d error channels

# Implementation Considerations

From the LLM, itâ€™s still basically a function name that is being retu
rned in the response, but now with the added considerations of :

* How do we standardize tool request/response formats?
 Should we? 
* Should we think about priority queuing? 
* How do we handle tool timeouts and retries
* Need to think abo
ut message ordering and consistency across queue
* Are agents going to be polling for response?

I'm curious if others h
ave tackled this:

* Does tooling like this already exist?
* I know Autogen's new architecture is around event-driven ag
ent communication, but what about tool calling specifically?
* How do you handle tool dependencies in complex workflows?

* What patterns have you found for sharing context between tools?

The more I think about it, the more an event-driven 
framework makes sense for complex agent systems. The potential for better scalability and flexibility seems worth the ad
ded complexity of message passing and event handling. But I'd love to hear thoughts from others building in this space. 
Am I missing existing solutions? Are there better patterns?

Let me know what you think - especially interested in heari
ng from folks who've dealt with similar challenges in production systems.
```
---

     
 
all -  [ Reranking using FlashrankReranker ](https://www.reddit.com/r/LangChain/comments/1ha8j1a/reranking_using_flashrankreranker/) , 2024-12-10-0914
```
Hey, I have a problem with using this Flash reranker. I have used this reranker (the exact same code like here [https://
python.langchain.com/docs/integrations/retrievers/flashrank-reranker/](https://python.langchain.com/docs/integrations/re
trievers/flashrank-reranker/) ) for the past month and it worked properly, today all of a sudden it doesnt anymore! I ge
t this error message saying that in the temp dir there is no model like the one i wish using (from the FlashranReranker)
. I did not change anything in my files. This is the error: \[ONNXRuntimeError\] : 3 : NO\_SUCHFILE : Load model from /t
mp/ms-marco-MultiBERT-L-12/flashrank-MultiBERT-L12\_Q.onnx failed:Load model /tmp/ms-marco-MultiBERT-L-12/flashrank-Mult
iBERT-L12\_Q.onnx failed. File doesn't exist  
Do you have any idea why this happens and how to solve it?
```
---

     
 
all -  [ Conceptual misunderstanding in LangChain ](https://www.reddit.com/r/LangChain/comments/1ha7pu2/conceptual_misunderstanding_in_langchain/) , 2024-12-10-0914
```
Hi everyone,

Over the past couple of months, I've started using LangChain, but I feel like I'm missing two important co
nceptual foundations that are core to this framework. I've watched tons of tutorials, but I still can't quite grasp what
's happening under the hood.

# The Chains

In my mind, I understand that the output of the first element becomes the in
put for the second element, similar to how pipes work in Linux. The logic makes sense, and when I see examples, they are
 clear. However, I still can't come up with my own chains.

For example:  
`chain = llm | some_prompt_template`

I see t
hat the model specified in the `llm` variable will be used with the prompt defined in the second step. But what exactly 
does an LLM output? What does it look like?

# The invoke() Method

I've created a chain that is a `Runnable`, so I unde
rstand I need to invoke, call it . I interpret this as making the actual call to the LLM, with the chain being built bef
orehand. Is this understanding correct? I'm curious about what happens under the hood during invocation.

I hope I'm not
 the only one struggling to understand these concepts. If you're extensively using LangChain and these questions seem to
o obvious, please try to put yourself in the shoes of a newbie. :)

Thank you!
```
---

     
 
all -  [ 'The ask' slide of my pitch ](https://www.reddit.com/r/SaaS/comments/1ha71xv/the_ask_slide_of_my_pitch/) , 2024-12-10-0914
```
Hi everyone,

Iâ€™m a sales engineer working for a branch of an international company specializing in industrial equipment
. I graduated in Mechanical Engineering five years ago.

About six months ago, I came up with a business idea: an AI-pow
ered technical chatbot designed to provide engineers and technicians with real-time, supplier-specific answers and solut
ions for industrial equipment.

Since then, Iâ€™ve conducted market research and developed an MVP using OpenAI APIs and La
ngchain. The data powering the model is publicly available, but Iâ€™ve leveraged my industry knowledge to structure the da
ta and design the modelâ€™s architecture. While I wonâ€™t delve into technical details here, the key point is that the chatb
ot is functional and ready for demonstrations.

Iâ€™m now at the stage where I want to pitch this idea to my current compa
ny, which I believe could be a strategic partner but also a customer as this would help the internal sales teams to incr
ease their efficiency in the chaos of a multitasking environment. They have a well-established network of sales channels
 across the EU, which would be invaluable for scaling the product. My managing director can arrange a meeting with the c
ompany CEO, giving me an opportunity to present my idea to influential decision-makers.

Hereâ€™s where Iâ€™m seeking advice
:  
Iâ€™d like to maintain my current employee benefits while negotiating shared equity in this new venture. I bring indus
try expertise, mechanical and sales engineering experience, and coding skills (itâ€™s important to emphasize that I person
ally developed the MVP).

What would you recommend I ask for in this situation, and how should I approach this discussio
n to maximize the chances of a successful partnership?

Cheers
```
---

     
 
all -  [ [1 YoE, Unemployed, Software Developer, USA] ](https://www.reddit.com/r/resumes/comments/1ha6soj/1_yoe_unemployed_software_developer_usa/) , 2024-12-10-0914
```
Hi all,

I am an international student in the USA and looking for full time job opportunities primarily in the software 
development field. I have been getting continuous rejects and I get a rejection mail in the screening around itself (ver
y few OAs and zero interviews). Is there anything in my resume that is causing this or any other possible approach I sho
uld use to increase my chances

https://preview.redd.it/dtadbws6vs5e1.png?width=1076&format=png&auto=webp&s=b0dd6e1be4b0
92728f493adcad31af2a1f95e196


```
---

     
 
all -  [ How to Convert Free-Form Language (English) to Valid JavaScript Functions ](https://www.reddit.com/r/LangChain/comments/1ha3f5v/how_to_convert_freeform_language_english_to_valid/) , 2024-12-10-0914
```
Hello everyone,

Iâ€™m trying to learn how to approach the task of converting free-form English descriptions into valid Ja
vaScript functions. For example, I have a design document written in informal English that contains instructions like:


1. You receive two parameters. Add them together, divide the result by 2, and check if there is a remainder. If there is
 a remainder, print it; otherwise, print 'No remainder.'
2. You receive a structure containing keys. Search for the key 
named `'foo'` and print its value. If the key is not found, print `'Key not found.'`

And so on.

From such descriptions
, I need to create simple JavaScript functions. My goal is to figure out how to approach this problem using LangChain. I
â€™m using Azure AI and have a beginner-level understanding of LangChain.

Can anyone guide me on how to get started with 
this? Any advice or examples would be appreciated.

Thanks!
```
---

     
 
all -  [ LangChain RAG2 tutorial not working! ](https://www.reddit.com/r/LangChain/comments/1h9zm7w/langchain_rag2_tutorial_not_working/) , 2024-12-10-0914
```
I was working around with and learning while following the RAG tutorials on LangChain website and in the RAG-2 tutorial 
( [https://python.langchain.com/docs/tutorials/qa\_chat\_history/#chains](https://python.langchain.com/docs/tutorials/qa
_chat_history/#chains) ) it is not performing tool calling ('retrieval') in my machine. I am using NVIDIA llama-70b-inst
ruct and chromadb. 

Please someone help me and tell me what am I doing wrong. The model is not doing any retrieval from
 saved docs and is straight up responding how a LLM would.
```
---

     
 
all -  [ Any idea how to create a search engine like MyMind? ](https://www.reddit.com/r/LangChain/comments/1h9vo1s/any_idea_how_to_create_a_search_engine_like_mymind/) , 2024-12-10-0914
```
[https://mymind.com/](https://mymind.com/) I tried hybrid search approaches but they don't work well with one or two wor
d searches... 
```
---

     
 
all -  [ How do you guys setup the folder structure  ](https://www.reddit.com/r/LangChain/comments/1h9mwqi/how_do_you_guys_setup_the_folder_structure/) , 2024-12-10-0914
```
Hey, guys, I am new to using Langchain. I understand the stuff, but I couldn't create a proper folder structure to break
 down my code. Currently, my code is in single files with hundreds of lines of code. Please help me integrate it with yo
ur backend. It would be good if anyone with Javascript show me their repo screenshot or share some example reports. Than
k you in advance.

https://preview.redd.it/tpfh0jpiln5e1.png?width=512&format=png&auto=webp&s=d43b8b68fba6e113af0ec37435
9e5b74dd9a841f


```
---

     
 
all -  [ [For Hire] Experienced Web Application Developer ](https://www.reddit.com/r/forhire/comments/1h9mpja/for_hire_experienced_web_application_developer/) , 2024-12-10-0914
```
Hi, I'm a Python/Javascript developer who can help you build or maintain an existing app.

I have experience in the foll
owing technologies:

- Python
- Django
- FastAPI
- Flask
- Javascript
- TypeScript
- ReactJS
- AlpineJS
- HTMX
- SQL
- A
nsible
- Docker
- Linux
- LlamaIndex
- Langchain

You can find my open source contributions on [my Github profile](https
://github.com/confuzeus. I also publish tech related articles on [my website](https://joshkaramuth.com).

## Availabilit
y

I'm currently located in [Mauritius](https://en.wikipedia.org/wiki/Mauritius), which is GMT+4 timezone-wise. I do asy
nchronous work in my own timezone but willing to join you in meetings in your own timezone. I'm comfortable in most US a
nd European timezones.

I'm interested in long-term engagements.

**My hourly rate is $50 (USD).**

Send me a message wi
th details about yourself and your project and let's schedule a call if there's a potential fit.
```
---

     
 
all -  [ Best Way to Learn LangChain and LangGraph from Scratch? ](https://www.reddit.com/r/LangChain/comments/1h9lnmt/best_way_to_learn_langchain_and_langgraph_from/) , 2024-12-10-0914
```
Hey Reddit! ğŸ‘‹

Iâ€™m looking for advice on the best way to learn LangChain and LangGraph from the beginning. I have some e
xperience with GenAI and Transformers and played around with Haystack last year, but now I want to start fresh and build
 a solid foundation in LangChain and LangGraph.

Hereâ€™s a bit about my background:

* Familiar with GenAI concepts and T
ransformer models.
* Used Haystack briefly for question-answering and document processing.
* Comfortable with Python and
 libraries like Hugging Face, but I wouldnâ€™t call myself an expert.

My goals are:

1. To understand the core concepts a
nd architecture of LangChain and LangGraph.
2. To learn how to build end-to-end AI applications with these tools (e.g., 
chatbots, retrieval-augmented generation, etc.).
3. To get hands-on experience through tutorials, projects, or practice 
exercises.

If youâ€™ve been on this learning path, Iâ€™d love to know:

* **What resources should I start with?** (docs, tu
torials, videos, courses, etc.)
* Are there any beginner-friendly project ideas to practice what I learn?
* Tips for com
bining LangChain with other tools like Vector DBs, OpenAI APIs, or custom data sources?

Thanks in advance for sharing y
our knowledge and recommendations! ğŸ™
```
---

     
 
all -  [ How to sequentially call tools in LangGraph ](https://www.reddit.com/r/LangChain/comments/1h9kano/how_to_sequentially_call_tools_in_langgraph/) , 2024-12-10-0914
```
Currently working on a PoC with multiple agents calling a database and one of these agents is a Text2SQL which can call 
3 tools:

* Tool1: find relevant tables pertaining to a users query (requires user's input)
* Tool2: calculate the cost 
of a generated sql query by the agent (requires sql query as input and outputs a number)
* Tool3: execute the sql query 
(requires cost and sql query as input)

  
I explicitly added in the descriptions of tools 2 and 3 that if Tool3 is call
ed then it needs the output of Tool2 in order to be called but it never ends up calling Tool2 despite calling Tool3. Not
 sure how I can go about sequentially programming tools or prompt engineering it to do so 
```
---

     
 
all -  [ A LangGraph AI agent designed to test and verify LangGraph AI agents ](https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true) , 2024-12-10-0914
```
ğŸ‰ Super excited to share The Systems Inspector, the 3rd place winner from the hackathon I ran with LangChain! ğŸš€

This br
illiant implementation uses AI to test AI, tackling issues like edge cases, security vulnerabilities, and user experienc
e gaps before they become real problems.

ğŸ› ï¸ Hereâ€™s What It Does:
- Maps and analyzes AI system architectures
- Creates 
specialized AI testers to handle unique challenges
- Provides actionable insights and recommendations

ğŸ“– Full Details:
t
he blog post attached contains: 
- The full description and motivation behind this agent
- A link to the complete code i
mplementation
- A YouTube video walking through how it works
```
---

     
 
all -  [ Looking for a Developer (m/f/d) for AI-Powered Training Planning in Football ](https://www.reddit.com/r/LangChain/comments/1h9gmel/looking_for_a_developer_mfd_for_aipowered/) , 2024-12-10-0914
```
Hi,  
We are a small start-up currently in the market research phase, exploring which products can deliver the most valu
e to the football market. Our focus is on innovative solutions using artificial intelligence â€“ particularly for smarter 
training planning to optimize player development and coaching efficiency.

Iâ€™m currently working on a prototype that lev
erages AI and Python to assist coaches in creating individualized, data-driven training plans. The goal is to make train
ing sessions more efficient and tailored to the needs of players, helping clubs of all sizes achieve their full potentia
l. Iâ€™m looking for someone with experience in AI development, training optimization, or related areas to exchange ideas 
on technical approaches and potential challenges:

* **How can AI-driven training plans be implemented most effectively?
**
* **What kind of data and models would deliver the greatest value to coaches?**
* **What logical steps can we take to
 develop this concept further?**

If this evolves into a collaboration, that would be amazing â€“ but for now, the focus i
s on consultation and idea sharing.

**About me:**  
I have 7 years of experience working in football clubs in Germany, 
including roles as a youth coach and video analyst, and Iâ€™m well-connected in Brazil. I split my time between Germany an
d Brazil. With a background in Sports Management and experience as a freelancer specializing in generative AI (GenAI) fo
r HR and recruiting, Iâ€™m passionate about applying AI to solve real challenges in football and player development.

**La
nguages:**  
Communication can be in English, German, or Portuguese.

**If youâ€™re passionate about football, AI, and sha
ping the future of training, letâ€™s connect!** Iâ€™d love to hear your ideas and see how we can work together to bring smar
ter training solutions to the game.
```
---

     
 
all -  [ Beginners Real world projects? ](https://www.reddit.com/r/learnmachinelearning/comments/1h9f71k/beginners_real_world_projects/) , 2024-12-10-0914
```
I love learning by doing and want to really get into ML. I know already some theory and have worked with PyTorch, Huggin
g face, Scikit learn, langchain, plotly, pandas and Numpy. Now I really want to create an actual useful project which is
 not just some cookie cutter tutorial project. I already followed some cookie cutter tutorial projects with using YOLO f
or object detection and also one with BERT from huggingface, however these projects were basically like â€œtake this ready
 made model and train it with data and youâ€™re doneâ€ which was really boring.   
  
Iâ€™d like some projects where I have t
o go deep into AI and not just using Someoneâ€™s premade model with my own data. What recommendations do you have?
```
---

     
 
all -  [ What are my options for using a local LLM on a 5-year-old i5 laptop with 32GB RAM? ](https://www.reddit.com/r/LocalLLM/comments/1h9eeyv/what_are_my_options_for_using_a_local_llm_on_a/) , 2024-12-10-0914
```
Hello everyone,

Iâ€™m new to working with local LLMs. So far, Iâ€™ve been using Azureâ€™s powerful LLMs alongside LangChain f
or interactions. However, Iâ€™d like to explore, learn, and use local LLMs with LangChain on my own setup.

The challenge 
is that Iâ€™m running an i5 processor on a 5-year-old laptop with 32GB of RAM. My primary goal is to use the LLM for tasks
 such as answering questions from PDFs and websites. Additionally, Iâ€™d like to explore generating simple property code i
n plain English.

What local LLM options are suitable for my hardware, and how can I get started?  
Thanks 
```
---

     
 
all -  [ Is there a more modern approach to this issue? ](https://www.reddit.com/r/LangChain/comments/1h9e9g8/is_there_a_more_modern_approach_to_this_issue/) , 2024-12-10-0914
```
I've been desperately trying to find a solution to my issue:

For context: I want to create a vectorstore DB for a chatb
ot web app I'm making and am unable to do so due to supposed 'outdated' API's. 

  
I have a script here which automatic
ally repalces the current PDF file (for the AI to read through) and then create a vectorStore db based on it:



    con
st { OpenAIEmbeddings } = require('@langchain/openai');
    const { HNSWLib } = require('@langchain/community/vectorstor
es/hnswlib');
    const {VectorDBQAChain} = require('langchain/chains')
    const fs = require('fs')
    const path = re
quire('path');
    
    let currentPdf = null;
    const PDF_PATH = 'temp/vectorDb.pdf';
    
    const Pdf = require('.
/schemas/baseSchemas/PDF_File');
    const { RecursiveCharacterTextSplitter } = require('langchain/text_splitter');
    

    async function stageFile(id, chain) {
    Â  Â  const file = await Pdf.findOne({ _id: id._id });
    
    Â  Â  if (!fi
le) {
    Â  Â  Â  Â  console.log('File not found');
    Â  Â  Â  Â  return;
    Â  Â  }
    
    Â  Â  if (currentPdf && currentPdf
._id.equals(file._id)) {
    Â  Â  Â  Â  console.log('File is the same as currentPdf, no action needed.');
    Â  Â  } else {

    Â  Â  Â  Â  currentPdf = file;
    Â  Â  Â  Â  const pdfPath = path.join(__dirname, 'temp', 'vectorDb.pdf');
    Â  Â  Â  Â  fs.
writeFileSync(pdfPath, file.pdfFile.data);
    Â  Â  Â  Â  console.log('Configured temp/vectorDb.pdf to the new file.');
   
 Â  Â  }
    Â  Â  const text = fs.readFileSync(PDF_PATH, 'utf8')
    Â  Â  const textSplitter = new RecursiveCharacterTextSpl
itter({chunkSize : 1000})
    Â  Â  const docs = await textSplitter.createDocuments([text])
    Â  Â  const vectorStore = aw
ait HNSWLib.fromDocuments(docs, new OpenAIEmbeddings());
    Â  Â  const newChain = VectorDBQAChain.fromLLM(chain.model, v
ectorStore)
    Â  Â  return newChain
    }
    
    
    
    module.exports = { stageFile };
    

  
Does anyone have a
ny ideas how to implement a more modern version of this?

  
Thank you.


```
---

     
 
all -  [ Looking for Advanced LangChain Tutorials on YouTube ](https://www.reddit.com/r/LangChain/comments/1h9digf/looking_for_advanced_langchain_tutorials_on/) , 2024-12-10-0914
```
Hello everyone,  
Iâ€™ve completed some basic tutorials on LangChain with Python, and Iâ€™m eager to explore more advanced t
opics. My end goal is to create a system that can take free-form language input and convert it into a structured script 
for a specific purpose, which will be my first project.

However, I feel that I need to deepen my understanding of LangC
hain before tackling this. I would be extremely grateful if you could recommend any updated advanced tutorials or resour
ces to help me improve.

Thank you so much!
```
---

     
 
all -  [ Llama 3.1 output not truncating ](https://www.reddit.com/r/learnmachinelearning/comments/1h9cxjx/llama_31_output_not_truncating/) , 2024-12-10-0914
```
Hi.  
I am trying to launch a chatbot using llama 3.1 and langchain. Huggingfacepipeline is from langchain\_huggingface 
library. I am generating the text using llm.invoke(prompt) method. When I run the code, it givesÂ **Setting \`pad\_token\
_id\` to \`eos\_token\_id\`:None for open-end generation.**Â and the output is not stopping even when I set max\_new\_tok
ens to a high number. Can anyone explain to me why the output is not stopping

    model_path = 'hf_llama/llama_8B'
    

    def load_model(model_path):
    Â  Â  tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    Â  Â  model = Auto
ModelForCausalLM.from_pretrained(
    Â  Â  Â  Â  model_path,
    Â  Â  Â  Â  device_map='auto',
    Â  Â  Â  Â  torch_dtype=torch.f
loat16,
    Â  Â  )
    
    Â  Â  pipe = pipeline(
    Â  Â  Â  Â  'text-generation',
    Â  Â  Â  Â  model=model,
    Â  Â  Â  Â  toke
nizer=tokenizer,
    Â  Â  Â  Â  torch_dtype=torch.float16,
    Â  Â  Â  Â  device_map='auto',
    Â  Â  Â  Â  do_sample=True,
    Â 
 Â  Â  Â  top_k=50,
    Â  Â  Â  Â  top_p=0.9,
    Â  Â  Â  Â  num_return_sequences=1,
    Â  Â  Â  Â  eos_token_id=tokenizer.eos_token
_id,
    Â  Â  Â  Â  # max_length=400,
    Â  Â  Â  Â  temperature=0.9,
    Â  Â  Â  Â  max_new_tokens=500
    Â  Â  )
    
    Â  Â  ll
m = HuggingFacePipeline(pipeline=pipe)
    Â  Â  return llm
```
---

     
 
all -  [ [New Grad][Software Engineer, Backend] Looking for feedback for my resume ](https://www.reddit.com/r/CSCareerHacking/comments/1h9a39s/new_gradsoftware_engineer_backend_looking_for/) , 2024-12-10-0914
```
https://preview.redd.it/dzkvvb308k5e1.png?width=682&format=png&auto=webp&s=36d3addc1b45631449b55bee3ca9fb282ea0ae13

I w
ould appreciate any and all feedback!
```
---

     
 
all -  [ Enquiry on RAG model Response Improvement ](https://www.reddit.com/r/LangChain/comments/1h99ik8/enquiry_on_rag_model_response_improvement/) , 2024-12-10-0914
```
One of the advantages of applying RAG on LLM is to be able to reference the source and page of the output. This is what 
I was trying to test with my output. I was trying to make my RAGLLM to output the response and print out the referenced 
document as well as page by modifying the prompt template. I know I see the retrieval details on langsmith but when I tr
y to include the details like source: <docname.pdf> and page number: <pg 113> in the RAGLLM output, it does not work and
 it hallucinates, giving me other sources and non-relevant page numbers. Is there a better way for me to do this? How do
 big enterprises using RAG usually do it? Is there a way for me to extract this info from langsmith into the output itse
lf? is there a more effective prompt template?
```
---

     
 
all -  [ Langgraph's weird behavior in Python!? Cannot rename nodes ](https://www.reddit.com/r/LangChain/comments/1h99h7z/langgraphs_weird_behavior_in_python_cannot_rename/) , 2024-12-10-0914
```
I'm working through the[ Intro to Langgraph ](https://academy.langchain.com/courses/take/intro-to-langgraph)tutorial on 
their website but some of it just doesn't make sense.

Here's a simple example. A example router that runs a set of tool
s or  responds to the user. The example works perfectly fine. BUT one small change and everything breaks. It's a simple 
change. Nothing crazy.

        from langchain_openai import ChatOpenAI
        from langgraph.graph import MessagesStat
e
        from langgraph.graph import StateGraph, START, END
        from langgraph.prebuilt import ToolNode, tools_cond
ition
        
        # Tool
        def multiply(a: int, b: int) -> int:
            '''Multiplies a and b.
        
 
           Args:
                a: first int
                b: second int
            '''
            return a * b
   
     
        def add(a: int, b: int) -> int:
            '''Adds a and b.
        
            Args:
                a:
 first int
                b: second int
            '''
            return a + b
        
        # LLM with bound tool

        llm = ChatOpenAI(model='gpt-4o')
        llm_with_tools = llm.bind_tools([multiply, add])
        
        # No
de
        def tool_calling_llm(state: MessagesState):
            return {'messages': [llm_with_tools.invoke(state['mes
sages'])]}
        
        # Build graph
        builder = StateGraph(MessagesState)
        builder.add_node('tool_cal
ling_llm', tool_calling_llm)
        builder.add_node('tools', ToolNode([multiply, add]))
        builder.add_edge(START
, 'tool_calling_llm')
        builder.add_conditional_edges(
            'tool_calling_llm',
            # If the latest
 message (result) from assistant is a tool call -> tools_condition routes to tools
            # If the latest message (
result) from assistant is a not a tool call -> tools_condition routes to END
            tools_condition,
        )
    
    builder.add_edge('tools', END)
        
        # Compile graph
        graph = builder.compile()

The above code ru
ns fine.

Now, I like to change the name of an edge... should be simple right? **I want to rename 'tools' to 'calc'.**


This code results in a weird error:

     # Build graph
        builder = StateGraph(MessagesState)
        builder.add_
node('tool_calling_llm', tool_calling_llm)
        builder.add_node('calc', ToolNode([multiply, add])) # Changed name he
re!
        builder.add_edge(START, 'tool_calling_llm')
        builder.add_conditional_edges(
            'tool_calling
_llm',
            # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools
   
         # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END
         
   tools_condition,
        )
        builder.add_edge('calc', END) # Changed name here!
        
        # Compile grap
h
        graph = builder.compile()

# The error on Studio and in the python notebook

    KeyError: 'branch:tool_callin
g_llm:tools_condition:tools'
```
---

     
 
all -  [ Fed up with LangGraph docs, I let Langgraph agents document it's entire codebase - It's 10x better! ](https://www.reddit.com/r/LangChain/comments/1h985k2/fed_up_with_langgraph_docs_i_let_langgraph_agents/) , 2024-12-10-0914
```
Like many of you, I got frustrated trying to decipher LangGraph's documentation. So I decided to fight fire with fire - 
I used LangGraph itself to build an AI documentation system that actually makes sense.  


What it Does:

* Auto-generat
es architecture diagrams from Langgraph's code
* Creates visual flowcharts of the entire codebase
* Documents API endpoi
nts clearly
* Syncs automatically with codebase updates

Why its Better:

* 80% less time spent on documentation
* Alway
s up-to-date with the codebase
* Full code references included
* Perfect for getting started with Langgraph

Would reall
y love feedback! 

https://preview.redd.it/nc767qsw6j5e1.png?width=2962&format=png&auto=webp&s=b57d002befe858f13778f8c68
ef96741e4521d8f



[https://entelligence.ai/documentation/langchain-ai&langgraph](https://entelligence.ai/documentation/
langchain-ai&langgraph)
```
---

     
 
all -  [ [3 YoE]- Applied for 1500+ SDE roles, not even getting any screening calls. Need advice ](https://www.reddit.com/r/EngineeringResumes/comments/1h97txj/3_yoe_applied_for_1500_sde_roles_not_even_getting/) , 2024-12-10-0914
```
https://preview.redd.it/5ak5n9l34j5e1.png?width=5100&format=png&auto=webp&s=ec1b0b258a413ef82d978213e4a9a053d29bf95d

I'
m currently a CS Graduate with 3+ years of experience working as s Full Stack Developer at Fortune 500 companies. I've s
tarted my job hunting in November 2023 and applied to closely 1000+ SWE Internships, no luck back then. I've started app
lying to the full time SDE roles on Linkedin andÂ [jobright.ai](http://jobright.ai/)Â and my resume is not even passing an
y screening rounds despite matching all the key words in the job description. I modify my resume to every job posting. C
an someone review my resume and let me know if I have to fine tune any section. Also, any guidance on the application st
rategies and my current resume would be really appreciated.


```
---

     
 
MachineLearning -  [ [P] Minima: local conversational retrieval augmented generation project (Ollama, Langchain, FastAPI, ](https://www.reddit.com/r/MachineLearning/comments/1h1pudq/p_minima_local_conversational_retrieval_augmented/) , 2024-12-10-0914
```
  
[https://github.com/dmayboroda/minima](https://github.com/dmayboroda/minima)  
  
Hey everyone, I would like to intro
duce you my latest repo, that is a local conversational rag on your files, Be honest, you can use this as a rag on-premi
ses, cause it is build with docker, langchain, ollama, fastapi, hf All models download automatically, soon I'll add an a
bility to choose a model For now solution contains:

* Locally running Ollama (currently qwen-0.5b model hardcoded, soon
 you'll be able to choose a model from ollama registry)
* Local indexing (using sentence-transformer embedding model, yo
u can switch to other model, but only sentence-transformers applied, also will be changed soon)
* Qdrant container runni
ng on your machine
* Reranker running locally (BAAI/bge-reranker-base currently hardcoded, but i will also add an abilit
y to choose a reranker)
* Websocket based chat with saving history
* Simple chat UI written with React
* As a plus, you 
can use local rag with ChatGPT as a custom GPT, so you able to query your local data through official chatgpt web and ma
c os/ios app.
* You can deploy it as a RAG on-premises, all containers can work on CPU machines

Couple of ideas/problem
s:

* Model Context Protocol support
* Right now there is no incremental indexing or reindexing
* No selection for the m
odels (will be added soon)
* Different environment support (cuda, mps, custom npu's)

Welcome to contribute (watch, fork
, star) Thank you so much!
```
---

     
