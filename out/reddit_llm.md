 
all -  [ I am sure I am passing ATS with this, later on I am getting impressive resume but we are moving with ](https://i.redd.it/ug0q35rk35gd1.jpeg) , 2024-08-02-0911
```

```
---

     
 
all -  [ LangChain or Ollama ](https://www.reddit.com/r/LanguageTechnology/comments/1ehufh2/langchain_or_ollama/) , 2024-08-02-0911
```
I'm very new to the field and still trying to get my bearings.

I'm working on a RAG-like application in Python. I chose
 Python because I reasoned that any AI or data science practitioners who join the team are likely to be more familiar wi
th it than a lower-level language.

I believe that my application will benefit from GraphRAG (or its SciPhi Triplex anal
ogue), so I've started transitioning it from its current conventional RAG approach.

Which would be better for this purp
ose--LangChain or Ollama? My current approach uses Ollama for text generation (with my own code handling all of the embe
dding vector elements rather than relying on a vector DB), but I feel that the greater complexity of GraphRAG would bene
fit from the flexibility of LangChain.
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses  ](https://www.reddit.com/r/udemyfreebies/comments/1ehtqj2/list_of_free_and_best_selling_discounted_courses/) , 2024-08-02-0911
```
# Udemy Free Courses for 02 August 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the c
ourses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12242/)AWS Certified Cloud Practitioner
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12229/)NEW AWS Cloud Technology Masterclass
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/12230/)AWS CodePipeline: DevOps CI/CD Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
12231/)Become an AWS Certified Data Engineer
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12232/)Azure Data Engin
eering-Master 6 Real-World Projects
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12233/)ChatGPT for Python Data S
cience and Machine Learning
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12234/)Azure Architect Technologies
* [R
EDEEM OFFER ](https://idownloadcoupon.com/udemy/12235/)AZ-305 ‚Äì Designing Azure Infrastructure Solutions
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/12236/)Microsoft Excel ‚Äì Excel from Beginner to Intermediate Level
* [REDEEM OFFER 
](https://idownloadcoupon.com/udemy/12237/)Mastering Figma from 0 to 100 (UI/UX Mastery Course)
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/12238/)Complete Machine Learning,NLP Bootcamp MLOPS & Deployment
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12239/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12240/)Drive Real Traffics to your site using Google ,Twitter,Linkd
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12241/)Ultimate Design Patterns
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12243/)Digi
tal Marketing That Drive Massive Results to Your Service
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12244/)How 
To Make Money Everyday Using AI ChatGPT /Fiverr.
* Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM O
FFER](https://idownloadcoupon.com/udemy/12245/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12227/)Professional 
Diploma in Office Administration Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12226/)How To Use R Prog
ramming for Research
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12225/)Score Full Mark in (P3O¬Æ) Foundation Exa
m ‚Äì Axelos
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12224/)TA-002: HashiCorp Terraform Practice Test ‚Äì 2024
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12223/)Professional Diploma in Digital Products Management
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12222/)Score 5 Above target in PMI-SP¬ÆExam
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/12221/)Scoring 5 Above target (PMI-RMP)¬Æ Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12220
/)Cloud Engineer (Google) Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12219/)JN0-104: Junip
er Networks Internet Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12218/)200-301: Cisco (CCN
A) Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12217/)No-Code Machine Learning Using Amazon
 AWS SageMaker Canvas
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11446/)C√≥mo Crear una Campa√±a de Email Marketi
ng Efectiva 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11298/)Learn UI UX Design Adobe XD : Learn User Exp
erience Design
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12189/)How to turn your IDEA into a BUSINESS that thr
ives!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7320/)Facebook Ads Marketing In Hindi/Urdu 2023
* Fast track F
rench for beginners
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/10791/)
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11488/)Universidad de Elementor Pro, ¬°Desde Cero Hasta Experto!
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/9697/)Microsoft Azure: Hands On Training: AZ-900 AZ-104 and AZ-305
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/45/)PHP for Beginners: PHP Crash Course 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9296/)C-level man
agement: 100 models for business success
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11487/)Mastering Email Deli
verability: The Comprehensive Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10785/)Sales operations: strateg
ies and frameworks for selling more
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1100/)Google Ads Mastery\~ Begin
ner To Pro \~ HINDI/URDU 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12214/)C√≥mo Usar el Creador de Sitios 
Web con IA de Hostinger 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12215/)Facebook Ads
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/12213/)Certified Kubernetes Application Developer (CKAD) ‚Äì Exams
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/12212/)Learn Camtasia Video Editing Masterclass Professional
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/12211/)PowerPoint Pr√§sentationen mit KI ChatGPT erstellen
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/12210/)Professional Diploma in Project Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12209
/)CISSP: Information Systems Security Practice Test 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12208/)CISM
: Information Security Manager Practice Test ‚Äì 2024
* C100DBA: MongoDB Practice Test ‚Äì 2024
* [REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/12207/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12206/)Amazon Afiliados: C√≥mo Crear u
na P√°gina Web de Nicho 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12205/)Professional Diploma in Corporate
 Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12204/)Python Project: Build a PDF File Handling Tool fr
om Scratch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12203/)AI for Business Strategy
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/11877/)Build, Host & Manage WordPress Websites using AI \[10Web\]
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/6763/)Become a Successful Affiliate Marketer \[Success Blueprint\]
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/4841/)Become a Successful SEO Freelancer & Start Online Businesses
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/6762/)Build Profitable E-Commerce Stores with WordPress & Woostify
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/6754/)AI x ChatGPT for Productivity 101 \[Masterclass\]
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/6750/)AI for Bloggers: SEO, Content Writing & Optimization
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6766/)Build a Profitable Online Courses Business \[Complete Guide\]
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6649/)Complete Microsoft Word Excel PowerPoint Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8692/)AI Vide
o Creation Course 2024: Generate Videos using AI
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1095/)Marketing en 
Facebook Ads ‚Äì Leads /Clientes Potenciales 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12202/)AZ-900: Azure
 Fundamentals Practice Test ‚Äì 2024
* CISSP: Information System Security Practice Test 2024
* [REDEEM OFFER](https://idow
nloadcoupon.com/udemy/12201/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12200/)Complete Ethical Hacking Master
class: Go from Zero to Hero
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12199/)550 Unix Interview Questions Prac
tice Test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12198/)Build, Train
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/12197/)CRISC: Risk and Information Systems Practice Test -2024
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/12196/)MO-201: Microsoft Excel Practice Test (Off 2019) ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/12195/)PCEP (30-02): Entry-Level Python Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/121
94/)SY0-501: CompTIA Security Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12193/)1Z0-071: O
racle Database SQL Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12192/)DA-104: Tableau Deskt
op Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12191/)Executive Diploma in General Manageme
nt
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5084/)2024 Google Cloud Digital Leader Certification practice Exa
m

GET MORE FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](https://www.reddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ List of FREE and Best Selling Discounted Courses  ](https://www.reddit.com/r/udemyfreeebies/comments/1ehtqck/list_of_free_and_best_selling_discounted_courses/) , 2024-08-02-0911
```
# Udemy Free Courses for 02 August 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the c
ourses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12242/)AWS Certified Cloud Practitioner
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12229/)NEW AWS Cloud Technology Masterclass
* [REDEEM OFFER ](https://idownloa
dcoupon.com/udemy/12230/)AWS CodePipeline: DevOps CI/CD Masterclass
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/
12231/)Become an AWS Certified Data Engineer
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12232/)Azure Data Engin
eering-Master 6 Real-World Projects
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12233/)ChatGPT for Python Data S
cience and Machine Learning
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12234/)Azure Architect Technologies
* [R
EDEEM OFFER ](https://idownloadcoupon.com/udemy/12235/)AZ-305 ‚Äì Designing Azure Infrastructure Solutions
* [REDEEM OFFER
 ](https://idownloadcoupon.com/udemy/12236/)Microsoft Excel ‚Äì Excel from Beginner to Intermediate Level
* [REDEEM OFFER 
](https://idownloadcoupon.com/udemy/12237/)Mastering Figma from 0 to 100 (UI/UX Mastery Course)
* [REDEEM OFFER ](https:
//idownloadcoupon.com/udemy/12238/)Complete Machine Learning,NLP Bootcamp MLOPS & Deployment
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12239/)Complete Generative AI Course With Langchain and Huggingface
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12240/)Drive Real Traffics to your site using Google ,Twitter,Linkd
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/12241/)Ultimate Design Patterns
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12243/)Digi
tal Marketing That Drive Massive Results to Your Service
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12244/)How 
To Make Money Everyday Using AI ChatGPT /Fiverr.
* Building Gen AI App 12+ Hands-on Projects with Gemini Pro
* [REDEEM O
FFER](https://idownloadcoupon.com/udemy/12245/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12227/)Professional 
Diploma in Office Administration Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12226/)How To Use R Prog
ramming for Research
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12225/)Score Full Mark in (P3O¬Æ) Foundation Exa
m ‚Äì Axelos
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12224/)TA-002: HashiCorp Terraform Practice Test ‚Äì 2024
*
 [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12223/)Professional Diploma in Digital Products Management
* [REDEEM 
OFFER ](https://idownloadcoupon.com/udemy/12222/)Score 5 Above target in PMI-SP¬ÆExam
* [REDEEM OFFER ](https://idownload
coupon.com/udemy/12221/)Scoring 5 Above target (PMI-RMP)¬Æ Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12220
/)Cloud Engineer (Google) Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12219/)JN0-104: Junip
er Networks Internet Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12218/)200-301: Cisco (CCN
A) Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12217/)No-Code Machine Learning Using Amazon
 AWS SageMaker Canvas
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11446/)C√≥mo Crear una Campa√±a de Email Marketi
ng Efectiva 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11298/)Learn UI UX Design Adobe XD : Learn User Exp
erience Design
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12189/)How to turn your IDEA into a BUSINESS that thr
ives!
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/7320/)Facebook Ads Marketing In Hindi/Urdu 2023
* Fast track F
rench for beginners
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/10791/)
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/11488/)Universidad de Elementor Pro, ¬°Desde Cero Hasta Experto!
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/9697/)Microsoft Azure: Hands On Training: AZ-900 AZ-104 and AZ-305
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/45/)PHP for Beginners: PHP Crash Course 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/9296/)C-level man
agement: 100 models for business success
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/11487/)Mastering Email Deli
verability: The Comprehensive Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/10785/)Sales operations: strateg
ies and frameworks for selling more
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1100/)Google Ads Mastery\~ Begin
ner To Pro \~ HINDI/URDU 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12214/)C√≥mo Usar el Creador de Sitios 
Web con IA de Hostinger 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12215/)Facebook Ads
* [REDEEM OFFER ](h
ttps://idownloadcoupon.com/udemy/12213/)Certified Kubernetes Application Developer (CKAD) ‚Äì Exams
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/12212/)Learn Camtasia Video Editing Masterclass Professional
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/12211/)PowerPoint Pr√§sentationen mit KI ChatGPT erstellen
* [REDEEM OFFER ](https://idownloadcoup
on.com/udemy/12210/)Professional Diploma in Project Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12209
/)CISSP: Information Systems Security Practice Test 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12208/)CISM
: Information Security Manager Practice Test ‚Äì 2024
* C100DBA: MongoDB Practice Test ‚Äì 2024
* [REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/12207/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12206/)Amazon Afiliados: C√≥mo Crear u
na P√°gina Web de Nicho 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12205/)Professional Diploma in Corporate
 Management
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12204/)Python Project: Build a PDF File Handling Tool fr
om Scratch
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12203/)AI for Business Strategy
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/11877/)Build, Host & Manage WordPress Websites using AI \[10Web\]
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/6763/)Become a Successful Affiliate Marketer \[Success Blueprint\]
* [REDEEM OFFER ](https://id
ownloadcoupon.com/udemy/4841/)Become a Successful SEO Freelancer & Start Online Businesses
* [REDEEM OFFER ](https://ido
wnloadcoupon.com/udemy/6762/)Build Profitable E-Commerce Stores with WordPress & Woostify
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/6754/)AI x ChatGPT for Productivity 101 \[Masterclass\]
* [REDEEM OFFER ](https://idownloadcoupon.
com/udemy/6750/)AI for Bloggers: SEO, Content Writing & Optimization
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6766/)Build a Profitable Online Courses Business \[Complete Guide\]
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy
/6649/)Complete Microsoft Word Excel PowerPoint Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/8692/)AI Vide
o Creation Course 2024: Generate Videos using AI
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/1095/)Marketing en 
Facebook Ads ‚Äì Leads /Clientes Potenciales 2023
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12202/)AZ-900: Azure
 Fundamentals Practice Test ‚Äì 2024
* CISSP: Information System Security Practice Test 2024
* [REDEEM OFFER](https://idow
nloadcoupon.com/udemy/12201/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12200/)Complete Ethical Hacking Master
class: Go from Zero to Hero
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12199/)550 Unix Interview Questions Prac
tice Test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12198/)Build, Train
* [REDEEM OFFER ](https://idownloadcou
pon.com/udemy/12197/)CRISC: Risk and Information Systems Practice Test -2024
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/12196/)MO-201: Microsoft Excel Practice Test (Off 2019) ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/12195/)PCEP (30-02): Entry-Level Python Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/121
94/)SY0-501: CompTIA Security Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12193/)1Z0-071: O
racle Database SQL Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12192/)DA-104: Tableau Deskt
op Practice Test ‚Äì 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/12191/)Executive Diploma in General Manageme
nt
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/5084/)2024 Google Cloud Digital Leader Certification practice Exa
m

GET MORE FREE ONLINE COURSES WITH CERTIFICATE ‚Äì¬†[CLICK HERE](https://idownloadcoupon.com/)
```
---

     
 
all -  [ Open Source RAG - best for production? ](https://www.reddit.com/r/LangChain/comments/1ehtdhs/open_source_rag_best_for_production/) , 2024-08-02-0911
```
Hello everyone,

I am currently looking at some opensource RAG such as Langchain and Llama index. Quite like Llama index
 but it does not seem suitable for production. I did not find the capability of doing batch inference especially for ret
rieving the closest chunks for a batch of query. (so lack of scalability here)  
Langchain seems to have this feature (c
orrect me if I am wrong but they are extracting the embeddings of queries by batch and not using multiple workers => one
 embedding model call instead of N call if we have N queries)

I was wondering if there are others open source RAG worth
 for production other than langchain allowing:

* Vector Store
* Chunking & Document upload of different type (pdf, docx
, raw text etc)
* scalability (such as batch for queries => embedding model call made by batch)
* flexible about choosin
g the embedding model (HF, OpenAI etc)
* good feature about the retriever such as filtering from metadata
* good postpro
cess function (or possibility to add custom function) such as chunk merging etc

Thanks for the help!
```
---

     
 
all -  [ How can I run Video-LLaMa ? ](https://www.reddit.com/r/LangChain/comments/1ehsukn/how_can_i_run_videollama/) , 2024-08-02-0911
```
Could someone show me how I can use [https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned](https://huggingface.
co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned) with Python, please? I am still a beginner. Thank you to those who take the t
ime to answer my question.
```
---

     
 
all -  [ Resume Review ](https://www.reddit.com/r/resumes/comments/1ehpbyu/resume_review/) , 2024-08-02-0911
```
# Please Roast my Resume in Detail. Looking for SDE and MLE roles. I am trying for Full time.
Have received over 450+ re
jections for internships with no interviews currently working a volunteer role 

https://preview.redd.it/yhw5ezjks3gd1.p
ng?width=737&format=png&auto=webp&s=5e3aabd529c431fb31d0d47fe25ee0f9799ef1e2


```
---

     
 
all -  [ Where to store vectors? ](https://www.reddit.com/r/LangChain/comments/1ehpb1d/where_to_store_vectors/) , 2024-08-02-0911
```
When you build RAG, where do you store all the vectors? 

I am using Postgres + pg_vector, and just storing the vectors 
in the same DB as the rest of my application data. It is convenient and works well with my toolchain.

But I also heard 
(without explanation) that it is better to use a separate database for vectors. 

Is this true? Any thoughts on why? Doe
s another Postgres database on the same instance ‚Äúcount‚Äù? 
```
---

     
 
all -  [ LangGraph Studio is amazing ](https://www.reddit.com/r/LangChain/comments/1ehp7h5/langgraph_studio_is_amazing/) , 2024-08-02-0911
```
[LangGraph Studio: The first agent IDE (youtube.com)](https://www.youtube.com/watch?v=pLPJoFvq4_M) -- check this out.

J
ust a week back, I was thinking of developing a web app kind of interface for langgraph, and they just launched it. Now,
 what if there were a drag-and-drop-like application for creating a complex graph chain?
```
---

     
 
all -  [ Allowing a real person to 'take over' the conversation? ](https://www.reddit.com/r/LangChain/comments/1ehmxa9/allowing_a_real_person_to_take_over_the/) , 2024-08-02-0911
```
Is anyone working on Conversational technology that allows a third¬† person to 'take over' the conversation, given the an
swer relevancy confidence is low, with a RAG pipeline?
```
---

     
 
all -  [ Need Help with NL to SQL Agent: Inconsistent Responses and Large Context Issues ](https://www.reddit.com/r/LangChain/comments/1ehhzzq/need_help_with_nl_to_sql_agent_inconsistent/) , 2024-08-02-0911
```
Hi everyone,

I‚Äôm developing a natural language to SQL to natural language agent using LangGraph. While my agent can gen
erate good responses with nice visualizations for some questions, it‚Äôs often inconsistent. I get different answers for t
he same question even though I have top\_p set to 1 and temperature set to 0.

Here are some details:

* The process inv
olves several steps before creating the query and composing the response like watching the db schema, executing tools an
d reflecting on the temporary response. 
* The median token utilization per run is around 40k tokens, except for very ba
sic questions. Is this context too large?
* Occasionally, the agent doesn‚Äôt follow my instructions. Sometimes changing t
he wording slightly improves performance, but I have to do so many attempts that I get crazy. Is it normal?

The databas
e structure:

* 2 tables with around 300 ish columns each
* 3 smaller tables with around 10 ish columns each

Am I on th
e right track, or is there a fundamental issue, possibly related to the large context size? Any insights or suggestions 
would be greatly appreciated!

Thanks!
```
---

     
 
all -  [ Looking for a Video Understanding Model with Commercial Use License ](https://www.reddit.com/r/LangChain/comments/1ehgnig/looking_for_a_video_understanding_model_with/) , 2024-08-02-0911
```
Hello, does anyone know of a model capable of understanding videos and answering my questions via an LLM? Something like
 Video-LLaMA but that allows commercial use? Thank you very much to those who take the time to respond.
```
---

     
 
all -  [ Adding Streaming Support to FastAPI LangChain Application with Agents ](https://www.reddit.com/r/LangChain/comments/1ehggqs/adding_streaming_support_to_fastapi_langchain/) , 2024-08-02-0911
```

I'm working on a production FastAPI application that uses LangChain with a cascade of tools for various AI tasks. I'm l
ooking to add asynchronous streaming support to my API and would appreciate feedback on my proposed design:

## Current 
Setup:
- FastAPI endpoints that use LangChain agents with multiple tools
- Synchronous API calls that return complete re
sponses, including main content and metadata (e.g., sources used)

## Proposed Design:
1. Keep existing synchronous API 
endpoints as-is for backward compatibility
2. Add new streaming endpoints for real-time token generation of the main res
ponse body
3. Use Redis as a message broker to collect and stream responses
4. Synchronous API continues to return full 
response with all fields (main content, sources, etc.)

## Implementation Idea:
- Modify existing endpoints to publish r
esponses to Redis
- Create new streaming endpoints that subscribe to Redis channels
- Update LangChain agents to publish
 chunks and full responses to Redis
- Client can use either sync API for full response or streaming API for real-time up
dates

## Questions:
1. Is this a sensible approach for adding streaming to an existing production API?
2. Are there bet
ter alternatives to using Redis for this purpose?
3. How can I ensure efficient resource usage and low latency with this
 design?
4. Any potential pitfalls or considerations I should be aware of?

I'd greatly appreciate any insights, alterna
tive approaches, or best practices for implementing streaming in a FastAPI LangChain application. Thanks in advance for 
your help!


```
---

     
 
all -  [ How to add specific source from db to RunnableSequence using Langchain ](https://www.reddit.com/r/LangChain/comments/1ehggmb/how_to_add_specific_source_from_db_to/) , 2024-08-02-0911
```
Hello. I use convex and langchain to create my rag application. In my case i need add to context specific data from my d
b - logic my application is serching some embeddings by id from my vectoredb then i use its embeddings for generate answ
er - but if i just add to context from RunnableSequence my embeddings i need use some format or embeddings are enough fo
r this? I dont find this example in langchain documentation

`const vectorStore = new ConvexVectorStore(new OpenAIEmbedd
ings(), { ctx });`  
`const llm = new ChatOpenAI({`  
`apiKey: process.env.OPENAI_API_KEY,`  
`model: 'gpt-3.5-turbo',` 
 
`temperature: 0,`  
`});`  
`const parcer = new StringOutputParser();`  
`const retriever = vectorStore.asRetriever()`
  
`const prompt = await pull<ChatPromptTemplate>('rlm/rag-prompt');`  
`const ragChain = RunnableSequence.from([`  
`{`
  
`context: retriever.pipe(formatDocumentsAsString) ,`  
`question: new RunnablePassthrough(),`  
`},`  
`prompt,`  
`l
lm,`  
`parcer,`  
`]);`
```
---

     
 
all -  [ Multiple turns prompting strategy ](https://www.reddit.com/r/LangChain/comments/1eheoc1/multiple_turns_prompting_strategy/) , 2024-08-02-0911
```
Hello guys,

I have a question concerning how to prompt a model.  
I'm currently using LLaMa 3.1 to interact with a tool
. The model is given an objective and generate multiple rounds of tool input to achieve it.  
Currently i'm simply using
 the following format:

ChatPromptTemplate(\[('system',system\_prompt),('user',user\_prompt)\])  
where user\_prompt con
tains the previous rounds of him generating commands and tool output like this:  
user\_prompt='''  
{prompt}  
previous
 commands executed:{previous\_rounds\_of\_tool\_call}  
'''  
This is inspired of ReAct prompt formatting.

But I'm thin
king about changing that to prompt him in the following format:  
ChatPromptTemplate(\[('system',system\_prompt),('user'
,user\_prompt)  
,('tool',tool\_message),('user',user\_prompt).....\])

adding each turns as separate message.  
I would
 like to know if someone already used that? Does it change something ? How to do the training with multi steps setup lik
e that?simply train each step separately?

Thanks for your advices!
```
---

     
 
all -  [ How to build Production grade Langchain Agents using ReAct
 ](https://www.reddit.com/r/LangChain/comments/1ehcpct/how_to_build_production_grade_langchain_agents/) , 2024-08-02-0911
```
Hi everyone,

ReAct agents are powerful, but I've found a way to make them even better for real-world use. Here's how:


Multi-LLM Integration: I've set up my ReAct agents to work with over 200 different LLMs. This flexibility lets you choos
e the best model for each task.  


Performance Tracking: By monitoring costs, token usage, and latency, I've optimized 
my agents' efficiency. This is crucial for large-scale applications.

Improved Reliability: I've implemented fallbacks b
etween LLMs, load-balancing, and automatic retries. This makes the agents much more stable in production environments.


Smart Caching: By storing frequently accessed data, I've significantly reduced API calls, making the agents faster and m
ore cost-effective.

Detailed Logging: Comprehensive action tracking has been a game-changer for debugging complex ReAct
 runs.

Easy Prompt Management- I can now update prompts without touching the code, which speeds up experimentation and 
optimization.

I've based my implementation on Simon Willison's work. You can find the starting point here: [https://git
.new/ReAct-framework](https://git.new/ReAct-framework)

Has anyone else been working on improving ReAct agents? What cha
llenges have you faced in real-world applications?
```
---

     
 
all -  [ I did not receive the results email from Nvidia generative AI contset. Also the certificate. ](https://www.reddit.com/r/LangChain/comments/1ehajmd/i_did_not_receive_the_results_email_from_nvidia/) , 2024-08-02-0911
```
I participated in the nvidia gen ai contest on June 18th in Korea time, or maybe June 17th in Pacific time.

And I've be
en waiting for today. But the result email and certificate haven't arrived to me. What's the reason?

Or is there anyone
 who is experiencing the same situation as me?

I also talked about this issue in the nvidia developer discord channel, 
but the people involved don't input any chat.
```
---

     
 
all -  [ [For Hire] Experienced backend developer - Java, Spring, Node, Nest, Elastic/Opensearch, Postgres, R ](https://www.reddit.com/r/forhire/comments/1ehai8u/for_hire_experienced_backend_developer_java/) , 2024-08-02-0911
```
Hi there üëã,

I am Anu, a software developer based in Sri Lanka.

Experience:
I have 4 years of experience in backend dev
elopment, primarily in Spring Boot. I also have experience building internal company tools and APIs using Node.JS and Py
thon. 

I have also worked part time as a React.JS developer, for 7 months, and have a decent grasp of frontend developm
ent.

Projects:
An interesting project I have worked on is the research and implementation of a chunking mechanism for a
 RAG application, for the purpose of generating vector embeddings on OpenSearch.

Education:
I have both a Bachelor's de
gree and a Master's degree in Software engineering, where there were modules covering data science and ML concepts.

Tec
hnologies:

Java 8 to 21
Spring boot
Spring
Postgres
Elasticsearch, OpenSearch
React, TypeScript, NextJS
Python
Langchai
n4J
Langchain
AWS
Node.js, Nest.Js

Github:
I dont use GitHub often, and don't have any meaningful projects on there. I 
am willing to take any test or take home (interview) project to prove my skills. I can share the GitHub via DMs if you w
ould still like to see it.

Rates:
Hourly rate (part time) - $15 to $20 per hour
Hourly rate if you like my work and hir
e me full time - starting $20 per hour, my notice period is 2 months for my current job.

Availability:
I am available p
art time on weekdays and full/ any time on weekends.

Thanks ü´°
```
---

     
 
all -  [ How to pass None Type as an input to LangGraph which deployed in LangServe ](https://www.reddit.com/r/LangChain/comments/1eh9wwv/how_to_pass_none_type_as_an_input_to_langgraph/) , 2024-08-02-0911
```
I have been deloyed an langgraph app which running at LangServe. One question is that I have a feature which required hu
man-in-the-loop that's send a None Type to the langgraph, that's the way to continue langgraph execution. I know how to 
do it in Python SDK but still no clues in LangServe client wayÔºåwhich I mimic request with Python `requests` through payl
oads. 

Any good ideas?
```
---

     
 
all -  [ Spoke to 22 LangGraph devs and here's what we found ](https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke_to_22_langgraph_devs_and_heres_what_we_found/) , 2024-08-02-0911
```
I recently had our AI interviewer speak with 22 developers who are building with LangGraph. The interviews covered vario
us topics, including how they're using LangGraph, what they like about it, and areas for improvement. I wanted to share 
the key findings because I thought you might find it interesting.

# Use Cases and Attractions

LangGraph is attracting 
developers from a wide range of industries due to its versatility in managing complex AI workflows. Here are some intere
sting use cases:

1. **Content Generation:** Teams are using LangGraph to create systems where multiple AI agents collab
orate to draft, fact-check, and refine research papers in real-time.
2. **Customer Service:** Developers are building dy
namic response systems that analyze sentiment, retrieve relevant information, and generate personalized replies with bui
lt-in clarification mechanisms.
3. **Financial Modeling:** Some are building valuation models in real estate that adapt 
in real-time based on market fluctuations and simulated scenarios.
4. **Academic Research**: Institutions are developing
 adaptive research assistants capable of gathering data, synthesizing insights, and proposing new hypotheses within a si
ngle integrated system.

# What Attracts Developers to LangGraph?

1. **Multi-Agent System Orchestration**: LangGraph ex
cels at managing multiple AI agents, allowing for a divide-and-conquer approach to complex problems.'We are working on a
 project that requires multiple AI agents to communicate and talk to one another. LangGraph helps with thinking through 
the problem using a divide-and-conquer approach with graphs, nodes, and edges.' - Founder, Property Technology Startup
2
. **Workflow Visualization and Debugging**: The platform's visualization capabilities are highly valued for development 
and debugging.'LangGraph can visualize all the requests and all the payloads instantly, and I can debug by taking LangGr
aph. It's very convenient for the development experience.' - Cloud Solutions Architect, Microsoft
3. **Complex Problem-S
olving**: Developers appreciate LangGraph's ability to tackle intricate challenges that traditional programming struggle
s with.'Solving complex problems that are not, um, possible with traditional programming.' - AI Researcher, Nokia
4. **A
bstraction of Flow Logic**: LangGraph simplifies the implementation of complex workflows by abstracting flow logic.'\[La
ngGraph helped\] abstract the flow logic and avoid having to write all of the boilerplate code to get started with the p
roject.' - AI Researcher, Nokia
5. **Flexible Agentic Workflows**: The tool's adaptability for various AI agent scenario
s is a key attraction.'Being able to create an agentic workflow that is easy to visualize abstractly with graphs, nodes,
 and edges.' - Founder, Property Technology Startup

# LangGraph vs Alternatives

The most commonly considered alternati
ves were CrewAI and Microsoft's Autogen. However, developers noted several areas where LangGraph stands out:

1. **Handl
ing Complex Workflows:** Unlike some competitors limited to simple, linear processes, LangGraph can handle complex graph
 flows, including cycles.'CrewAI can only handle DAGs and cannot handle cycles, whereas LangGraph can handle complex gra
ph flows, including cycles.' -  Developer
2. **Developer Control:** LangGraph offers a level of control that many find u
nmatched, especially for custom use cases.'We did tinker a bit with CrewAI and Meta GPT. But those could not come even n
ear as powerful as LangGraph. And we did combine with LangChain because we have very custom use cases, and we need to ha
ve a lot of control. And the competitor frameworks just don't offer that amount of, control over the code.' - Founder, G
enAI Startup
3. **Mature Ecosystem:** LangGraph's longer market presence has resulted in more resources, tools, and infr
astructure.'LangGraph has the advantage of being in the market longer, offering more resources, tools, and infrastructur
e. The ability to use LangSmith in conjunction with LangGraph for debugging and performance analysis is a significant di
fferentiator.' -  Developer
4. **Market Leadership:** Despite a volatile market, LangGraph is currently seen as a leader
 in functionality and tooling for developing workflows.'Currently, LangGraph is one of the leaders in terms of functiona
lity and tooling for developing workflows. The market is volatile, and I hope LangGraph continues to innovate and create
 more tools to facilitate developers' work.' - Developer

# Areas for Improvement

While LangGraph has garnered praise, 
developers also identified several areas for improvement:

1. **Simplify Syntax and Reduce Complexity:** Some developers
 noted that the graph-based approach, while powerful, can be complex to maintain.'Some syntax can be made a lot simpler.
' - Senior Engineering Director, BlackRock
2. **Enhance Documentation and Community Resources:** There's a need for more
 in-depth, complex examples and community-driven documentation.'The lack of how-to articles and community-driven documen
tation... There's a lot of entry-level stuff, but nothing really in-depth or complex.' - Research Assistant, BYU
3. **Im
prove Debugging Capabilities:** Developers expressed a need for more detailed debugging information, especially for trac
king state within the graph.'There is a need for more debugging information. Sometimes, the bug information starts from 
the instantiation of the workflow, and it's hard to track the state within the graph.' - Senior Software Engineer, Canad
ian Government Agency
4. **Better Human-in-the-Loop Integration:** Some users aren't satisfied with the current implemen
tation of human-in-the-loop concepts.'More options around the human-in-the-loop concept. I'm not a very big fan of their
 current implementation of that.' - AI Researcher, Nokia
5. **Enhanced Subgraph Integration:** Multiple developers menti
oned issues with integrating and combining subgraphs.'The possibility to integrate subgraphs isn't compatible with \[gra
ph drawing\].' - Engineer, IT Consulting Company 'I wish you could combine smaller graphs into bigger graphs more easily
.' - Research Assistant, BYU
6. **More Complex Examples:** There's a desire for more complex examples that developers ca
n use as starting points.'Creating more examples online that people can use as inspiration would be fantastic.' - Senior
 Engineering Director, BlackRock

\_\_\_\_  
You can check out the interview transcripts here: [kgrid.ai/company/langgra
ph](http://kgrid.ai/company/langgraph)

Curious to know whether this aligns with your experience? 
```
---

     
 
all -  [ RAG PDF Chat + Web Search ](https://www.reddit.com/r/LangChain/comments/1egyn3g/rag_pdf_chat_web_search/) , 2024-08-02-0911
```
Hi guys I have created a PDF Chat/ Web Search RAG application deployed on Hugging Face Spaces https://shreyas094-searchg
pt.hf.space. Providing the model documentation below please feel free to contribute.

# AI-powered Web Search and PDF Ch
at Assistant

This project combines the power of large language models with web search capabilities and PDF document ana
lysis to create a versatile chat assistant. Users can interact with their uploaded PDF documents or leverage web search 
to get informative responses to their queries.

## Features

- **PDF Document Chat**: Upload and interact with multiple 
PDF documents.
- **Web Search Integration**: Option to use web search for answering queries.
- **Multiple AI Models**: C
hoose from a selection of powerful language models.
- **Customizable Responses**: Adjust temperature and API call settin
gs for fine-tuned outputs.
- **User-friendly Interface**: Built with Gradio for an intuitive chat experience.
- **Docume
nt Selection**: Choose which uploaded documents to include in your queries.

## How It Works

1. **Document Processing**
: 
   - Upload PDF documents using either PyPDF or LlamaParse.
   - Documents are processed and stored in a FAISS vector
 database for efficient retrieval.

2. **Embedding**: 
   - Utilizes HuggingFace embeddings (default: 'sentence-transfor
mers/all-mpnet-base-v2') for document indexing and query matching.

3. **Query Processing**:
   - For PDF queries, relev
ant document sections are retrieved from the FAISS database.
   - For web searches, results are fetched using the DuckDu
ckGo search API.

4. **Response Generation**:
   - Queries are processed using the selected AI model (options include Mi
stral, Mixtral, and others).
   - Responses are generated based on the retrieved context (from PDFs or web search).

5. 
**User Interaction**:
   - Users can chat with the AI, asking questions about uploaded documents or general queries.
   
- The interface allows for adjusting model parameters and switching between PDF and web search modes.

## Setup and Usag
e

1. Install the required dependencies (list of dependencies to be added).
2. Set up the necessary API keys and tokens 
in your environment variables.
3. Run the main script to launch the Gradio interface.
4. Upload PDF documents using the 
file input at the top of the interface.
5. Select documents to query using the checkboxes.
6. Toggle between PDF chat an
d web search modes as needed.
7. Adjust temperature and number of API calls to fine-tune responses.
8. Start chatting an
d asking questions!

## Models

The project supports multiple AI models, including:
- mistralai/Mistral-7B-Instruct-v0.3

- mistralai/Mixtral-8x7B-Instruct-v0.1
- meta/llama-3.1-8b-instruct
- mistralai/Mistral-Nemo-Instruct-2407

## Future I
mprovements

- Integration of more embedding models for improved performance.
- Enhanced PDF parsing capabilities.
- Sup
port for additional file formats beyond PDF.
- Improved caching for faster response times.

## Contribution

Contributio
ns to this project are welcome!


```
---

     
 
all -  [ What's your favorite approach to managing prompt templates? ](https://www.reddit.com/r/LocalLLaMA/comments/1egvdix/whats_your_favorite_approach_to_managing_prompt/) , 2024-08-02-0911
```
By 'prompt template' I mean more than just the format for a particular instruction model. I'm interested in what you do 
to generate prompts.

Approaches I'm aware of:

* Just use formatted strings. Python's got handy string-formatting code 
after all. The drawback is that it only does string substitution
* A custom prompting script format. In the past, I've w
ritten a script parser that takes a text or json file and substitutes variables and does some loop logic and so on. The 
drawback is that I have to implement everything myself and expressing loops or branching starts to get trickier.
* LangC
hain has prompt templates. Drawback: I bounced hard off LangChain last time I tried it; too many abstractions getting in
 the way.
* DSPy has a very elegant way to specify templates via Signature and Module classes; the Modules in particular
 can have arbitrary logic and nest other modules inside making for some elegant structures. Can use the AI to optimize p
rompts. Drawback is that it is a bit opinionated about the exact format of the prompts (which I can adjust externally, b
ut it's a bit off-label at that point).
* txtai: In addition to the very good embeddings features, includes fairly direc
t access to the prompts. Lots and lots of examples in the docs. Drawbacks: needs to work within their pipeline abstracti
on; I haven't used it enough to say if the prompt management is helpful *enough*.

Other stuff I've considered but haven
't used: Burr, Haystack, Pezzo, OpenPrompt, Agenta, LangFuse, LangTail, magnetic, or just using Jinja2 templates.

Some 
of these are geared at managing prompts across large teams; I'm personally interested in smaller, more modular solutions
 for rapid prototyping, but there might be some crossover. I'm aiming for something where there's a few custom-targeted 
prompts rather than a whole raft of them.

My personal #1 prompt management priority is to be able to see when and where
 a prompt went off the rails. I don't want to debug a failed RAG lookup by painfully combing stack traces or stepping th
rough my code. Part of the solution is telemetry and observability, assuming you've got a telemetry library that can tra
ce the prompt assembly and not just the inference requests. But a good bit of it is just having one place where all the 
data is assembled into a prompt, instead of having it all over the place.

What are you doing to create your prompts? Wr
iting them all by hand? Using a library?
```
---

     
 
all -  [ Want to create RAG application for stackoverflow / stackexchange questions and answers. Is it legal  ](https://www.reddit.com/r/LangChain/comments/1egvbm4/want_to_create_rag_application_for_stackoverflow/) , 2024-08-02-0911
```
Hi Folks,

Apologies if the above question does not belong here. But I am create a RAG application, Basically it is a RA
G application for stackoverflow / stackexchange questions and answers.

But my first dilemma is - is it legal to scrape 
answers from stackoverflow / stackexchange?

I am planning to provide links back to the original answer in my app.

Any 
suggestions or advice would be great.
```
---

     
 
all -  [ Create_sql_agent issue ](https://www.reddit.com/r/LangChain/comments/1egub1z/create_sql_agent_issue/) , 2024-08-02-0911
```
Hello everyone. Im building an application using the langchain create_sql_agent constructor: langchain_community.agent_t
oolkits.sql.base.create_sql_agent, for a strange use case that requires finding out which table in an SQL database a par
ticular dataset(which I feed in the prompt as key value pairs of column headers and corresponding 5 values as a list) mo
st resembles. Ive written prompts asking the agent to use the column headers to guess which table the dataset resembles.
 This is happening with llama 3 8b running via ollama. 

The problem is I keep getting an error message which im recalli
ng from my memory like:

ValueError: An outputparsing error occured. In order to pass this back to the agent and have it
 try again, pass handle_parsing_errors = True to the Agent executor.  

However, the create_sql_agent constructor does n
ot even have handle_parsing_errors as a parameter! Anyone have any idea how to resolve this? Im sure i must be getting s
omething wrong. 

For context, I've worked with the AgentExecutor class before which has a parameter handle_parsing_erro
rs, which worked well, but for this specific use case, I need the sql agent. Is there a way to call the sql agent using 
the AgentExecutor? 
```
---

     
 
all -  [ how to send relevant data to llm? ](https://www.reddit.com/r/LangChain/comments/1egt6tz/how_to_send_relevant_data_to_llm/) , 2024-08-02-0911
```
So I am creating a software it scrapes the website, cleans the unwanted html like img, meta tags, script, style etc. and
 now I have a clean html file. Now I have a user description on what he wants from that url for example he want to submi
t a form. then only the form and login form component is important and significant. now I don't want to send the whole h
tml code but in a way trim it down to more relevant code which in this case is only code related to login. maybe omit ht
ml code of header, footer and other unwanted stuff. Now want some guidance how I can achieve this?
```
---

     
 
all -  [ Create robust API over Langchain chains using Langserve ](https://www.reddit.com/r/LangChain/comments/1egn31o/create_robust_api_over_langchain_chains_using/) , 2024-08-02-0911
```
Hello everyone,

Just wrote an article on how to use LangServe to create an API over LangChain chains.  
Here's the [lin
k](https://www.metadocs.co/2024/07/31/easily-create-production-ready-apis-over-your-langchain-chains-using-langserve/). 
 
This is actually something that I use in production in my company :D.

  
Enjoy!
```
---

     
 
all -  [ Interview with Jacob Lee, lead maintainer of LangChain.js ](https://www.reddit.com/r/LangChain/comments/1egmw06/interview_with_jacob_lee_lead_maintainer_of/) , 2024-08-02-0911
```
Hi folks,

Exciting news! Two weeks ago, I had the pleasure of recording a podcast interview with Jacob Lee, the lead ma
intainer of LangChain.js.   
  
Check it out here: [https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/](http
s://www.js-craft.io/blog/interview-jacob-lee-langchain-js/)

During this short talk, we go through topics such as:

* Th
e advantages of using LangChain
* A good roadmap for learning LangChain
* How all the Langs work together (LangGraph, La
ngSmith, LangServe, LangChain itself)
* Using LangChain.js with or without TypeScript 

... and much more.

Listen now::
 [https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/](https://www.js-craft.io/blog/interview-jacob-lee-langc
hain-js/)

  
Hope you will like it, and happy to hear your opinions! 
```
---

     
 
all -  [ Any local and opensource alternative to Adept.ai? ](https://www.reddit.com/r/LocalLLaMA/comments/1egk7n8/any_local_and_opensource_alternative_to_adeptai/) , 2024-08-02-0911
```
So I was wondering, if there is a way for us to automate tasks on the computer like updating tickets on JIRA, doing stuf
f on the computer (maybe just browser to start with)

Found the video from [adept](https://www.adept.ai ) interesting.


Also previously check [langchain webvoyeger](https://github.com/langchain-ai/langgraph/blob/main/examples/web-navigation
/web\_voyager.ipynb)
```
---

     
 
all -  [ Langgraph: What is the best practice for displaying messages to the user as the we move through the  ](https://www.reddit.com/r/LangChain/comments/1egjtsg/langgraph_what_is_the_best_practice_for/) , 2024-08-02-0911
```
Hi, right now my graph is not displaying to the user most of the messages that AI generate as it goes through the graph.
 This is specially bad in steps when I am getting the user confirmation for something, but it would be nice to display s
ome messages as the llm moves from one node to another.   
What is the best practice for that? I've been doing console.p
rint for displaying the last message in the message array in certain parts of the code, but I guess that's not the best 
way to solve it. How do you usually do it?   

```
---

     
 
all -  [ Using Code Compiler as a Tool? ](https://www.reddit.com/r/LangChain/comments/1egirrf/using_code_compiler_as_a_tool/) , 2024-08-02-0911
```
Did anyone try to create a custom tool that can compile your generated code to check if the code is working or not?  
Ca
n I get some help creating this type of custom tool?
```
---

     
 
all -  [ question about retrievers - slow pdf loading times also when using cache ](https://www.reddit.com/r/LangChain/comments/1eghtid/question_about_retrievers_slow_pdf_loading_times/) , 2024-08-02-0911
```
Hey everyone,

I‚Äôve been working with LangChain to create an efficient document retriever using embeddings and caching m
echanisms. I ran into a problem where the PyPDF loading process takes a substantial amount of time, and I believe this c
an be optimized by leveraging caching because i can only access the specifc location in the pdf where the retrieved cont
ext is - but the code right now doesn't achieve this.

my question is then - how to achieve this more efficient functino
ality. 

Here's my original setup:

  
`from langchain_community.vectorstores import Chroma`

`from langchain_openai imp
ort OpenAIEmbeddings`

`from langchain.storage import LocalFileStore`

`from langchain.embeddings import CacheBackedEmbe
ddings`

`from langchain_community.document_loaders import PyPDFLoader`

`from langchain.text_splitter import RecursiveC
haracterTextSplitter`



`def load_jodrag_retriever(use_cache=True, chunk_size=2500, chunk_overlap=300, num_docs_retriev
e=2):`

`embed = OpenAIEmbeddings()`

`docs = load_jodrag(chunk_size=chunk_size, chunk_overlap=chunk_overlap)`

`retriev
er = retriever_setup(docs, use_cache=use_cache, embed=embed, num_docs_retrieve=num_docs_retrieve)`

`return retriever`




`def load_rag(path = 'paper1.pdf', chunk_size = 500, chunk_overlap = 20):`

`loader = PyPDFLoader(path)`

`pages = loa
der.load()`

`pages = pages[9:360]`

`text = ''`

`for page in pages:`

`text += page.page_content`

`text = text.replac
e('\t', ' ')`

`text_splitter = RecursiveCharacterTextSplitter(separators=['\n\n', '\n', '\t'], chunk_size=chunk_size, c
hunk_overlap=chunk_overlap)`

`docs = text_splitter.create_documents([text])`

`return docs`



`def retriever_setup(doc
s, use_cache=True, cache_dir= './cache/', embed=OpenAIEmbeddings(), num_docs_retrieve=2):`

`if use_cache:`

`store = Lo
calFileStore(cache_dir)`

`cached_embedder = CacheBackedEmbeddings.from_bytes_store(embed, store, namespace=embed.model)
`

`vectorstore = Chroma.from_documents(docs, cached_embedder)`

`else:`

`vectorstore = Chroma.from_documents(documents
=docs, collection_name='rag-chroma', embedding=embed)`

`retriever = vectorstore.as_retriever(search_kwargs={'k': num_do
cs_retrieve})`

`return retriever`


```
---

     
 
all -  [ GPT Graph: A Flexible Pipeline Library ](https://www.reddit.com/r/LangChain/comments/1egh70y/gpt_graph_a_flexible_pipeline_library/) , 2024-08-02-0911
```
ps: This is a repost (2 days ago). Reddit decided to shadow-ban my previous new account simply because i have posted thi
s. They mark it as 'scam'. I hope they will not do so again this time, like this is using a open source license and i di
dn't get any commercial benefit from it.

# Introduction (skip this if you like)

I am an intermediate self-taught pytho
n coder with no formal CS experience. I have spent 5 months for this and learnt a lot when writing this project. I have 
never written anything this complicated before, and I have rewrite this project from scratch at least several times. The
re are many smaller-scale rewrite when i am not satisfied with the structure of anything. I hope it is useful for somebo
dy. (Also warning, this might not be the most professional piece of code) Any feedback is appreciated!

# What My Projec
t Does

GPT Graph is a pipeline for llm data transfer. When I first studied LangChain, I don't understand why we need a 
server(langsmith) to do debug, and things get so complicated. Therefore, i have spent time in order to write a pipeline 
structure targeting being flexible and easy to debug. While it's still in early development and far less sophisticated a
s Langchain, I think my idea is better at least in some way in turns of how to abstract things (maybe i am wrong).

This
 library allows you to create more complex pipelines with features like dynamic caching, conditional execution, and easy
 debugging.

The main features of GPT Graph include:

1. Component-based pipelines
2. Allowing nested Pipeline
3. Dynami
c caching according to defined keys
4. Conditional execution of components using bindings or linkings
5. Debugging and a
nalysis methods
6. Priority Queue to run Steps in the Pipeline
7. Parameters can be updated with priority score. (e.g. i
f a Pipeline contains 4 Components, you can write config files for each of the Component and Pipeline, as Pipeline has h
igher priority than each component, if there are any conflict in parameters, the parent Pipeline's parameters will be us
ed)
8. One of the key advantages of GPT Graph is its debuggability. Every output is stored in a node (a dict with struct
ure {'content':xxx, ‚Äúextra‚Äù:xxx})

The following features are lacking (They are all TODO in the future)

1. currently al
l are using sync mode
2. No database is used at this moment. All data stored in networkx graph's wrapper.
3. No RAG at t
his moment. Although I have already written some prototype for it, basically calculate the vector and store in the nodes
. They are not submitted yet.

# Example

    from gpt_graph.core.pipeline import Pipeline  
    from gpt_graph.core.dec
orators.component import component
    
    @component()  
    def greet(x):  
    return x + ' world!'
    
    pipelin
e = Pipeline()  
    pipeline | greet()
    
    result = pipeline.run(input_data='Hello')  
    print(result) # Output:
 ['Hello world!']  

# Comparison

As for as I know and my understanding(which may be wrong)(e.g. Langgraph or Langchain
), there is no framework that can do nested pipeline, or using priority queue.

# Target Audience

Fast prototyping and 
small project related to llm data pipelines. It is because currently everything is stored as a wrapper of networkx graph
 (including outputs of each Step and step structure). Later I may write implementation for graph database, although I do
n't have the skill now.

# Welcome Feedback and Contributions

I welcome any comments, recommendations, or contributions
 from the community.  
I know that as someone that releases his first complicated project (at least for me), there may b
e a lot of things that i am not doing correctly, including documentations/ writing style/ testing or others. So any reco
mmendation is encouraged! Your feedback will be invaluable for me.  
If you have any questions about the project, feel f
ree to ask me as well. My documentation may not be the easiest to understand. I will soon take a long holiday for severa
l months, and when I come back I will try to enhance this project to a better and usable level.  
The license now is GPL
 v3, if more people feel interested in or contribute to the project, i will consider change it to more permissive licens
e.

# Link to Github

[https://github.com/Ignorance999/gpt\_graph](https://github.com/Ignorance999/gpt_graph)

# Link to
 Documentation

[https://gpt-graph.readthedocs.io/en/latest/hello\_world.html](https://gpt-graph.readthedocs.io/en/lates
t/hello_world.html)

# More Advanced Example (you can check documentation tutorial 1 Basics):

    class z:
        def 
__init__(self):
            self.z = 0
    
        def run(self):
            self.z += 1
            return self.z
   
 
    @component(
        step_type='node_to_list',
        cache_schema={
            'z': {
                'key': '[c
p_or_pp.name]',
                'initializer': lambda: z(),
            }
        },
    )
    def f4(x, z, y=1):
      
  return x + y + z.run(), x - y + z.run()
    
    @component(step_type='list_to_node')
    def f5(x):
        return np
.sum(x)
    
    @component(
        step_type='node_to_list',
        cache_schema={'z': {'key': '[base_name]', 'initia
lizer': lambda: z()}},
    )
    def f6(x, z):
        return [x, x - z.run(), x - z.run()]
    
    s = Session()
    s
.f4 = f4()
    s.f6 = f6()
    s.f5 = f5()
    s.p6 = s.f4 | s.f6 | s.f5
    
    result = s.p6.run(input_data=10)  # ou
tput: 59

    '''
    output: 
    Step: p6;InputInitializer:sp0
    text = 10 (2 characters)

    Step: p6;f4.0:sp0
   
 text = 12 (2 characters)
    text = 11 (2 characters)

    Step: p6;f6.0:sp0
    text = 12 (2 characters)
    text = 11
 (2 characters)
    text = 10 (2 characters)
    text = 11 (2 characters)
    text = 8 (1 characters)
    text = 7 (1 ch
aracters)

    Step: p6;f5.0:sp0
    text = 59 (2 characters)
    '''

```
---

     
 
all -  [ I was working on this for a long time - a SWE Kit that simplifies SWE Agent Creation ](https://www.reddit.com/r/LangChain/comments/1ege590/i_was_working_on_this_for_a_long_time_a_swe_kit/) , 2024-08-02-0911
```
Hey everyone! I‚Äôm excited to share a new project: SWEKit, a powerful framework for building software engineering agents 
using the Composio tooling ecosystem.

**Objectives**

SWEKit allows you to:

* Scaffold agents that work out-of-t
he-box with frameworks like CrewAI and LlamaIndex.
* Add or optimize your agent's abilities.
* Benchmark your agents a
gainst SWE-Bench.

# Implementation Details

* **Tools Used**: Composio, CrewAI, Python

**Setup**:

1. Install 
agentic framework of your choice and the Composio plugin
2. The agent requires a github access token to work with your 
repositories
3. You also need to setup API key for the LLM provider you're planning to use 

**Scaffold and Run Your 
Agent**

**Workspace Environment:**

SWEKit supports different workspace environments:

* **Host**: Run on the hos
t machine.
* **Docker**: Run inside a Docker container.
* **E2B**: Run inside an E2B Sandbox.
* **FlyIO**: Run inside
 a FlyIO machine.

**Running the Benchmark:**

* **SWE-Bench** evaluates the performance of software engineering age
nts using real-world issues from popular Python open-source projects.

[GitHub](https://git.new/SWE)

Feel free to e
xplore the project, give it a star if you find it useful, and let me know your thoughts or suggestions for improvements!
 üåü
```
---

     
 
all -  [ Is anyone aware of a good OCR model that can be used for document processing (Multi-language support ](https://www.reddit.com/r/LangChain/comments/1egcvsy/is_anyone_aware_of_a_good_ocr_model_that_can_be/) , 2024-08-02-0911
```
I need it to process documents for government agency. 
```
---

     
 
all -  [ Not sure which IT job to target ](https://www.reddit.com/r/ITCareerQuestions/comments/1eg9il0/not_sure_which_it_job_to_target/) , 2024-08-02-0911
```
Hi,

I work as an editor and staff writer for a trade magazine targeting STEM professionals. Fell into the job a few yea
rs ago when I was 22; turned out to be really fun and paid decently so I stuck with it.

However, I have an associate de
gree in computer programming and can work in a few different languages (more on that below). I'm also familiar and comfo
rtable in Windows and Linux environments, including CLI for both.

While I love working as a writer, I have also always 
loved IT and computers---and it pays quite a bit more. 

**My question:** Below is a rundown of my experience and skills
 pulled from my resume. Based on what you see, what kind of IT role should I be targeting? Help Desk? Jr. Sysadmin? Some
thing else?

Thanks

**SUMMARY/SKILLS**

Experienced technical communicator with expertise in programming and IT support
 (Windows, Linux). AAS in software development. Capable in Python, C#, SQL, markup languages, and Linux CLI. Regularly w
rite informative content around software, data, AI/ML, cybersecurity, and more. Creative and conscientious with a flair 
for explaining technical topics simply.

**Skills:** Programming (Python, C#, HTML/CSS, Bash, Powershell), Windows, Linu
x, SQL, Selenium, writing documentation, user training, troubleshooting, self-hosting services (Apache, FreshRSS), autom
ation, research

**EXPERIENCE**

**JOB 2**

**Associate Editor / Editorial IT Support**

**4/2022 - Present**

* Develop
ed a custom-trained LLM chatbot using **Python** and the **langchain** library
* Built an RSS reader for internal resear
ch use (**C#**)
* Programmed an application that automates social media promotion by crawling sitemap for new articles a
nd generating snippets with the OpenAI API (**Python, Flask, HTML/CSS**)
* Wrote **PowerShell** script to automate bulk 
image manipulation and storage processes
* Assist other users with computer issues, troubleshooting, etc.
* Write inform
ative content about software, AI/ML, cybersecurity, and more
* Lead production of multiple issues of print magazine, act
ing as project manager for high-visibility projects on strict deadlines

**JOB 1**

**Developer / Technical Content Mana
ger**

**2/2018 ‚Äì 4/2022**

* Wrote program to generate HTML web pages automatically, saving $6,000+ annually, then depl
oyed across company and trained users (**C#**)
* Wrote data pipeline to export and scrub data from internal inventory pl
atform for use in KPI reporting (**Python, pandas library**), saving significant time daily
* Wrote a variety of web scr
apers to assist in research and CRM data manipulation processes (**Python, Selenium library**)
* Wrote automated two-way
 sync between internal inventory platform and e-commerce website to reconcile inventory differences (**Python**)
* Assis
ted in troubleshooting and maintaining user workstations as well as organization network hardware


```
---

     
 
all -  [ RAG based recommendation system  ](https://www.reddit.com/r/LangChain/comments/1eg9g86/rag_based_recommendation_system/) , 2024-08-02-0911
```
I want to build a chatbot which gives recommendations say books based on the conversation it had before with the user an
d I also want it to have good language skills like fundamental models so what are resource for learning this and what ar
e the techstack to be used for this?
```
---

     
 
all -  [ Confused on What to Use for Chatbot? ](https://www.reddit.com/r/LangChain/comments/1eg41kn/confused_on_what_to_use_for_chatbot/) , 2024-08-02-0911
```
Hello -- I am trying to incrementally create a chatbot that will do three things (depending on user input)

1. Summarize
 a JSON specification for the product (thinking some simple prompt engineering here should be able to do this)
2. Answer
 questions about some ontologies/hierarchies we maintain (thinking RAG)
3. Generate / Modify a JSON specification for th
e product (thinking a fine-tuned model for this specific structured output we use - internally before JSON we use pydant
ic models)

My question is what is the best way to use LangChains building blocks to properly route a user's request to 
the appropriate model within the chat?

I was reading the docs and I wasn't sure if I needed to create a custom agent (a
nd somehow let it decide which of the three to use?) or if I should do a 'dumber' rule-based function to then determine 
which of the three to use and just have that integrate with the basic chatbot.

Any help / guidance would be greatly app
reciated! Am supposed to look into this for work and a little out of my depth right now.
```
---

     
 
all -  [ Discussion: How to dynamically modify tool descriptions in Langgraph? ](https://www.reddit.com/r/LangChain/comments/1eg12qg/discussion_how_to_dynamically_modify_tool/) , 2024-08-02-0911
```
Does anyone know how to dynamically modify the description of a Tool?

I am using ToolNode in Langgraph with tools defin
ed with the decorator, and to define the args, I am using a Pydantic BaseModel, something like:

    class ToolInput(Bas
eModel):
        arg_1: str = Field(description='...', type='string')
        ...
    
    u/tool('get_data', args_schem
a=ToolInput)
    def get_data(
        arg_1: str,
        ...
    ):
        '''Get the data, the accepted values of th
e arg_1 are:
        - val_1, val_2, val_3 ... val_n
        '''
        ...
        return data
    

The point is, I w
ant to dynamically pass data from the graph's state to construct the prompt, something like:

    class ToolInput(BaseMo
del):
        arg_1: int = Field(description='...', type='string')
        ...
    
    @tool('get_data', args_schema=To
olInput)
    def get_data(
        arg_1: str,
        ...
    ):
        '''Get the data, the accepted values of the ar
g_1 are:
        - {val_1}, {val_2}, {val_3}, ... , {val_n}
        '''
        # Where the {val_x} come from the State,
 for example state['available_values']
        ...
        return data
    

Does anyone have an idea of how I can do th
is?
```
---

     
 
MachineLearning -  [ [D] Embedding generation in production? How are you doing it? ](https://www.reddit.com/r/MachineLearning/comments/1e7xt6k/d_embedding_generation_in_production_how_are_you/) , 2024-08-02-0911
```


For those building production RAG pipelines, how are you generating embeddings. More than which model, I'm interested 
in how your deploying it. Are you calling the openai/vertex API endpoint directly? Using langchain/llamaindex wrappers? 
Using vectordb  classes? Or some other way?
```
---

     
 
MachineLearning -  [ [D] Is Anyone Else Setting Up Real-Time Django Workers for their AI Application? What's the best way ](https://www.reddit.com/r/MachineLearning/comments/1e0qens/d_is_anyone_else_setting_up_realtime_django/) , 2024-08-02-0911
```
We completely underestimated this one tbh, thought it would be much more straight forward. But we've done it now and doc
umented how step by step¬†[in this article series](https://medium.com/p/5828a1ea43a3).

A bit of context, we're building 
a mini free AI Agent that auto-generates manually customisable plots, so the user can basically style however they want.
 It needs to be cost effective and efficient, so we thought about how to do it and tested a couple other ways.

https://
preview.redd.it/cmly0a6bhwbd1.png?width=640&format=png&auto=webp&s=be1f5b2853e744adcaf8013e6d43b43f6be89617

We plan on 
releasing the project open source, so all feedback welcome! Is anyone else doing this and has any feedback? or do know o
f a better way to do it?
```
---

     
 
MachineLearning -  [ [P] Real Time AI Workers Web Application ](https://www.reddit.com/r/MachineLearning/comments/1dzryk9/p_real_time_ai_workers_web_application/) , 2024-08-02-0911
```
Hi everyone!

I've created a mini series on how to build a real time AI application using Django, LangChain and Celery.


Free knowledge - posting it in here for anyone working on something similar and had the same blockers I had when buildi
ng.

Let me know what you think on how I could potentially improve this architecture.

Part 1

[https://medium.com/towar
dsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79](https://medium.
com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-601dff7ada79)

Part 
2

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-5
828a1ea43a3](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time
-django-5828a1ea43a3)

Part 3

[https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-channels-red
is-docker-real-time-django-8e73c7b6b4c8](https://medium.com/towardsdev/how-to-set-up-django-from-scratch-with-celery-cha
nnels-redis-docker-real-time-django-8e73c7b6b4c8)

Part 4

[https://medium.com/towardsdev/how-to-set-up-django-from-scra
tch-with-celery-channels-redis-docker-real-time-django-c090c300517a](https://medium.com/towardsdev/how-to-set-up-django-
from-scratch-with-celery-channels-redis-docker-real-time-django-c090c300517a)

Part 5  
[https://medium.com/@cubode/how-
to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c](https://medium.com/@cubod
e/how-to-set-up-django-from-scratch-with-celery-channels-redis-docker-real-time-django-0845eb7e083c)
```
---

     
