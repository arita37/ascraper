 
all -  [ Community-driven development of LLM applications — interesting, wdyt? ](https://medium.com/@gensphere/community-driven-development-of-llm-applications-introducing-gensphere-182fd2a70e3e) , 2024-11-07-0912
```

```
---

     
 
all -  [ People who make langchain based chatbot, how do you make sure it is responsive and replies back in f ](https://www.reddit.com/r/Langchaindev/comments/1gl4o0o/people_who_make_langchain_based_chatbot_how_do/) , 2024-11-07-0912
```
I’ve built so many langchain based chatbots & one thing that always tips off the clients is the response time. What do y
ou in such scenarios?
```
---

     
 
all -  [ Need help regarding some preparation ](https://www.reddit.com/r/LLMDevs/comments/1gl3wtl/need_help_regarding_some_preparation/) , 2024-11-07-0912
```
I have a live coding test (30min) coming up for an AI/ML LLM internship. The internship requires knowledge of python, NL
P, LLMs, Langchain, Tensorflow, Pytorch, RAG and prompt engineering. I have some knowledge of everything except RAG. 

C
an anyone share some resources or their own experience? What type of questions can be asked to code and how should I go 
about it? This will be my first live coding interview so kinda panicking.

Urgent!!!!!
```
---

     
 
all -  [ Text-to-Table: Extracting Unstructured Data from a Large Legal Text ](https://www.reddit.com/r/LangChain/comments/1gl3pl7/texttotable_extracting_unstructured_data_from_a/) , 2024-11-07-0912
```
Hi everyone! I'm working with a lengthy HTML document of about 1,500 pages of legal text, and I need to extract data on 
items and goods, such as tax rates, to build a structured table.

The challenge is that the information is scattered acr
oss the text – for example, details for one item might appear on page 50, with additional information on page 200. I’m l
ooking for suggestions on techniques and tools to tackle this issue.

I'm considering using a Retrieval-Augmented Genera
tion (RAG) approach, but I haven't fully fleshed out the solution yet.

Has anyone worked on a similar task? Any recomme
ndations on papers, videos, or techniques would be incredibly helpful!

Thank you in advance!
```
---

     
 
all -  [ Cost effective solutions for talking with your database  ](https://www.reddit.com/r/LangChain/comments/1gl3082/cost_effective_solutions_for_talking_with_your/) , 2024-11-07-0912
```
I am currently working on an application where user can enter his query in natural language and the answer would be gene
rated basis the results from database. Database is the source of data for answering any queries. 

I tried two approache
s currently -
1. Non agentic using chains
2. Agentic

In both since we need to make multiple calls to llm and also token
s are more so cost incurred is higher. In general the agentic approach takes more cost as most of the decision making is
 left to it. 

So i wanted to discuss if anyone has worked on a similar problem on production scale and what things shou
ld be done to keep the costs in check ? I haven't tried any models apart from chatgpt yet but one thing that i could obs
erve was generally the top models are the ones that perform reliably for this particular problem
```
---

     
 
all -  [ Dyanmic Data Source ](https://www.reddit.com/r/LangChain/comments/1gl0luf/dyanmic_data_source/) , 2024-11-07-0912
```
I want to build a RAG system using data stored in an S3 bucket. The data in this bucket grows by approximately 100 new r
ecords (PDFs) daily, with each record averaging around 500 words. What would be the best approach to implement a RAG sol
ution that can handle this continuous data expansion efficiently?


```
---

     
 
all -  [ Easiest way to launch paid AI tools/wrappers? ](https://www.reddit.com/r/OpenAI/comments/1gl082q/easiest_way_to_launch_paid_ai_toolswrappers/) , 2024-11-07-0912
```
**I want to create a few simple AI tools** (similar to twitterbio.io for example). Basically I get text from the user an
d based on custom prompts/instructions I give them a list of ideas (text generated with OpenAI API). I might want to acc
ept also URLs, images and PDFs as inputs.

Some of my tools will be free and open. Others will be paid (monthly subscrip
tion), so **I need payments, authentication, etc.**

**I guess the quickest option would be to use some boilerplate or t
emplate**. I’ve done some research, but I’m completely lost between dozens of options: SaaS boilerplates, AI-specific bo
ilerplates, Github templates from Vercel/Langchain/others, templates or kits from Backend as a Service providers (Supaba
se/Firebase), frameworks with many “batteries included” such as Laravel…

I know some basic Python and HTML/CSS. Nothing
 else. I want to learn and also experiment with AI coding helpers (Cursor? Replit AI? v0?), but not spend several months
 before launching if possible. So **I want something easy to start, but also flexible** (being able to add features and 
make changes in the future without having to “fight” with the limitations of a certain boilerplate or whatever).

**What
 do you recommend?**

General advice and specific tools are both welcomed ;)
```
---

     
 
all -  [ On-Premise GPU Servers vs. Cloud for Agentic AI: Which Is the REAL Money Saver? ](https://www.reddit.com/r/LangChain/comments/1gkzjf2/onpremise_gpu_servers_vs_cloud_for_agentic_ai/) , 2024-11-07-0912
```
I’ve got a pipeline with 5 different agent calls, and I need to scale for at least 50-60 simultaneous users. I’m hosting
 Ollama, using Llama 3.2 90B, Codestral, and some SLM. Data security is a key factor here, which is why I can’t rely on 
widely available APIs like ChatGPT, Claude, or others.

Groq.com offers data security, but their on-demand API isn’t ava
ilable yet, and I can't opt for their enterprise solution.

So, is it cheaper to go with an on-premise GPU server, or sh
ould I stick with the cloud? And if on-premise, what are the scaling limitations I need to consider? Let’s break it down
!
```
---

     
 
all -  [ Ask me for any AI agent implementation  ](https://i.redd.it/rhjzwluhgazd1.png) , 2024-11-07-0912
```
Imagine you had a genie who could solve any problem you wanted...

Now, let's convert this wish-making concept into real
ity: What kind of AI agent would you love to see created? It could be something to solve your own challenges, help other
s, or tackle any interesting task you can imagine!

I can help make this happen!

I’m running a global online hackathon 
in conjunction with #LangChain, which has nearly 700 registrations so far, and many participants are looking for project
 ideas. Since the hackathon rules allow creating any AI agent you can imagine, this could be a win-win situation - share
 your ideas for AI agents, and maybe someone will make your wish come true!

Share your ideas in the comments below for 
any AI agents or problems you'd like solved, and I'll pass all these ideas to our participants.

P.S. registration close
s in 5 days, if you want to secure your spot:

https://www.tensorops.ai/aiagentsonlinehackathon


```
---

     
 
all -  [ A Web AI agent framework I'm planning on open sourcing ](https://www.reddit.com/r/OpenAI/comments/1gkytyh/a_web_ai_agent_framework_im_planning_on_open/) , 2024-11-07-0912
```
Hey! I’ve been building a simple framework called Dendrite for interacting with websites using natural language. Instead
 of having to find brittle css selectors or xpaths you can describe them with natural language.

`browser.click(“the sig
n in button”)`

The selectors are then cached so the next time you want to get an element you don’t need any interferenc
e. For the developers who like their code typed, specify what data you want with a Pydantic BaseModel and Dendrite retur
ns it in that format with one simple function call. Built on top of playwright for a robust experience. This is an easy 
way to give your AI agents the same web browsing capabilities as humans have. Integrates easily with frameworks such as 
 Langchain, CrewAI, Llamaindex and more.

I’m planning on **open sourcing** everything the coming month so feel free to 
reach out if you’re interested in contributing

Github: [https://github.com/dendrite-systems/dendrite-python-sdk](https:
//github.com/dendrite-systems/dendrite-python-sdk)  
Demo: [https://www.youtube.com/watch?v=yChAUerKKxo](https://www.you
tube.com/watch?v=yChAUerKKxo&feature=youtu.be)
```
---

     
 
all -  [ How to chunk effectively on very large pdf file (a book for example) ? ](https://www.reddit.com/r/LangChain/comments/1gkx5kn/how_to_chunk_effectively_on_very_large_pdf_file_a/) , 2024-11-07-0912
```
Hi everyone,

I'm new to LLM and RAG. I had built RAG once, but the data source is limited to PDF with a few pages only,
 when I try to scale the source to a book of hundreds of pages (world of warcraft lore), the retrieval result is not goo
d. I have tried with semantic chunking, but the speed is too slow, and the result is not better than recursive chunking.


I'm thinking on using another language model to summarize each chapter, but i think it may cause misinformation, since
 some small details can be bypass in this stage.

Are there any methods you guys know about ? Or some papers to solve th
is problem ?

Thanks everyone.
```
---

     
 
all -  [ Easiest way to launch paid AI tools/wrappers? ](https://www.reddit.com/r/startups/comments/1gkx0cm/easiest_way_to_launch_paid_ai_toolswrappers/) , 2024-11-07-0912
```
**I want to create a few simple AI tools** (similar to twitterbio.io for example). Basically I get text from the user an
d based on custom prompts/instructions I give them ideas (text generated with an AI API). I might want to accept also UR
Ls, images and PDFs as inputs.

Some of my tools will be free and open. Others will be paid (monthly subscription), so *
*I need payments, authentication, etc.**

**I guess the quickest option would be to use some boilerplate or template**. 
I’ve done some research, but I’m completely lost between dozens of options: SaaS boilerplates, AI-specific boilerplates,
 Github templates from Vercel/Langchain/others, templates or kits from Backend as a Service providers (Supabase/Firebase
), frameworks with many “batteries included” such as Laravel…

I know some basic Python and HTML/CSS. Nothing else. I wa
nt to learn and also experiment with AI coding helpers (Cursor? Replit AI? v0?), but not spend several months before lau
nching if possible. So **I want something easy to start, but also flexible** (being able to add features and make change
s in the future without having to “fight” with the limitations of a certain boilerplate or whatever).

**What do you rec
ommend?**

General advice and specific tools are both welcomed ;)
```
---

     
 
all -  [ SupabaseVectoreStore ](https://www.reddit.com/r/LangChain/comments/1gkvhjc/supabasevectorestore/) , 2024-11-07-0912
```
Hello , i'm using langchain js along with Supabase,   
let me give you simple example   


    const vectoreStore = new 
SupabaseVectorStore(embedings , {
        client , tableName :'documents' , queryName : 'match_documents'
    });
    co
nst 
    retriever 
    =    vectoreStore.asRetriever(null,{ metadataField: 'value' });

when documents table has more t
han 5000 record i have an erreur  
Error: Error searching for documents: 57014 canceling statement due to statement time
out null

which trigger right away and not after the supabase default timeout 2s. 

I have looked into documentation i d
ont see anything related to 5000 records limits  ( Im Free tier ) 

worthy to not this is not related to tHe max Rows 10
00  related to supabase setting  


```
---

     
 
all -  [ OpenAI history compression ](https://www.reddit.com/r/LangChain/comments/1gkv200/openai_history_compression/) , 2024-11-07-0912
```
Hi,

I'm trying to build a prompt compression logic using vector embeddings and similarity search. My goal is to save to
kens by compressing conversation history, keeping only the most relevant parts based on the user's latest query. This wo
uld be particularly useful when approaching token limits in consecutive messages.

I was wondering if something like thi
s has already been implemented, perhaps in a cookbook or similar resource, instead of writing my own crappy solution. Is
 this even considered a common approach? Ideally, I'm looking for something that takes OpenAI messages format as input a
nd outputs the same structured messages with irrelevant context redacted.
```
---

     
 
all -  [ Looking for tech-cofounder with in-depth experience of large AI-RAG systems in production with advan ](https://www.reddit.com/r/LangChain/comments/1gkuul5/looking_for_techcofounder_with_indepth_experience/) , 2024-11-07-0912
```
**I am building an AI system to solve this problem using Advanced RAG:** In anybody's professional field say SEO, AI, Fi
nance and many others, new content is published everyday covering news, solutions, techniques and others. Keeping abreas
t with such explosion of content is humanly not possible. Lot of content has overlapping, repeated and even pieces of kn
owledge that you are already familiar with and so on. Anybody is mostly interested in unique, fresh pieces of knowledge,
 those nuggets and gems of knowledge not known to them already, without countless hours of reading / watching videos etc
.

If you are interested in building a solution for this along with me and have in-depth experience of building advanced
 RAG systems in production and scaling them, please connect.
```
---

     
 
all -  [ Need help/suggestion: So I want to use an LLM to evaluate human and AI models responses to medical q ](https://www.reddit.com/r/LangChain/comments/1gkuk2s/need_helpsuggestion_so_i_want_to_use_an_llm_to/) , 2024-11-07-0912
```
I want to know what would be the best way of doings, what should be my approach?. I want to compare how good or bad are 
the responses of AI model compare to the human ones. 
```
---

     
 
all -  [ My Rag chatbot suddenly started giving no/unmatched responses... ](https://www.reddit.com/r/LangChain/comments/1gku4dd/my_rag_chatbot_suddenly_started_giving/) , 2024-11-07-0912
```
Hi guys,   
I have developed a RAG-based chatbot( Retriever - Cohere; VectorDB - ChromaDB; memory chain - conversational
 buffer memory; LLM - Mistral 7b Instruct (inference API); Front end - Flask)... It gave an excellent response maybe a w
eek back, but now when I ask questions, it is not even showing any responses. It sometimes gives the answer, but for the
 follow-up questions, its not give any answer and the memory also becomes empty.... I don't know where the problem is an
d where to proceed to solve it... Pls help me rectify it, if u want any other information regarding the implementations,
 I will send it...
```
---

     
 
all -  [ Stop pandas dataframe agent from timing out ](https://www.reddit.com/r/LangChain/comments/1gkt383/stop_pandas_dataframe_agent_from_timing_out/) , 2024-11-07-0912
```
I have two columns in two dataframes which I need to compare, which I am doing using a pandas dataframe agent. Now one o
f the dataframes is around 700 rows long, and the other is small, but the token limit is being breached, unless I make t
he other dataframe smaller. Does anyone have any ideas on how to approach this?
```
---

     
 
all -  [ How to Combine RAG and Function Calling for a Hybrid Chatbot? ](https://www.reddit.com/r/LangChain/comments/1gksk4g/how_to_combine_rag_and_function_calling_for_a/) , 2024-11-07-0912
```
I'm building a chatbot using RAG to answer general information queries for a health-related website, such as 'What are c
ommon symptoms of high blood pressure?' or 'How does a balanced diet benefit mental health?' These are publicly availabl
e answers that don’t require user-specific information.

However, I also want the bot to handle member-specific requests
, like 'Show my latest lab results' or 'When is my next scheduled appointment?' For these personalized queries, I plan t
o use OpenAI's function calling to connect with an external API and fetch user-specific data securely.

  
I'm looking f
or advice on how to structure this system so that it can:

1. **Accurately classify** incoming queries as either general
 information (handled by RAG) or user-specific (requiring function calling).
2. **Route queries accordingly** to either 
the RAG model or an API call, without requiring user intervention.
```
---

     
 
all -  [ Open-source declarative framework to build LLM apps - looking for contributors ](https://www.reddit.com/r/developersIndia/comments/1gkq6y9/opensource_declarative_framework_to_build_llm/) , 2024-11-07-0912
```
I've been building LLM-based applications, and was super frustated with all major frameworks - langchain, autogen, crewA
I, etc. They also seem to introduce a pile of unnecessary abstractions. It becomes super hard to understand what's going
 behind the curtains even for very simple stuff.

[So I just published this open-source framework GenSphere.](https://gi
thub.com/octopus2023-inc/gensphere) The idea is have something like **Docker for LLMs**. You build applications with YAM
L files, that define an execution graph. Nodes can be either LLM API calls, regular function executions or other graphs 
themselves. Because you can nest graphs easily, building complex applications is not an issue, but at the same time you 
don't lose control.

You basically code in YAML, stating what are the tasks that need to be done and how they connect. O
ther than that, you only write individual python functions to be called during the execution. No new classes and abstrac
tions to learn.

Its all open-source. **Now I'm looking for contributors** to adapt the framework for cycles and conditi
onal nodes - which would allow full-fledged agentic system building. Anyone interested? Pls reach out  if you want to co
ntribute, there are tons of things to do!

PS: [you can read the detailed docs here,](https://gensphere.readthedocs.io/e
n/latest/) And go over this quick [Google Colab tutorial.](https://github.com/octopus2023-inc/gensphere/blob/main/exampl
es/gensphere_tutorial.ipynb)
```
---

     
 
all -  [ [P] Open-source declarative framework to build LLM applications - looking for contributors ](https://www.reddit.com/r/MachineLearning/comments/1gkpazh/p_opensource_declarative_framework_to_build_llm/) , 2024-11-07-0912
```
I've been building LLM-based applications, and was super frustated with all major frameworks - langchain, autogen, crewA
I, etc. They also seem to introduce a pile of unnecessary abstractions. It becomes super hard to understand what's going
 behind the curtains even for very simple stuff.

[So I just published this open-source framework GenSphere.](https://gi
thub.com/octopus2023-inc/gensphere) The idea is have something like **Docker for LLMs**. You build applications with YAM
L files, that define an execution graph. Nodes can be either LLM API calls, regular function executions or other graphs 
themselves. Because you can nest graphs easily, building complex applications is not an issue, but at the same time you 
don't lose control.

You basically code in YAML, stating what are the tasks that need to be done and how they connect. O
ther than that, you only write individual python functions to be called during the execution. No new classes and abstrac
tions to learn.

Its all open-source. **Now I'm looking for contributors** to adapt the framework for cycles and conditi
onal nodes - which would allow full-fledged agentic system building! Pls reach out  if you want to contribute, there are
 tons of things to do!

PS: [you can read the detailed docs here,](https://gensphere.readthedocs.io/en/latest/) And go o
ver this quick [Google Colab tutorial.](https://github.com/octopus2023-inc/gensphere/blob/main/examples/gensphere_tutori
al.ipynb)
```
---

     
 
all -  [ PDF chat with source highlight ](https://www.reddit.com/r/LangChain/comments/1gkkm74/pdf_chat_with_source_highlight/) , 2024-11-07-0912
```
We’ve released **Denser Chat** as an open-source project! You can chat with your uploaded PDF with source highlighted. 


Check it out on GitHub: [https://github.com/denser-org/denser-chat](https://github.com/denser-org/denser-chat)

✨ Extra
ct text & tables from PDFs  
🤖 Build chatbots with [denser-retriever](https://github.com/denser-org/denser-retriever)  

💬 Interactive Streamlit app w/ PDF source highlights

Boost transparency & power up your AI projects! 💼 #opensource #AI 
#DenserChat
```
---

     
 
all -  [ How to use a pgvector db as a retriever in a chain? ](https://www.reddit.com/r/LangChain/comments/1gkibvy/how_to_use_a_pgvector_db_as_a_retriever_in_a_chain/) , 2024-11-07-0912
```
Apologies if some of this doesn't make sense, I'm pretty new to Python and Langchain so please bear with me. 

Earlier t
his year I created a simple RAG chatbot using Langchain and Chainlit. The embeddings were stored in a pgvector enabled P
ostgres database in GCP Cloud SQL. I packaged it up in a container and hosted it on GCP Cloud Run. It worked great.

I'm
 trying to create a new chatbot using a new dataset but the same architecture as the previous one. I've updated Langchai
n and it seems some of the code from my previous chatbot is no longer working. Here's the portion I'm struggling with. T
his is a bit of code from the OLD chatbot that worked fine:

    store = PGVector(
        collection_name=COLLECTION_NA
ME,
        connection_string=CONNECTION_STRING,
        embedding_function=embeddings,
    )
    
    retriever = store
.as_retriever()
    
    template = '''My system prompt
    Context: {context}
    Question: {question}
    '''    
    

    prompt = ChatPromptTemplate.from_template(template)
        
    chain = (
        {'context': retriever, 'question
': RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser())

I should also point out that the above chatbo
t was written for Gemini, prior to when Gemini supported a system prompt so I had to convert the first human message to 
system.

Here's the same bit of code from the NEW chatbot that I'm trying to create. I'm using a different ChatPromptTem
plate method because Gemini now supports a system prompt and from\_messages is giving me better results than from\_templ
ate. So the only thing that has changed is changing the ChatPromptTemplate from from\_template to from\_messages, but no
w I'm not sure how to structure the actual chain. I've tried a few things but nothing is working. Any ideas?

I also wan
t to point out that the code below works perfectly fine as-is (well, the entire file obviously), without the retriever. 
I can do a chainlit run [main.py](http://main.py) on this file and it launches Chainlit and I can have a conversation wi
th Gemini. The only thing I'm struggling with is how to insert the retriever into the chain.



    store = PGVector(
  
      collection_name-COLLECTION_NAME,
        connection_string=CONNECTION_STRING,
        embedding_function=embedding
s,
    )
    
    retriever = store.as_retriever()
    
    system_template = '''My system template'''
    
    prompt_t
emplate = ChatPromptTemplate.from_messages(
        [('system', system_template), ('user', '{text}')]
    )
    
    run
nable = prompt_template | model | StrOutputParser()
```
---

     
 
all -  [ Check out EidolonAI, an open-source framework for AI agents ](https://www.reddit.com/r/agenticAI/comments/1gkhvsd/check_out_eidolonai_an_opensource_framework_for/) , 2024-11-07-0912
```
Hey folks!

[Eidolon AI](https://github.com/eidolon-ai/eidolon) is an open-source project devoted to making agent develo
pment simpler. It's not uncommon for us to write a demo with about 20% of the code you'd need to do the same with Llama 
or Langchain.

We're on the lookout for developers looking at the options available to them, and any potential contribut
ors as well.

August Data, the sponsors for this project, have been working on this framework for three years and is now
 looking for investors and 'interesting' customers.

Come give us a look-see. We're always looking for stars to the repo
 as well to gain a broader audience. No hidden fees or fine print! You give the repo a star, we thank you thank you than
k you, everyone feels good!
```
---

     
 
all -  [ Dendrite: Interact with websites with natural language instead of using css selectors ](https://www.reddit.com/r/Python/comments/1gkg23q/dendrite_interact_with_websites_with_natural/) , 2024-11-07-0912
```
**What my project does:**

**Dendrite** is a simple framework for interacting with websites using natural language. Inte
ract and extract without having to find brittle css selectors or xpaths like this:

    browser.click(“the sign in butto
n”)

For the developers who like their code typed, specify what data you want with a Pydantic BaseModel and Dendrite ret
urns it in that format with one simple function call. Built on top of playwright for a robust experience. This is an eas
y way to give your AI agents the same web browsing capabilities as humans have. Integrates easily with frameworks such a
s  Langchain, CrewAI, Llamaindex and more. 

We are planning on **open sourcing** everything soon as well so feel free t
o reach out to us if you’re interested in contributing!

Github: [https://github.com/dendrite-systems/dendrite-python-sd
k](https://github.com/dendrite-systems/dendrite-python-sdk)

**Overview**

* **Authenticate Anywhere**: Dendrite Vault, 
our Chrome extension, handles secure authentication, letting your agents log in to almost any website.
* **Interact Natu
rally**: With natural language commands, agents can click, type, and navigate through web elements with ease.
* **Extrac
t and Manipulate Data**: Collect structured data from websites, return data from different websites in the same structur
e without having to maintain different scripts.
* **Download/Upload Files**: Effortlessly manage file interactions to an
d from websites, equipping agents to handle documents, reports, and more.
* **Resilient Interactions**: Dendrite's inter
actions are designed to be resilient, adapting to minor changes in website structure to prevent workflows from breaking

* **Full Compatibility**: Works with popular tools like LangChain and CrewAI, letting you seamlessly integrate Dendrite’
s capabilities into your AI workflows.

**Target Audience:**

* Automation developers
* Webscraping people
* Web AI agen
t developers
* QA engineers

**Comparison:**

There are some frameworks for scraping information from websites with natu
ral language prompts but there are no real alternatives when it comes to interacting with the websites as well as access
ing data behind authentication. The most similar alternative would be something like Multion or some other fully autonom
ous agent framework that doesn't really work
```
---

     
 
all -  [ Infinit Craft with Kobold ](https://www.reddit.com/r/KoboldAI/comments/1gkfur6/infinit_craft_with_kobold/) , 2024-11-07-0912
```
    Infinit Craft with Kobold
    The code is based on https://github.com/githubpradeep/notebooks/blob/main/Infinite%20c
raft%20game-1.ipynb
    tested with https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/blob/main/Meta-Lla
ma-3-8B-Instruct.Q8_0.gguf
    
    from langchain.output_parsers import PydanticOutputParser
    from langchain.prompts
 import PromptTemplate
    from langchain_core.messages import HumanMessage
    from pydantic import BaseModel, Field
  
  from langchain_community.llms import KoboldApiLLM
    
    
    class Craft(BaseModel):
        word: str = Field(desc
ription='the new word which was created')
    
    
    class Crafter:
        def __init__(self, local=False):
    
   
         llm = KoboldApiLLM(endpoint='http://localhost:5001/', temperature=0.8, max_length=48)
            parser = Pyda
nticOutputParser(pydantic_object=Craft)
    
            prompt = PromptTemplate(
                template='Answer the u
ser query.\n{format_instructions}\n{query}\n',
                input_variables=['query'],
                partial_variab
les={'format_instructions': parser.get_format_instructions()},
            )
    
            chain = prompt | llm | par
ser
            self.chain = chain
    
        def craft(self, word1, word2):
            while True:
                t
ry:
    
                    ans = self.chain.invoke({'query': f'''You are an AI that combines words to create meaningfu
l new words. Always respond as JSON with no unnecessary information.
                    For example:
                  
  Earth + Wind = Dust
                    Fire + Water = Steam
                    Earth + Water = Plant
               
     Dust + Earth = Planet
                    Plant + Steam = Tea
                    Planet + Wind = Storm
           
         Storm + Tea = Tempest
                    Plant + Tempest = Tree
                    Dust + Tree = Wood
       
             Fire + Wood = Campfire
                    Dust + Water = Mud
                    Campfire + Earth = Charco
al
                    Charcoal + Mud = Fossil
                    Water + Fire = Steam
                    Wind + Steam
 = Cloud
                    {word1} + {word2} ='''})
                    return ans.word
                except:
      
              continue
    import pygame
    import sys
    
    
    pygame.init()
    
    screen_width, screen_height
 = 1024, 576
    screen = pygame.display.set_mode((screen_width, screen_height))
    pygame.display.set_caption('Infinit
e Craft')
    
    
    background_color = (255, 255, 255)
    text_color = (0, 0, 0)
    box_color = (200, 200, 200)
  
  sidebar_color = (100, 100, 100)
    element_color = (160, 160, 160)
    element_text_color = text_color  # (255, 255, 
255)
    font_size = 24
    font = pygame.font.Font(None, font_size)
    
    # Element combinations
    combinations = 
{
        ('Fire', 'Water'): 'Steam',
        # Add more combinations as needed
    }
    
    sidebar_elements = ['Fire
', 'Water', 'Earth', 'Wind', 'Soil', 'Seed']
    sidebar_rects = []
    
    elements = []
    
    
    class TextBox:

        def __init__(self, text, pos, from_sidebar=False):
            self.text = text
            self.pos = pos
     
       self.rect = pygame.Rect(pos[0], pos[1], 120, 40)
            self.dragging = False
            self.from_sidebar 
= from_sidebar
    
        def draw(self, screen):
            draw_bordered_rounded_rect(screen, self.rect, box_color,
 box_color, 3, 5)
            # pygame.draw.rect(screen, element_color, self.rect,1,1)
            text_surface = font.r
ender(self.text, True, element_text_color)
            screen.blit(text_surface, (self.rect.x + 10, self.rect.y + 10))
 
   
        def handle_event(self, event):
            if event.type == pygame.MOUSEBUTTONDOWN:
                if self.
rect.collidepoint(event.pos):
                    self.dragging = True
                    self.offset_x = self.rect.x -
 event.pos[0]
                    self.offset_y = self.rect.y - event.pos[1]
    
            elif event.type == pygame.
MOUSEBUTTONUP:
                self.dragging = False
                if self.from_sidebar:
                    # Snap ba
ck to sidebar if it's not dragged into the main area
                    if not (200 < self.rect.x < screen_width):
    
                    elements.remove(self)
                    else:
                        self.from_sidebar = False
  
          elif event.type == pygame.MOUSEMOTION:
                if self.dragging:
                    self.rect.x = eve
nt.pos[0] + self.offset_x
                    self.rect.y = event.pos[1] + self.offset_y
    
    
    def init_sidebar(
):
        y = 100
        sidebar_rects = []
        for element in sidebar_elements:
            rect = pygame.Rect(25
, y, 150, 30)
            sidebar_rects.append(rect)
            y += 50
        return sidebar_rects
    
    
    side
bar_rects = init_sidebar()
    
    import pygame
    import sys
    
    pygame.init()
    
    screen_width, screen_he
ight = 800, 600
    screen = pygame.display.set_mode((screen_width, screen_height))
    
    WHITE = (255, 255, 255)
   
 GREY = (200, 200, 200)
    DARK_GREY = (100, 100, 100)
    
    font = pygame.font.Font(None, 30)
    
    sidebar_widt
h = 200
    sidebar_content_height = 5000  # Example content height
    scroll_y = 0  # Scroll position
    import pygam
e.gfxdraw
    
    
    def draw_rounded_rect(surface, rect, color, corner_radius):
        
    ''' Draw a rectangle wi
th rounded corners.
        Would prefer this:
            pygame.draw.rect(surface, color, rect, border_radius=corner_r
adius)
        but this option is not yet supported in my version of pygame so do it ourselves.
        We use anti-alia
sed circles to make the corners smoother
        '''
        
    if rect.width < 2 * corner_radius or rect.height < 2 *
 corner_radius:
            raise ValueError(
                f'Both height (rect.height) and width (rect.width) must be
 > 2 * corner radius ({corner_radius})')
    
        # need to use anti aliasing circle drawing routines to smooth the 
corners
        pygame.gfxdraw.aacircle(surface, rect.left + corner_radius, rect.top + corner_radius, corner_radius, col
or)
        pygame.gfxdraw.aacircle(surface, rect.right - corner_radius - 1, rect.top + corner_radius, corner_radius, co
lor)
        pygame.gfxdraw.aacircle(surface, rect.left + corner_radius, rect.bottom - corner_radius - 1, corner_radius,
 color)
        pygame.gfxdraw.aacircle(surface, rect.right - corner_radius - 1, rect.bottom - corner_radius - 1, corner
_radius,
                                color)
    
        pygame.gfxdraw.filled_circle(surface, rect.left + corner_ra
dius, rect.top + corner_radius, corner_radius, color)
        pygame.gfxdraw.filled_circle(surface, rect.right - corner_
radius - 1, rect.top + corner_radius, corner_radius,
                                     color)
        pygame.gfxdraw.
filled_circle(surface, rect.left + corner_radius, rect.bottom - corner_radius - 1, corner_radius,
                      
               color)
        pygame.gfxdraw.filled_circle(surface, rect.right - corner_radius - 1, rect.bottom - corner
_radius - 1,
                                     corner_radius, color)
    
        rect_tmp = pygame.Rect(rect)
    
 
       rect_tmp.width -= 2 * corner_radius
        rect_tmp.center = rect.center
        pygame.draw.rect(surface, color
, rect_tmp)
    
        rect_tmp.width = rect.width
        rect_tmp.height -= 2 * corner_radius
        rect_tmp.cente
r = rect.center
        pygame.draw.rect(surface, color, rect_tmp)
    
    
    def draw_bordered_rounded_rect(surface,
 rect, color, border_color, corner_radius, border_thickness):
        if corner_radius < 0:
            raise ValueError
(f'border radius ({corner_radius}) must be >= 0')
    
        rect_tmp = pygame.Rect(rect)
        center = rect_tmp.ce
nter
    
        if border_thickness:
            if corner_radius <= 0:
                pygame.draw.rect(surface, bord
er_color, rect_tmp)
            else:
                draw_rounded_rect(surface, rect_tmp, border_color, corner_radius)

    
            rect_tmp.inflate_ip(-2 * border_thickness, -2 * border_thickness)
            inner_radius = corner_rad
ius - border_thickness + 1
        else:
            inner_radius = corner_radius
    
        if inner_radius <= 0:
   
         pygame.draw.rect(surface, color, rect_tmp)
        else:
            draw_rounded_rect(surface, rect_tmp, color
, inner_radius)
    
    
    def draw_sidebar(screen, sidebar_rects, scroll_y):
        pygame.draw.rect(screen, sideba
r_color, [0, 0, 200, screen_height], 1, 1)
        scrollable_area = pygame.Rect(0, scroll_y, sidebar_width, sidebar_con
tent_height)
    
        for idx, rect in enumerate(sidebar_rects):
            rect.y += scrollable_area.y
           
 draw_bordered_rounded_rect(screen, rect, box_color, box_color, 3, 5)
            text_surface = font.render(sidebar_ele
ments[idx], True, text_color)
            screen.blit(text_surface, (rect.x + 5, rect.y + 5))
    
    
    crafter = Cr
after()
    
    
    def merge_elements(elements, sidebar_elements):
        for i, elem1 in enumerate(elements):
     
       for j, elem2 in enumerate(elements):
                if i != j:  # Ensure not checking the same element
         
           if elem1.rect.colliderect(elem2.rect):  # Check for collision
                        if not elem1.from_sideb
ar and not elem2.from_sidebar:
                            # Concatenate the text to create a new element
              
              new_text = crafter.craft(elem1.text, elem2.text)
                            # new_text = elem1.text+ elem
2.text
                            if new_text not in sidebar_elements:
                                sidebar_elements
.append(new_text)
                            new_pos = (elem1.pos[0], elem1.pos[1])
                            # Creat
e the new element and add it to the list
                            new_element = TextBox(new_text, elem1.pos)
        
                    new_element.rect.x = elem1.rect.x
                            new_element.rect.y = elem1.rect.y
    
                        elements.append(new_element)
                            elements.remove(elem1)
                
            elements.remove(elem2)
                            return
    def main():
        offset = 0
        scroll_
y = 0
        scroll_speed = 1
        clock = pygame.time.Clock()
        running = True
        running = True
       
 clock = pygame.time.Clock()
    
        while running:
            for event in pygame.event.get():
                if
 event.type == pygame.QUIT:
                    running = False
                elif event.type == pygame.MOUSEBUTTONDOW
N:
    
                    if event.button == 1:
                        for idx, rect in enumerate(sidebar_rects):
   
                         if rect.collidepoint(event.pos):
                                elements.append(TextBox(sideba
r_elements[idx], event.pos, from_sidebar=True))
                                break
                elif event.type ==
 pygame.MOUSEWHEEL:
                    scroll_y += event.y * 10
                    # Limit scrolling
                 
   scroll_y = min(0, max(-(sidebar_content_height - screen_height), scroll_y))
    
                for element in eleme
nts:
                    element.handle_event(event)
    
            sidebar_rects = init_sidebar()
    
            me
rge_elements(elements, sidebar_elements)
    
            screen.fill(background_color)
            draw_sidebar(screen,
 sidebar_rects, scroll_y)
    
            for element in elements:
                element.draw(screen)
    
          
  pygame.display.flip()
            clock.tick(30)
    
        pygame.quit()
        sys.exit()
    
    
    if __name
__ == '__main__':
        main()
```
---

     
 
all -  [ Better way to retrieve function definitions from codebase (vector embeddings)? ](https://www.reddit.com/r/LangChain/comments/1gkc7ug/better_way_to_retrieve_function_definitions_from/) , 2024-11-07-0912
```
I have created vector embeddings of codebase (C/C++ files) and stored them, using the tree sitter and Generic Loader fro
m langchain, by referring this

https://python.langchain.com/docs/integrations/document_loaders/source_code/

Currently 
I'm using db.as_retriever({search_type='mmr'}) for retrieving the function definitions (because most of the queries will
 be dependent of their definition: find the bug in abc_function) and for some of the functions it is working as expected
 since those functions aren't used much in the codebase, so retrieving the correct chunk is easier with them, but the fu
nctions which are called in multiple functions, for them this retriever isn't able to retrieve their function definition
s

Are there any specific retrievers for the codebase? Like tree-sitter is for parsing the codebase?
```
---

     
 
all -  [ YouTube video summarizer and post generator ](https://www.reddit.com/r/SaaS/comments/1gk9a8x/youtube_video_summarizer_and_post_generator/) , 2024-11-07-0912
```
I have developed a tool which takes url of YouTube video and can summarize it, generate a blog post, generate a linkedin
 post. The target market is Youtubers, marketing agencies, bloggers, and other content creators
I want to sell this tool
 which is developed using python, langchain, streamlit for UI, crewai, ChatGroq. If anyone are interested in acquiring t
his tool and want to convert it into their own SaaS tool for making good revenue please contact me
```
---

     
 
all -  [ Need help ! ](https://www.reddit.com/r/Supabase/comments/1gk877a/need_help/) , 2024-11-07-0912
```
I do have an app using langchain js along Supabase , I have an issue when i'm using SupabaseVectoreStore on a specific t
able , if that table has more than 5000 records , it returns timeout error 

# Error code: 57014: Canceling Statement Du
e To Statement Timeout

  
this happen right away not after the 2 min timeout, maybe i need to mention i'm using the Fre
e tier.

I could'nt find anything on the documentations.
```
---

     
 
all -  [ IBM release Agentic Framework 'Bee' ](https://www.reddit.com/r/LangChain/comments/1gk7z5v/ibm_release_agentic_framework_bee/) , 2024-11-07-0912
```
[https://i-am-bee.github.io/bee-agent-framework/#/](https://i-am-bee.github.io/bee-agent-framework/#/)
```
---

     
 
all -  [ 🌲Hierarchical Indices: Enhancing RAG Systems ](https://open.substack.com/pub/diamantai/p/hierarchical-indices-enhancing-rag?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true) , 2024-11-07-0912
```
📚 Hierarchical indices are an advanced method for organizing information in RAG systems. Unlike traditional flat structu
res, they use a multi-tiered approach typically consisting of:

1. Top-level summaries
2. Mid-level overviews
3. Detaile
d chunks

✨ This hierarchical structure helps overcome common RAG limitations by:
• Improving context understanding 
• B
etter handling complex queries
• Enhancing scalability
• Increasing answer relevance

Attached is the full blog describi
ng it, which includes link to code implementation as well ☺️
```
---

     
 
all -  [ Built a LangChain integration that solves the multi-system customer data problem (with fuzzy matchin ](https://www.reddit.com/r/LangChain/comments/1gk35pf/built_a_langchain_integration_that_solves_the/) , 2024-11-07-0912
```
Hey r/LangChain,

We built a LangChain integration that solves one of the biggest headaches in building customer-facing 
LLM apps: getting a single, accurate view of customer data across all your systems.

-Combines data from Hubspot, Salesf
orce, Zendesk, Snowflake, databases etc. using fuzzy matching
-Creates and updates unified customer profiles in real-tim
e
-Plugs right into LangChain for building customer support bots that actually know your customers

We built this becaus
e we found lots of companies struggling with internal LLM apps when the customer data existed somewhere in their data st
ack - just not in one place. The fuzzy matching handles all the messy real-world data issues (typos, different formats, 
etc.).

If you want to give it a shot:

Demo repo: https://github.com/tilotech/identity-rag-customer-insights-chatbot
Th
ere is a demo video showing it in action at the same link

For anyone in Berlin - we're doing a hands-on session with La
ngChain and AWS next week: https://www.meetup.com/unstructured/events/304128662/. In-person only for now, but might stre
am if there's interest (drop a comment if you'd watch!).

I would love to hear your thoughts/feedback, especially if you
've tackled similar problems before!
```
---

     
 
all -  [ Udemy Free Courses for 05 November 2024 ](https://www.reddit.com/r/udemyfreebies/comments/1gk2uqc/udemy_free_courses_for_05_november_2024/) , 2024-11-07-0912
```
# Udemy Free Courses for 05 November 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the
 courses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22567/)Ace the ISTQB CTFL AT Agile Tester Mock E
xams & Explanations
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22566/)LLM Pentesting: Mastering Security Testin
g for AI Models
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22565/)E20-555: Dell EMC Isilon Solution and Design 
Specialist Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22564/)E20-393: Dell EMC Unity Solution Specialist P
ractice test 24
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22563/)DES-1D12: Dell EMC Specialist – Midrange Stor
age Solutions
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22562/)DES-1423: Dell EMC Specialist Isilon Solution P
ractice test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22561/)NSE7\_ZTA-7.2: Fortinet Network Security Expert 
Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22560/)NSE7\_SDW-7.2: Fortinet Network Security Expert
 Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22559/)NSE7\_SDW-7.0: Fortinet Network Security Exper
t Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22558/)NSE7\_SDW-6.4: Fortinet Network Security Expe
rt Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22557/)Generative AI for All: Practical Prompt Engi
neering Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22556/)Shopify: Your Essential Guide to E-commerce Su
ccess
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22555/)Facebook Ads 2024: Launch Your Best Advertising Campaig
n
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22554/)Build Your Best Cold Email Strategy!
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/22553/)Grow your business with Chatbot Marketing!
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/22552/)Blogging and Influencer Marketing
* Complete Figma Course: Web & Mobile Projects from Scratch
* [REDE
EM OFFER](https://idownloadcoupon.com/udemy/22551/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22550/)Executive
 Assistant Professional Certification (EAPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22549/)Timeboxing: A Sh
ort and Practical Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22548/)BANXIETY: Beginner and Beyond Breathi
ng for Anxiety
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22547/)The Complete Manager: Management Skills Guide 
for Beginners
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22546/)Managing a business with business analytics and
 frameworks
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22545/)HTML For Beginners
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/22544/)Automatiza YouTube al 100% con IA
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22543
/)Secretary Professional Certification (SPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22542/)Master Splits & 
Conditioning for Martial or Performance Arts
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22541/)Luxury Industry 
Professional Certification (LIPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22540/)C# desde 0: Inicia tu carre
ra como programador
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22539/)Paralegal Professional Certification (PPC
)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22537/)The Complete Video Editing Masterclass with Vegas Pro
* [RE
DEEM OFFER ](https://idownloadcoupon.com/udemy/22536/)Executive Diploma in Business Management
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/22535/)CLF-C01: AWS Certified Cloud Practitioner Practice test 2024
* DBS-C01: AWS Certified 
Database Specialty Practice Test 2024
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/22534/)
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/22533/)DOP-C01: AWS Certified DevOps Engineer Practice test 2024
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/22532/)Google SEO Guide: How to Rank First on Google
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/22531/)The Ultimate Google Analytics 4 Course – Complete Guide 2024
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/22530/)C++ Beginner to Advanced: Modern C++20 and Multithreading
* [REDEEM OFFER ](https://idownloadcoupon.co
m/udemy/22529/)Python Machine Learning: From Beginner to Pro
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22528/)
Build a WordPress Blog Website Step by Step
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22527/)Instagram Marketi
ng Course: Fastest ways to grow your page
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22526/)User Experience Des
ign – Learn UI UX App Design with Figma
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22525/)Beginning Bash Script
ing
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22524/)Ethical Hacking: Hacker Methodology
* [REDEEM OFFER ](htt
ps://idownloadcoupon.com/udemy/22523/)Interview Success: Business English for Job interviews
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/22522/)Business Process Management: Certification
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/22521/)15 Günde Anne Sütü Mucizesi: Beslenme Rehberiniz
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22520
/)Office Administration Management Professional Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22519/
)C-level management: 20 models for business operations (2/5)
* Growth Hacking Professional Certification (GHPC)
* [REDEE
M OFFER](https://idownloadcoupon.com/udemy/22518/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22517/)The Comple
te JavaScript Course: From Zero to Expert
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22516/)Selenium Webdriver 
with Java & TestNG Testing Framework
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22515/)सीखें WordPress हिन्दी म
ें
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22514/)Certified Culinarian Practice Exam
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/22513/)The Complete C++ Programming Course from Basic to Expert
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/22512/)Next.js for Beginners : The Complete Guide 2024
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/22511/)Python And Django Framework For Beginners Complete Course
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/22510/)AWS Certified Machine Learning Specialty 2024 – Hands On!
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/22509/)Ultimate AWS Certified Solutions Architect Associate (SAA)
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/22508/)x64dbg Script Programming For Reverse Engineering
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22507/)
F5 101 Exam Preparation – Complete Course w/ Practice Exams
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22506/)2
025 Master Langchain and Ollama – Chatbot, RAG and Agents
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22505/)Unb
ounce: Create Landing Pages that Convert + A/B Testing
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22504/)Cómo C
rear una Tienda Online con Blogger Desde Cero 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22503/)Herramient
as de Google 2024, ¡Desde Cero Hasta Experto!

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://www.
reddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ Udemy Free Courses for 05 November 2024 ](https://www.reddit.com/r/udemyfreeebies/comments/1gk2unl/udemy_free_courses_for_05_november_2024/) , 2024-11-07-0912
```
# Udemy Free Courses for 05 November 2024

Note : Coupons might expire anytime, so enroll as soon as possible to get the
 courses for FREE.

* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22567/)Ace the ISTQB CTFL AT Agile Tester Mock E
xams & Explanations
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22566/)LLM Pentesting: Mastering Security Testin
g for AI Models
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22565/)E20-555: Dell EMC Isilon Solution and Design 
Specialist Exam
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22564/)E20-393: Dell EMC Unity Solution Specialist P
ractice test 24
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22563/)DES-1D12: Dell EMC Specialist – Midrange Stor
age Solutions
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22562/)DES-1423: Dell EMC Specialist Isilon Solution P
ractice test
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22561/)NSE7\_ZTA-7.2: Fortinet Network Security Expert 
Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22560/)NSE7\_SDW-7.2: Fortinet Network Security Expert
 Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22559/)NSE7\_SDW-7.0: Fortinet Network Security Exper
t Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22558/)NSE7\_SDW-6.4: Fortinet Network Security Expe
rt Practice 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22557/)Generative AI for All: Practical Prompt Engi
neering Course
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22556/)Shopify: Your Essential Guide to E-commerce Su
ccess
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22555/)Facebook Ads 2024: Launch Your Best Advertising Campaig
n
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22554/)Build Your Best Cold Email Strategy!
* [REDEEM OFFER ](http
s://idownloadcoupon.com/udemy/22553/)Grow your business with Chatbot Marketing!
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/22552/)Blogging and Influencer Marketing
* Complete Figma Course: Web & Mobile Projects from Scratch
* [REDE
EM OFFER](https://idownloadcoupon.com/udemy/22551/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22550/)Executive
 Assistant Professional Certification (EAPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22549/)Timeboxing: A Sh
ort and Practical Guide
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22548/)BANXIETY: Beginner and Beyond Breathi
ng for Anxiety
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22547/)The Complete Manager: Management Skills Guide 
for Beginners
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22546/)Managing a business with business analytics and
 frameworks
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22545/)HTML For Beginners
* [REDEEM OFFER ](https://idow
nloadcoupon.com/udemy/22544/)Automatiza YouTube al 100% con IA
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22543
/)Secretary Professional Certification (SPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22542/)Master Splits & 
Conditioning for Martial or Performance Arts
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22541/)Luxury Industry 
Professional Certification (LIPC)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22540/)C# desde 0: Inicia tu carre
ra como programador
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22539/)Paralegal Professional Certification (PPC
)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22537/)The Complete Video Editing Masterclass with Vegas Pro
* [RE
DEEM OFFER ](https://idownloadcoupon.com/udemy/22536/)Executive Diploma in Business Management
* [REDEEM OFFER ](https:/
/idownloadcoupon.com/udemy/22535/)CLF-C01: AWS Certified Cloud Practitioner Practice test 2024
* DBS-C01: AWS Certified 
Database Specialty Practice Test 2024
* [REDEEM OFFER](https://idownloadcoupon.com/udemy/22534/)
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/22533/)DOP-C01: AWS Certified DevOps Engineer Practice test 2024
* [REDEEM OFFER ](https://
idownloadcoupon.com/udemy/22532/)Google SEO Guide: How to Rank First on Google
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/22531/)The Ultimate Google Analytics 4 Course – Complete Guide 2024
* [REDEEM OFFER ](https://idownloadcoupon
.com/udemy/22530/)C++ Beginner to Advanced: Modern C++20 and Multithreading
* [REDEEM OFFER ](https://idownloadcoupon.co
m/udemy/22529/)Python Machine Learning: From Beginner to Pro
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22528/)
Build a WordPress Blog Website Step by Step
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22527/)Instagram Marketi
ng Course: Fastest ways to grow your page
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22526/)User Experience Des
ign – Learn UI UX App Design with Figma
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22525/)Beginning Bash Script
ing
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22524/)Ethical Hacking: Hacker Methodology
* [REDEEM OFFER ](htt
ps://idownloadcoupon.com/udemy/22523/)Interview Success: Business English for Job interviews
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/22522/)Business Process Management: Certification
* [REDEEM OFFER ](https://idownloadcoupon.com
/udemy/22521/)15 Günde Anne Sütü Mucizesi: Beslenme Rehberiniz
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22520
/)Office Administration Management Professional Certification
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22519/
)C-level management: 20 models for business operations (2/5)
* Growth Hacking Professional Certification (GHPC)
* [REDEE
M OFFER](https://idownloadcoupon.com/udemy/22518/)
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22517/)The Comple
te JavaScript Course: From Zero to Expert
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22516/)Selenium Webdriver 
with Java & TestNG Testing Framework
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22515/)सीखें WordPress हिन्दी म
ें
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22514/)Certified Culinarian Practice Exam
* [REDEEM OFFER ](https
://idownloadcoupon.com/udemy/22513/)The Complete C++ Programming Course from Basic to Expert
* [REDEEM OFFER ](https://i
downloadcoupon.com/udemy/22512/)Next.js for Beginners : The Complete Guide 2024
* [REDEEM OFFER ](https://idownloadcoupo
n.com/udemy/22511/)Python And Django Framework For Beginners Complete Course
* [REDEEM OFFER ](https://idownloadcoupon.c
om/udemy/22510/)AWS Certified Machine Learning Specialty 2024 – Hands On!
* [REDEEM OFFER ](https://idownloadcoupon.com/
udemy/22509/)Ultimate AWS Certified Solutions Architect Associate (SAA)
* [REDEEM OFFER ](https://idownloadcoupon.com/ud
emy/22508/)x64dbg Script Programming For Reverse Engineering
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22507/)
F5 101 Exam Preparation – Complete Course w/ Practice Exams
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22506/)2
025 Master Langchain and Ollama – Chatbot, RAG and Agents
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22505/)Unb
ounce: Create Landing Pages that Convert + A/B Testing
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22504/)Cómo C
rear una Tienda Online con Blogger Desde Cero 2024
* [REDEEM OFFER ](https://idownloadcoupon.com/udemy/22503/)Herramient
as de Google 2024, ¡Desde Cero Hasta Experto!

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://idow
nloadcoupon.com/)
```
---

     
 
all -  [ Run GGUF models using python ](https://www.reddit.com/r/LanguageTechnology/comments/1gk06za/run_gguf_models_using_python/) , 2024-11-07-0912
```
GGUF is an optimised file format to store ML models (including LLMs) leading to faster and efficient LLMs usage with red
ucing memory usage as well. This post explains the code on how to use GGUF LLMs (only text based) using python with the 
help of Ollama and LangChain : https://youtu.be/VSbUOwxx3s0
```
---

     
 
all -  [ LangChain RetrievalQA Working Locally but Failing on Windows Server Deployment ](https://www.reddit.com/r/techsupport/comments/1gjzdea/langchain_retrievalqa_working_locally_but_failing/) , 2024-11-07-0912
```
I'm using LangChain (version langchain==0.3.3) and specifically the RetrievalQA class from langchain.chains to retrieve 
answers from PDF files. My setup works perfectly on my local machine, but I’m having trouble getting it to work after de
ploying it to a live server running Django on a Windows Server.



Here’s the core part of my code:

conversation\_chain
 = RetrievalQA.from\_chain\_type(

llm=llm,

retriever=vectorstore.as\_retriever(search\_kwargs={'k': 30}),

\# memory=m
emory,

chain\_type='stuff',

chain\_type\_kwargs={'prompt': my\_prompt},

)



response = conversation\_chain.invoke(


{'query': fieldPrompt.Prompt}

)



In my local environment, everything runs smoothly. However, once deployed, it doesn’
t work as expected, and I’m not getting the intended responses.



Could anyone help me figure out why this might be hap
pening on the live server? Is there something specific about deploying on Windows Server or Django that might cause issu
es with LangChain or RetrievalQA? Any troubleshooting tips would be greatly appreciated!
```
---

     
 
all -  [ How can I add a filter for my retriever? ](https://www.reddit.com/r/LangChain/comments/1gjxwxx/how_can_i_add_a_filter_for_my_retriever/) , 2024-11-07-0912
```
    vectorstore = AzureCosmosDBVectorSearch.from_connection_string(
                    connection_string=self.uri,
    
                namespace=self.namespace,
                    embedding=self.embedding_model,
                    index_
name = self.index_name,
                    embedding_key=self.embedding_key
                )
    
    retriever = vect
orstore.as_retriever(
                    search_kwargs={
                        'k': 10,
                        'filt
er': {'username': username}
                    }
                )

What is the syntax to construct the filter? Cant se
em to find the documentation for it.

For context, I want to only retrieve documents where the metadata contains my user
name (only documents belonging to the user). However, the filter does not seem to be working and is returning me all the
 documents.
```
---

     
 
all -  [ How to use RAG? ](https://www.reddit.com/r/Rag/comments/1gjwjb8/how_to_use_rag/) , 2024-11-07-0912
```
Hi! I'm kind of new to programming and machine learning as a whole, and I was wondering if someone can give me an outlin
e of implementing RAG using langchain??

I know the general outline: data collection --> vector embeddings --> storing i
n vector database --> and using this in the generation step as extra context as you prompt the LLM.

Am I missing someth
ing? And wouldn't this mean that the data collection step is the most important since you're building your vector databa
se off of how you collect the data and which data you end up collecting? Lastly, approximately how much data do you need
 for a decently sized vector database, generally speaking for a personal project. 

Thanks!
```
---

     
 
all -  [ Need Help with FAISS Integration - ‘IndexFlat’ Object is Not Callable Error ](https://www.reddit.com/r/LangChain/comments/1gjubsw/need_help_with_faiss_integration_indexflat_object/) , 2024-11-07-0912
```
  
Hi everyone,  
I’m facing an issue while integrating FAISS vector storage with the Langchain library. Specifically, I
’m encountering the following error when I try to create or update my FAISS vector store:  


    php
    
    
    Type
Error: 'IndexFlat' object is not callable

Context of the Project:  
I am building a two-fold document retrieval system:
  


1. **Main AI** \- This functionality provides access to all uploaded documents, allowing users to ask questions tha
t are answered based on the contents of all available documents.
2. **Copilot (Similar to Discord Bots)** \- Users can u
se a prefix `/filename` followed by their query to ask specific questions about an individual document (e.g., `/ansible.
pdf describe this file`). The aim is to retrieve information only from the selected document.

The data flow involves st
oring FAISS index files and metadata in Google Cloud Storage, retrieving them as needed, and updating the vector store b
ased on new documents being uploaded.  
Problem:  


* When I upload the first document, the FAISS index and metadata ar
e created successfully, and everything works fine.
* However, when I upload additional files and try to update the FAISS
 vector store, the following error occurs:

`TypeError: 'IndexFlat' object is not callable`  
This error occurs specific
ally at the point where I try to add more texts to an existing FAISS vector store.  
Changes Made So Far:  
I initially 
suspected that the embedding function was incorrectly defined or called. Here’s what I tried doing:  


* **Initializati
on of Embeddings Model**: I am using Google Generative AI for embeddings, specifically `GoogleGenerativeAIEmbeddings`. H
ere’s a sample initialization:

`from langchain_google_genai import GoogleGenerativeAIEmbeddings`  
`embeddings = Google
GenerativeAIEmbeddings(model='models/embedding-001', task_type='retrieval_document')`

* **Creating Vector Store**: I us
ed the FAISS method `from_texts` to create a vector store. Here’s a snippet of my `get_vector_store()` function:

&#8203
;

        def download_and_initialize_vectorStore_fromGC(self, bucket_name, prefix, text_chunks, uid, client_organizati
on_id, grant_proposal_form_id, file_name):
            temp_dir = f'/tmp/download_vectorStore/{uid}/{client_organization
_id}/{grant_proposal_form_id}'
            os.makedirs(temp_dir, exist_ok=True)
            blobs = self.upload_bucket.l
ist_blobs(prefix=prefix)
            faiss_file_found = False
            pkl_file_found = False
            for blob in
 blobs:
                if blob.name.endswith('/') or 'index' not in blob.name:
                    continue
           
     local_path = Path(temp_dir) / Path(blob.name).name
                local_path.parent.mkdir(parents=True, exist_ok=T
rue)
                blob.download_to_filename(str(local_path))
                print(local_path)
    
                i
f 'index.faiss' in str(local_path):
                    faiss_file_found = True
                if 'index.pkl' in str(lo
cal_path):
                    pkl_file_found = True
            
            if not faiss_file_found or not pkl_file_fo
und:
                raise FileNotFoundError(f'Required FAISS or PKL files not found in {prefix}')
    
            prin
t(f'Files Downloaded to {temp_dir}: {os.listdir(temp_dir)}')
    
            os.getenv('GOOGLE_API_KEY')
            em
beddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001', task_type='retrieval_document')
    
            p
rint(f'Loading FAISS index from temp directory: {temp_dir}')
            self.load_vector_store(temp_dir, embeddings)
  
  
            print('Successfully Loaded the vector store')
            self.vector_store.add_texts(text_chunks)
      
      print('Updated the vector store')
    
            cloud_path_to_delete = f'/tmp/{uid}/{client_organization_id}/{g
rant_proposal_form_id}'
            self.delete_directory_in_cloud(self.upload_bucket_name, cloud_path_to_delete)
      
      print('Successfully deleted the Faiss_index')
    
            print(f'Vector store attributes before saving:{vars
(self.vector_store)}')
            updated_faiss_path = f'/tmp/{uid}/{client_organization_id}/{grant_proposal_form_id}'

            try:
                self.save_vector_store(updated_faiss_path, text_chunks, file_name)
                prin
t('Successfully saved the updated Faiss Index')
            except Exception as e:
                print(f'Error during 
FAISS save_local:{e}')
            self.upload_Vector_DB_files(self.upload_bucket_name, updated_faiss_path)
            
print('successfully uploaded the updated Faiss_index to cloud storage')
            shutil.rmtree(temp_dir)
            
print('Temp Directory removed successfully')
    
        def get_vector_store(self, text_chunks: list, uid: str, client
_organization_id: str, grant_proposal_form_id: str, file_name: str):
            if not self._faiss_index_exists(uid, cl
ient_organization_id, grant_proposal_form_id):
                print('FAISS index does not exist. Creating a new one.')

                self.vector_store = self._create_faiss_index(text_chunks)
                print('FAISS index created wit
h chunks')
                self.save_vector_store(f'/tmp/{uid}/{client_organization_id}/{grant_proposal_form_id}', text_
chunks, file_name)
                print('FAISS index saved in local')
                self.upload_Vector_DB_files(self.
upload_bucket_name, f'/tmp/{uid}/{client_organization_id}/{grant_proposal_form_id}')
                print('FAISS index 
upload complete')
            else:
                print('Faiss Index Available')
                self.download_and_ini
tialize_vectorStore_fromGC(self.upload_bucket_name, f'/tmp/{uid}/{client_organization_id}/{grant_proposal_form_id}', tex
t_chunks, uid, client_organization_id, grant_proposal_form_id, file_name)
                print('Faiss Index successfull
y updated and stored')
            print('Vector store created successfully.')

* **Adding Texts to Vector Store**: When
 trying to add texts to the FAISS vector store, I encountered the `IndexFlat` error. The problematic line is as follows:


`self.vector_store.add_texts(text_chunks)`Attempted Solutions:  


* **Verified Embedding Model Initialization**: I ma
de sure that the `GoogleGenerativeAIEmbeddings` model was correctly instantiated and passed as an argument to `FAISS.fro
m_texts()`.
* **Checked** `embed_documents` **Method**: I confirmed that `embed_documents()` is indeed a method supporte
d by `GoogleGenerativeAIEmbeddings` and tried passing text to it manually:

Relevant source code is here: [https://colab
.research.google.com/drive/1erJ\_liA9ldPHiKBEzuzr05o8j8KVgxON?usp=sharing](https://colab.research.google.com/drive/1erJ_
liA9ldPHiKBEzuzr05o8j8KVgxON?usp=sharing)

* What I’m Looking for:
   * **Why the** `IndexFlat` **object is being consid
ered callable**: I’m not entirely sure why the `IndexFlat` object is incorrectly being used as a callable. Is there some
thing inherently wrong with the way the embedding model is being assigned or initialized?
   * **How to Correctly Update
 the FAISS Vector Store**: Given that the initial vector store is successfully created but fails when trying to add new 
documents, is there a particular pattern I should be following to avoid this error?
   * **Efficient Hybrid Approach**: 
Since I am combining traditional metadata approaches with embeddings for selective document retrieval, is there a recomm
ended way to integrate this type of hybrid retrieval functionality effectively with Langchain and FAISS?

Any insights i
nto what I’m doing wrong or how I could correct my approach would be greatly appreciated.  
**Thank you so much for your
 help and time in advance!** 
```
---

     
 
all -  [ Is there any nodejs packages for visualising a langgraph JS graph?  ](https://www.reddit.com/r/LangChain/comments/1gju54m/is_there_any_nodejs_packages_for_visualising_a/) , 2024-11-07-0912
```
Something that actually is produced from the code and the compiled graph.
```
---

     
 
all -  [ A new discovery tool for the Langchain ecosystem ](https://www.reddit.com/r/LangChain/comments/1gjpfzv/a_new_discovery_tool_for_the_langchain_ecosystem/) , 2024-11-07-0912
```
Hi! I built a new page to browse resources in the Langchain ecosystem -

[https://ecosystems.gitwallet.co/ecosystems/lan
gchain](https://ecosystems.gitwallet.co/ecosystems/langchain)

This is part of a bigger product called **Echo**, which i
s a new way to find projects, resources and people in open source ecosystems. You can think of this as a 'New Github Exp
lore', or a 'Product Hunt for Open Source', in a sense.

We also made a different take on the Github repo page to make i
t a bit more readable, see related repos, and a few more things. Here's an example for langchain4j:

[https://ecosystems
.gitwallet.co/ecosystems/langchain/projects/langchain4j](https://ecosystems.gitwallet.co/ecosystems/langchain/projects/l
angchain4j)

I'm still an agent n00b and really appreciate how langchain is creating all the 'right abstractions' to mak
e agent development easier. Anyways, would love to get some feedback from this community!
```
---

     
 
deeplearning -  [ Fast AI's deep learning for coders by jeremy howard for begginer?  ](https://www.reddit.com/r/deeplearning/comments/1gb2k3p/fast_ais_deep_learning_for_coders_by_jeremy/) , 2024-11-07-0912
```
I am a full stack python developer who do web dev in django

I am now starting deep learning,i am a compelete begginer


(Have worked with pandas,numpy,matplotlib,langchain only)

I wanna ask,should i do this course,will i understand what he
 is coding and code myslef

I just dont want to do blind coding,i wanna learn what is the purpose,how it works and how t
o do it

Will this course teach me that or not?

Thanks in advance
```
---

     
