 
all -  [ Resume Review: ML/AI Engineering Grad Student Looking for Internships, not having much luck ](https://www.reddit.com/r/Resume/comments/1hp6pt3/resume_review_mlai_engineering_grad_student/) , 2024-12-30-0913
```
I'm a current Computer Engineering Master's student focusing on AI/Machine Learning, and I've been applying to internshi
ps, but the only replies I ever get are if I have a referral. I got an interview with Salesforce for an AI internship be
cause of a referral and the it went well. So even though I don't know if I'll get the position I'm wondering why I can't
 get companies lower on the totem pole than Salesforce to give me an interview or OA.

I'm wondering if my resume format
 is bad and getting auto rejected or if I just don't have enough experience to make it in a competitive market (It could
 be a combination of both). I get the sense that my resume isn't even making it past recruiters. I see other people at l
east get interviews with these places, I'm wondering what they're doing that I'm not.

Any advice or tips would be great
ly appreciated. I haven't had much luck getting advice in other subs or having my resume refined by someone on Fiver for
 $60. For reference I am a US citizen (I know that can affect what recruiters do with applications). 

https://preview.r
edd.it/wkkxxgb1yu9e1.jpg?width=1252&format=pjpg&auto=webp&s=f09d4baa91524c95784f175dce6b085689404595


```
---

     
 
all -  [ Is there any simpler way to implement memory in a chat app? ](https://www.reddit.com/r/OpenAI/comments/1hp6h5g/is_there_any_simpler_way_to_implement_memory_in_a/) , 2024-12-30-0913
```
I am creating a simple chat app with Haystack but like Langchain, Haystack is too much abstraction for a simple task.

S
o I was wondering if anyone knows of a way to implement memory for the chat app without using Haystack or Langchain?

Al
so, this is a simple chat app and not a document based chat app.
```
---

     
 
all -  [ Need advice regarding job search  ](https://i.redd.it/4v2brxtzkt9e1.jpeg) , 2024-12-30-0913
```
I'm a Master's student pursuing my degree in EE, my bachelor's was in EE as well.  I was originally interested in roboti
cs design.
However, opportunities have been limited to say the least. I figure I can't be selective anymore and have bee
n applying to broader roles in EE as well, but have had no luck with the applications. Tried internships but no luck the
re either.
I need advice on what roles would be the best fit given my skills. And what approach I should take to improve
 my resume.
Any feedback on the resume itself would be greatly appreciated as well.
Thank you for your time.

```
---

     
 
all -  [ LinkedIn tool integration - how to implement ](https://www.reddit.com/r/AI_Agents/comments/1hp028i/linkedin_tool_integration_how_to_implement/) , 2024-12-30-0913
```
Hi there,  
I am currently working on an AI agent project and need to scrape through my clients Linkedin contacts, to id
entify potential leads. As far as I am aware, there is no tool integration for LinkedIn. I have checked the LangChain an
d crewAI documentation, and could not find a tool there. I saw composio has a LinkedIn connector, but then you have to i
mplement your own tool logic (which is fine for me, I am a senior dev, but I have concerns about getting blocked on Link
edIn for scraping). 

Do you know of any other libraries or frameworks I can use? I am looking for free solutions, no lo
w code. Thanks in advance. 
```
---

     
 
all -  [ Web browser example is giving me - Error: Failed to parse. Text: '```json... is not valid JSON'  ](https://www.reddit.com/r/flowise/comments/1hos4vp/web_browser_example_is_giving_me_error_failed_to/) , 2024-12-30-0913
```
After following this example - [https://www.youtube.com/watch?v=yEHC7\_x2x4U](https://www.youtube.com/watch?v=yEHC7_x2x4
U) \- I'm getting an error while working on Flowise and I'm hoping someone can help me troubleshoot. I'm getting a 'Fail
ed to parse. Text: \`\`\`json... is not valid JSON' error.

Here's the full error message:

Failed to parse. Text: '\`\`
\`json { 'action': 'Final Answer', 'action\_input': | { 'definition\_of\_word\_of\_the\_day': 'A word of the day is a re
gularly occurring piece of content, such as a quote, fact, or definition, that is shared with users on a particular plat
form.', 'example\_use\_case\_for\_perspicacious': 'The detective was known for being perspicacious and could often solve
 cases by observing small details that others had missed.' } }

{

  '... is not valid JSON



Troubleshooting URL: [htt
ps://js.langchain.com/docs/troubleshooting/errors/OUTPUT\_PARSING\_FAILURE/](https://js.langchain.com/docs/troubleshooti
ng/errors/OUTPUT_PARSING_FAILURE/)

*Processing img 2i89l4mshn9e1...*


```
---

     
 
all -  [ Building a Production-Ready RAG Application: Need Advice ](https://www.reddit.com/r/LangChain/comments/1horktb/building_a_productionready_rag_application_need/) , 2024-12-30-0913
```

Hi everyone,

Iâ€™m currently working on building a production-ready RAG application. My primary is Azure OpenAI, but Iâ€™m
 open to other LLM integrations if necessary.

Key Requirements:
- Handling a large volume of internal documents.
- Feat
ures like question reformulation and reranking to improve retrieval accuracy.

Frameworks Iâ€™m Considering:
- LangChain
-
 Haystack
- Semantic Kernel

Do you have any recommendations on which framework is best suited for this use case? Am I m
issing any other frameworks that I should evaluate?

Iâ€™d appreciate your insights and experiences
```
---

     
 
all -  [ [8 YOE, full stack, Senior engineer, canada] please help me correct my resume ðŸ™ðŸ½ðŸ™ðŸ½ ](https://i.redd.it/rp4h4epeup9e1.jpeg) , 2024-12-30-0913
```

```
---

     
 
all -  [ Monopoly - beat a human collective ](https://www.reddit.com/r/ollama/comments/1hoi9rm/monopoly_beat_a_human_collective/) , 2024-12-30-0913
```
So its christmas and the thought turns to the family board games,

Is there a model or app (python) or gui site where i 
can basicaly kick the families backsides by using ai to process the permutations for me?

Ditto many other popular board
 games such as cludeo, sorry, stratego,, ( ignoring knowledge based such as trivial pursuits) 

I have a decent enough l
aptop with a 4070 that runs models happily locally using ollama and i am comfortable with python and langchain and local
 class modules.. 

Just a random thought to use what i mess with in the day job to kick the families arses round the din
ner table ðŸ¤£
```
---

     
 
all -  [ Best Way to Chunk Large-ish Text Documents for Make.com ](https://www.reddit.com/r/vectordatabase/comments/1hoeees/best_way_to_chunk_largeish_text_documents_for/) , 2024-12-30-0913
```
I'm looking around for the best way to chunk large documents in a [Make.com](http://Make.com) scenario before sending th
e data into Pinecone. Within Make, there is CustomJS and 0CodeUtil. LangChain apparently is an option as well. Honestly,
 I would love to be able to deploy a custom function somewhere in the cloud and then call it using an API. Really trying
 to avoid complex setups and want quick and dirty.
```
---

     
 
all -  [ Underlying tech of Cursor? ](https://www.reddit.com/r/ycombinator/comments/1hod5iv/underlying_tech_of_cursor/) , 2024-12-30-0913
```
Very curious about how the Cursor team is approaching their solution technically

1. How do they handle context across t
he project?
2. Do they use raw APIs or something like LangChain or LangGraph?
3. Is it proprietary tech or just a 'LLM w
rapper'? (I don't think so)

Is there info about this?
```
---

     
 
all -  [ Top 5 Hacker News Posts on RAG This Week ](https://www.reddit.com/r/Rag/comments/1hobxkl/top_5_hacker_news_posts_on_rag_this_week/) , 2024-12-30-0913
```
Curated the top 5 most insightful posts on RAG â€” highlighting key discussions and practical takeaways:

1ï¸âƒ£ ð—§ð—¶ð˜ð—¹ð—²: RAG L
ogger: An Open-Source Alternative to LangSmith  
ð—¨ð—½ð˜ƒð—¼ð˜ð—²ð˜€: 95  
ð—Ÿð—¶ð—»ð—¸: [https://news.ycombinator.com/item?id=42485113](htt
ps://news.ycombinator.com/item?id=42485113)  
ð—ªð—µð—®ð˜ ð—¶ð˜€ ð—¶ð˜ ð—®ð—¯ð—¼ð˜‚ð˜: RAG Logger is a simple, open-source RAG pipeline logging
 tool with suggested enhancements like visualization, OpenTelemetry support, and replay features.

2ï¸âƒ£ ð—§ð—¶ð˜ð—¹ð—²: Collab Not
ebook â€“ RAG on Your Unstructured Data  
ð—¨ð—½ð˜ƒð—¼ð˜ð—²ð˜€: 14  
ð—Ÿð—¶ð—»ð—¸: [https://news.ycombinator.com/item?id=42517745](https://news
.ycombinator.com/item?id=42517745)  
ð—ªð—µð—®ð˜ ð—¶ð˜€ ð—¶ð˜ ð—®ð—¯ð—¼ð˜‚ð˜: The post outlines using LangChain and Unstructured IO to address 
unstructured data challenges in RAG with FAISS, LLMs, and Athina AI evaluation.

3ï¸âƒ£ ð—§ð—¶ð˜ð—¹ð—²: Web RAG to generate perplexi
ty like answers from your docs in browser  
ð—¨ð—½ð˜ƒð—¼ð˜ð—²ð˜€: 5  
ð—Ÿð—¶ð—»ð—¸: [https://news.ycombinator.com/item?id=42516981](https://n
ews.ycombinator.com/item?id=42516981)  
ð—ªð—µð—®ð˜ ð—¶ð˜€ ð—¶ð˜ ð—®ð—¯ð—¼ð˜‚ð˜: The system offers a private, browser-based solution for indexi
ng, searching, and generating responses using GTE-small, SQLite, and WebLLM, with zero API costs ðŸ‘©â€ðŸ’»

4ï¸âƒ£ ð—§ð—¶ð˜ð—¹ð—²: LLM app
s, AI Agents, and RAG tutorials with step-by-step instructions  
ð—¨ð—½ð˜ƒð—¼ð˜ð—²ð˜€: 3  
ð—Ÿð—¶ð—»ð—¸: [https://news.ycombinator.com/item?i
d=42510073](https://news.ycombinator.com/item?id=42510073)  
ð—ªð—µð—®ð˜ ð—¶ð˜€ ð—¶ð˜ ð—®ð—¯ð—¼ð˜‚ð˜: A curated repository of RAG-powered LLM a
pplications, showcasing models from OpenAI, Anthropic, Google, and open-source options like LLaMA.

5ï¸âƒ£ ð—§ð—¶ð˜ð—¹ð—²: GraphRAG 
SDK 0.4.0: Simplify RAG with Graph Databases  
ð—¨ð—½ð˜ƒð—¼ð˜ð—²ð˜€: 2  
ð—Ÿð—¶ð—»ð—¸: [https://news.ycombinator.com/item?id=42496411](https:
//news.ycombinator.com/item?id=42496411)  
ð—ªð—µð—®ð˜ ð—¶ð˜€ ð—¶ð˜ ð—®ð—¯ð—¼ð˜‚ð˜: The module simplifies RAG application development with grap
h databases, multi-LLM support, smarter queries, LiteLLM integration, and cost-effective deployment ðŸš€
```
---

     
 
all -  [ [Student] Looking for feedback on my resume and general advise regarding job search ](https://www.reddit.com/r/EngineeringResumes/comments/1hoa3j9/student_looking_for_feedback_on_my_resume_and/) , 2024-12-30-0913
```
My last post didn't get much traction so I hope this one does better. I believe this is my first time posting here, but 
I have posted on the resumes subreddit before. Looking for criticism/feedback on the latest iteration of my resume. 

I 
am looking for robotics/EE roles, and have been applying since the start of the fall semester, but no luck regarding get
ting interviews. No luck with internships either. A couple of pre-recorded video interviews but they didn't go anywhere.
 I am not sure what I am doing wrong, is it the fact that I am an international student, lack of experience, my resume, 
or all three.

I would also like advice on what roles in EE/robotics would best fit me, given my skills. I figure being 
specific will not get me anywhere hence the desperation.

Thanks again for your time.

https://preview.redd.it/zcn91jq9g
m9e1.jpg?width=4967&format=pjpg&auto=webp&s=75cd4e61fcc35fd21d160ef084daa48f029f30cc




```
---

     
 
all -  [ An Open Source Computer/Browser Tool for your Langgraph AI Agents ](https://www.reddit.com/r/LangChain/comments/1ho8m91/an_open_source_computerbrowser_tool_for_your/) , 2024-12-30-0913
```
MarinaBox is an open-source toolkit for creating browser/computer sandboxes for AI Agents. If you ever wanted your Langg
raph agents to use a computer using Claude Computer-Use, you can check this out,  
[https://medium.com/@bayllama/a-compu
ter-tool-for-your-langgraph-agents-using-marinabox-b48e0db1379c](https://medium.com/@bayllama/a-computer-tool-for-your-l
anggraph-agents-using-marinabox-b48e0db1379c)

We also support creating just a browser sandbox if having access to a des
ktop environment is not necessary.

Documentation:[https://marinabox.mintlify.app/get-started/introduction](https://mari
nabox.mintlify.app/get-started/introduction)Â   
Main Repo:Â [https://github.com/marinabox/marinabox](https://github.com/m
arinabox/marinabox)Â   
Infra Repo:Â [https://github.com/marinabox/marinabox-sandbox](https://github.com/marinabox/marinab
ox-sandbox)

PS: We currently only support running locally. Will soon add the ability to self-host on your own cloud.
```
---

     
 
all -  [ Supabase and Open AI Realtime with langchain powered App to interact with your PDFs ](https://www.reddit.com/r/Supabase/comments/1ho40ha/supabase_and_open_ai_realtime_with_langchain/) , 2024-12-30-0913
```
Hi Everyone, we are proud to share the release of our open source voice-to-voice Proof of concept where you can upload y
our documents and ask questions related to them.

You can upload your documents and interact with them through our dashb
oard.ðŸ“Š.

Based on OpenAI Realtime AND langchain

Powered by [Supabase](https://www.linkedin.com/company/supabase/)  \+ [
Qdrant](https://www.linkedin.com/company/qdrant/)  \+ [NextJs](https://www.linkedin.com/company/nextjs/)

Github repo: [
https://github.com/actualize-ae/voice-chat-pdf](https://github.com/actualize-ae/voice-chat-pdf)

**If you like the conce
pt or have feedback please feel free to contribute a star and share feedback :)**

Video: [https://vimeo.com/1039742928?
share=copy](https://vimeo.com/1039742928?share=copy)
```
---

     
 
all -  [ Open AI Realtime with langchain powered RAG POC ](https://www.reddit.com/r/OpenAIDev/comments/1ho3sxb/open_ai_realtime_with_langchain_powered_rag_poc/) , 2024-12-30-0913
```
Hi Everyone, we are proud to share the release of our open source voice-to-voice Proof of concept where you can upload y
our documents and ask questions related to them.

You can upload your documents and interact with them through our dashb
oard.ðŸ“Š.

Based on OpenAI Realtime AND langchain

Powered by [Supabase](https://www.linkedin.com/company/supabase/)  \+ [
Qdrant](https://www.linkedin.com/company/qdrant/)  \+ [NextJs](https://www.linkedin.com/company/nextjs/)

Github repo: [
https://github.com/actualize-ae/voice-chat-pdf](https://github.com/actualize-ae/voice-chat-pdf)

**If you like the conce
pt or have feedback please feel free to contribute a star and share feedback :)**

Video: [https://vimeo.com/1039742928?
share=copy](https://vimeo.com/1039742928?share=copy)


```
---

     
 
all -  [ Invite Emails for EU Region are not being Sent ](https://www.reddit.com/r/LangChain/comments/1ho3a66/invite_emails_for_eu_region_are_not_being_sent/) , 2024-12-30-0913
```
I've been trying to sign up via https://eu.smith.langchain.com/. It keeps saying I should check my email for a confirmat
ion link, which is not arriving (no, not in my spam either). Please advise.
```
---

     
 
all -  [ Langchain and embeddings in voice pipeline? ](https://www.reddit.com/r/homeassistant/comments/1hnwy4q/langchain_and_embeddings_in_voice_pipeline/) , 2024-12-30-0913
```
Has anyone thought about adding a vertex DB to the voice pipeline rather than adding all entities exported in the prompt
 every time? Maybe we could have a plug-in that allows calling a langchain pipeline rather than an LLM directly, this wo
uld allow querying entities rather than having them in the prompt and could open up to a more complex multi agent setup 

```
---

     
 
all -  [ Guide to Integrating LangChain with Ollama for Local AI Workflows ](https://www.reddit.com/r/u_KonradFreeman/comments/1hntzfb/guide_to_integrating_langchain_with_ollama_for/) , 2024-12-30-0913
```
For those seeking to transition from cloud-based AI services to a more private and cost-effective local setup, I have re
cently published a comprehensive guide on integrating LangChain with Ollama. This guide outlines how to build robust wor
kflows powered by locally hosted language models (LLMs). You can access the complete write-up here: [LangChain + Ollama 
Guide](https://danielkliewer.com/2024/12/27/langchain-ollama).

This resource serves as a valuable starting point for ex
ploring local AI workflows or considering alternatives to cloud-based solutions. I am happy to answer any questions or d
iscuss potential use cases in more detail.

To provide a preview, the final program created as part of the guide is incl
uded below. While I used the QwQ model in this implementation, the setup is flexibleâ€”you can easily swap in a different 
model by modifying the corresponding payload entry.

The project was designed with two main objectives:

1. Core Concept
 Mastery: To understand the fundamental principles behind building scalable AI workflows.
2. Enhanced Local Model Capabi
lities: To explore methods of improving locally hosted models, enabling them to match or surpass some of the functionali
ty of cloud-based alternatives.

Currently, the application leverages simple folders containing .json persona files. Fut
ure iterations could integrate a database for greater flexibility. Additionally, a React-based UI for persona customizat
ion could be implemented, similar to the functionality I developed in my Personagen project.

# Key Innovations

* Graph
-Based Logic and Reasoning: By simulating logic with graph structures, the workflow can enhance local model outputs. Thi
s involves using multiple LLM calls with a context tracker, implemented through a graph-based LLM-to-LLM structure. This
 reduces hallucinations and enables more advanced functionalities.
* Scalable Personas: The personas folder allows for s
eamless customization, enabling developers to define any desired attributes. These can range from predefined JSON struct
ures to dynamic outputs generated by LLM calls, facilitating more complex orchestration of nodes and subnodes.
* Optimiz
ed Workflow Execution: By utilizing LangChain asynchronously with topological sorting, the application chains prompts ef
ficiently, minimizing response times.

requirements.txt

    langchain
    networkx
    markdown
    langchain_community

    click
    
    
    
    # main.py
    
    import click
    import os
    import networkx as nx
    from langchain
 import PromptTemplate, LLMChain
    from langchain.llms import Ollama
    import json
    
    # Define the Node class

    class Node:
        def __init__(self, node_id, prompt_text, persona_name):
            self.id = node_id
          
  self.prompt_text = prompt_text
            self.response_text = None
            self.context = ''
            self.pe
rsona_name = persona_name
            self.persona_attributes = {}
    
    # Initialize the graph
    G = nx.DiGraph()

    
    def build_graph(nodes_info, edges_info):
        G = nx.DiGraph()
        nodes = {}
        # Create nodes
   
     for node_info in nodes_info:
            node_id = node_info['id']
            prompt_text = node_info['prompt_text
']
            persona_name = node_info['persona_name']
            node = Node(node_id, prompt_text, persona_name)
    
        G.add_node(node_id, data=node)
            nodes[node_id] = node
    
        # Add edges
        for edge in ed
ges_info:
            G.add_edge(edge['from'], edge['to'])
        
        return G
    
    def process_graph(G):
    
    for node_id in nx.topological_sort(G):
            node = G.nodes[node_id]['data']
            if node.persona_name 
!= 'Analyst':
                node.context = collect_context(node_id, G)
                node.response_text = generate_r
esponse(node)
                update_markdown(node)
            else:
                analyze_responses(node, G)
    
  
  def load_personas(persona_dir):
        personas = {}
        for filename in os.listdir(persona_dir):
            if 
filename.endswith('.json'):
                filepath = os.path.join(persona_dir, filename)
                with open(fil
epath, 'r', encoding='utf-8') as f:
                    persona_data = json.load(f)
                    name = persona_d
ata.get('name')
                    if name:
                        personas[name] = persona_data
        return person
as
    
    # Load personas
    persona_dir = 'personas'  # Directory where persona JSON files are stored
    personas =
 load_personas(persona_dir)
    
    # Function to collect context from predecessor nodes
    def collect_context(node_i
d, G):
        predecessors = list(G.predecessors(node_id))
        context = ''
        for pred_id in predecessors:
  
          pred_node = G.nodes[pred_id]['data']
            if pred_node.response_text:
                context += f'From
 {pred_node.persona}:\n{pred_node.response_text}\n\n'
        return context
    
    # Function to generate responses u
sing LangChain and Ollama
    def generate_response(node):
        persona = personas.get(node.persona_name)
        if 
not persona:
            raise ValueError(f'Persona '{node.persona_name}' not found.')
        
        node.persona_att
ributes = persona
    
        # Build the system prompt based on persona attributes
        system_prompt = build_syste
m_prompt(persona)
    
        # Build the complete prompt
        prompt_template = PromptTemplate(
            input_v
ariables=['system_prompt', 'context', 'prompt'],
            template='{system_prompt}\n\n{context}\n\n{prompt}'
       
 )
        # Instantiate the Ollama LLM
        llm = Ollama(
            base_url='http://localhost:11434',  # Default 
Ollama server URL
            model='qwq',  # Replace with the model you have downloaded
        )
        chain = LLMCh
ain(llm=llm, prompt=prompt_template)
        response = chain.run(
            system_prompt=system_prompt,
            
context=node.context,
            prompt=node.prompt_text
        )
        return response
    
    def build_system_pr
ompt(persona):
        # Construct descriptive sentences based on persona attributes
        # We'll focus on key attrib
utes for brevity
        name = persona.get('name', 'The speaker')
        tone = persona.get('tone', 'neutral')
       
 sentence_structure = persona.get('sentence_structure', 'varied')
        vocabulary_complexity = persona.get('vocabular
y_complexity', 5)
        formality_level = persona.get('formality_level', 5)
        pronoun_preference = persona.get('
pronoun_preference', 'third-person')
        language_abstraction = persona.get('language_abstraction', 'mixed')
    
  
      # Create a description
        description = (
            f'You are {name}, writing in a {tone} tone using {sente
nce_structure} sentences. '
            f'Your vocabulary complexity is {vocabulary_complexity}/10, and your formality l
evel is {formality_level}/10. '
            f'You prefer {pronoun_preference} narration and your language abstraction is
 {language_abstraction}.'
        )
    
        # Include any other attributes as needed
        # ...
    
        ret
urn description
    
    
    # Function to log interactions to a markdown file
    def update_markdown(node):
        w
ith open('conversation.md', 'a', encoding='utf-8') as f:
            f.write(f'## Node {node.id}: {node.persona_name}\n\
n')
            f.write(f'**Prompt:**\n\n{node.prompt_text}\n\n')
            f.write(f'**Response:**\n\n{node.response_
text}\n\n---\n\n')
    
    # Function for nodes that perform analysis
    def analyze_responses(node, G):
        # Col
lect responses from predecessor nodes
        predecessors = list(G.predecessors(node.id))
        analysis_input = ''
 
       for pred_id in predecessors:
            pred_node = G.nodes[pred_id]['data']
            analysis_input += f'{pr
ed_node.persona_name}'s response:\n{pred_node.response_text}\n\n'
    
        node.prompt_text = f'Provide an analysis 
comparing the following perspectives:\n\n{analysis_input}'
        node.context = ''  # Analysis is based solely on the 
provided responses
        node.response_text = generate_response(node)
        update_markdown(node)
    
    
    @cli
ck.group()
    def cli():
        pass
    
    @cli.command()
    def list_personas():
        '''List all available pe
rsonas.'''
        for persona_name in personas.keys():
            print(persona_name)
            
    @cli.command()

    @click.option('--nodes', '-n', default=2, help='Number of nodes (excluding the analyst node).')
    def run(nodes):

        '''Run the application with the specified number of nodes.'''
        # Let the user select personas and input p
rompts for each node
        nodes_info = []
        for i in range(1, nodes + 1):
            print(f'\nConfiguring Nod
e {i}')
            persona_name = click.prompt('Enter the persona name', type=str)
            while persona_name not i
n personas:
                print('Persona not found. Available personas:')
                for name in personas.keys():

                    print(f' - {name}')
                persona_name = click.prompt('Enter the persona name', type=str)

            
            prompt_text = click.prompt('Enter the prompt text', type=str)
            node_info = {
      
          'id': i,
                'prompt_text': prompt_text,
                'persona_name': persona_name
            
}
            nodes_info.append(node_info)
        
        # Add the analyst node
        analyst_node_id = nodes + 1
 
       analyst_node_info = {
            'id': analyst_node_id,
            'prompt_text': '',
            'persona_name
': 'Analyst'
        }
        nodes_info.append(analyst_node_info)
        
        # Define edges (here we assume that
 the analyst node depends on all other nodes)
        edges_info = []
        for i in range(1, nodes + 1):
            
edges_info.append({'from': i, 'to': analyst_node_id})
        
        # Build and process the graph
        G = build_g
raph(nodes_info, edges_info)
        process_graph(G)
        print('\nConversation has been generated and logged to con
versation.md')
    
    if __name__ == '__main__':
        cli()
```
---

     
 
all -  [ Recommendations on how to implement an Agentic RAG architecture in GO ](https://www.reddit.com/r/golang/comments/1hnrjqh/recommendations_on_how_to_implement_an_agentic/) , 2024-12-30-0913
```
Ask: I notice there are popular libraries called LangGraph and LangChain which can be used to create agent based RAG mod
els very easily (there are tutorials online) but I see there arent many Libs for GO. How have developers using GO dealt 
with this problem? what kind of BE architecture best supports a build with Agentic RAG with a GO BE?

Context: I am curr
ently building an application that aims to explore text data using Gen AI, I have my core BE setup and I can store copio
us amounts of data and surface it to my FE with no issues (power of GO!!), but now I need the AI service that will allow
 for user queries to be ran against the data I have in my db store. I want to use Agentic RAG models such that the queri
es are as precise as possible and I want to test the merit of this AI architecture.
```
---

     
 
all -  [ What's the big deal about agents in 2025?  ](https://www.reddit.com/r/ArtificialInteligence/comments/1hnq2t3/whats_the_big_deal_about_agents_in_2025/) , 2024-12-30-0913
```

I know what agents are and how could they be useful in general. But why the hype around them right now? 
We already hav
e frameworks/libraries for developing agentic work flows, like langchain, crewai, autogen etc. This could already be don
e in 2024, if not sooner. 

Why are all the big companies starting to talk about the agents right now? 
```
---

     
 
all -  [ Review my resume and suggest Some changes as it gets rejected everytime. ](https://i.redd.it/6wtgtxc0lg9e1.jpeg) , 2024-12-30-0913
```
I am final year student from tier-3.looking for internships and full time roles.can anyone suggest what changes should I
 make in my resume.
```
---

     
 
all -  [ Langgraph without Langsmith? ](https://www.reddit.com/r/LangChain/comments/1hnjzi6/langgraph_without_langsmith/) , 2024-12-30-0913
```
I'm new to Langgraph and enjoying it as I learn this space.  A major concern for me is the fact that my logs all go to L
angsmith.  I can not build anything beyond a basic POC if company data, which would be in all of the agent interactions,
 is being logged to Langsmith.  Is there a way to turn this off?
```
---

     
 
all -  [ Was reading through the docs. What is the difference between putting the chat history in the chat pr ](https://www.reddit.com/r/LangChain/comments/1hngbcw/was_reading_through_the_docs_what_is_the/) , 2024-12-30-0913
```
Just wanted to know the difference between putting the history here:

    const prompt = ChatPromptTemplate.fromMessages
([
    ['system', 'You are a helpful assistant'],
    ['placeholder', '{chat_history}'],
    ['human', '{input}'],
    [
'placeholder', '{agent_scratchpad}'],
    ]);

vs here:

    const result2 = await agentExecutor.invoke({
    input: 'wh
at's my name?',
    chat_history: [
    new HumanMessage('hi! my name is cob'),
    new AIMessage('Hello Cob! How can I 
assist you today?'),
    ],
    });

Thanks
```
---

     
 
all -  [ Was reading through the docs. What is the difference between putting the chat history in the chat pr ](https://www.reddit.com/r/LangChain/comments/1hngbcp/was_reading_through_the_docs_what_is_the/) , 2024-12-30-0913
```
Just wanted to know the difference between putting the history here:

const prompt = ChatPromptTemplate.fromMessages(\[ 
 
  \['system', 'You are a helpful assistant'\],  
  \['placeholder', '{chat\_history}'\],  
  \['human', '{input}'\],  

  \['placeholder', '{agent\_scratchpad}'\],  
\]);

vs here:

const result2 = await agentExecutor.invoke({  
  input: '
what's my name?',  
  chat\_history: \[  
new HumanMessage('hi! my name is cob'),  
new AIMessage('Hello Cob! How can I 
assist you today?'),  
  \],  
});

  
Thanks
```
---

     
 
all -  [ How does AI understand us (Or what are embeddings)? ](https://open.substack.com/pub/diamantai/p/how-ai-understands-us-the-secret?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true) , 2024-12-30-0913
```
Ever wondered how AI can actually â€œunderstandâ€ language? The answer lies in embeddingsâ€”a powerful technique that maps wo
rds into a multidimensional space. This allows AI to differentiate between â€œThe light is brightâ€ and â€œShe has a bright f
uture.â€

Iâ€™ve written a blog post explaining how embeddings work intuitively with examples. hope you'll like it :)
```
---

     
 
all -  [ How to build a scalable Doc Store for PDF RAG app ? ](https://www.reddit.com/r/LangChain/comments/1hne4tl/how_to_build_a_scalable_doc_store_for_pdf_rag_app/) , 2024-12-30-0913
```
Hello everyone,

I'm currently developing a PDF RAG app .

App's workflow is like : uploading a pdf , parsing it ( using
 pymupdf4llm ) , chunking it ( using Semantic Chunker ) , creating embeddings ( text-embedding-3-large ) , storing embed
dings to the Pinecone DB .

Now, along with the embeddings I store the original parsed markdown text to the PineconeDB .


This worked OK so far .

I want to develop this app into a multi modal RAG app . So I started researching how to build
 one .

I came across Alejandro's latest video (Â [https://www.youtube.com/watch?v=uLrReyH5cu0](https://www.youtube.com/w
atch?v=uLrReyH5cu0)Â ) .

Here, what he's doing is storing the original chunk in a doc store and summary of the chunk in 
the vector store.

He used Langchain's InMemoryStore as the doc store . As it is an in memory store , it isn't scalable 
, I want something that persists. Came across Langchain's LocalFileStore .

According to Langchain official docs , It wo
rks on the local file system , if I have many users , then my app server will eventually become slow .

Can it be linked
 to AWS S3 or some other storage solution ?

If yes , then how ? are there any example implementations that you guys can
 refer me to ?

If no , then how do I build one ?

I want to build the doc store user specific .

User A has UserA\_DocS
tore  
User B has UserB\_DocStore
```
---

     
 
all -  [ How to build a scalable Doc Store for PDF RAG app ? ](https://www.reddit.com/r/Rag/comments/1hne0mr/how_to_build_a_scalable_doc_store_for_pdf_rag_app/) , 2024-12-30-0913
```
Hello everyone,

I'm currently developing a PDF RAG app .   
  
App's workflow is like : uploading a pdf , parsing it ( 
using pymupdf4llm ) , chunking it ( using Semantic Chunker ) , creating embeddings ( text-embedding-3-large ) , storing 
embeddings to the Pinecone DB .

Now, along with the embeddings I store the original parsed markdown text to the Pinecon
eDB .

This worked OK so far .   
  
I want to develop this app into a multi modal RAG app . So I started researching ho
w to build one .

I came across Alejandro's latest video ( [https://www.youtube.com/watch?v=uLrReyH5cu0](https://www.you
tube.com/watch?v=uLrReyH5cu0) ) .

Here, what he's doing is storing the original chunk in a doc store and summary of the
 chunk in the vector store.   
  
He used Langchain's InMemoryStore as the doc store . As it is an in memory store , it 
isn't scalable , I want something that persists. Came across Langchain's LocalFileStore .   
  
According to Langchain o
fficial docs , It works on the local file system , if I have many users , then my app server will eventually become slow
 .   
  
Can it be linked to AWS S3 or some other storage solution ?  
  
If yes , then how ? are there any example impl
ementations that you guys can refer me to ?

If no , then how do I build one ?

I want to build the doc store user speci
fic . 

User A has UserA\_DocStore  
User B has UserB\_DocStore 
```
---

     
 
all -  [ [Student] Master's student looking for feedback on my resume and general help regarding job search ](https://www.reddit.com/r/EngineeringResumes/comments/1hn7lsc/student_masters_student_looking_for_feedback_on/) , 2024-12-30-0913
```
I am an international Master's student based in Cincinnati, looking for Robotics or Electrical engineering roles I am wo
rking on my thesis, and hope to graduate in the summer if all goes well. By going well I mean I land a job by then. I ha
ve been applying since the fall, and have had no real luck except for a couple of pre-recorded video interviews that did
 not go anywhere. Tried applying for internships but that was a dead end as well.

I have posted here before as well, an
d have to my knowledge incorporated all suggestions. At this point I am unsure what I am doing wrong. Is it my resume, l
ack of experience, the fact that I am an international student, or all three combined. I have been working on upskilling
 myself by brushing up on AutoOCAD, AutoCAD Electrical and Fusion. Is there anything else I can do to improve my resume?


I'd also appreciate any advice on what roles I should apply for, given my experience and skill set. I am open to gener
ic EE roles as well. Or is that an approach I should take? How do I narrow down?

Any suggestions or advice would be gre
atly appreciated.

https://preview.redd.it/9wpxw3stqb9e1.jpg?width=4967&format=pjpg&auto=webp&s=a32ba7566c9d41401831ccce
b40169ae19c710e6






```
---

     
 
all -  [ Langsmith Not Showing All Tokens ](https://www.reddit.com/r/LangChain/comments/1hn4e54/langsmith_not_showing_all_tokens/) , 2024-12-30-0913
```
I'm new to langchain, and I was trying out langsmith. I tried to compare token usage from langchain to the OpenAI playgr
ound for assistants. The assistant I made has a system prompt and some functions.

I made a langchain/langgraph react ag
ent with the same setup.

I prompted the model to where it would trigger one of my function calls.


---

The total toke
ns via OpenAI playground were 1713 (1608 input, 105 output).

On langsmith, it shows 267 tokens (234 input/prompt, 33 ou
tput/completion).

The difference is drastic.

If I put the final AI response from the langsmith trace into OpenAI's tok
enizer, I get 33 tokens. 

If I go to the OpenAI Chat completions playground and put the system prompt and then my user 
message, no function calling or any additional padding, I get a total of 115 input tokens. In langsmith, it also shows 1
15 input tokens.

I believe the 119 remaining input tokens are likely the function call result being passed to the model
.

It seems that langsmith is not counting tokens beyond what is passed into the message history when invoking the agent
, as well as the tool result. It doesn't include the tokens from tool definitions, and I guess anything else that langch
ain/graph add into the input prompts. This means that as far as I can tell, there is no clear way to see the actual/real
 token consumption through langsmith.

Why is that? Is there a way to configure langsmith to include all tokens?

## Edi
t:

I think I figured it out! You need to enable `stream_usage` in your model, otherwise I guess langsmith doesn't recei
ve correct usage metrics? After enabling this, langsmith now shows the correct token usage.

In my case, it's `ChatOpenA
I(model='gpt-4o-mini', stream_usage=True)`
```
---

     
 
all -  [ Build a LangGraph Customer Support Bot ](https://www.reddit.com/r/copilotkit/comments/1hn14x4/build_a_langgraph_customer_support_bot/) , 2024-12-30-0913
```
Curious if anyone has gone through this LangGraph tutorial and if so, added CopilotKit?   
[https://langchain-ai.github.
io/langgraph/tutorials/customer-support/customer-support/](https://langchain-ai.github.io/langgraph/tutorials/customer-s
upport/customer-support/)
```
---

     
 
all -  [ ai frameworks vs customs ai agents? ](https://www.reddit.com/r/AI_Agents/comments/1hn1066/ai_frameworks_vs_customs_ai_agents/) , 2024-12-30-0913
```
Iâ€™ve recently gotten into AI agents, but Iâ€™m not sure where to start.

Some people say that frameworks like LangChain an
d LlamaIndex have too many abstractions and not great for production environments. I came across Pydantic AI, and it loo
ks interesting, but itâ€™s new, so Iâ€™m not sure if itâ€™s any good.

Others say frameworks are a waste of time and that the 
best way is to build everything from scratch.

What do you guys think I should do, and how can I learn this stuff?
```
---

     
 
all -  [ Comparing PDF with JSON data ](https://www.reddit.com/r/LangChain/comments/1hmw5an/comparing_pdf_with_json_data/) , 2024-12-30-0913
```
Hi everyone, I'm new to Langchain and this is my first post here. I'm looking to write a script that compares informatio
n from a PDF file against data from a JSON file. The PDF is a one-page export from Adobe Illustrator, designed for produ
ct packaging, and the data is unstructured. I want to identify discrepancies between the two, including typos, differenc
es in values, upper/lower case differences, and spaces, and return coordinates of rectangles where are those erroros

Ca
n anyone recommend an approach for this task and share some tips and tricks? I'm just starting out with Langchain and wo
uld appreciate any guidance.

Any help or advice would be greatly appreciated. 
```
---

     
 
all -  [ [Opern Source]: Open AI Realtime with Langchain powered RAG to talk to your PDF ](https://www.reddit.com/r/OpenSourceeAI/comments/1hmuk90/opern_source_open_ai_realtime_with_langchain/) , 2024-12-30-0913
```
Hi Everyone, we are proud to share the release of our open source voice-to-voice Proof of concept where you can upload y
our documents and ask questions related to them.

You can upload your documents and interact with them through our dashb
oard.ðŸ“Š.

Based on OpenAI Realtime AND langchain

Powered by [Supabase](https://www.linkedin.com/company/supabase/)  \+ [
Qdrant](https://www.linkedin.com/company/qdrant/)  \+ [NextJs](https://www.linkedin.com/company/nextjs/)

Github repo: [
https://github.com/actualize-ae/voice-chat-pdf](https://github.com/actualize-ae/voice-chat-pdf)

Link to Playground: [ht
tps://talk-to-docs.vercel.app/](https://talk-to-docs.vercel.app/)

Demo Video: [https://vimeo.com/1039742928?share=copy]
(https://vimeo.com/1039742928?share=copy)

**If you like the concept or have feedback please feel free to contribute a s
tar and share feedback :)**

Architecture Diagram:

https://preview.redd.it/g29cnxdk5g6e1.png?width=2050&format=png&auto
=webp&s=3abdc714f810565c163d7aba3d5c4cebcf666b55


```
---

     
 
all -  [ Injustice at the NVIDIA Hackathon: Letâ€™s Support Francisco Angulo de Lafuente ](https://www.reddit.com/r/LangChain/comments/1hmuj9i/injustice_at_the_nvidia_hackathon_lets_support/) , 2024-12-30-0913
```
Greetings, I hope this space can help bring attention to an important issue. I kindly ask for your support in sharing th
is news: Francisco Angulo de Lafuente, known on Twitter as @**Francisco\_Ecofa**, won a hackathon organized by NVIDIA wi
th an incredibly complex project named **NEBULA**.

This project introduces an innovative way to optimize neural network
s using light reflections and basic principles of quantum computing instead weigths. However, despite his outstanding ac
hievement, Francisco was stripped of the prize without clear or detailed explanations.

Itâ€™s crucial that this situation
 is clarified and that NVIDIA acts transparently. I would greatly appreciate your help in spreading this news to ensure 
fairness.

Thank you for your support. ðŸ™
```
---

     
 
all -  [ Looking for a Python Library to Manage Prompt Versioning and Performance Locally ](https://www.reddit.com/r/LangChain/comments/1hmue25/looking_for_a_python_library_to_manage_prompt/) , 2024-12-30-0913
```
Hi everyone,

I'm searching for a Python library that can help manage versioning and performance tracking of prompts loc
ally during development. Ideally, the system should:

* Run on localhost
* Save prompt metrics and versions in YAML or J
SON
* Provide a UI for creating and managing prompts
* Allow consuming the created prompts both through the UI and via c
ode

Does anyone know of an existing library that fits these requirements or have suggestions on how to implement this?


Thanks in advance!
```
---

     
 
all -  [ CS Masters (UCL maybe?) ](https://www.reddit.com/r/cscareerquestionsuk/comments/1hmrk8c/cs_masters_ucl_maybe/) , 2024-12-30-0913
```
Hi all, some background: I'm a career switcher. Have an undergrad law degree from SOAS and an LLM from KCL (intellectual
 property law). 

Moved back to Singapore after graduating (not willingly, I couldn't get a training contract to qualify
 to practise English law, and this was when there was no graduate visa due to Theresa May reasons). I got qualled in Sin
gapore, practised commercial litigation for 3 years, realised I didn't like law very much, ditched it, learned to code, 


For some reason I did a data science bootcamp, then figured out I hated Jupyter notebooks, so I found a job as a data 
engineer. No idea how I convinced them that I could figure Scala out but 4 interviews later I got my current role as a S
cala Data Engineer and have been working in it for the last 9 months. 

I'm not exactly doing data engineering work per 
se, it's been all about building and maintaining a system for other data engineers to configure spark scala pipelines wi
th yaml/json and my code handles it (my fingers are still sore from the 300 pages of documentation). 

Recently, work fi
gured out I learned langchain when they weren't looking so they started getting me write python to throw AI into everyth
ing. I am having fun at work, but I'm looking ahead.

Separately, I do a bunch of random projects in my free time as wel
l, here's my personal GitHub:

https://github.com/Shredmetal

Here's where I'm at right now:

1. I want to move back to 
the UK, and honestly, while I can build a pile of stuff, my fundamentals in data structures and algorithms could use wor
k, like, a lot of work. I go play leetcode for fun when I'm not working on some project and pay for LC premium for edito
rials and explanations on how the solution works under the hood (python abstracts away a lot of stuff)

2. I suspect a l
ot of jobs are closed off to me because they see 'bootcamp' and go lol no.

3. I am considering a CS degree of some sort
. I'm not getting any younger, so a 3-year undergrad degree is out of the question.

4. Therefore, I'm wondering if a CS
 masters is the way forward, or if there are other computing degrees worth pursuing in order to actually seek employment
 in the UK.

Advice? Thanks!
```
---

     
 
all -  [ Supabase Auth with SSR + RAGðŸš€ ](https://www.reddit.com/r/Supabase/comments/1hmpblw/supabase_auth_with_ssr_rag/) , 2024-12-30-0913
```
Hey Supabase community! ðŸ‘‹

Remember that simple AI chat template I shared earlier? Well, it just got a major upgrade! I'
m excited to announce that we've added document chat capabilities (RAG) while keeping true to our core principle: keepin
g things simple and straightforward.

What's New in v1.7.0:

# ðŸŽ‰ Document Chat (RAG) Features:

https://preview.redd.it/
g4aez3jjb79e1.png?width=2554&format=png&auto=webp&s=f29ace8a181e210bbdd0766287c77556f4e002a2

* Chat with your documents
 using our simple RAG implementation
* Upload PDFs and DOCX files with ease
* Smart document processing using LlamaCloud

* Vector storage with Pinecone
* Interactive split-screen interface
* Click-to-navigate source references
* Contextual 
embeddings for improved relevancy

# ðŸš€ Core Features:

* Supabase Auth with SSR
* Multiple AI model support (GPT-3.5, GP
T-4, Claude AI Sonnet)
* Efficient chat history with pagination
* Enhanced chat interface with streaming responses
* Doc
ument viewer with source highlighting

# ðŸ“‘ Smart Document Processing Pipeline:

We've implemented a robust document proc
essing flow that circumvents serverless function limitations:

1. Client directly uploads document to Supabase Storage
2
. API route fetches the document from Supabase Storage and sends to LlamaCloud
3. Background polling checks LlamaCloud p
rocessing status every 10 seconds
4. Once processing is complete, we:
   * Download processed markdown from LlamaCloud
 
  * Generate contextual embeddings
   * Store in Pinecone
   * Ready for semantic search and chat!

Why this approach? S
erverless functions have a 4.5MB payload limit, which can be restrictive for larger documents. By uploading directly to 
Supabase Storage first, we can handle documents of much larger size while maintaining a smooth user experience. However,
 there are still limits on how long a process can run. An example would be Cloudflare have a 100s cutoff timer. It is ge
nerally recommended to host your own server somewhere handle uploading using this.

https://preview.redd.it/grntfq1qa79e
1.png?width=336&format=png&auto=webp&s=abf6770a809b5f8baee8c3e81911fa096367cb83

Who It's For:

* Developers who need bo
th chat and document QA capabilities
* Teams looking to build document-aware chatbots
* Anyone who wants to implement RA
G without reaching for tools that overcomplicates everything ( I'm talking about you Langchain...)

The Goal: To provide
 a starting point for projects that require authentication, AI chat, and document chat capabilities. It's completely fre
e, as we don't believe in charging $299 for templates (looking at you, Shitfast).

Check out the project on GitHub: [htt
ps://github.com/ElectricCodeGuy/SupabaseAuthWithSSR](https://github.com/ElectricCodeGuy/SupabaseAuthWithSSR)

Note: The 
project is functional and ready to use, but we're currently cleaning up the codebase and working on improving the docume
ntation. If you'd like to contribute, especially with the documentation or how-to guide in the README, feel free to jump
 in!

https://reddit.com/link/1hmpblw/video/pqleduora79e1/player
```
---

     
 
all -  [ Complete Generative AI Course With Langchain and Huggingface review by krish naik ](https://www.reddit.com/r/u_Specialist-Light8348/comments/1hmo45t/complete_generative_ai_course_with_langchain_and/) , 2024-12-30-0913
```
Complete Generative AI Course With Langchain and Huggingface review by krish naik
```
---

     
 
all -  [ Tables in PDF | GraphRAG ](https://www.reddit.com/r/LangChain/comments/1hmnim4/tables_in_pdf_graphrag/) , 2024-12-30-0913
```
I am working on a GraphRAG tool. My PDF contains tables too. I can create regular chunks out of the rest of the text bas
ed on a markup splitter. Now how do I consider the tables in the PDF and importantly, their position in the PDF too?  
F
or example, I dont want the tables to be separately read and embedded as text, but I want them to be embedded as present
 in their respective sections of the PDF.
```
---

     
 
all -  [ ChatOllama doesn't call Tool ](https://www.reddit.com/r/LangChain/comments/1hmkz59/chatollama_doesnt_call_tool/) , 2024-12-30-0913
```
Hi everyone, I am currently working on migrating to ChatOllama and following one of LangChain's [tutorials](https://pyth
on.langchain.com/docs/integrations/chat/ollama/#tool-calling). 

    from typing import List
    
    from langchain_oll
ama import ChatOllama
    from typing_extensions import TypedDict
    
    
    def validate_user(user_id: int, addresse
s: List) -> bool:
        '''Validate user using historical addresses.
    
        Args:
            user_id: (int) the
 user ID.
            addresses: Previous addresses.
        '''
        return True
    
    
    llm = ChatOllama(
   
     model='llama3.1:70b-instruct-fp16',
        base_url='http://localhost:11434/',
        temperature=0,
    ).bind_t
ools([validate_user])
    
    result = llm.invoke(
        'Could you validate user 123? They previously lived at '
   
     '123 Fake St in Boston MA and 234 Pretend Boulevard in '
        'Houston TX.'
    )
    result.tool_calls

However
, I am not getting the expected output. This is the output I got:

`[]`

Instead of the expected output:

    [{'name': 
'validate_user',
      'args': {'addresses': '['123 Fake St, Boston, MA', '234 Pretend Boulevard, Houston, TX']',
      
 'user_id': '123'},
      'id': '40fe3de0-500c-4b91-9616-5932a929e640',
      'type': 'tool_call'}]

  
Does anyone know
 what might cause the model to not call the tool, resulting in an empty result.tool\_calls array?
```
---

     
 
all -  [ Chroma client hosting with docker container ](https://www.reddit.com/r/LangChain/comments/1hmkf8n/chroma_client_hosting_with_docker_container/) , 2024-12-30-0913
```
I'm trying to run chromadb  on a docker container as a service and trying to access it locally or through a docker conta
iner I'm only able to create Collection and upload data to the collection

Issue: while I'm trying to query the db as a 
'persistent_clinet' im able to query it but I'm not able to access the same through 'http_client'

I'm getting the follo
wing error 

'HTTPError: 400 Client Error: Bad Request for url: http://localhost:8000/api/v1/collections/cfda7a8f-3cc7-4
7b4-877b-775d3f39dfe
3/query'

'Exception:-('error':'InvalidArgumentError','message';'Expected where to have exactly one
 operator, got )')'



Docker commands used to run as a container:

1.docker pull chromadb/chroma

2.docker run-d --rm--
name chromadb -p 8000:8000 -v ~/chroma:/chroma/chroma-e IS_PERSISTENT-TRUE-e ANONYMIZED_TELEMETRY=TRUE chromadb/chroma:l
atest
```
---

     
 
all -  [ AI code editor that works with LangChain and LangGraph? ](https://www.reddit.com/r/LangChain/comments/1hmiz5j/ai_code_editor_that_works_with_langchain_and/) , 2024-12-30-0913
```
Are there AI code editors that work with LangChain and LangGraph? For example, one can describe the use case, specify th
e use of LangChain/LangGraph, and then the editor will write the initial code for you.
```
---

     
 
all -  [ Are my projects good enough for ML Intern roles? ](https://www.reddit.com/r/learnmachinelearning/comments/1hmdn3m/are_my_projects_good_enough_for_ml_intern_roles/) , 2024-12-30-0913
```
https://preview.redd.it/0va6cae6h39e1.jpg?width=2550&format=pjpg&auto=webp&s=6f49c02de60a74483d7d640dca4aafb69a13933b


```
---

     
 
all -  [ Ways to summarize with RAG ](https://www.reddit.com/r/LangChain/comments/1hm9cvv/ways_to_summarize_with_rag/) , 2024-12-30-0913
```
â€œRAG is not designed to summarize entire bookâ€ - you may wanted to write this comment which is quite ok, I dove into ful
l internet resources, trying to find most sophisticated method to summarize user uploaded file using rag, imagine simple
 scenario, user uploads pdf book, and later asks question: â€œwho are main characters in this book?â€, what is approaches y
ou have used to get near good results? 
```
---

     
