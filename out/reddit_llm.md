 
all -  [ Advice on improving my business agent ](https://www.reddit.com/r/LangChain/comments/16i2zrv/advice_on_improving_my_business_agent/) , 2023-09-14-0909
```
I'm looking for some feedback on my agent design. I've built a simple marketing agent assistant with a tool that generat
es a report on a market using Google search, but I'd like to know if anybody has any better ideas on my agent design? Wh
at do you think could make the agent perform better?

You can find the agent design here: [https://build.firekit.ai/e42d
aa39-4758-41b5-ad8d-47153666eb03](https://build.firekit.ai/e42daa39-4758-41b5-ad8d-47153666eb03) 
```
---

     
 
all -  [ Chunking strategy in LangChain ](https://www.linkedin.com/pulse/chunking-strategy-langchain-girijesh-prasad/) , 2023-09-14-0909
```

```
---

     
 
all -  [ New formatting to improve readability - how did I do?? ](https://www.reddit.com/r/resumes/comments/16i0adt/new_formatting_to_improve_readability_how_did_i_do/) , 2023-09-14-0909
```
Got some valuable feedback on here recently about poor readability, so I've made changes and would love more harsh feedb
ack!  


I also dropped by Overview section at the top since it took up a lot of room and I've heard they're unnecessary
.   


Welcome any and all comments! Thanks so much.

&#x200B;

https://preview.redd.it/ysifuqsxh3ob1.png?width=734&form
at=png&auto=webp&s=b2d9f8edbd632f440e180529f7468f139c5d24e8
```
---

     
 
all -  [ Struggling with langchain for Web Research on Safety Tech Companies ](https://www.reddit.com/r/LangChain/comments/16hzyl6/struggling_with_langchain_for_web_research_on/) , 2023-09-14-0909
```
I've been working on a project where I utilise langchain to retrieve information about safety tech companies from variou
s websites (like LinkedIn, Crunchbase, YCombinator, and Huggingface etc..).

I'm able to get some results but it feels k
inda tame and limited, I'm trying to figure out ways to:

&#x200B;

1. **Web Retrieval Scope**: expand my search to cove
r more parts of the internet for a broader and more comprehensive dataset.
2. **Result Export**: After the retrieval and
 processing, I want to be able to sort and export the results to an Excel sheet. Each row representing a company, with t
he columns containing specific information such as the company's name, CEO, description, and so on  
.

If anyone has ex
perience with this kinda thing or similar tools and can provide insights or suggestions, I'd greatly appreciate it. I'm 
keen on getting better at this and using it more frequently . 
```
---

     
 
all -  [ Improving the performance of RAG over 10m+ documents ](https://www.reddit.com/r/LangChain/comments/16hz0nr/improving_the_performance_of_rag_over_10m/) , 2023-09-14-0909
```
What has the biggest leverage to improve the performance of RAG when operating at scale?

When I was working for a Legal
Tech startup and we had to ingest millions of litigation documents into a single vector database collection, we figured 
out that you can increase the retrieval results significantly by using an open source embedding model (sentence-transfor
mers/sentence-t5-xxl) instead of OpenAI ADA.

What other techniques do you see besides swapping the model?

We are build
ing VectorFlow an open-source vector embedding pipeline and want to know what other features we should build next after 
adding open-source Sentence Transformer embedding models. Check out our Github repo: [https://github.com/dgarnitz/vector
flow](https://github.com/dgarnitz/vectorflow) to install VectorFlow locally or t*ry it out in the playground (*[https://
app.getvectorflow.com/](https://app.getvectorflow.com/)).
```
---

     
 
all -  [ Online 'Free' Private LLMs ](https://www.reddit.com/r/UoPeople/comments/16htcdu/online_free_private_llms/) , 2023-09-14-0909
```
Greetings from Kenya, East Africa.

It is finally raining, I'm happy though most of my fellow farmers are not. Anyways,


UoPeople banned us from using ChatGPT(I haven't heard about Bard, yet). Being the lazy type, I started developing my ow
n local LLM, only to encounter '*Retrying langchain.embeddings.openai.embed\_with\_retry.<locals>.\_embed\_with\_retry i
n 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..
*' 

Meaning I had to pay. 

Being a Kenyan and the Dollar being its highest ever, I decided to look for free stuff, I t
herefore, considered installing the free Llama2 locally using HuggingFace, but instead, I found:

[https://www.quivr.app
/](https://www.quivr.app/) and

[https://powerdrill.ai/](https://powerdrill.ai/)

All I need to do is to load the Texts,
 URLs, and PDFs and I've got a 'Private' LLM.

The power of patience and selfless builders of these applications is just
 amazing!

There you go fellow classmates, these are alternatives to ChatGPT. 

Educate us on more if you do encounter t
hem. 

Those who have installed Llama2, what is your experience?

&#x200B;
```
---

     
 
all -  [ Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought ](https://www.reddit.com/r/LangChain/comments/16hrq3a/finetuning_a_gpt35_react_agent_on_better_chain_of/) , 2023-09-14-0909
```
Has anyone fine-tuned gpt\_3.5 using ReACT Agent on better Chan of Thought? How was the output as compared to an non-tra
ined gpt3.5?
```
---

     
 
all -  [ Recursive character text splitter ](https://www.reddit.com/r/node/comments/16hp24q/recursive_character_text_splitter/) , 2023-09-14-0909
```
I've been using langchain in a project, but I've recently started to migrate off it. However, the [text splitters](https
://github.com/langchain-ai/langchainjs/blob/main/langchain/src/text_splitter.ts) provided were quite useful, although it
 doesn't make sense to keep this rather large dependency for that sake. Are there any alternative npm modules that provi
de the RecursiveCharacterTextSplitter?
```
---

     
 
all -  [ Langsmith alternative ](https://www.reddit.com/r/LangChain/comments/16ho366/langsmith_alternative/) , 2023-09-14-0909
```
Hey guys,

I've tried using Langsmith but found it to be quite convoluted. Do any of you know some great alternatives? W
ould be happy about any suggestions
```
---

     
 
all -  [ Advice for langchain architecture: Location reviews for {business} ](https://www.reddit.com/r/LangChain/comments/16hnasv/advice_for_langchain_architecture_location/) , 2023-09-14-0909
```
Hello, I've been working my way around the gpt tools world, and have built 5 or 6 personal projects using different aspe
cts of tools (personal custom python script, embedding, langchain agents and tools, autogpt - have not fine tuned yet as
 I have not been able to justify the use case). I run them all through streamlit. But now I am building a production ver
sion and I am still in the weeds.

&#x200B;

TLDR: What tools should I be using? What data structures for agents and dat
a should I be using? How do i store data to make it available to the LLM? I'm sorry this turned into a novel, but maybe 
it will be edifying for others.

&#x200B;

Details:

I like my pure python / bard hacky python, for what it does. I'm tr
ying to recreate it using langchain. Here's how my script works:

\- Takes business name input from user (streamlit)

\-
 reads all initial\_prompt\_x.txt - handles formatting, questions, etc. for each review subsection

\- replace placehold
er strings with inputs

\- get results from bard

\- read filter\_prompt.txt - handles fact-checking (bard is live-data,
 which is why i did all this)

\- print final result

&#x200B;

This outputs a structured review based on different cate
gories/features that is pretty good, but it's total BS. But it is kind of langchain framework already. It has some funda
mental flaws, the core problem being, even though the data ARE live, we can't expect an LLM to know which products are c
urrently available.

&#x200B;

\*\*Goal\*\*: break down my tasks using lanchain agents and tools. Not sure if I should b
e embedding or not. Here is my pseudocode:

\- Take input (as before)

\- Use templates instead of manually constructing
 prompts with python. Use micro-prompts for ea

\- Initialize agent, llm, tools (internet browse, youtubesearch, date / 
site parser). \*\*question \*\* Should I be using use other tools? like SERP?

\- Look up website, parse to obtain produ
ct availability

\- Result storage, \*\*question\*\*. How do i store this this data? A hacky version is to store it loca
lly, and then run a prompt / template to perform tasks based on those objects. That is a bad answer. Should I be embeddi
ng all these sets? It's basically a few thousand PDFs.

\- perform data-augmented task on availability

\- assemble resu
lts into final product

&#x200B;

Does this all sound right? I could add more steps, like specifically getting reviews f
rom yelp / google / foursquare, and embedding those as well, rather than just relying on internet search? 

&#x200B;

&#
x200B;
```
---

     
 
all -  [ Help needed for langchain create_pandas_dataframe_agent with Open AI function ](https://www.reddit.com/r/LangChain/comments/16hlioz/help_needed_for_langchain_create_pandas_dataframe/) , 2023-09-14-0909
```
I’m using create_pandas_dataframe_agent  (using OpenAI Function as agent type) with a df . 

But I’m not able to place a
 memory in my agent. Ultimate goal is to built a chatbot which can query database and have a memory of previous conversa
tions. 

Previous conversations are saved but agent is not able to relate. What should be my prompt?
```
---

     
 
all -  [ Kendra retriever and Conversation Chain ](https://i.redd.it/7wtup8hul0ob1.jpg) , 2023-09-14-0909
```
using Amazonkendra Retriever but unable to pass to the Conversation Chain

referring to this github repo for chat_histor
u memory implementation as i am using amazon lex for chat.
[https://github.com/aws-samples/conversational-ai-llms-with-a
mazon-lex-and-sagemaker](https://github.com/aws-samples/conversational-ai-llms-with-amazon-lex-and-sagemaker)
```
---

     
 
all -  [ O fluxo de trabalho como full-stack focado á volta de OpenAI ChatGPT (Part 3) ](https://www.reddit.com/r/devpt/comments/16hkvys/o_fluxo_de_trabalho_como_fullstack_focado_á_volta/) , 2023-09-14-0909
```
Olá Devs,

Eu tenho feito uma série de posts em relação ao fluxo de AI para trabalhar como *software developer* ([part 2
](https://www.reddit.com/r/devpt/comments/13oi66l/o_fluxo_de_trabalho_como_fullstack_focado_%C3%A1_volta/)). Nestes últi
mos meses tem havido imensas mudanças no que apareceu no mercado e queria dar um update:

# Motivation:

**Automation do
esn't work -** Eu estava a tentar automatizar, mas não resulta. É demasiado (e.g langchain flow).

**Models and limitati
ons -** Os modelos dentro do IDE são limitados.

**Github Copilot:**

https://preview.redd.it/ktru973cd0ob1.png?width=17
40&format=png&auto=webp&s=41a695544881f93e5c8a0a1066c2000ffe9f57dc

Isto é o primeiro modelo do github copilot. Funciona
 bem para completar funções.

**Github Chat:**

https://preview.redd.it/hyl1qinmd0ob1.png?width=1386&format=png&auto=web
p&s=8efbeca469e139fd56f5ce9b9037816fe0cf9b9d

Funciona bem para coisas mais abrangentes mas fechadas. Não consegue ver a
 'big picture'. É um bocado '**meh**'

**GPT-4 superior reasoning skills:**

A principal razão para ter feito este novo 
fluxo é porque via me constantemente a entrar dentro do ChatGPT e resolver o problema que o copilot Chat não conseguia.


# New approach:

O que mudou isto foi mesmo a feature '**Advance Data Analysis/code interpreter**'. Essencialmente por 
trás tem um ecosistema de python para analysis, o que é optimo porque consegue concentrar muito mais contexto do que o m
odelo é suposto conseguir. Resolve também o problema de estar preso em **setembro de 2021**.

https://preview.redd.it/jb
erfe42e0ob1.png?width=2536&format=png&auto=webp&s=82dfcb5a94c187bf5167bb441a686b282afc7de2

1- **Setting the environment
.**

* Advance Data Analysis/code interpreter
* [Professor synapse](https://github.com/ProfSynapse/Synapse_CoR) \- Simul
a 'auto-gpt tasks'. Util para guiar o que fazer.

2- **Load Codebase and possible documentation.**

* Basta dar zip ao c
ódigo todo, que ele consegue extrair.
* Ir ao Github e ir buscar documentação se necessário (e.g nextjs, prisma)

3- **L
oad the task. Generate the code**

4- **Go back to IDE and refactor what is needed**. Em termos de testes continua igual
.

Obrigado,
```
---

     
 
all -  [ Has anyone tried running a Llama2/Lang Flow setup? ](https://www.reddit.com/r/LocalLLaMA/comments/16hj5od/has_anyone_tried_running_a_llama2lang_flow_setup/) , 2023-09-14-0909
```
Inspired by a post by the Floneum dev I was looking into alternatives to text generation. I found Lang Flow which is a G
UI for LangChain. As far as I can tell it is a node based system to integrate LangChain functionality in a node based sy
stem.

It seems to have Llama2 model support but I haven't been able to find much in the way of guides/tutorials on how 
to set up such a system. I come from a design background and have used a bit of ComfyUI for SD and use node based workfl
ows a lot in my design work.

Does anyone have an expertise with this workflow, any suggestions before I get stuck in? T
hanks.
```
---

     
 
all -  [ Top 50 Udemy Paid Courses For Free With Certificate ](https://www.reddit.com/r/Udemy/comments/16hia2p/top_50_udemy_paid_courses_for_free_with/) , 2023-09-14-0909
```
**Courses for 13 September 2023**

Note : Coupons might expire anytime, so enroll as soon as possible to get the courses
 for FREE.

* Aprende MongoDB desde cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/2675/)
* Aprende Docker, Compos
e y Swarm[REDEEM OFFER](https://idownloadcoupon.com/udemy/2674/)
* Ethically Hack the Planet Part 1[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/2673/)
* Complete Accounting + Tallyprime + Tally ERP9 + GST (4 in 1)[REDEEM OFFER](https://
idownloadcoupon.com/udemy/2672/)
* Google My Business. How to Master Powerful Tool for Company[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2671/)
* Geometry Basics to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/2670/)
* Sup
ply Chain Analytics Decoded: The Beginner’s Handbook[REDEEM OFFER](https://idownloadcoupon.com/udemy/2669/)
* Practical 
MongoDB + PHP: For Absolute Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2668/)
* Self-Care for YOUREDEEM O
FFER
* Learn Big Data Hadoop: Hands-On for Beginner[REDEEM OFFER](https://idownloadcoupon.com/udemy/2666/)
* Java And C+
+ And PHP Crash Course For Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2665/)
* 4 Practice Tests for any C
++ Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/2664/)
* Complete Windows 11 with Microsoft Copilot Mas
terclass[REDEEM OFFER](https://idownloadcoupon.com/udemy/2663/)
* Python And Flask Framework Complete Course For Beginne
rs[REDEEM OFFER](https://idownloadcoupon.com/udemy/2662/)
* Excellent Human Resources (HR) Management ( HRM) Generalist[
REDEEM OFFER](https://idownloadcoupon.com/udemy/2661/)
* Excellence in Digital Marketing (Advanced Learning Classes)[RED
EEM OFFER](https://idownloadcoupon.com/udemy/2660/)
* Personal Finance Education, Planning, Investing & Management[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2659/)
* CSS, JavaScript And Python Complete Course[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2658/)
* 2023 Gestión Ágil de Proyectos con Scrum: Curso AGILE[REDEEM OFFER](https://idownloadcou
pon.com/udemy/2657/)
* Bootstrap 5 Essentials: A Comprehensive Guide 2023[REDEEM OFFER](https://idownloadcoupon.com/udem
y/2656/)
* The Ultimate Sass & Less Course: Boost Your Web Skills 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2
655/)
* Executive Diploma in Marketing Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/2654/)
* Write Html & 
Css 5 Times Faster With Vs Code & Emmet 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2653/)
* Become a PHP Pro: 
A Step-by-Step Guide for Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2652/)
* Workshops und Seminare 
professionell vorbereiten und leiten[REDEEM OFFER](https://idownloadcoupon.com/udemy/2651/)
* Introduction to Bar Graphs
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2650/)
* Introduction to Histogram and Frequency Polygon[REDEEM OFFER](
https://idownloadcoupon.com/udemy/2649/)
* Pros and Cons of MNCs : A Comparative Study[REDEEM OFFER](https://idownloadco
upon.com/udemy/2648/)
* Writing Clear and Concise Reports: Tips and Strategies[REDEEM OFFER](https://idownloadcoupon.com
/udemy/2647/)
* Mastering the Art of Speech Writing[REDEEM OFFER](https://idownloadcoupon.com/udemy/2646/)
* Crafting Yo
ur Career: Expert Tips for a Winning Resume[REDEEM OFFER](https://idownloadcoupon.com/udemy/2645/)
* The Ultimate Guide 
to Private and Public Sector[REDEEM OFFER](https://idownloadcoupon.com/udemy/2644/)
* An In-depth Study of Antivirus Sof
tware[REDEEM OFFER](https://idownloadcoupon.com/udemy/2643/)
* Linear Equation Part- 2 Linear Equations in two Variables
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2642/)
* MAKE MONEY ONLINE: Mindset Training + Real-Life Examples[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2641/)
* Master Python using ChatGPT[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/2640/)
* How to Make Money Online for Beginners: Follow PROVEN STEPSREDEEM OFFER
* Quantity Surveying With Rate 
Analysis And Take Off-Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2638/)
* Effective Delegation – Principl
es and practical concepts[REDEEM OFFER](https://idownloadcoupon.com/udemy/2637/)
* Digital Marketing Foundation CDMA | C
DMP Pathway Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/2636/)
* Programming the Microcontroller using Mi
kroC PRO for PIC[REDEEM OFFER](https://idownloadcoupon.com/udemy/2635/)
* Microsoft Excel – Excel from Beginner to Advan
ced level[REDEEM OFFER](https://idownloadcoupon.com/udemy/2634/)
* Simulation of Electronic Circuits by Proteus in Arabi
c[REDEEM OFFER](https://idownloadcoupon.com/udemy/2633/)
* AI-Driven Cybersecurity[REDEEM OFFER](https://idownloadcoupon
.com/udemy/2632/)
* Learning the Professional Design Program Edraw Max in Arabic[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/2631/)
* Learn International Trade Negotiation Tricks In Just 2 Days[REDEEM OFFER](https://idownloadcoupon.com/
udemy/2630/)
* Ultimate Quantum Jump BluePrint[REDEEM OFFER](https://idownloadcoupon.com/udemy/2629/)
* Master LangChain
 with No-Code tools: Flowise and LangFlow[REDEEM OFFER](https://idownloadcoupon.com/udemy/2628/)
* Azure Virtual Network
 Connectivity Options[REDEEM OFFER](https://idownloadcoupon.com/udemy/2627/)
* Business Administration Executive Certifi
cation[REDEEM OFFER](https://idownloadcoupon.com/udemy/2626/)
* Microsoft PowerPoint Masterclass For Beginners[REDEEM OF
FER](https://idownloadcoupon.com/udemy/2625/)
* Dart and Flutter: The Ultimate Mobile App Development Course[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/2624/)

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://www.re
ddit.com/r/udemyfreeebies/)
```
---

     
 
all -  [ Top 50 Udemy Paid Courses For Free With Certificate | Hurry Don’t Miss | Wednesday, September 13, 20 ](https://www.reddit.com/r/udemyfreeebies/comments/16hi8n7/top_50_udemy_paid_courses_for_free_with/) , 2023-09-14-0909
```
**Courses for 13 September 2023**

Note : Coupons might expire anytime, so enroll as soon as possible to get the courses
 for FREE.

* Aprende MongoDB desde cero[REDEEM OFFER](https://idownloadcoupon.com/udemy/2675/)
* Aprende Docker, Compos
e y Swarm[REDEEM OFFER](https://idownloadcoupon.com/udemy/2674/)
* Ethically Hack the Planet Part 1[REDEEM OFFER](https:
//idownloadcoupon.com/udemy/2673/)
* Complete Accounting + Tallyprime + Tally ERP9 + GST (4 in 1)[REDEEM OFFER](https://
idownloadcoupon.com/udemy/2672/)
* Google My Business. How to Master Powerful Tool for Company[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2671/)
* Geometry Basics to Advanced[REDEEM OFFER](https://idownloadcoupon.com/udemy/2670/)
* Sup
ply Chain Analytics Decoded: The Beginner’s Handbook[REDEEM OFFER](https://idownloadcoupon.com/udemy/2669/)
* Practical 
MongoDB + PHP: For Absolute Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2668/)
* Self-Care for YOUREDEEM O
FFER
* Learn Big Data Hadoop: Hands-On for Beginner[REDEEM OFFER](https://idownloadcoupon.com/udemy/2666/)
* Java And C+
+ And PHP Crash Course For Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2665/)
* 4 Practice Tests for any C
++ Certification[REDEEM OFFER](https://idownloadcoupon.com/udemy/2664/)
* Complete Windows 11 with Microsoft Copilot Mas
terclass[REDEEM OFFER](https://idownloadcoupon.com/udemy/2663/)
* Python And Flask Framework Complete Course For Beginne
rs[REDEEM OFFER](https://idownloadcoupon.com/udemy/2662/)
* Excellent Human Resources (HR) Management ( HRM) Generalist[
REDEEM OFFER](https://idownloadcoupon.com/udemy/2661/)
* Excellence in Digital Marketing (Advanced Learning Classes)[RED
EEM OFFER](https://idownloadcoupon.com/udemy/2660/)
* Personal Finance Education, Planning, Investing & Management[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2659/)
* CSS, JavaScript And Python Complete Course[REDEEM OFFER](https://ido
wnloadcoupon.com/udemy/2658/)
* 2023 Gestión Ágil de Proyectos con Scrum: Curso AGILE[REDEEM OFFER](https://idownloadcou
pon.com/udemy/2657/)
* Bootstrap 5 Essentials: A Comprehensive Guide 2023[REDEEM OFFER](https://idownloadcoupon.com/udem
y/2656/)
* The Ultimate Sass & Less Course: Boost Your Web Skills 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2
655/)
* Executive Diploma in Marketing Management[REDEEM OFFER](https://idownloadcoupon.com/udemy/2654/)
* Write Html & 
Css 5 Times Faster With Vs Code & Emmet 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2653/)
* Become a PHP Pro: 
A Step-by-Step Guide for Beginners 2023[REDEEM OFFER](https://idownloadcoupon.com/udemy/2652/)
* Workshops und Seminare 
professionell vorbereiten und leiten[REDEEM OFFER](https://idownloadcoupon.com/udemy/2651/)
* Introduction to Bar Graphs
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2650/)
* Introduction to Histogram and Frequency Polygon[REDEEM OFFER](
https://idownloadcoupon.com/udemy/2649/)
* Pros and Cons of MNCs : A Comparative Study[REDEEM OFFER](https://idownloadco
upon.com/udemy/2648/)
* Writing Clear and Concise Reports: Tips and Strategies[REDEEM OFFER](https://idownloadcoupon.com
/udemy/2647/)
* Mastering the Art of Speech Writing[REDEEM OFFER](https://idownloadcoupon.com/udemy/2646/)
* Crafting Yo
ur Career: Expert Tips for a Winning Resume[REDEEM OFFER](https://idownloadcoupon.com/udemy/2645/)
* The Ultimate Guide 
to Private and Public Sector[REDEEM OFFER](https://idownloadcoupon.com/udemy/2644/)
* An In-depth Study of Antivirus Sof
tware[REDEEM OFFER](https://idownloadcoupon.com/udemy/2643/)
* Linear Equation Part- 2 Linear Equations in two Variables
[REDEEM OFFER](https://idownloadcoupon.com/udemy/2642/)
* MAKE MONEY ONLINE: Mindset Training + Real-Life Examples[REDEE
M OFFER](https://idownloadcoupon.com/udemy/2641/)
* Master Python using ChatGPT[REDEEM OFFER](https://idownloadcoupon.co
m/udemy/2640/)
* How to Make Money Online for Beginners: Follow PROVEN STEPSREDEEM OFFER
* Quantity Surveying With Rate 
Analysis And Take Off-Beginners[REDEEM OFFER](https://idownloadcoupon.com/udemy/2638/)
* Effective Delegation – Principl
es and practical concepts[REDEEM OFFER](https://idownloadcoupon.com/udemy/2637/)
* Digital Marketing Foundation CDMA | C
DMP Pathway Essentials[REDEEM OFFER](https://idownloadcoupon.com/udemy/2636/)
* Programming the Microcontroller using Mi
kroC PRO for PIC[REDEEM OFFER](https://idownloadcoupon.com/udemy/2635/)
* Microsoft Excel – Excel from Beginner to Advan
ced level[REDEEM OFFER](https://idownloadcoupon.com/udemy/2634/)
* Simulation of Electronic Circuits by Proteus in Arabi
c[REDEEM OFFER](https://idownloadcoupon.com/udemy/2633/)
* AI-Driven Cybersecurity[REDEEM OFFER](https://idownloadcoupon
.com/udemy/2632/)
* Learning the Professional Design Program Edraw Max in Arabic[REDEEM OFFER](https://idownloadcoupon.c
om/udemy/2631/)
* Learn International Trade Negotiation Tricks In Just 2 Days[REDEEM OFFER](https://idownloadcoupon.com/
udemy/2630/)
* Ultimate Quantum Jump BluePrint[REDEEM OFFER](https://idownloadcoupon.com/udemy/2629/)
* Master LangChain
 with No-Code tools: Flowise and LangFlow[REDEEM OFFER](https://idownloadcoupon.com/udemy/2628/)
* Azure Virtual Network
 Connectivity Options[REDEEM OFFER](https://idownloadcoupon.com/udemy/2627/)
* Business Administration Executive Certifi
cation[REDEEM OFFER](https://idownloadcoupon.com/udemy/2626/)
* Microsoft PowerPoint Masterclass For Beginners[REDEEM OF
FER](https://idownloadcoupon.com/udemy/2625/)
* Dart and Flutter: The Ultimate Mobile App Development Course[REDEEM OFFE
R](https://idownloadcoupon.com/udemy/2624/)

GET MORE FREE ONLINE COURSES WITH CERTIFICATE – [CLICK HERE](https://idownl
oadcoupon.com/)
```
---

     
 
all -  [ Can you teach an agent how to interpret information returned by the tool function? ](https://www.reddit.com/r/LangChain/comments/16ha0da/can_you_teach_an_agent_how_to_interpret/) , 2023-09-14-0909
```
I built a function that returns SQL results retrieved from a database. However, even if the function returns the correct
 information, the agent sometimes interprets it wrong.
How can I teach the agent to properly interpret the information r
eturned by the tool?
```
---

     
 
all -  [ What are other LLM's with executable API? ](https://www.reddit.com/r/LangChain/comments/16h6zmm/what_are_other_llms_with_executable_api/) , 2023-09-14-0909
```
One thing I like about GPT models is that I don't need to maintain or own a heavy infrastructure to run the model. I can
 make a call to their API and have the embeddings and inferences done. What other similar LLM's I can use where I can ma
ke an API call and get the outcomes rather than downloading huge models and maintaining on local infra?
```
---

     
 
all -  [ What ancillary services are you paying for? ](https://www.reddit.com/r/LangChain/comments/16h4vvp/what_ancillary_services_are_you_paying_for/) , 2023-09-14-0909
```
i.e. serpapi etc

And what benefit are you getting from it / what are you using it for
```
---

     
 
all -  [ Is there a way to dynamically use grammar ](https://www.reddit.com/r/Langchaindev/comments/16h4gqn/is_there_a_way_to_dynamically_use_grammar/) , 2023-09-14-0909
```
My code is below. I want to initialize the model without the grammar parameters. However, when I ask for a detailed step
 by step plan I would like that returned as a list. What is the best way to do this without having to create a new insta
nce of llamacpp?   



```
import os
import sys
import argparse
from langchain.llms import LlamaCpp
import chromadb
impo
rt json
import uuid
import re
import datetime
from langchain.chains import LLMChain
from langchain.memory import Convers
ationBufferMemory
from langchain.prompts import PromptTemplate

# Load the configuration values from the JSON file
with 
open('model_config.json', 'r') as config_file:
    config = json.load(config_file)

class TemporaryNetworkError(Exceptio
n):
    def __init__(self, message='A temporary network error occurred'):
        super().__init__(message)

class Chrom
aVectorStore:
    def __init__(self, collection_name='chroma_collection'):
        # Get the current date and time
     
   current_datetime = datetime.datetime.now()
        formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')
   
     collection_name_time = f'{formatted_datetime}_{collection_name}'

        self.chroma_client = chromadb.Client()
  
      self.chroma_client = chromadb.PersistentClient(path='./')
        self.collection = self.chroma_client.create_coll
ection(name=collection_name_time)

    def store(self, result):
        unique_id = str(uuid.uuid4())  # Generate a uniq
ue ID for the result
        # Convert result to string if it's not already
        print(type(result))
        print(re
sult)
        result_str = str(result) if not isinstance(result, str) else result
        self.collection.add(documents=
[result], ids=[unique_id])

class AutonomousAgent:
    def __init__(self, prompt_path, model_path):
        self.prompt_
path = prompt_path
        self.model_path = model_path
        self.plan = []
        self.results = []
        self.pr
ompt = ''
        self.llama = LlamaCpp(
            model_path=args.model_path,
            n_gpu_layers=config['n_gpu_
layers'],
            n_batch=config['n_batch'],
            n_threads=config['n_threads'],
            f16_kv=config['f
16_kv'],
            n_ctx=config['n_ctx'],
            max_tokens=config['max_tokens'],
            temperature=config[
'temperature'],
            verbose=config['verbose'],
            use_mlock=config['use_mlock'],
            echo=True

        )
        self.chroma_vector_store = ChromaVectorStore()

    def extract_steps(self, text):
        # Remove co
ntent between ``` ```
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)

        pattern = r'(\d+)\.\s(.*?)
(?=\d+\.|$)'
        matches = re.findall(pattern, text, re.DOTALL)
        steps_with_numbers = [(int(match[0]), match[
1].strip()) for match in matches if match[1].strip() != '']
        steps_with_numbers.sort(key=lambda x: x[0])
        
steps = [step[1] for step in steps_with_numbers]
        return steps

    def fetch_prompt(self):
        with open(sel
f.prompt_path, 'r') as file:
            self.prompt = file.read()

    def get_plan(self):
        prompt = f'''Give a 
detailed step by step plan to complete the following task. Do not include any programming code in your response. Do not 
include examples. You must return a numbered list interperable by Python. The format for a numbered list is 1. Step 1 2.
 Step 2 3. This is a more detailed step.

            {self.prompt}
            '''
        result = self.llama(prompt)

        self.plan = self.extract_steps(result)
        print('The plan is: ' + ', '.join(self.plan))

    def execute_pl
an(self):
        for step in self.plan:
            retry_count = 0
            while retry_count < 3:
                
try:
                    result = self.llama(step)
                    self.results.append((step, result))
             
       self.chroma_vector_store.store(result)
                    break
                except TemporaryNetworkError:
  
                  retry_count += 1
                    if retry_count == 3:
                        sys.exit(1)

    def
 archive_results(self):
        if not os.path.exists('output'):
            os.makedirs('output')
        current_datet
ime = datetime.datetime.now()
        formatted_datetime = current_datetime.strftime('%Y%m%d%H%M%S')
        filename = 
f'output/{formatted_datetime}_results.txt'

        with open(filename, 'w') as file:
            for step, result in se
lf.results:
                file.write(f'Query: {step}\nResult: {result}\n\n')

if __name__ == '__main__':
    parser = 
argparse.ArgumentParser(description='Autonomous agent that executes a plan based on a prompt.')
    parser.add_argument(
'--prompt_path', type=str, default='prompt.md', help='Path to the prompt file.')
    parser.add_argument('--model_path',
 type=str, required=True, help='Path to the language model file.')
    args = parser.parse_args()

    agent = Autonomou
sAgent(args.prompt_path, args.model_path)
    agent.fetch_prompt()
    agent.get_plan()
    agent.execute_plan()
    age
nt.archive_results()
```
```
---

     
 
all -  [ Langchain and embeddings: Attribution ](https://www.reddit.com/r/LangChain/comments/16h1f9y/langchain_and_embeddings_attribution/) , 2023-09-14-0909
```
Hi,
I'm using langchain, embeddings and the openai API to 'talk to my pdf documents'. When I want to verify the response
 I must open the pdf manually and use the search function. How can I generate source attributions like. Document 'xy.pdf
', Page 24, Line 3.
Is there a 'out of the box' solution or do I need to implement it by myself?
```
---

     
 
all -  [ LangChain and GPT Tokens ](https://www.reddit.com/r/LangChain/comments/16h0x6a/langchain_and_gpt_tokens/) , 2023-09-14-0909
```
I was planning on using LangChain in a recent project. Basically, I have hundreds of documents worth of text from a text
book, and I wanted to create a 'chatbot' which could return information to questions which could be found in the textboo
k. However, I realized that OpenAI doesn't offer free credits for the API anymore, so I was wondering: how many tokens w
ill it take to do all of this? Will all of the pages of the textbook count as tokens in the prompt, or will only the que
stion I ask count? I don't want to run it once and accidentally waste like 50 dollars worth of tokens.
```
---

     
 
all -  [ [P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with ](https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/) , 2023-09-14-0909
```
Hey all, we just released our new project/paper and we thought you all might find it useful!

Our project (Kani) is a su
per lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in c
allable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one li
ne (the `@ai_function()` decorator) to turn any function into an AI-callable function!

Kani works with any model and ha
s built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt e
ngineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly custo
mizable.

Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. [https://colab
.research.google.com/github/zhudotexe/kani/blob/main/examples/colab\_examples.ipynb](https://colab.research.google.com/g
ithub/zhudotexe/kani/blob/main/examples/colab_examples.ipynb)  

If you're interested in learning more check out our lin
ks below!  
Paper: [https://arxiv.org/abs/2309.05542](https://arxiv.org/abs/2309.05542)  
GitHub: [https://github.com/zh
udotexe/kani](https://github.com/zhudotexe/kani)  
Docs: [https://kani.readthedocs.io/](https://kani.readthedocs.io/)
```
---

     
 
all -  [ Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with Tool U ](https://www.reddit.com/r/LocalLLaMA/comments/16gxlor/kani_a_lightweight_highly_hackable_opensource/) , 2023-09-14-0909
```
Hey all, we just released our new project/paper and we thought you all might find it useful!

Our project (Kani) is a su
per lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in c
allable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one li
ne (the `@ai_function` decorator) to turn any function into an AI-callable function!

Kani works with any model and has 
built-in tools for HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt engineering
 under the hood and doesn't require learning complex library tools---all defaults are minimal and highly customizable.


Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. [https://colab.research.
google.com/github/zhudotexe/kani/blob/main/examples/colab\_examples.ipynb](https://colab.research.google.com/github/zhud
otexe/kani/blob/main/examples/colab_examples.ipynb)

If you're interested in learning more check out our links below!  

Paper: [https://arxiv.org/abs/2309.05542](https://arxiv.org/abs/2309.05542)  
GitHub: [https://github.com/zhudotexe/kani
](https://github.com/zhudotexe/kani)  
Docs: [https://kani.readthedocs.io/](https://kani.readthedocs.io/)
```
---

     
 
all -  [ Using LangChain and GPT in robotic projects ](https://www.reddit.com/r/LangChain/comments/16gx6wj/using_langchain_and_gpt_in_robotic_projects/) , 2023-09-14-0909
```
We are using LangChain and GPT3.5 to generate a ROS (Robot Operating System) framework for robotic projects:

[https://g
ithub.com/RoboCoachTechnologies/ROScribe](https://github.com/RoboCoachTechnologies/ROScribe)

This is a special-domain c
ode generation software. Earlier we published GPT-synthesizer as a general-domain code-generation tool:

[https://github
.com/RoboCoachTechnologies/GPT-Synthesizer](https://github.com/RoboCoachTechnologies/GPT-Synthesizer)

We are a robotic 
company and ROScribe will be our main product. We have a lot of plans on how to expand on it. I hope these softwares pro
ve useful to you. We would love to hear your feedback and have you as a contributor on our projects.
```
---

     
 
all -  [ The fine-tuned model is not getting better ](https://www.reddit.com/r/LangChain/comments/16gwgr5/the_finetuned_model_is_not_getting_better/) , 2023-09-14-0909
```
I've fine-tuned the model and I'm using it with Langchain SQL Agent to respond to SQL queries. However, I've noticed tha
t the results I'm getting are identical to those from the untrained GPT-3.5 model. To provide some context, we have appr
oximately 20 tables, and I've trained the fine-tuned model using around 50 examples so far. Below is the code I've imple
mented for the SQL agent. Could you please review it and let me know if there are any issues? Even when I pose questions
 based on the examples I've used for training, the responses appear to be incorrect. Is there something crucial that I m
ight be overlooking? I'm considering adding a few hundred more examples to the training set, but is there anything else 
I should be doing to improve the performance of the model?

&#x200B;

    finetuned_llm = ChatOpenAI(temperature=0, mode
l_name='ft:gpt-3.5-turbo-0613:xxxxx::xxxx')
    
    agent_executor = create_sql_agent(
        llm=ChatOpenAI(temperatu
re=0, model_name='gpt-3.5-turbo-0613'),
        toolkit=SQLDatabaseToolkit(db=db, llm=finetuned_llm),
        verbose=Tr
ue,
        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        top_k=5
    )

I have built the finetuned model fo
llowing this document - [https://medium.com/dataherald/fine-tuning-gpt-3-5-turbo-for-natural-language-to-sql-4445c1d37f7
c](https://medium.com/dataherald/fine-tuning-gpt-3-5-turbo-for-natural-language-to-sql-4445c1d37f7c) 
```
---

     
 
all -  [ The fine-tuned model is not getting better ](https://www.reddit.com/r/ChatGPTCoding/comments/16gwern/the_finetuned_model_is_not_getting_better/) , 2023-09-14-0909
```
I've fine-tuned the GPT3.5 model and I'm using it with Langchain SQL Agent to respond to SQL queries. However, I've noti
ced that the results I'm getting are identical to those from the untrained GPT-3.5 model. To provide some context, we ha
ve approximately 20 tables, and I've trained the fine-tuned model using around 50 examples so far. Below is the code I'v
e implemented for the SQL agent. Could you please review it and let me know if there are any issues? Even when I pose qu
estions based on the examples I've used for training, the responses appear to be incorrect. Is there something crucial t
hat I might be overlooking? I'm considering adding a few hundred more examples to the training set, but is there anythin
g else I should be doing to improve the performance of the model?

&#x200B;

    finetuned_llm = ChatOpenAI(temperature=
0, model_name='ft:gpt-3.5-turbo-0613:xxxxx::xxxx')
    
    agent_executor = create_sql_agent(
        llm=ChatOpenAI(te
mperature=0, model_name='gpt-3.5-turbo-0613'),
        toolkit=SQLDatabaseToolkit(db=db, llm=finetuned_llm),
        ver
bose=True,
        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        top_k=5
    )

&#x200B;

&#x200B;
```
---

     
 
all -  [ Discrepancy in outputs from chat.openai.com v/s via the langchain API ](https://www.reddit.com/r/ChatGPTCoding/comments/16guxui/discrepancy_in_outputs_from_chatopenaicom_vs_via/) , 2023-09-14-0909
```
I notice that the same prompt gives me fantastic results on https://chat.openai.com, and does not on `gpt-3.5-turbo-16k`
 via langchain + python. I've reduced the variables as much as I can. Does the chat console use a better model underneat
h or something?

This is roughly my code:
    
    
    llm = ChatOpenAI(
    openai_api_key=xyz,
    temperature=0.5,
 
   model_name='gpt-3.5-turbo-16k',
    streaming=True,
    cache=True,
    )    
    
     create_structured_output_chai
n(
        llm=llm,
        memory=memory,
        prompt=prompt,
        output_schema=some_pydantic_schema,
        ve
rbose=True,
    )

I set verbose to true, so langchain prints the entire prompt to console and then I can take that to t
he openai.chat.com console which gives much better results.
```
---

     
 
all -  [ Creating a RAG-System that references the name of a document where the information is from (like Bin ](https://www.reddit.com/r/LangChain/comments/16gujc5/creating_a_ragsystem_that_references_the_name_of/) , 2023-09-14-0909
```
Hey Community,

i was wondering how to create a RAG-System where the LLM can provide the Name of the Document it retriev
ed the information from. I cannot find good resources regarding this topic.  


Thanks in advance!
```
---

     
 
all -  [ I made a secure GPT-4 for my company knowledge base. ](https://www.reddit.com/r/Entrepreneur/comments/16gnmaw/i_made_a_secure_gpt4_for_my_company_knowledge_base/) , 2023-09-14-0909
```
Almost no companies integrate chat GPT with their sensitive data for obvious reasons. The OpenAI API compromises securit
y.  
  
However, Morgan Stanley just launched a GPT-4 of their entire knowledge base for every employee a few months a
go.  
  
But they really have something to hide, I thought. So there must be a secure way to do this!  
  
That thou
ght got me spending a few days in the OpenAI security rabbit hole.  
  
Turns out there is a solution - all you have t
o do is use Azure OpenAI instead of the plain old OpenAI API. Then you top it with LangChain and you have a pretty badas
s AI assistant for every single team member.  
  
You pretty much just talk to your company's SOPs, product specificat
ions, or any other structured/unstructured data.  
  
A huge time saver top-down. Senior empolyees don't get the same 
annoying questions over and over again, and the juniors get to ask the bot literally anything and anytime.  
  
So now
 I'm rolling out a project that does just this for companies (securely integrating GPT-4 for your knowledge base), and I
'm willing to do a few companies from r/EntrepreneurRideAlong for free, just to collect the case studies. Comment and le
t's collab!
```
---

     
 
all -  [ I made a secure GPT-4 for my company knowledge base. ](https://www.reddit.com/r/EntrepreneurRideAlong/comments/16gnjs8/i_made_a_secure_gpt4_for_my_company_knowledge_base/) , 2023-09-14-0909
```
Almost no companies integrate chat GPT with their sensitive data for obvious reasons. The OpenAI API compromises securit
y.

However, Morgan Stanley just launched a GPT-4 of their entire knowledge base for every employee a few months ago. 


But they really have something to hide, I thought. So there must be a secure way to do this!

That thought got me spendi
ng a few days in the OpenAI security rabbit hole.

Turns out there is a solution - all you have to do is use Azure OpenA
I instead of the plain old OpenAI API. Then you top it with LangChain and you have a pretty badass AI assistant for ever
y single team member.

You pretty much just talk to your company's SOPs, product specifications, or any other structured
/unstructured data. 

A huge time saver top-down. Senior empolyees don't get the same annoying questions over and over a
gain, and the juniors get to ask the bot literally anything and anytime.

So now I'm rolling out a project that does jus
t this for companies (securely integrating GPT-4 for your knowledge base), and I'm willing to do a few companies from r/
EntrepreneurRideAlong for free, just to collect the case studies. Comment and let's collab!
```
---

     
 
all -  [ Best LLM ](https://www.reddit.com/r/LangChain/comments/16gnidn/best_llm/) , 2023-09-14-0909
```
What is the best LLM other than GPT that is free to use? Like i want good performance for GTX 1650 and 8gb ram with i5 1
1th gen
```
---

     
 
all -  [ AzureChatOpenAI System-User-assistant input ](https://www.reddit.com/r/LangChain/comments/16gmr7a/azurechatopenai_systemuserassistant_input/) , 2023-09-14-0909
```
If I use the openai platform or use official API, i can set system user assistant message. But how can i do this in Azur
eChatOpenAI in langchain. The reason i want to use AzureChatOpenAI is because of retry implementation
```
---

     
 
all -  [ Langchain + Azure Formrecognizer: How to pass documents into agent.run()? ](https://www.reddit.com/r/Langchaindev/comments/16gl6fh/langchain_azure_formrecognizer_how_to_pass/) , 2023-09-14-0909
```

I am following a tutorial that says you should call it like this:

‘agent.run('what is the due date of the following in
voice?' 'data/Sample-Invoice-printable.png')‘

But I cannot get it to run on a local file. There is an error message tha
t the resource cannot be found.

In addition: What kind of formatting is it in the example with the two arguments not se
parated by a comma? I am confused.
```
---

     
 
all -  [ Loading a web page and returning structured output ](https://www.reddit.com/r/LangChain/comments/16gkhf4/loading_a_web_page_and_returning_structured_output/) , 2023-09-14-0909
```
I am interested to know how you all would tackle the following use case:

I want to load a url of a page that contains a
 recipe for a meal. I use the CheerioWebLoader for this in combination with the html-to-text package. I then obtain the 
document for this page, which I then divide into chunks. 

This is the part where it gets a but confusing for me. Ultima
tely I want to obtain an object from these chunks that has properties such as recipe title, preparation time, ingredient
s, etc. But I do not fully understand how I can connect Langchain's structured output parser to these chunks. 

What I w
ould do now is run a number of chat queries (such as 'What is the title of this recipe?') on these chunks and then push 
the results of these queries into an array of strings. Eventually I'll get a properly shaped response object back, but t
his is a slow process and it might take up to a minute to take a response back.

I was wondering if there is a better or
 quicker strategy to obtain structured output from a large document, such as a website.
```
---

     
 
all -  [ Best open source FUNCTION CALLING solution? ](https://www.reddit.com/r/LargeLanguageModels/comments/16gjj4x/best_open_source_function_calling_solution/) , 2023-09-14-0909
```
I love the OpenAI's function calling/arg parsing solution but I am trying to use local model. I know we can use FastChat
+Langchain to mimic it but it is very very very bad (vicuna-13b-v1.5-16k). 

my question is: any suggested model fine tu
ned for this purpose? is a bigger model will performs better? thanks
```
---

     
 
all -  [ Is langchain messing up my gpt 3.5 output? ](https://www.reddit.com/r/LangChain/comments/16ggg13/is_langchain_messing_up_my_gpt_35_output/) , 2023-09-14-0909
```
I notice that the same prompt gives me fantastic results on https://chat.openai.com, and does not on `gpt-3.5-turbo-16k`
 via langchain + python. I've reduced the variables as much as I can. Or does the chat console use a better model undern
eath or something?
```
---

     
 
all -  [ Can you use an agent in a Router Chain? ](https://www.reddit.com/r/LangChain/comments/16g9pme/can_you_use_an_agent_in_a_router_chain/) , 2023-09-14-0909
```
I'm trying to use an an agent in a router chain for a chatbot I'm developing. looking at the logs it looks like the rout
er selects the agent and passes it everything properly and the agent runs just fine. But at the parse step it fails beca
use there's no key 'text', which makes no sense to me. Any advice? Has anyone been able to do this successfully? 
```
---

     
 
all -  [ What are the hard and technical skills you need to be a Machine Learning/ Data Scientist ](https://www.reddit.com/r/PinoyProgrammer/comments/16g2cnn/what_are_the_hard_and_technical_skills_you_need/) , 2023-09-14-0909
```
# [Context]

May naka sticky na thread which can be found here [How to Become a data scientist:](https://www.reddit.com/
r/PinoyProgrammer/comments/l8zf7v/how_to_become_a_data_scientist/)

&#x200B;

[Generated with https:\/\/hotpot.ai\/](htt
ps://preview.redd.it/vk4bhtw24onb1.png?width=256&format=png&auto=webp&s=226e9825b57afda2599f66e99318298b111792c7)

Eto y
ung mga tips nya

&#x200B;

>***educational background*** *- <blah>*  
>  
>***learn the fundamentals*** *- <blah>*  
> 
 
>***rack up relevant experience*** *- <blah>*  
>  
>***apply, apply, apply***  *- <blah>*  
>  
>*Data Science jobs f
or fresh grads are a rarity back then so I took a job as a software engineer just to rack up experience, constantly join
ing Kaggle competitions and studying about DS. Finally got a job as a Data Scientist after 2 years.*

&#x200B;

Now, I'm
 **NOT** going to dispute what he has shared, but tingin ko, medyo vague yung tips and hindi ganun ka-tangible. Unfortun
ately, OP already deleted his account so no way for him to update and add more info. In case you have a new account, pls
 message me.

So, naisip ko na dagdagan with something more tangible yung tips and advice nya. By sharing the hard and t
echnical skills, the courses, MOOCS, and links that I personally used and utilized.

# [Massive Open Online Courses (MOO
Cs)]

* [Statistics for Data Science and Business Analysis](https://www.udemy.com/course/statistics-for-data-science-and
-business-analysis/)\- costs less than Php 1000, Udemy also has regular discounts pa. One can finish the course in a few
 weeks to a few months. What is important is that you, OO IKAW, don't need to rush finishing this as this is one of the 
fundamental skills. Now if you're very good in stat, no need for this. I finished this course in a month during covid
* 
[Introduction to Computational Thinking and Data Science](https://learning.edx.org/course/course-v1:MITx+6.00.2x+3T2020)
\- I took this course in EDX, may assignments, lectures, and exams. I finished this in like 2 months during the height o
f covid. This is an official course and has a certificate from the Massachusetts Institute of Technology.
* [DeepLearnin
g.AI TensorFlow Developer Professional Certificate](https://www.coursera.org/professional-certificates/tensorflow-in-pra
ctice) \- I completed this in around 2 months during the tail-end of COVID, but I was already using Tensorflow for more 
than a year. I haven't taken the official Google certification, but this was an amazing course. Intermediate to Advanced
 knowledge of Python is a must.
* [TensorFlow: Advanced Techniques Specialization](https://www.coursera.org/specializati
ons/tensorflow-advanced-techniques)\- took this course immediately after i finished the course above, it took me around 
2 months to finish. Marami akong natutunan na bagong techniques and approaches using Tensorflow.
* [Fine Tune BERT with 
Tensorflow](https://www.coursera.org/learn/fine-tune-bert-tensorflow/)**-** **Bidirectional Encoder Representations from
 Transformers (BERT),** one of the most important libraries for Natural Language Processing, released in 2018 by Google.
 During that time, it was State of the Art (SOTA) and became the de facto standard library when working with NLP with a 
Deep Learning Library.
* [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-p
rompt-engineering-for-developers/)\- You will learn how to use a large language model (LLM) to quickly build new and pow
erful applications

# [Youtube channels]

* [STATQUEST](https://www.youtube.com/@statquest)\- this guy explains very com
plex Statistics and Data science concepts and formulas in an excellent way complete with visuals, animations, and sample
 computations. Very valuable resource to help 'bake-in' the knowledge and concepts

# [Cloud Competencies and Certs]

* 
[Microsoft Azure Fundamentals](https://learn.microsoft.com/en-us/certifications/exams/az-900/)\- this is the entry cert 
for Azure Cloud, I started poking into Azure circa 2019, I took this cert during the height of COVID. Took me around 2 m
onths to review, personally run and setup  the GITHUB repos
   * I took a UDEMY course for the Fundamentals but unfortun
ately, wala na yung course sa Udemy. So here's a good alternative [https://www.udemy.com/course/az900-azure/](https://ww
w.udemy.com/course/az900-azure/)
* [Designing and Implementing a Data Science Solution on Azure](https://learn.microsoft
.com/en-us/certifications/exams/dp-100/)\- I took this during the height of COVID pandemic, I also downloaded the offici
al GITHUB repo of Microsoft then studied for this cert for around 2 months.

# [Website Memberships]

* [Kaggle.com](htt
ps://Kaggle.com) \- unarguably the largest data science community today, also leading the democratization of AI/ Machine
 Learning/ Deep Learning. Sign up for membership then study the notebooks (aka kernels), participate in the forums, uplo
ad and create datasets, as well as join competitions. They have a discord channel too which one can optionally join.
* [
Medium.com](https://Medium.com) \- good source of articles
* [Stackoverflow.com](https://Stackoverflow.com) \- no need f
or an explanation
* [Huggingface.co](https://Huggingface.com)\- Simple, safe way to store and distribute neural networks
 weights safely and quickly.

# [Python, Libraries, and others]

* **Python-** one of the best language for datascience,
 has lots of [libraries and ecosystem is very much alive.](https://survey.stackoverflow.co/2023/)
* [Adherence to PEP8 S
tandards](https://peps.python.org/pep-0008/)\- for writing beautiful Python code.
* [Creating python environments with c
onda](https://stackoverflow.com/questions/48174935/conda-creating-a-virtual-environment) **-** for modularity and managi
ng environments
* **SQL-** plain-ol' SQL, as long as you can write optimal SQL code, and you know how to join tables pro
perly and know when to use LEFT vs INNER vs OUTER.
   * I personally used SQL on POSTGRESQL, SQL SERVER, SNOWFLAKE, and 
DATABRICKS with minimal changes in syntax. MUST-LEARN.
* [Numpy](https://numpy.org/) **-** you have to get comfortable w
orking with numbers
* [Scikit-Learn](https://scikit-learn.org/) **-** scikit-learn is a free software machine learning l
ibrary for the Python programming language. It features various classification, regression and clustering algorithms
* [
Pandas](https://pandas.pydata.org/) \- you need to become very competent when massaging and aggregating data
   * [Aggre
gations](https://stackoverflow.com/a/43173207/1465073)\- bread and butter mo
* [Simple Linear Regression](https://scikit
-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)**-** Simple linear regression
* [XGBOOST
](https://xgboost.readthedocs.io/en/stable/)\- if you work with structured or tabular data, almost nothing beats XGBOOST

* [FAISS (Facebook AI Similarity Search)](https://github.com/facebookresearch/faiss)  library used to compute cosine-si
milarity among dense and sparse vectors/ embeddings.
* [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.d
ecomposition.PCA.html)**,** [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)**,** [U
MAP](https://umap-learn.readthedocs.io/en/latest/), etc- various dimension-reduction libraries, know when to use when, a
nd what.
* [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)**,** [HDBScan](https:
//scikit-learn.org/stable/modules/generated/sklearn.cluster.HDBSCAN.html)**,** etc- for clustering
* [NLTK](https://www.
nltk.org/)**-** a suite of libraries and programs for symbolic and statistical natural language processing for English w
ritten in the Python programming language
* [BERT](https://huggingface.co/blog/bert-101)\- and BERT derivations (Roberta
, ALBERT, SBERT, etc)
* [List Comprehension](https://medium.com/techtofreedom/8-levels-of-using-list-comprehension-in-py
thon-efc3c339a1f0) \- Super important
* **Other important Python libraries**\- [os](https://docs.python.org/3/library/os
.html), [re](https://docs.python.org/3/library/re.html), [requests](https://pypi.org/project/requests/), [json](https://
docs.python.org/3/library/json.html), [python](https://docs.python.org/3/library/pickle.html),  [swifter](https://github
.com/jmcarpenter2/swifter),  (and many more)
* [Scalars, Vectors, Matrices, and Tensors](https://www.stephanosterburg.co
m/math_data_types) \- Good [visualization](https://towardsdatascience.com/better-visualizing-tensors-thanks-to-cities-b9
7e6b4ca2ca), An *tensor* is an array of data (numbers, functions, etc.) which is expanded in any number (0 and greater) 
of dimensions

# [Tensorflow vs Pytorch + Keras]

* Either library would be good, but based on what I'm reading nowadays
, [Pytorch](https://pytorch.org/) seem to have the advantage. You wont get wrong with either as both Deep Learning Frame
works are very mature, well documented. I personally prefer [Tensorflow](https://www.tensorflow.org/), but if you can le
arn and be proficient with both, then much much better.

# [Kaggle + Practice (KELANGAN MO ITO)]

* [Kaggle Datasets](ht
tps://www.kaggle.com/datasets) \- download datasets that pique your interests from Kaggle
* [Kaggle Notebooks](https://w
ww.kaggle.com/code) \- best way to learn is to find a working example, with a corresponding dataset.

# [Data Visualizat
ion]

* [MATPLOTLIB](https://matplotlib.org/)\- comprehensive library for creating static, animated, and interactive vis
ualizations in Python (required)
* [Seaborn](https://seaborn.pydata.org/)**-** Python library for better visually pleasi
ng charts and graphs (optional)
* [Tableau](https://www.tableau.com/en-gb/trial/tableau-software) **vs** [PowerBI](https
://powerbi.microsoft.com/en-us/downloads/)\- optional, but I chose POWERBI kasi yun ang pinoprovide ng company namin. (o
ptional)
* **Excel- w**hen you talk to business people, this is one of the best and easiest ways to share data and chart
s (highly recommended)
* **Powerpoint-** you will be presenting your findings to business and technical people, and ever
yone in between (highly recommended)

&#x200B;

# [Cutting Edge/ State Of The Art (SOTA)]

Eto ang mga cutting edge NGAY
ON, as I write this September 12, 2023.

* [OpenAI.com](https://OpenAI.com) \- ChatGPT, no need to explain
* [Meta AI's 
Llama](https://ai.meta.com/blog/large-language-model-llama-meta-ai/)\- a state-of-the-art foundational [large language m
odel](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/) designed to help 
researchers advance their work in this subfield of AI.
* [Langchain](https://python.langchain.com/)\- is a framework for
 developing applications powered by language models.
* [Kor](https://eyurtsev.github.io/kor/tutorial.html)\- is a thin w
rapper on top of LLMs that helps to extract structured data using LLMs.
* [Pinecone](https://www.pinecone.io/)\- fully-m
anaged, developer-friendly, and easily scalable vector database
* [https://www.youtube.com/@DataIndependent](https://www
.youtube.com/@DataIndependent)
   * One of the BEST resources on how to weave and integrate Langchain + LLM (like Llama 
or ChatGPT) + your own data + [Retrieval Augmented Generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-g
eneration-RAG)

# [So you want to deploy these LLMs  on your local eh?]

* [https://huggingface.co/TheBloke/](https://hu
ggingface.co/TheBloke/)\- choose your quantized GGUF/ GGML/ GPTQ models
* [https://github.com/ggerganov/llama.cpp](https
://github.com/ggerganov/llama.cpp) \- Port of Facebook's LLaMA model in C/C++
* [https://github.com/oobabooga/text-gener
ation-webui](https://github.com/oobabooga/text-generation-webui)\- A Gradio web UI for Large Language Models. Supports t
ransformers, GPTQ, llama.cpp (GGUF), Llama models.
* [https://github.com/turboderp/exllama](https://github.com/turboderp
/exllama) \- A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weigh
ts.
* NOTE: I have a deep-learning PC and i tried all the deployments methods above

# [Nice to haves]

* **Data Pipelin
e Orchestration**\- if you have knowledge with something like [Azure Data Factory](https://azure.microsoft.com/en-us/pro
ducts/data-factory/) or [Databricks](https://www.databricks.com/) to pull data from point A to B, then much better. Most
 companies nowadays are still in the early stages of data maturity, only the FAANG level companies have dedicated Data E
ngineers to pull the data for you. Most of the time, like sa case ko, I also double down as the data engineer
* [Docker]
(https://www.docker.com/)**-** when deploying your models to production, you will most likely create images of your appl
ication with your model for containerization and will deploy it
* **Linux-** sometimes I double down as a DEVOPS person 
as well and do my own deployment of models with DOCKER in Azure, most (if not all) VMs and computes in the cloud are HEA
DLESS Linux meaning  no GUI. So you have to be somewhat proficient with Linux command like `sudo -rm -rf` , **ok dont do
 that if ayaw mong magulpi ng mga teammates mo.** But, seriously, linux proficiency is a nice to have.
* [Spacy](https:/
/spacy.io/)**-** *spaCy* is a free open-source library for Natural Language Processing in Python
* **Object Oriented Pro
gramming-** arguably not a must, but when your goal is to actually deploy models to production, your code must be very m
odular, easy to understand, and adheres to industry standards and patterns.
* [Flask](https://flask.palletsprojects.com/
en/2.3.x/)**/** [Streamlit](https://streamlit.io/)**-** for your application's web part
* [Doccano](https://github.com/d
occano/doccano)**-** open source labelling and text annotation software.
* [Beautiful Soup](https://pypi.org/project/bea
utifulsoup4/) **+** [Selenium](https://www.selenium.dev/)**-** for webscraping and automating it
* [Regex](https://regex
101.com/)**-** Yung hate mo nung college, malaking bagay ngayon
* VectorDB- like [Pinecone](https://www.pinecone.io/) or
 [Redis](https://redis.io/)
* [FASTAPI](https://fastapi.tiangolo.com/) \- FastAPI is a modern web framework for building
 RESTful APIs in Python-
* Cloud platform competencies - blob storages, cloud VMs and computes, Linux terminal, how to s
pinup services, how to deploy models, how to deploy containers, etc. Overlap with DEVOPS, but I am quite proficient so I
 can do tasks with minimal to no DEVOPS assistance.

&#x200B;

# [Software]

* **Jupyter notebook/ lab**\- notebook for 
Python
* **Visual Studio Code-** good IDE from Microsoft
* **GIT-** for storing your code, cloning repos, etc

# [Other 
Important Concepts and Misc]

* **Descriptive and Inferential statistics**
* **Measures of Central Tendency and Dispersi
on**
* **Normality Tests**
* **Null and Alternative Hypothesis**
* **Different t-tests**
* **How to read p-values**
* **
Correlation vs. Causation**
* **Confusion Matrix and Type-1 and Type-2 errors**
* **Multilabel vs. Multiclass**
* **Impu
tations**
* **Standardization vs. Normalization**
* **Scaling and different preprocessing techniques**
* **Outlier detec
tion using standard deviation, IQR**
* **Classification Metrics**\- when to use what and how to read
   * Accuracy, Prec
ision, Recall, F1-score, etc
* **Regression Metrics**
   * Mean Squared Error, Mean Absolute Error, Root Mean Squared Er
ror, R-squared, etc
* **Sparse vs. Dense Vectors**
* **Distance Metrics**
   * Euclidean Distance, Manhattan Distance, C
osine Similarity, etc
* **Dimension Reduction and curse of dimensionality**
* **Supervised, Semi-supervised, and Unsuper
vised learning**
* **Word Embeddings**
* **Tokens, unigrams, bigrams, trigrams, n-grams**
* **Handling imbalanced data**

   * SMOTE, Classweights, Undersampling, oversampling, synthetic data generation, etc
* **Data Leakage and how to ident
ify and address them**
* **Hyperparameterization**
* **(Model) Weights and biases**
* **Overfitting vs Underfitting, con
vergence**
* **Activation functions in Deep Learning**
* **Model Ensembling**
* **Encodings**
   * ascii, utf-8,  utf-16

* **File types**
   * parquet, csv, json, xml, excel
* **Gradient Descent, Learning Rates, local and global minima**
  
 * Statquest is very good in explaining the math and I manually computed the derivatives by hand as an exercise. Very go
od discussion and tutorial.
* **(And many many many, ..., many more)-** I'll leave it up to you to research these topics
, but you will naturally bump into these concepts and terms as you study and go along.

# [Related Post]

* [How to beco
me a data engineer](https://www.reddit.com/r/PinoyProgrammer/comments/166usob/comment/jym6906/?utm_source=share&utm_medi
um=web2x&context=3)

# [Notes and Advice]

* I went Azure with my cloud platform,  you can choose other cloud platforms 
like AWS and GCP
* I went Tensorflow with my Deep learning library, you can choose Pytorch here
* Nagkaroon na ng mga Ba
chelor of Science In Data Science na medyo recent lang ata na naoffer sa mga universities, I dont have visibility sa cur
riculum nila.
* Two people with the same role 'DATA SCIENTIST' can actually be doing different things.
* I believe there
 are two main flavors of data scientists, the 'theory-inclined' na mga super henyo sa mga algorithms and jargon, and the
 'implementation-inclined' na just utilizes the libraries to do the calculations, I am more of the latter.
* Sometimes t
he problem is complex, sometimes it's not, you have to know which algorithm to choose. But before everything else, you h
ave to know the problem at hand and kelangan mo maintindihan ang nuances and gain domain knowledge. Sometimes a very goo
d solution is a very simple one.
* Don't fall for those MASTER-DATA SCIENCE in 3 months snake-oil stuff, The field is fa
st evolving and no, you can't MASTER this field in 3 months.
* **I WONT SUGARCOAT**  but this is a very deep and technic
al field, if you do not have a knack for studying, burning the midnight oil, failing-miserably nang paulit-ulit, learnin
g from your mistakes, and overcoming them, **then go back**. But if you love challenges and you have the grit, soldier o
n.
* Di mo maiiwasan na makipagusap with people from other countries and various levels (c-levels, managers, fellow deve
lopers, business people, etc), so polish your communication skills.
* You must be open-minded as there are countless way
s to approach a problem, but you also have to know when to call someone's BS.
* The list above is my personal journey an
d there are countless resources, even better ones that I've mentioned. So share 'em in the comments!
* I'm far from bein
g an expert in Data Science, and I consider myself as a perpetual student who is still learning and studying.
* Keep you
r ego in check, there will always be someone better than you.
* Buy a notebook and a pen, jot down notes, solve equation
s by hand, never underestimate the hand-brain connection
* Enjoy and celebrate the small wins

# [GOOD LUCK]
```
---

     
 
MachineLearning -  [ [D] Data Extraction using fine-tuned LLM? ](https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/) , 2023-09-14-0909
```
Hey Reddit,

I'm working on a tool to pull data from highly irregular Excel files. I've gotten reasonable results which 
is extremely fast with standard Python coding, but it's far from perfect due to the lack of standardized templates. 

In
terestingly, when I tested ChatGPT-4 on a sample table, it did a decent job at data extraction. However, relying solely 
on GPT-4 has its downsides like token limits and slow processing speed (and data privacy issues). Plus, splitting the Ex
cel sheet to fit within these limits results in loss of context and data.

I'm considering fine-tuning a language model 
to post-process data that was in a Pandas DataFrame (perhaps converted to JSON). Has anyone had success with this approa
ch or have alternative recommendations? I've tried Langchain, but it wasn't helpful.

I have figured out to extract the 
relevant columns, but the post-processing part is where I am considering using an LLM which understands the domain and w
hat needs to be extracted based on the examples I feed it.

Looking forward to your thoughts! And would be happy to answ
er any additional questions.
```
---

     
 
MachineLearning -  [ [D] Chains and Agents ](https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/) , 2023-09-14-0909
```
I think there's a lot of confusion around AI agents today and it's mainly because of lack of definition and using the wr
ong terminology.

We've been talking to many companies who are claiming they're working on agents but when you look unde
r the hood, they are really just chains.

I just listened to the Latent Space pod with Harrison Chase (Founder of Langch
ain) and I really liked how he thinks about chains vs agents.

Chains: sequence of tasks in a more rigid order, where yo
u have more control, more predictability.  
Agents: handling the edge-cases, the long-tail of things that can happen.

A
nd the most important thing is that it's not an OR question but an AND one: you can use them in the same application by 
starting with chains -> figuring our the edge-cases -> using agents to deal with them.

https://preview.redd.it/l59sc4sr
i0nb1.png?width=3127&format=png&auto=webp&s=1f3f8730c48687eaabf1f554deb181cf35b96036
```
---

     
 
MachineLearning -  [ [P] FalkorDB - a fast Graph Database - Knowledge Graph as RAG ](https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/) , 2023-09-14-0909
```
We're building a fast low latency Graph Database called FalkorDB that will also support Vector search.  
It's based on R
edis and can be used both as a stand alone database or a module for existing Redis.  
It feels like that is going to be 
the most optimized way to serve Knowledge as RAG, would love to get your feedback.  
[https://github.com/FalkorDB/falkor
db](https://github.com/FalkorDB/falkordb)  


It already supports LlamIndex and Langchain:  
[https://python.langchain.c
om/docs/use\_cases/more/graph/graph\_falkordb\_qa](https://python.langchain.com/docs/use_cases/more/graph/graph_falkordb
_qa)  
[https://gpt-index.readthedocs.io/en/latest/examples/index\_structs/knowledge\_graph/FalkorDBGraphDemo.html](http
s://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/FalkorDBGraphDemo.html)

&#x200B;
```
---

     
 
MachineLearning -  [ [D] Is there anything LangChain can do better than using LLMs directly (either through a website or  ](https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/) , 2023-09-14-0909
```
I haven't used ChatGPT a lot or any other LLMs, I've been reading about  Langchain and its use cases, and I'm having tro
uble wrapping my head  around exactly what it does. From what I understand, its an alternative  interface for LLMs, allo
wing for easy switching between them, and makes  some work for specific use cases easier. If I wanted to write an app or
  script to interact with LLMs and do other tasks, how would LangChain be  better than just making API call(s) to an LLM
, getting back the result  as a string, and doing whatever with it?
```
---

     
 
MachineLearning -  [ Apache Airflow vs. LangChain and LlamaHub for LLM data pipeline [D] ](https://www.reddit.com/r/MachineLearning/comments/160lexg/apache_airflow_vs_langchain_and_llamahub_for_llm/) , 2023-09-14-0909
```
I’m looking for recommendations, suggestions, and/or good documentation that outlines which data pipeline would be best 
to ingest my private data (which will then be split into chunks/nodes for vector embeddings and so forth). Thank you in 
advance!
```
---

     
 
MachineLearning -  [ [P] LLM Apps Are Mostly Data Pipelines ](https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/) , 2023-09-14-0909
```
My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster
](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.

It contains a complete 
implementation

* with scraping context data from a docs website
* chunking it, getting embeddings via the openAI API
* 
loading it into pinecone
* and finally a simple Q&A interface with streamlit on top of it

**Here's a quick summary:**


* LangChain and LlamaIndex are great tools for quick exploration
* But aren't perfect for production-grade use
* I think
 we all know the 'LangChain is pointless' debate, but there's a lot of real meat to it, and Pat describes a few of them 
(a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)
* LLM applications are all about movin
g data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps
* A bunch of dat
a engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.
* Meltan
o is one such tool and Pat implemented the above described pipeline with it

**FWIW**: The GitHub project that comes wit
h the post is super easy to run and super modular. I just tested it and was able to modify everything for my own applica
tion within 30 mins.
```
---

     
 
MachineLearning -  [ [P] pgml-chat: A command-line tool for deploying low-latency knowledge-based chatbots ](https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/) , 2023-09-14-0909
```
We've created an open source chat bot builder, on top of PostgresML. This tool makes it easy to ingest documents and set
 a system prompt for a chatbot with knowledge of your content. The innovation is in the simplicity and efficiency, rathe
r than the functionality.

PostgresML runs open source embedding models alongside pgvector in Postgres to implement chat
 bot prompt creation without any network calls, which makes it \~4x faster than competing architectures. It can also do 
text generation with that prompt (and no additional network hops) using any open source model from HuggingFace, but it a
lso integrates with the GPT-4 API if you'd like to use that instead. 

The full writeup including some benchmarks for co
mpeting architectures is here:  [https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-kno
wledge-based-chatbots-part-I](https://postgresml.org/blog/pgml-chat-a-command-line-tool-for-deploying-low-latency-knowle
dge-based-chatbots-part-I)

You can chat with a deployment that has access to our blogs and documentation content it in 
\[our Discord\]([https://discord.com/channels/1013868243036930099/1013868243536072868](https://discord.com/channels/1013
868243036930099/1013868243536072868)), where it answers questions addressed to @PgBot.

&#x200B;

* The source code for 
the bot builder and server is only a few hundred lines of Python [https://github.com/postgresml/postgresml/tree/master/p
gml-apps/pgml-chat#readme](https://github.com/postgresml/postgresml/tree/master/pgml-apps/pgml-chat#readme)
* The chat a
pp is so small, because it's delegates all the vector db and embedding generation options to our Python client SDK, whic
h is available for anyone to build other apps with: [https://pypi.org/project/pgml/](https://pypi.org/project/pgml/)
* T
he Python client SDK is so small, because it's just a wrapper around the Rust client SDK: [https://github.com/postgresml
/postgresml/tree/master/pgml-sdks/rust/pgml](https://github.com/postgresml/postgresml/tree/master/pgml-sdks/rust/pgml). 
Currently we also support JS/Typescript SDKs as well, all generated from the same safe and efficient underlying Rust imp
lementation, using some fancy Rust macros.
* The Rust client SDK is also pretty simple though, because it just delegates
 everything to the Postgres database extension, which is where everything is computed in a single GPU accelerated proces
s, without having to load any ML models, data, or dependencies on client apps, effectively eliminating all the typical M
L data<->model network hops. Which makes it faster, simpler and safer.

This lays out what we think a is a better approa
ch to AI application architecture compared to libraries like LangChain or LlamaIndex, that focus on glueing together dis
parate data stores, algorithms, models over the network.  

```
---

     
 
MachineLearning -  [ [P] My apprehension about LangChain and why you don’t need LangChain for building a RAG bot. ](https://www.reddit.com/r/MachineLearning/comments/15ry3z4/p_my_apprehension_about_langchain_and_why_you/) , 2023-09-14-0909
```
A lot of you might be giving me a mouthful just by reading the title of this blog. But to each their own, and probably y
ou might be just riding the hype train. Initially, I was quite fascinated by the work being done on LangChain and using 
it. And so I thought I would give it a try, but when I was installing it, I saw it downloading loads and loads of other 
libraries and most of which were not useful for what I was trying to build.

Checkout the entire blog post at [https://t
hevatsalsaglani.medium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f](https://thevatsalsaglani.med
ium.com/why-you-dont-need-langchain-for-building-a-rag-bot-a1dfbc74b64f)
```
---

     
 
deeplearning -  [ How to find 'custom' datasets for LLM ](https://www.reddit.com/r/deeplearning/comments/16bj3hg/how_to_find_custom_datasets_for_llm/) , 2023-09-14-0909
```
Hey folks,

I've been digging everywhere, including here, for LLMs and custom applications. So, I read many things, lear
ned from ppl here. Its time to try something. I will try implement Llama v2 - Langchain - Chroma combination. But also I
 want to upload a dataset so that I can try my model on that. 

I find some datasets big enough (for now, 2-5 gb is ok) 
however they are table-style. I want something more texty, I mean I could use 'American Stories' or 'Arxiv' however I be
lieve that they are already used by Llama to train. 

&#x200B;

Is there any suggestions or sources that you can provide
 ? Thanks!
```
---

     
