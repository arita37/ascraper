 
all -  [ Styling stream response ](https://www.reddit.com/r/OpenAI/comments/17mh3bh/styling_stream_response/) , 2023-11-03-0909
```
Hey OpenAi community! I’m currently working on a research website where I can put in a question in the search box and it
 gives me points to answer that question:

1. Lorem ipsum

2. Lorem ipsum

For this, I am using gpt 4, langchain, NextJS
, and SerpApi. In my response, at the beginning, I want to include links to the specific sources that were being used.


Brookings    Harvard   University of Utah
…response

However, what is the best way to go over this? I want my links to b
e clickable and look nice. First I was thinking about letting my LLM write it, but that takes too long and is not too pr
etty.

Is there a way to use regex or something similar to insert my stylings?
```
---

     
 
all -  [ SolidGPT integrate with AutoGen, understand your codebase and let Multi-LLMAgent give you the code s ](https://www.reddit.com/r/AutoGenAI/comments/17mgs5f/solidgpt_integrate_with_autogen_understand_your/) , 2023-11-03-0909
```
Hi, Folks I just updated my open-source project - SolidGPT to integrate with AutoGen to improve my AI core power. I try 
to combine the LLMAgent and Chat into one task. Let me know your thoughts, are the LLMAgent and Chat two different ways?


SolidGPTn<>AutoGen. Introducing AutoGen Analysis, engage in issue-focused agent <> chat combination sessions, to get t
he most detailed insights.

Please try my new work: [https://github.com/AI-Citizen/SolidGPT](https://github.com/AI-Citiz
en/SolidGPT)

Scan and understand code with LangChain

Analysis requirement and give the response with AutoGen

&#x200B;


https://preview.redd.it/zco8n994p0yb1.png?width=3012&format=png&auto=webp&s=0ff795d3851d643e8fa418df33d9823eada2bce3
```
---

     
 
all -  [ Using GPT-4 and merging LangChain and AutoGen to create a ChatApp which can understand your codebase ](https://www.reddit.com/r/ChatGPT/comments/17mgpuw/using_gpt4_and_merging_langchain_and_autogen_to/) , 2023-11-03-0909
```
Hi, Folks I always have a question, are the LLMAgent and Chat two different ways for AI?

 I just updated my GPT4 dev ch
at app to integrate with AutoGen . I try to combine the LLMAgent and Chat into one task to give the code planbasede on t
he user codebase. Let me know your thoughts, are the LLMAgent and Chat two different ways?

Please try my new work: [htt
ps://github.com/AI-Citizen/SolidGPT](https://github.com/AI-Citizen/SolidGPT)

&#x200B;

https://preview.redd.it/j7lustb7
o0yb1.png?width=3012&format=png&auto=webp&s=35d5eb5f123a663e706e8d9e363b0637b4647ec4
```
---

     
 
all -  [ Merging LangChain and AutoGen, understand your codebase and let Multi-LLMAgent give you the code sol ](https://www.reddit.com/r/foss/comments/17mgmnt/merging_langchain_and_autogen_understand_your/) , 2023-11-03-0909
```
Hi, Folks I just updated my open-source project to integrate with AutoGen to improve my AI core power. I try to combine 
the LLMAgent and Chat into one task. Let me know your thoughts, are the LLMAgent and Chat two different ways? 

Merging 
LangChain<>AutoGen. Introducing AutoGen Analysis,  engage in issue-focused agent <> chat combination sessions, to get th
e most detailed insights.  

Please try my new work: [https://github.com/AI-Citizen/SolidGPT](https://github.com/AI-Citi
zen/SolidGPT)

Scan and understand code with LangChain

Analysis requirement and give the response with AutoGen 

https:
//preview.redd.it/enmjidzxn0yb1.png?width=3012&format=png&auto=webp&s=39bdf25c2713e26cc64e602c61f9a27c4b498975

&#x200B;

```
---

     
 
all -  [ Building a Recommendation System for a React Native ](https://www.reddit.com/r/react/comments/17mg4xn/building_a_recommendation_system_for_a_react/) , 2023-11-03-0909
```
So basically I am a beginner I want to build a React Native application specifically a dating app to practice my skills 
and knowledge I planned on using Supabase as the BE but I am pretty confused on how I would go about building the recomm
endation system so each user can get someone similar to them instead of just randomly showing any user I am thinking vec
torizing and doing some stuff like those AI Applications do using Vector DB and Langchain will work but still pretty con
fused on those also

EDIT: I might need to show why he/she/they/them was recommended maybe based on location, shared int
erest or other things

&#x200B;
```
---

     
 
all -  [ Any tips on debugging or configuration? ](https://www.reddit.com/r/ollama/comments/17mfdwd/any_tips_on_debugging_or_configuration/) , 2023-11-03-0909
```
1) Ollama rocks

2) See 1 above

Recently started using it and managed to pump a healthy amount of data through Ollama +
 llama2 with URL retrieval  on an MBP with an M2 and GPU, and have been really impressed. 

So tried out using RAG with 
chroma & langchain, and performance has been not so great. 

A single document, using OllamaEmbeddings 

\`\`\`

 'model
' : 'llama2:7b',

 'num\_gpu': 1,

 'num\_thread' : 10

\`\`\`

Doing a bit of profiling \_stream\_with\_aggregation [ht
tps://github.com/langchain-ai/langchain/blob/f66a9d2adfe84ae70bd66d957f153f975a55313e/libs/langchain/langchain/llms/olla
ma.py#L147C1-L148C1](https://github.com/langchain-ai/langchain/blob/f66a9d2adfe84ae70bd66d957f153f975a55313e/libs/langch
ain/langchain/llms/ollama.py#L147C1-L148C1)

Seems to be taking all the cumulative time and activity viewer is only show
ing me ollama-runner with 98% GPU. 

&#x200B;

What should my next steps be in terms of debugging? 

Appreciate any poin
ters
```
---

     
 
all -  [ Synology Chat LLM feedback ](https://www.reddit.com/r/synology/comments/17ma5fm/synology_chat_llm_feedback/) , 2023-11-03-0909
```
I created a thing to use with synology chat, it is a local LLM service where one is the basic talk to a llm and the othe
r uses langchain for memory and wiki Q&A. I would love some feedback and maybe help in ways to improve it.  
[https://gi
thub.com/CaptJaybles/synologyLLM](https://github.com/CaptJaybles/synologyLLM)

[https://github.com/CaptJaybles/SynoLangc
hain](https://github.com/CaptJaybles/SynoLangchain)
```
---

     
 
all -  [ LLM Fun: Building a Q&A Bot of Myself ](https://bjlkeng.io/posts/building-a-qa-bot-of-me-with-openai-and-cloudflare/) , 2023-11-03-0909
```

```
---

     
 
all -  [ My name is Jordy and I just got rickrolled by an AI agent. AMA ](https://i.redd.it/yuzovs6q1zxb1.jpg) , 2023-11-03-0909
```
I was testing it out, asked for a 2 minute cat video, got rickrolled. 

AI has developed a sense of humour before the Ge
rmans did. Chapeau.
```
---

     
 
all -  [ Vote for Cassandra in LangChain integrations. ](https://www.reddit.com/r/cassandra/comments/17m8674/vote_for_cassandra_in_langchain_integrations/) , 2023-11-03-0909
```

1) Go to https://integrations.langchain.com/
2) Sign In with email/GitHub/discord
3) Click Vector Stores filter
4) Pres
s the heart button for *Cassandra*
```
---

     
 
all -  [ Please help! Trying to get ChatGPT to work with multiple PDFs and ePubs (using old Macs running High ](https://www.reddit.com/r/ChatGPTPro/comments/17m7zk4/please_help_trying_to_get_chatgpt_to_work_with/) , 2023-11-03-0909
```
Please help!
I want to write some text, using multiple book-length (200-400 pages) PDFs and ePubs as reference. 
My plan
 was to upload the files, have ChatGPT summarize each chapter, THEN have it cross reference the different source materia
ls that I would upload into each chapter. (The chats themselves would be self-contained; they wouldn’t cross-reference e
ach other.)
I uploaded the first PDF (again, most of my source ebooks are 200-400 pages): ChatGPT said it couldn’t read 
it due to some encoding issue, then suggested that I run it through an OCR. 
Skipping to the end, I finally uploaded a T
XT file, which Chat still claimed it couldn’t work with. 
(The original PDF was 95% text, now it’s just missing a few ch
arts and diagrams, but it’s still mostly intact. So…REALLY?) 
Again: I had wanted to cycle through about a dozen differe
nt chats, with each chat requiring at least a dozen ebooks: the ebooks in the individual chats were supposed to cross-re
ference each other, but each chat is a separate, different beast. 
I’m patient enough to go through the process of reduc
ing each PDF to TXT (although now we’re talking about DOZENS of ebooks that would need to be processed) but what’s the d
eal NOW?! 
I feel like the YouTube tutorials skip a LOT of steps and general info that would be useful. 
BTW, I use 2 In
tel Macs. Both of them are more than 5 years old, and run on High Sierra. I didn’t really have problems uploading, so I’
m guessing the problem is on ChatGPT’s end, and I’m missing something. 
Most of my source material is copyrighted, but b
ecause my computers and OS are old, I can’t use GitHub solutions like Langchain, Quivr, or PrivateGPT (which I was never
, ever told BEFORE I attempted to set them up). 
Thoughts…? Advice…? Please and thank you!
```
---

     
 
all -  [ How should I go about creating a file management system that will be used for an LLM application? ](https://www.reddit.com/r/LangChain/comments/17m5cpf/how_should_i_go_about_creating_a_file_management/) , 2023-11-03-0909
```
I've built a simple LLM application using LangChain which is basically a chatbot that makes use of PDF files that I vect
orize and store in a Pinecone index. What I'm now looking for is a way to build a file management system that enables th
e user to upload new documents that are automatically vectorized. How should I go about building such a system? Is there
 any tools or resources that you can suggest?
```
---

     
 
all -  [ Is LangChain the right tool to solve my problem? ](https://www.reddit.com/r/LangChain/comments/17m4uqw/is_langchain_the_right_tool_to_solve_my_problem/) , 2023-11-03-0909
```
I need the following feature:  
The user will answer a series of questions, and based on that, there will be an output w
ith an analysis and suggestions. That will be shown to the user and saved on the db as reports.   


ChatGPT gives me a 
reasonable output, and I can work with that. The problem is there is no coherence from one output to the other. I want t
o use the previous reports so that if I have the same input, the endpoint returns the same answer, or if there is a slig
ht change in the input, the answer doesn't change drastically. Basically, to take the previous reports as the basis, use
 that and also ChatGPT.

&#x200B;

How can I use LangChain to solve this?  

```
---

     
 
all -  [ Quant Research for the Week ](https://www.reddit.com/r/quant/comments/17m4bjo/quant_research_for_the_week/) , 2023-11-03-0909
```
# ArXiv

Finance

[**Estimating Realized Correlation in High-Frequency Financial Data**](https://arxiv.org/abs/2310.1999
2): A new method for analyzing high-frequency financial data shows that intraday market changes are mainly driven by int
raday correlation changes. (2023-10-30, shares: 5)

[**Agent-based Model for Deep Hedging**](https://arxiv.org/pdf/2310.
18755.pdf): The Chiarella-Heston model, an advanced agent-based model, enhances deep hedging strategies by incorporating
 different types of traders, and performs better in creating realistic financial time series than three other models. (2
023-10-28, shares: 9)

[**Estimating Systemic Risk in Networks**](https://arxiv.org/abs/2310.18658): The article propose
s a two-step nonparametric estimation method for measuring financial systemic risk, showing that only the second step's 
estimation error affects the results. (2023-10-28, shares: 4)

[**Optimal Fees in Hedge Funds with Compensation**](http:
//dx.doi.org/10.1016/j.jbankfin.2020.105884): The research suggests alternative fee schemes for hedge funds, arguing tha
t traditional management and performance fees are suboptimal and that the recommended schemes reduce the fund's volatili
ty. (2023-10-29, shares: 3)

[**Visibility Graph Analysis of Oil Futures Markets**](https://arxiv.org/abs/2310.18903): A
 study using visibility graph methodology examines the effects of the Russia-Ukraine conflict and COVID-19 on crude oil 
futures markets, uncovering distinct market reactions to global disturbances. (2023-10-29, shares: 5)

[**Investing Char
acteristics' Impact on Financial Performance**](http://dx.doi.org/10.1109/ieem44572.2019.8978725): A research study iden
tifies 13 key investment characteristics that contribute to success in the equity market, offering a deeper understandin
g of the necessary traits for success in these markets. (2023-11-01, shares: 5)

[**Corruption's Impact on Performance**
](https://arxiv.org/abs/2310.20028): The study investigates the effect of managerial corruption on company performance, 
emphasizing the need for ethical corporate governance and careful manager selection. (2023-10-30, shares: 4)

[**Charact
erizing Law-Invariant Measures**](https://arxiv.org/abs/2310.19552): The paper introduces new characterizations for law-
invariant star-shaped functionals, demonstrating their wide use in finance, insurance, and probability scenarios. (2023-
10-30, shares: 2)

## Historical Trending

[**Optimal Execution with Machine Learning**](https://arxiv.org/abs/2204.0858
1): A study introduces a numerical algorithm using dynamic programming and deep learning for optimal order execution, hi
ghlighting the convenience of using neural-network substitutes in stochastic control issues. (2022-04-18, shares: 52)

[
**Analysis of Nonlinear Pricing**](https://arxiv.org/abs/2302.11643): A paper proposes a method to calculate the best pr
ice schedule considering consumer diversity in continuous-choice situations, demonstrating that optimal price discrimina
tion can boost a firm's profit by at least 5.5% compared to linear pricing. (2023-02-22, shares: 43)

[**Risk Evaluation
 and Robust Optimization with Model Aggregation**](https://arxiv.org/abs/2201.06370): The model aggregation (MA) approac
h is a new method for risk evaluation that provides a robust value and distributional model, refining Value-at-Risk and 
Expected Shortfall characterizations. (2022-01-17, shares: 33)

[**Deep Reinforcement Learning for Portfolio Management 
Enhancement**](https://arxiv.org/abs/1911.11880): A reinforcement learning framework for portfolio management is introdu
ced, allowing for continuous asset weights, short selling, and decision-making, with three reinforcement learning algori
thms compared for effectiveness. (2019-11-26, shares: 33)

[**Option Valuation on a Credit Index using Levy-driven Ornst
ein-Uhlenbeck Process**](https://arxiv.org/abs/2301.05332): A Levy-driven Ornstein-Uhlenbeck process is proposed to mode
l the risk-free rate and default intensities for evaluating option contracts on a credit index, with derived formulas an
d numerical experiments conducted. (2023-01-12, shares: 27)

[**TabR: Tabular DL Meets Nearest Neighbors**](https://arxi
v.org/abs/2307.14338): TabR, a new deep learning model for tabular data, outperforms existing models by using a k-Neares
t-Neighbors-like component for better predictions. (2023-07-26, shares: 68)

[**Online Estimation & Community Detection 
of Network Point Processes**](https://arxiv.org/abs/2009.01742): The research introduces a fast online variational infer
ence algorithm for estimating latent structure in dynamic event arrivals on a network, offering comparable performance t
o non-online variants with computational benefits. (2020-09-03, shares: 19)

## Crypto & Blockchain

[**NFT Market Fluct
uations: Statistical Properties**](https://arxiv.org/abs/2310.19747?utm_source=dlvr.it&utm_medium=twitter): The study sh
ows that the Non-fungible token (NFT) market, although new and unique in its trading methods, has many statistical simil
arities with traditional financial markets, with some variations in certain quantitative measures. (2023-10-30, shares: 
7)

[**High Frequency Analysis of Bitcoin Volume-Volatility**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=46150
28): Research shows that unexpected trading volume is the key factor in spot volatility in Bitcoin futures and spot mark
ets, while Bitcoin futures volumes have a calming effect on systemic volatility. (2023-10-27, shares: 2.0)

# SSRN

### 
Recently Published

## Quantitative

[**VolGAN: Realistic Volatility Surfaces**](https://papers.ssrn.com/sol3/papers.cfm
?abstract_id=4617536): VolGAN, a new model that can generate realistic scenarios for the joint dynamics of implied volat
ility surfaces and underlying assets, is introduced. (2023-10-30, shares: 173.0)

[**Machine Learning for Earnings Forec
asts**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4619313): Using machine learning models and comprehensive Co
mpustat financial statement data for earnings forecasting can yield predictions that are up to 13% more accurate than tr
aditional linear approaches. (2023-10-31, shares: 7.0)

[**Smart Beta ETFs & Increased Flow Sensitivity to Multi-Factor 
Alphas**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4620486): Smart beta ETFs trading activity significantly i
mpacts mutual fund flow sensitivity, especially in funds with high nonmarket risk factor exposure. (2023-11-01, shares: 
2.0)

[**Google Trends Credit Interest Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618881): The pap
er discusses the use of Google Trends for analyzing credit interest in Armenia, eliminating the need for traditional sur
veys by gathering online search data. (2023-10-31, shares: 2.0)

[**Projected Fuzzy C-Means Algorithm**](https://papers.
ssrn.com/sol3/papers.cfm?abstract_id=4619454): The article proposes a new algorithm for high-dimensional data clustering
 in machine learning, aiming to improve performance and manage anomalous instances. (2023-10-31, shares: 2.0)

[**KMeans
 Initialization**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4616032): The article highlights the role of clus
tering in data mining and machine learning, focusing on the Kmeans algorithm and the challenge of selecting optimal clus
ter centroids. (2023-10-28, shares: 2.0)

## Financial

[**Efficient Heston Model for Climate Contracts**](https://paper
s.ssrn.com/sol3/papers.cfm?abstract_id=4619038): A proposal suggests using Bitcoin-denominated derivatives contracts on 
carbon bonds to help governments hedge against climate change and influence carbon bond and cryptocurrency prices. (2023
-10-31, shares: 3.0)

[**Private Equity Investment & Liquidity Shocks**](https://papers.ssrn.com/sol3/papers.cfm?abstrac
t_id=4615423): Private equity investment outcomes can be influenced by investor composition, with funds from property an
d casualty insurers investing less during natural disasters, resulting in lower returns. (2023-10-27, shares: 3.0)

[**G
reen Derivatives & Climate Risk**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4615427): The EU Green Deal aims 
to make Europe carbon-neutral by 2050, requiring 1 trillion euro in sustainable investments, with derivatives markets an
d 'green derivatives' crucial for managing climate risk. (2023-10-27, shares: 4.0)

[**Time & Frequency Analysis of Oil 
Futures Market**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617533): A study of the oil futures market from 1
986 to 2020 reveals patterns and relationships between inventory, basis, hedging pressure, and futures risk premium, emp
hasizing the importance of the data measurement period. (2023-10-30, shares: 4.0)

[**Art as an Alternative Asset for Di
versification**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617318): Art and collectibles can act as alternati
ve assets for portfolio diversification, with art performing well compared to standard investments and showing a unique 
seasonal pattern in returns. (2023-10-30, shares: 4.0)

[**Indian Mutual Funds Performance Analysis**](https://papers.ss
rn.com/sol3/papers.cfm?abstract_id=4615710): The study examines the performance and risk characteristics of Indian mutua
l funds across market capitalization groups, offering insights for investors and financial professionals. (2023-10-27, s
hares: 2.0)

### Recently Updated

## Quantitative

[**The Common Factor in Volatility Risk Premia**](https://papers.ssr
n.com/sol3/papers.cfm?abstract_id=4618943): Firm-level volatility risk premium has a strong factor structure, with stock
s with the weakest exposures to the common bad volatility risk premium factor earning higher average returns, and the co
mmon factor in total bad volatility risk premium predicting stock market returns. (2023-10-31, shares: 3.0)

[**Batch-St
ochastic Sub-Gradient Method for Non-Smooth Loss Functions**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=461405
1): The new machine learning method, Batchstochastic Subgradient, offers stable loss value estimates and is more memory 
efficient, as demonstrated using SQL. (2023-10-21, shares: 2.0)

[**US. Treasuries: Liquidity Premiums and Results**](ht
tps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4619340): A new model of U.S. Treasuries suggests that liquidity facto
rs are more significant than others, Federal Reserve asset purchases impact expected rates and term premiums, and inflat
ion expectations are less stable than previously thought. (2022-05-06, shares: 2.0)

[**Global Uncertainties and Emergin
g Market Sectors**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618546): A study finds a significant link betwe
en global financial uncertainties and emerging market sectoral indices, based on data from 2008 to 2021. (2023-07-17, sh
ares: 2.0)

## Financial

[**Algorithmic Trading's Influence on Human-Only Markets**](https://papers.ssrn.com/sol3/paper
s.cfm?abstract_id=4620189): The potential existence of algorithmic trading can impact human price predictions, trading a
ctivities, and price dynamics in human-only asset markets, even if no actual algorithmic trading is present. (2023-07-17
, shares: 3.0)

[**Bond Funds and Liquidity Provision**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4614945): C
hanges in regulations have moved profits from liquidity provision in the corporate bond market to mutual funds, increasi
ng volatility and vulnerability to market disruptions like the COVID-19 pandemic. (2023-10-23, shares: 23.0)

[**ETFs an
d Market Efficiency**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4615092): Capital constraints on intermediari
es can affect the pricing efficiency of assets they manage, as seen in ETFs and their lead market makers during the COVI
D-19 debt market disruptions. (2022-03-30, shares: 369.0)

[**ETF Closures: Inaction for Investors?**](https://papers.ss
rn.com/sol3/papers.cfm?abstract_id=4620553): Research indicates smaller ExchangeTraded Funds (ETFs) often yield higher d
aily returns and typically close after positive returns. Investors usually fare better by not reacting to closure announ
cements. (2023-01-23, shares: 60.0)

[**Investor Returns: Market-Based Statistics**](https://papers.ssrn.com/sol3/papers
.cfm?abstract_id=4614148): The study presents three market-based approximations of actual return from market trades, whi
ch deviate from traditional evaluations based on time series analysis of investors' returns. (2023-04-11, shares: 25.0)


[**Cost of Capital: Cross-Sectional Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4620204): Research 
spanning 20 years across multiple countries shows that most variations in perceived capital cost are not supported by su
bsequent returns, questioning the production-based asset pricing model. (2020-12-11, shares: 2.0)

[**Equity and Credit 
Index Options: Risk & Return Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618313): A new credit risk
 model accurately prices equity and credit index options, contradicting previous claims of inconsistent pricing, and hig
hlights the need to balance three systematic risk sources. (2021-07-14, shares: 2.0)

[**Levered ETF Rebalancing: Market
 Volatility Impact**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617640): The study reveals that the interacti
on between investor behavior, ETFs fund flows, and index return autocorrelation can either temper or intensify market vo
latility, as observed during the COVID-19 pandemic onset. (2022-04-08, shares: 2.0)

# RePec

## Machine Learning

[**Ex
plainable AI Reveals Bond Excess Return Determinants**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Flin
k.springer.com%2F10.1007%2Fs11573-023-01149-5;h=repec:spr:jbecon:v:93:y:2023:i:9:d:10.1007_s11573-023-01149-5): The SHap
ley Additive exPlanations technique is used in a paper to identify key factors influencing bond excess return prediction
s made by machine learning models. (2023-11-02, shares: 21.0)

[**Forecasting volatility with machine learning: Panel da
ta perspective**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle
%2Fpii%2FS0927539823000683;h=repec:eee:empfin:v:73:y:2023:i:c:p:251-271): The study uses machine learning to predict vol
atility in high-frequency data, with panel-data-based methods proving most effective. (2023-11-02, shares: 45.0)

[**Cro
ss-market info & stock market volatility prediction**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.
sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1062940823001006;h=repec:eee:ecofin:v:68:y:2023:i:c:s1062940823001006): A
 study reveals that cross-market information greatly impacts the volatility of the Chinese stock market, especially in m
edium and long-term forecasts. (2023-11-02, shares: 18.0)

## Finance

[**Intraday profitability and trading behavior in
 algorithmic trading: Profitability and behavior in algorithmic trading.**](https://econpapers.repec.org/scripts/redir.p
f?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0264999323003334;h=repec:eee:ecmode:v:128:y:2023:i:c
:s0264999323003334): The study examines the intraday profitability and interactions among traders, revealing that algori
thmic traders profit while non-algorithmic traders lose, with market volatility causing contrasting trading behaviors. (
2023-11-02, shares: 29.0)

[**Dynamic bond portfolio optimization with a stochastic interest rate model: Bond portfolio 
optimization with stochastic interest rate model.**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Flink.s
pringer.com%2F10.1007%2Fs10690-023-09401-2;h=repec:kap:apfinm:v:30:y:2023:i:4:d:10.1007_s10690-023-09401-2): The paper i
ntroduces a new framework for multi-period dynamic bond portfolio optimization, showing that multi-period optimization o
utperforms single-period optimization, particularly over extended investment and utilization periods. (2023-11-02, share
s: 26.0)

[**Multiperiod portfolio allocation with volatility clustering and non-normalities: Portfolio allocation with 
volatility clustering and non-normalities.**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedi
rect.com%2Fscience%2Farticle%2Fpii%2FS1062940823001201;h=repec:eee:ecofin:v:68:y:2023:i:c:s1062940823001201): The resear
ch investigates the dynamic multiperiod portfolio choices of a U.S. stock market investor, discovering that considering 
volatility clustering decreases hedging demands and non-normalities slightly affect allocations. (2023-11-02, shares: 23
.0)

[**Performance of U.S. ESG ETFs**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fwww.mfa.com.my%2Fw
p-content%2Fuploads%2F2023%2F09%2Fv31_i2_a5_pg89-101.pdf;h=repec:mfa:journl:v:31:y:2023:i:2:p:89-101): A study finds tha
t ESG equity ETFs in the U.S. generally outperform the S&P 500 Index, challenging the notion that ESG investing compromi
ses financial returns. (2023-11-02, shares: 15.0)

[**High-Dimensional Portfolio Optimization with Tree-Structured Facto
rs**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS09
27538X23001774;h=repec:eee:pacfin:v:81:y:2023:i:c:s0927538x23001774): A new portfolio optimization method using a tree-s
tructured portfolio sorting technique predicts stock returns and risk exposures, outperforming benchmark strategies in t
he Chinese A-share market. (2023-11-02, shares: 15.0)

[**Volatility Smile in Emerging Markets: Dynamic Approach**](http
s://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fdoi.org%2F10.1002%2Ffut.22450;h=repec:wly:jfutmk:v:43:y:2023:i
:11:p:1615-1644): A study shows the Dynamic Nelson-Siegel model is more effective than static models for predicting vola
tility in options markets. (2023-11-02, shares: 23.0)

[**Bond-Commodity Volatility Spillover & Global Liquidity Risk**]
(https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fpanoeconomicus.org%2Findex.php%2Fjorunal%2Farticle%2Fview%
2F604%2F761;h=repec:voj:journl:v:70:y:2023:i:1:p:71-100:id:604): Research reveals significant volatility spillovers betw
een gold and bond markets, and oil and some bond markets, suggesting limited diversification benefits for investors. (20
23-11-02, shares: 20.0)

[**fBetas & Portfolio Optimization with f-Divergence Risk Measures**](https://econpapers.repec.
org/scripts/redir.pf?u=http%3A%2F%2Fhdl.handle.net%2F10.1080%2F14697688.2023.2230629;h=repec:taf:quantf:v:23:y:2023:i:10
:p:1483-1496): A new f-Beta for portfolio optimization, which assesses portfolio performance under an optimally disturbe
d market probability measure, offers flexibility and interpretability. (2023-11-02, shares: 18.0)

[**Performance of Act
ively Managed ETFs**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fwww.mfa.com.my%2Fwp-content%2Fupload
s%2F2022%2F10%2Fv30_i2_a3_pg39-61.pdf;h=repec:mfa:journl:v:30:y:2022:i:2:p:39-61): A study from 2018-2021 reveals that a
ctively managed Exchange Traded Funds (ETFs) in the U.S. did not yield significant above-market returns, indicating mana
gers lacked superior market timing skills. (2022-12-23, shares: 18.0)

# GitHub

## Trending

[**FinGAN for Financial Ti
me Series -> FinGAN for Time Series**](https://github.com/milenavuletic/Fin-GAN): This article shares the code related t
o the FinGAN paper, which uses Generative Adversarial Networks for financial time series forecasting and classification.
 (2023-10-26, shares: 16.0)

[**Easy Data Loading with DLT -> Data Loading with DLT**](https://github.com/dlt-hub/dlt): 
The article presents 'data load tool dlt', a Python library that simplifies data loading. (2022-01-26, shares: 669.0)

[
**SolidGPT: Code Collaboration**](https://github.com/AI-Citizen/SolidGPT): The article explores a platform that facilita
tes interaction with your code repository and discussion of coding needs. (2023-08-08, shares: 1369.0)

# LinkedIn

## T
rending

[**VolGAN: A Generative Model for Arbitrage-Free Volatility Surfaces**](https://www.linkedin.com/feed/update/ur
n:li:activity:7124861140286795777): The article presents VolGAN, a generative model for arbitrage-free implied volatilit
y surfaces, and discusses its performance on SPX implied volatility time series. (2023-11-01, shares: 1.0)

[**The New E
ra of Systematic Investing and Parallels to ESG**](https://www.linkedin.com/feed/update/urn:li:activity:7124757870738313
216): The article analyzes Campbell Harvey's views on the role of Machine Learning/AI in investing, discussing potential
 benefits, risks, and its relation to ESG investing. (2023-11-01, shares: 1.0)

[**Quantitative Models in Chinese Stock 
Market**](https://www.linkedin.com/feed/update/urn:li:activity:7125151875129044992): The Chinese stock market's growth a
nd adaptability make it ideal for quantitative models, as discussed at a London forum. (2023-11-01, shares: 1.0)

## Inf
ormative

[**Nasdaq's SEC-Approved AI Order Type**](https://www.linkedin.com/feed/update/urn:li:activity:712508174031801
1392): The U.S. Securities and Exchange Commission has approved Nasdaq's use of an AI-driven order type, the first of it
s kind, for executing orders. (2023-11-01, shares: 1.0)

[**New Paper on Statistical Arbitrage Portfolios**](https://www
.linkedin.com/feed/update/urn:li:activity:7124718120375660544): A new paper on statistical arbitrage portfolio construct
ion based on preference relations has been published by Fredi Šarić, Stjepan Begušić, Andro Merćep and Zvonko Kostanjcar
. (2023-11-01, shares: 1.0)

[**Machine Learning Applications: Tricky Properties and Catastrophic Forgetting**](https://
www.linkedin.com/feed/update/urn:li:activity:7125318036898660352): The article highlights the difficulties in implementi
ng machine learning applications, focusing on issues like 'catastrophic forgetting' and the need for model and data inpu
t adjustments. (2023-11-01, shares: 1.0)

[**Challenging the Belief in More Data for ML Models**](https://www.linkedin.c
om/feed/update/urn:li:activity:7125305960251715584): Clint Howard, in a seminar, challenged the notion that more data us
ed in training machine learning models always results in better performance. (2023-11-01, shares: 1.0)

[**Stock Market 
Efficiency in Pricing Climate Change Risks**](https://www.linkedin.com/feed/update/urn:li:activity:7124830762608021504):
 Man Institute researchers suggest that the stock market often underestimates the impact of climate-related news, creati
ng opportunities for savvy investors. (2023-11-01, shares: 1.0)

[**Common Domain Model (CDM): Revolutionizing Finance**
](https://www.linkedin.com/feed/update/urn:li:activity:7125255238592147457): The Common Domain Model (CDM), an open-sour
ce framework, is transforming finance by standardizing processes and reducing operational risks and costs. (2023-11-01, 
shares: 1.0)

# Podcasts

## Quantitative

[**Scariest Options Strategies Revealed**](http://advisorsoption.libsyn.com/t
he-advisors-option-130-top-5-scariest-options-strategies): The Options Insider Media Group talks about the current marke
t situation, the forthcoming earnings season, and the five most daunting options strategies. (2023-11-01, shares: 8)

[*
*Macro Volatility and Recession Risks with Boris Vladimirov**](https://macrohive.libsyn.com/boris-vladimirov-on-macro-vo
latility-us-yields-and-recession-risks): Goldman Sachs' Boris discusses fiscal policy's impact on growth, private sector
 rate sensitivity changes, and recession odds in a podcast. (2023-10-27, shares: 4)

[**Corey Hoffstein on Bitcoin ETF a
nd TBill Discussion**](https://traffic.megaphone.fm/TIFM8769633628.mp3?updated=1698795275): Corey Hoffstein and Meb disc
uss Bitcoin ETF, BlackRock's TargetDate ETFs, and the end of the 60/40 strategy on a radio show. (2023-11-01, shares: 3)


[**Efficient Use of Graphs with LLMs in GraphText**](https://dataskeptic.com/blog/episodes/2023/graph-text): In a podc
ast, Jianan Zhao, a Computer Science student, talks about the efficient use of graphs with LLMs. (2023-10-31, shares: 2)


[**In-depth Conversation with Traderade Cofounder on MH Ep.**](https://markethuddle.com/podcast/mh/): Kevin and Trader
ade Cofounder Horselover Fat discuss trading setups, Traderade's origins, and experiences in the trading industry. (2023
-10-31, shares: 1)

[**Insights on FOMC Meeting: The Financial Conditions Dummy**](https://ibkrcampus.com/podcasts/ibkr-
podcasts/its-the-financial-conditions-dummy/): Neil Azous from Rareview Capital predicts no further policy tightening ah
ead of the November FOMC meeting. (2023-10-31, shares: 1)

# Twitter

## Quantitative

[**Total Return vs. Derivative In
come in Covered Call Strategies**](https://twitter.com/quantseeker/status/1718676493969006708): Israelov and Ndong's pap
er discusses the inverse relationship between expected total return and derivative income in covered call strategies. (2
023-10-29, shares: 3)

[**Decoding the Volatility Puzzle**](https://twitter.com/quantseeker/status/1718262660926509132):
 Swedroe's article investigates the idiosyncratic volatility puzzle by studying the fundamental aspects. (2023-10-28, sh
ares: 2)

[**SciPhi ΨΦ: Custom Data Generation with LLMs**](https://twitter.com/carlcarrie/status/1718223977292685790): 
The article introduces SciPhi ΨΦ, a system for creating synthetic data to meet specific requirements using LLM-based Ope
nAI Anthropic Llama. (2023-10-28, shares: 2)

[**MS Report on Wealth Management and Generative AI Tipping Point**](https
://twitter.com/carlcarrie/status/1717945102247637161): The report by OliverWynan and MS explores the convergence of weal
th and asset management and the critical point of generative AI. (2023-10-27, shares: 2)

[**Langchain Extensions for Co
ordinated Computation**](https://twitter.com/carlcarrie/status/1719024689110974851): The article presents Permchain and 
Langchain extensions, tools that enable multiple agents to coordinate over several computation steps using LangChain Exp
ression Language and Pregel. (2023-10-30, shares: 0)

## Miscellaneous

[**Large Language Model Inferences on Stock Fact
ors**](https://twitter.com/carlcarrie/status/1717947026430677010): A new study has been released discussing the implicat
ions of Large Language Model on different stock factors. (2023-10-27, shares: 0)

[**China LLM with Advanced Question An
swering Abilities**](https://twitter.com/carlcarrie/status/1718831674862006576): Article 2: DISCFinLLM is a novel Chines
e financial LLM that features multiturn question answering, text processing, mathematical computation, and enhanced retr
ieval generation. (2023-10-30, shares: 0)

[**Abductive Reasoning in Financial Language Model Building**](https://twitte
r.com/carlcarrie/status/1718830111850385462): Article 3: A new financial LLM that uses abductive reasoning surpasses sta
ndard financial LLMs, setting new high scores in financial analysis and interpretation tasks. (2023-10-30, shares: 0)

[
**Python and R Time Series Library**](https://twitter.com/carlcarrie/status/1718780011455361268): Pytimetk is a high-per
formance timeseries library, compatible with Python and R, that utilizes Polaris dataframes for simplicity. (2023-10-30,
 shares: 0)

# Videos

## Quantitative

[**Discovering Supply Chain Edges with Graph Neural Networks**](https://www.yout
ube.com/watch?v=PtzCJvdWdJc): Achintya Gopal from Bloomberg uses graph neural networks to predict unknown suppliers and 
customers, improving supply chain risk analysis. (2023-11-01, shares: 9.0)

[**Where Did All the Quants Go?**](https://w
ww.youtube.com/watch?v=trVhkfwfzPg): A LinkedIn comment criticizes quant programs for lacking intuition and rigor, stres
sing the need for continuous learning and understanding of financial market logic and mathematics. (2023-10-29, shares: 
52.0)

# Reddit

## Quantitative

[**Two Sigma Hedge Fund Scandal**](https://www.reddit.com/r/quant/comments/17j1b1a/wsj
_news_exclusive_hedge_fund_two_sigma_is_hit_by/): The article explores the differences in pay at proprietary trading fir
ms, with some requiring negotiations on a per-portfolio manager basis. (2023-10-29, shares: 230.0)

[**Famous Quants in 
History**](https://www.reddit.com/r/quant/comments/17imr5k/who_arewere_the_most_famousinfluential_quants_of/): The autho
r is asking for suggestions of well-known quants, besides Pat Haber and Martin Artajo, whom they already know. (2023-10-
28, shares: 117.0)

[**Quant Trader in HK or SG**](https://www.reddit.com/r/quant/comments/17jio63/honk_kong_or_singapor
e/): The author is looking for guidance on a potential Quant Trader role in the Asian branches of a London hedge fund, p
articularly in Singapore and Hong Kong. (2023-10-30, shares: 17.0)

[**Million Market Experiment Loss**](https://www.red
dit.com/r/quant/comments/17jj1k2/fastest_way_to_lose_1_million_usd_in_the_quickest/): The author is exploring strategies
 for a hypothetical scenario where all money is lost through market investments as part of an experiment. (2023-10-30, s
hares: 114.0)

# Paper with Code

## Rising

[**Natural Language Graphs**](https://github.com/agiresearch/InstructGLM): 
ChatGPT, a large-scale pretrained language model, has significantly advanced various fields of artificial intelligence r
esearch. (2023-11-01, shares: 117.0)

[**Tuning Graph Instructions for Language Models**](https://github.com/HKUDS/Graph
GPT): GraphGPT uses a graph instruction tuning paradigm to align large language models with graph structural knowledge. 
(2023-10-30, shares: 92.0)

[**Graph-based Tools for Language Model Augmentation**](https://github.com/opengvlab/control
llm): ControlLLM is a new framework that enables large language models to use multimodal tools to tackle complex real-wo
rld tasks. (2023-10-31, shares: 45.0)
```
---

     
 
all -  [ Research of the week (November Week 1) ](https://www.reddit.com/r/u_OppositeMidnight/comments/17m4abb/research_of_the_week_november_week_1/) , 2023-11-03-0909
```
# ArXiv

## Finance

[**Estimating Realized Correlation in High-Frequency Financial Data**](https://arxiv.org/abs/2310.1
9992): A new method for analyzing high-frequency financial data shows that intraday market changes are mainly driven by 
intraday correlation changes. (2023-10-30, shares: 5)

[**Agent-based Model for Deep Hedging**](https://arxiv.org/pdf/23
10.18755.pdf): The Chiarella-Heston model, an advanced agent-based model, enhances deep hedging strategies by incorporat
ing different types of traders, and performs better in creating realistic financial time series than three other models.
 (2023-10-28, shares: 9)

[**Estimating Systemic Risk in Networks**](https://arxiv.org/abs/2310.18658): The article prop
oses a two-step nonparametric estimation method for measuring financial systemic risk, showing that only the second step
's estimation error affects the results. (2023-10-28, shares: 4)

[**Optimal Fees in Hedge Funds with Compensation**](ht
tp://dx.doi.org/10.1016/j.jbankfin.2020.105884): The research suggests alternative fee schemes for hedge funds, arguing 
that traditional management and performance fees are suboptimal and that the recommended schemes reduce the fund's volat
ility. (2023-10-29, shares: 3)

[**Visibility Graph Analysis of Oil Futures Markets**](https://arxiv.org/abs/2310.18903)
: A study using visibility graph methodology examines the effects of the Russia-Ukraine conflict and COVID-19 on crude o
il futures markets, uncovering distinct market reactions to global disturbances. (2023-10-29, shares: 5)

[**Investing C
haracteristics' Impact on Financial Performance**](http://dx.doi.org/10.1109/ieem44572.2019.8978725): A research study i
dentifies 13 key investment characteristics that contribute to success in the equity market, offering a deeper understan
ding of the necessary traits for success in these markets. (2023-11-01, shares: 5)

[**Corruption's Impact on Performanc
e**](https://arxiv.org/abs/2310.20028): The study investigates the effect of managerial corruption on company performanc
e, emphasizing the need for ethical corporate governance and careful manager selection. (2023-10-30, shares: 4)

[**Char
acterizing Law-Invariant Measures**](https://arxiv.org/abs/2310.19552): The paper introduces new characterizations for l
aw-invariant star-shaped functionals, demonstrating their wide use in finance, insurance, and probability scenarios. (20
23-10-30, shares: 2)

## Historical Trending

[**Optimal Execution with Machine Learning**](https://arxiv.org/abs/2204.0
8581): A study introduces a numerical algorithm using dynamic programming and deep learning for optimal order execution,
 highlighting the convenience of using neural-network substitutes in stochastic control issues. (2022-04-18, shares: 52)


[**Analysis of Nonlinear Pricing**](https://arxiv.org/abs/2302.11643): A paper proposes a method to calculate the best
 price schedule considering consumer diversity in continuous-choice situations, demonstrating that optimal price discrim
ination can boost a firm's profit by at least 5.5% compared to linear pricing. (2023-02-22, shares: 43)

[**Risk Evaluat
ion and Robust Optimization with Model Aggregation**](https://arxiv.org/abs/2201.06370): The model aggregation (MA) appr
oach is a new method for risk evaluation that provides a robust value and distributional model, refining Value-at-Risk a
nd Expected Shortfall characterizations. (2022-01-17, shares: 33)

[**Deep Reinforcement Learning for Portfolio Manageme
nt Enhancement**](https://arxiv.org/abs/1911.11880): A reinforcement learning framework for portfolio management is intr
oduced, allowing for continuous asset weights, short selling, and decision-making, with three reinforcement learning alg
orithms compared for effectiveness. (2019-11-26, shares: 33)

[**Option Valuation on a Credit Index using Levy-driven Or
nstein-Uhlenbeck Process**](https://arxiv.org/abs/2301.05332): A Levy-driven Ornstein-Uhlenbeck process is proposed to m
odel the risk-free rate and default intensities for evaluating option contracts on a credit index, with derived formulas
 and numerical experiments conducted. (2023-01-12, shares: 27)

[**TabR: Tabular DL Meets Nearest Neighbors**](https://a
rxiv.org/abs/2307.14338): TabR, a new deep learning model for tabular data, outperforms existing models by using a k-Nea
rest-Neighbors-like component for better predictions. (2023-07-26, shares: 68)

[**Online Estimation & Community Detecti
on of Network Point Processes**](https://arxiv.org/abs/2009.01742): The research introduces a fast online variational in
ference algorithm for estimating latent structure in dynamic event arrivals on a network, offering comparable performanc
e to non-online variants with computational benefits. (2020-09-03, shares: 19)

## Crypto & Blockchain

[**NFT Market Fl
uctuations: Statistical Properties**](https://arxiv.org/abs/2310.19747?utm_source=dlvr.it&utm_medium=twitter): The study
 shows that the Non-fungible token (NFT) market, although new and unique in its trading methods, has many statistical si
milarities with traditional financial markets, with some variations in certain quantitative measures. (2023-10-30, share
s: 7)

[**High Frequency Analysis of Bitcoin Volume-Volatility**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=46
15028): Research shows that unexpected trading volume is the key factor in spot volatility in Bitcoin futures and spot m
arkets, while Bitcoin futures volumes have a calming effect on systemic volatility. (2023-10-27, shares: 2.0)

# SSRN

#
## Recently Published

## Quantitative

[**VolGAN: Realistic Volatility Surfaces**](https://papers.ssrn.com/sol3/papers.
cfm?abstract_id=4617536): VolGAN, a new model that can generate realistic scenarios for the joint dynamics of implied vo
latility surfaces and underlying assets, is introduced. (2023-10-30, shares: 173.0)

[**Machine Learning for Earnings Fo
recasts**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4619313): Using machine learning models and comprehensive
 Compustat financial statement data for earnings forecasting can yield predictions that are up to 13% more accurate than
 traditional linear approaches. (2023-10-31, shares: 7.0)

[**Smart Beta ETFs & Increased Flow Sensitivity to Multi-Fact
or Alphas**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4620486): Smart beta ETFs trading activity significantl
y impacts mutual fund flow sensitivity, especially in funds with high nonmarket risk factor exposure. (2023-11-01, share
s: 2.0)

[**Google Trends Credit Interest Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618881): The 
paper discusses the use of Google Trends for analyzing credit interest in Armenia, eliminating the need for traditional 
surveys by gathering online search data. (2023-10-31, shares: 2.0)

[**Projected Fuzzy C-Means Algorithm**](https://pape
rs.ssrn.com/sol3/papers.cfm?abstract_id=4619454): The article proposes a new algorithm for high-dimensional data cluster
ing in machine learning, aiming to improve performance and manage anomalous instances. (2023-10-31, shares: 2.0)

[**KMe
ans Initialization**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4616032): The article highlights the role of c
lustering in data mining and machine learning, focusing on the Kmeans algorithm and the challenge of selecting optimal c
luster centroids. (2023-10-28, shares: 2.0)

## Financial

[**Efficient Heston Model for Climate Contracts**](https://pa
pers.ssrn.com/sol3/papers.cfm?abstract_id=4619038): A proposal suggests using Bitcoin-denominated derivatives contracts 
on carbon bonds to help governments hedge against climate change and influence carbon bond and cryptocurrency prices. (2
023-10-31, shares: 3.0)

[**Private Equity Investment & Liquidity Shocks**](https://papers.ssrn.com/sol3/papers.cfm?abst
ract_id=4615423): Private equity investment outcomes can be influenced by investor composition, with funds from property
 and casualty insurers investing less during natural disasters, resulting in lower returns. (2023-10-27, shares: 3.0)

[
**Green Derivatives & Climate Risk**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4615427): The EU Green Deal ai
ms to make Europe carbon-neutral by 2050, requiring 1 trillion euro in sustainable investments, with derivatives markets
 and 'green derivatives' crucial for managing climate risk. (2023-10-27, shares: 4.0)

[**Time & Frequency Analysis of O
il Futures Market**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617533): A study of the oil futures market fro
m 1986 to 2020 reveals patterns and relationships between inventory, basis, hedging pressure, and futures risk premium, 
emphasizing the importance of the data measurement period. (2023-10-30, shares: 4.0)

[**Art as an Alternative Asset for
 Diversification**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617318): Art and collectibles can act as altern
ative assets for portfolio diversification, with art performing well compared to standard investments and showing a uniq
ue seasonal pattern in returns. (2023-10-30, shares: 4.0)

[**Indian Mutual Funds Performance Analysis**](https://papers
.ssrn.com/sol3/papers.cfm?abstract_id=4615710): The study examines the performance and risk characteristics of Indian mu
tual funds across market capitalization groups, offering insights for investors and financial professionals. (2023-10-27
, shares: 2.0)

### Recently Updated

## Quantitative

[**The Common Factor in Volatility Risk Premia**](https://papers.
ssrn.com/sol3/papers.cfm?abstract_id=4618943): Firm-level volatility risk premium has a strong factor structure, with st
ocks with the weakest exposures to the common bad volatility risk premium factor earning higher average returns, and the
 common factor in total bad volatility risk premium predicting stock market returns. (2023-10-31, shares: 3.0)

[**Batch
-Stochastic Sub-Gradient Method for Non-Smooth Loss Functions**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=461
4051): The new machine learning method, Batchstochastic Subgradient, offers stable loss value estimates and is more memo
ry efficient, as demonstrated using SQL. (2023-10-21, shares: 2.0)

[**US. Treasuries: Liquidity Premiums and Results**]
(https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4619340): A new model of U.S. Treasuries suggests that liquidity fa
ctors are more significant than others, Federal Reserve asset purchases impact expected rates and term premiums, and inf
lation expectations are less stable than previously thought. (2022-05-06, shares: 2.0)

[**Global Uncertainties and Emer
ging Market Sectors**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618546): A study finds a significant link be
tween global financial uncertainties and emerging market sectoral indices, based on data from 2008 to 2021. (2023-07-17,
 shares: 2.0)

## Financial

[**Algorithmic Trading's Influence on Human-Only Markets**](https://papers.ssrn.com/sol3/pa
pers.cfm?abstract_id=4620189): The potential existence of algorithmic trading can impact human price predictions, tradin
g activities, and price dynamics in human-only asset markets, even if no actual algorithmic trading is present. (2023-07
-17, shares: 3.0)

[**Bond Funds and Liquidity Provision**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4614945)
: Changes in regulations have moved profits from liquidity provision in the corporate bond market to mutual funds, incre
asing volatility and vulnerability to market disruptions like the COVID-19 pandemic. (2023-10-23, shares: 23.0)

[**ETFs
 and Market Efficiency**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4615092): Capital constraints on intermedi
aries can affect the pricing efficiency of assets they manage, as seen in ETFs and their lead market makers during the C
OVID-19 debt market disruptions. (2022-03-30, shares: 369.0)

[**ETF Closures: Inaction for Investors?**](https://papers
.ssrn.com/sol3/papers.cfm?abstract_id=4620553): Research indicates smaller ExchangeTraded Funds (ETFs) often yield highe
r daily returns and typically close after positive returns. Investors usually fare better by not reacting to closure ann
ouncements. (2023-01-23, shares: 60.0)

[**Investor Returns: Market-Based Statistics**](https://papers.ssrn.com/sol3/pap
ers.cfm?abstract_id=4614148): The study presents three market-based approximations of actual return from market trades, 
which deviate from traditional evaluations based on time series analysis of investors' returns. (2023-04-11, shares: 25.
0)

[**Cost of Capital: Cross-Sectional Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4620204): Resear
ch spanning 20 years across multiple countries shows that most variations in perceived capital cost are not supported by
 subsequent returns, questioning the production-based asset pricing model. (2020-12-11, shares: 2.0)

[**Equity and Cred
it Index Options: Risk & Return Analysis**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4618313): A new credit r
isk model accurately prices equity and credit index options, contradicting previous claims of inconsistent pricing, and 
highlights the need to balance three systematic risk sources. (2021-07-14, shares: 2.0)

[**Levered ETF Rebalancing: Mar
ket Volatility Impact**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4617640): The study reveals that the intera
ction between investor behavior, ETFs fund flows, and index return autocorrelation can either temper or intensify market
 volatility, as observed during the COVID-19 pandemic onset. (2022-04-08, shares: 2.0)

# RePec

## Machine Learning

[*
*Explainable AI Reveals Bond Excess Return Determinants**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2F
link.springer.com%2F10.1007%2Fs11573-023-01149-5;h=repec:spr:jbecon:v:93:y:2023:i:9:d:10.1007_s11573-023-01149-5): The S
Hapley Additive exPlanations technique is used in a paper to identify key factors influencing bond excess return predict
ions made by machine learning models. (2023-11-02, shares: 21.0)

[**Forecasting volatility with machine learning: Panel
 data perspective**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farti
cle%2Fpii%2FS0927539823000683;h=repec:eee:empfin:v:73:y:2023:i:c:p:251-271): The study uses machine learning to predict 
volatility in high-frequency data, with panel-data-based methods proving most effective. (2023-11-02, shares: 45.0)

[**
Cross-market info & stock market volatility prediction**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fw
ww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1062940823001006;h=repec:eee:ecofin:v:68:y:2023:i:c:s1062940823001006)
: A study reveals that cross-market information greatly impacts the volatility of the Chinese stock market, especially i
n medium and long-term forecasts. (2023-11-02, shares: 18.0)

## Finance

[**Intraday profitability and trading behavior
 in algorithmic trading: Profitability and behavior in algorithmic trading.**](https://econpapers.repec.org/scripts/redi
r.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0264999323003334;h=repec:eee:ecmode:v:128:y:2023:
i:c:s0264999323003334): The study examines the intraday profitability and interactions among traders, revealing that alg
orithmic traders profit while non-algorithmic traders lose, with market volatility causing contrasting trading behaviors
. (2023-11-02, shares: 29.0)

[**Dynamic bond portfolio optimization with a stochastic interest rate model: Bond portfol
io optimization with stochastic interest rate model.**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Flin
k.springer.com%2F10.1007%2Fs10690-023-09401-2;h=repec:kap:apfinm:v:30:y:2023:i:4:d:10.1007_s10690-023-09401-2): The pape
r introduces a new framework for multi-period dynamic bond portfolio optimization, showing that multi-period optimizatio
n outperforms single-period optimization, particularly over extended investment and utilization periods. (2023-11-02, sh
ares: 26.0)

[**Multiperiod portfolio allocation with volatility clustering and non-normalities: Portfolio allocation wi
th volatility clustering and non-normalities.**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.scienc
edirect.com%2Fscience%2Farticle%2Fpii%2FS1062940823001201;h=repec:eee:ecofin:v:68:y:2023:i:c:s1062940823001201): The res
earch investigates the dynamic multiperiod portfolio choices of a U.S. stock market investor, discovering that consideri
ng volatility clustering decreases hedging demands and non-normalities slightly affect allocations. (2023-11-02, shares:
 23.0)

[**Performance of U.S. ESG ETFs**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fwww.mfa.com.my%
2Fwp-content%2Fuploads%2F2023%2F09%2Fv31_i2_a5_pg89-101.pdf;h=repec:mfa:journl:v:31:y:2023:i:2:p:89-101): A study finds 
that ESG equity ETFs in the U.S. generally outperform the S&P 500 Index, challenging the notion that ESG investing compr
omises financial returns. (2023-11-02, shares: 15.0)

[**High-Dimensional Portfolio Optimization with Tree-Structured Fa
ctors**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2F
S0927538X23001774;h=repec:eee:pacfin:v:81:y:2023:i:c:s0927538x23001774): A new portfolio optimization method using a tre
e-structured portfolio sorting technique predicts stock returns and risk exposures, outperforming benchmark strategies i
n the Chinese A-share market. (2023-11-02, shares: 15.0)

[**Volatility Smile in Emerging Markets: Dynamic Approach**](h
ttps://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fdoi.org%2F10.1002%2Ffut.22450;h=repec:wly:jfutmk:v:43:y:202
3:i:11:p:1615-1644): A study shows the Dynamic Nelson-Siegel model is more effective than static models for predicting v
olatility in options markets. (2023-11-02, shares: 23.0)

[**Bond-Commodity Volatility Spillover & Global Liquidity Risk
**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fpanoeconomicus.org%2Findex.php%2Fjorunal%2Farticle%2Fvi
ew%2F604%2F761;h=repec:voj:journl:v:70:y:2023:i:1:p:71-100:id:604): Research reveals significant volatility spillovers b
etween gold and bond markets, and oil and some bond markets, suggesting limited diversification benefits for investors. 
(2023-11-02, shares: 20.0)

[**fBetas & Portfolio Optimization with f-Divergence Risk Measures**](https://econpapers.rep
ec.org/scripts/redir.pf?u=http%3A%2F%2Fhdl.handle.net%2F10.1080%2F14697688.2023.2230629;h=repec:taf:quantf:v:23:y:2023:i
:10:p:1483-1496): A new f-Beta for portfolio optimization, which assesses portfolio performance under an optimally distu
rbed market probability measure, offers flexibility and interpretability. (2023-11-02, shares: 18.0)

[**Performance of 
Actively Managed ETFs**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fwww.mfa.com.my%2Fwp-content%2Fupl
oads%2F2022%2F10%2Fv30_i2_a3_pg39-61.pdf;h=repec:mfa:journl:v:30:y:2022:i:2:p:39-61): A study from 2018-2021 reveals tha
t actively managed Exchange Traded Funds (ETFs) in the U.S. did not yield significant above-market returns, indicating m
anagers lacked superior market timing skills. (2022-12-23, shares: 18.0)

# GitHub

## Trending

[**FinGAN for Financial
 Time Series -> FinGAN for Time Series**](https://github.com/milenavuletic/Fin-GAN): This article shares the code relate
d to the FinGAN paper, which uses Generative Adversarial Networks for financial time series forecasting and classificati
on. (2023-10-26, shares: 16.0)

[**Easy Data Loading with DLT -> Data Loading with DLT**](https://github.com/dlt-hub/dlt
): The article presents 'data load tool dlt', a Python library that simplifies data loading. (2022-01-26, shares: 669.0)


[**SolidGPT: Code Collaboration**](https://github.com/AI-Citizen/SolidGPT): The article explores a platform that facil
itates interaction with your code repository and discussion of coding needs. (2023-08-08, shares: 1369.0)

# LinkedIn

#
# Trending

[**VolGAN: A Generative Model for Arbitrage-Free Volatility Surfaces**](https://www.linkedin.com/feed/update
/urn:li:activity:7124861140286795777): The article presents VolGAN, a generative model for arbitrage-free implied volati
lity surfaces, and discusses its performance on SPX implied volatility time series. (2023-11-01, shares: 1.0)

[**The Ne
w Era of Systematic Investing and Parallels to ESG**](https://www.linkedin.com/feed/update/urn:li:activity:7124757870738
313216): The article analyzes Campbell Harvey's views on the role of Machine Learning/AI in investing, discussing potent
ial benefits, risks, and its relation to ESG investing. (2023-11-01, shares: 1.0)

[**Quantitative Models in Chinese Sto
ck Market**](https://www.linkedin.com/feed/update/urn:li:activity:7125151875129044992): The Chinese stock market's growt
h and adaptability make it ideal for quantitative models, as discussed at a London forum. (2023-11-01, shares: 1.0)

## 
Informative

[**Nasdaq's SEC-Approved AI Order Type**](https://www.linkedin.com/feed/update/urn:li:activity:712508174031
8011392): The U.S. Securities and Exchange Commission has approved Nasdaq's use of an AI-driven order type, the first of
 its kind, for executing orders. (2023-11-01, shares: 1.0)

[**New Paper on Statistical Arbitrage Portfolios**](https://
www.linkedin.com/feed/update/urn:li:activity:7124718120375660544): A new paper on statistical arbitrage portfolio constr
uction based on preference relations has been published by Fredi Šarić, Stjepan Begušić, Andro Merćep and Zvonko Kostanj
car. (2023-11-01, shares: 1.0)

[**Machine Learning Applications: Tricky Properties and Catastrophic Forgetting**](https
://www.linkedin.com/feed/update/urn:li:activity:7125318036898660352): The article highlights the difficulties in impleme
nting machine learning applications, focusing on issues like 'catastrophic forgetting' and the need for model and data i
nput adjustments. (2023-11-01, shares: 1.0)

[**Challenging the Belief in More Data for ML Models**](https://www.linkedi
n.com/feed/update/urn:li:activity:7125305960251715584): Clint Howard, in a seminar, challenged the notion that more data
 used in training machine learning models always results in better performance. (2023-11-01, shares: 1.0)

[**Stock Mark
et Efficiency in Pricing Climate Change Risks**](https://www.linkedin.com/feed/update/urn:li:activity:712483076260802150
4): Man Institute researchers suggest that the stock market often underestimates the impact of climate-related news, cre
ating opportunities for savvy investors. (2023-11-01, shares: 1.0)

[**Common Domain Model (CDM): Revolutionizing Financ
e**](https://www.linkedin.com/feed/update/urn:li:activity:7125255238592147457): The Common Domain Model (CDM), an open-s
ource framework, is transforming finance by standardizing processes and reducing operational risks and costs. (2023-11-0
1, shares: 1.0)

# Podcasts

## Quantitative

[**Scariest Options Strategies Revealed**](http://advisorsoption.libsyn.co
m/the-advisors-option-130-top-5-scariest-options-strategies): The Options Insider Media Group talks about the current ma
rket situation, the forthcoming earnings season, and the five most daunting options strategies. (2023-11-01, shares: 8)


[**Macro Volatility and Recession Risks with Boris Vladimirov**](https://macrohive.libsyn.com/boris-vladimirov-on-macro
-volatility-us-yields-and-recession-risks): Goldman Sachs' Boris discusses fiscal policy's impact on growth, private sec
tor rate sensitivity changes, and recession odds in a podcast. (2023-10-27, shares: 4)

[**Corey Hoffstein on Bitcoin ET
F and TBill Discussion**](https://traffic.megaphone.fm/TIFM8769633628.mp3?updated=1698795275): Corey Hoffstein and Meb d
iscuss Bitcoin ETF, BlackRock's TargetDate ETFs, and the end of the 60/40 strategy on a radio show. (2023-11-01, shares:
 3)

[**Efficient Use of Graphs with LLMs in GraphText**](https://dataskeptic.com/blog/episodes/2023/graph-text): In a p
odcast, Jianan Zhao, a Computer Science student, talks about the efficient use of graphs with LLMs. (2023-10-31, shares:
 2)

[**In-depth Conversation with Traderade Cofounder on MH Ep.**](https://markethuddle.com/podcast/mh/): Kevin and Tra
derade Cofounder Horselover Fat discuss trading setups, Traderade's origins, and experiences in the trading industry. (2
023-10-31, shares: 1)

[**Insights on FOMC Meeting: The Financial Conditions Dummy**](https://ibkrcampus.com/podcasts/ib
kr-podcasts/its-the-financial-conditions-dummy/): Neil Azous from Rareview Capital predicts no further policy tightening
 ahead of the November FOMC meeting. (2023-10-31, shares: 1)

# Twitter

## Quantitative

[**Total Return vs. Derivative
 Income in Covered Call Strategies**](https://twitter.com/quantseeker/status/1718676493969006708): Israelov and Ndong's 
paper discusses the inverse relationship between expected total return and derivative income in covered call strategies.
 (2023-10-29, shares: 3)

[**Decoding the Volatility Puzzle**](https://twitter.com/quantseeker/status/171826266092650913
2): Swedroe's article investigates the idiosyncratic volatility puzzle by studying the fundamental aspects. (2023-10-28,
 shares: 2)

[**SciPhi ΨΦ: Custom Data Generation with LLMs**](https://twitter.com/carlcarrie/status/1718223977292685790
): The article introduces SciPhi ΨΦ, a system for creating synthetic data to meet specific requirements using LLM-based 
OpenAI Anthropic Llama. (2023-10-28, shares: 2)

[**MS Report on Wealth Management and Generative AI Tipping Point**](ht
tps://twitter.com/carlcarrie/status/1717945102247637161): The report by OliverWynan and MS explores the convergence of w
ealth and asset management and the critical point of generative AI. (2023-10-27, shares: 2)

[**Langchain Extensions for
 Coordinated Computation**](https://twitter.com/carlcarrie/status/1719024689110974851): The article presents Permchain a
nd Langchain extensions, tools that enable multiple agents to coordinate over several computation steps using LangChain 
Expression Language and Pregel. (2023-10-30, shares: 0)

## Miscellaneous

[**Large Language Model Inferences on Stock F
actors**](https://twitter.com/carlcarrie/status/1717947026430677010): A new study has been released discussing the impli
cations of Large Language Model on different stock factors. (2023-10-27, shares: 0)

[**China LLM with Advanced Question
 Answering Abilities**](https://twitter.com/carlcarrie/status/1718831674862006576): Article 2: DISCFinLLM is a novel Chi
nese financial LLM that features multiturn question answering, text processing, mathematical computation, and enhanced r
etrieval generation. (2023-10-30, shares: 0)

[**Abductive Reasoning in Financial Language Model Building**](https://twi
tter.com/carlcarrie/status/1718830111850385462): Article 3: A new financial LLM that uses abductive reasoning surpasses 
standard financial LLMs, setting new high scores in financial analysis and interpretation tasks. (2023-10-30, shares: 0)


[**Python and R Time Series Library**](https://twitter.com/carlcarrie/status/1718780011455361268): Pytimetk is a high-
performance timeseries library, compatible with Python and R, that utilizes Polaris dataframes for simplicity. (2023-10-
30, shares: 0)

# Videos

## Quantitative

[**Discovering Supply Chain Edges with Graph Neural Networks**](https://www.y
outube.com/watch?v=PtzCJvdWdJc): Achintya Gopal from Bloomberg uses graph neural networks to predict unknown suppliers a
nd customers, improving supply chain risk analysis. (2023-11-01, shares: 9.0)

[**Where Did All the Quants Go?**](https:
//www.youtube.com/watch?v=trVhkfwfzPg): A LinkedIn comment criticizes quant programs for lacking intuition and rigor, st
ressing the need for continuous learning and understanding of financial market logic and mathematics. (2023-10-29, share
s: 52.0)

# Reddit

## Quantitative

[**Two Sigma Hedge Fund Scandal**](https://www.reddit.com/r/quant/comments/17j1b1a/
wsj_news_exclusive_hedge_fund_two_sigma_is_hit_by/): The article explores the differences in pay at proprietary trading 
firms, with some requiring negotiations on a per-portfolio manager basis. (2023-10-29, shares: 230.0)

[**Famous Quants 
in History**](https://www.reddit.com/r/quant/comments/17imr5k/who_arewere_the_most_famousinfluential_quants_of/): The au
thor is asking for suggestions of well-known quants, besides Pat Haber and Martin Artajo, whom they already know. (2023-
10-28, shares: 117.0)

[**Quant Trader in HK or SG**](https://www.reddit.com/r/quant/comments/17jio63/honk_kong_or_singa
pore/): The author is looking for guidance on a potential Quant Trader role in the Asian branches of a London hedge fund
, particularly in Singapore and Hong Kong. (2023-10-30, shares: 17.0)

[**Million Market Experiment Loss**](https://www.
reddit.com/r/quant/comments/17jj1k2/fastest_way_to_lose_1_million_usd_in_the_quickest/): The author is exploring strateg
ies for a hypothetical scenario where all money is lost through market investments as part of an experiment. (2023-10-30
, shares: 114.0)

# Paper with Code

## Rising

[**Natural Language Graphs**](https://github.com/agiresearch/InstructGLM
): ChatGPT, a large-scale pretrained language model, has significantly advanced various fields of artificial intelligenc
e research. (2023-11-01, shares: 117.0)

[**Tuning Graph Instructions for Language Models**](https://github.com/HKUDS/Gr
aphGPT): GraphGPT uses a graph instruction tuning paradigm to align large language models with graph structural knowledg
e. (2023-10-30, shares: 92.0)

[**Graph-based Tools for Language Model Augmentation**](https://github.com/opengvlab/cont
rolllm): ControlLLM is a new framework that enables large language models to use multimodal tools to tackle complex real
-world tasks. (2023-10-31, shares: 45.0)
```
---

     
 
all -  [ Metadata filtering in Opensearch ](https://www.reddit.com/r/LangChain/comments/17m2vdi/metadata_filtering_in_opensearch/) , 2023-11-03-0909
```
I’m using opensearch as a vector database in a RAG type project. Since I have 10,000s of documents I want to filter firs
t on metadata before the similarity search I was try something along these lines

Retriever=vector_db.as_retriever(searc
h_kwargs={“filter”:{”bool”:{”term”:{“class”:”classA”}}}})

From here:
https://opensearch.org/docs/latest/search-plugins/
knn/filter-search-knn/

But the similarity search ignores the filter. Does anyone have any experience getting something 
like this to work?
```
---

     
 
all -  [ Do you find langsmith useful? Why? ](https://www.reddit.com/r/LangChain/comments/17m2u2d/do_you_find_langsmith_useful_why/) , 2023-11-03-0909
```
For the people who have tried it out, what's your opinion? Is it actually useful?
```
---

     
 
all -  [ Best framework for LLM based applications in production ](https://www.reddit.com/r/LocalLLaMA/comments/17m2lql/best_framework_for_llm_based_applications_in/) , 2023-11-03-0909
```
We've been building LLM based tools for months, but I think that there should be efficient frameworks by now that actual
ly add value. I tried langchain a while back but I felt like it was just an over complicated overhead where it was alway
s simpler to make everything from scratch each time. Guidance has been the only real improvement for me as it does way m
ore than basic prompt templating, but it is in no way a full framework.

Now there are LlamaIndex, TigerLab, Langchain..
. but I simply don't have the time to test them all.

We need to run the models by ourselves, so no Open AI api, ideally
 run something compatible with TGI / VLLM. We need to connect to proper databases and vectorDB (currently using Milvus).
 And I'm looking for something that is actually useful and I don't have to struggle and hack the library everytime I wan
t to do something slightly different.

Does any of you have a good recommendation? Everything changes so quickly I feel 
like I can't trust articles that are older than two months. So what are you currently using and what has been an overhyp
ed crap? 
```
---

     
 
all -  [ AimOS: Open-source modular observability for AI Systems ](https://www.reddit.com/r/mlops/comments/17m2c90/aimos_opensource_modular_observability_for_ai/) , 2023-11-03-0909
```
Hey folks! Tatyana from Aim here, AI Enthusiast. 

Wanted to share with you the product you may find helpful. We've laun
ched AimOS, an open-source, modular observability platform for AI Systems.  

With AimOS, you can log, connect, and obse
rve every facet of your AI systems –  from experimentation and production stages to input prompts and monitoring. 

AimO
S comes installed with default logging apps: 

\- Base App for a basic logging,  
\- ML experiment tracking App  
\- AI 
Systems Tracing and Debugging Apps - a combination of variety of apps that log from LangChain to LlamaIndex traces all i
n one place.

[AimOS Apps](https://preview.redd.it/7p2c1nkvgxxb1.png?width=1040&format=png&auto=webp&s=6f9239364e53a0888
014611990014a1ad3cb38ed)

AimOS is a game-changer, it's easy to use but powerful enough to meet next-stage infrastructur
e needs.  

[Experiment tracker](https://preview.redd.it/nhiyft40hxxb1.png?width=2510&format=png&auto=webp&s=c7ac8e54651
f4543ea12ea29b5251472f346c19b)

Aim 💫 — An easy-to-use & supercharged open-source experiment tracker: [https://github.co
m/aimhubio/aim](https://github.com/aimhubio/aim)  
AimOS 🔍 — An easy-to-use modular observability for AI Systems. Extens
ible, scalable and modular: [https://github.com/aimhubio/aimos](https://github.com/aimhubio/aimos) 

To learn more about
 AimOS, check out the [article.](https://aimstack.io/blog/new-releases/aim-4-0-open-source-modular-observability-for-ai-
systems)
```
---

     
 
all -  [ RAG refresh ](https://www.reddit.com/r/LangChain/comments/17m2ai8/rag_refresh/) , 2023-11-03-0909
```
I got tasked to set up a query bot on one of our file servers for HR and I got everything working. But I am trying to fi
nd a way to dynamically re embed documents that get modified by the end user. Right now i just have the user drop the do
cs they want available into a file and i embed the file every day. If i go company wide it is going to be expensive to d
o it that way. anybody else have a way to keep their docs relevant?
```
---

     
 
all -  [ Why Customized ChatBot using OpenAI API is slow and Inaccurate? ](https://www.reddit.com/r/ChatGPT/comments/17m1ds9/why_customized_chatbot_using_openai_api_is_slow/) , 2023-11-03-0909
```
I created Multiple ChatPDF application from Youtuber Alejandro AO. Using langchain and OpenAI's API. I feel that this ap
proach isn't as much good as ChatGPT or the ChatPDF which is already in the market. Why my model is slow and not replyin
g accurately? I trier temperature 0,0.5 as well.
```
---

     
 
all -  [ does anyone know how to intelligently plot a graph for the requested data in an LLM Chat app? ](https://www.reddit.com/r/LangChain/comments/17lzio5/does_anyone_know_how_to_intelligently_plot_a/) , 2023-11-03-0909
```
 For example, if the user asks a question like, 'What was Apple's profit in 2022?' The LLM will answer the question usin
g a data source, but I also want to plot a bar graph of Apple's profit over the years. How can I identify which data to 
plot based on the question?

I am using an agent with multiple tools
```
---

     
 
all -  [ Difference between Langchain and Botpress ](https://www.reddit.com/r/LangChain/comments/17lyodl/difference_between_langchain_and_botpress/) , 2023-11-03-0909
```
Hi folks! Iam really new to this LLMs and Langchain. I have been building some chatbots on Botpress. I would like to kno
w what are the differences in making a chatbot on Botpress and Langchain. Please help. I would like to learn more about 
Langchain.
```
---

     
 
all -  [ Question: Building and Deploying LLM apps to production ](https://www.reddit.com/r/LocalLLaMA/comments/17lvpn4/question_building_and_deploying_llm_apps_to/) , 2023-11-03-0909
```
Hey everyone,

I'm currently researching how building production ready software is different with LLMs compared to 'Soft
ware 1.0'

While building my own small project i noticed some difficulties and wonder how you guys managed them:

* Buil
ding agents in langchain quickly lets context size and cost explode ($0.10 per request). How do you work around it?
* Ho
w do you ensure that users are getting the responses they expected?
* How do you version control and test your prompts? 
Do you run tests against prompts?
* Do you integrate Open Source LLMs in your pipelines and let them manage simpler task
s? How do you host them?

Super exited to learn other problems and challenges you guys encountered!
```
---

     
 
all -  [ Token Counts with stream=True ](https://www.reddit.com/r/LangChain/comments/17lslnq/token_counts_with_streamtrue/) , 2023-11-03-0909
```
I'm building a chatbot pipeline with OpenAI + Langchain, and I'm particularly keen to track prompt token count, token ou
tput, and cost. From what I can tell, the context manager token counter cannot be used in a streaming situation. I'm alr
eady counting output tokens using \`on\_llm\_new\_token\` in my callback handler. What I can't figure out is how to coun
t prompt tokens. Do I need to manually calculate this using tiktoken, or is it being processed and saved somewhere else 
already?
```
---

     
 
all -  [ How can I speed up an analytic chatbot that's based on Langchain (with agents and tools) and Streaml ](https://www.reddit.com/r/LangChain/comments/17lromq/how_can_i_speed_up_an_analytic_chatbot_thats/) , 2023-11-03-0909
```
I created an analytic chatbot using Langchain (with tools and agents) for the backend and Streamlit for the frontend. It
 works, but for some users' questions, it takes too much time to output anything. If I look at the output of intermediat
e steps, I can see that the chatbot tries to print out all relevant rows in the output. For example, below, the chatbot 
found 40 relevant comments and printed them out in one of its intermediate steps one by one (it takes up to one minute).
  

https://preview.redd.it/cw1l7ry14uxb1.png?width=640&format=png&auto=webp&s=e9855cc5a75f5751c3bc2f62c51fecf351502ca2


&#x200B;

&#x200B;

My questions are:  

1) Is there any way to speed up this process?  

2) How can I disable the inte
rmediate output of the chatbot? (I already put \`return\_intermediate\_steps=False\`, \`verbose=False\`, and \`expand\_n
ew\_thoughts=False\`, but the chatbot still shows intermediate steps.)  

&#x200B;

Code for chatbot:

&#x200B;

    
  
  def load_data(path):
        return pd.read_csv(path)
    
    if st.sidebar.button('Use Data'):
        # If button i
s clicked, load the EDW.csv file
        st.session_state['df'] = load_data('./data/EDW.csv')
    uploaded_file = st.sid
ebar.file_uploader('Choose a CSV file', type='csv')
    
    
    if 'df' in st.session_state:
    
        msgs = Strea
mlitChatMessageHistory()
        memory = ConversationBufferWindowMemory(chat_memory=msgs, 
                            
                    return_messages=True, 
                                                k=5, 
                       
                         memory_key='chat_history', 
                                                output_key='output'
)
        
        if len(msgs.messages) == 0 or st.sidebar.button('Reset chat history'):
            msgs.clear()
     
       msgs.add_ai_message('How can I help you?')
            st.session_state.steps = {}
    
        avatars = {'human
': 'user', 'ai': 'assistant'}
    
        # Display a chat input widget
        if prompt := st.chat_input(placeholder=
''):
            st.chat_message('user').write(prompt)
    
            llm = AzureChatOpenAI(
                         
   deployment_name = 'gpt-4',
                            model_name = 'gpt-4',
                            openai_api_k
ey = os.environ['OPENAI_API_KEY'],
                            openai_api_version = os.environ['OPENAI_API_VERSION'],
  
                          openai_api_base = os.environ['OPENAI_API_BASE'],
                            temperature = 0, 

                            streaming=True
                            )
            
            max_number_of_rows = 
40
            agent_analytics_node = create_pandas_dataframe_agent(
                                                   
         llm, 
                                                            st.session_state['df'], 
                    
                                        verbose=False, 
                                                            agen
t_type=AgentType.OPENAI_FUNCTIONS,
                                                            reduce_k_below_max_tokens
=True, # to not exceed token limit 
                                                            max_execution_time = 20,

                                                            early_stopping_method='generate', # will generate a final a
nswer after the max_execution_time has been surpassed
                                                            # max_
iterations=2, # to cap an agent at taking a certain number of steps
                                                    
    )
            tool_analytics_node = Tool(
                                    return_intermediate_steps=False,
     
                               name='Analytics Node',
                                    func=agent_analytics_node.run,

                                    description=f''' 
                                                This tool is usef
ul when you need to answer questions about data stored in a pandas dataframe, referred to as 'df'. 
                    
                            'df' comprises the following columns: {st.session_state['df'].columns.to_list()}.
          
                                      Here is a sample of the data: {st.session_state['df'].head(5)}.
                  
                              When working with df, ensure not to output more than {max_number_of_rows} rows at once, ei
ther in intermediate steps or in the final answer. This is because df could contain too many rows, which could potential
ly overload memory, for example instead of `df[df['survey_comment'].str.contains('wet', na=False, case=False)]['survey_c
omment'].tolist()` use `df[df['survey_comment'].str.contains('wet', na=False, case=False)]['survey_comment'].head({max_n
umber_of_rows}).tolist()`.
                                                '''
                                )        
      
            
            tools = [tool_analytics_node] 
            chat_agent = ConversationalChatAgent.from_llm
_and_tools(llm=llm, tools=tools, return_intermediate_steps=False)
        
            
            executor = AgentExec
utor.from_agent_and_tools(
                                                            agent=chat_agent,
               
                                             tools=tools,
                                                            me
mory=memory,
                                                            return_intermediate_steps=False,
              
                                              handle_parsing_errors=True,
                                              
              verbose=False,
                                                        )
            
            with st.
chat_message('assistant'):
              
                st_cb = StreamlitCallbackHandler(st.container(), expand_new_th
oughts=False)
                response = executor(prompt, callbacks=[st_cb])
                st.write(response['output']
)

&#x200B;
```
---

     
 
all -  [ Add a LangChain chatbot to my personal website? ](https://www.reddit.com/r/webdev/comments/17lookb/add_a_langchain_chatbot_to_my_personal_website/) , 2023-11-03-0909
```
I have a website, [myname.com](https://myname.com), built using GitHub Pages and my custom url. I want to add a chatbot 
to it, using LangChain so I can augment the chatbot with a research paper I wrote. Is there a way I can do this using La
ngChain in python?
```
---

     
 
all -  [ Fastest most accurate vector store in langchain ](https://www.reddit.com/r/LangChain/comments/17llrgr/fastest_most_accurate_vector_store_in_langchain/) , 2023-11-03-0909
```
Hello! 

I've been working with chromadb as the vector store, it performs good. I just want to explore more. I explored 
pinecone, but it turns out that the cheapest version is at 70USD per month which is not a good idea for young students.


Could someone please suggest me a vector store that performs (somewhat) as good as pinecone and is free as well?

My da
ta size is small, like 9k tokens in total. I just need efficiency.

Thanks for helping :-)
```
---

     
 
all -  [ Introducing Mimir, a Discord / CLI compatible Agent runtime and framework that is highly customizabl ](https://www.reddit.com/r/ChatGPTCoding/comments/17lil4m/introducing_mimir_a_discord_cli_compatible_agent/) , 2023-11-03-0909
```
I am proud to introduce [Mimir](https://github.com/Altaflux/agent-mimir)!

Mimir is a Discord or command line 'agent' to
olkit for LLM's like Chat-GPT that provides the models with access to tooling and a framework with which accomplish mult
i-step tasks.

It supports out of the box a robust code-interpreter that is capable of working with files in a very simi
lar manner to ChatGPT's code interpreter. Functionality wise they should be on par.

Multi-agent collaboration is suppor
ted, you can create multiple agents that can interact with each other as well as share files between them.

A robust but
 still BETA web-browser is also supported. It allows the agent to completely control, read and navigate websites using a
ny browser.

Features:

* Both plain-text LLM and OpenAI function's LLM are supported and optimized for.
* Robust Python
 3 code-interpreter with the ability to work with and share files.
* Optimized memory management, conversations are summ
arized in a way where context is maintained with minimal loss of context.
* High level of configurability, you can easil
y add new tools and functions to the agent.
* Discord and CLI clients available.
* Agents are persistent, if a work dire
ctory is configured agents will persist in their work and chat history between restarts.
* Multiple agent support, agent
s can collaborate with each other to achieve complex coordinated tasks.  


It is very easy to configure your own agent 
with a custom personality or profession as well as enabling access to all tools that are compatible with LangchainJS. [h
ttps://js.langchain.com/docs/modules/agents/tools/integrations/](https://js.langchain.com/docs/modules/agents/tools/inte
grations/).

I hope to make it more configurable and provide access to chat in different forms like web or text to speec
h.

Any feedback or questions are more than welcome!

Link to repository:

[https://github.com/Altaflux/agent-mimir](htt
ps://github.com/Altaflux/agent-mimir)
```
---

     
 
all -  [ Switching between pdf and got ](https://www.reddit.com/r/LangChain/comments/17lfncm/switching_between_pdf_and_got/) , 2023-11-03-0909
```
If I am talking to a pdf, how can I switch between answers from the pdf and answers from gpt? I am trying to get answers
 from gpt if the answer is not on the pdf.
```
---

     
 
all -  [ LangChain Templates: The New Way to Customize Chains & Agents ](https://www.reddit.com/r/LangChain/comments/17lf4k0/langchain_templates_the_new_way_to_customize/) , 2023-11-03-0909
```
Yesterday the LangChain team announced the release of LangChain Templates. A lot of developers were finding it difficult
 to edit the internals of chains and agents which prompted the team to release these new templates that solve this issue
 by making chains and agents directly accessible as standardized templates within your application’s code.

I tested the
 rag-conversation template which I believe will be the most widely used and wrote about setting it up and testing the ou
tput. 

A must-read if you’re using LangChain in your RAG LLM app:

https://www.gettingstarted.ai/how-to-customize-chain
s-and-agents-using-new-langchain-templates/

I’d love to know your thoughts and comments!
```
---

     
 
all -  [ 🦙 How To: Build Chatbot that knows your company's documents ](https://www.reddit.com/r/Entrepreneur/comments/17lezca/how_to_build_chatbot_that_knows_your_companys/) , 2023-11-03-0909
```
  
Hello, I've seen some posts asking how to build a chatbot with access to company docs, so here is a tutorial on build
ing a RAG chatbot with access to your data.  
Step 1: Choose your models  
Different models have different strengths. GP
T4 is the best at reasoning and following instructions, but less secure than local models. For secure but weaker local m
odels, Xwin (70B) is a good choice if you have powerful hardware. If you are GPU poor you can use Speechless (13B). For 
the embedding models, you can use OpenAI's ADA 2 or locally use MiniLM-L6-v2.  
Step 2: Organize your data  
This step i
s more complicated because it depends on what your data looks like. The good news is as long as it can be turned into te
xt the models can work with it. At a basic level, you can convert important pdfs or other text documentation into text, 
and add it to a RAG database. Here is a good tutorial. If you have lots of secure data it can be more complicated. Feel 
free to DM me.  
Step 3: Set up in LangChain  
LangChain is an easy way to set up the chatbot. Here are the docs. The ba
sic idea is to connect your RAG database with the model of your choice and use LangChain's interface to customize your c
hatbot's functionality. After you set this up, the model will be able to access your company's documentation and answer 
specific questions about it!  
This tutorial is not an in-depth guide, it's more of a high level overview for those who 
are new to the space or RAG. I work with a company doing this so if you have questions DM me and good luck!
```
---

     
 
all -  [ 🦙 How To: Build Chatbot that knows your company's documents ](https://www.reddit.com/r/OpenAI/comments/17leyw7/how_to_build_chatbot_that_knows_your_companys/) , 2023-11-03-0909
```
Hello, I've seen some posts asking how to build a chatbot with access to company docs, so here is a tutorial on building
 a RAG chatbot with access to your data.

Step 1: Choose your models  
Different models have different strengths. GPT4 i
s the best at reasoning and following instructions, but less secure than local models. For secure but weaker local model
s, Xwin (70B) is a good choice if you have powerful hardware. If you are GPU poor you can use Speechless (13B). For the 
embedding models, you can use OpenAI's ADA 2 or locally use MiniLM-L6-v2.

Step 2: Organize your data  
This step is mor
e complicated because it depends on what your data looks like. The good news is as long as it can be turned into text th
e models can work with it. At a basic level, you can convert important pdfs or other text documentation into text, and a
dd it to a RAG database. [Here](https://youtu.be/LhnCsygAvzY?t=1067) is a good tutorial. If you have lots of secure data
 it can be more complicated. Feel free to DM me.

Step 3: Set up in LangChain  
LangChain is an easy way to set up the c
hatbot. [Here](https://python.langchain.com/docs/get_started/introduction) are the docs. The basic idea is to connect yo
ur RAG database with the model of your choice and use LangChain's interface to customize your chatbot's functionality. A
fter you set this up, the model will be able to access your company's documentation and answer specific questions about 
it!

This tutorial is not an in-depth guide, it's more of a high level overview for those who are new to the space or RA
G. I work with a company doing this so if you have questions DM me and good luck!
```
---

     
 
all -  [ What is the difference between GGUF(new format) vs GGML models ? ](https://www.reddit.com/r/LocalLLaMA/comments/17ldznm/what_is_the_difference_between_ggufnew_format_vs/) , 2023-11-03-0909
```
I'm using llama models for local inference with Langchain , so i get so much hallucinations with GGML models i used both
 LLM and chat of ( 7B, !3 B) beacuse i have 16GB of RAM.   
So Now i'm exploring new models and want to get a good model
 , should i try GGUF format ??   
Kindly give me suggestions if someone using Local models with langchain at production 
level .
```
---

     
 
all -  [ Help with using Pandas Agent on big csv file ](https://www.reddit.com/r/LangChain/comments/17lcsua/help_with_using_pandas_agent_on_big_csv_file/) , 2023-11-03-0909
```
Hi,

So I learning to build RAG system with LLaMa 2 and local embeddings. I have this big csv of data on books. Each row
 is a book and the columns are author(s), genres, publisher(s), release dates, ratings, and then one column is the brief
 summaries of the books.

I am trying to build an agent to answer questions on this csv. From basic lookups like 

'what
 books were published in the last two years?', 

'give me 10 books from this publisher ABC with a rating higher then 3'


to more meaningful queries that need to read into the free-text summary column like:

'what books have a girl as the ma
in character?'

'what books feature dragons? compare their plots'

I believe I got the general framework, but when I tri
ed running it I got into a token limit error. Seems like the file is too big to be digested. Would love to hear your adv
ice on any strategies to overcome this? I though about chunking but then how to recombine the answers from each chunk is
 unclear to me.

Thanks a ton! Cheers :D

&#x200B;

&#x200B;
```
---

     
 
all -  [ Additional SQL layer for a RAG system? ](https://www.reddit.com/r/LangChain/comments/17lcrv0/additional_sql_layer_for_a_rag_system/) , 2023-11-03-0909
```
We want to build a RAG system based on a single SQL table that contains multiple long text columns. My first approach wa
s to convert each entry into a JSON string, treat it as a document for indexing and build a simple RAG on top. It worked
 well with many questions but not for those that require SQL-query logic like:

* What's the **most recent** description
 for ... ?
* What's the **average value** of all ... ?
* Which calendar month had the **highest** ... ?

It seems like I
 want to have an additional layer where the LLM agent can interact with the database in SQL before answering the questio
n.

Can you recommend an article or other type of starting point for something like this?

Edit: Turned out I needed a S
QLAgent and a retriever agent in parallel. Let the wrapper decide to which of the two to post it to.
```
---

     
 
all -  [ How does Tools actually work with LLM ? ](https://www.reddit.com/r/LangChain/comments/17lblnx/how_does_tools_actually_work_with_llm/) , 2023-11-03-0909
```
Hello everyone,  
I'm working as a devops engineer. I decided to learn LangChain and other things about developing appli
cations on top of LLM to understand what developer goes through and how the LLMOps should be and also to learn this new 
technology. I came across something called chains , tools and agents.  
All the videos talked about how to use tools pro
vided by LangChain or create custom tools. I'm not able to understand few things here  


1. What exactly are tools ? Is
 it a function or an api ? - from researching i found it's a function and Langchain provides tools as a interface to it.

2. Let's say I prompt the LLM to caluclator circumference of circle and provide radius. I also gave math calculator too
ls with proper syntax and everything . What is the flow here ?

   what i understand is  


* Because of the prompt from
 **ReAct Framework** , it follows thought -> action -> observation . It thinks and then it responds with **action,action
 input** in a specified format. Later because of stop sequence langchain stops it right after action and then this uses 
it as input to the caluculator tool. The output is sent to the LLM as **Observation** .
* If there is need for multiple 
steps it goes through it else provides the final answer.
* Is my above understanding right ? where i can find any detail
ed article or something about this?

3. Let's say I don't want to use LangChain and want to do it entirely using python 
script  just to understand it deeply. how should I go about it ?Please help me with this or point me to any resources(di
scord channels or slack channels) that can help me with my doubts  


Thank you for your time
```
---

     
 
all -  [ Uses cases for embeddings beyond RAG and retrieval. ](https://www.reddit.com/r/LangChain/comments/17lbhzu/uses_cases_for_embeddings_beyond_rag_and_retrieval/) , 2023-11-03-0909
```
for an organization that has implemented RAG by creating embeddings for 10s of thousands of documents (PDFs, word files,
 some Structured dbs) what other than similarity search can we do to make use of this embeddings database.

&#x200B;
```
---

     
 
all -  [ Agent keeps on invoking tool with empty input when it should have been a string ](https://www.reddit.com/r/LangChain/comments/17l6lop/agent_keeps_on_invoking_tool_with_empty_input/) , 2023-11-03-0909
```
I made a chatbot that specializes in Javanese language and culture. A fragment of my code looks like this:

    llm = Ch
atOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0.0)
    embeddings = OpenAIEmbeddings()
    
    def split_texts(t
ext_name):
      loader = TextLoader(text_name, encoding='utf-8')
      documents = loader.load()
      text_splitter = 
RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
      texts = text_splitter.split_documents(documents)

      return texts
    
    ...
    unggah_docsearch = Chroma.from_documents(split_texts('data/C-unggah-ungguh-basa.txt
'), embeddings,persist_directory='db_unggah',collection_name='unggah-ungguh-col')
    unggah = RetrievalQA.from_chain_ty
pe(llm=OpenAI(temperature=0.0), chain_type='stuff', retriever=unggah_docsearch.as_retriever())
    
    tools = [
      
  Tool(
            name='Unggah-Ungguh-lan-Ngoko-Krama',
            func=unggah.run,
            description=('Dokumen
 kang ngebahas babagan 'unggah-ungguh' yaiku babagan etika ing interaksi kaliyan wong, yaiku ngoko lan krama '
         
               # 'A document list concerning 'unggah-ungguh' which is Javanese way of speaking '
            )
        )

        ...
    ]
    
    class JawabotAgent(object):
    
        ...
    
        self.agent_chain = initialize_agen
t(
                                    tools,
                                    llm,
                                 
   agent=AgentType.OPENAI_FUNCTIONS,
                                    verbose=True,
                                 
   agent_kwargs=agent_kwargs,
                                    memory=self.memory
                                )
 
   
        def generate(self, text):
            resp = self.agent_chain.run(input=text, user_id = self.id)
           
 return resp
    
    agent = JawabotAgent()

Sometimes when I run agent.generate() with the text having the same contex
t as the tool's description it returns a response just fine. However sometimes it returns an error saying:

    langchai
n.tools.base.ToolException: Too many arguments to single-input tool Unggah-Ungguh-lan-Ngoko-Krama. Args: []

Just like t
he following image:

&#x200B;

https://preview.redd.it/hhue70k5toxb1.jpg?width=1280&format=pjpg&auto=webp&s=48c6f7f12213
2d622e0b919f09a028b2ad7c6a0e

Even though I clearly gave an input there. Does anyone knows how to resolve this?
```
---

     
 
all -  [ Langchain Vectorstore Overriding ](https://www.reddit.com/r/LangChain/comments/17l5tmq/langchain_vectorstore_overriding/) , 2023-11-03-0909
```
Right now, my faiss vectorstore stores my ingested documents but however overrides the existing data once new documents 
are ingested.  


Is there a workaround where the newly ingested data gets stored along with the existing data without o
verriding?
```
---

     
 
all -  [ Overview of RAG Methods ](https://www.reddit.com/r/vectordatabase/comments/17l4t6d/overview_of_rag_methods/) , 2023-11-03-0909
```
Hey all, there's been a lot of developments in RAG recently, not sure if you've been following LlamaIndex, Langchain, or
 others.

We're going to overview different approaches on my LinkedIn live next Wed if you want to attend. Personally I 
think it's really useful content

https://www.linkedin.com/posts/kx-systems_retrieval-augmented-generation-rag-is-a-acti
vity-7124795222554787840-WypR
```
---

     
 
all -  [ Agent Executor getting stuck in a loop with GPT 3.5 ](https://www.reddit.com/r/LangChain/comments/17l3gw1/agent_executor_getting_stuck_in_a_loop_with_gpt_35/) , 2023-11-03-0909
```
Hi

Following are the libraries I use for my chatbot:

   import os
   import json
   import yaml

    from langchain im
port SQLDatabase
    from langchain_experimental.sql import SQLDatabaseChain
    from langchain.prompts.prompt import Pr
omptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.memory import ConversationBufferWindowM
emory
    from langchain.chains import ConversationChain, LLMChain
    from langchain.embeddings import OpenAIEmbeddings

    from langchain.chains import RetrievalQAWithSourcesChain
    from langchain.vectorstores import Pinecone
    from l
angchain.agents import Agent, Tool, AgentType, AgentOutputParser, AgentExecutor, initialize_agent
    from langchain.age
nts.conversational.output_parser import ConvoOutputParser
    from langchain.agents.conversational.prompt import SUFFIX

    from pydantic import Field
    from langchain.tools.base import BaseTool
    from langchain.base_language import Bas
eLanguageModel
    from langchain.callbacks.base import BaseCallbackManager
    from typing import Any, List, Optional, 
Sequence
    import pinecone
    from sqlalchemy import create_engine as create_engine_sql
    from snowflake.sqlalchemy
 import URL

I am using multiple Tools and an Agent in my pipeline. I initialize and call an Agent Executor as follows:



    agent_memory = ConversationBufferWindowMemory(k=1, memory_key='chat_history', return_messages=True)
    agent_exec
utor = AgentExecutor.from_agent_and_tools(agent=paid_agent, tools=paid_tools, memory=agent_memory, verbose=verbose, hand
le_parsing_errors=True)

    answer = agent_executor.run(question)


Now, when I use GPT 3.5, the Agent Executor gets st
uck in a loop and feeds the output from the Tool as input to the next iteration of the Agent Executor. This continues un
til context window maximum is reached. Following is response:

```
> Entering new AgentExecutor chain...
Thought: I need
 to find information about the rise of Hot Supply cost basis.
Action: Text Retrieval
Action Input: Cause behind the rise
 of Hot Supply cost basis
Observation: The rise of Hot Supply cost basis in Bitcoin is attributed to a shift in sentimen
t among Short-Term Holders (STHs) who are now experiencing unrealized losses. The cost basis of STHs who are spending fe
ll below the cost basis of holders as the market sold off, leading to concerns of permanent loss. This shift in sentimen
t is reflected in the trend confidence metric unveiled by Glassnode analysts. However, there are differing opinions amon
g Bitcoin traders and analysts, with some optimists anticipating a change in BTC price performance in the fourth quarter
. The overall caution in the market suggests that lower price levels may still be tested. 
 https://cointelegraph.com/ne
ws/bitcoin-short-term-holders-panic-amid-nearly-100-unrealized-loss
Thought:Could not parse LLM output: `According to a 
report from CoinTelegraph, the rise of Hot Supply cost basis in Bitcoin is attributed to a shift in sentiment among Shor
t-Term Holders (STHs) who are now experiencing unrealized losses. The cost basis of STHs who are spending fell below the
 cost basis of holders as the market sold off, leading to concerns of permanent loss. This shift in sentiment is reflect
ed in the trend confidence metric unveiled by Glassnode analysts. However, there are differing opinions among Bitcoin tr
aders and analysts, with some optimists anticipating a change in BTC price performance in the fourth quarter. The overal
l caution in the market suggests that lower price levels may still be tested.

Please note that while I can provide info
rmation and insights from various sources, I cannot provide personalized investment advice. It's always important to do 
your own research and consider your own risk tolerance and investment objectives before making any investment decisions.
`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I couldn't find any specific informat
ion about the rise of Hot Supply cost basis. However, I can provide some general insights about Bitcoin sentiment and ma
rket conditions.

Please note that while I can provide information and insights from various sources, I cannot provide p
ersonalized investment advice. It's always important to do your own research and consider your own risk tolerance and in
vestment objectives before making any investment decisions.

If you have any other questions or need further assistance,
 feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I don't have the in
formation about the rise of Hot Supply cost basis. However, I can provide some general insights about Bitcoin sentiment 
and market conditions.

Please note that while I can provide information and insights from various sources, I cannot pro
vide personalized investment advice. It's always important to do your own research and consider your own risk tolerance 
and investment objectives before making any investment decisions.

If you have any other questions or need further assis
tance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I don't have 
the information about the rise of Hot Supply cost basis. However, I can provide some general insights about Bitcoin sent
iment and market conditions.

Please note that while I can provide information and insights from various sources, I cann
ot provide personalized investment advice. It's always important to do your own research and consider your own risk tole
rance and investment objectives before making any investment decisions.

If you have any other questions or need further
 assistance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I could
n't find any specific information about the rise of Hot Supply cost basis. However, I can provide some general insights 
about Bitcoin sentiment and market conditions.

Please note that while I can provide information and insights from vario
us sources, I cannot provide personalized investment advice. It's always important to do your own research and consider 
your own risk tolerance and investment objectives before making any investment decisions.

If you have any other questio
ns or need further assistance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LL
M output: `I couldn't find any specific information about the rise of Hot Supply cost basis. However, I can provide some
 general insights about Bitcoin sentiment and market conditions.

Please note that while I can provide information and i
nsights from various sources, I cannot provide personalized investment advice. It's always important to do your own rese
arch and consider your own risk tolerance and investment objectives before making any investment decisions.

If you have
 any other questions or need further assistance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:
Could not parse LLM output: `I couldn't find any specific information about the rise of Hot Supply cost basis. However, 
I can provide some general insights about Bitcoin sentiment and market conditions.

Please note that while I can provide
 information and insights from various sources, I cannot provide personalized investment advice. It's always important t
o do your own research and consider your own risk tolerance and investment objectives before making any investment decis
ions.

If you have any other questions or need further assistance, feel free to ask.`
Observation: Invalid or incomplete
 response
Thought:Could not parse LLM output: `I couldn't find any specific information about the rise of Hot Supply cos
t basis. However, I can provide some general insights about Bitcoin sentiment and market conditions.

Please note that w
hile I can provide information and insights from various sources, I cannot provide personalized investment advice. It's 
always important to do your own research and consider your own risk tolerance and investment objectives before making an
y investment decisions.

If you have any other questions or need further assistance, feel free to ask.`
Observation: Inv
alid or incomplete response
Thought:Could not parse LLM output: `I couldn't find any specific information about the rise
 of Hot Supply cost basis. However, I can provide some general insights about Bitcoin sentiment and market conditions.


Please note that while I can provide information and insights from various sources, I cannot provide personalized invest
ment advice. It's always important to do your own research and consider your own risk tolerance and investment objective
s before making any investment decisions.

If you have any other questions or need further assistance, feel free to ask.
`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I couldn't find any specific informat
ion about the rise of Hot Supply cost basis. However, I can provide some general insights about Bitcoin sentiment and ma
rket conditions.

Please note that while I can provide information and insights from various sources, I cannot provide p
ersonalized investment advice. It's always important to do your own research and consider your own risk tolerance and in
vestment objectives before making any investment decisions.

If you have any other questions or need further assistance,
 feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I couldn't find any
 specific information about the rise of Hot Supply cost basis. However, I can provide some general insights about Bitcoi
n sentiment and market conditions.

Please note that while I can provide information and insights from various sources, 
I cannot provide personalized investment advice. It's always important to do your own research and consider your own ris
k tolerance and investment objectives before making any investment decisions.

If you have any other questions or need f
urther assistance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not parse LLM output: `I
 couldn't find any specific information about the rise of Hot Supply cost basis. However, I can provide some general ins
ights about Bitcoin sentiment and market conditions.

Please note that while I can provide information and insights from
 various sources, I cannot provide personalized investment advice. It's always important to do your own research and con
sider your own risk tolerance and investment objectives before making any investment decisions.

If you have any other q
uestions or need further assistance, feel free to ask.`
Observation: Invalid or incomplete response
Thought:Could not pa
rse LLM output: `I couldn't find any specific information about the rise of Hot Supply cost basis. However, I can provid
e some general insights about Bitcoin sentiment and market conditions.

Please note that while I can provide information
 and insights from various sources, I cannot provide personalized investment advice. It's always important to do your ow
n research and consider your own risk tolerance and investment objectives before making any investment decisions.

If yo
u have any other questions or need further assistance, feel free to ask.`
Observation: Invalid or incomplete response
Th
ought:Could not parse LLM output: `I couldn't find any specific information about the rise of Hot Supply cost basis. How
ever, I can provide some general insights about Bitcoin sentiment and market conditions.

Please note that while I can p
rovide information and insights from various sources, I cannot provide personalized investment advice. It's always impor
tant to do your own research and consider your own risk tolerance and investment objectives before making any investment
 decisions.

If you have any other questions or need further assistance, feel free to ask.`
Observation: Invalid or inco
mplete response
Thought:

> Finished chain.

> Agent stopped due to iteration limit or time limit.

But if I use GPT 4, 
it works perfectly fine as intended.

Also note, this was working fine with GPT 3.5 as of last week. What can be the rea
son?
```
---

     
 
all -  [ Why should I learn LangChain? It’s like learning a whole new tool set on top of LLM/Transformer mode ](https://www.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/) , 2023-11-03-0909
```
If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc
..
```
---

     
 
MachineLearning -  [ [D] Is this close enough to be usable? Need your inputs: Automated RAG testing tool. AI Data Pipelin ](https://www.reddit.com/r/MachineLearning/comments/17kkbm0/d_is_this_close_enough_to_be_usable_need_your/) , 2023-11-03-0909
```
Hey there, Redditors! 

I'm back with the latest installment on creating dependable AI data pipelines for real-world pro
duction. 

If you've been following along, you know I'm on a mission to move beyond the '[thin OpenAI wrapper](https://t
opoteretes.notion.site/Going-beyond-Langchain-Weaviate-and-towards-a-production-ready-modern-data-platform-7351d77a1eba4
0aab4394c24bef3a278?pvs=4)' trend and tackle the challenges of building robust data pipelines. 

With 18 months of hands
-on experience and many user interviews, I realized that with the probabilistic nature of systems, we need better\_testi
ng.gpt:

  
**1. As you build you should test**  
The world of AI is a fast-moving one, and we've realized that just wor
king on systems is not an optimal design choice. By the time your product ships, it might already be using outdated tech
nology. So, what's the lesson here? Embrace change, test along, but be prepared to switch pace.  
**2. No Best Practices
 Yet for RAGs**  
In this rapidly evolving landscape, there are no established best practices. You'll need to make educa
ted bets on tools and processes, knowing that things will change. With the RAG testing tool, I tried allowing for testin
g many potential parameter combinations **automatically**  
**3. Testing Frameworks**  
If your generative AI product do
esn't have users giving feedback, then you are building in isolation. I used [Deepeval](https://github.com/confident-ai/
deepeval) to generate test sets, and they will soon support synthetic test set generation  
**4. Infographics only go so
 far**  
AI researchers and data scientists, while brilliant, end up in a loop of pursuing Twitter promotional content. 
New ways are promoted via new content pieces, but ideally, we need something above simple tracing but less than full-fle
dged analytics. To do this, I stored test outputs in Postgres and created a Superset instance to visualize the results  

**5. Bridging the Gap between VectorDBs**  
There's a noticeable number of Vector DBs. To ensure smooth product develop
ment, we need to be able to switch to best best-performing one, especially since user interviews signal that they might 
start deteriorating after loading 50 million rows

&#x200B;

Github repo is [here](https://topoteretes.notion.site/Going
-beyond-Langchain-Weaviate-Level-3-towards-production-e62946c272bf412584b12fbbf92d35b0?pvs=4)  


Next steps:  
I have q
uestions for you: 

1. What variables do you change when building RAGs?
2. What is the set of strategies I should add to
 the solution? (parent-son etc.)
3. How can I improve it in general? 
4. Is anyone  interested in a leaderboard for best
 parameter configs?

Check out the blog post:

[Link to part 3](https://topoteretes.notion.site/Going-beyond-Langchain-W
eaviate-Level-3-towards-production-e62946c272bf412584b12fbbf92d35b0?pvs=4)

  
*Remember to give this post an upvote if 
you found it insightful!*  
*And also star our* [*Github repo*](https://github.com/topoteretes/PromethAI-Memory)
```
---

     
 
MachineLearning -  [ [D] Relevance Extraction in RAG Pipelines ](https://www.reddit.com/r/MachineLearning/comments/17k6iha/d_relevance_extraction_in_rag_pipelines/) , 2023-11-03-0909
```
I came across this interesting problem in RAG, what I call **Relevance Extraction**.

After retrieving relevant document
s (or chunks), these chunks are often large and may contain several portions **irrelevant** to the query at hand. Stuffi
ng the entire chunk into an LLM prompt impacts token-cost as well as response accuracy (distracting the LLM with irrelev
ant text), and and can also cause bumping into context-length limits.

So a critical step in most pipelines is **Relevan
ce Extraction**: use the LLM to extract **verbatim** only the portions relevant to the query. This is known by other nam
es, e.g. LangChain calls it Contextual Compression, and the RECOMP paper calls it Extractive Compression [https://twitte
r.com/manelferreira\_/status/1713214439715938528](https://twitter.com/manelferreira_/status/1713214439715938528)

Thinki
ng about how best to do this, I realized it is **highly inefficient** to simply ask the LLM to 'parrot' out relevant por
tions of the text: this is obviously slow, and also consumes valuable token generation space and can cause you to bump i
nto context-length limits (and of course is expensive, e.g. for gpt4 we know generation is 6c/1k tokens vs input cost of
 3c/1k tokens).

I realized the best way (or at least a good way) to do this is to **number** the sentences and have the
 LLM simply spit out the relevant sentence **numbers.** Langroid's unique Multi-Agent + function-calling architecture al
lows an elegant implementation of this, in the RelevanceExtractorAgent ([https://github.com/langroid/langroid/blob/main/
langroid/agent/special/relevance\_extractor\_agent.py](https://github.com/langroid/langroid/blob/main/langroid/agent/spe
cial/relevance_extractor_agent.py)).  The agent annotates the docs with sentence numbers, and instructs the LLM to pick 
out the **sentence-numbers** relevant to the query, rather than whole sentences using a function-call (SegmentExtractToo
l [https://github.com/langroid/langroid/blob/main/langroid/agent/tools/segment\_extract\_tool.py](https://github.com/lan
groid/langroid/blob/main/langroid/agent/tools/segment_extract_tool.py)), and the agent's function-handler interprets thi
s message and strips out the indicated sentences by their numbers. To extract from a set of passages, langroid automatic
ally does this async + concurrently so latencies in practice are much, much lower than the sentence-parroting approach.


\[FD -- I am the lead dev of Langroid - [https://github.com/langroid/langroid](https://github.com/langroid/langroid))


I thought this **numbering** idea is a fairly obvious idea in theory, so I looked at LangChain's equivalent `LLMChainExt
ractor` (they call this Contextual Compression [https://python.langchain.com/docs/modules/data\_connection/retrievers/co
ntextual\_compression?ref=blog.langchain.dev](https://python.langchain.com/docs/modules/data_connection/retrievers/conte
xtual_compression?ref=blog.langchain.dev)) and was surprised to see it is the simple '**parrot**' method, i.e. the LLM w
rites out whole sentences verbatim from its input. I thought it would be interesting to compare Langroid vs LangChain, y
ou can see it in this Colab: [https://colab.research.google.com/drive/1RDPCR2xNuBffcmpUuPIXYDRG3SXIJC5F](https://colab.r
esearch.google.com/drive/1RDPCR2xNuBffcmpUuPIXYDRG3SXIJC5F)

On the specific example in the notebook, the Langroid **num
bering** approach is 22x faster and 36% cheaper (with gpt4) than LangChain's **parrot** method (I promise this name is *
not* inspired by their logo :). See table below.

&#x200B;

[Relevance Extraction: Langroid vs LangChain](https://previe
w.redd.it/1m7u6ulq8fxb1.png?width=1108&format=png&auto=webp&s=d2f35cf5db07e2e699baa54b274ffa60833e924a)

&#x200B;

I won
der if anyone had thoughts on relevance extraction, or other approaches. At the very least, I hope langroid's implementa
tion is useful to you -- you can use the `DocChatAgent.get_verbatim_extracts()` ([https://github.com/langroid/langroid/b
lob/main/langroid/agent/special/doc\_chat\_agent.py#L804](https://github.com/langroid/langroid/blob/main/langroid/agent/
special/doc_chat_agent.py#L804)) as part of your pipeline, regardless of whether you are using Langroid for your entire 
system or not.

&#x200B;
```
---

     
 
MachineLearning -  [ [R] Model Troubles ](https://www.reddit.com/r/MachineLearning/comments/17ikh2u/r_model_troubles/) , 2023-11-03-0909
```
So i’m working on a model that diagnoses alzheimer’s disease and suggests medication depending on how severe the symptom
s might have become 
I’m using the Openai API and Langchain.

But it’s dumb and it doesn’t learn (
Me: I forgot my keys 
at home
Model: Yup, Alzheimer’s)
How do i incorporate the actual machine learning

Edit: I didn’t choose this project my
 supervisor did and she barely knows anything about the topic or how to approach it
```
---

     
 
MachineLearning -  [ [P] NexaAgent: A highly efficient multi-task PDF tool for all your needs | backed by AutoGen ](https://www.reddit.com/r/MachineLearning/comments/17eajz2/p_nexaagent_a_highly_efficient_multitask_pdf_tool/) , 2023-11-03-0909
```
Just a quick open-source project recently submitted to huggingface backed by AutoGen. Share this initial version with yo
u guys!

[NexaAgent 0.0.1](https://huggingface.co/spaces/xuyingliKepler/nexaagent) offers a straightforward solution for
 handling PDFs.

* Users can easily upload any PDF, regardless of its size.
* The tool emphasizes accuracy, minimizing d
iscrepancies in PDF processing.

At its core, NexaAgent is backed by the AutoGen and LangChain frameworks. AutoGen facil
itates multi-agent interactions for task execution, while LangChain bridges LLMs with external data sources. Together, t
hese technologies ensure NexaAgent's robust and precise PDF management capabilities.

https://preview.redd.it/kwgo3phnav
vb1.jpg?width=1440&format=pjpg&auto=webp&s=1c5fbc566938d60d5c43802aff3a0690821e1c79
```
---

     
 
MachineLearning -  [ [D] Is lang chain the right solution? ](https://www.reddit.com/r/MachineLearning/comments/17coyym/d_is_lang_chain_the_right_solution/) , 2023-11-03-0909
```
Hello, I would love to have an LLm that can provide answers (in chat format) based some of the sql db  data we have. Wan
t it for an internal company project. I am by no means an expert but decent in programming and want to build a system to
 get answers in chat format. My understanding is that training LLMs ground up is prohibitively expensive and langchains 
are sort of hybrid , efficient solutions. 

Please suggest any other solutions. Also would Langchain being a company and
 not open source pose a problem in terms of copyrights? Thanks!
```
---

     
 
MachineLearning -  [ [P] building a D&D NPC ](https://www.reddit.com/r/MachineLearning/comments/17clyw6/p_building_a_dd_npc/) , 2023-11-03-0909
```
Hey everyone,

I'm learning ML but i'm barely scratching the terminologies. 2 years ago I couldn't code anything but wit
h school (python,sql and R) I learned fundamentals. I also have access to code academy.  My current program is very mach
ine learning/deep learning focused.

On the side I DM a d&d game. Within the context of the world (eberron) robots are c
ommon. With my ADHD and being a new DM I want to outsource lore questions might have (that I would have to look up and s
low down the game).

The concept is to have a GUI and have the player interact with the chat bot. I've gotten to a proof
 of concept workflow. On Google colab. Thanks to langchain I managed to ingest pdfs and a url. Make then a directory, Em
bedded the text, bring it into a vector dB. Have the llm pull from the vector. Answer the question.

Now I don't know wh
at to do. I tried to bring the colab notebook onto Google cloud. But now cloud is becoming a rabbit home with vertex and
 docAI...and I don't want to deep dive into that, if it's a outside the scope of this 'project'

I'd appreciate any advi
ce, links...etc. 


I got a limited success in botpress using a single pdf. It works but feel unsatisfying.
N8N looks pr
omising but if it's not intuitive then I don't want to go down that road.


If I posted in the wrong group please direct
 me to the correct one.
```
---

     
 
MachineLearning -  [ [D] Exploring Methods to Improve Text Chunking in RAG Models (and other things...) ](https://www.reddit.com/r/MachineLearning/comments/179j7l3/d_exploring_methods_to_improve_text_chunking_in/) , 2023-11-03-0909
```
Hello everyone,

I'm currently working on Retrieval Augmented Generation (RAG) models and have developed a custom chunki
ng function, as I found the methods in LangChain not entirely satisfactory.

I'm keen on exploring other methods, algori
thms (related to NLP or otherwise), and models to enhance text chunking in RAG. There are many RAG implementations out t
here, but I've noticed a lack of focus on improving chunking performance specifically.

Are there any other promising ap
proaches beyond my current pipeline, which consists of a bi-encoder (retriever), cross-encoder (reranker), and a Large L
anguage Model (LLM) for interactions?

For queries, I'm using both traditional and HyDE (Hypothetical Document Embedding
) approaches in the retrieval phase, and sending the top 'n' results of both similarity search to the reranker.

I've al
so tried using an LLM to convert the query into a series of 10-20 small phrases or keywords, which are then used as the 
query for the retriever model. However, the results vary depending on the LLM used. To generate good keywords (with a no
t extractive approach) , I had to  use a 'CoT' prompt, instructing the model to  write self-instruct, problem analysis a
nd reasonings before generating the required keywords. But this approach use lots of tokens, and requires careful scrapi
ng to ensure the model has used the right delimiter to separate reasoning and the actual answer.

I'm also planning to m
odify the text used to generate embeddings, while returning the original text after the recall phase. But this is still 
a work in progress and scaling it is proving to be a challenge. If anyone has any tips or experience with this, I'd appr
eciate your input.

I'd be grateful for any resources, repositories, libraries, or existing implementations of novel chu
nking methods that you could share. Or we could just discuss ideas, thoughts, or approaches to improve text chunking for
 RAG here.

Thanks in advance for your time!
```
---

     
 
MachineLearning -  [ [News] AI & ML conference in San Francisco [Special discount code for this subreddit] ](https://www.reddit.com/r/MachineLearning/comments/1771m35/news_ai_ml_conference_in_san_francisco_special/) , 2023-11-03-0909
```
I work for this database company SingleStore and we are hosting a AI & ML conference in San Francisco on 17th of October
, 2023.

It is an in-person conference with amazing speakers line-up like Harrison Chase, co-founder and CEO of LangChai
n and many more. We will have hands-on workshops, swags giveaway and much more.

I don't know if it makes sense to share
 this but I believe it might help some of you near San Francisco to go and meet the industry leaders and network with ot
her data engineering folks.

Use my discount coupon code 'PAVAN100OFF' to avail 100% off on the ticket price. (the origi
nal ticket price is $199)

[Get your tickets now!](https://singlestore.com/now)
```
---

     
 
MachineLearning -  [ [D] Best way to validate llm prompts? ](https://www.reddit.com/r/MachineLearning/comments/176vnxh/d_best_way_to_validate_llm_prompts/) , 2023-11-03-0909
```
We have a platform for data analytics which uses a very simple dsl to generate charts.  
We have been experimenting with
 llms to use natural language that gets translated into this dsl and hence generates charts.

This is working pretty goo
d.  
The stack is langchain with openai api. (don't have much experience with llms, it's a prototype to get a feel for i
t)

The question is what is the best way to limit the options user can type in as a prompt.  
Basically the the only all
owed things should be: 'What is the X, Y over 10 days period for this or that?'  
I don't want users to ask questions li
ke when did we first land on the moon.

Is it something that is possible to do at all without additional tooling?  
We p
robably don't want to train another model to classify the prompt as valid or invalid or something similar.
```
---

     
 
MachineLearning -  [ [P] Retrieval augmented generation with OpenSearch and reranking [Video tutorial] ](https://www.reddit.com/r/MachineLearning/comments/16zouad/p_retrieval_augmented_generation_with_opensearch/) , 2023-11-03-0909
```
I created a video tutorial that tries to demonstrate that semantic search (using embeddings) is not always necessary for
 RAG (retrieval augmented generation). It was inspired by the following Cohere blog post: [https://txt.cohere.com/rerank
/](https://txt.cohere.com/rerank/)


I code up a minimal RAG pipeline: `OpenSearch -> Rerank -> Chat completion` (withou
t using Langchain or similar libraries) and then see how it performs on various queries.


Hope some of you find it help
ful. Feel free to share any feedback@

Video link: https://youtu.be/OsE7YcDcPz0
```
---

     
 
deeplearning -  [ Error with Mistral 7B model in ConversationalRetrievalChain ](https://www.reddit.com/r/deeplearning/comments/179vvou/error_with_mistral_7b_model_in/) , 2023-11-03-0909
```
 I'm encountering an issue while using the Mistral 7B model in a ConversationalRetrievalChain. When I input a question, 
such as 'What is the highest GDP?', I receive an error and after that the model generates a random response as output wh
ich is not relevant to the Input query. It seems that the number of tokens in the input exceeds the maximum context leng
th. 

Here's the relevant code: 

 

>`from langchain.document_loaders.csv_loader import CSVLoader`  
`from langchain.te
xt_splitter import RecursiveCharacterTextSplitter`  
`from langchain.embeddings import HuggingFaceEmbeddings`  
`from la
ngchain.vectorstores import FAISS`  
`from langchain.llms import CTransformers`  
`from langchain.memory import Conversa
tionBufferMemory`  
`from langchain.chains import ConversationalRetrievalChain`  
`import sys`  
`DB_FAISS_PATH = 'vecto
rstore/db_faiss'`  
`loader = CSVLoader(file_path='data/World Happiness Report 2022.csv', encoding='utf-8', csv_args={'d
elimiter': ','})`  
`data = loader.load()`  
`print(data)`  
`# Split the text into Chunks`  
`text_splitter = Recursive
CharacterTextSplitter(chunk_size=500, chunk_overlap=20)`  
`text_chunks = text_splitter.split_documents(data)`  
`print(
len(text_chunks))`  
`# Download Sentence Transformers Embedding From Hugging Face`  
`embeddings = HuggingFaceEmbedding
s(model_name = 'sentence-transformers/all-MiniLM-L6-v2')`  
`# COnverting the text Chunks into embeddings and saving the
 embeddings into FAISS Knowledge Base`  
`docsearch = FAISS.from_documents(text_chunks, embeddings)`  
`docsearch.save_l
ocal(DB_FAISS_PATH)`  
  
>  
>`#query = 'What is the value of GDP per capita of Finland provided in the data?'`  
`#doc
s = docsearch.similarity_search(query, k=3)`  
`#print('Result', docs)`  
`llm = CTransformers(model='models/mistral-7b-
v0.1.Q4_0.gguf',`  
 `model_type='llama',`  
 `max_new_tokens=1000,`  
 `temperature=0.1)`  
`qa = ConversationalRetriev
alChain.from_llm(llm, retriever=docsearch.as_retriever())`  
`while True:`  
 `chat_history = []`  
 `#query = 'What is 
the value of  GDP per capita of Finland provided in the data?'`  
 `query = input(f'Input Prompt: ')`  
 `if query == 'e
xit':`  
 `print('Exiting')`  
 `sys.exit()`  
 `if query == '':`  
 `continue`  
 `result = qa({'question':query, 'chat
_history':chat_history})`  
 `print('Response: ', result['answer'])`

 

**Problem Statement:**

I'm trying to utilize t
he Mistral 7B model for a ConversationalRetrievalChain, but I'm encountering an error related to token length:

Number o
f tokens (760) exceeded maximum context length (512).

**Context:**

I'm working on a project that involves using Mistra
l 7B to answer questions based on a dataset. The dataset contains information about the World Happiness Report 2022.

**
Steps Taken:**

* Loaded and preprocessed the dataset using langchain.
* Initialized Mistral 7B with the following param
eters:
* Model: 'models/mistral-7b-v0.1.Q4\_0.gguf'
* Model Type: 'llama'
* Max New Tokens: 1000
* Temperature: 0.1
* Se
t up a ConversationalRetrievalChain with Mistral 7B as the language model and a retriever based on FAISS.

**Expected Ou
tput:**

I expect to receive a meaningful response from Mistral 7B based on the input query.

**Additional Information:*
*

I'm using Python and relevant libraries for this project. The dataset I'm working with is from the World Happiness Re
port 2022.

**Environment Details:**

* Python version: 3.11.4 
* Relevant libraries and versions: 

langchain 

ctransf
ormers 

sentence-transformers 

faiss-cpu
```
---

     
 
deeplearning -  [ Error with Mistral 7B model in ConversationalRetrievalChain. ](https://www.reddit.com/r/deeplearning/comments/179vsif/error_with_mistral_7b_model_in/) , 2023-11-03-0909
```
I'm encountering an issue while using the Mistral 7B model in a ConversationalRetrievalChain. When I input a question, s
uch as 'What is the highest GDP?', I receive an error and after that the model generates a random response as output whi
ch is not relevant to the Input query. It seems that the number of tokens in the input exceeds the maximum context lengt
h.

Here's the relevant code:

>from langchain.document\_loaders.csv\_loader import CSVLoader  
>  
>from langchain.text
\_splitter import RecursiveCharacterTextSplitter  
>  
>from langchain.embeddings import HuggingFaceEmbeddings  
>  
>fr
om langchain.vectorstores import FAISS  
>  
>from langchain.llms import CTransformers  
>  
>from langchain.memory impo
rt ConversationBufferMemory  
>  
>from langchain.chains import ConversationalRetrievalChain  
>  
>import sys  
>  
>  

>  
>DB\_FAISS\_PATH = 'vectorstore/db\_faiss'  
>  
>loader = CSVLoader(file\_path='data/World Happiness Report 2022.c
sv', encoding='utf-8', csv\_args={'delimiter': ','})  
>  
>data = loader.load()  
>  
>print(data)  
>  
>  
>  
>\# Sp
lit the text into Chunks  
>  
>text\_splitter = RecursiveCharacterTextSplitter(chunk\_size=500, chunk\_overlap=20)  
> 
 
>text\_chunks = text\_splitter.split\_documents(data)  
>  
>  
>  
>print(len(text\_chunks))  
>  
>  
>  
>\# Downlo
ad Sentence Transformers Embedding From Hugging Face  
>  
>embeddings = HuggingFaceEmbeddings(model\_name = 'sentence-t
ransformers/all-MiniLM-L6-v2')  
>  
>  
>  
>\# COnverting the text Chunks into embeddings and saving the embeddings in
to FAISS Knowledge Base  
>  
>docsearch = FAISS.from\_documents(text\_chunks, embeddings)  
>  
>  
>  
>docsearch.save
\_local(DB\_FAISS\_PATH)  
>  
>  
>  
>  
>  
>\#query = 'What is the value of GDP per capita of Finland provided in th
e data?'  
>  
>  
>  
>\#docs = docsearch.similarity\_search(query, k=3)  
>  
>  
>  
>\#print('Result', docs)  
>  
>
  
>  
>llm = CTransformers(model='models/mistral-7b-v0.1.Q4\_0.gguf',  
>  
>model\_type='llama',  
>  
>max\_new\_toke
ns=1000,  
>  
>temperature=0.1)  
>  
>  
>  
>qa = ConversationalRetrievalChain.from\_llm(llm, retriever=docsearch.as\
_retriever())  
>  
>  
>  
>while True:  
>  
>chat\_history = \[\]  
>  
>\#query = 'What is the value of  GDP per cap
ita of Finland provided in the data?'  
>  
>query = input(f'Input Prompt: ')  
>  
>if query == 'exit':  
>  
>print('E
xiting')  
>  
>sys.exit()  
>  
>if query == '':  
>  
>continue  
>  
>result = qa({'question':query, 'chat\_history':
chat\_history})  
>  
>print('Response: ', result\['answer'\])

 

**Problem Statement:**

I'm trying to utilize the Mis
tral 7B model for a ConversationalRetrievalChain, but I'm encountering an error related to token length:

Number of toke
ns (760) exceeded maximum context length (512).

**Context:**

I'm working on a project that involves using Mistral 7B t
o answer questions based on a dataset. The dataset contains information about the World Happiness Report 2022.

**Steps 
Taken:**

* Loaded and preprocessed the dataset using langchain.
* Initialized Mistral 7B with the following parameters:

* Model: 'models/mistral-7b-v0.1.Q4\_0.gguf'
* Model Type: 'llama'
* Max New Tokens: 1000
* Temperature: 0.1
* Set up a
 ConversationalRetrievalChain with Mistral 7B as the language model and a retriever based on FAISS.

**Expected Output:*
*

I expect to receive a meaningful response from Mistral 7B based on the input query.

**Additional Information:**

I'm
 using Python and relevant libraries for this project. The dataset I'm working with is from the World Happiness Report 2
022.

**Environment Details:**

Python version: 3.11.4 Relevant libraries and versions: langchain ctransformers sentence
-transformers faiss-cpu

&#x200B;
```
---

     
 
deeplearning -  [ Free courses to learn about Large Language Models and building AI projects ](https://www.reddit.com/r/deeplearning/comments/178zu2u/free_courses_to_learn_about_large_language_models/) , 2023-11-03-0909
```
[**LangChain for LLM Application Development by Andrew Ng**](https://www.deeplearning.ai/short-courses/langchain-for-llm
-application-development/): Apply LLMs to your proprietary data to build personal assistants and specialized chatbots. 


[**Full Stack LLM Bootcamp**](https://fullstackdeeplearning.com/llm-bootcamp/): Learn best practices and tools for buil
ding LLM-powered apps 

[**Stanford CS324**](https://stanford-cs324.github.io/winter2022/): In this course, students wil
l learn the fundamentals about the modeling, theory, ethics, and systems aspects of large language models, as well as ga
in hands-on experience working with them. 

[**LangChain & Vector Databases in Production**](https://learn.activeloop.ai
/courses/langchain): Learn how to leverage LangChain, a robust framework for building applications with LLMs, and explor
e Deep Lake, a groundbreaking vector database for all AI data. 

[**Stanford CS25**](https://web.stanford.edu/class/cs25
/): In this course, learn how transformers work, and dive deep into the different kinds of transformers and how they're 
applied in different fields. 

[**LLMOps Space Discord**](https://llmops.space/discord): LLMOps Space is a global commun
ity for LLM practitioners.
```
---

     
 
deeplearning -  [ AutoGen from Microsoft ](https://www.reddit.com/r/deeplearning/comments/170hke6/autogen_from_microsoft/) , 2023-11-03-0909
```
AI agents are AI systems that can exhibit capabilities such as conducting conversations, completing tasks, reasoning, an
d seamlessly interacting with humans. 

As frameworks like LangChain build Agents as a module in their framework, Micros
oft is thinking way ahead. It has built **AutoGen**, a framework to enable seamless MULTI-agent conversation and collabo
ration to accomplish complex tasks by reasoning and working autonomously. 

Here is a video explaining the latest AutoGe
n framework from Microsoft: https://youtu.be/daigxHA2aYw?si=86alxsVZkRpz5Quv

Do you think multi-agents are the future o
f AI? Or will AI emerge in other ways? Let me know your thoughts.
```
---

     
