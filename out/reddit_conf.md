 
all -  [ VERSES AI ($VERS) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/smallcapsociety/comments/1cxi2hx/verses_ai_vers_sets_new_standards_in_ai_with/) , 2024-05-22-0910
```
VERSES AI ($VERS), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a research
 roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by prov
iding clear goals to measure the progress and importance of $VER's research and development endeavors.

The company plan
s to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be as 
good as or better than advanced AI models on various industry tests, all while using less data and energy.

By meeting t
hese benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to get th
eir AI into more hands through their Genius Platform.

Research Roadmap Highlights:

VERSES’ research roadmap has 3 benc
hmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge

The first benc
hmark, Classification and generation tasks, focuses on proving $VER's approach is better at tasks like recognizing image
s and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that their method 
has the ability to outperform traditional deep learning methods. This test is important because it shows whether VERSES 
can make top-quality AI while being more efficient.

The second benchmark, the Atari 10k Challenge, is all about testing
 VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VERSES is tryin
g to play video games almost like a human but with way less practice. $VERS is using active inference to help their AI b
e super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming

Lastly, the
re’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky situations whe
re lots of different AI systems need to work together. $VERS wants to show that their AI can understand these complicate
d situations and work smoothly with other AI systems. Through the use of active inference and explicit representational 
structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and tackle complex pr
oblems together.

$VERS publicly released this roadmap so the public can track their progress. The roadmap can be access
ed here: [www.verses.ai/rd-overview](http://www.verses.ai/rd-overview)

Note: this is not financial advice please do you
r own research before investing.
```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/kanpur/comments/1cwa3qt/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-22-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/rau0q0kyej1d1.png?width=1920&for
mat=png&auto=webp&s=8f49b22c78e16399f92194c3551303474022e65a


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/developers_lucknow/comments/1cwa3gc/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-22-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/g61lajfuej1d1.png?width=1920&for
mat=png&auto=webp&s=80313475aa3a531609364a0d487a61a733f55877


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/LucknowUniversity/comments/1cwa2sh/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-22-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/k95x0bekej1d1.png?width=1920&for
mat=png&auto=webp&s=b64f71dfea4921355b3bb281ccf4cf5b06871190


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/lucknow/comments/1cwa0gu/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-22-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** (https://www.commudle.com/communi
ties/tfug-lucknow/events/hack-to-crack), we are also organizing the **Gen AI Awadh Summit** (https://www.commudle.com/co
mmunities/tfug-lucknow/events/gen-ai-awadh-summit). During this summit, we will explore cutting-edge topics such as fine
-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We invite you to join us, share your
 knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs is an independent initiative led 
by a group of scholars and researchers. Our primary goal is to nurture the AI research community in Lucknow. If you woul
d like to contribute, we encourage you to do so through mentoring or providing resources that can benefit students and r
esearchers in the AI domain.

As part of our community engagement initiatives, we regularly host AMA (Ask Me Anything) s
essions over the weekends. These sessions provide a fantastic opportunity for anyone to interact with experts, ask quest
ions, and gain insights into various aspects of AI and related fields.

To join our WhatsApp group and Discord server, p
lease visit our website at [https://lucknowai.github.io/](https://lucknowai.github.io/).

We would greatly appreciate it
 if you could help us spread the word by sharing this information in other relevant subreddits and groups. As our accoun
t is newly created, we are currently facing limitations in posting to other communities ourselves.

https://preview.redd
.it/oxz0fmhtdj1d1.png?width=1920&format=png&auto=webp&s=6cc4f32667d5fa9d957f883563e4325dd09aac99
```
---

     
 
all -  [ [D] Why are non technical people leading AI? ](https://www.reddit.com/r/MachineLearning/comments/1cw5dby/d_why_are_non_technical_people_leading_ai/) , 2024-05-22-0910
```
Why do non-technical figures lead the charge in AI? Pichai, Nadella, Fidji (Open AI board member), Altman, Murati, and m
any other VPs of AI in FAANG. Despite never coding, they hold sway in AI. Meanwhile, those coding and publishing groundb
reaking work are often stuck at lower levels. 

What's the deal? Why isn't the industry recognizing those publishing at 
Neurips, EMNLP, CVPR, or the masterminds behind creations like GPT, Gemini, or Claude? They seem to be hidden in the sha
dows. 

What's your take on this?


```
---

     
 
all -  [ [D] Culture of Recycling Old Conference Submissions in ML ](https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/) , 2024-05-22-0910
```
I work on statistical ML. I notice that many people (including myself and those that I review) often recycle their submi
ssions for ML conferences.

E.g., if their papers got rejected by ICML, they submit to NeurIPS, and later to ICLR (or UA
I/AISTATS which are also top in my field). If they did not get into ICML/NeurIPS/ICLR after 2\~3 times, they would submi
t them to AAAI/IJCAI/TMLR/ICDM, journals like T-NNLS/T-KDD/NN/Neurocomputing, or domain-specific venues like LoG/CoLLAs/
AABI. After all these, if the paper still did not get accepted, they then simply put them or arXiv. I believe this might
 also be the case for CV/NLP.

As a reviewer, I often encounter conference submissions where the authors resubmit withou
t really taking into account the previous reviews provided. Sometimes they do incorporate the reviews when resubmitting-
-but sometimes the work may just be not at the level of Tier 1 conferences but they just keep resubmitting and hoping th
at they can accepted by chance.

I think that this is consuming a lot of reviewers' time from the community to keep revi
ewing the same submissions (especially given that NeurIPS hits 20k submission id; I expect to see many resubmissions). T
his is perhaps also one of the reason TMLR was born (to emphasize correctness instead of novelty).

I do understand argu
ments like 'the quality of research is more important than the publication venues' or 'OpenAI often simply just put thei
r papers like GPT-X on arXiv these days'. However, students or junior researchers also need publications in their career
, including myself. 

What do folks think about it?
```
---

     
 
all -  [ This Will Be NeurIPS in 2026 ](https://i.redd.it/1ibbavmp391d1.png) , 2024-05-22-0910
```

```
---

     
 
all -  [ NeurIPS Submission Question ](https://www.reddit.com/r/MLQuestions/comments/1cudjmn/neurips_submission_question/) , 2024-05-22-0910
```
I am an undergrad submitting to NeurIPS for the first time. I saw there was only one form, so I filled the abstract and 
saw it was saved. But I didn't submit as it required the full pdf, and I thought it was due later.

Now, my registration
 has disappeared, so I emailed the PCs. Do you think I have any hope of still submitting at this point? (I heard their a
bstract submission is strict)
```
---

     
 
all -  [ [D] Real chances to be accepted in NeurIPS 2024 - Other conferences ](https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/) , 2024-05-22-0910
```
Hey!

This is my first time submitting to NeurIPS.

Does anyone know when the reviews are visible to the authors? August
, or is it possible that earlier? If we have really bad reviews... The best thing is to exit the submission path, right?
 In that case, which alternatives do you recommend on those dates?

My topic is NN reliability, but I am always undercon
fident about my research and I always think that it is not enough, more if I think in a conference as Neurips. Do you th
ink that everybody submits good papers or is there a large quantity of rubbish papers? I read a lot of bad opinions here
 about the reviewing process... So, I am a little afraid.

This year, there are 20000ish submissions. So, I don't know w
hat to do, if continue the submission or submit to another conference. As the gap that I am filling is clear, I am sure 
that others are covering that gap and submitting it to NeurIPS. Is there any other conference that outputs the results f
irst than NeurIPS? I am trying to think in a smart way. So hard to be a researcher...

Thank you!
```
---

     
 
all -  [ Why is AI for medical imaging, such as histopathology, such a saturated area? And why is AI for mole ](https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/) , 2024-05-22-0910
```
I work on projects involving AI for biomedical research, and something that shocks me is why there are so many papers/pr
ojects involving AI for medical imaging, especially computational pathology (or radiology)? Is it because of the demand 
in this area (i.e. histopathology for hospitals doing biopsies on patients)?

Why I'm confused is that histopathology, s
uch as whole-slide image analysis, is such a resource-intensive problem - a typical WSI (Whole-Slide Image) takes up to 
\~10GBs to load, and so training a model could take days to even weeks. That is not to mention that you have to convert 
the images to smaller patches and then apply methods like multiple-instance learning to aggregate the image embeddings f
rom each patch to get a final prediction. And then you have to look at which patches are important towards the disease (
via something like attention maps), and then you need a domain expert/expertise to understand whether the model is focus
ing on the right parts of the image towards a prediction. 

And yet there's so many papers published in this field since
 \~2020, probably in the order of thousands, spanning conferences and journals like NeurIPS/ICLR/ICML, CVPR/ECCV/ICCV, M
ICCAI (which is dedicated to medical imaging), Nature, etc. I wonder if this is because a lot of people coming from the 
computer vision area wanted a more difficult problem to tackle (involving non-natural images?)

And then I'm also confus
ed why there's much, much, much less work being done in ML for molecular biology, especially DNA/RNA/epigenomics (exclud
ing protein structure/folding)? It seems for molecular biology almost all the focus seems to be on protein folding/struc
ture with the new AlphaFold 3, but other than that RNA/DNA/epigenomics has been largely ignored? i.e. there has been onl
y a very recent wave of papers for single-cell RNA sequencing foundation models like scGPT/Geneformer/etc in late 2023 t
o early 2024? Is it because there is much more domain knowledge needed to do good analysis in molecular biological modal
ities, and less people have that? Even though molecular biological datasets (esp. RNA sequencing) are often much less co
mputationally intensive than medical imaging, like histopathology?
```
---

     
 
all -  [ [D] Any reason not to submit to NeurIPS? ](https://www.reddit.com/r/MachineLearning/comments/1cs6p6j/d_any_reason_not_to_submit_to_neurips/) , 2024-05-22-0910
```
As we all know, abstracts are due tomorrow. I'm on the fence on being able to finish a strong submission in a week. I kn
ow that I can always withdraw if reviews are bad (or if I don't feel like I have a strong submission in a week when it's
 due), but I'm worried that there might be a trace of the submission left online which future reviewers would be able to
 google. Can anyone confirm that this is only the case if you don't withdraw and instead submit a rebuttal that results 
in a rejection? If you withdraw from openreview, is any trace of it left online? Do you have to do some trick where you 
edit and scrub your submission before withdrawing? I know submission results are stochastic, so I'd like to know when, i
f ever, submitting is a strategic blunder.
```
---

     
 
all -  [ VERSES AI ($VERS) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/Wealthsimple_Penny/comments/1crv28d/verses_ai_vers_sets_new_standards_in_ai_with/) , 2024-05-22-0910
```
VERSES AI ($VERS), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a research
 roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by prov
iding clear goals to measure the progress and importance of $VERS's research and development endeavors. 

The company pl
ans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be a
s good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By meeti
ng these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to ge
t their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap has 
3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The fir
st benchmark, Classification and generation tasks, focuses on proving VERS's approach is better at tasks like recognizin
g images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that their 
method has the ability to outperform traditional deep learning methods. This test is important because it shows whether 
VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all abou
t testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VERSES
 is trying to play video games almost like a human but with way less practice. $VERS is using active inference to help t
heir AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming 

L
astly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky situ
ations where lots of different AI systems need to work together. $VERS wants to show that their AI can understand these 
complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit represe
ntational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and tackle 
complex problems together. 

$VERS publicly released this roadmap so the public can track their progress. The roadmap ca
n be accessed here: www.verses.ai/rd-overview 

Note: this is not financial advice please do your own research before in
vesting.
```
---

     
 
all -  [ AskScience AMA Series: I am a computer scientist at the University of Maryland. My research focus is ](https://www.reddit.com/r/askscience/comments/1crpcaj/askscience_ama_series_i_am_a_computer_scientist/) , 2024-05-22-0910
```
Hi Reddit! I am a computer scientist from the University of Maryland here to answer your questions about artificial inte
lligence.

**Furong Huang** is an Assistant Professor in the Department of Computer Science at the University of Marylan
d. She specializes in trustworthy machine learning, AI for sequential decision-making, and generative AI and focuses on 
applying foundational principles to solve practical challenges in contemporary computing.

Dr. Huang develops efficient,
 robust, scalable, sustainable, ethical and responsible machine learning algorithms that operate effectively in real-wor
ld settings. She has also made significant strides in sequential decision-making, aiming to develop algorithms that not 
only optimize performance but also adhere to ethical and safety standards. She is recognized for her contributions with 
awards including best paper awards, the MIT Technology Review Innovators Under 35 Asia Pacific, the MLconf Industry Impa
ct Research Award, the NSF CRII Award, the Microsoft Accelerate Foundation Models Research award, the Adobe Faculty Rese
arch Award, three JP Morgan Faculty Research Awards and Finalist of AI in Research - AI researcher of the year for Women
 in AI Awards North America.

**Souradip Chakraborty** is a third-year computer science Ph.D. student at the University 
of Maryland advised by Dr. Furong Huang. He works on the foundations of trustworthy reinforcement learning with a focus 
on developing safe, reliable, deployable and provable RL methods for real-world applications. He has co-authored top-tie
r publications and U.S. patents in artificial intelligence and machine learning. Recently he received an Outstanding Pap
er Award (TSRML workshop at Neurips 2022) and Outstanding Reviewer Awards at Neurips 2022, Neurips 2023 and AISTATS 2023
.

**Mucong Ding** is a fifth-year Ph.D. student in computer science at the University of Maryland, advised by Dr. Furon
g Huang. His work broadly encompasses data efficiency, learning efficiency, graph and geometric machine learning and gen
erative modeling. His recent research focuses on designing a more unified and efficient framework for AI alignment and i
mproving their generalizability to solve human-level challenging problems. He has published in top-tier conferences, and
 some of his work has been recognized for oral presentations and spotlight papers.

We'll be on from **2 to 4 p.m. ET (1
8-20 UT)** - ask us anything!

Other links:

+ Website: https://furong-huang.com/
+ Google Scholar page: https://scholar
.google.com/citations?user=13yyuCcAAAAJ&hl=en
+ Q&A on whether AI-generated content is detectable: https://cmns.umd.edu/
news-events/news/ai-generated-content-actually-detectable

Username: /u/umd-science
```
---

     
 
all -  [ [D] Neurips 2024 submissions ](https://www.reddit.com/r/MachineLearning/comments/1crahli/d_neurips_2024_submissions/) , 2024-05-22-0910
```
I just submitted an abstract to Neurips 2024. I was so impressed with my self for being two days early, and yet, my pape
r ID is over 7000. In the past I recall paper IDs were incremented as openreview received more submissions. Surely, this
 year it’s not the case! 7000 submissions already?!
```
---

     
 
all -  [ $VRSSF Releases Research Roadmap - New AI Standards ](https://www.reddit.com/r/Baystreetbets/comments/1cr11x8/vrssf_releases_research_roadmap_new_ai_standards/) , 2024-05-22-0910
```
VERSES AI ($VRSSF), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a researc
h roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by pro
viding clear goals to measure the progress and importance of $VRSSF's research and development endeavors. 

The company 
plans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be
 as good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By mee
ting these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to 
get their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap ha
s 3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The f
irst benchmark, Classification and generation tasks, focuses on proving VRSSF's approach is better at tasks like recogni
zing images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that the
ir method has the ability to outperform traditional deep learning methods. This test is important because it shows wheth
er VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all a
bout testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VER
SES is trying to play video games almost like a human but with way less practice. $VRSSF is using active inference to he
lp their AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming
 

Lastly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky 
situations where lots of different AI systems need to work together. $VRSSF wants to show that their AI can understand t
hese complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit re
presentational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and ta
ckle complex problems together. 

$VRSSF publicly released this roadmap so the public can track their progress. The road
map can be accessed here: [https://www.verses.ai/rd-overview](https://www.verses.ai/rd-overview) 

Note: this is not fin
ancial advice please do your own research before investing. 
```
---

     
 
all -  [ $VRSSF Releases Research Roadmap - New AI Standards ](https://www.reddit.com/r/pennystocks/comments/1cpxq1l/vrssf_releases_research_roadmap_new_ai_standards/) , 2024-05-22-0910
```
VERSES AI ($VRSSF), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a researc
h roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by pro
viding clear goals to measure the progress and importance of $VRSSF's research and development endeavors. 

The company 
plans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be
 as good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By mee
ting these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to 
get their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap ha
s 3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The f
irst benchmark, Classification and generation tasks, focuses on proving VRSSF's approach is better at tasks like recogni
zing images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that the
ir method has the ability to outperform traditional deep learning methods. This test is important because it shows wheth
er VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all a
bout testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VER
SES is trying to play video games almost like a human but with way less practice. $VRSSF is using active inference to he
lp their AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming
 

Lastly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky 
situations where lots of different AI systems need to work together. $VRSSF wants to show that their AI can understand t
hese complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit re
presentational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and ta
ckle complex problems together. 

$VRSSF publicly released this roadmap so the public can track their progress. The road
map can be accessed here: [https://www.verses.ai/rd-overview](https://www.verses.ai/rd-overview) 

Note: this is not fin
ancial advice please do your own research before investing. 
```
---

     
 
all -  [ VERSES AI ($VRSSF) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/smallstreetbets/comments/1cp6x6p/verses_ai_vrssf_sets_new_standards_in_ai_with/) , 2024-05-22-0910
```
VERSES AI ($VRSSF), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a researc
h roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by pro
viding clear goals to measure the progress and importance of $VRSSF's research and development endeavors. 

The company 
plans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be
 as good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By mee
ting these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to 
get their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap ha
s 3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The f
irst benchmark, Classification and generation tasks, focuses on proving VRSSF's approach is better at tasks like recogni
zing images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that the
ir method has the ability to outperform traditional deep learning methods. This test is important because it shows wheth
er VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all a
bout testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VER
SES is trying to play video games almost like a human but with way less practice. $VRSSF is using active inference to he
lp their AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming
 

Lastly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky 
situations where lots of different AI systems need to work together. $VRSSF wants to show that their AI can understand t
hese complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit re
presentational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and ta
ckle complex problems together. 

$VRSSF publicly released this roadmap so the public can track their progress. The road
map can be accessed here: www.verses.ai/rd-overview 

Note: this is not financial advice please do your own research bef
ore investing.
```
---

     
 
all -  [ How to leverage research opportunities in AI/ML as a student in Undergrad? ](https://www.reddit.com/r/UofT/comments/1cl4eks/how_to_leverage_research_opportunities_in_aiml_as/) , 2024-05-22-0910
```
Hi, I'm a first year student in ece and wanted to ask how I can get involved in ai and ml research? I know the first ste
p usually involves securing a grant through NSERC or smthg similar and reaching out to profs, but does anyone know how y
ou can get to the level of expertise that allows you to publish papers while in undergrad and get involved with things l
ike NeurIPS? I know some areas of specialty that a lot of people are working in is deep learning, I'm not too sure about
 any others like computer vision, but I know that a lot of companies like Nvidia seem to have connections to grad studen
ts who eventually connect research to industry, are there ways for undergrads to do things like that as well? Also, I kn
ow there are some cool startups that I've been trying to become involved in, and I've been working on side projects, but
 what would help me further develop my skills? Thanks.
```
---

     
 
all -  [ [HIRING][USD 100K - 180K+] Founding AI Engineer, Agents in New York ](https://www.reddit.com/r/PythonJobs/comments/1cjw1ec/hiringusd_100k_180k_founding_ai_engineer_agents/) , 2024-05-22-0910
```
As a Founding AI Engineer, you'll play a critical role in the development and scaling of our agents infrastructure, goin
g all the way from data ingestion to building state-of-the-art action-taking architectures. If you have a strong bias to
 action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Things you can work on
  
Work with researchers to translate the latest in state-of-the-art automation and reasoning methods to working code.  

Devise and implement ground-truth data collection techniques for fine-tuning generative action models.  
Implement pipe
lines for processing and constructing reference datasets and tools for solving goals.  
Build end-to-end machine learnin
g models that power self-improving agents.  
Implement public and private knowledge graphs for generative models.  
Thin
gs we look for  
Evidence of exceptional ability.  
Experience with generative model architectures, including Retrieval 
Augmented Generation, Graph Learning, AI agents and tree-search augmented LLMs.  
Experience building scalable data appl
ications with Python.  
Full-stack ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS,
 ICML, CCVPR).  
Experience building fast-changing enterprise software in a high-growth environment.  


**Read more / a
pply:** [**https://ai-jobs.net/job/198951-founding-ai-engineer-agents/**](https://ai-jobs.net/job/198951-founding-ai-eng
ineer-agents/)

&#x200B;
```
---

     
 
all -  [ [HIRING][USD 60K - 96K] AI Engineer Intern, Agents in New York (Flexibility to work remotely for exc ](https://www.reddit.com/r/PythonJobs/comments/1cjvzhv/hiringusd_60k_96k_ai_engineer_intern_agents_in/) , 2024-05-22-0910
```
As an AI Engineer Intern, you’ll have the opportunity to build a state of the art experience in building generative mode
l architectures. We’ll support you in owning a challenging end-to-end generative model focused problem. If you have a st
rong bias to action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Example pr
ojects  
Work with researchers to extend our generative model prompting architecture.  
Take part in implementing our gr
ound-truth data collection platform that powers the fine-tuning of generative action models.  
Extend our reference tool
s and datasets and integrate them into our automated reasoning systems.  
Things we look for  
Evidence of exceptional a
bility.  
Real world ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS, ICML, CCVPR).
  
Plus: Experience with generative model architectures, including Retrieval Augmented Generation, Graph Learning, AI ag
ents and tree-search augmented LLMs.

&#x200B;

**Read more / apply:** [**https://ai-jobs.net/job/198461-ai-engineer-int
ern-agents/**](https://ai-jobs.net/job/198461-ai-engineer-intern-agents/)

&#x200B;
```
---

     
 
all -  [ [HIRING][USD 60K - 96K] AI Engineer Intern, Agents in New York (Flexibility to work remotely for exc ](https://www.reddit.com/r/NYCjobs/comments/1cjvze8/hiringusd_60k_96k_ai_engineer_intern_agents_in/) , 2024-05-22-0910
```
As an AI Engineer Intern, you’ll have the opportunity to build a state of the art experience in building generative mode
l architectures. We’ll support you in owning a challenging end-to-end generative model focused problem. If you have a st
rong bias to action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Example pr
ojects  
Work with researchers to extend our generative model prompting architecture.  
Take part in implementing our gr
ound-truth data collection platform that powers the fine-tuning of generative action models.  
Extend our reference tool
s and datasets and integrate them into our automated reasoning systems.  
Things we look for  
Evidence of exceptional a
bility.  
Real world ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS, ICML, CCVPR).
  
Plus: Experience with generative model architectures, including Retrieval Augmented Generation, Graph Learning, AI ag
ents and tree-search augmented LLMs.

  
**Read more / apply:** [**https://ai-jobs.net/job/198461-ai-engineer-intern-age
nts/**](https://ai-jobs.net/job/198461-ai-engineer-intern-agents/)

&#x200B;
```
---

     
 
all -  [ [D] Something I always think about, for top conferences like ICML, NeurIPS, CVPR,..etc. How many pap ](https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/) , 2024-05-22-0910
```
I have some papers in top venus myself, but whenever I sit down and be brutually honest with myself. I feel my work is g
ood but it is just not that impactful, like one more brick in the wall.
I wonder how often we can see something as impac
tful as 'Attention is all you need' for example.
```
---

     
 
all -  [ [D] Why do juniors (undergraduates or first- to second-year PhD students) have so many papers at maj ](https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/) , 2024-05-22-0910
```
Hello everyone, today the ICML results are out, congratulations to all those who have papers accepted here. I'm not an a
cademic myself, but sometimes I read papers at these conferences for work, and it's really interesting. I just have a qu
estion: why do juniors have so many papers at these conferences? I thought this was something you would have to learn th
roughout your 5 years of PhD and almost only achieve in the final years of your PhD. Furthermore, I've heard that to get
 into top PhD programs in the US, you need to have some papers beforehand. So, if a junior can publish papers early like
 that, why do they have to spend 5 long years pursuing a PhD?
```
---

     
 
all -  [ Combinatorial Optimization in OR? ](https://www.reddit.com/r/OperationsResearch/comments/1cg8ysh/combinatorial_optimization_in_or/) , 2024-05-22-0910
```
Hi,

I got a Phd in Computer Science. I am interested in combinatorial optimization, so I am thinking of starting a post
doc in RO to work on this topic. 

What makes me doubt is that if I look for combinatorial optimization papers in 2024 i
n Google scholar most of them are published in NeurIPS conference, so my question is OR is the right place?

From my exp
erience during my master's and bachelor's, combinatorial optimization is always taught in the OR courses.
```
---

     
 
all -  [ Does anyone know a method to solve this problem? (besides installing a new version of comfyui) ](https://www.reddit.com/r/comfyui/comments/1cfsu8x/does_anyone_know_a_method_to_solve_this_problem/) , 2024-05-22-0910
```
https://preview.redd.it/zjwgov5pedxc1.png?width=800&format=png&auto=webp&s=f998c3b61ddfd5b5dcbdab63a2645fc7a4cb145b


```
---

     
 
all -  [ [R] I made an app to predict ICML paper acceptance from reviews ](https://www.reddit.com/r/MachineLearning/comments/1cbwsr2/r_i_made_an_app_to_predict_icml_paper_acceptance/) , 2024-05-22-0910
```
[https://www.norange.io/projects/paper\_scorer/](https://www.norange.io/projects/paper_scorer/)

A couple of years ago, 
u/programmerChilli [analyzed](https://www.reddit.com/r/MachineLearning/comments/im65ia/r_i_made_a_website_for_predicting
_whether_your/) ICLR 2019 reviews data and trained a model that rather accurately predicted acceptance results for NeurI
PS.

I've decided to continue this analysis and trained a model (total \~6000 parameters) on newer NeurIPS reviews, whic
h has twice as many reviews compared to ICLR 2019. Additionally, review scores system for NeurIPS has changed since 2019
, and here is what I've learned:

1) Both conferences consistently reject nearly all submissions scoring <5 and accept t
hose scoring >6. The most common score among accepted papers is 6. An average rating around 5.3 typically results in dec
isions that could go either way for both ICML and NeurIPS, suggesting that \~5.3 might be considered a soft threshold fo
r acceptance.

2) Confidence scores are less impactful for borderline ratings such as 4 (borderline reject), 5 (borderli
ne accept), and 6 (weak accept), but they can significantly affect the outcome for stronger reject or accept cases. 

Fo
r instance, with ratings of \[3, 5, 6\] and confidences of \[\*, 4, 4\], changing the 'Reject' confidence from 5 to 1 sh
ifts the probabilities from 26.2% - 31.3% - 52.4% - 54.5% - 60.4%, indicating that lower confidence in this case increas
es your chances.

Conversely, for ratings \[3, 5, 7\] with confidences \[4, 4, 4\], the acceptance probability is 31.3%,
 but it drops to 28.1% when the confidence changes to \[4, 4, 5\]. Although it might seem counterintuitive, a confidence
 score of 5 actually decreases your chances. One possible explanation is that many low-quality reviews rated 5 are often
 discounted by the Area Chairs (ACs).

Hope this will be useful, and thanks to u/programmerChilli for the inspiration!


I also discussed this topic in a series of [tweets](https://x.com/nikitadurasov/status/1782746231082488131).


```
---

     
 
all -  [ Should I Keep Trying or Master Out? ](https://www.reddit.com/r/PhD/comments/1caz9rx/should_i_keep_trying_or_master_out/) , 2024-05-22-0910
```
I entered the Computer Science PhD program at our school 3 years ago (I'm in USA). I did not have a masters, they had a 
combined program thingie. I did all of the masters courses so I can master out now, but I have 0 papers. My advisorwhen 
I joined had consultancy work in France on Spring and Summer semesters, and would generally let his students fend for th
emselves and only offer feedback once you had a draft for a paper. We also had no lab or lab meetings in person, if he n
eeded to talk to you it'd be over zoom. Since I had 0 research experience I spent the last 2.5 years banging my head aga
inst the wall and making no progress.

I received an offer to join another professors lab beginning of this semester bec
ause he seemed to generally like me, with a slightly better pay as well so I accepted and changed labs. He's the head of
 the Explainable AI lab here. He expects 3 top-tier conference papers from his students (NeurIPS, CVPR, etc). The proble
m as I found out, is that there's no research direction to his lab, he has no ideas to lead you, and none of the student
s are good at collaborating, so everyone is throwing shit at a wall and hoping it sticks. XAI in general is not an excit
ing and interesting field either. Not many interesting new papers come out recently, so its mostly about coming up with 
methods no one gives a shit about, or coming up with datasets no one else has made, showing existing papers do badly, an
d training a model to say we did it better, at least from what I've observed here so far. On average his students seem t
o spend 5-6 years before finishing their PhD, and after being in this lab since January I kinda see why. Since I joined 
now, it's safe to say I have 3-5 years ahead if I stay here. I'm trying to get a paper out for NeurIPS Datasets & Benchm
ark track but part of me knows its a hack job that I assembled together just to have something to submit and appease the
 prof. Its kind of looking bleak, but I have only 8 months or so of job experience and can't seem to get any offers in t
he current market. I work full time on top of my PhD. Its been extremely stressful, and I've developed what seems to be 
treatment resistant depression over the last 3 years.

What do I do? Do I keep trying and hope it pays off? Do I just st
art writing Masters with a graduation date at the end of next semester or something so I can start applying? I can't qui
t on the spot, I kind of need the salary as I have bills to pay and no one to support me. Not a day goes by where I wish
 I could turn back time and just apply for jobs back in 2021 when I first graduated instead of this shit.

Alternatively
, there's a professor who Im relatively familiar with and have good-ish relationship with. She's primarily working in VR
&Game Dev. I mainly focused on AI because I want to get a good paying job, but have experience in both VR and game dev f
rom freelance jobs I did, and generally think its a lot more fun and tolerable than AI work for me. Would it make sense 
to try and switch labs a 3rd time? She expects journal, or maybe even just a few arxiv papers and does not seem to care 
much about conferences etc. in general, which seems doable. She doesn't pay a GRA salary though, so I'd only have a teac
hing assistant's salary if I made the switch.

I don't care about academia, I want to work in industry since my primary 
motivation is money. I've been told PhD matters when it comes to hiring but I don't know the specific papers/conferences
 etc. will matter in the end.
```
---

     
 
all -  [ Submitting to EMNLP after submitting to a workshop? ](https://www.reddit.com/r/LanguageTechnology/comments/1caktsl/submitting_to_emnlp_after_submitting_to_a_workshop/) , 2024-05-22-0910
```
Hi there,

I recently finished a paper that I submitted to an EAMT workshop through OpenReviews. That workshop is going 
to have published proceedings. I was wondering if I still was allowed to submit my paper to EMNLP 2024. I checked [https
://aclrollingreview.org/cfp#multiple-submission-policy](https://aclrollingreview.org/cfp#multiple-submission-policy) and
 they say this:

'ARR + Other Venue: ARR precludes multiple submissions. ARR will not consider any paper that is under r
eview in a journal or another conference at the time of submission, and submitted papers must not be submitted elsewhere
 during the ARR review period. This policy covers all journals and refereed and archival conferences and workshops witho
ut exception (e.g., TACL, Computational Linguistics, IJCAI, SIGIR, AAAI, ICASSP, ICML, NeurIPS, etc). In addition, we wi
ll not consider any paper that overlaps significantly in content or results with papers that will be (or have been) publ
ished elsewhere, without exception.'

What do they mean exactly by 'refeered and archival conferences and workshops'? Do
es this apply to my case?
```
---

     
 
all -  [ Confusion about gradient and divergence as adjoint operators ](https://www.reddit.com/r/askmath/comments/1c9lpzo/confusion_about_gradient_and_divergence_as/) , 2024-05-22-0910
```
I understand the derivation of -div and grad being adjoint operators, but then shouldn't equality hold between 'integral
 of (norm of gradient)\^2' and '-1 \* integral of laplacian \* function' ? Where did the negative go in the equality?

&
#x200B;

[https://proceedings.neurips.cc/paper\_files/paper/2001/file/f106b7f99d2cb30c3db1c3cc0fde9ccb-Paper.pdf](https:
//proceedings.neurips.cc/paper_files/paper/2001/file/f106b7f99d2cb30c3db1c3cc0fde9ccb-Paper.pdf)  


page 5 in the middl
e of the page (reddit removed my post when I put a screenshot and I'm not sure how to type the manifold integral in late
x)
```
---

     
