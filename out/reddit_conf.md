 
all -  [ [D] Do NeurIPs workshop papers get published? ](https://www.reddit.com/r/MachineLearning/comments/16nsw95/d_do_neurips_workshop_papers_get_published/) , 2023-09-21-0909
```
I’m submitting to the workshop and was wondering if the papers there get published?
```
---

     
 
all -  [ [D] NeurIPS 2023 paper acceptance results ](https://www.reddit.com/r/MachineLearning/comments/16nljrn/d_neurips_2023_paper_acceptance_results/) , 2023-09-21-0909
```
NeurIPS 2023 paper acceptance results are supposed to be released at 8 pm (CDT) on September 21. I thought to create a d
iscussion thread for us to countdown and discuss any celebration/issue/complaint/feedback or anything else.

There is so
 much noise in the reviews every year. Some good work that the authors are proud of might get rejected because of the no
isy system, given that NeurIPS is growing so large these years. We should keep in mind that the work is still valuable n
o matter what the final result is.
```
---

     
 
all -  [ Profile Evaluation MSCS 2024 ](https://www.reddit.com/r/MSCS/comments/16m58hk/profile_evaluation_mscs_2024/) , 2023-09-21-0909
```
Hi everyone, could you kindly help to advise on my choices given the following profile? Thank you so much!

I am aiming 
for a MSCS in AI/ML field and plan to apply for both thesis based (see if I'm into research) and course based (in case I
 decide to go for industry). You may refer to my [resume](https://imgur.com/XOvOAiz) for more details. Moreover, below a
re some supplementary info:

&#x200B;

Background:

* Undergraduate from Hong Kong, on CSRankings (World: 90 - 100; Asia
: 10 - 20)
* BSc in Computer Science (CGPA: 3.52/4.3; CS major GPA: 3.56/4.3) // I got half As and half Bs
   * WES eval
uation: CGPA 3.67/4.0
* Overseas exchange at UIUC (CGPA: 3.55/4.0) // got a B- for Machine Learning course... was workin
g on NeurIPS at the time so screwed up the assignments, got As for other Non-CS courses
* English: IELTS 8.0/9.0 (expire
d May 2023; planning to take TOEFL soon)
* GRE: to be taken

Academics:

1. NeurIPS (Computer Vision related, joint 1st 
author)
2. arXiv (Computer Vision related, joint 1st author, rejected by TPAMI)
3. bioRxiv (bioinformatics related, 4th 
author, submitted to Science/AAAS journal under review)
4. Patent (reinforcement learning related, 1st author, under rev
iew)

&#x200B;

Choices:

**Dream:**  MCS@UIUC

**Ambitious:**  MSCS@USC (CS32 thesis), MSCS@NYU Courant, MSCS@TAMU, MEN
G@Waterloo ECE (co-op), MENG@Toronto ECE, MPhil@Edinburgh

**Moderate:** MSCS@Tandon, MCS@UMass, MENG@UCLA

**Safe:** MC
S@NEU SV, MENG@Waterloo ECE (non co-op)

&#x200B;

Would it be an over- or under-estimation? Please feel free to suggest
 more programs/schools.

Given that spring applications are still open, I'm also trying for the spring deadlines in Sep/
Oct, if it has less severe competition. Since I primarily wish for research based, so having less internships does not a
ffect much.

&#x200B;

Update 20230919

Last year I was rejected by MSSE@CMU-SV, MCS@UIUC, MSCS@Columbia, MSCS@SFU, MSCS
@UBC

If possible, can you also comment on my possibility of going for research-based alternatives of the MCS programs a
bove? E.g. MS/PhD@UMass, MMath@Waterloo, MSCS@UCLA
```
---

     
 
all -  [ Is it weird to send out cold emails asking professors for an opportunity to do a long-term self-fund ](https://www.reddit.com/r/AskAcademia/comments/16l25ha/is_it_weird_to_send_out_cold_emails_asking/) , 2023-09-21-0909
```
As the title suggests, I'm currently pursuing a CS PhD in China. However, I'm considering a different career path and ha
ve decided to mastering out to pursue a PhD in the US. I'm aiming for a top 10-20 school in the field of computer scienc
e, but I'm not sure if my profile is competitive enough. I have 2-3 papers published in venues like NeurIPS and ICLR, as
 well as work experience. However, I feel I lack strong references, particularly from the US. I've heard that recommenda
tion letters are as important as qualifications.

Therefore, I'm considering delaying my grad application for at least s
ix months. During this time, I plan to visit a renowned lab to gain more experience and connect with professors who coul
d write me recommendation letters. I've sent out 3-4 cold emails to professors who I believe would be a good fit. In the
se emails, I expressed my interest in working with them and briefly outlined my research plans. I also mentioned that I 
could self-fund my visit if necessary. The emails are quite long, usually 200-300 words. As for now I have yet received 
any response from them.

Do you think it's off-putting to directly ask about the possibility of a self-funded visit with
out prior conversations? Which might appear that I am quite desperate.
```
---

     
 
all -  [ Call for Submissions: Queer in AI Workshop @ NeurIPS 2023 ](https://groups.google.com/g/ml-news/c/LR_he9Med3g) , 2023-09-21-0909
```

```
---

     
 
all -  [ [P] Guide: Implementing ImageNet classification using Deep CNNs Paper. ](https://www.reddit.com/r/MachineLearning/comments/16ilhcd/p_guide_implementing_imagenet_classification/) , 2023-09-21-0909
```
Need help on how to get started with implementing a research paper. I'm implementing the Imagenet classification task pa
per for my final year undergrad mini-project. Any advice is appreciated on how to get started? I have mid-level machine 
learning knowledge and am ready to pick the required concepts on the go. Please help. Thank you :)

Link: [https://proce
edings.neurips.cc/paper\_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.c
c/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
```
---

     
 
all -  [ Profile Evaluation for MS in CS/ML/DS - Fall '24 ](https://www.reddit.com/r/MSCS/comments/16ibebe/profile_evaluation_for_ms_in_csmlds_fall_24/) , 2023-09-21-0909
```
Academic Profile

· B.E. ECE from '24  + Data Science Minor

· GPA - 9.29 from Tier 1 college

· GRE/TOEFL : Not yet giv
en (Target \~330/\~110)

=======================================

Work & Research Experience

· \~1 year at Brown Univer
sity

· 4 months at TUD

· Upcoming thesis at Cambridge

· Two projects under university professors

===================
====================

LORs

· PI from Brown University (Strong - Moderate)

· PI from TU Dresden (Strong - Moderate)

· 
BITS professor (Academic based rather than research based)

=======================================

Publication

· Co-A
uthorship in paper that got Oral Presentation at ICML

· Submitting first authorship paper at NeurIPS workshop (relative
ly sure of its acceptance)

=======================================

Awards

· DAAD Schoalrship

· MITACS Scholarship

=
======================================

Universities and classification

Ambitious :

* ETH Zurich CS
* Cambridge MLMI
*
 Princeton CS
* UCSD CS

Moderate:

* EPFL DS
* GATech CS
* UC London ML
* U Toronto MScAC AI

Safe(?) :

* Uni Edinburg
h DS
* UvAmsterdam AI

Wanted an evaluation of the unis and some suggestions for safe universities
```
---

     
 
all -  [ Exploring the Landscape of AI: Developments, Challenges, and Future Prospects ](https://www.reddit.com/r/ai_news_by_ai/comments/16i9cbm/exploring_the_landscape_of_ai_developments/) , 2023-09-21-0909
```





#leaders #tool #update #startups #release #feature #event #science #opinions #opensource #vc #ai_enabled #api #majo
r_players #paper #scheduled

Several non-parametric methods such as nearest neighbor, Parzen windows, and kernel methods
 are discussed, but they suffer from the curse of dimensionality [1]. Yann LeCun and François Vallet were colleagues in 
1991, with Vallet using LeCun's neural net simulator called HLM starting from 1986 [2].







California Governor Gavin
 Newsom has signed an executive order to study the development, use, and risks of generative artificial intelligence, a 
significant step towards potentially regulating this rapidly growing technology [3].







Stability AI has launched St
able Audio, their first AI product for music and sound generation, allowing users to create music with AI for free [4]. 
Stable Audio uses generative AI techniques to deliver faster and higher-quality music and sound effects through a user-f
riendly web interface [5]. Stability AI has partnered with Audiosparx, a leading music library, to curate a new model [6
]. However, due to high demand, their servers are currently at full capacity [11].







AIVF, an Israeli start-up, has
 developed an AI tool that selects the most viable embryo for implantation during IVF, increasing the chances of a healt
hy pregnancy by up to 30% [8]. OpenAI stores user data for 30 days, allows its employees to access the data, and may sha
re it with other services [9].







The author transitioned from building web applications to focusing on Machine Lear
ning systems, learning valuable skills while using Upwork [10]. LLM output validation is important to ensure the reliabi
lity and predictability of generative AI applications, with Guardrails AI introduced as a tool for implementing it [12].








Replit has introduced a new tool called Replit ModelFarm, which allows users to build Generative AI apps quickly
 and securely [15]. The tool is currently available for free on Hacker and Pro plans until October 15th [20]. Kraftful h
as developed a plugin for ChatGPT called the product coach, providing assistance with various product-related questions 
and tasks [21].







Apple is poised to become the leading AI company globally, with their advancements in hardware an
d the impressive capabilities of their ChatGPT competitor, Ajax [22]. Auto-regressive language models (LLMs) cannot plan
 or reason effectively, according to Yann LeCun [23].







Google AI hosted Research@ Accra in Ghana, featuring lightn
ing talks and interactive demos on various important topics [18]. Google AI has announced that the NeurIPS Unlearning Co
mpetition is now open for submissions on Kaggle [28].







OpenAI has announced the opening of a new office in Dublin,
 Ireland, to better serve the European market [30].




[1. Yann LeCun @ylecun https://twitter.com/ylecun/status/1701820
417323696318](https://twitter.com/ylecun/status/1701820417323696318)

[2. Yann LeCun @ylecun https://twitter.com/ylecun/
status/1701825789472161896](https://twitter.com/ylecun/status/1701825789472161896)

[3. Mustafa Suleyman @mustafasuleyma
n https://twitter.com/mustafasuleyman/status/1701875880149012561](https://twitter.com/mustafasuleyman/status/17018758801
49012561)

[4. Stability AI @stabilityai https://twitter.com/stabilityai/status/1701872897076191485](https://twitter.com
/stabilityai/status/1701872897076191485)

[5. Stability AI @stabilityai https://twitter.com/stabilityai/status/170187337
5440699583](https://twitter.com/stabilityai/status/1701873375440699583)

[6. Stability AI @stabilityai https://twitter.c
om/stabilityai/status/1701873857697566772](https://twitter.com/stabilityai/status/1701873857697566772)

[7. Stability AI
 @stabilityai https://twitter.com/stabilityai/status/1701879160837226554](https://twitter.com/stabilityai/status/1701879
160837226554)

[8. Mustafa Suleyman @mustafasuleyman https://twitter.com/mustafasuleyman/status/1701893430744420721](htt
ps://twitter.com/mustafasuleyman/status/1701893430744420721)

[9. Santiago @svpino https://twitter.com/svpino/status/170
1903118617767953](https://twitter.com/svpino/status/1701903118617767953)

[10. Santiago @svpino https://twitter.com/svpi
no/status/1701942866904318118](https://twitter.com/svpino/status/1701942866904318118)

[11. Stability AI @stabilityai ht
tps://twitter.com/stabilityai/status/1701981144076386695](https://twitter.com/stabilityai/status/1701981144076386695)

[
12. cohere @cohere https://twitter.com/cohere/status/1701982872566186350](https://twitter.com/cohere/status/170198287256
6186350)

[13. a16z @a16z https://twitter.com/a16z/status/1701989432591536539](https://twitter.com/a16z/status/170198943
2591536539)

[14. a16z @a16z https://twitter.com/a16z/status/1701989433795317967](https://twitter.com/a16z/status/170198
9433795317967)

[15. Replit ⠕ @replit https://twitter.com/replit/status/1701993771465052666](https://twitter.com/replit/
status/1701993771465052666)

[16. Meta AI @metaai https://twitter.com/metaai/status/1701996259761144003](https://twitter
.com/metaai/status/1701996259761144003)

[17. Meta AI @metaai https://twitter.com/metaai/status/1701997478869147844](htt
ps://twitter.com/metaai/status/1701997478869147844)

[18. Google AI @googleai https://twitter.com/googleai/status/170200
3213569015829](https://twitter.com/googleai/status/1702003213569015829)

[19. Google AI @googleai https://twitter.com/go
ogleai/status/1702004647815532739](https://twitter.com/googleai/status/1702004647815532739)

[20. Replit ⠕ @replit https
://twitter.com/replit/status/1702013320868544607](https://twitter.com/replit/status/1702013320868544607)

[21. Y Combina
tor @ycombinator https://twitter.com/ycombinator/status/1702016907073962284](https://twitter.com/ycombinator/status/1702
016907073962284)

[22. Santiago @svpino https://twitter.com/svpino/status/1702026895339000213](https://twitter.com/svpin
o/status/1702026895339000213)

[23. Yann LeCun @ylecun https://twitter.com/ylecun/status/1702027572077326505](https://tw
itter.com/ylecun/status/1702027572077326505)

[24. Greg Brockman @gdb https://twitter.com/gdb/status/1702039916056821858
](https://twitter.com/gdb/status/1702039916056821858)

[25. Santiago @svpino https://twitter.com/svpino/status/170204218
9700731042](https://twitter.com/svpino/status/1702042189700731042)

[26. Mustafa Suleyman @mustafasuleyman https://twitt
er.com/mustafasuleyman/status/1702055970388492618](https://twitter.com/mustafasuleyman/status/1702055970388492618)

[27.
 Sundar Pichai @sundarpichai https://twitter.com/sundarpichai/status/1702069747041399105](https://twitter.com/sundarpich
ai/status/1702069747041399105)

[28. Google AI @googleai https://twitter.com/googleai/status/1702075819030704609](https:
//twitter.com/googleai/status/1702075819030704609)

[29. Yann LeCun @ylecun https://twitter.com/ylecun/status/1702137952
879415772](https://twitter.com/ylecun/status/1702137952879415772)

[30. OpenAI @openai https://twitter.com/openai/status
/1702172713962598765](https://twitter.com/openai/status/1702172713962598765)
```
---

     
 
all -  [ What are the best venues for industry Data Scientists and ML practitioners to publish their work? ](https://www.reddit.com/r/datascience/comments/16i0roz/what_are_the_best_venues_for_industry_data/) , 2023-09-21-0909
```
As a professional in the field, I've always targeted SIGKDD for publishing applied DS/ML work. I think SIGKDD is the top
 and most reputable in particular for industry practitioners, as opposed to academic researchers, who focus more on nove
lty and therefore aim for NeurIPS or ICML. This is thanks to the Applied-Data-Science track in SIGKDD which scopes deplo
yed systems and domain specific applications, rather than purely novel discoveries.

My question is whether there are ot
her \*\*reputable\*\* conferences similar to KDD in this sense and allow for publishing?
```
---

     
 
all -  [ Chances for Global Talent (exceptional promise) under peer review ](https://www.reddit.com/r/ukvisa/comments/16ewurq/chances_for_global_talent_exceptional_promise/) , 2023-09-21-0909
```
Hi everyone,

I am a research scientist working in one of the FAANG companies in the US. I did my undergrad and PhD in t
he UK (both at Oxford/Cambridge). I've worked a while for my current employer but got a bit fed up with the Bay Area & b
ecause of personal reasons I want to move back to the UK, either via an internal transfer (my company has a large resear
ch presence in the UK) or, if that's not possible, finding a new job. I got my eyes on the global talent programme, and 
since I will most likely be working as a researcher in industry rather than academia, I don't think any of the fast-trac
k routes would apply and 'peer review' (in my case through RAEng) seems to be the only choice. I've not seen many data p
oints on how high the bar is through this route (unlike the US EB-1 route, where tons of data are available), though, so
 I think it's a good idea to gather wisdom from Reddit to see how likely I'll be granted that visa, before more commitme
nt like getting a lawyer. Any advice is extremely appreciated!

&#x200B;

**About me:**

\- integrated masters & PhD wit
h scholarship in AI/ML (Oxbridge)

\- 1-2 yr work experience at one of the major US tech companies (think Alphabet / Met
a / Amazon) in California

\- \~20 papers (first/co-first author in half of them); around 15 published in top conference
s (NeurIPS/ICML/ICLR/ACL etc. if you are familiar with AI/ML venues)  & journals -- note that in Computer science in gen
eral, conferences are the primary venue in contrast to journals. I have also served as a peer reviewer in these venues (
reviewed >50 papers).

\- \~400 citations according to Google Scholar, although half of the papers are published fairly 
recently (<1 year) -- hopefully citations will catch up later.

\- Good chance of getting a recommendation letter from s
ome big guy (think a Fellow of RAEng level) at my old lab in the UK.

\- Have been and will still be active in research 
(publishing papers, etc.) even though I'm working in the industry.

&#x200B;

A side question is: it seems that getting 
sponsored by RAEng would allow me to get ILR in 3 years even under 'exceptional promise' -- would that be true in my cas
e as well, even though I'm not conducting research in academia?

&#x200B;

Thanks, everyone!
```
---

     
 
all -  [ [D]What do people think about papers published in the NeurIPS dataset track in comparison to those p ](https://www.reddit.com/r/MachineLearning/comments/16cto3t/dwhat_do_people_think_about_papers_published_in/) , 2023-09-21-0909
```
 I'm curious to learn about the perception of papers published in the NeurIPS dataset track in comparison to those publi
shed in the main conference. Specifically, I'd like to know how both companies and Ph.D. committees view these papers. A
re they considered equally valuable, or is there a notable difference in their reputation and significance? Your insight
s and experiences would be greatly appreciated! 
```
---

     
 
all -  [ Profile Eval - Quant Trading to ML PhD ](https://www.reddit.com/r/gradadmissions/comments/16bamcs/profile_eval_quant_trading_to_ml_phd/) , 2023-09-21-0909
```
Hello! I’ve been working a bit over a year in trading and now looking to fulfill my dream of getting a PhD and focusing 
purely on research. Would love to get some feedback on how realistic the schools I’m looking at are given my background.


School:
US T15, 3.8 GPA, Major in CS + Math

Research (ML related):
2nd author in a Neurips workshop
2nd author in a N
ature Journal
1st author poster presentation at a small workshop

Awards:
Putnam top 500

Work:
1 internship at FAANG
1 
internship in trading
currently in trading FT

Rec letters:
research advisor (good), work manager (good), professor (wea
k)

(US Citizen)

1. Given my summers were spent interning in the industry rather than doing research, will this notably
 impact my application negatively?

2. Obviously I’d like to go to Stanford/CMU/MIT/Berkeley, but how are my odds given 
other competing applicants probably have all summers spent on research? (I can verify the labs there have interesting+re
levant work I’d like to be a part of)

3. Is it perhaps better to apply for a research based MS programs instead to get 
better research experience and stronger rec letters?
```
---

     
 
all -  [ Publishing in a journal vs top conference for computational biology ](https://www.reddit.com/r/bioinformatics/comments/16a2wtg/publishing_in_a_journal_vs_top_conference_for/) , 2023-09-21-0909
```
My group has been able to create some novel, medium impact findings in the field of  'omics sequence labeling using dila
ted networks.  We are considering on where we would like to send our results to.

Since the work is highly within the in
tersection of applied deep learning and computational biology, we are indecisive on whether to send our work towards a d
eep learning confrerence (ICML, neurIPS, ICLR) or to send it to a traditional journal within this domain.  Additionally,
 there are some promising conferences within the machine learning and computational biology arising (MLCB).  How does on
e pick between these options?
```
---

     
 
all -  [ [D] NeurIPS reviewers edited review and score after discussion period: can they delete their own rev ](https://www.reddit.com/r/MachineLearning/comments/1687luu/d_neurips_reviewers_edited_review_and_score_after/) , 2023-09-21-0909
```
Hi, we have a paper submission to NeurIPS and we have two reviewers who changed their scores and review content silently
 by editing the original review comment and score after the discussion period. The edited review comment now discusses e
ntirely different point.

We would like to raise this concern to AC but the thing is that we didn’t save the original re
view comment, and the “revision history” for some reason doesn’t show the previous content, other than the entry that th
ere was previous version. But this revision history overall isn’t inconsistent (showing the last two history after the d
iscussion period, but the ones before the period is not shown) 


Can reviewers delete their own revision history in Ope
nReview tool? I don’t know if this is a bug or they deleted them with an intention.
```
---

     
 
all -  [ [D] Am I the only one finding this a bit upsetting? ](https://www.reddit.com/r/MachineLearning/comments/167n0g0/d_am_i_the_only_one_finding_this_a_bit_upsetting/) , 2023-09-21-0909
```
Hello everyone,

In the process of writing up a literature review for my master's thesis, I wanted to cover the impact o
f ReLU on the field which was significant. When looking for an original paper I came across this paper/report: [https://
arxiv.org/abs/1803.08375](https://arxiv.org/abs/1803.08375). There isn't anything special about this work and as a matte
r of fact, I was surprised that it has thousands of citations (2974 at the moment of writing this post according to Goog
le Scholar). Given this and that this work is not an original ReLU paper but more of a file documenting an implementatio
n of it for a particular setup I found it quite intriguing. Then I started to dig into works that cited this and unexpec
tedly papers from top conferences such as NeurIPS cited the aforementioned document as a reference to the activation fun
ction. Here are some examples:

1. [https://proceedings.neurips.cc/paper\_files/paper/2022/file/fbb10d319d44f8c3b4720873
e4177c65-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/fbb10d319d44f8c3b4720873e4177c
65-Paper-Conference.pdf)
2. [https://proceedings.neurips.cc/paper\_files/paper/2022/file/69e2f49ab0837b71b0e0cb7c555990f
8-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/69e2f49ab0837b71b0e0cb7c555990f8-Pape
r-Conference.pdf)

The researchers who have done that are not referencing the original ReLU paper instead which I think 
is a bit disrespectful towards the achievement of original authors. On the other hand, maybe I am overthinking it a bit.
 ReLU has been around for a while and it would be surprising for someone conducting research in deep learning to not kno
wing it hence as a reader I wouldn't necessarily mind if people did not include the reference to the paper which is wide
ly known. However, I reckon if a reference is made, then it should be meaningful and correct, and not just another extra
 few lines in a bibliography making it look big.
```
---

     
 
all -  [ Road from ML PhD to Data Scientist/MLE ](https://www.reddit.com/r/learnmachinelearning/comments/166872e/road_from_ml_phd_to_data_scientistmle/) , 2023-09-21-0909
```
Hi all;  


So, I have just received my PhD in Machine Learning. From a known uni in the EU, I had a slightly above-aver
age PhD (Neurips, AAAI, UAI papers). Now I am starting a postdoc at another uni, for 2 years. However, I am getting cold
 feet about academia and thinking of leaving for industry. 

My question is: what can I do in the next two years to incr
ease my chances of finding data science or MLE roles? Being a more theory-oriented researcher, my SWE game is very weak.
 I need to show employers that I have the tech stack knowledge. Would certificates help if I train for, say, Google's ML
 Engineer certification? What about data science? I do not expect to start senior or middle-level just because I have a 
PhD. I am more than okay starting as a junior, knowing that my SWE game is weak, and I don't have any industry experienc
e. I don't mind starting from the bottom of the barrel.

Follow-up questions:

1. For all those who are going to say: ce
rtificate is useless, you need experience; how do I get the first job to get experience then?  


&#x200B;
```
---

     
 
all -  [ [D] Limit the Number of Papers I Review on OpenReview? ](https://www.reddit.com/r/MachineLearning/comments/162uumz/d_limit_the_number_of_papers_i_review_on/) , 2023-09-21-0909
```
Hello,

Does anyone know if it's possible to set a limit to the number of papers you are assigned as a reviewer on OpenR
eview? Specifically for ICLR 2024. I saw a Twitter thread about this option before for ICML. It blows my mind that this 
is not easy to change. I got 5 papers for the last NeurIps which was very overwhelming. As reviewers, we provide a free 
service to the community, and we should be allowed to pick how much work we want to undertake...
```
---

     
 
all -  [ [Discussion] Should religion-based workshops exist in ML conferences ](https://www.reddit.com/r/MachineLearning/comments/161c7zm/discussion_should_religionbased_workshops_exist/) , 2023-09-21-0909
```
Over the years, ML conferences had a lot of workshops such as women in ML, LatinXAL etc. that are aimed at increasing th
e diversity in the ML community. I've always been supportive of these workshops as I've seen first-hand how some of them
 face obstacles just based on their gender or ethnicity.   


However, I recently saw a tweet for Muslim in ML workshop 
at NeurIPS and I am not sure how to feel about it. They say it's a workshop meant for 'those who self-identify as Muslim
, or work on research that address challenges faced by Muslims'. I am not exactly sure what they mean by research that a
ddress challenges faced by Muslims. Over that, I don't think religion-based workshops in a science conference is a good 
idea. I think religion should be kept out of science, and I don't know if tomorrow n different religion based workshops 
are going to popup. 

Like I said, I'm not completely sure if I'd support such a workshop or not, but I'd love to hear w
hat other folks in ML research community think about it. Before someone calls me Islamophobic, I'm talking about any rel
igion-based workshop in general, not just Muslim in ML. I'd have made this post even if I saw a Christian in ML or Jews 
in ML workshop. 

  


&#x200B;
```
---

     
 
all -  [ Meta AIs Code Llama and Googles Quantum Experiments: Advancements in AI and Quantum Computing ](https://www.reddit.com/r/ai_news_by_ai/comments/160nxjm/meta_ais_code_llama_and_googles_quantum/) , 2023-09-21-0909
```





#major_players #tool #release #opensource #leaders #api #science #paper #event #scheduled

Meta AI has launched Cod
e Llama, a large language model (LLM) based on Llama 2, specifically designed for coding tasks. This state-of-the-art mo
del is available for both research and commercial use[1]. Code Llama can generate code based on text prompts, aiming to 
enhance developer workflows and simplify the process of learning to code. It supports popular programming languages and 
comes in three sizes with different parameters, providing stable generations with up to 100,000 tokens of context[2]. Co
de Llama has outperformed other open-source LLMs in benchmark tests and has undergone safety measures to mitigate risks[
2]. Notable figures such as Yann LeCun have shared their experiences using Code Llama as a debugging helper[3].







G
oogle AI has announced a workshop called ATTRIB at NeurIPS 2023. The workshop invites researchers and practitioners to s
ubmit papers and ideas on attributing model behavior to training data, algorithms, architecture, and more. The aim is to
 advance the understanding of model behavior attribution and address challenges in understanding the influence of traini
ng datasets, subcomponents within models, and algorithmic choices on model performance[4].







In a blog post, an app
roach using in-context learning and a novel algorithmic prompting technique to enable algorithmic reasoning capabilities
 in large language models was discussed. The approach leverages algorithmic prompting, which extracts algorithmic reason
ing abilities from language models by outputting the steps needed for an algorithmic solution and providing detailed exp
lanations for each step. The results show that the model can reliably execute algorithms on out-of-distribution examples
 and achieve strong generalization on arithmetic problems[6].







Google AI has made progress in developing useful be
yond-classical quantum experiments that can be performed on current noisy quantum processors. They have introduced a fra
mework for measuring the computational cost of a quantum experiment, called the 'effective quantum volume'. This framewo
rk has been applied to evaluate the computational cost of three recent experiments: random circuit sampling, out of time
 order correlators (OTOCs), and a Floquet evolution related to the Ising model[7].







Satya Nadella emphasizes the i
mportance of building and deploying AI in a safe, secure, and transparent manner to expand opportunities in India and be
yond[5].




[1. Meta AI @metaai https://twitter.com/metaai/status/1694729071325007993](https://twitter.com/metaai/statu
s/1694729071325007993)

[2. Yann LeCun @ylecun https://twitter.com/ylecun/status/1694741307652964600](https://twitter.co
m/ylecun/status/1694741307652964600)

[3. Yann LeCun @ylecun https://twitter.com/ylecun/status/1694741931375362357](http
s://twitter.com/ylecun/status/1694741931375362357)

[4. Google AI @googleai https://twitter.com/googleai/status/16947474
22734606780](https://twitter.com/googleai/status/1694747422734606780)

[5. Satya Nadella @satyanadella https://twitter.c
om/satyanadella/status/1694747170744987779](https://twitter.com/satyanadella/status/1694747170744987779)

[6. Google AI 
@googleai https://twitter.com/googleai/status/1694795671503786297](https://twitter.com/googleai/status/16947956715037862
97)

[7. Google AI @googleai https://twitter.com/googleai/status/1694836751305744764](https://twitter.com/googleai/statu
s/1694836751305744764)
```
---

     
 
all -  [ [D] NeurIPS 2023 Paper Reviews - Datasets and Benchmarks ](https://www.reddit.com/r/MachineLearning/comments/160m2aw/d_neurips_2023_paper_reviews_datasets_and/) , 2023-09-21-0909
```
I saw a few reddit posts about the [main track](https://www.reddit.com/r/MachineLearning/comments/15fo7td/d_neurips_2023
_paper_reviews/) reviews and wanted to create a discussion post for the datasets and benchmarks. 

As a first time submi
tter, I'm curious if there are any different experiences between the main track and the datasets track.
```
---

     
 
all -  [ Data independent sparsification of models after training ](https://www.reddit.com/r/deeplearning/comments/1608q3h/data_independent_sparsification_of_models_after/) , 2023-09-21-0909
```
I was looking at papers on model pruning or quantization that aims to make inference faster and/or reduce size of the mo
del. [Most](https://proceedings.neurips.cc/paper_files/paper/2022/file/1caf09c9f4e6b0150b06a07e77f2710c-Paper-Conference
.pdf) of [them](http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf) rely on calibration data to identify weights th
at can be pruned. I am skeptical about this approach since the calibration data could be skewed and in the process of pr
uning the model could be overfitting on that small sample of data. Are there data independent approaches to post-trainin
g sparsification?
```
---

     
 
all -  [ [D] NeurIPS Discussion phase has ended. How was the overall experience for you ? ](https://www.reddit.com/r/MachineLearning/comments/15xygyr/d_neurips_discussion_phase_has_ended_how_was_the/) , 2023-09-21-0909
```
I am not sure if 'Discussion' was always part of the Neurips pipeline but I felt like it was a good addition (in princip
le). 

On one hand it alows the authors to present their case with more clarity. On the other hand, it does increase the
 overhead for the reviewers which are now required to work even harder (and for free). 

For me, it was a mixed bag. Mos
t of the reviewers did engage and the discussion was indeed fruitful.  However, some didn't bother to follow up on the r
esponses to their concerns and questions. Unfortunately, also quite expected. 

I would definitely like to see this in t
he next Neurips but maybe with some tweaks and modifications keeping in mind the (unpaid) reviewers.
```
---

     
