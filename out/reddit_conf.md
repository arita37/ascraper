 
all -  [ [Vote] First paper nomination starts! ](https://www.reddit.com/r/CVPaper/comments/1d1q49z/vote_first_paper_nomination_starts/) , 2024-05-28-0910
```
Hello everyone!

For our first computer vision paper read, the paper drop and voting period starts today.

The nominatio
n will be continued **for one week**. This post will be in contest mode which will hide the vote scores and randomize th
e order of the comments.

Please drop a paper of your interest and upvote the paper that you are interested in reading.


**Rules for nomination:**

* Only papers from **top-tier computer vision venues** such as CVPR, ECCV / ICCV, NeurIPS, B
MVC
* **No self-promotion**
* Comment by sharing the **paper name, link, publication venue and year**

Paper reading per
iod will start next week. The comments not complying with these guidelines will be removed.

Happy voting!
```
---

     
 
all -  [ Internship Opportunity ](https://www.reddit.com/r/CollegeAdmissions/comments/1czxefp/internship_opportunity/) , 2024-05-28-0910
```
We are currently seeking interns for our AI lab headed by ML researchers at CMU. Our lab’s research has been published a
t a top ML conference (NeurIPS) and has since been endorsed by leaders from Microsoft, Amazon, and Stanford. Commerciall
y, we are helping large organizations scale petabytes of data to millions of users. Currently, we are looking for intern
s with an interest in business or marketing to help us validate a new product. Please pm me for a link and the applicati
on form.  
```
---

     
 
all -  [ Internship Opportunity ](https://www.reddit.com/r/HighSchoolInternships/comments/1czbi7c/internship_opportunity/) , 2024-05-28-0910
```
We are currently seeking interns for our AI lab headed by ML researchers at CMU. Our lab’s research has been published a
t a top ML conference (NeurIPS) and has since been endorsed by leaders from Microsoft, Amazon, and Stanford. Commerciall
y, we are helping large organizations scale petabytes of data to millions of users. Currently, we are looking for intern
s with an interest in business or marketing to help us validate a new product. 

Website: [https://openlocus.ai/](https:
//openlocus.ai/)

Application: [https://forms.gle/gs2riFyJ9Xme8Ux69](https://forms.gle/gs2riFyJ9Xme8Ux69)
```
---

     
 
all -  [ Modern LLM/LMM mimarisi için okuma listesi ](https://www.reddit.com/r/CodingTR/comments/1cyox1z/modern_llmlmm_mimarisi_için_okuma_listesi/) , 2024-05-28-0910
```
Merhabalar, buradaki bir gönderiye yorum olarak aşağıdaki listeyi paylaşmıştım ama gönderi silinmiş.

Popüler bir konu o
lduğu ve nereden başlayacağını bilmeyen çok kişi olduğunu düşündüğüm için tekrar paylaşıyorum. Eğer eklemek istediğiniz 
makaleler varsa yorum olarak paylaşabilirsiniz.

Transformers Architecture / Attention Mechanisms:

* [Attention Is All 
You Need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
* [CCNet: Criss-Cro
ss Attention for Semantic Segmentation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_CCNet_Criss-Cross_A
ttention_for_Semantic_Segmentation_ICCV_2019_paper.pdf)
* [Universal Transformers](https://arxiv.org/pdf/1807.03819)
* [
Reformer: The Efficient Transformer](https://arxiv.org/pdf/2001.04451)

Latent Embedding:

* [A Latent Space Approach to
 Dynamic Embedding of Co-occurrence Data](https://proceedings.mlr.press/v2/sarkar07a/sarkar07a.pdf)
* [Euclidean Embeddi
ng of Co-occurrence Data](https://proceedings.neurips.cc/paper_files/paper/2004/file/ec1f850d934f440cfa8e4a18d2cf5463-Pa
per.pdf)
* [Factorization Meets the Item Embedding: Regularizing Matrix Factorization with Item Co-occurrence](https://c
seweb.ucsd.edu//classes/fa17/cse291-b/reading/p59-liang.pdf)

Quantization:

* [BitNet: Scaling 1-bit Transformers for L
arge Language Models](https://arxiv.org/pdf/2310.11453)
* [Bit Regularized Optimization of Neural Nets](https://openrevi
ew.net/pdf?id=HJg1NTGZRZ)
* [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/24
02.17764)

Lora:

* [LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2106.09685)
* [Robust Vis
ual Domain Adaptation with Low-Rank Reconstruction](https://www.researchgate.net/profile/D-Lee-4/publication/261317681_R
obust_visual_domain_adaptation_with_low-rank_reconstruction/links/54c78f840cf22d626a369b6e/Robust-visual-domain-adaptati
on-with-low-rank-reconstruction.pdf)

Context Unification/Multimodality:

* [Multimodal Neural Language Models](https://
proceedings.mlr.press/v32/kiros14.pdf)
* [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models](ht
tps://arxiv.org/pdf/1411.2539)
* [PaLM-E: An Embodied Multimodal Language Model](https://arxiv.org/pdf/2303.03378)
* [Mu
ltimodal Transformer for Unaligned Multimodal Language Sequences](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7195022/p
df/nihms-1570579.pdf)
```
---

     
 
all -  [ CS AI PhD chances ](https://www.reddit.com/r/gradadmissions/comments/1cxpfji/cs_ai_phd_chances/) , 2024-05-28-0910
```
Hi all,

I’ve been out of school for a while. I wasn’t able to get a PhD earlier due to life stuff. But I’d like to go b
ack and get my PhD, I’m trying to figure out what programs are realistic to target.

My top choice is CMU, but things ar
e extremely competitive right now.

Undergrad: Top three Ivy
GPA 3.3, magna cum laude in major
Research: 2 years in unde
rgrad won best undergraduate research poster, and got a Sigma Xi award.

Post-undergrad: 
AI research scientist at large
 government company for around 6 years
Research: first author paper at NeurIPS, lots of classified research, three paper
s at smaller conferences (one first author). Have a package with a like 200 stars on GitHub. A couple company awards for
 my research, and best research project of the year award from the government.

Misc: Invited as a guest lecturer a coup
le times.

I’m really disconnected from the general space of academia, but am finally at a place where I feel like I can
 get my PhD, which haven’t been able to.

Would love to hear thoughts and guidance on what programs would be good target
s.

```
---

     
 
all -  [ VERSES AI ($VERS) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/smallcapsociety/comments/1cxi2hx/verses_ai_vers_sets_new_standards_in_ai_with/) , 2024-05-28-0910
```
VERSES AI ($VERS), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a research
 roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by prov
iding clear goals to measure the progress and importance of $VER's research and development endeavors.

The company plan
s to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be as 
good as or better than advanced AI models on various industry tests, all while using less data and energy.

By meeting t
hese benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to get th
eir AI into more hands through their Genius Platform.

Research Roadmap Highlights:

VERSES’ research roadmap has 3 benc
hmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge

The first benc
hmark, Classification and generation tasks, focuses on proving $VER's approach is better at tasks like recognizing image
s and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that their method 
has the ability to outperform traditional deep learning methods. This test is important because it shows whether VERSES 
can make top-quality AI while being more efficient.

The second benchmark, the Atari 10k Challenge, is all about testing
 VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VERSES is tryin
g to play video games almost like a human but with way less practice. $VERS is using active inference to help their AI b
e super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming

Lastly, the
re’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky situations whe
re lots of different AI systems need to work together. $VERS wants to show that their AI can understand these complicate
d situations and work smoothly with other AI systems. Through the use of active inference and explicit representational 
structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and tackle complex pr
oblems together.

$VERS publicly released this roadmap so the public can track their progress. The roadmap can be access
ed here: [www.verses.ai/rd-overview](http://www.verses.ai/rd-overview)

Note: this is not financial advice please do you
r own research before investing.
```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/kanpur/comments/1cwa3qt/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-28-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/rau0q0kyej1d1.png?width=1920&for
mat=png&auto=webp&s=8f49b22c78e16399f92194c3551303474022e65a


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/developers_lucknow/comments/1cwa3gc/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-28-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/g61lajfuej1d1.png?width=1920&for
mat=png&auto=webp&s=80313475aa3a531609364a0d487a61a733f55877


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/LucknowUniversity/comments/1cwa2sh/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-28-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** ([https://www.commudle.com/commun
ities/tfug-lucknow/events/hack-to-crack](https://www.commudle.com/communities/tfug-lucknow/events/hack-to-crack)), we ar
e also organizing the **Gen AI Awadh Summit** ([https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-su
mmit](https://www.commudle.com/communities/tfug-lucknow/events/gen-ai-awadh-summit)). During this summit, we will explor
e cutting-edge topics such as fine-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We
 invite you to join us, share your knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs
 is an independent initiative led by a group of scholars and researchers. Our primary goal is to nurture the AI research
 community in Lucknow. If you would like to contribute, we encourage you to do so through mentoring or providing resourc
es that can benefit students and researchers in the AI domain.

https://preview.redd.it/k95x0bekej1d1.png?width=1920&for
mat=png&auto=webp&s=b64f71dfea4921355b3bb281ccf4cf5b06871190


```
---

     
 
all -  [ Pioneering AI Research in Lucknow: Gen AI Hackathon and Awadh Summit by Lucknow AI Labs
 ](https://www.reddit.com/r/lucknow/comments/1cwa0gu/pioneering_ai_research_in_lucknow_gen_ai/) , 2024-05-28-0910
```
Greetings!

Lucknow AI Labs is organizing a Gen AI Hackathon. The community aims to foster a vibrant research culture in
 Lucknow and empower students to publish their work in prestigious conferences such as ACL, ACM, and NeurIPS, even durin
g their undergraduate studies.

You can read more about the vision behind Lucknow AI Labs. [https://lucknowai.github.io/
](https://lucknowai.github.io/)

We are a group of dedicated researchers with extensive experience in publishing at top-
tier conferences. Our mission is to facilitate and guide aspiring researchers in Lucknow who are seeking collaboration a
nd support to advance their research careers.

In addition to the **Gen AI Hackathon** (https://www.commudle.com/communi
ties/tfug-lucknow/events/hack-to-crack), we are also organizing the **Gen AI Awadh Summit** (https://www.commudle.com/co
mmunities/tfug-lucknow/events/gen-ai-awadh-summit). During this summit, we will explore cutting-edge topics such as fine
-tuning GEMMA, prompt engineering, RAG (Retrieval Augmented Generation), and more.

We invite you to join us, share your
 knowledge, and learn from the experts in the field.

Please note that Lucknow AI Labs is an independent initiative led 
by a group of scholars and researchers. Our primary goal is to nurture the AI research community in Lucknow. If you woul
d like to contribute, we encourage you to do so through mentoring or providing resources that can benefit students and r
esearchers in the AI domain.

As part of our community engagement initiatives, we regularly host AMA (Ask Me Anything) s
essions over the weekends. These sessions provide a fantastic opportunity for anyone to interact with experts, ask quest
ions, and gain insights into various aspects of AI and related fields.

To join our WhatsApp group and Discord server, p
lease visit our website at [https://lucknowai.github.io/](https://lucknowai.github.io/).

We would greatly appreciate it
 if you could help us spread the word by sharing this information in other relevant subreddits and groups. As our accoun
t is newly created, we are currently facing limitations in posting to other communities ourselves.

https://preview.redd
.it/oxz0fmhtdj1d1.png?width=1920&format=png&auto=webp&s=6cc4f32667d5fa9d957f883563e4325dd09aac99
```
---

     
 
all -  [ [D] Why are non technical people leading AI? ](https://www.reddit.com/r/MachineLearning/comments/1cw5dby/d_why_are_non_technical_people_leading_ai/) , 2024-05-28-0910
```
Why do non-technical figures lead the charge in AI? Pichai, Nadella, Fidji (Open AI board member), Altman, Murati, and m
any other VPs of AI in FAANG. Despite never coding, they hold sway in AI. Meanwhile, those coding and publishing groundb
reaking work are often stuck at lower levels. 

What's the deal? Why isn't the industry recognizing those publishing at 
Neurips, EMNLP, CVPR, or the masterminds behind creations like GPT, Gemini, or Claude? They seem to be hidden in the sha
dows. 

What's your take on this?


```
---

     
 
all -  [ [D] Culture of Recycling Old Conference Submissions in ML ](https://www.reddit.com/r/MachineLearning/comments/1cvp0x8/d_culture_of_recycling_old_conference_submissions/) , 2024-05-28-0910
```
I work on statistical ML. I notice that many people (including myself and those that I review) often recycle their submi
ssions for ML conferences.

E.g., if their papers got rejected by ICML, they submit to NeurIPS, and later to ICLR (or UA
I/AISTATS which are also top in my field). If they did not get into ICML/NeurIPS/ICLR after 2\~3 times, they would submi
t them to AAAI/IJCAI/TMLR/ICDM, journals like T-NNLS/T-KDD/NN/Neurocomputing, or domain-specific venues like LoG/CoLLAs/
AABI. After all these, if the paper still did not get accepted, they then simply put them or arXiv. I believe this might
 also be the case for CV/NLP.

As a reviewer, I often encounter conference submissions where the authors resubmit withou
t really taking into account the previous reviews provided. Sometimes they do incorporate the reviews when resubmitting-
-but sometimes the work may just be not at the level of Tier 1 conferences but they just keep resubmitting and hoping th
at they can accepted by chance.

I think that this is consuming a lot of reviewers' time from the community to keep revi
ewing the same submissions (especially given that NeurIPS hits 20k submission id; I expect to see many resubmissions). T
his is perhaps also one of the reason TMLR was born (to emphasize correctness instead of novelty).

I do understand argu
ments like 'the quality of research is more important than the publication venues' or 'OpenAI often simply just put thei
r papers like GPT-X on arXiv these days'. However, students or junior researchers also need publications in their career
, including myself. 

What do folks think about it?
```
---

     
 
all -  [ This Will Be NeurIPS in 2026 ](https://i.redd.it/1ibbavmp391d1.png) , 2024-05-28-0910
```

```
---

     
 
all -  [ NeurIPS Submission Question ](https://www.reddit.com/r/MLQuestions/comments/1cudjmn/neurips_submission_question/) , 2024-05-28-0910
```
I am an undergrad submitting to NeurIPS for the first time. I saw there was only one form, so I filled the abstract and 
saw it was saved. But I didn't submit as it required the full pdf, and I thought it was due later.

Now, my registration
 has disappeared, so I emailed the PCs. Do you think I have any hope of still submitting at this point? (I heard their a
bstract submission is strict)
```
---

     
 
all -  [ [D] Real chances to be accepted in NeurIPS 2024 - Other conferences ](https://www.reddit.com/r/MachineLearning/comments/1ctv9li/d_real_chances_to_be_accepted_in_neurips_2024/) , 2024-05-28-0910
```
Hey!

This is my first time submitting to NeurIPS.

Does anyone know when the reviews are visible to the authors? August
, or is it possible that earlier? If we have really bad reviews... The best thing is to exit the submission path, right?
 In that case, which alternatives do you recommend on those dates?

My topic is NN reliability, but I am always undercon
fident about my research and I always think that it is not enough, more if I think in a conference as Neurips. Do you th
ink that everybody submits good papers or is there a large quantity of rubbish papers? I read a lot of bad opinions here
 about the reviewing process... So, I am a little afraid.

This year, there are 20000ish submissions. So, I don't know w
hat to do, if continue the submission or submit to another conference. As the gap that I am filling is clear, I am sure 
that others are covering that gap and submitting it to NeurIPS. Is there any other conference that outputs the results f
irst than NeurIPS? I am trying to think in a smart way. So hard to be a researcher...

Thank you!
```
---

     
 
all -  [ Why is AI for medical imaging, such as histopathology, such a saturated area? And why is AI for mole ](https://www.reddit.com/r/learnmachinelearning/comments/1csvuiv/why_is_ai_for_medical_imaging_such_as/) , 2024-05-28-0910
```
I work on projects involving AI for biomedical research, and something that shocks me is why there are so many papers/pr
ojects involving AI for medical imaging, especially computational pathology (or radiology)? Is it because of the demand 
in this area (i.e. histopathology for hospitals doing biopsies on patients)?

Why I'm confused is that histopathology, s
uch as whole-slide image analysis, is such a resource-intensive problem - a typical WSI (Whole-Slide Image) takes up to 
\~10GBs to load, and so training a model could take days to even weeks. That is not to mention that you have to convert 
the images to smaller patches and then apply methods like multiple-instance learning to aggregate the image embeddings f
rom each patch to get a final prediction. And then you have to look at which patches are important towards the disease (
via something like attention maps), and then you need a domain expert/expertise to understand whether the model is focus
ing on the right parts of the image towards a prediction. 

And yet there's so many papers published in this field since
 \~2020, probably in the order of thousands, spanning conferences and journals like NeurIPS/ICLR/ICML, CVPR/ECCV/ICCV, M
ICCAI (which is dedicated to medical imaging), Nature, etc. I wonder if this is because a lot of people coming from the 
computer vision area wanted a more difficult problem to tackle (involving non-natural images?)

And then I'm also confus
ed why there's much, much, much less work being done in ML for molecular biology, especially DNA/RNA/epigenomics (exclud
ing protein structure/folding)? It seems for molecular biology almost all the focus seems to be on protein folding/struc
ture with the new AlphaFold 3, but other than that RNA/DNA/epigenomics has been largely ignored? i.e. there has been onl
y a very recent wave of papers for single-cell RNA sequencing foundation models like scGPT/Geneformer/etc in late 2023 t
o early 2024? Is it because there is much more domain knowledge needed to do good analysis in molecular biological modal
ities, and less people have that? Even though molecular biological datasets (esp. RNA sequencing) are often much less co
mputationally intensive than medical imaging, like histopathology?
```
---

     
 
all -  [ [D] Any reason not to submit to NeurIPS? ](https://www.reddit.com/r/MachineLearning/comments/1cs6p6j/d_any_reason_not_to_submit_to_neurips/) , 2024-05-28-0910
```
As we all know, abstracts are due tomorrow. I'm on the fence on being able to finish a strong submission in a week. I kn
ow that I can always withdraw if reviews are bad (or if I don't feel like I have a strong submission in a week when it's
 due), but I'm worried that there might be a trace of the submission left online which future reviewers would be able to
 google. Can anyone confirm that this is only the case if you don't withdraw and instead submit a rebuttal that results 
in a rejection? If you withdraw from openreview, is any trace of it left online? Do you have to do some trick where you 
edit and scrub your submission before withdrawing? I know submission results are stochastic, so I'd like to know when, i
f ever, submitting is a strategic blunder.
```
---

     
 
all -  [ VERSES AI ($VERS) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/Wealthsimple_Penny/comments/1crv28d/verses_ai_vers_sets_new_standards_in_ai_with/) , 2024-05-28-0910
```
VERSES AI ($VERS), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a research
 roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by prov
iding clear goals to measure the progress and importance of $VERS's research and development endeavors. 

The company pl
ans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be a
s good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By meeti
ng these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to ge
t their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap has 
3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The fir
st benchmark, Classification and generation tasks, focuses on proving VERS's approach is better at tasks like recognizin
g images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that their 
method has the ability to outperform traditional deep learning methods. This test is important because it shows whether 
VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all abou
t testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VERSES
 is trying to play video games almost like a human but with way less practice. $VERS is using active inference to help t
heir AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming 

L
astly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky situ
ations where lots of different AI systems need to work together. $VERS wants to show that their AI can understand these 
complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit represe
ntational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and tackle 
complex problems together. 

$VERS publicly released this roadmap so the public can track their progress. The roadmap ca
n be accessed here: www.verses.ai/rd-overview 

Note: this is not financial advice please do your own research before in
vesting.
```
---

     
 
all -  [ AskScience AMA Series: I am a computer scientist at the University of Maryland. My research focus is ](https://www.reddit.com/r/askscience/comments/1crpcaj/askscience_ama_series_i_am_a_computer_scientist/) , 2024-05-28-0910
```
Hi Reddit! I am a computer scientist from the University of Maryland here to answer your questions about artificial inte
lligence.

**Furong Huang** is an Assistant Professor in the Department of Computer Science at the University of Marylan
d. She specializes in trustworthy machine learning, AI for sequential decision-making, and generative AI and focuses on 
applying foundational principles to solve practical challenges in contemporary computing.

Dr. Huang develops efficient,
 robust, scalable, sustainable, ethical and responsible machine learning algorithms that operate effectively in real-wor
ld settings. She has also made significant strides in sequential decision-making, aiming to develop algorithms that not 
only optimize performance but also adhere to ethical and safety standards. She is recognized for her contributions with 
awards including best paper awards, the MIT Technology Review Innovators Under 35 Asia Pacific, the MLconf Industry Impa
ct Research Award, the NSF CRII Award, the Microsoft Accelerate Foundation Models Research award, the Adobe Faculty Rese
arch Award, three JP Morgan Faculty Research Awards and Finalist of AI in Research - AI researcher of the year for Women
 in AI Awards North America.

**Souradip Chakraborty** is a third-year computer science Ph.D. student at the University 
of Maryland advised by Dr. Furong Huang. He works on the foundations of trustworthy reinforcement learning with a focus 
on developing safe, reliable, deployable and provable RL methods for real-world applications. He has co-authored top-tie
r publications and U.S. patents in artificial intelligence and machine learning. Recently he received an Outstanding Pap
er Award (TSRML workshop at Neurips 2022) and Outstanding Reviewer Awards at Neurips 2022, Neurips 2023 and AISTATS 2023
.

**Mucong Ding** is a fifth-year Ph.D. student in computer science at the University of Maryland, advised by Dr. Furon
g Huang. His work broadly encompasses data efficiency, learning efficiency, graph and geometric machine learning and gen
erative modeling. His recent research focuses on designing a more unified and efficient framework for AI alignment and i
mproving their generalizability to solve human-level challenging problems. He has published in top-tier conferences, and
 some of his work has been recognized for oral presentations and spotlight papers.

We'll be on from **2 to 4 p.m. ET (1
8-20 UT)** - ask us anything!

Other links:

+ Website: https://furong-huang.com/
+ Google Scholar page: https://scholar
.google.com/citations?user=13yyuCcAAAAJ&hl=en
+ Q&A on whether AI-generated content is detectable: https://cmns.umd.edu/
news-events/news/ai-generated-content-actually-detectable

Username: /u/umd-science
```
---

     
 
all -  [ [D] Neurips 2024 submissions ](https://www.reddit.com/r/MachineLearning/comments/1crahli/d_neurips_2024_submissions/) , 2024-05-28-0910
```
I just submitted an abstract to Neurips 2024. I was so impressed with my self for being two days early, and yet, my pape
r ID is over 7000. In the past I recall paper IDs were incremented as openreview received more submissions. Surely, this
 year it’s not the case! 7000 submissions already?!
```
---

     
 
all -  [ VERSES AI ($VRSSF) Sets New Standards in AI with Benchmark Tests ](https://www.reddit.com/r/smallstreetbets/comments/1cp6x6p/verses_ai_vrssf_sets_new_standards_in_ai_with/) , 2024-05-28-0910
```
VERSES AI ($VRSSF), a cognitive computing company, is continuing to make big strides in AI. They’ve introduced a researc
h roadmap that outlines the key milestones and benchmarks. This roadmap could revolutionize the development of AI by pro
viding clear goals to measure the progress and importance of $VRSSF's research and development endeavors. 

The company 
plans to use this roadmap this year to monitor its AI progress. Basically, it wants to check whether its approach can be
 as good as or better than advanced AI models on various industry tests, all while using less data and energy.  

By mee
ting these benchmarks, VERSES can prove that they can create AI that is better, cheaper, and faster. The end goal is to 
get their AI into more hands through their Genius Platform. 

Research Roadmap Highlights: 

VERSES’ research roadmap ha
s 3 benchmarks: Classification and generation tasks, Atari 10k Challenge, and NeurIPS 2024 Melting Pot Challenge 

The f
irst benchmark, Classification and generation tasks, focuses on proving VRSSF's approach is better at tasks like recogni
zing images and creating new ones. By utilizing advanced Bayesian inference techniques, they are trying to show that the
ir method has the ability to outperform traditional deep learning methods. This test is important because it shows wheth
er VERSES can make top-quality AI while being more efficient.  

The second benchmark, the Atari 10k Challenge, is all a
bout testing VERSES' AI skills in playing video games. Unlike conventional methods that need a lot of gameplay data, VER
SES is trying to play video games almost like a human but with way less practice. $VRSSF is using active inference to he
lp their AI be super adaptable. And by doing this, they're hoping to raise the bar for how well AI can perform in gaming
 

Lastly, there’s the NeurIPS 2024 Melting Pot Challenge. This is all about testing how well VERSES' can handle tricky 
situations where lots of different AI systems need to work together. $VRSSF wants to show that their AI can understand t
hese complicated situations and work smoothly with other AI systems. Through the use of active inference and explicit re
presentational structures, VERSES aims to become a leader in creating AI systems that can collaborate effectively and ta
ckle complex problems together. 

$VRSSF publicly released this roadmap so the public can track their progress. The road
map can be accessed here: www.verses.ai/rd-overview 

Note: this is not financial advice please do your own research bef
ore investing.
```
---

     
 
all -  [ How to leverage research opportunities in AI/ML as a student in Undergrad? ](https://www.reddit.com/r/UofT/comments/1cl4eks/how_to_leverage_research_opportunities_in_aiml_as/) , 2024-05-28-0910
```
Hi, I'm a first year student in ece and wanted to ask how I can get involved in ai and ml research? I know the first ste
p usually involves securing a grant through NSERC or smthg similar and reaching out to profs, but does anyone know how y
ou can get to the level of expertise that allows you to publish papers while in undergrad and get involved with things l
ike NeurIPS? I know some areas of specialty that a lot of people are working in is deep learning, I'm not too sure about
 any others like computer vision, but I know that a lot of companies like Nvidia seem to have connections to grad studen
ts who eventually connect research to industry, are there ways for undergrads to do things like that as well? Also, I kn
ow there are some cool startups that I've been trying to become involved in, and I've been working on side projects, but
 what would help me further develop my skills? Thanks.
```
---

     
 
all -  [ [HIRING][USD 100K - 180K+] Founding AI Engineer, Agents in New York ](https://www.reddit.com/r/PythonJobs/comments/1cjw1ec/hiringusd_100k_180k_founding_ai_engineer_agents/) , 2024-05-28-0910
```
As a Founding AI Engineer, you'll play a critical role in the development and scaling of our agents infrastructure, goin
g all the way from data ingestion to building state-of-the-art action-taking architectures. If you have a strong bias to
 action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Things you can work on
  
Work with researchers to translate the latest in state-of-the-art automation and reasoning methods to working code.  

Devise and implement ground-truth data collection techniques for fine-tuning generative action models.  
Implement pipe
lines for processing and constructing reference datasets and tools for solving goals.  
Build end-to-end machine learnin
g models that power self-improving agents.  
Implement public and private knowledge graphs for generative models.  
Thin
gs we look for  
Evidence of exceptional ability.  
Experience with generative model architectures, including Retrieval 
Augmented Generation, Graph Learning, AI agents and tree-search augmented LLMs.  
Experience building scalable data appl
ications with Python.  
Full-stack ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS,
 ICML, CCVPR).  
Experience building fast-changing enterprise software in a high-growth environment.  


**Read more / a
pply:** [**https://ai-jobs.net/job/198951-founding-ai-engineer-agents/**](https://ai-jobs.net/job/198951-founding-ai-eng
ineer-agents/)

&#x200B;
```
---

     
 
all -  [ [HIRING][USD 60K - 96K] AI Engineer Intern, Agents in New York (Flexibility to work remotely for exc ](https://www.reddit.com/r/PythonJobs/comments/1cjvzhv/hiringusd_60k_96k_ai_engineer_intern_agents_in/) , 2024-05-28-0910
```
As an AI Engineer Intern, you’ll have the opportunity to build a state of the art experience in building generative mode
l architectures. We’ll support you in owning a challenging end-to-end generative model focused problem. If you have a st
rong bias to action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Example pr
ojects  
Work with researchers to extend our generative model prompting architecture.  
Take part in implementing our gr
ound-truth data collection platform that powers the fine-tuning of generative action models.  
Extend our reference tool
s and datasets and integrate them into our automated reasoning systems.  
Things we look for  
Evidence of exceptional a
bility.  
Real world ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS, ICML, CCVPR).
  
Plus: Experience with generative model architectures, including Retrieval Augmented Generation, Graph Learning, AI ag
ents and tree-search augmented LLMs.

&#x200B;

**Read more / apply:** [**https://ai-jobs.net/job/198461-ai-engineer-int
ern-agents/**](https://ai-jobs.net/job/198461-ai-engineer-intern-agents/)

&#x200B;
```
---

     
 
all -  [ [HIRING][USD 60K - 96K] AI Engineer Intern, Agents in New York (Flexibility to work remotely for exc ](https://www.reddit.com/r/NYCjobs/comments/1cjvze8/hiringusd_60k_96k_ai_engineer_intern_agents_in/) , 2024-05-28-0910
```
As an AI Engineer Intern, you’ll have the opportunity to build a state of the art experience in building generative mode
l architectures. We’ll support you in owning a challenging end-to-end generative model focused problem. If you have a st
rong bias to action, thrive on ambiguity and desire to own problems end-to-end, we’d love to hear from you.  
Example pr
ojects  
Work with researchers to extend our generative model prompting architecture.  
Take part in implementing our gr
ound-truth data collection platform that powers the fine-tuning of generative action models.  
Extend our reference tool
s and datasets and integrate them into our automated reasoning systems.  
Things we look for  
Evidence of exceptional a
bility.  
Real world ML development experience.  
Publications in top deep learning venues (ICLR, NeurIPS, ICML, CCVPR).
  
Plus: Experience with generative model architectures, including Retrieval Augmented Generation, Graph Learning, AI ag
ents and tree-search augmented LLMs.

  
**Read more / apply:** [**https://ai-jobs.net/job/198461-ai-engineer-intern-age
nts/**](https://ai-jobs.net/job/198461-ai-engineer-intern-agents/)

&#x200B;
```
---

     
 
all -  [ [D] Something I always think about, for top conferences like ICML, NeurIPS, CVPR,..etc. How many pap ](https://www.reddit.com/r/MachineLearning/comments/1cin6s8/d_something_i_always_think_about_for_top/) , 2024-05-28-0910
```
I have some papers in top venus myself, but whenever I sit down and be brutually honest with myself. I feel my work is g
ood but it is just not that impactful, like one more brick in the wall.
I wonder how often we can see something as impac
tful as 'Attention is all you need' for example.
```
---

     
 
all -  [ [D] Why do juniors (undergraduates or first- to second-year PhD students) have so many papers at maj ](https://www.reddit.com/r/MachineLearning/comments/1cidsz7/d_why_do_juniors_undergraduates_or_first_to/) , 2024-05-28-0910
```
Hello everyone, today the ICML results are out, congratulations to all those who have papers accepted here. I'm not an a
cademic myself, but sometimes I read papers at these conferences for work, and it's really interesting. I just have a qu
estion: why do juniors have so many papers at these conferences? I thought this was something you would have to learn th
roughout your 5 years of PhD and almost only achieve in the final years of your PhD. Furthermore, I've heard that to get
 into top PhD programs in the US, you need to have some papers beforehand. So, if a junior can publish papers early like
 that, why do they have to spend 5 long years pursuing a PhD?
```
---

     
 
all -  [ Combinatorial Optimization in OR? ](https://www.reddit.com/r/OperationsResearch/comments/1cg8ysh/combinatorial_optimization_in_or/) , 2024-05-28-0910
```
Hi,

I got a Phd in Computer Science. I am interested in combinatorial optimization, so I am thinking of starting a post
doc in RO to work on this topic. 

What makes me doubt is that if I look for combinatorial optimization papers in 2024 i
n Google scholar most of them are published in NeurIPS conference, so my question is OR is the right place?

From my exp
erience during my master's and bachelor's, combinatorial optimization is always taught in the OR courses.
```
---

     
 
all -  [ Does anyone know a method to solve this problem? (besides installing a new version of comfyui) ](https://www.reddit.com/r/comfyui/comments/1cfsu8x/does_anyone_know_a_method_to_solve_this_problem/) , 2024-05-28-0910
```
https://preview.redd.it/zjwgov5pedxc1.png?width=800&format=png&auto=webp&s=f998c3b61ddfd5b5dcbdab63a2645fc7a4cb145b


```
---

     
