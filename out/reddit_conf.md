 
all -  [ My first ever paper got accepted to neurips workshop! ](https://www.reddit.com/r/womenintech/comments/17jmdaa/my_first_ever_paper_got_accepted_to_neurips/) , 2023-10-31-0910
```
I just wanted to share the news! I don’t know what this means but I’m excited to share.
```
---

     
 
all -  [ AI Weekly Rundown (October 21 to October 28) ](https://www.reddit.com/r/ArtificialInteligence/comments/17j1egi/ai_weekly_rundown_october_21_to_october_28/) , 2023-10-31-0910
```
Major AI announcements from Meta, NVIDIA, OpenAI, Google and more.   


* **Meta introduces Habitat 3.0, a leap toward s
ocially intelligent robots**  
\- Meta claims it is the highest-quality simulator that supports robots and humanoid avat
ars and allows for human-robot collaboration in home-like environments. AI agents trained with Habitat 3.0 learn to find
 and collaborate with human partners at everyday tasks like cleaning up a house, thus improving their human partner’s ef
ficiency.  
\- Meta also announced Habitat Synthetic Scenes Dataset and HomeRobot– three major advancements in developin
g socially embodied AI agents that can cooperate with and assist humans in daily tasks.
* **NVIDIA’s research breakthrou
gh, Eureka, puts a new spin on robot learning**  
\- A new AI agent that can teach robots complex skills has trained a r
obotic hand to perform rapid pen-spinning tricks– for the first time, as well as a human can. The robots have learned to
 accomplish nearly 30 tasks expertly thanks to Eureka, which autonomously writes reward algorithms to train bots.
* **Op
enAI reveals DALL-E 3's secret sauce of accurate, prompt generation**  
\- OpenAI has published a paper on DALL-E 3, sho
wing how the system follows prompts more accurately than other systems using better image labels.
* **Qualcomm’s new PC 
chip with AI features the first to challenge Apple**  
\- Its new Snapdragon Elite X chip will be available in laptops s
tarting next year and has been redesigned to better handle AI tasks like summarizing emails, writing text, and generatin
g images.   
\- Qualcomm claims it is faster than Apple's M2 Max chip at some tasks and more energy efficient than Apple
 and Intel PC chips.
* **Microsoft is outdoing its biggest rival, Google, in the AI game**  
\- From the two tech giants
’ September-quarter results, growth at Microsoft’s Azure cloud unit (and the company generally) accelerated due to highe
r-than-expected consumption of AI-related services.   
\- Google Cloud earnings slowed by nearly 6 percentage points in 
the same quarter.
* **Samsung’s Galaxy S24 is your upcoming pocket AI machine**  
\- Going all in with AI on its next fl
agship, Samsung wants to make the Galaxy S24, Galaxy S24+, and Galaxy S24 Ultra the smartest AI phones ever. The series 
will have features lifted straight from ChatGPT and Google Bard, and Samsung has designed independently. Many will be av
ailable online and offline, and some Samsung features will be improved.
* **Berlin-based AI company Jina AI launched Ope
nAI rival jina-embeddings-v2, the world's first open-source 8K text embedding model**  
\- Jina-embeddings-v2 offers ext
ended context potential, allowing for applications such as legal document analysis, medical research, literary analysis,
 financial forecasting, and conversational AI.   
\- Benchmarking shows that it outperforms other leading base embedding
 models. The model is available in two sizes: a base model for heavy-duty tasks and a small model for lightweight applic
ations. 
* **LLM hallucination problem will be over with “Woodpecker”**   
\- Researchers from the University of Science
 and Technology of China and Tencent YouTu Lab have developed a 'Woodpecker' framework to correct hallucinations in mult
imodal large language models (MLLMs).   
\- Woodpecker uses a training-free method to identify and correct hallucination
s in the generated text. The framework goes through 5 stages, including key concept extraction, question formulation, vi
sual knowledge validation, visual claim generation, and hallucination correction. 
* **NVIDIA Research has announced a r
ange of AI advancements**  
\- That will be presented at the NeurIPS conference. The projects include new techniques for
 transforming text-to-images, photos-to-3D avatars, and specialized robots into multi-talented machines. The research fo
cuses on gen AI models, reinforcement learning, robotics, and applications in the natural sciences.   
\- Highlights inc
lude improving text-to-image diffusion models, AI avatar advancements, reinforcement learning and robotics breakthroughs
, AI-accelerated physics, climate, and healthcare research. 
* **OpenAI is forming a “Preparedness” team to support safe
ty of highly capable AI**  
\- The team will tightly connect capability assessment, evaluations, and internal red teamin
g for frontier models, from the models we develop in the near future to those with AGI-level capabilities.   
\- The tea
m will help track, evaluate, forecast, and protect against catastrophic risks spanning multiple categories, including nu
clear threats.
* **Google expands its bug bounty program for attacks specific to GenAI**  
\- It is also expanding its o
pen-source security work and building upon our prior collaboration with the Open Source Security Foundation. In addition
, Google is to support a new effort by the non-profit MLCommons Association to develop standard AI safety benchmarks.
* 
**Boston Dynamics turns its robot dog into a talking tour guide using ChatGPT**  
\- Spot could run, jump, and even danc
e, but now it can talk. With ChatGPT, it can answer questions and generate responses about the company’s facilities whil
e giving a tour.  

* And there was more… 
   * **IBM is developing a brain-inspired chip for faster, more energy-effici
ent AI**  
\- New research out of IBM Research’s lab, nearly two decades in the making, has the potential to drastically
 shift how we can efficiently scale up powerful AI hardware systems. The new type of digital AI chip for neural inferenc
e is called NorthPole.
   * **Oracle loops in NVIDIA AI for end-to-end model development**  
\- Oracle is bringing the N
VIDIA AI stack to its marketplace to simplify AI development and deployment for its customers. It gives Oracle customers
 access to the most sought-after, top-of-the-line GPUs for training foundation models and building generative applicatio
ns.
   * **YouTube develops an AI tool to help creators sound like famous musicians**  
\- In beta, the tool will let a 
select pool of artists give permission to a select group of creators to use their voices in videos on the platform. Nego
tiations with major labels are ongoing and slowing down the project's beta release.
   * **There’s now an AI cancer surv
ivor calculator**  
\- Researchers have created an AI-based tool to predict a cancer patient's odds of long-term surviva
l after a fresh diagnosis. It was found to predict cancer survival length for three types of cancers accurately.
   * **
Instagram’s latest AI feature test is a way to make stickers from photos**  
\- Meta’s newest sticker feature is much li
ke the one built into the iPhone Messages app in iOS 17– Instagram detects and cuts out an object from a photo so you ca
n place it over another.
   * **Google Photos will soon give you more say in its AI-created video highlights**  
\- With
 the latest Google Photos update, you can prompt AI-generated videos by searching for specific tags like places, people,
 or activities. Once generated, you can trim clips, rearrange them, or swap out music for something better.
   * **Lenov
o and NVIDIA announce hybrid AI solutions to help enterprises quickly adopt GenAI**  
\- The new end-to-end solutions in
clude accelerated systems, AI software, and expert services to build and deploy domain-specific AI models easily.
   * *
*Amazon's AI-powered van inspections give it a powerful new data feed**  
\- Amazon delivery drivers at sites worldwide 
will be asked to drive through camera-studded archways at the end of shifts. The data gathered will be used by algorithm
s to identify whether the vehicle is damaged or needs maintenance, picking up every scratch, dent, nail in a tire, or cr
ack in the windshield.
   * **IBM acquires Manta Software Inc. to complement data and AI governance capabilities**  
\- 
Manta’s data lineage capabilities help increase transparency within Watsonx so businesses can determine whether the righ
t data was used for their AI models and systems, where it originated, how it has evolved, and any discrepancies in data 
flows.
   * **This new data poisoning tool lets artists fight back against GenAI**  
\- The tool, called Nightshade, let
s artists add invisible changes to the pixels in their art before they upload it online so that if it’s scraped into an 
AI training set, it can cause the resulting model to break in chaotic and unpredictable ways.   
\- This “poisoning” of 
training data could damage future iterations of image-generating AI models, such as DALL-E, Midjourney, and Stable Diffu
sion.
   * **Google announces new AI tools to help users fact-check images and more**  
\- Also prevent the spread of fa
lse information. The tools include viewing an image's history, metadata, and the context in which it was used on differe
nt sites. Users can also see when the image was first seen by Google Search to understand its recency.   
\- Additionall
y, the tools allow users to understand how people described the image on other sites to debunk false claims. Google mark
s all images created by its AI, and the new image tools are accessible through the three-dot menu on Google Images resul
ts.
   * **Grammarly announces a new feature, 'Personalized voice detection & application'**   
\- That uses generative 
AI to detect a person's unique writing style and create a 'voice profile' that can rewrite any text in that style.   
\-
 The feature will be available to Grammarly's business tier subscribers by the end of the year. It aims to recognize and
 reimburse writers for AI-generated works that mimic their voices.   
\- Users can customize their profiles to discard e
lements that don't accurately reflect their writing style. 
   * **AI features boost Motorola's new foldable phone**   

\- They've developed an AI model that runs locally on the device, allowing users to 'bring their personal style to their
 phone.' Users can upload or take photos to get an AI-generated theme to match their style.  
\- Embedded AI features in
 many areas, like camera, battery, display, and performance. It will serve as a personal assistant and a tool to enhance
 everyday tasks, improve performance, and create meaningful user experiences.
   * **Forbes now has its own GenAI search
 engine**  
\- The tool, Adelaide, is purpose-built for news search and offers AI-driven personalized recommendations an
d insights from Forbes’ trusted journalism. It is in beta and is powered by Google Cloud.
   * **Cisco rolls out new AI 
tools at the Webex One customer conference**  
\- These tools include a real-time media model (RMM) that uses generative
 AI for audio and video, an AI-powered audio codec up to 16 times more efficient in bandwidth usage, and the Webex AI As
sistant, which pulls together all the AI tooling for users.   
\- The AI Assistant can detect when a user steps away fro
m a meeting and provide summaries or replays of missed content.
   * **Amazon reveals AI image generation to help advert
isers create more engaging ads**  
\- The use of data science, analytics, and AI has greatly improved the efficiency of 
digital advertising, but many advertisers still struggle with building successful campaigns.   
\- By providing tools th
at reduce friction and effort for advertisers, Amazon aims to deliver a better advertising experience for customers.
   
* **Google Maps is becoming more like Search, thanks to AI**  
\- Google wants Maps to be more like Search, where people
 can get directions or find places but also enter queries like “things to do in Tokyo” and get actually useful hits and 
discover new experiences, guided by its all-powerful algorithm.
   * **Shutterstock will now let you edit its library of
 images using AI**  
\- It revealed a set of new AI-powered tools, like Magic Brush, which lets you tweak an image by br
ushing over an area and describing what you want to add/replace/erase. Others include a smart resizing feature and a bac
kground removal tool.
   * **UK to set up world's first AI safety institute, Sunak says**  
\- The institute will carefu
lly examine, evaluate, and test new types of AI so that we understand what each new model is capable of, exploring all t
he risks from social harms like bias and misinformation through to the most extreme risks of all.
   * **Intel will sell
 specialized AI software and services**  
\- Intel is working with multiple consulting firms to build ChatGPT-like apps 
for customers who don’t have the expertise to do it on their own.

More detailed breakdown of these news and innovations
 is in the [weekly edition](https://theaiedge.substack.com/p/ai-weekly-rundown-october-21-to-october27).
```
---

     
 
all -  [ NVIDIA Research Announces AI Advancements at NeurIPS https://blogs.nvidia.com/wp-content/uploads/202 ](https://gamingnews01.com/nvidia-research-announces-ai-advancements-at-neurips/?feed_id=38993&_unique_id=653de4e13baf5) , 2023-10-31-0910
```

```
---

     
 
all -  [ AI Revolution October 2023: Week 4 Updates - “Woodpecker” Solving LLM Hallucination & Latest from Ji ](https://www.reddit.com/r/u_enoumen/comments/17i5evp/ai_revolution_october_2023_week_4_updates/) , 2023-10-31-0910
```
Dive into the latest AI advancements and breakthroughs in this week's AI Revolution podcast! We dissect the game-changin
g 'Woodpecker' technology set to tackle the Large Language Models (LLM) hallucination problem, bringing more accuracy an
d reliability to AI-generated content. Plus, get insider updates from leading tech giants and emerging players in the AI
 field. October 2023, Week 4: Here’s what we’re covering:- “Woodpecker”: The promising solution to LLM hallucination iss
ues- Jina AI: How OpenAI’s newest rival is shaping the AI landscape- Meta’s AI ventures: What’s next from the social med
ia giant?- NVIDIA: Latest innovations and collaborations- Google, Qualcomm, Grammarly, Motorola, Cisco, and Amazon: AI u
pdates and developments- And more!

**Video**: [https://youtu.be/Q6rTpvzUpng](https://youtu.be/Q6rTpvzUpng)

**Forbes la
unches its own generative AI search platform built with Google Cloud.**

The tool, Adelaide, is purpose-built for news s
earch and offers AI-driven personalized recommendations and insights from Forbes’ trusted journalism. It is in beta and 
select visitors can access it through the website. *(*[*Link*](https://www.forbes.com/sites/forbes-spotlights/2023/10/26
/forbes-launches-new-generative-ai-search-tool-adelaide-powered-by-google-cloud/)*)*

**Google Maps is becoming more lik
e Search– thanks to AI.**

Google wants Maps to be more like Search, where people can get directions or find places but 
also enter queries like “things to do in Tokyo” and get actually useful hits and discover new experiences, guided by its
 all-powerful algorithm. *(*[*Link*](https://www.theverge.com/2023/10/26/23932315/google-maps-ai-immersive-view-ev-charg
ing-search)*)*

**Shutterstock will now let you edit its library of images using AI.**

It revealed a set of new AI-powe
red tools, like Magic Brush, which lets you tweak an image by brushing over an area and describing what you want to add/
replace/erase. Others include smart resizing feature and background removal tool. *(*[*Link*](https://www.theverge.com/2
023/10/26/23933120/shutterstock-transform-real-photos-ai)*)*

**UK to set up world's first AI safety institute, says PM 
Rishi Sunak.**

The institute will carefully examine, evaluate and test new types of AI so that we understand what each 
new model is capable of, exploring all the risks from social harms like bias and misinformation through to the most extr
eme risks of all. *(*[*Link*](https://www.reuters.com/world/uk/uk-set-up-worlds-first-ai-safety-institute-sunak-says-202
3-10-26)*)*

**Intel is trying something different– selling specialized AI software and services.**

Intel is working wi
th multiple consulting firms to build ChatGPT-like apps for customers that don’t have the expertise to do it on their ow
n. *(*[*Link*](https://www.theinformation.com/articles/ai-laggard-intel-expands-effort-to-help-companies-build-chatgpt-l
ike-apps)*)*

**Google expands its bug bounty program for attacks specific to GenAI**\- It is also expanding its open so
urce security work and building upon our prior collaboration with the Open Source Security Foundation. In addition, Goog
le is to to support a new effort by the non-profit MLCommons Association to develop standard AI safety benchmarks.

**Bo
ston Dynamics turns its robot dog into a talking tour guide using ChatGPT**\- Spot could run, jump, and even dance, but 
now it can talk. With ChatGPT, it can answer questions and generate responses about the company’s facilities while givin
g a tour.

**UK to set up world's first AI safety institute, Sunak says**\- The institute will carefully examine, evalua
te and test new types of AI so that we understand what each new model is capable of, exploring all the risks from social
 harms like bias and misinformation through to the most extreme risks of all.

**Intel will sell specialized AI software
 and services**\- Intel is working with multiple consulting firms to build ChatGPT-like apps for customers that don’t ha
ve the expertise to do it on their own.

**Berlin-based AI company Jina AI launched OpenAI rival jina-embeddings-v2, the
 world's first open-source 8K text embedding model.**\- This model supports an impressive 8K context length, putting it 
on par with OpenAI's proprietary model. Jina-embeddings-v2 offers extended context potential, allowing for applications 
such as legal document analysis, medical research, literary analysis, financial forecasting, and conversational AI.- Ben
chmarking shows that it outperforms other leading base embedding models. The model is available in two sizes, a base mod
el for heavy-duty tasks and a small model for lightweight applications.

**LLM hallucination problem will be over with “
Woodpecker”**\- Researchers from the University of Science and Technology of China and Tencent YouTu Lab have developed 
a framework called 'Woodpecker' to correct hallucinations in multimodal large language models (MLLMs).- Woodpecker uses 
a training-free method to identify and correct hallucinations in generated text. The framework goes through 5 stages, in
cluding key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucin
ation correction.- The researchers have released the source code and an interactive demo of Woodpecker for further explo
ration and application.

**NVIDIA Research has announced a range of AI advancements**\- That will be presented at the Ne
urIPS conference. The projects include new techniques for transforming text to images, photos to 3D avatars, and special
ized robots into multi-talented machines. The research focuses on gen AI models, reinforcement learning, robotics, and a
pplications in the natural sciences.- Highlights include improving text-to-image diffusion models, advancements in AI av
atars, breakthroughs in reinforcement learning and robotics, and AI-accelerated physics, climate, and healthcare researc
h.

**Google announces new AI tools to help users fact-check images and more**\- Also prevent the spread of false inform
ation. The tools include viewing an image's history, metadata, and the context in which it was used on different sites. 
Users can also see when the image was first seen by Google Search to understand its recency.- Additionally, the tools al
low users to understand how people described the image on other sites to debunk false claims. Google marks all images cr
eated by its AI, and the new image tools are accessible through the three-dot menu on Google Images results.

**Grammarl
y’s announces new feature 'Personalized voice detection & application'**\- That uses generative AI to detect a person's 
unique writing style and create a 'voice profile' that can rewrite any text in that style.- The feature, which will be a
vailable to subscribers of Grammarly's business tier by the end of the year, aims to recognize and remunerate writers fo
r AI-generated works that mimic their voices.- Users can customize their profiles to discard elements that don't accurat
ely reflect their writing style.

**Motorola's new foldable phone is boosted by AI features**\- They've developed an AI 
model that runs locally on the device, allowing users to 'bring their personal style to their phone.' Users can upload o
r take a photo to get an AI-generated theme to match their style.- They’ve embedded AI features in many areas of our dev
ices, like camera, battery, display and device performance. It will serve as a personal assistant and a tool to enhance 
everyday tasks, improve performance, and create more meaningful experiences for the users.

**Cisco rolls out new AI too
ls at the Webex One customer conference**\- These tools include a real-time media model (RMM) that uses generative AI fo
r audio and video, an AI-powered audio codec that is up to 16 times more efficient in bandwidth usage, and the Webex AI 
Assistant, which pulls together all the AI tooling for users.- The AI Assistant can detect when a user steps away from a
 meeting and provide summaries or replays of missed content.

**Amazon reveals AI image generation to help advertisers c
reate more engaging ads**\- The use of data science, analytics, and AI has greatly improved the efficiency of digital ad
vertising, but many advertisers still struggle with building successful campaigns.- By providing tools that reduce frict
ion and effort for advertisers, Amazon aims to deliver a better advertising experience for customers.

**Qualcomm’s new 
PC chip with AI features the first to challenge Apple**\- Its new Snapdragon Elite X chip will be available in laptops s
tarting next year and has been redesigned to better handle AI tasks like summarizing emails, writing text, and generatin
g images. Qualcomm claims it is faster than Apple's M2 Max chip at some tasks and more energy efficient than both Apple 
and Intel PC chips.

**Microsoft is outdoing its biggest rival, Google, in the AI game**\- From the two tech giants’ Sep
tember-quarter results, growth at Microsoft’s Azure cloud unit (and the company generally) accelerated in the quarter du
e to higher-than-expected consumption of AI-related services. In the same quarter, Google Cloud earnings slowed by nearl
y 6 percentage points.

**Samsung’s Galaxy S24 is your upcoming pocket AI machine**\- Going all in with AI on its next f
lagship, Samsung wants to make the Galaxy S24, Galaxy S24+, and Galaxy S24 Ultra the smartest AI phones ever. The series
 will have features lifted straight from ChatGPT and Google Bard, and Samsung has designed on its own. Many of them will
 be available online and offline, and some Samsung features will be improved.

**Google Photos will soon give you more s
ay in its AI-created video highlights**\- With the latest Google Photos update, you can prompt AI-generated videos by se
arching for specific tags like places, people, or activities. Once generated, you can trim clips, rearrange them, or swa
p out music for something better.

**Lenovo and NVIDIA announce hybrid AI solutions to help enterprises quickly adopt Ge
nAI**\- The new end-to-end solutions include accelerated systems, AI software, and expert services to build and deploy d
omain-specific AI models with ease.

**Amazon's AI-powered van inspections give it a powerful new data feed**\- Amazon d
elivery drivers at sites around the world will be asked to drive through camera-studded archways at the end of shifts. T
he data gathered will be used by algorithms to identify whether the vehicle is damaged or needs maintenance, picking up 
every scratch, dent, nail in a tire, or crack in the windshield.

**IBM acquires Manta Software Inc. to complement data 
and AI governance capabilities**\- Manta’s data lineage capabilities help increase transparency within watsonx so busine
sses can determine whether the right data was used for their AI models and systems, where it originated, how it has evol
ved and any discrepancies in data flows.

**This new data poisoning tool lets artists fight back against GenAI**\- The t
ool, called Nightshade, lets artists add invisible changes to the pixels in their art before they upload it online so th
at if it’s scraped into an AI training set, it can cause the resulting model to break in chaotic and unpredictable ways.
 This “poisoning” of training data could damage future iterations of image-generating AI models, such as DALL-E, Midjour
ney, and Stable Diffusion.

**Video**: [https://youtu.be/Q6rTpvzUpng](https://youtu.be/Q6rTpvzUpng)

Full transcript: [h
ttps://enoumen.com/2023/10/02/ai-revolution-in-october-2023-the-latest-innovations-reshaping-the-tech-landscape/](https:
//enoumen.com/2023/10/02/ai-revolution-in-october-2023-the-latest-innovations-reshaping-the-tech-landscape/)

Are you ea
ger to expand your understanding of artificial intelligence? Look no further than the essential book '[**AI Unraveled: D
emystifying Frequently Asked Questions on Artificial Intelligence,**](https://amzn.to/3BwRqkF)' available at [**Apple**]
(http://books.apple.com/us/book/id6445730691), [**Google**](https://play.google.com/store/books/details?id=oySuEAAAQBAJ)
, or [**Amazon**](https://amzn.to/3ZrpkCu) today: [https://amzn.to/3ZrpkCu](https://amzn.to/3ZrpkCu)
```
---

     
 
all -  [ Two-minute Daily AI Update (Date: 10/26/2023): News from Jina AI (OpenAI’s new rival), NVIDIA, Woodp ](https://www.reddit.com/r/ArtificialInteligence/comments/17gwd5t/twominute_daily_ai_update_date_10262023_news_from/) , 2023-10-31-0910
```
Continuing with the exercise of sharing an easily digestible and smaller version of the main updates of the day in the w
orld of AI.  


* **Berlin-based AI company Jina AI launched OpenAI rival jina-embeddings-v2, the world's first open-sou
rce 8K text embedding model.**  
\- This model supports an impressive 8K context length, putting it on par with OpenAI's
 proprietary model. Jina-embeddings-v2 offers extended context potential, allowing for applications such as legal docume
nt analysis, medical research, literary analysis, financial forecasting, and conversational AI.   
\- Benchmarking shows
 that it outperforms other leading base embedding models. The model is available in two sizes, a base model for heavy-du
ty tasks and a small model for lightweight applications. 
* **LLM hallucination problem will be over with “Woodpecker”**
   
\- Researchers from the University of Science and Technology of China and Tencent YouTu Lab have developed a framewo
rk called 'Woodpecker' to correct hallucinations in multimodal large language models (MLLMs).   
\- Woodpecker uses a tr
aining-free method to identify and correct hallucinations in generated text. The framework goes through 5 stages, includ
ing key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucinatio
n correction.   
\- The researchers have released the source code and an interactive demo of Woodpecker for further expl
oration and application. 
* **NVIDIA Research has announced a range of AI advancements**  
\- That will be presented at 
the NeurIPS conference. The projects include new techniques for transforming text to images, photos to 3D avatars, and s
pecialized robots into multi-talented machines. The research focuses on gen AI models, reinforcement learning, robotics,
 and applications in the natural sciences.   
\- Highlights include improving text-to-image diffusion models, advancemen
ts in AI avatars, breakthroughs in reinforcement learning and robotics, and AI-accelerated physics, climate, and healthc
are research. 
* **Google announces new AI tools to help users fact-check images and more**  
\- Also prevent the spread
 of false information. The tools include viewing an image's history, metadata, and the context in which it was used on d
ifferent sites. Users can also see when the image was first seen by Google Search to understand its recency.   
\- Addit
ionally, the tools allow users to understand how people described the image on other sites to debunk false claims. Googl
e marks all images created by its AI, and the new image tools are accessible through the three-dot menu on Google Images
 results.
* **Grammarly’s announces new feature 'Personalized voice detection & application'**   
\- That uses generativ
e AI to detect a person's unique writing style and create a 'voice profile' that can rewrite any text in that style.   

\- The feature, which will be available to subscribers of Grammarly's business tier by the end of the year, aims to reco
gnize and remunerate writers for AI-generated works that mimic their voices.   
\- Users can customize their profiles to
 discard elements that don't accurately reflect their writing style. 
* **Motorola's new foldable phone is boosted by AI
 features**   
\- They've developed an AI model that runs locally on the device, allowing users to 'bring their personal
 style to their phone.' Users can upload or take a photo to get an AI-generated theme to match their style.  
\- They’ve
 embedded AI features in many areas of our devices, like camera, battery, display and device performance. It will serve 
as a personal assistant and a tool to enhance everyday tasks, improve performance, and create more meaningful experience
s for the users.
* **Cisco rolls out new AI tools at the Webex One customer conference**  
\- These tools include a real
-time media model (RMM) that uses generative AI for audio and video, an AI-powered audio codec that is up to 16 times mo
re efficient in bandwidth usage, and the Webex AI Assistant, which pulls together all the AI tooling for users.   
\- Th
e AI Assistant can detect when a user steps away from a meeting and provide summaries or replays of missed content.
* **
Amazon reveals AI image generation to help advertisers create more engaging ads**  
\- The use of data science, analytic
s, and AI has greatly improved the efficiency of digital advertising, but many advertisers still struggle with building 
successful campaigns.   
\- By providing tools that reduce friction and effort for advertisers, Amazon aims to deliver a
 better advertising experience for customers.

More detailed breakdown of these news and innovations in the [daily newsl
etter](https://theaiedge.substack.com/p/openai-new-rival-jina-ai-woodpecker-nvidia).
```
---

     
 
all -  [ At what programs am I competitive? - PhD in CS (AI/ML) ](https://www.reddit.com/r/gradadmissions/comments/17gskbg/at_what_programs_am_i_competitive_phd_in_cs_aiml/) , 2023-10-31-0910
```
 I plan to apply to 10-12 CS PhD programs, with a research focus in ML/NLP. 

While I understand that many successful ap
plicants in top programs have published NeurIPS/CVPR/ACL/EMNLP papers and are from prestigious labs/schools, what rankin
gs of programs should I expect to be a competitive applicant for? #10-20? #20-40? #40-60? etc.

&#x200B;

\- 4.0 GPA fro
m a small private school in California, graduated #1 in class

\- 2 years as an RA in an on-campus NLP lab, while also d
oing independent research

\- 3 first author research papers (1 in submission at an A-tier conference, 2 on arXiv)

\- 1
 second author paper (in submission at an A-tier conference)

\- 3 LoRs from profs who know me well. I am confident that
 they will be quite strong, discussing my research and leadership abilities. But the profs are relatively unknown in aca
demia

\- Strong (I think) SoP, taking inspiration from many previously successful applicants. My research experiences a
nd interests are very well-defined and catered to specific schools/profs

\- Currently an SWE at a well-known company (n
ot FAANG). I also do NLP consulting

\- 3 SWE internships

\- 330 GRE (169Q, 161V, 5.0AW)

\- A couple of solid ML proje
cts in school

&#x200B;

What kind of schools should I target? Where would be a reach? Any safeties?

(Specific schools 
listed below are arbitrary examples)

\#10-20: UCLA/USC/UNC/Duke

\#20-40: NYU/UCI/Rice/Ohio St

\#40-60: NCSU/Vanderbil
t/UT Dallas/UCF
```
---

     
 
all -  [ [D] Are people in ML Phds still happy? ](https://www.reddit.com/r/MachineLearning/comments/17fahm6/d_are_people_in_ml_phds_still_happy/) , 2023-10-31-0910
```
As an outsider who has many friends in ML Phds, this is my perspective of their lives:

1. long hours, working nights, w
eekends
2. no work-life balance, constant fear of being scooped and time pressure from deadlines
3. frustrating broken r
eview systems
4. many incremental, advertisement papers that produce very little actual contribution (which is justified
 by 2.)
5. 'engineering' and not 'science'
6. all this pressure amounts to severe imposter syndrome

Are people in the f
ield still happy? Where do people get their satisfaction? To me it looks like almost like a religion or a cult. The sele
ct few who say, get neurips outstanding paper are promoted to stardom - almost a celebrity status while everyone else su
ffers a punishing work cycle. Are the phd students all banking on AGI? What else motivates them?

Edit: the discussion i
s about whether 1-6 are worse in ML than other fields (or even the median experience). The reference for 'other field' i
s highly heterogenous. Experience obviously varies by lab, and then even by individuals within labs. 'It happens in othe
r fields too' is a trivial statement - of course some version of 1-6 affects somebody in another field.

Edit 2: small n
 but summarizing the comments - experience seems to differ based on geographic region, one's expectations for the phd, a
bility to exert work-life balance, and to some extent ignore the trends others are all following. Some people have reson
ated with problems 1-6, yet others have presented their own, anecdotal solutions. I recommend reading comments from thos
e who claim to have solutions.
```
---

     
 
all -  [ [R] Biologically plausible vision models for classification and grasping tasks ](https://www.reddit.com/r/MachineLearning/comments/17ea25h/r_biologically_plausible_vision_models_for/) , 2023-10-31-0910
```
Hey everyone! I am looking for papers that propose or explore biologically plausible vision models, primarily tasks like
 classification and grasping (predicting grasping bounding boxes) tasks. By biologically plausible, I mean papers that p
ropose models inspired by the human brain in some way or the other. I know convolution is loosely inspired by human cogn
ition, but everything I can find seems to suggest the opposite for ViT like models.

I have come across certain papers l
ike these:
- https://arxiv.org/abs/1901.00945
- https://proceedings.neurips.cc/paper/2020/hash/98b17f068d5d9b7668e19fb8a
e470841-Abstract.html

But I am still looking for more. Any suggestions?
```
---

     
 
all -  [ Inpaintint Not working ](https://www.reddit.com/gallery/17d832h) , 2023-10-31-0910
```
So I'm a begginer, I've been using SD for sometime. My inpaint Stopped working 1 or 2 months ago(i think).I usually upda
te to the latest version everytime.

I'm using A1111 direct ml (by Ishqqytiger) on Rx 590 8gb, chrome as browser, window
s 10 as os.

The generated image is either the same or has a blur on inapinted area. increasing mask blur also doesn't d
o anything it just makes the exact same face but with a weird sort of light blur on it.

I have tried changing every pos
sible setting to fix it such as clip skip, model, original mask mode, latent noise mask mode and the other 2 mask mode a
s well, changing cfg scale, denoising strength, sampler steps, samplers, inpaint area, resolution.

my command args is i
n the screen shot.

is this caused my some new update or some extension bug (I was not using any extension while generat
ing the images), or is it something just bad with my machine or is there a problem with SD directml version.
```
---

     
 
all -  [ [R] How to compare research results? ](https://www.reddit.com/r/computervision/comments/17cczj7/r_how_to_compare_research_results/) , 2023-10-31-0910
```
Hello all,

I am conducting research in the field of ViT. Research focuses on developing a method to improve ViT on a sm
all dataset from scratch and using ImageNet weights. In literature, I found similar work is already been proposed in the
 paper 'Efficient Training of Visual Transformers with Small Datasets' [https://proceedings.neurips.cc/paper/2021/file/c
81e155d85dae5430a8cee6f2242e82c-Paper.pdf](https://proceedings.neurips.cc/paper/2021/file/c81e155d85dae5430a8cee6f2242e8
2c-Paper.pdf).

My question is with whom to compare my method? should I compare with **this paper** or should I compare 
my results with the **original** ViT-S/32, ViT-B/32, ViT-T/32, ViT-T/16, SWIN-T, CVT, T2T.

Further, should I use the sa
me dataset or can I replace some with other datasets?
```
---

     
 
all -  [ [R] How to compare research results? ](https://www.reddit.com/r/MachineLearning/comments/17ccypi/r_how_to_compare_research_results/) , 2023-10-31-0910
```
Hello all,

I am conducting research in the field of ViT. Research focuses on developing a method to improve ViT on a sm
all dataset from scratch and using ImageNet weights. In literature, I found similar work is already been proposed in the
 paper 'Efficient Training of Visual Transformers with Small Datasets' [https://proceedings.neurips.cc/paper/2021/file/c
81e155d85dae5430a8cee6f2242e82c-Paper.pdf](https://proceedings.neurips.cc/paper/2021/file/c81e155d85dae5430a8cee6f2242e8
2c-Paper.pdf). 

My question is with whom to compare my method? should I compare with **this paper** or should I compare
 my results with the **original** ViT-S/32, ViT-B/32, ViT-T/32, ViT-T/16, SWIN-T, CVT, T2T.

Further, should I use the s
ame dataset or can I replace some with other datasets?
```
---

     
 
all -  [ MSCS Profile Evaluation - Fall 2024 ](https://www.reddit.com/r/gradadmissions/comments/17c2w15/mscs_profile_evaluation_fall_2024/) , 2023-10-31-0910
```
B.E. (ongoing) from a Tier 2 Institution in India  
CGPA: 9.46  
Research Papers: 4 (One accepted at NeurIPS workshop)  

Internships: 2 (one research-based at a US startup)  
LoRs: 2 from professors whom I have worked with (published resear
ch papers) and one from the startup (the founder is an MIT Postdoc)

This is where I am afraid:  
TOEFL: 100 (R:27, L:26
, S:23, W:24)  
This was my 2nd attempt to improve my speaking score but still couldn't do it.

Shortlisted Universities
:  


1. **Ambitious**  
MIT  
Stanford  
Princeton  
UCB  
UIUC  
UCSD  
UCLA  
UT Austin  
UMCP
2.  **Moderate**  
UMa
ss Amherst  
Purdue  
NEU  
ASU
```
---

     
 
all -  [ [R] Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data (NeurIPS ](https://www.reddit.com/r/MachineLearning/comments/17bzbaq/r_neural_relation_graph_a_unified_framework_for/) , 2023-10-31-0910
```
**paper**: [https://arxiv.org/abs/2301.12321](https://arxiv.org/abs/2301.12321)

**code**: [https://github.com/snu-mllab
/Neural-Relation-Graph](https://github.com/snu-mllab/Neural-Relation-Graph)

**TDLR**: We present a scalable and domain-
agnostic approach utilizing the relational structure of data for identifying label noise and outliers

https://preview.r
edd.it/o9k7kliqe9vb1.png?width=3108&format=png&auto=webp&s=b7c34bd7f4bc130915440986570104f9bebd4f07

>Diagnosing and cle
aning data is a crucial step for building robust machine learning systems. However, identifying problems within large-sc
ale datasets with real-world distributions is challenging due to the presence of complex issues such as label errors, un
der-representation, and outliers. In this paper, we propose a unified approach for identifying the problematic data by u
tilizing a largely ignored source of information: a relational structure of data in the feature-embedded space. To this 
end, we present scalable and effective algorithms for detecting label errors and outlier data based on the relational gr
aph structure of data. We further introduce a visualization tool that provides contextual information of a data point in
 the feature-embedded space, serving as an effective tool for interactively diagnosing data. We evaluate the label error
 and outlier/out-of-distribution (OOD) detection performances of our approach on the large-scale image, speech, and lang
uage domain tasks, including ImageNet, ESC-50, and SST2. Our approach achieves state-of-the-art detection performance on
 all tasks considered and demonstrates its effectiveness in debugging large-scale real-world datasets across various dom
ains.

&#x200B;

[Detected samples with label error \(red colored\) from ImageNet \(top\) and SST2 \(bottom\).](https://
preview.redd.it/4x2244ure9vb1.png?width=2778&format=png&auto=webp&s=6c6cb9f8d1befce392d31546eab569ffa70d74cc)

&#x200B;


[Detected outlier samples from ImageNet \(top\) and SST2 \(bottom\) validation sets.](https://preview.redd.it/2kkfdspxe
9vb1.png?width=2720&format=png&auto=webp&s=312249638229b4cb5e815b76c1ef8309a829581b)
```
---

     
 
all -  [ [D] Has anybody heard back from NeurIPS financial aid yet? ](https://www.reddit.com/r/MachineLearning/comments/17bsyp6/d_has_anybody_heard_back_from_neurips_financial/) , 2023-10-31-0910
```
Was supposed to be Monday but instead it's rolling
```
---

     
 
all -  [ [R] Curve your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models ](https://www.reddit.com/r/MachineLearning/comments/17bfgsj/r_curve_your_enthusiasm_concurvity_regularization/) , 2023-10-31-0910
```
**Accepted at NeurIPS 2023**

*Link:* [https://arxiv.org/abs/2305.11475](https://arxiv.org/abs/2305.11475)

*Authors:* J
ulien Siems\*, Konstantin Ditschuneit\*, Winfried Ripken\*, Alma Lindborg\*, Maximilian Schambach, Johannes Otterbach, M
artin Genzel

\*equal contribution

*Abstract:* Generalized Additive Models (GAMs) have recently experienced a resurgenc
e in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear tran
sformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possib
ly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concur
vity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regulari
zer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicabl
e to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability b
y eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer 
in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that c
oncurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and r
educing variance in the feature importances.

*Keywords:* Interpretable Machine Learning, Generalized Additive Models, C
oncurvity, Multicollinearity, Regularization, Time-Series Forecasting, Interpretability

https://preview.redd.it/wtdkhb3
bsbvb1.png?width=1002&format=png&auto=webp&s=3067a2361f55603bf4b7769eaede32ca1f32496f
```
---

     
 
all -  [ prof eval for AI PhD, declined last cycle ](https://www.reddit.com/r/gradadmissions/comments/17b3kxe/prof_eval_for_ai_phd_declined_last_cycle/) , 2023-10-31-0910
```
Finished undergrad in math/cs in 2.5 years from a solid research uni in the US (top 30 overall, top 10 for cs). 3.7 GPA 
with a few grad courses

1 tiny publication in astrophysics (not related at all)
1 first/solo author publication at a po
pular workshop in my field. 
5 papers under submission to WACV, ICLR, NeurIPS workshops (will know 4/5 of them by the en
d of the month). Likely will see 2-3 acceptances out of the 4. 

Currently ai research intern after undergrad and had a 
prev ai research internship, so like 1-1.5 years total experience

signed up for GRE and took it pretty much immediately
, got 157 verbal 168 quant and not sure if I should retake it & do a full prep. 

Main priority:
UCSD DSC / CSE PhD

Oth
ers:
UCSD ECE PhD (ML track)
Harvard CS PhD (really good research match there)
UCLA CS PhD (good research match too)
MIT
 PhD

Harvard MIT are big reach, but how far off am I for UCSD? is it worth to take GRE again? Last year I didn’t really
 talk to a lot of professors or have a good research match at UCSD, so I got declined (also no papers).

Edit: graduated
 9 months ago, applied to similar schools last year with no papers (was working on them, but not finished), no GRE, and 
got declined.

My field of research is generally in deep learning architectures (NAS, Model Compression, Quantization, S
SL)
```
---

     
 
all -  [ How can I stay up-to-date with the latest advancements in machine learning after completing a course ](https://www.reddit.com/r/u_nearlearns/comments/1755o0j/how_can_i_stay_uptodate_with_the_latest/) , 2023-10-31-0910
```
 

In the fast-evolving realm of [machine learning](https://nearlearn.com/blog/top-10-machine-learning-training-institut
e-bangalore/), staying up-to-date with the latest advancements is crucial. As the technology landscape constantly evolve
s, it’s essential to keep pace with the newest trends, methodologies, and breakthroughs to remain relevant and competiti
ve. This article provides a comprehensive guide on how to stay informed and at the forefront of the ever-changing field 
of machine learning.

### Why Staying Updated is Essential

Before delving into strategies for staying current, let’s fi
rst understand why it’s imperative to do so. Machine learning is a dynamic and innovative domain, and advancements occur
 at a breakneck pace. Here are a few reasons why staying updated is crucial:

1. Competitive Edge: In a highly competiti
ve job market, professionals who are well-versed in the latest developments in machine learning have a significant advan
tage. Cutting-edge knowledge can make you stand out among your peers.
2. Relevance: Machine learning models, tools, and 
techniques quickly become outdated. By staying current, you ensure your skills and knowledge are relevant, avoiding obso
lescence.
3. Innovation: The latest advancements often lead to new applications and possibilities. Staying updated enabl
es you to be at the forefront of innovation, allowing you to create groundbreaking solutions.

### Leveraging Online Res
ources

### 1. Online Courses and Tutorials

To keep abreast of the latest in machine learning, consider enrolling in on
line courses and tutorials. Websites like Coursera, edX, and Udacity offer a plethora of courses taught by experts in th
e field.

### 2. Blogs and Forums

Following [machine learning](https://nearlearn.com/machine-learning-classroom-trainin
g-in-bangalore-india) blogs and participating in relevant forums is another effective way to stay updated. Websites like
 Towards Data Science and Kaggle provide valuable insights, discussions, and community support.

### 3. YouTube and Podc
asts

Visual and auditory learners can benefit from machine learning YouTube channels and podcasts. These platforms offe
r engaging content from industry experts, often in a digestible format.

### 4. Social Media

Platforms like Twitter and
 LinkedIn are excellent for following influential figures and organizations in the machine learning space. Regularly che
cking your social media feeds can keep you informed about the latest news, research, and trends.

&#x200B;

https://prev
iew.redd.it/z85dalvu4itb1.png?width=1200&format=png&auto=webp&s=21413a440d23fcce49c4b203445b0b8693169126

**Read More** 
: [Everything You Need To Know About Machine Learning In 2023](https://nearlearn.com/blog/everything-you-need-to-know-ab
out-machine-learning-in-2023/)

### Attending Conferences and Meetups

1. Machine Learning Conferences: Attending confer
ences like NeurIPS, ICML, and ICLR provides an opportunity to learn from thought leaders and connect with peers. These e
vents showcase the most recent research and developments in the field.
2. Local Meetups: Joining machine learning meetup
s in your area can help you stay updated on local developments and network with professionals who share your interests.


### Academic Journals and Publications

1. Research Papers: Regularly reading academic journals and research papers is 
essential for a deep understanding of the latest advancements. Websites like ArXiv and Google Scholar are valuable resou
rces.
2. Books: Explore textbooks and publications by experts in machine learning. These provide comprehensive insights 
and foundational knowledge.

### Hands-On Learning

1. Personal Projects: Applying your knowledge through personal proje
cts allows you to experiment with new concepts and techniques. It’s an excellent way to gain practical experience with t
he latest advancements.
2. Competitions: Participate in machine learning competitions on platforms like Kaggle. These co
mpetitions often involve cutting-edge challenges that push your skills to the limit.

### Networking and Collaboration


1. Join Professional Networks: Being part of professional organizations like the Association for Computing Machinery (AC
M) or the Institute of Electrical and Electronics Engineers (IEEE) can help you connect with experts in the field.
2. Co
llaborate with Peers: Collaborative projects with colleagues and peers can expose you to different perspectives and inno
vative ideas.

### Continuous Learning

The field of machine learning is characterized by constant change. To stay ahead
, it’s crucial to embrace a mindset of continuous learning. Regularly set aside time for self-improvement, be it through
 online courses, conferences, or personal projects.

### In Conclusion

Staying updated with the latest advancements in 
machine learning is vital for personal and professional growth. In this dynamic field, knowledge is power, and being wel
l-informed can open doors to exciting opportunities and innovations. By leveraging online resources, attending conferenc
es, reading academic publications, engaging in hands-on learning, and building a network of like-minded individuals, you
 can ensure that you’re always at the forefront of this ever-evolving field.
```
---

     
 
all -  [ Final year PhD student aiming to transitioning from ML PhD to industry. ](https://www.reddit.com/r/resumes/comments/174fy9s/final_year_phd_student_aiming_to_transitioning/) , 2023-10-31-0910
```
I am a final year PhD student in France working on privacy and  fairness topics in deep neural networks. My publication 
record is decent but not top-tier (think EMNLP, TMLR rather than ICML/NeurIPS).  Recently, I've been applying to data sc
ience and machine learning  engineering roles. However, out of 50-75 applications over the past few  weeks, I have not r
eceived any callbacks.  
I'm wondering if there is something I should optimize on resume.  Any tips would be greatly app
reciated!  


P.S. - I also posted something similar to another sub, and the key advice I received was to add publicatio
ns on the second page.   
Resume - [https://i.imgur.com/x2IavdR.jpg](https://i.imgur.com/x2IavdR.jpg)
```
---

     
 
all -  [ Seeking advice on transitioning from ML PhD to industry ](https://www.reddit.com/r/cscareerquestionsEU/comments/173rtr4/seeking_advice_on_transitioning_from_ml_phd_to/) , 2023-10-31-0910
```
I am currently a final year PhD student in France working on privacy and fairness topics in deep neural networks. My pub
lication record is decent but not top-tier (think EMNLP, TMLR rather than ICML/NeurIPS). Recently, I've been applying to
 data science and machine learning engineering roles. However, out of 50-75 applications over the past few weeks, I have
 not received any callbacks.  
I'm wondering if anyone here has been in a similar situation or has advice on how to effe
ctively market myself in industry? I've attached my anonymized resume as well. Any tips would be greatly appreciated!  

Resume - https://i.imgur.com/x2IavdR.jpg
```
---

     
 
all -  [ How to write LOR ](https://www.reddit.com/r/MSCS/comments/171gsl6/how_to_write_lor/) , 2023-10-31-0910
```
Hey there!

I am a third year bachelor cse student and I want to apply to top unis in the UK, USA and Switzerland. I hav
e asked one of the profs for a recommendation letter (with whom I have done a research project which turned into a paper
, currently in submission at a workshop at NeurIPS). He agreed, and he allowed me to write a draft first. What are the u
nis looking for, exactly? What abilities should be emphasized in the letter? Is it just the usual hard-working student w
ho learns very fast and proved to have research skills etc?

Thank you very much!
```
---

     
 
all -  [ Profile evaluation for Master's (in CS mostly) applications in the US (Fall 24) ](https://www.reddit.com/r/gradadmissions/comments/16znemg/profile_evaluation_for_masters_in_cs_mostly/) , 2023-10-31-0910
```
Hi all,

I am looking for a realistic evaluation of my profile for MS CS applications in the US for Fall 2024. All help 
appreciated.

Undergrad college - Indian Institute of Technology (IIT), Delhi 

Undergrad Major - Mathematics and Comput
ing

Undergrad GPA - 9.53/10

Internships - 2 research internships (at Adobe Research & Max Planck Institute for Softwar
e Systems), 1 web development internship at a startup

Job experience - 1.5 years at a research lab in Adobe

Publicatio
ns - 2 first-author papers (at CVPR 2023 workshops and BMVC 2023). 2 papers currently under review at WACV and NeurIPS w
orkshops 

Patents - 3 filed (US PTO), 1 awaiting internal review

Field of interest: Computer Vision

GRE: 326/340 (Q:1
70, V:156, AWA:4.5/6)

TOEFL: TBD

Shortlisted universities/programs so far: MIT Media Lab, Stanford, CMU (MSR, MSML, MS
CV), UC Berkeley, UIUC, UT Austin, Georgia Tech, UCSD, Cornell.

What are my chances at these universities? Any specific
 things to consider while applying? and, any colleges/programs I should consider adding/removing from the list above? Al
so, is the GRE score too low for CMU?


Thank you in advance!
```
---

     
