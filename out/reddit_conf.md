 
all -  [ Chance me Harvard, UMich, NYU ](https://www.reddit.com/r/chanceme/comments/1hmlac5/chance_me_harvard_umich_nyu/) , 2024-12-28-0912
```
**CS for all**

**Demographics**:

South Asian

Low-Mid Tier HS

**Stats**:

GPA: 3.4/4 UW 3.8/5 W(Extenuating circumsta
nces, 4.0 UW Jr and Senior year so far)

SAT: 1500

7 AP’s, 9 is the Maximum. 12 Honors

**Awards**:

Top 100 Nationally
 ranked Chess players in Age group all 4 years of HS(5th in state rn😭)

Won Prestigious FIDE international Chess Tournam
ent

Won Chess State Championship

Ap Scholar With Honors

NHS

**EC’s**:

HS State Chess League Pres - 30 teams, 100+ p
layers, 10k raised from [Chess.com](http://Chess.com) and academies

1st author to a paper accepted to Neurips and SoCal
 NLP(top conference/symposium)

Chess Club Pres - 3 peat regionals and top 4 in State

Motorola Solutions SWE Intern - m
ade REST API for an app in prod

Volunteer Chess coach at local chess academy 200+ hrs

Paid remote chess coach apart of
 non-profit for at-risk/underprivileged Chicago youth

South asian student association treasurer - raised 10k and provid
ed 5k in scholarships to south asian students for the 1st time in chapter history

DECA 3x States Qual, 1x ICDC

Varsity
 Wrestler

Inspirit AI scholars program - Mentored by MIT+Harvard grads on AI/ML. Created ChessGPT, 1st GPT4 based chess
 engine that can play at advanced level with no illegal moves. Presented to school board + superintendent.(Iykyk how cra
zy this really is)

Essays: 8/10

Recs: Humanities 9/10, Stem 8/10, UC Berkley research mentor 8/10

**Schools**:

UIUC(
Math & CS through CAS)

UMASS Amherst CS

UMD CS

UW Madison CS

NYU CS through CAS

UMich CS

Harvard CS

UC Berkley, L
A, SD for CS

\*These are all my reaches, already got into Penn State, Upitt, and NEU NUin\*

Will I beat the odds???
```
---

     
 
all -  [ # of papers vs. citations ](https://www.reddit.com/r/eb_1a/comments/1hm9j9b/of_papers_vs_citations/) , 2024-12-28-0912
```
How are the two compared?

My lawyers are aiming for EB1B for me but I’m worried that I might not have enough papers.

I
 have 4 publications, 1 thesis, 3 preprints (one of which was also presented as an industrial demo at CVPR). My works ar
e mostly focused in vision / nlp (CVPR, WACV, AACL). All first author except 1 publication and 1 preprint.

Now, I got l
ike 450 citations, and am getting cited rapidly - decent chance to be at 500 by the time the doc is ready. Have served a
s reviewer for all top tier conferences in ML/CV (NeurIPS, CVPR, ICLR, ICML, ICCV, etc.) for something like 50+ papers.


My big worry is having issues stemming from only 4 of my works having been actually published (although the non-publish
ed ones are also getting cited). What do you guys think?
```
---

     
 
all -  [ i sensed anxiety and frustration at NeurIPS 24 ](https://kyunghyuncho.me/i-sensed-anxiety-and-frustration-at-neurips24/) , 2024-12-28-0912
```

```
---

     
 
all -  [ [D] What would you like in a ML/ML-related course in university? ](https://www.reddit.com/r/MachineLearning/comments/1hhdch4/d_what_would_you_like_in_a_mlmlrelated_course_in/) , 2024-12-28-0912
```
Hi!

I'm invited to give a course in university (not really a university, it's a different educational system, they call
 it engineering school but it's equivalent) in ML or ML-related.

The course is 22 hours in total. Which is short. The c
ourse is divided in both theoretical classes and practices classes. But I can change the proportion of hours. When I say
 practice it's more like a project they can do and then I grade it.

It's not the only ML course the students have, I wa
s told the students already have a machine learning course where they cover all the basics in Machine Learning and some 
statistical models (the usual ones like random forests, SVMs etc.), and they also have an in-depth NLP course, so I don'
t think I'm going with that.

What bothers me is, how to balance the theory with practice. I don't want to cover some to
pic superficially but at the same time I don't know if it's worth it for the students to cover a specific topic too deep
ly.

I don't know if it's a good idea to do something like two topics, 11 hours each with like 5 hours of theory and 6 h
ours of practice. Or do I go with just one topic.

I was suggested to show them about MLOps and tooling like Git, Docker
, Mlflow, basically just a bit of Mlops, monitoring models, how to productionize them etc. But I don't know if it's wort
h it, I feel like it's superficial to teach them how to use these tools, and there are a lot of resources online anyways
 and I guess recruiters won't expect them to know that or have experience with for junior positions.

I was also suggest
ed time series as a course, but I don't know if going in-depth in them would be interesting to the students 😅 there's a 
lot of math, and though professors assured me that they have a good level in math, I don't know if they'll be interested
 in that.

Another drawback is that I don't have access to computational resources for this course so I'm a bit limited.
 I think if I were at their place I'd have loved a course in low-level stuff like how flash attention works, some distri
buted training mechanisms, cuda etc. But I don't have means to ensure that for them :(

Another thing I'd love to do is 
to take some of the best awards papers of this year or something and help them gain the knowledge and understanding nece
ssary to understand the paper and the topics around it. Or maybe have different sessions with different topics like, one
 about diffusion models, one about multi-modal models etc., like 'let's understand how they came about qwen2-vl', 'let's
 understand what's the main contribution and novelty of the best paper in neurips main track about var' etc.

So I'm a b
it lost and I'd love to have your ideas and suggestions. What I care about is giving the students enough knowledge about
 some topic(s) so they don't only have a high-level idea (I've had interns to which I asked what is a transformer and th
ey went 'we import a transformer from hugging face') but at the same time equip them with skills or knowledge that can h
elp them get recruited for junior positions

Thank you!

```
---

     
 
all -  [ Winning edge models from Neurips 2024 competition  ](https://www.reddit.com/r/LocalLLaMA/comments/1hhbl6a/winning_edge_models_from_neurips_2024_competition/) , 2024-12-28-0912
```
I have been following up the neurips edge llm competition for a while and recently they announced the winners. The compe
tition had two tracks. One was compression challenge and another was training from scratch. Though the models and associ
ated compression techniques are not yet made public, it is interesting to see the edge llm space getting more traction 


https://edge-llms-challenge.github.io/edge-llm-challenge.github.io/leaderboard
```
---

     
 
all -  [ NeurIPS 2024: Capital One showcases leading AI research ](https://www.reddit.com/r/u_CapitalOne/comments/1hh7gli/neurips_2024_capital_one_showcases_leading_ai/) , 2024-12-28-0912
```
# This past week, many Capital One associates were active participants at the r/NeurIPS conference. Explore our contribu
tions to the world's premier AI research conference, from papers and workshops to expert presentations.

The 38th Annual
 Conference on Neural Information Processing Systems ([NeurIPS](https://neurips.cc/)), returned this December, and Capit
al One is excited to be a part of it! As a company committed to [responsible and innovative AI](https://www.capitalone.c
om/tech/machine-learning/applied-ai-research/), we're eager to share our latest research, connect with fellow researcher
s and engage in the vibrant exchange of ideas that defines this event.

# Capital One's impact at NeurIPS 2024

At Capit
al One, we're [leveraging AI to unlock new possibilities in financial services](https://www.capitalone.com/tech/machine-
learning/machine-learning-research-roundup/) and deliver exceptional customer experiences. NeurIPS provides a crucial pl
atform to engage and exchange ideas with some of the best minds in AI and science. We're eager to engage with leading ac
ademics, researchers and industry experts to discuss the latest advancements and challenges in AI. Our research efforts 
are focused on applying AI/ML techniques to address real-world challenges in the financial domain, such as improving the
 efficiency and interpretability of models, developing advanced techniques for analyzing financial time series data and 
building transparent and understandable AI systems. This work is critical to developing trustworthy AI solutions, and we
're particularly excited to share our progress in areas like deep learning, sequence modeling, explainable AI and genera
tive AI.

At [NeurIPS 2023](https://www.capitalone.com/tech/machine-learning/neurips-applied-research/), our Applied Res
earch team had several works accepted. This year, we’re continuing to showcase our research, foster collaboration and su
pport the next generation of AI talent

# Advancing AI research: Main conference papers

We have contributed to three pa
pers accepted to the main conference track:

* [**Distributional Preference Alignment of LLMs via Optimal Transport**](h
ttps://neurips.cc/virtual/2024/poster/96822): Distinguished Applied Researcher, [Igor Melnyk](https://scholar.google.com
/citations?user=4vDRTWwAAAAJ&hl=en), takes the lead as first-author exploring novel methods for aligning large language 
models (LLMs) with user preferences using optimal transport theory. This work enhances LLMs' ability to generate content
 that aligns with specific needs and values. 
* [**Searching for Efficient Linear Layers over a Continuous Space of Stru
ctured Matrices**](https://neurips.cc/virtual/2024/poster/94195): VP of AI Research [Bayan Bruss](https://scholar.google
.com/citations?user=ClqvGRQAAAAJ&hl=en) and Senior Machine Learning Engineer [Christopher Ferri](https://scholar.google.
co.uk/citations?hl=en&user=rGuDTOIAAAAJ) contribute their expertise to this collaborative research with NYU, which focus
es on optimizing the efficiency of neural networks by exploring a continuous space of structured matrices for linear lay
ers. This has the potential to lead to faster and more efficient models.
* [**Tiny Time Mixers (TTMs): Fast Pre-trained 
Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series**](https://neurips.cc/virtual/2024/poster/9674
8): In partnership with IBM Corp, Senior Distinguished Applied Researcher [Nam Nguyen](https://scholar.google.com/citati
ons?user=zzBcUpEAAAAJ&hl=en) helps to introduce innovative techniques for time series forecasting with Tiny Time Mixers 
(TTMs). These pre-trained models are optimized for fast and accurate predictions, even with limited fine-tuning data.

[
Dr. Furong Huang](https://scholar.google.com/citations?user=13yyuCcAAAAJ&hl=en), our inaugural Visiting Scholar and an A
ssociate Professor in Computer Science at the University of Maryland, also contributed to [six additional NeurIPS papers
](https://nips.cc/virtual/2024/papers.html?filter=authors&search=Furong+Huang). Dr. Huang’s expertise in trustworthy mac
hine learning strengthens our research collaborations and reflects our commitment to bridging academia and industry. 

#
 Fostering the next generation of AI talent: Workshop papers

Capital One's presence at NeurIPS extends beyond the main 
conference with seven accepted workshop papers, further demonstrating our commitment to advancing AI research and foster
ing the next generation of AI talent through our internship programs. 

# Applied Research Internship Program (ARIP)

Fi
ve of the accepted papers are authored by talented individuals from our 2024 [Applied Research Internship Program](https
://www.capitalonecareers.com/upgrade-ai-work-with-the-applied-research-internship-students-tech) (ARIP), a program desig
ned to provide PhD students with hands-on experience tackling real-world AI challenges in the financial sector. 

* [**R
efusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models**](https://scholar.google.com/citations?view_
op=view_citation&hl=en&user=nSn7jtIAAAAJ&citation_for_view=nSn7jtIAAAAJ:4DMP91E08xMC): This paper explores a novel metho
d for controlling the refusal behavior of large language models by introducing 'refusal tokens' during training. This te
chnique allows for fine-grained control over the model's tendency to refuse certain prompts or questions, enhancing safe
ty and reliability.
* [**Dense Backpropagation Improves Routing for Sparsely-Gated Mixture of Experts**](https://openrev
iew.net/pdf?id=huy8g3iKy0): This paper investigates the use of dense backpropagation in Mixture of Experts (MoE) models,
 demonstrating its effectiveness in improving routing decisions and overall model performance. This work contributes to 
the advancement of MoE models, which are known for their efficiency and scalability.
* [**Language Model Scaling Laws an
d Zero-sum Learning**](https://openreview.net/forum?id=yBq2g832Go&referrer=%5Bthe%20profile%20of%20Irina%20Rish%5D(%2Fpr
ofile%3Fid%3D~Irina_Rish1))**:** This research delves into the relationship between language model scaling laws and zero
-sum learning, exploring how the competitive dynamics of zero-sum games can influence the scaling behavior and performan
ce of large language models.
* [**StructMoE: Augmenting MoEs with Hierarchically Routed Low Rank Experts**](https://open
review.net/pdf?id=v71Nsh6R7m): This paper proposes StructMoE, a novel architecture that enhances Mixture of Experts (MoE
) models by incorporating hierarchically routed low-rank experts. This approach aims to improve the efficiency and expre
ssiveness of MoE models, further advancing their capabilities in various applications.

# Data Science Internship Progra
m (DSIP)

We are also proud to highlight a workshop paper authored by a former intern from our [Data Science Internship 
Program](https://campus.capitalone.com/employment/new-york-data-science-jobs/1786/8161296/6252001-5128638-5128581/4) (DS
IP), which offers aspiring data scientists the opportunity to contribute to cutting-edge research and development.

* [*
*Enhancing Table Representations with LLM-powered Synthetic Data Generation**](https://openreview.net/forum?id=h9465s0xu
7#discussion): This paper explores the use of large language models (LLMs) to generate synthetic tabular data for improv
ing table representations. This approach aims to enhance the performance of similar table recommendation systems, which 
are crucial for efficient data management and analysis in data-driven enterprises. The research introduces a novel synth
etic data generation pipeline that leverages LLMs to create a large-scale dataset tailored for table-level representatio
n learning, leading to improved accuracy in recommending similar tables.

# Collaborative research

Finally, we have wor
kshop papers co-authored by Senior Distinguished Applied Researcher [Nam Nguyen](https://scholar.google.com/citations?us
er=zzBcUpEAAAAJ&hl=en), and Distinguished Applied Researcher [Supriyo Chakraborty](https://scholar.google.com/citations?
user=UIM7nGwAAAAJ&hl=en) further demonstrating our commitment to collaborative research and knowledge sharing within the
 AI community.

* [**Scaling-laws for Large Time-series Models**](https://arxiv.org/pdf/2405.13867): This research, cond
ucted in collaboration with Johns Hopkins University, explores the scaling laws that govern the performance of large tim
e-series models. By examining the relationships among model size, data volume, and computational resources, this study o
ffers valuable insights into the efficient training and deployment of these models for diverse time-series forecasting t
asks in finance and other domains.
* [**MyCroft: Towards Effective and Efficient External Data Augmentation**](https://s
cholar.google.com/citations?view_op=view_citation&hl=en&user=QOsVyPMAAAAJ&citation_for_view=QOsVyPMAAAAJ:LkGwnXOMwfcC): 
This research introduces MyCroft, a new data-efficient framework implementing techniques to evaluate relative utility of
  relevant external data sources that can augment internal data to improve model performance. These techniques leverage 
feature space distances and gradient matching to identify small but informative data subsets to maximize performance wit
h minimal data [exposure.Capital](http://exposure.Capital) One's presence at NeurIPS extends beyond the main conference 
with seven accepted workshop papers, further demonstrating our commitment to advancing AI research and fostering the nex
t generation of AI talent through our internship programs. 

# Our two engaging expo talks

# Sequence Modeling in Finan
cial Services

Led by Senior Distinguished Applied Researcher [Nam Nguyen](https://scholar.google.com/citations?user=zzB
cUpEAAAAJ&hl=en), this talk delves into the intricacies of applying sequence modeling to financial data. Learn about cut
ting-edge research, including novel approaches for leveraging powerful transformer models for enhanced insights and pred
ictions.

* **Date/Time:** Tuesday, December 10th, 4:00 PM local time
* **Location:** West Ballroom B

# Deep Tabular Da
ta

Led by Distinguished Machine Learning Engineer [Doron Bergman](https://scholar.google.com/citations?user=FeCagRUAAAA
J&hl=en), this talk explores the challenges and opportunities of deep learning for tabular data in finance. Discover how
 deep learning can surpass traditional methods and unlock new possibilities for financial modeling.

* **Date/Time:** We
dnesday, December 11th, 1:00 PM local time
* **Location:** West Meeting Room 109/110

# Connect with Capital One at Neur
IPS 2024!

We're excited to connect with you at NeurIPS 2024! Come visit us at booth #315 where you can:

* **Explore ou
r research**: Dive deep into our latest [advancements in AI](https://www.capitalone.com/tech/ai/) and machine learning.

* **Discover career opportunities**: Learn about exciting [applied research career paths](https://www.capitalonecareers.
com/search-jobs/applied%20research/234/1) at Capital One for researchers and engineers passionate about AI and join our 
world-class team.
* **Engage with our team**: Meet our researchers and AI experts, ask questions and discuss the [future
 of AI in finance](https://www.capitalone.com/tech/ai-research/).

This Reddit post is a [\~repurposed Tech blog\~](http
s://www.capitalone.com/tech/ai-research/?utm_campaign=always-on&utm_source=reddit&utm_medium=organic-social&utm_content=
neur-ips). For more learning opportunities check out the [\~Capital One Tech blog\~](https://www.capitalone.com/tech/blo
g/) and keep the progress going! 
```
---

     
 
all -  [ Can o1-preview find major mistakes amongst 59 NeurIPS '24 MLSB papers? ](https://www.reddit.com/r/slatestarcodex/comments/1hh25xz/can_o1preview_find_major_mistakes_amongst_59/) , 2024-12-28-0912
```
[Link to the essay](https://www.owlposting.com/p/can-o1-preview-find-major-mistakes)

  
Summary: I saw this Twitter thr
ead recently about how o1 [was able to find a major error in a scientific paper. ](https://x.com/emollick/status/1868329
599438037491)I wondered: could it do something similar in my own field of biology x ML? I downloaded 59 papers from [Neu
rIPS '24 MLSB](https://www.mlsb.io/), a structural biology + chemistry + AI workshop that happened just last week, pushe
d them through o1 to ask if there are any errors, and interpreted its response. Of the 59, o1 said 3 have major errors. 
Upon reviewing the 3, none of the complaints seem well-founded. But all were intelligent and fun to grapple with! But fo
r at least one of the papers, it took quite a bit of effort (contacting the authors) to disprove. All this to say, o1 is
n't a drop in replacement for an academic reviewer, but its critiques are still often interesting and useful. 
```
---

     
 
all -  [ Influential creators at tech conference: 'Don't say AI democratizes art-making. Should we democratiz ](https://www.reddit.com/r/aiwars/comments/1hgq91u/influential_creators_at_tech_conference_dont_say/) , 2024-12-28-0912
```
Despite being mostly public figures, names still censored as per rules.

https://preview.redd.it/x3x3wzuubi7e1.png?width
=721&format=png&auto=webp&s=b61a67d70cba854f9aa57743566211748ae073f9

Here's the issue.

You can't democratize marathon 
running with mopeds, because then it would no longer be running. Marathon running is a specific activity performed for a
 specific purpose.

What you *can* democratize -- and what we have successfully democratized to everyone's benefit -- is
 getting from place-to-place quickly. For this you can give people mopeds, electric wheelchairs, cars, planes, whatever.
 Because the goal of the activity is not to use your legs to run, but simply to get from one place to another. There was
 a time when those who couldn't walk were mostly out of luck. There were times when there weren't ramps for wheelchairs 
to get into most buildings. But we've taken steps to make it easier for everyone to get around; we've democratized trave
l.

  
To take all this back to AI, AI doesn't democratize drawing or painting, because those are specific activities wh
ich AI is not. But it does democratize art-making. If you don't like calling it art, fine, it democratizes the ability t
o get ideas from your head into imagery which can be enjoyed or shared. If you'd say it didn't need to be democratized b
ecause anyone can draw, well sure, and anyone can walk. But we have technology like bicycles and mopeds to get to places
 faster...or Photoshop with all its conveniences like layering and undo...and as long as you're not in a context where t
hose tools don't match the activity, there's nothing wrong with that.
```
---

     
 
all -  [ Am I Making the Right Choice? Masters in ML, Research Lab Experience, and Building Things That Matte ](https://www.reddit.com/r/learnmachinelearning/comments/1hgng0o/am_i_making_the_right_choice_masters_in_ml/) , 2024-12-28-0912
```
I’m currently pursuing my master’s in machine learning, and I love building things — that’s how I understand concepts be
st. But my first semester hit me with a tough realization: I joined a research lab way too early, and it just wasn’t the
 right fit for me.

The lab’s environment felt off. The code was sloppy, results were rushed, and even the smallest net-
positive outcome led to a question: “Which journal should we target?” Maybe this is how it works in many research labs —
 I don’t know, this was my first experience. But the emphasis on quick publication, without deeper exploration or clean 
fundamentals, didn’t sit well with me.

For context, I was working with LLMs. What surprised me is how many papers get p
ublished even when they’re essentially hacks — a lot of prompt engineering, and observations that openly admit “We don’t
 know why this works, but it does.” I respect research, but it started to feel… unfulfilling. I wasn’t enjoying it, and 
I had no time to work on projects of my own.

Now I’m planning to quit the lab. But here’s where I’m conflicted: it seem
s like most ML jobs require a strong research profile — X papers in NeurIPS, ICML, etc. Part of me wonders if I should s
tick with it, keep my head down, and publish papers just to “check the box.” But then I remember why I’m here in the fir
st place: I genuinely enjoy ML, especially when I’m building things that matter, not just chasing publications.

To thos
e who’ve been down this road: Am I sabotaging my career prospects by walking away from research so early? Is it better t
o focus on building meaningful projects, even if they don’t come with a DOI? Or am I missing something about the value o
f sticking it out in the lab?
```
---

     
 
all -  [ Legal Tech’s Data Dilemma: Trust, Betrayal, and Competition. ](https://www.reddit.com/r/legaltech/comments/1hgmxc4/legal_techs_data_dilemma_trust_betrayal_and/) , 2024-12-28-0912
```
Ilya Sutskever, co-founder of OpenAI, recently highlighted a critical issue at the NeurIPS 2024 conference: the AI indus
try is facing a data scarcity problem, often referred to as 'peak data.' Despite advancements in computing power, the av
ailability of high-quality training data is becoming a bottleneck for AI development. Sutskever emphasized that syntheti
c data, while a potential solution, does not fully address this challenge.

In this landscape, companies promising not t
o mine your data face immense pressure to break that pledge. The competitive advantage of leveraging vast, real-world da
tasets is simply too great to ignore. Discarding millions of dollars’ worth of high-quality data—data that could refine 
models, boost performance, and outpace competitors—is a hard sell for any profit-driven firm.

And here lies the uncomfo
rtable truth: no amount of compliance paperwork, signed audits, or certifications can fully guarantee your data’s safety
. Unless you examine production code directly, there’s no way to ensure that your data isn’t being anonymized and quietl
y used to train systems. Unlike static cloud storage, generative AI operates on a completely different scale. Its rapid 
feedback loops and massive bandwidth allow companies to quickly organize and refine reinforcement-learning-grade dataset
s—even with anonymized or de-identified data.

We’re decisively moving from the compute era to the data era of AI, where
 success is no longer about the size of your GPU cluster but the quality of your post-training data. In this new paradig
m, aligning models with the correct data is essential—placing tools for data curation, human supervision, and evaluation
 at the heart of AI development.

The legal tech industry must take heed: make sure you own your AI. AI in the cloud is 
not aligned with you—it’s aligned with the company that owns it. To protect sensitive data and retain control, on-premis
e solutions and transparent practices are no longer optional—they are imperative.

[NeurIPS 2024 conference](https://pre
view.redd.it/k32axcw1lh7e1.jpg?width=2048&format=pjpg&auto=webp&s=3887497b862f3190153705674c943c94697a7bd3)


```
---

     
 
all -  [ ChanceMe : Asian Male CS 🙏🙏🙏 ](https://www.reddit.com/r/chanceme/comments/1hgkgzi/chanceme_asian_male_cs/) , 2024-12-28-0912
```
I think its a strong application but holy shit my GPA is eating at my confidence rn, please chanceme would be much appre
ciated

Currently a junior - any senior related stuff is likely predictions - chanceme as such

**Demographics:**   
Mal
e, Indian, Southern USA, Looking at top CS programs, potentially recruited for d2 level swim, upper middle class income


**Intended major(s):**

CS w a focus on AI/ML, EECS

**Academics:**

* **SAT:** 1600 superscore
* **Class rank:** top 2
0% atleast, most likely top 15%
* **UW/W GPA: 3.9/6.05 on a 6.7 scale**
   * My school grades by semester, so i have 63 
total semester grades of which 6 are B's.
* **Coursework:** 
   * AP Human geo, Discrete Math
   * AP physics, AP CSA, A
P Precalc, AP World history, Linear Algebra
   * AP Lang, AP Physics C:Mech, AP Calc AB, AP Stats, APUSH, AP CSP
   * AP
 Lit, AP Physics C: EM, AP Calc BC, Multivariable Calc & Differential EQ, AP Macro/Micro, AP Gov
      * 5's on all exce
pt a 4 on AP human geo
* **Awards:**
   * USACO Plat
   * USAJMO Qual
   * ISEF grand award
   * USAPhO Medallist (Not g
old)
   * Published research in a major CS conference (Neurips level but not neurips)
   * Deciding between All state ja
zz saxophone or a business related award,

**Extracurriculars:**

* AI/ML startup - 5 figure revenue, interviewed by Y c
ombinator, abt 15k users
* Software/CSE Intern at a major company working in lawtech
* Nonprofit that provides olympiad 
tutoring and classes for free, about 500 hours taught total, 15 volunteers, personally taught about 100 hours early on
*
 d2/3 swim, some minor schools reaching out, 25 second 50 free
* Math competition club president - major club with about
 100 members, schools ranked pretty high nationally in this one competition
* Speech and debate congressional debate com
petitor, finaled some pretty big tournaments and have accumulated 15 bids to TOC
* AI ML publication - if not in awards 
ill mention here, did prompting research and technical research with a PhD at berkeley - through cold emailing
* Patent 
for a novel bio-based material, considering commercializing but probably not
* Jazz saxophone player for abt 8 years, pl
ay a lot for fun and am decent at it, considering putting it on like a portfolio
* Youtube channel with 1.1 million life
time views and about 5k subscribers, where I post music and education content

**Schools:**

* Basically the top 20 CS s
chools, preference on MIT/CMU/Stanford

LOR

10/10 - research teacher

10/10 - Math teacher

7/10 - Saxophone tutor

Ess
ays  
Common app - 8/10 - not an amazing writer but fairly good feeling about it  
Supps - didnt write yet - re: current
 junior

**H**ad a shitty GPA because close family member died first semester of sophomore year, so I got some B's, and 
got into some disciplinary trouble around that time with the school, nothing major, no suspension etc. all the classes w
ith B's were A+ next semester.

I feel decently confident, but im fairly worried about my GPA and how it measures up her
e, I go to a rich private school full of tryhards :()

Would really appreciate yall's thoughts on this :D
```
---

     
 
all -  [ Valence & Recursion Sweep Awards at Foundation Models for Science Workshop at NeurIPS ](https://www.reddit.com/r/RecursionPharma/comments/1hfo8d6/valence_recursion_sweep_awards_at_foundation/) , 2024-12-28-0912
```
https://preview.redd.it/0jg8zf1sv87e1.png?width=1200&format=png&auto=webp&s=951c8af14784f575ef01a613f15a8c80e2f73d17

Th
is past weekend at NeurIPS, Valence Labs and Recursion won first, second and third place awards at the Foundation Models
 for Science workshop. These foundation models offer breakthroughs in leveraging machine learning to better model the in
tersection of biology and chemistry necessary to improve and scale AI drug discovery. 

**First place** was awarded to a
 paper on MolPhenix, a foundation model that can predict the effect of any given molecule and concentration pair on phen
otypic cell assays and cell morphology by integrating phenomics data with chemistry data. Over the past decade, Recursio
n has generated billions of phenomics images through automated, high-throughput experiments. Paired with new phenomics f
oundation models like Phenom-1, Recursion can extract meaningful representations from these high-dimensional images to b
uild Maps of Biology, allowing them to navigate which molecules and genes map to the same space of morphological changes
. MolPhenix mines that rich data and delivers 10X improvement over previous methods – from 7.9% to 77.3% on the Top 1% r
ecall of active molecules. **Paper:** [https://www.arxiv.org/abs/2409.08302](https://www.arxiv.org/abs/2409.08302?fbclid
=IwZXh0bgNhZW0CMTAAAR1DNiyBVjVqVLuNtS9J5NV1MFqG6gxWIEMc8VxgmY_h1F61pVC1QMYBx5E_aem_eMEc0w9oQCwp4X5KhTwjSA)

**Second pla
ce** was awarded to a paper on Atomic GFlowNets (A-GFNs), a foundational generative model leveraging individual atoms as
 building blocks to explore drug-like chemical space more comprehensively. The model uses an unsupervised pre-training a
pproach using offline drug-like molecule datasets, conditioning A-GFNs on inexpensive yet informative molecular descript
ors such as drug-likeliness, topological polar surface area, and synthetic accessibility scores. These properties serve 
as proxy rewards, guiding A-GFNs towards regions of chemical space that exhibit desirable pharmacological properties. **
Paper:** [https://arxiv.org/abs/2409.09702](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F2409.09702%3F
fbclid%3DIwZXh0bgNhZW0CMTAAAR1TFhx9hYXN7h0fUw0yz-jj1XbKnG5VVmeGbhBjXq3D_mI-0EaoAFSuPdM_aem_DSvWO2X4lUCyArxe25tAxg&h=AT3p
MSPJmPbXaJMGgs_or31Oprx-0d6DEJfLPfDpG7eaT2mbKba97Q38wnlIRWtiiybJk6-ebgL6mKUxVGSjRbxBmELjxYpjXNjdHgL29VeAnS-hGjDCqAKKMQMj
w7aG1g&__tn__=-UK-R&c[0]=AT0iM8paHD3SnWn3-5OATLDMYPKlw0l87qqsKblkdsjHHaCw_MGxpfhRaSEvxsy0AUorpVBjv6c2ceWmePe-Jl-BcrAc3Ma
QXhUG9VtgoQ9q8Jm8kZAX4gjgN8BWRSb9QeIYE2XwWCLl8bqvpU0AKz5RAGcDYz5s2BukDaagpBsjOI07tAnlVJ-4_HtQZ-b4sEweKQ) 

**Third place
** was awarded to a paper on the largest foundation model for cell microscopy data to date, a new 1.9 billion-parameter 
ViT-G/8 MAE trained on over 8 billion microscopy images that achieves a 60% improvement in linear separability of geneti
c perturbations and obtains the best overall performance on whole-genome biological relationship recall and replicate co
nsistency benchmarks. **Paper:** [https://arxiv.org/abs/2411.02572](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.o
rg%2Fabs%2F2411.02572%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR1TFhx9hYXN7h0fUw0yz-jj1XbKnG5VVmeGbhBjXq3D_mI-0EaoAFSuPdM_aem_DSvWO
2X4lUCyArxe25tAxg&h=AT2mulqFETtdCih5m7gG70wHri8uodEz6hXHak0aAKc6GwUbm4BJnRDlDjN6L8dYBc_aXrweThNM8xEMPZ5GqovHoSWE3w2YETVv
k99BY8TWSX6EyOpJw5-OvDXcHdj2fw&__tn__=-UK-R&c[0]=AT0iM8paHD3SnWn3-5OATLDMYPKlw0l87qqsKblkdsjHHaCw_MGxpfhRaSEvxsy0AUorpVB
jv6c2ceWmePe-Jl-BcrAc3MaQXhUG9VtgoQ9q8Jm8kZAX4gjgN8BWRSb9QeIYE2XwWCLl8bqvpU0AKz5RAGcDYz5s2BukDaagpBsjOI07tAnlVJ-4_HtQZ-b
4sEweKQ)

\#NeurIPS #NeurIPS2024 #ML
```
---

     
 
all -  [ NeurIPS conference in Vancouver draws 16,000 AI researchers $META ](https://www.reddit.com/r/alertscreener/comments/1hfitr5/neurips_conference_in_vancouver_draws_16000_ai/) , 2024-12-28-0912
```
With major companies like Meta $META, Alphabet $GOOGL, and Microsoft $MSFT showcasing their latest AI advancements and p
roducts.

### Follow [@alertscreener](https://x.com/intent/user?screen_name=alertscreener) for more
```
---

     
 
all -  [ Last Evening in Vancouver: Must-See Experiences Before Heading Back? ](https://www.reddit.com/r/askvan/comments/1hf3fah/last_evening_in_vancouver_mustsee_experiences/) , 2024-12-28-0912
```
I've been here for a week attending NeurIPS 2024 and will be heading back Toronto tomorrow. I only have this evening lef
t—what's the must-see or unique experience I shouldn’t miss to avoid regretting it later
```
---

     
 
all -  [ Last Evening in Vancouver: Must-See Experiences Before Heading Back? ](https://www.reddit.com/r/canadatravel/comments/1hf37do/last_evening_in_vancouver_mustsee_experiences/) , 2024-12-28-0912
```
I've been here for a week attending NeurIPS 2024 and will be heading back Toronto tomorrow. I only have this evening lef
t—what's the must-see or unique experience I shouldn’t miss to avoid regretting it later


```
---

     
 
all -  [ [D] Are We Okay With This? Questionable Poster Behavior at NeurIPS ](https://www.reddit.com/r/MachineLearning/comments/1heo36q/d_are_we_okay_with_this_questionable_poster/) , 2024-12-28-0912
```
This was my first year at NeurIPS. It’s inspiring to see so much cutting-edge research being presented, but something tr
oubling caught my attention during the poster sessions that I feel compelled to share, especially given [the recent inci
dent with Rosalind Picard](https://www.reddit.com/r/MachineLearning/comments/1hdxbru/d_what_happened_at_neurips/).

Gett
ing a paper accepted at NeurIPS is a huge achievement. Each poster spot represents so much hard work and is highly covet
ed.

I saw two posters that *shouldn’t* have been there, and it has left me wondering about the exploitation of these sp
aces.

**Illegal Poster #1:** [Generative Boba](https://x.com/BoyuanChen0/status/1778565953627775453). This was a “cute,
 look at me” poster, but it also featured a QR code linking to the creator’s X/Twitter. While the poster itself was plac
ed on a side wall in the exhibition hall and not in an official poster spot (when I saw it anyway), it still felt odd. W
hy did they make this poster? Was this about sparking joy, or gaining attention and followers?

[Illegal Poster #1: Gene
rative Boba.](https://preview.redd.it/u3vfvszkoy6e1.jpg?width=3363&format=pjpg&auto=webp&s=8c09ddda45e0ac002223dadf0eac4
165bfdc0433)

**Illegal Poster #2:** [Benchmarkthing](https://x.com/xdotli/status/1867823150068535797)**.** This was far
 more concerning. It blatantly promoted a new AI startup, mentioning funding by a prominent figure in our field, Jeff De
an. Unlike the boba poster, this could visually pass as a real NeurIPS poster. Probably most passersby didn’t give it a 
second thought, but the poster's presenter (who is also the company’s founder) was essentially promoting his new startup
, sometimes to a significant audience size AND across *multiple* poster sessions. This feels deceptive and exploitative 
— gaming the trust of the community to cheatingly gain visibility in a sacred academic space.

[Illegal Poster #2: Bench
markthing.](https://preview.redd.it/qn7vpos4py6e1.jpg?width=2646&format=pjpg&auto=webp&s=4cfd1aa535bdf74cdb57ba8e44f1fa8
13b9d28a7)

A different type of gaming involves authors putting up their poster at unused spots while leaving a sign in 
their formally assigned location that says “See poster at #{better spot}”. If the authors for the unused spot arrived, t
hey’d just move their poster back — but if not, they would presumably revel in the extra attention from being located, f
or example, closer to the hall’s entrance with more foot traffic.

Relocating posters still seems problematic, but at le
ast the posters *belong* at the conference. On the other hand, I feel much more strongly that unauthorized posters for p
ersonal or commercial promotion hurts the integrity of the space, disrespects the presenters whose posters truly belong 
there, and undermines the conference overall.

Questions for the community:

1. Should there be stricter policies or bet
ter enforcement for poster sessions?
2. How do we differentiate between minor gaming (e.g. relocating posters) and outri
ght exploitation (e.g. unauthorized posters)?
3. Is it fair to tolerate some flexibility as long as the intentions are l
ighthearted or still academic? 
4. How do we address these behaviors moving forward? Should there be consequences?
```
---

     
 
all -  [ A little bit of drama: Pre-training is only over if you have no imagination - Logan Kilpatrick ](https://www.reddit.com/r/singularity/comments/1he9tsn/a_little_bit_of_drama_pretraining_is_only_over_if/) , 2024-12-28-0912
```
https://x.com/OfficialLoganK/status/1868002617311596552?t=uNazJ-3HPuWlBrXGagkAag&s=19

It's a slow saturday so why not s
hitpost a little.
This is in response to Ilya Sutskever's talk during NeurIPS 2024.
```
---

     
 
all -  [ A Perfect Storm for AI Inference TPU will be new king  ](https://www.reddit.com/r/Bard/comments/1he4e14/a_perfect_storm_for_ai_inference_tpu_will_be_new/) , 2024-12-28-0912
```
Ilya Sutskever's recent bombshell at NeurIPS – [https://www.theverge.com/2024/12/13/24320811/what-ilya-sutskever-sees-op
enai-model-data-training](https://www.theverge.com/2024/12/13/24320811/what-ilya-sutskever-sees-openai-model-data-traini
ng) that we've reached 'peak data' and the era of pre-training as we know it is ending – has sent ripples through the AI
 world. His vision of a future dominated by 'agentic,' reasoning AI, capable of learning from limited data, sets the sta
ge for a fundamental shift in how we develop and deploy artificial intelligence. This shift, it turns out, might just be
 the perfect storm for the rise of the TPU and Broadcom's latest chip announcement could be the catalyst. [https://www.b
roadcom.com/company/news/product-releases/62691](https://www.broadcom.com/company/news/product-releases/62691)

**Why TP
Us are Poised to Shine in a Post-'Peak Data' World:**

1. **Inference, Inference, Inference:** Sutskever's emphasis on a
 future where AI is smarter, not just bigger, puts the spotlight squarely on **inference**. This is where AI applies its
 learned knowledge to make predictions and decisions in real-world scenarios. And this is precisely where TPUs have a di
stinct advantage.
2. **Enter Broadcom: The 3.5D XDSiP and the TPU Advantage:** Broadcom's new 3.5D chip isn't just anoth
er incremental improvement; it's a potential game-changer, especially for TPUs. Its innovative design, featuring vertica
l die stacking and face-to-face interconnects, directly addresses the key challenges of inference:
   * **Latency Killer
:** By drastically reducing the distance data needs to travel, Broadcom's chip minimizes latency, enabling the rapid-fir
e calculations that TPUs are built for. This is crucial for real-time inference applications.
   * **Power Saver:** The 
3.5D architecture slashes power consumption, a critical factor for deploying TPUs in data centers and edge devices where
 energy efficiency is paramount.
   * **Density Champion:** The compact form factor allows for denser packing of TPUs, p
aving the way for more powerful and efficient inference systems.

The potential rise of TPUs, spurred by the need for mo
re efficient inference and enabled by innovations like Broadcom's, could trigger a paradigm shift, compelling all major 
players in the AI field to develop their own specialized chips and hardware solutions to remain competitive in this rapi
dly evolving landscape. This may be the dawn of the age of custom AI silicon, and potentially the beginning of the TPU e
ra.
```
---

     
 
all -  [ Ilya Sutskever, cofondateur et ancien directeur scientifique d'OpenAI, a fait une rare apparition pu ](https://www.reddit.com/r/actutech/comments/1hdxdjs/ilya_sutskever_cofondateur_et_ancien_directeur/) , 2024-12-28-0912
```
Il a notamment affirmé que le pré-entraînement des modèles tel que nous le connaissons va inévitablement prendre fin, co
mparant les données à un 'combustible fossile' limité. Selon lui, nous avons atteint un pic des données disponibles, car
 il n'existe qu'un seul internet.  
  
Pour l'avenir, il prédit que les prochaines générations d'IA seront plus 'agentiq
ues' et capables de raisonner véritablement, contrairement aux systèmes actuels qui se contentent principalement de reco
nnaître des motifs. Ces systèmes deviendront plus imprévisibles à mesure qu'ils développeront leur capacité.  
  
Il a é
galement établi un parallèle intéressant entre l'évolution de l'IA et la biologie évolutive, suggérant que l'IA pourrait
 découvrir de nouvelles approches de mise à l'échelle, tout comme l'évolution a trouvé un nouveau modèle pour le cerveau
 des hominidés.

https://preview.redd.it/2ly7b8fejr6e1.jpg?width=960&format=pjpg&auto=webp&s=ae6cfe8241a9fc37bf648d189d8
2908a8624094c


```
---

     
 
all -  [ [D] The winner of the NeurIPS 2024 Best Paper Award  sabotaged the other teams ](https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/) , 2024-12-28-0912
```
Presumably, the winner of the NeurIPS 2024 Best Paper Award (a guy from ByteDance, the creators of Tiktok) sabotaged the
 other teams to derail their research and redirect their resources to his own. Plus he was at meetings debugging his col
leagues' code, so he was always one step ahead. There's a call to withdraw his paper.

[https://var-integrity-report.git
hub.io/](https://var-integrity-report.github.io/)

I have not checked the facts themselves, so if you can verify what is
 asserted and if this is true this would be nice to confirm.
```
---

     
 
all -  [ Feels good to see Mr.X getting noted ](https://i.redd.it/oexht6c8rg6e1.jpeg) , 2024-12-28-0912
```
Link: https://x.com/elonmusk/status/1866797259968614885?s=46
```
---

     
 
all -  [ and now we know why Elon named his stupid AI 'Grok'  ](https://i.redd.it/j0pk4yr54f6e1.png) , 2024-12-28-0912
```
also why does the chart go all the way back to 1991
```
---

     
 
all -  [ 
New framework for quantifying uncertainty in LLMs: Semantic Density ](https://www.reddit.com/r/airesearch/comments/1hc6fez/new_framework_for_quantifying_uncertainty_in_llms/) , 2024-12-28-0912
```
Can we trust LLMs in high-stakes decisions? Cognizant AI Research Lab introduces Semantic Density, a scalable framework 
to quantify response-specific uncertainty without retraining. Tested on state-of-the-art models, it outperforms existing
 methods on benchmarks. Presented at NeurIPS 2024—let’s discuss: [https://medium.com/@evolutionmlmail/quantifying-uncert
ainty-in-llms-with-semantic-density-ff0e58836416](https://medium.com/@evolutionmlmail/quantifying-uncertainty-in-llms-wi
th-semantic-density-ff0e58836416)


```
---

     
 
all -  [ How well-informed Elon Musk is when he makes a statement ](https://www.reddit.com/r/EnoughMuskSpam/comments/1hc415l/how_wellinformed_elon_musk_is_when_he_makes_a/) , 2024-12-28-0912
```
https://preview.redd.it/ekphsq71aa6e1.png?width=798&format=png&auto=webp&s=025884971824e9394aa64d398c70b1d44da62083


```
---

     
 
MachineLearning -  [ [D] How to make friends and network at NeurIPS? ](https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/) , 2024-12-28-0912
```
I’m attending NeurIPS for the first time and it’s quite overwhelming seeing the amount of people and so many recruiters.
 I come from a not so well known university, and have come to the conference completely alone, not even my supervisor is
 here.

I didn’t really end up talking to many other attendees or recruiters because (1) it just seemed hard to approach
 others who are in big groups of people and (2) I’m feeling strong imposter syndrome and under-qualified for the jobs re
cruiters offer. I only got a workshop paper accepted that is more application and not as technical as many of the other 
students.

Any advice for how I can make the most of the rest of the conference? On that note, would anyone also want to
 potentially meet up and have a chat? I’m a 3rd year PhD student from the UK, but from Vancouver myself so know lots of 
stuff going on in the area. Cheers!
```
---

     
 
MachineLearning -  [ [R] Improving robustness to corruptions with multiplicative weight perturbations - A simple yet effe ](https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/) , 2024-12-28-0912
```
We would like to share and discuss this NeurIPS spotlight paper (disclaimer: I am a co-author).

**Paper**: [https://arx
iv.org/abs/2406.16540](https://arxiv.org/abs/2406.16540)  
**GitHub**: [https://github.com/trungtrinh44/DAMP](https://gi
thub.com/trungtrinh44/DAMP)  
**DAMP** (Data augmentation via multiplicative perturbations) is a simple yet effective ap
proach to improving neural network robustness through multiplicative weight perturbations. Unlike traditional data augme
ntation methods, DAMP operates directly on model weights during training, enabling improved corruption robustness withou
t compromising clean image performance or increasing computational cost.  
  
**Key Highlights:**

* **Theoretical Found
ation**: DAMP demonstrates that input corruptions can be equivalently represented as multiplicative weight perturbations
, providing a theoretical basis for weight-space data augmentation.
* **Simple Implementation**: The method requires onl
y random Gaussian sampling and pointwise multiplication, maintaining almost the same training cost as standard SGD while
 being fully compatible with data parallelism.
* **Breakthrough in ViT Training**: Successfully trains Vision Transforme
rs from scratch using only basic preprocessing, achieving ResNet50-level performance (23.7% top-1 error) on ImageNet wit
hout complex augmentations.
* **Advanced Integration**: When combined with MixUp and RandAugment, DAMP significantly imp
roves both clean and corruption performance:
   * ViT-S/16: 20.09% clean error (vs 20.25% baseline), 58.30% avg corrupti
on error (vs 60.07% baseline)
   * ViT-B/16: 19.36% clean error (vs 20.41% baseline), 56.76% avg corruption error (vs 58
.83% baseline)

**Why DAMP?** Unlike traditional approaches that rely on complex data augmentation pipelines or computat
ionally expensive ensemble methods, DAMP provides a simple, theoretically-grounded solution to improving model robustnes
s. Its ability to train Vision Transformers from scratch without advanced augmentations and compatibility with existing 
techniques makes it a practical choice for developing robust vision models.  
**Since DAMP has minimal overhead over sta
ndard training, it is particularly effective when applied to large models and datasets.**  
  
We welcome technical disc
ussions, particularly regarding theoretical connections to other robustness methods and potential applications beyond co
mputer vision!
```
---

     
