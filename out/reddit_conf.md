 
all -  [ [D] The winner of the NeurIPS 2024 Best Paper Award  sabotaged the other teams ](https://www.reddit.com/r/MachineLearning/comments/1hctf36/d_the_winner_of_the_neurips_2024_best_paper_award/) , 2024-12-13-0914
```
Presumably, the winner of the NeurIPS 2024 Best Paper Award (a guy from ByteDance, the creators of Tiktok) sabotaged the
 other teams to derail their research and redirect their resources to his own. Plus he was at meetings debugging his col
leagues' code, so he was always one step ahead. There's a call to withdraw his paper.

[https://var-integrity-report.git
hub.io/](https://var-integrity-report.github.io/)

I have not checked the facts themselves, so if you can verify what is
 asserted and if this is true this would be nice to confirm.
```
---

     
 
all -  [ Feels good to see Mr.X getting noted ](https://i.redd.it/oexht6c8rg6e1.jpeg) , 2024-12-13-0914
```
Link: https://x.com/elonmusk/status/1866797259968614885?s=46
```
---

     
 
all -  [ Musk does a lot of 'research' before he makes a claim in X ](https://www.reddit.com/gallery/1hcqya9) , 2024-12-13-0914
```

```
---

     
 
all -  [ and now we know why Elon named his stupid AI 'Grok'  ](https://i.redd.it/j0pk4yr54f6e1.png) , 2024-12-13-0914
```
also why does the chart go all the way back to 1991
```
---

     
 
all -  [ 
New framework for quantifying uncertainty in LLMs: Semantic Density ](https://www.reddit.com/r/airesearch/comments/1hc6fez/new_framework_for_quantifying_uncertainty_in_llms/) , 2024-12-13-0914
```
Can we trust LLMs in high-stakes decisions? Cognizant AI Research Lab introduces¬†Semantic Density, a scalable framework 
to quantify response-specific uncertainty without retraining. Tested on state-of-the-art models, it outperforms existing
 methods on benchmarks. Presented at NeurIPS 2024‚Äîlet‚Äôs discuss: [https://medium.com/@evolutionmlmail/quantifying-uncert
ainty-in-llms-with-semantic-density-ff0e58836416](https://medium.com/@evolutionmlmail/quantifying-uncertainty-in-llms-wi
th-semantic-density-ff0e58836416)


```
---

     
 
all -  [ How well-informed Elon Musk is when he makes a statement ](https://www.reddit.com/r/EnoughMuskSpam/comments/1hc415l/how_wellinformed_elon_musk_is_when_he_makes_a/) , 2024-12-13-0914
```
https://preview.redd.it/ekphsq71aa6e1.png?width=798&format=png&auto=webp&s=025884971824e9394aa64d398c70b1d44da62083


```
---

     
 
all -  [ Can research projects be replacement for internships in North America? ](https://www.reddit.com/r/csMajors/comments/1hc391a/can_research_projects_be_replacement_for/) , 2024-12-13-0914
```
I'm not a computer science major but do have extensive technical background (I'm in cognitive science with a computer sc
ience minor.) I've completed a research project for credit under a big name in cognitive science and it involved CNNs. I
 aim to refine the project so that I can submit it to a journal or a good conference (NeurIPS maybe!) I've also done thi
s unpaid internship thing from back home under a research organization my father knows very well and it too was technica
l in nature. I presented the research at a big psychology conference. I'm also volunteering at a computational psychiatr
y lab as a technical reviewer.

That being said, how much are research projects worth when finding full-time jobs, even 
the ones that are published or presented at conferences? I'm graduating next May. I haven't gotten any internships throu
ghout my undergrad, only got technical assessments without any interviews.

Edit: My GPA is bad because of long-term men
tal health issues
```
---

     
 
all -  [ [D] How to make friends and network at NeurIPS? ](https://www.reddit.com/r/MachineLearning/comments/1hc0x89/d_how_to_make_friends_and_network_at_neurips/) , 2024-12-13-0914
```
I‚Äôm attending NeurIPS for the first time and it‚Äôs quite overwhelming seeing the amount of people and so many recruiters.
 I come from a not so well known university, and have come to the conference completely alone, not even my supervisor is
 here.

I didn‚Äôt really end up talking to many other attendees or recruiters because (1) it just seemed hard to approach
 others who are in big groups of people and (2) I‚Äôm feeling strong imposter syndrome and under-qualified for the jobs re
cruiters offer. I only got a workshop paper accepted that is more application and not as technical as many of the other 
students.

Any advice for how I can make the most of the rest of the conference? On that note, would anyone also want to
 potentially meet up and have a chat? I‚Äôm a 3rd year PhD student from the UK, but from Vancouver myself so know lots of 
stuff going on in the area. Cheers!
```
---

     
 
all -  [ NeurIPS 2024: What Matters When Building Vision Language Models ](https://www.reddit.com/r/computervision/comments/1hb2zk0/neurips_2024_what_matters_when_building_vision/) , 2024-12-13-0914
```
Check out [Harpreet Sahota‚Äôs](https://www.linkedin.com/in/harpreetsahota204/) conversation with [Hugo Lauren√ßon](https:/
/www.linkedin.com/in/hugo-lauren%C3%A7on/) of Sorbonne Universit√© and Hugging Face about his NeurIPS 2024 paper, ‚ÄúWhat M
atters When Building Vision Language Models.‚Äù

* [Complete paper presentation and Q&A on YouTube](https://www.youtube.co
m/watch?v=OfbsZeBBFrg)
* [Research paper on arXiv](https://arxiv.org/abs/2405.02246)

  
Preview video below:

https://r
eddit.com/link/1hb2zk0/video/9ebds5l7716e1/player


```
---

     
 
all -  [ NeurIPS is starting tomorrow but I‚Äôm too young to go thereüò≠üò≠üò≠ ](https://www.reddit.com/r/teenagers/comments/1haqs1i/neurips_is_starting_tomorrow_but_im_too_young_to/) , 2024-12-13-0914
```
It‚Äôs right where I live as well
```
---

     
 
all -  [ [R] Improving robustness to corruptions with multiplicative weight perturbations - A simple yet effe ](https://www.reddit.com/r/MachineLearning/comments/1hap6gx/r_improving_robustness_to_corruptions_with/) , 2024-12-13-0914
```
We would like to share and discuss this NeurIPS spotlight paper (disclaimer: I am a co-author).

**Paper**:¬†[https://arx
iv.org/abs/2406.16540](https://arxiv.org/abs/2406.16540)  
**GitHub**:¬†[https://github.com/trungtrinh44/DAMP](https://gi
thub.com/trungtrinh44/DAMP)  
**DAMP**¬†(Data augmentation via multiplicative perturbations) is a simple yet effective ap
proach to improving neural network robustness through multiplicative weight perturbations. Unlike traditional data augme
ntation methods, DAMP operates directly on model weights during training, enabling improved corruption robustness withou
t compromising clean image performance or increasing computational cost.  
  
**Key Highlights:**

* **Theoretical Found
ation**: DAMP demonstrates that input corruptions can be equivalently represented as multiplicative weight perturbations
, providing a theoretical basis for weight-space data augmentation.
* **Simple Implementation**: The method requires onl
y random Gaussian sampling and pointwise multiplication, maintaining almost the same training cost as standard SGD while
 being fully compatible with data parallelism.
* **Breakthrough in ViT Training**: Successfully trains Vision Transforme
rs from scratch using only basic preprocessing, achieving ResNet50-level performance (23.7% top-1 error) on ImageNet wit
hout complex augmentations.
* **Advanced Integration**: When combined with MixUp and RandAugment, DAMP significantly imp
roves both clean and corruption performance:
   * ViT-S/16: 20.09% clean error (vs 20.25% baseline), 58.30% avg corrupti
on error (vs 60.07% baseline)
   * ViT-B/16: 19.36% clean error (vs 20.41% baseline), 56.76% avg corruption error (vs 58
.83% baseline)

**Why DAMP?**¬†Unlike traditional approaches that rely on complex data augmentation pipelines or computat
ionally expensive ensemble methods, DAMP provides a simple, theoretically-grounded solution to improving model robustnes
s. Its ability to train Vision Transformers from scratch without advanced augmentations and compatibility with existing 
techniques makes it a practical choice for developing robust vision models.  
**Since DAMP has minimal overhead over sta
ndard training, it is particularly effective when applied to large models and datasets.**  
  
We welcome technical disc
ussions, particularly regarding theoretical connections to other robustness methods and potential applications beyond co
mputer vision!
```
---

     
 
all -  [ NeurIPS 2024 - Creating SPIQA: Addressing the Limitations of Existing Datasets for Scientific VQA ](https://www.reddit.com/r/computervision/comments/1ha9cup/neurips_2024_creating_spiqa_addressing_the/) , 2024-12-13-0914
```
Check out¬†[Harpreet Sahota](https://www.linkedin.com/in/harpreetsahota204/)‚Äôs conversation with¬†[Shraman Pramanick](http
s://www.linkedin.com/in/shramanpramanick/)¬†of Johns Hopkins University and Meta AI about his NeurIPS 2024 paper, ‚ÄúCreati
ng SPIQA: Addressing the Limitations of Existing Datasets for Scientific VQA.‚Äù

* [Complete paper presentation and Q&A o
n YouTube](https://youtu.be/p56kAbdYtUg)
* [Research paper on arXiv](https://arxiv.org/abs/2407.09413)

Preview video:


https://reddit.com/link/1ha9cup/video/z1vatdr5ot5e1/player

  

```
---

     
 
all -  [ NeurIPS 2024 - No ‚ÄúZero-Shot‚Äù Without Exponential Data: Pretraining Concept Frequency Determines Mul ](https://www.reddit.com/r/computervision/comments/1h9q0x1/neurips_2024_no_zeroshot_without_exponential_data/) , 2024-12-13-0914
```
Check out [Harpreet Sahota](https://www.linkedin.com/in/harpreetsahota204/)‚Äôs conversation with [Vishaal Udandarao](http
s://www.linkedin.com/in/vishaal-udandarao/) of the University of T√ºbingen and Cambridge about his NeurIPS 2024 paper, ‚ÄúN
o 'Zero-Shot' Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance.‚Äù

* [Comp
lete paper presentation and Q&A on YouTube](https://youtu.be/_4cQJmz2u1c)
* [Research paper on arXiv](https://arxiv.org/
abs/2404.04125)

Preview video:

https://reddit.com/link/1h9q0x1/video/pcw40i25ao5e1/player
```
---

     
 
all -  [ NeurIPS 2024: A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis ](https://www.reddit.com/r/computervision/comments/1h82qz6/neurips_2024_a_textbook_remedy_for_domain_shifts/) , 2024-12-13-0914
```
Check out [Harpreet Sahota‚Äôs](https://www.linkedin.com/in/harpreetsahota204/) conversation with [Yue Yang](https://www.l
inkedin.com/in/yue-yang-4b2075174) of the University of Pennsylvania and AI2 about his NeurIPS 2024 paper, ‚ÄúA Textbook R
emedy for Domain Shifts: Knowledge Priors for Medical Image Analysis.‚Äù

* [Complete paper presentation and Q&A on YouTub
e](https://youtu.be/VjJWOQHgsmk)
* [Research paper on arXiv](https://arxiv.org/abs/2405.14839)

Video preview below:

ht
tps://reddit.com/link/1h82qz6/video/lintlyfuo85e1/player
```
---

     
 
all -  [ NeurlPS 2024: NaturalBench - Evaluating Vision-Language Models on Natural Adversarial Samples ](https://www.reddit.com/r/computervision/comments/1h7f4k2/neurlps_2024_naturalbench_evaluating/) , 2024-12-13-0914
```
Check out [Harpreet Sahota](https://www.linkedin.com/in/harpreetsahota204/)‚Äôs conversation with [Zhiqiu Lin](https://www
.linkedin.com/in/zhiqiu-lin-b49ba7126/) of Carnegie Mellon University about his NeurIPS 2024 paper, ‚ÄúNaturalBench: Evalu
ating Vision-Language Models on Natural Adversarial Samples.‚Äù

* [Complete interview and discussion on YouTube](https://
youtu.be/eFfdo4vZIic)
* [Research paper on arXiv](https://youtu.be/eFfdo4vZIic)

Video preview below:

https://reddit.co
m/link/1h7f4k2/video/6mw2ahngi25e1/player

  

```
---

     
 
all -  [ Former Intern Sabotages ByteDance‚Äôs AI Training, Faces ¬•8 Million Lawsuit, Yet Wins NeurIPS 2024 Bes ](https://www.reddit.com/r/LocalLLaMA/comments/1h6i1m9/former_intern_sabotages_bytedances_ai_training/) , 2024-12-13-0914
```
In October 2024, media outlets reported that 'ByteDance's large-scale model training was attacked by an intern,' and onl
ine sources claimed that 'over 8,000 GPUs were involved, resulting in losses exceeding tens of millions of dollars.' Byt
eDance later issued an official statement to clarify the situation, confirming that a serious infraction did occur invol
ving an intern. The intern in question was terminated by the company in August 2024.

[ByteDance Official Statement](htt
ps://preview.redd.it/uvwtbcqyhu4e1.png?width=785&format=png&auto=webp&s=3b9040d2ac1f03c5c0c2d279b61704c4997a438d)

ByteD
ance's lawsuit against former intern Tian for tampering with code and attacking the company's internal model training ha
s been officially accepted by the Haidian District People's Court in Beijing. ByteDance is requesting the court to order
 Tian to compensate the company for damages amounting to ¬•8 million, along with reasonable expenses of ¬•20,000, and to p
ublicly issue an apology.

Recently, the intern who maliciously attacked ByteDance's training cluster, Keyu Tian, receiv
ed the NeurIPS 2024 Best Paper Award. [Paper](https://arxiv.org/abs/2404.02905) [Github](https://github.com/FoundationVi
sion/VAR)

https://preview.redd.it/4hfxwbkcju4e1.png?width=1802&format=png&auto=webp&s=ec79a9a1b49bbd1e329c6b7560e74a415
907dff1

Coincidentally, this award-winning paper was the result of his collaboration with the team during his internshi
p in ByteDance's Commercialization Technology Department.
```
---

     
 
all -  [ NeurIPS 2024 - A Label is Worth a Thousand Images in Dataset Distillation ](https://www.reddit.com/r/computervision/comments/1h6hx3p/neurips_2024_a_label_is_worth_a_thousand_images/) , 2024-12-13-0914
```
https://reddit.com/link/1h6hx3p/video/k7wh8qlfiu4e1/player

Check out¬†[Harpreet Sahota‚Äôs](https://www.linkedin.com/in/ha
rpreetsahota204/)¬†conversation with¬†[Sunny Qin](https://www.linkedin.com/in/sunnytqin/)¬†of Harvard University about her 
NeurIPS 2024 paper, 'A Label is Worth a Thousand Images in Dataset Distillation.‚Äù

https://i.redd.it/mg9isc68iu4e1.gif


* [Complete interview and discussion on YouTube](https://www.youtube.com/watch?v=9TdDJ9J-VZI)
* [Research Paper](https:/
/arxiv.org/abs/2406.10485)
```
---

     
 
all -  [ I have reasons to believe that Recursion (RXRX) will became quite popular in the next month. ](https://www.reddit.com/r/wallstreetbets/comments/1h1volv/i_have_reasons_to_believe_that_recursion_rxrx/) , 2024-12-13-0914
```
I believe that in the future, drugs will be highly customisable based on the patience‚Äôs health history. Based on your ph
ysiology, syndromes, and genetics, you may receive a drug that is well-suited for you and only you. 

How can you do tha
t? First and foremost, you need data, huge amounts of it. We all know how generative and predictive models had advanced 
in the last year. It wasn‚Äôt in fact, until the launch of AlphaFold (by Google, whose team was recently awarded with the 
Chemistry Nobel Prize), that AI drug discovery became prominent. This open source model is used for molecular discovery.
 Again, would be nice if a company could:

1. Generate proprietary synthetic, good quality molecular data using models l
ike AlphaFold.
2. Using this data to train models for drug discovery, reducing pipelines costs and times up to 50%.
3. E
ventually, with the possibility of bringing the first AI-aided drug to the market.

First two points have been achieved,
 and the company is Recursion. We may know them because NVIDIA invested 50m in them. Why then are at ATL? I think the an
swer is time. We all know there is no room for patience when it comes to money sometimes. Training and bringing such res
ults may take years.

However, I think another catalyst is coming. On 9. December, they will host a seminar for new read
outs in one of their most well-known drugs in development, CDK7, for advance solid tumours (an inhibitor, which are curr
ently none approved by the FDA).

Now, I am not saying that they will cure cancer - that‚Äôs BS. But over the years conver
ging to novel oncological solutions using AI? This is not the only drug they have (other 9 are in development).

They ha
ve more than 60 petabytes of data.
They combined forces with Exscientia recently, forming probably the most important po
werhouse of AI-drug research.
They are extremely active in the research field (see their presence in the upcoming NeuRIP
S conference) or their new open dataset for Quantum Computing (OpenQDC).

I started investing in IONQ in 2021 for a simi
lar impression. Now I am getting the same vibes with this. I feel that a small catalyst will put this to fly, although t
he real potencial will come in the next 5-10 years. If they can bring the first AI drug to the market,  this implodes.


Of course, no financial advice. I‚Äôm long 800 shares and loading as much as I possibly can.
```
---

     
 
all -  [ can I attend neurips as an enthusiast?  ](https://www.reddit.com/r/MLQuestions/comments/1h1kw31/can_i_attend_neurips_as_an_enthusiast/) , 2024-12-13-0914
```
neurips is coming to my hometown, can I just go? I want to hunt down all the recruiters lol 
```
---

     
 
all -  [ [0 YoE, Unemployed, Machine Learning Research Intern, Serbia] ](https://www.reddit.com/r/resumes/comments/1h0jscl/0_yoe_unemployed_machine_learning_research_intern/) , 2024-12-13-0914
```
&#x200B;

[CV](https://preview.redd.it/hv5mq2zkma3e1.png?width=5100&format=png&auto=webp&s=5afe5f21d9ec107c2f5d6cafffd7e
e872ebaa606)

Hello, I hope you are doing well!

I am a second year undergraduate student seeking to land a machine lear
ning research intern position next summer. The CV up there is shrunk to be 1-page length and contains only the most mach
ine learning-related stuff I have created in the past year.  
I am curious in what ways could this CV be bettered and de
tails provided, so I can increase my chances. I have already gotten plenty of industry offers, but I would like to maxim
ize my chances for research positions.

I am very much so aware that, after the second year of undergraduate studies, it
 is very hard to land one, but in case it happens, it can kickstart my career a lot.

I am also interested whether I sho
uld add 2 work in progress papers that I am aiming to publish in the following months - one is related to graph neural n
etworks in medicine, while the other is related to graph neural networks and categorical deep learning.

Thank you in ad
vance - every advice is helpful and appreciated!
```
---

     
 
all -  [ MS Thesis project at IBM Research-Zurich ](https://www.reddit.com/r/ethz/comments/1gzk140/ms_thesis_project_at_ibm_researchzurich/) , 2024-12-13-0914
```
Dear MS Students,

We have an opportunity for an MS Thesis project at IBM Research-Zurich. ¬†

**Project description:** D
espite the breakthrough made by large language models (LLMs), they struggle with high-level reasoning tasks requiring de
liberate thinking and problem-solving skills. Particularly, the pretrained state-of-the-art Transformer language models 
fail at compositional generalization, multi-step deductive reasoning, and analogical reasoning \[1, 2, 3\]. As a potenti
al alternative, neuro-symbolic AI seeks complementary approaches that beneficially combine deep learning advancements wi
th symbolic computations to endorse their strengths and supplement their weaknesses. Key challenges in neuro-symbolic AI
 involve the potentially exponential time required to perform probabilistic inference and the difficulty in learning new
 symbolic programs. Our latest research results addressed these challenges by performing analogical reasoning over distr
ibuted representations \[4,5\]. In this project, the main objective is to develop methods that reduce the computational 
bottleneck in general neuro-symbolic AI systems, while maintaining learning rules/programs that exhibit out-of-distribut
ion generalization, flexibility, and interpretability. Other inputs or directions are welcomed.

**Requirements:** Stron
g motivation and self-drive. Strong analytical and problem-solving skills. Concrete knowledge in deep learning, or a sol
id background in machine learning. Experience with TensorFlow or PyTorch frameworks. Expertise with LLMs is an advantage
.

**Some administrative information:**  
o Earliest start date: Feb 2025  
o Duration: 6 months  
o Pay: None (prohibit
ed from ETH)

The thesis will be performed at the IBM Research-Zurich in R√ºschlikon. If you are interested in this chall
enging position on an exciting new topic, please send your most recent curriculum vitae including a transcript of BS and
 MS grades by email to: Dr. Michael Hersche ([her@zurich.ibm.com](mailto:her@zurich.ibm.com)) and Dr. Abbas Rahimi ([abr
@zurich.ibm.com](mailto:abr@zurich.ibm.com))

\[1\] N. Dziri et al., ‚ÄòFaith and Fate: Limits of Transformers on Composit
ionality‚Äô, *Advances in* *Neural Information Processing Systems (NeurIPS),* 2023.

\[2\] J. Thomm et al., ‚ÄòLimits of Tra
nsformer Language Models on Learning to Compose Algorithms‚Äô, *Advances in* *Neural Information Processing Systems (NeurI
PS),* 2024.

\[3\] X. Chen, et al., ‚ÄòPremise Order Matters in Reasoning with Large Language Models‚Äô, *ICML*, 2024.

\[4\
] M. Hersche, et al., ‚ÄòA Neuro-Vector-Symbolic Architecture for Solving Raven‚Äôs Progressive Matrices‚Äô, *Nature Machine I
ntelligence*, 2023.

\[5\] G. Camposampiero, et al., ‚ÄòTowards Learning Abductive Reasoning using VSA Distributed Represe
ntations‚Äô, *International Conference on Neural-Symbolic Learning and Reasoning (NeSy*), 2024.
```
---

     
 
all -  [ Should i even try for my chances or is it just a waste of time applying with poor grades . Can my SO ](https://www.reddit.com/r/Indians_StudyAbroad/comments/1gzec5d/should_i_even_try_for_my_chances_or_is_it_just_a/) , 2024-12-13-0914
```
I have completed my undergrad from Osmania University (VCE) in electronics and communications ( a tier 2 ish college in 
India )

I have a very low GPA ( 3.18 / 4 ) , I have graduated in 2024 and am aspiring to apply for fall 2026 .

I have 
had severe health issues during my undergrad and did a lot of community outreach programs in my sophomore year , My grad
es were good in my junior year but it was just downhill after that , I was suffering from many health issues which spoil
ed my grades but got recovered in final year and had good grades.

After my health recovered I worked like hell and alre
ady published 4 papers in IEEE conferences and 2 in smaller conferences

**I am currently working at AT&T as senior asso
ciate software engineer with the field being machine learning . I have applied to CVPR 2025 conference and am sure of ge
tting my paper published there , I have 3 more papers ready for ICML and NeurIPS as well , these are the top most confer
ences in ML in the entire world . I am sure of having at least 15 paers published by end of 2025 ( 5 are Q1 level ) . I 
have 3 patents on my name and aspire to get more . It took me sleepless nights during my final year to accomplish all of
 this after my health recovered**

My\_qualifications :

2 research internships , strong LOR's from top international un
iversities where I worked with a professor , aiming to do at least 2 more internships at labs by end of 2025

Can I conv
ince the admission committee that my health affected my grades and can the other strong part of backup my grades part in
 my SOP or is it just a waste of time applying ??

dream target univs - Caltech MS EE ( ML track ) , Stanford MS EE ( ML
 track ) , Stanford MS CS

I recently read this¬†[https://www-cs.stanford.edu/\~rkarthik/DAGAP.pdf](https://www-cs.stanfo
rd.edu/~rkarthik/DAGAP.pdf)¬†where the writer says low GPA will be immediately rejected . Should i even try building my p
rofile or give up hope ?

Stanford and Caltech have been my dream univs since many years and life seems meaningless with
out them , I really need serious advice if i have to give up hope and change my path or still build profile . i have one
 year of time to apply .
```
---

     
 
all -  [ Should i even try ? ](https://www.reddit.com/r/gradadmissions/comments/1gze93d/should_i_even_try/) , 2024-12-13-0914
```
I have completed my undergrad from Osmania University (VCE) in electronics and communications ( a tier 2 ish college in 
India ) 



I have a very low GPA ( 3.18 ) , I have graduated in 2024 and am aspiring to apply for fall 2026 .

 I have 
had severe health issues during my undergrad and did a lot of community outreach programs in my sophomore year , My grad
es were good in my junior year but it was just downhill after that , I was suffering from many health issues which spoil
ed my grades but got recovered in final year and had good grades. 

After my health recovered I worked like hell and alr
eady published 4 papers in IEEE conferences and 2 in smaller conferences

**I am currently working at AT&T as senior ass
ociate software engineer with the field being machine learning . I have applied to CVPR 2025 conference and am sure of g
etting my paper published there , I have 3 more papers ready for ICML and NeurIPS as well , these are the top most confe
rences in ML in the entire world . I am sure of having at least 18 papers published by end of 2025 ( 5 are Q1 level ) . 
I have 3 patents on my name and aspire to get more . It took me sleepless nights during my final year to accomplish all 
of this after my health recovered**



other profile aspects -

2 research internships , strong LOR's from top internati
onal universities where I worked with a professor , aiming to do at least 2 more internships at labs by end of 2025

Can
 I convince the admission committee that my health affected my grades and can the other strong part of backup my grades 
part in my SOP or is it just a waste of time applying ??

dream target univs - Caltech MS EE ( ML track ) , Stanford MS 
EE ( ML track ) , Stanford MS CS

I recently read this [https://www-cs.stanford.edu/\~rkarthik/DAGAP.pdf](https://www-cs
.stanford.edu/~rkarthik/DAGAP.pdf) where the writer says low GPA will be immediately rejected . Should i even try buildi
ng my profile or give up hope ?

Stanford and Caltech have been my dream univs since many years and life seems meaningle
ss without them , I really need serious advice if i have to give up hope and change my path or still build profile . i h
ave one year of time to apply .
```
---

     
 
all -  [ Should I even apply for a PhD? ](https://www.reddit.com/r/PhD/comments/1gy1xp7/should_i_even_apply_for_a_phd/) , 2024-12-13-0914
```
Hi all

So I (23M, Indian) had the dream to pursue a MS+PhD in CS (AI) in the US (No masters, I just have a Bachelors de
gree in Electronics Engineering). I was aiming to get into universities like UCSD, John Hopkins, UIUC.

To make it happe
n, I applied to Indian professors and worked with them. Have spent over 1 year working in research, while managing my so
ftware engineering job in parallel. Got one paper published in ICPR 2024, and one in a small conference, not a big deal.
 I have managed to gather 3 Letters of Recommendation after working.

However, from some sample SOPs on the net, I see t
hat the applicants for these colleges have already 1st author publications in top-tier conferences like AAAI, NeurIPS et
c.

In this scenario, should I even apply? I feel like I have no chance to compete with these people. Am I aiming for to
o high? What would you suggest?

Thank you everyone.

  
Edit 1

Thank you everyone. I got overwhelmed by everything and
 became tensed. I will curate and apply. Whatever happens next, will happen. Let me do my part at least. thanks!
```
---

     
 
all -  [ [D] Accepted NeurIPS 2024 paper claimed to be solving a novel problem as first work, but ignores 5 p ](https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/) , 2024-12-13-0914
```
At NeurIPS 2024 I found a paper that got accepted that positions its main contribution in the form of ‚ÄúExisting algorith
ms for X ignore Y. We adapt algorithm Z for X to account for Y‚Äù.

On OpenReview I see that the reviewers in particular p
raised the novelty of the work, and recognised Y as an important aspect that had been ignored in the field of X.

Now th
e interesting bit: co-authors and I published a paper in Springer‚Äôs Machine Learning journal in 2023 that also proposes 
an algorithm for X that account for Y. We were also not the first to study the problem setting of X with Y: our paper‚Äôs 
related work section discusses 4 papers that have all proposed algorithms for X that account for Y. One is even from Neu
rIPS (2017), and the oldest one dates back to 2012 (an AAAI paper).

The authors of this 2024 NeurIPS paper completely m
issed all this prior literature and believed they were the first, and so did all the reviewers.

This week I e-mailed th
e authors of this NeurIPS 2024 paper and they acknowledged that these works (mine + the 4 others) indeed were all workin
g on the same problem setting, mentioned that they were unaware of all these works, and acknowledged that they can no lo
nger claim novelty of the problem setting.

NeurIPS allows updating the camera ready paper after the conference, and the
 authors promised to use this opportunity to incorporate those related works and modify their contribution statements to
 no longer claim novelty of a first solution of X with Y.

At the one hand, it makes me happy that our work will get cre
dited appropriately.

At the other hand I have my doubts about the ethics of severely modifying contribution statements 
post-review. The authors will no longer claim novelty, but the reviewers in particular praised this novelty, which makes
 me uncertain whether reviewers would have recommended acceptance had they known that this paper will ultimately no long
er be able to claim the novelty that it claimed to have in the reviewed version.

Moreover this makes me wonder about th
e experimental section. Almost surely, reviewers would have demanded comparison to those 5 prior works as baselines. Thi
s paper did not compare against baselines, which will have seemed reasonable to a reviewer who reviewed this work under 
the assumption that the problem setting was completely novel and no prior methods exist that could function as a baselin
e.

Asking the group here about any thoughts on how such cases should get resolved:
- should the paper be retracted?
- s
hould the area chair / program committee be informed? who may or may not take action
- should the paper just get updated
 by authors in the way that was promised, and that is it?
- something else?

I redacted X, Y and Z in order to not publi
cly shame the authors, as they have engaged with my e-mails and I am convinced that there is no foul play and they truly
 were unaware of those works.
```
---

     
 
all -  [ Does anyone function more as a 'applied scientist' but have no research background? ](https://www.reddit.com/r/datascience/comments/1gxhjfr/does_anyone_function_more_as_a_applied_scientist/) , 2024-12-13-0914
```
**TLDR: DS profile is shifting to be more ML heavy, but lack research experience to compete with ML specialists.**

I've
 been a DS for several years, mostly in jack-of-all-trades functions: large-scale pipeline building, ad-hoc/bespoke stat
istical modeling for various stakeholders, ML applications, etc. More recently, I've started on a lot more GenAI/LLM wor
k alongside applied scientists. Leaving aside the negativity on LLM hype, most of the AS folks have heavy research backg
rounds: either PhDs or publications, attendance at conferences like ICLR, CVPR, NeurIPS, etc. I don't have any research 
experience except for a short stint in a lab during grad school but was never published. Luckily my AS peers have treate
d me as their own, which is good from credibility perspective.

That said, when I look at the market, DS jobs are either
 heavy on product analytics (hypothesis testing, experimentation, product sense, etc.) or DA/BI (dashboards, reporting, 
vis, etc.). The ones that are ML-heavier generally want much more research experience and involvement. I can explain the
 theory behind transformers, attention, decoders vs. encoders, etc. but I have zero publications and wouldn't stand a ch
ance against people with much deeper ML research experience.

I guess what I'm looking for is an applied/ML scientist-ad
jacent role, but still gives opportunity to flex to occasionally support other functions, like TPM'ing, DE, MLOps, etc. 
Aside from startups, there doesn't seem to be much out there. Anyone else?
```
---

     
 
all -  [ All the test environments used to benchmark BALROG. ](https://www.reddit.com/r/agi/comments/1gwqhry/all_the_test_environments_used_to_benchmark_balrog/) , 2024-12-13-0914
```
# BabyAI

+ Purpose is to facilitate research on *grounded language learning.*  The current domain of BabyAI is a 2D gri
dworld in which synthetic natural-looking instructions (e.g. ‚Äúput the red ball next to the box on your left‚Äù) require th
e agent to navigate the world including unlocking doors) and move objects to specified locations.  

https://openreview.
net/forum?id=rJeXCo0cYX

----

# Crafter

+ Crafter features randomly generated 2D worlds where the player needs to fora
ge for food and water, find shelter to sleep, defend against monsters, collect materials, and build tools.

https://gith
ub.com/danijar/crafter?tab=readme-ov-file


----

# TextWorld

+ Microsoft TextWorld is an open-source, extensible engin
e that both generates and simulates text games. You can use it to train reinforcement learning (RL) agents to learn skil
ls such as language understanding and grounding, combined with sequential decision making.

https://www.microsoft.com/en
-us/research/project/textworld/

https://github.com/microsoft/TextWorld

https://arxiv.org/pdf/1806.11532

----

# Baba 
is AI 

+ Humans solve problems by following existing rules and procedures, and also by leaps of creativity to redefine 
those rules and objectives.    We test three ***state-of-the-art multi-modal large language models (OpenAI GPT-4o, Googl
e Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail dramatically*** when generalization requires that the rul
es of the game must be manipulated and combined. 


https://github.com/nacloos/baba-is-ai

https://arxiv.org/abs/2407.13
729

----

# MiniHack

+ MiniHack is a sandbox framework for easily designing rich and diverse environments for Reinforc
ement Learning (RL).   The motivation behind MiniHack is to be able to perform RL experiments in a controlled setting wh
ile being able to increasingly scale the complexity of the tasks.

https://github.com/facebookresearch/minihack

https:/
/minihack.readthedocs.io/en/latest/


----

# NetHack

+ NetHack is an attractive research platform as it contains hundr
eds of enemy and object types, has complex and stochastic environment dynamics, and has a clearly defined goal (descend 
the dungeon, retrieve an amulet, and ascend) which can be achieved in a diverse set of ways. The game is considered one 
of the hardest in the world1, with winning episodes lasting 100,000s of steps, and a permadeath setting that starts agen
ts at the beginning in a whole new world if they die in the dungeon. NetHack is even difficult to master for human playe
rs who often rely on external knowledge.


https://proceedings.neurips.cc/paper_files/paper/2023/file/764ba7236fb6374301
4fafbd87dd4f0e-Paper-Conference.pdf

https://github.com/upiterbarg/hihack

https://arxiv.org/pdf/2203.11889

https://www
.youtube.com/watch?v=8L8LiQ-cIWA
```
---

     
 
all -  [ Google Scholar Completely Disappeared Our Paper With 60+ Citations ](https://www.reddit.com/r/academia/comments/1gwjzrk/google_scholar_completely_disappeared_our_paper/) , 2024-12-13-0914
```
Our paper 'Real-Time Reinforcement Learning' published on [Arxiv](https://arxiv.org/abs/1911.04448) and [Neurips](https:
//papers.nips.cc/paper_files/paper/2019/hash/54e36c5ff5f6a1802925ca009f3ebb68-Abstract.html) was [correctly listed on Go
ogle Scholar](https://web.archive.org/web/20240603082519/https://scholar.google.com/citations?user=4_1LlbAAAAAJ&hl=en) s
ince 2019. At some point during the last few months it vanished from Google Scholar leaving only an info box without any
 links or citations on [my profile today](https://web.archive.org/web/20241121144849/https://scholar.google.com/citation
s?user=4_1LlbAAAAAJ&hl=en). Even [searching for it ](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=real+time+r
einforcement+learning+ramstedt+pal&btnG=)using the full title and author names yields no results now.  
  
It seems like
 Google Scholar erroneously and retroactively (after 5 years) merged our paper with another paper from 2019 with complet
ely different title and authors. The Google Scholar link on Arxiv explicitly referencing the Arxiv-ID now points to [ano
ther paper](https://scholar.google.com/scholar_lookup?arxiv_id=1911.04448). On that page, when clicking on 'All 14 Versi
ons', it then [shows versions of our paper](https://scholar.google.com/scholar?cluster=14219642840399587525&hl=en&as_sdt
=0,5). The only commonality between the two papers is that both papers were published at Neurips 2019.

Does anyone have
 an idea on how to fix this? As far as I know Google Scholar doesn't have a support email or support forum.


```
---

     
 
all -  [ [D] PhD in RL/ML Theory or LLM ](https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/) , 2024-12-13-0914
```
Hi guys,

I'm at a crossroads in my academic journey and would appreciate the community's insights. I'm trying to decide
 between pursuing a PhD focused on reinforcement learning/ML theory versus specializing in large language models with mo
re experimental/applied research (these are the only two offers I had).

# Key considerations are the following:

# Rese
arch Impact

* RL/ML Theory: Foundational work that could advance the field's mathematical understanding
* LLMs: Direct 
applications in today's most transformative AI systems

# Job Prospects

* Theory: Academia, research labs, potentially 
more limited industry roles
* LLMs: High industry demand, active research area in both academia and industry

# Long-ter
m Relevance

* Theory: Core principles likely to remain valuable regardless of specific technologies
* LLMs: Currently r
evolutionary but uncertain long-term trajectory

Personal background

* I'm an international student and about to finish
 my master program in US, so I no longer has enough time before making the final decision. I used to research in ml theo
ry, but did not end up with a real top conference publication in theory. I personally doubt if I have enough mathematica
l background to pursue a successful PhD in this area (e.g., at least publish 2 theory papers a year on ICML/NeurIPS/ICLR
/COLT/AISTATS). At the same time, I am personally doubting if theory works indeed advance the ML/AI community, as many p
apers are just proving vacuous bounds or propose some new algorithms that themselves cannot even implement or experiment
ally tested.
* I also used to research in more applied ml, with one aaai paper. My personal concerns is that I'm not fas
t at implementation and coding, the most strategic ability for a successful applied ML researcher. After we entered the 
LLM era, the pacing or applied ML research (especially in LLM and CV) becomes so fast. It's like competitive programming
 in research community (well, also the #GPUs competition).
```
---

     
 
all -  [ That‚Äôs it folks! ](https://i.redd.it/69mlt91aku1e1.jpeg) , 2024-12-13-0914
```
(Not the person in the post)
```
---

     
 
all -  [ [D] Expectation from Machine Learning Engineering jobs ](https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/) , 2024-12-13-0914
```
Hey everyone,

I‚Äôve seen a lot of posts here about careers in ML and landing internships or jobs, and two things come up
 a lot

1. Building a strong research portfolio and publishing at conferences like NeurIPS, ICLR, and ICML, which seems 
to focus more on getting research scientist roles.

2. The growing demand for Machine Learning Engineer (MLE) roles, whi
ch are apparently more in demand than research scientist positions.

I‚Äôm curious about the difference between these two 
roles and what kind of portfolio would be ideal for landing an MLE position. I know having a master‚Äôs degree is often pr
eferred, but is an impressive publication record necessary for MLE roles? Or is it not that big of a deal?

What are you
r thoughts?
```
---

     
 
all -  [ On the current state of robotics (ig?) (from a CSE perspective) (For all my homies out there) ](https://www.reddit.com/r/Btechtards/comments/1gsjxio/on_the_current_state_of_robotics_ig_from_a_cse/) , 2024-12-13-0914
```
Follow up on¬†[https://www.reddit.com/r/Btechtards/comments/1gseqvq/cs\_roadmap\_for\_all\_my\_1st\_year\_homes\_out\_the
re/](https://www.reddit.com/r/Btechtards/comments/1gseqvq/cs_roadmap_for_all_my_1st_year_homes_out_there/)

Background -
 CSE 4th year, T1 (idk much about the electronics aspects of robotics and I kinda do computer vision not robotics)

\---
Profs---

I have like a research-ish approach to robotics cause of labs and stuff. Here's how I judge research -¬†[https:
//csrankings.org/#/index?all&us](https://csrankings.org/#/index?all&us)¬†(only considers the good conferences)

As for Ro
botics and CV in India -¬†[https://csrankings.org/#/index?vision&robotics&in](https://csrankings.org/#/index?vision&robot
ics&in)

You get the usual research heavy unis (IIIT H, IISc, IIT K).

Let's go from a professor perspective, here are t
he absolute beasts in India (in no particular order) (CV + robotics):

1. K Madhava Krishna (IIIT H):¬†[https://scholar.g
oogle.co.in/citations?user=QDuPGHwAAAAJ&hl=en](https://scholar.google.co.in/citations?user=QDuPGHwAAAAJ&hl=en)
2. C V Ja
wahar (IIIT H):¬†[https://scholar.google.com/citations?user=U9dH-DoAAAAJ&hl=en](https://scholar.google.com/citations?user
=U9dH-DoAAAAJ&hl=en)
3. R. Venkatesh Babu (IISc):¬†[https://cds.iisc.ac.in/faculty/venky](https://cds.iisc.ac.in/faculty/
venky)
4. Shishir N Y Kolathaya (IISc):¬†[https://www.shishirny.com/](https://www.shishirny.com/)
5. Indranil Saha (IIT K
):¬†[https://scholar.google.com/citations?user=F6QSFGkAAAAJ&hl=en](https://scholar.google.com/citations?user=F6QSFGkAAAAJ
&hl=en)
6. Avinash Sharma (IIT J):¬†[https://3dcomputervision.github.io/](https://3dcomputervision.github.io/)
7. Chetan 
Arora (IIT D):¬†[https://www.cse.iitd.ac.in/\~chetan/](https://www.cse.iitd.ac.in/~chetan/)

(Lmk if I should add any)

H
ere's how I would have started:

1. Look up their research and try to make sense out of it
2. Look at their top 5 newest
 papers and top 5 papers and see if you understand the abstract. If you don't relentelessly use Perplexity and get infor
mation.

Now you know the SOTA in India for robotics and CV. Then, look at these international profs (trying to add 5 in
 no order that have diverse research interests)

1. [https://www.cs.cmu.edu/\~./choset/](https://www.cs.cmu.edu/~./chose
t/)
2. [https://people.eecs.berkeley.edu/\~svlevine/](https://people.eecs.berkeley.edu/~svlevine/)¬†(absolute fucking god
 imo)
3. [https://animesh.garg.tech/](https://animesh.garg.tech/)
4. [https://research.qut.edu.au/qcr/people/michael-mil
ford](https://research.qut.edu.au/qcr/people/michael-milford)
5. [https://people.eecs.berkeley.edu/\~anca/](https://peop
le.eecs.berkeley.edu/~anca/)¬†(HCI stuff but I consider her robotics)

Good, now you know what's happening in academia. S
ince industry stems from academic esp. in robotics, you also know what will be happening there 5 years down the line. Lo
ok at cool stuff from Boston Dynamics (duh), Allen Institue for AI, Honda Research, etc. as well. Some pretty amazing Ch
inese and Israeli companies exist as well.

\---Starting with robotics---

I'm a sucker for mobile robotics -

1. [https
://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN\_](https://www.youtube.com/playlist?list=PLgnQpQtFTOG
QrZ4O5QzbIHgl3b1JHimN_)
2. [https://www.youtube.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp\_yMb4v](https://www.youtu
be.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp_yMb4v)
3. [https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh\_J16IM
wDlji18SWQ2PZ6](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh_J16IMwDlji18SWQ2PZ6)

All by C. Stachniss.

Then, q
uite literally do any course on robot manipulation and dynamics.

Then, start OpenCV - the docs are beautiful. Use them.
 Use Python. Learn PyTorch as well! (docs work).

Learn ROS using the docs (or any playlist tbh, all are pretty good).


Tie eveyrthing together by building a CV + Robotics pipeline using ROS simulations such as camera calibration, SLAM pipe
line, etc.

\---Going ahead---

Take a top-tier robotics paper (one that is not too math-y but more ML-y) and read their
 codebases. Literally just google any of the papers from the conferences listed below and choose one that sounds interes
ting (and has the codebase available).

Then, and I cannot emphasize this further, write your own implementation. It mig
ht take weeks (and ik the difficulties involved vis-a-vis hardware or GPUs - just simulate / do on a lower scale) but it
'll be worth it.

My fav repos are

1. [https://github.com/amaralibey/MixVPR](https://github.com/amaralibey/MixVPR)
2. [
https://github.com/robodhruv/visualnav-transformer](https://github.com/robodhruv/visualnav-transformer)¬†(all three of th
e codebases)
3. [https://github.com/PRBonn/kiss-icp](https://github.com/PRBonn/kiss-icp)

(Again, lmk if you have any ad
ditions to this list)

Robotics honestly just diversifies at this point. Choose a direction that interests you (SLAM, ha
rdware, optimizations, vision, HCI, etc.)

\---Jobs?---

Join academia or a research lab (none in India unfortunately). 
You can cold-email profs asking for research internships or assistantships - that works sometimes. CAIR in Blr is also a
mazing.

Industry - some super cool stuff in India as well rn (minuszero, Swaayatt Robots, a bunch of drone companies, e
tc.). Nvidia also has some cool roles as well.

\---Should you do it?---

Idk. I'm an undergrad. This is what I've done 
and what some PhDs and MS people told me. Ask people on LinkedIn / Twitter to figure out whether robotics (and which par
t of robotics specifically) is what you want.

\---Conferences---

Robotics - ICRA, IROS, CORL, RSS

CV - CVPR, ICCV, EC
CV, BMVC, WACV (people also submit CV stuff to ICLR, NeurIPS, ICML, etc)


```
---

     
 
all -  [ [R] Convolutional Differentiable Logic Gate Networks ](https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/) , 2024-12-13-0914
```
Abstract

With the increasing inference cost of machine learning models, there is a growing interest in models with fast
 and efficient inference. Recently, an approach for learning logic gate networks directly via a differentiable relaxatio
n was proposed.  Logic gate networks are faster than conventional neural network approaches be- cause their inference on
ly requires logic gate operators such as NAND, OR, and XOR, which are the underlying building blocks of current hardware
 and can be efficiently executed. We build on this idea, extending it by deep logic gate tree convolutions, logical OR p
ooling, and residual initializations. This allows scaling logic gate networks up by over one order of magnitude and util
izing the paradigm of convolution. On CIFAR-10, we achieve an accuracy of 86.29% using only 61 million logic gates, whic
h improves over the SOTA while being 29√ó smaller.

  
Accepted at Neurips 2024, 'SOTA' here means comparable approaches.
 I found this paper really interesting, even though non-toy networks seems like they would be very expensive to train. C
urious what others think?
```
---

     
 
all -  [ How is the ACL Conference? ](https://www.reddit.com/r/deeplearning/comments/1gs7he7/how_is_the_acl_conference/) , 2024-12-13-0914
```
Hello, I know it's a very noob question but I was wondering what the reputation of ACL is in the field. I have been writ
ing my first paper and my mentor recommended that I aim for the ACL deadline, I just wanted to know how prestigious it w
as relative to bigger conferences like NeurIPS, ICML, ICLR, etc.

Also, purely hypothetical, but what weight does an ACL
 acceptance hold for getting a summer internship/research? I'm an undergrad and I'm kind of cooked with my summer intern
ship prospects, so I was wondering if it would help in any regard.
```
---

     
 
all -  [ [D] Neurips 2024 Hotel Roommate Search ](https://www.reddit.com/r/MachineLearning/comments/1gs0gj8/d_neurips_2024_hotel_roommate_search/) , 2024-12-13-0914
```
The hotels around the venue for Neurips 2024 are pretty expensive, and I'm looking for a roommate to split the cost with
 (my university has a limit on the nightly hotel rate they are willing to reimburse). I currently have reserved a room f
or Tuesday-Sunday in the Century Plaza Hotel, which is 0.9 miles from the convention center. The nightly rate is $414. I
f anyone wants to split the cost of a room, please reach out! Also, it would be helpful if you could share this post wit
h your research group or other attendees that you know.

If you are unsure about rooming with a complete stranger, you c
an get to know me a little bit through my personal website (https://mtcrawshaw.github.io/), which has links to my google
 scholar page, CV, etc. I do have a paper at the conference in the area of federated learning/distributed optimization. 
Just a grad student trying to make conferences affordable! Thanks.
```
---

     
 
all -  [ Need an Advice ](https://www.reddit.com/r/PhD/comments/1grg73d/need_an_advice/) , 2024-12-13-0914
```
Hi everyone, I‚Äôm a first-year computer science PhD student in Europe from Asia, going into my second year soon. I wanted
 to ask for some advice on what I should do. First off, I‚Äôm an international student from a Southeast Asian country, and
 right now I‚Äôm really struggling with the lab environment.

First, my professor requires all PhD students to work in the
 lab from 9 to 5 every weekday, no exceptions except for weekends. We‚Äôre only allowed to take time off when the universi
ty is officially closed. Second, I found out from previous PhD students that my professor insists on a strict policy of 
‚Äúequal credit‚Äù in publications, meaning that even if I do all the work for a paper‚Äîfrom analysis to programming, writing
, and revisions‚Äîmy name won‚Äôt be listed as the first author because authorship order is strictly alphabetical.

Third, s
ome of us in the lab (we‚Äôre all international students) aren‚Äôt allowed to submit our papers to conferences, even big one
s like ICML or NeurIPS. My professor only wants our publications in journals, even though conferences are important for 
PhD students to network and get feedback from experts in the field.

Lastly, and perhaps the most difficult part for me,
 is that I‚Äôm not allowed to collaborate with anyone outside the lab. I‚Äôm not even allowed to discuss my project or seek 
advice from people outside the lab group. This restriction makes me feel isolated, and for the past three months, I‚Äôve h
ad recurring nightmares and panic attacks before going into the lab. I reached out to the PhD board to ask if I could tr
ansfer to a different lab, but they said it‚Äôs impossible.

I‚Äôm really at a loss here. Should I stick it out in this lab 
for the next 2-3 years, knowing I won‚Äôt have the chance to publish as the primary author and that, when I graduate, I‚Äôll
 probably have no network beyond the people in this lab?
```
---

     
 
all -  [ [D] Looking for a project partner who's published in top conferences [cvpr, neurips, wacv, iccv, etc ](https://www.reddit.com/r/computervision/comments/1gpfcpk/d_looking_for_a_project_partner_whos_published_in/) , 2024-12-13-0914
```
Hello y'all. Deep into my master's degree, I am in a dire need of a mentor/partner for my research partner. Some of the 
professors at the academia who claim to specialize in the field of computer vision/ai doesnt know how to clone an existi
ng model from github or provide gpu alternatives and solutions who doesnt have fancy things to speed up the process. 

s
o if you do feel the same way and is interested to work on some cool research gap leading to a publication. drop a comme
nt on what excites you most. thankss.
```
---

     
 
all -  [ [D] How to Choose an AI-Focused Master's Program? ](https://www.reddit.com/r/computervision/comments/1gpba3y/d_how_to_choose_an_aifocused_masters_program/) , 2024-12-13-0914
```
I'm currently applying for AI-focused Master's programs, and I could really use some advice. I love working in computer 
vision, and I think I‚Äôm genuinely passionate about research. I presented my first paper at an affinity workshop at ICML,
 and I‚Äôll be attending NeurIPS as a workshop presenter. This experience has been a blast, and I'm hoping to continue dow
n this path.

Right now, I'm feeling overwhelmed by all the options and the looming deadlines. The only program I‚Äôm trul
y excited about is at UvA (University of Amsterdam). But I know I need to consider more options to keep my career moving
 forward.

Here‚Äôs what I'm interested in:

* **Self-Supervised Learning (SSL):** I have experience in this area and woul
d love to deepen my expertise.
* **Video Understanding and GNNs:** These are becoming my newest interests, and I‚Äôd love 
to join a program where I can explore these topics.
* **Research-oriented environments:** I‚Äôm currently collaborating wi
th a professor and have found that I really enjoy the collaborative, exploratory nature of research.

The problem? I don
‚Äôt want to settle for a program that doesn‚Äôt align with these interests or doesn‚Äôt offer strong mentorship and research 
opportunities. I‚Äôm also worried I might be *too* picky, which is making the process even more stressful. I‚Äôd love to hea
r from anyone who‚Äôs been in a similar position:

1. **How did you prioritize which programs to apply to?**
2. **Did you 
find a strategy that helped you balance your interests with program options?**
3. **Any advice on picking a program that
 will help with a long-term research-focused career?**

Thanks so much for any insights you can share!
```
---

     
 
all -  [ [D] NeurIPS After Dark Networking Event ](https://www.reddit.com/r/MachineLearning/comments/1gpamvn/d_neurips_after_dark_networking_event/) , 2024-12-13-0914
```
Just got an email about an official ticketed after dark NeurIPS networking event - this will be my first time attending/
presenting, wondering if these events are worth going to. More generally, also interested in hearing about how to make t
he most of my time attending.
```
---

     
 
all -  [ NeuroAI - NeurIPS Workshop (Vancouver, Dec 15) ](https://www.reddit.com/r/corticallabs/comments/1gp8lg5/neuroai_neurips_workshop_vancouver_dec_15/) , 2024-12-13-0914
```
Hey all, just wanted to make the announcement that some of the Cortical Labs team will be in Vancouver for NeurIPS and C
TO Dave will be publishing the beta API spec for community feedback.

  
[https://neuroai-workshop.github.io](https://ne
uroai-workshop.github.io)
```
---

     
