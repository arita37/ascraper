 
all -  [ What are the equivalents to NeurIPS, and ICML for CV? ](https://www.reddit.com/r/computervision/comments/1h7hox3/what_are_the_equivalents_to_neurips_and_icml_for/) , 2024-12-06-0914
```
I know about CVPR, but are there more?
```
---

     
 
all -  [ NeurlPS 2024: NaturalBench - Evaluating Vision-Language Models on Natural Adversarial Samples ](https://www.reddit.com/r/computervision/comments/1h7f4k2/neurlps_2024_naturalbench_evaluating/) , 2024-12-06-0914
```
Check out [Harpreet Sahota](https://www.linkedin.com/in/harpreetsahota204/)’s conversation with [Zhiqiu Lin](https://www
.linkedin.com/in/zhiqiu-lin-b49ba7126/) of Carnegie Mellon University about his NeurIPS 2024 paper, “NaturalBench: Evalu
ating Vision-Language Models on Natural Adversarial Samples.”

* [Complete interview and discussion on YouTube](https://
youtu.be/eFfdo4vZIic)
* [Research paper on arXiv](https://youtu.be/eFfdo4vZIic)

Video preview below:

https://reddit.co
m/link/1h7f4k2/video/6mw2ahngi25e1/player

  

```
---

     
 
all -  [ Former Intern Sabotages ByteDance’s AI Training, Faces ¥8 Million Lawsuit, Yet Wins NeurIPS 2024 Bes ](https://www.reddit.com/r/LocalLLaMA/comments/1h6i1m9/former_intern_sabotages_bytedances_ai_training/) , 2024-12-06-0914
```
In October 2024, media outlets reported that 'ByteDance's large-scale model training was attacked by an intern,' and onl
ine sources claimed that 'over 8,000 GPUs were involved, resulting in losses exceeding tens of millions of dollars.' Byt
eDance later issued an official statement to clarify the situation, confirming that a serious infraction did occur invol
ving an intern. The intern in question was terminated by the company in August 2024.

[ByteDance Official Statement](htt
ps://preview.redd.it/uvwtbcqyhu4e1.png?width=785&format=png&auto=webp&s=3b9040d2ac1f03c5c0c2d279b61704c4997a438d)

ByteD
ance's lawsuit against former intern Tian for tampering with code and attacking the company's internal model training ha
s been officially accepted by the Haidian District People's Court in Beijing. ByteDance is requesting the court to order
 Tian to compensate the company for damages amounting to ¥8 million, along with reasonable expenses of ¥20,000, and to p
ublicly issue an apology.

Recently, the intern who maliciously attacked ByteDance's training cluster, Keyu Tian, receiv
ed the NeurIPS 2024 Best Paper Award. [Paper](https://arxiv.org/abs/2404.02905) [Github](https://github.com/FoundationVi
sion/VAR)

https://preview.redd.it/4hfxwbkcju4e1.png?width=1802&format=png&auto=webp&s=ec79a9a1b49bbd1e329c6b7560e74a415
907dff1

Coincidentally, this award-winning paper was the result of his collaboration with the team during his internshi
p in ByteDance's Commercialization Technology Department.
```
---

     
 
all -  [ NeurIPS 2024 - A Label is Worth a Thousand Images in Dataset Distillation ](https://www.reddit.com/r/computervision/comments/1h6hx3p/neurips_2024_a_label_is_worth_a_thousand_images/) , 2024-12-06-0914
```
https://reddit.com/link/1h6hx3p/video/k7wh8qlfiu4e1/player

Check out [Harpreet Sahota’s](https://www.linkedin.com/in/ha
rpreetsahota204/) conversation with [Sunny Qin](https://www.linkedin.com/in/sunnytqin/) of Harvard University about her 
NeurIPS 2024 paper, 'A Label is Worth a Thousand Images in Dataset Distillation.”

https://i.redd.it/mg9isc68iu4e1.gif


* [Complete interview and discussion on YouTube](https://www.youtube.com/watch?v=9TdDJ9J-VZI)
* [Research Paper](https:/
/arxiv.org/abs/2406.10485)
```
---

     
 
all -  [ Hello, what is the rarest research offered by universities among these? ](https://www.reddit.com/r/research/comments/1h5ex8p/hello_what_is_the_rarest_research_offered_by/) , 2024-12-06-0914
```

Hello, can anyone tell what is the rarest research subjects among these?

I'm an undergrad student and i want to do res
earch that only handful of universities offer. can anyone tell what are the rarest researches among these

* Title: AI a
nd Social Technologies to Aid Educational Migrants from the Global South Description: In this project, one student will 
work directly on a PhD student's project to design an AI and/or social technology to address the security and privacy ne
eds among educational migrants from the Global South. The student will become certified in Human Subjects Research and f
amiliar with the existing relevant human-AI interaction and usability research for the project. They will be expected to
 support the PhD student in literature review, design ideation, and/or prototyping. They will assist the PhD student in 
preparing publications.
* Title: Improving Users’ Experiences with Security and Privacy Tasks on Mobile Devices Descript
ion:Our Security and Privacy Experiences (SPEX) group wants to assist mobile phone users with dealing with their securit
y and privacy concerns directly on their device. The selected student will work with a PhD student on one or both of the
 following projects: (a) mitigating people’s vulnerability to SMS text scams and misinformation, aka “smishing”; and (b)
 providing AI-assisted question-answering and community for mobile users dealing with security and privacy concerns. The
 student will become certified in Human Subjects Research and familiar with the existing relevant cybersecurity and usab
ility research for the project. They will help with tasks such as reviewing published literature on the subject, brainst
orming ideas, recruiting and scheduling participants for an interview study, cleaning up transcripts, and analyzing coll
ected data. They also may be asked to help refine a prototype mobile-friendly web app.
* Title: Efficient State Space Mo
dels through the Convolutional Lens Description: Recently, structured state-space models (SSMs) have emerged as a strong
 contender for sequence modeling in deep learning, mitigating semantic challenges of Transformer models induced by their
 limited window lengths. Recent such models have dominated certain benchmarks such as the Long Range Arena and have been
 especially successful in domains involving continuous signal data such as audio and vision, while also beating Transfor
mers due to the linear or near-linear scaling of their computational complexity in sequence length. While the scaling of
 state-of-the-art SSMs such as Mamba and Mamba-2 is near-linear in the sequence length, it is quadratic in the hidden st
ate dimension, which is detriment towards the construction of scalable, expressive SSMs capturing complex state informat
ion. In this project, we revisit a convolutional perspective on SSMs that additionally the leverage selection mechanism 
introduced by Mamba, and develop a variant of Mamba-2 type of model via a block-Toeplitz matrix perspective, which allow
s for a near-linear scaling in the hidden state dimension both for training and inference. Tasks in this project include
 the implementation and modification of SSM code bases, the training of SSM models, and the structuring and presentation
s of resulting computational experiments.
* Title: Buiidling Visualizations of Real World Datasets using D3JS Descriptio
n: The project will provide experience and benefits for building information visualizations of real world datasets using
 the D3JS Visualization toolkit, a Javascript based toolkit. The goal is to build complete applications that can demonst
rate the significance and relevance of visualizations for datasets that are difficult to understand or very little is kn
own about it. Possible applications would involve outputs of machine learning models, medical data statistics. Visualiza
tions related to an existing educational research project would also be considered as part of the project. Applicants sh
ould be strong programmers in high level languages so that they can work independently to complete assigned tasks. Exper
ience with visualization tools and/or Web technologies is a plus.
* Title: Robotic Coverage and Informative Path Plannin
g Description: In this project, the undergraduate researcher will learn about state-of-the-art algorithms for robot cove
rage and informative path planning. The goal is to develop and implement new online approaches that incorporate sensor d
ata. Applications include inspection of critical infrastructure (e.g., power lines, roads) and search and rescue (e.g., 
after disasters). Students will work on cutting edge research in robotics and learn about optimization and machine learn
ing algorithms and ROS (robot operating system). The research will be conducted in the Robotics Laboratory in the Comput
er Science Department. In addition to validation of the algorithms in simulation, there will be opportunities to impleme
nt and demonstrate the algorithms on quadcopter drones and wheeled mobile robots.
* Title: Parameter-Efficient Training 
through Efficient Joint Sparse and Low-Rank Adaptation Description: With the advent of deep learning and large language 
models, which have delivered impressive results for a large number of machine learning tasks, models with hundred of mil
lions, billions or more parameters have been become main stream. While the hardware and energy requirements of a full-tr
aining process prevent state-of-the-art deep learning models to be trained on consumer hardware, it is possible to “opti
mize” a pre-trained model to excel for a particular task on consumer hardware via Parameter-Efficient Fine-Tuning (PEFT)
. Among the most popular techniques for PEFT, low-rank adaptation and sparse adaptation has merged in the last two years
. The recent paper “RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation” (https://arxiv.org/pdf/2401.04
679) has shown that the performance of methods that jointly optimize sparse and low-rank adapters outperform either of t
he two pure methods. In this projcet, we build on recent advances on low-rank fine-tuning and training within our resear
ch group based on quadratic differentiable rank regularizers and plan to develop algorithms for PEFT that obtain improve
d performance over RoSA and other PEFT methods given the same parameter budget.
* Title: A Customizable Pathfinding Modu
le for Lightning Network Clients Description: Since its conception in the wake of the global financial crisis in late 20
08 by its pseudonymous creator, the Bitcoin cryptocurrency network has gained a considerable amount of traction as the b
ase layer of an alternative financial system with around $20\\%$ of American adults as owners. The Lightning network is 
a scaling solution in which payment channels backed by blockchain transactions allow to overcome any blockchain's inhere
nt throughput limitations and furthermore, instantaneous payments. In order to send a payment within the network, a part
icipant picks one or more suitable payment paths that satisfy their needs. In this project, we design a software package
 that implements different pathfinding algorithms and underlying modelings to provide customized, user-friendly solution
s for pathfinding problems faced by Lightning node operators. The software is meant to interface with as many different 
popular Lightning node implementations such as Rust-Lightning
* Title: Novel Solvers for Sparse Generalized Linear Model
s Description: High-dimensional, sparse generalized linear models are widely used in statistics and machine learning. Ho
wever, optimizing and fitting these models to data poses significant computational and algorithmic challenges for respec
tive optimization algorithms. The framework of iteratively reweighted least squares (IRLS) \[Daubechies et al. 2010, htt
ps://doi.org/10.1002/cpa.20303; Peng et al. 2022 https://proceedings.neurips.cc/paper\_files/paper/2022/file/ba3354bcfea
e4f166a8bfe75443ac8f7 Paper-Conference.pdf\] has been shown to be highly effective and efficient for several sparse regr
ession models, but has been under-explored in the context of sparse \_logistic\_ regression, which is the backbone of ma
ny classification models in machine learning. In this project, we will develop a variant of IRLS that is specifically ta
ilored for sparse logistic regression and benchmark it against other state-of-the-art methods within the 'benchopt' benc
hmarking framework \[Moreau et al. 2021, https://arxiv.org/pdf/2206.13424\] and evaluate it on relevant datasets. If suc
cessful, this project will lead to a journal or conference publication.
* Title: AI Models for Nonlinear Rewriting of Na
rratives Description: Stories are often told in a non-linear fashion, in order to increase suspense, emotional involveme
nt, engagement, and overall enjoyment. This is done across the various mediums used to tell the story, ranging from text
 (novels) to audio (radio, podcasts), to audio-visual (movies and TV series). However, the deadline-driven environment w
here creators need to generate new content at a very high pace leads to a non-linear storytelling that feels rushed, tha
t detracts from understanding and enjoying the story as a whole, and that does not optimize the true potential of the no
n-linear technique. Additionally, readers and audiences enjoy different levels of non-linearity. In this context, we exp
ect that a tool that can optimize non-linear story telling would have significant impact. However, for lack of access to
 the original linear version of a story, a pre requisite task is that of taking as input a story and creating a linear v
ersion of it. In this project, we propose to (1) develop LLM-based narrative linearization methods that take as input th
e text of a story and produce as output a linearized version of it. (2) models for nonlinear rewriting of narratives sta
rting from their linear versions.
```
---

     
 
all -  [ Hello, can anyone tell what is the rarest research subjects among these? ](https://www.reddit.com/r/csMajors/comments/1h4qz8i/hello_can_anyone_tell_what_is_the_rarest_research/) , 2024-12-06-0914
```
I'm an undergrad student and i want to do research that only handful of universities offer. can anyone tell what are the
 rarest researches among these

* Title: AI and Social Technologies to Aid Educational Migrants from the Global South De
scription: In this project, one student will work directly on a PhD student's project to design an AI and/or social tech
nology to address the security and privacy needs among educational migrants from the Global South. The student will beco
me certified in Human Subjects Research and familiar with the existing relevant human-AI interaction and usability resea
rch for the project. They will be expected to support the PhD student in literature review, design ideation, and/or prot
otyping. They will assist the PhD student in preparing publications.
* Title: Improving Users’ Experiences with Security
 and Privacy Tasks on Mobile Devices Description:Our Security and Privacy Experiences (SPEX) group wants to assist mobil
e phone users with dealing with their security and privacy concerns directly on their device. The selected student will 
work with a PhD student on one or both of the following projects: (a) mitigating people’s vulnerability to SMS text scam
s and misinformation, aka “smishing”; and (b) providing AI-assisted question-answering and community for mobile users de
aling with security and privacy concerns. The student will become certified in Human Subjects Research and familiar with
 the existing relevant cybersecurity and usability research for the project. They will help with tasks such as reviewing
 published literature on the subject, brainstorming ideas, recruiting and scheduling participants for an interview study
, cleaning up transcripts, and analyzing collected data. They also may be asked to help refine a prototype mobile-friend
ly web app.
* Title: Efficient State Space Models through the Convolutional Lens Description: Recently, structured state
-space models (SSMs) have emerged as a strong contender for sequence modeling in deep learning, mitigating semantic chal
lenges of Transformer models induced by their limited window lengths. Recent such models have dominated certain benchmar
ks such as the Long Range Arena and have been especially successful in domains involving continuous signal data such as 
audio and vision, while also beating Transformers due to the linear or near-linear scaling of their computational comple
xity in sequence length. While the scaling of state-of-the-art SSMs such as Mamba and Mamba-2 is near-linear in the sequ
ence length, it is quadratic in the hidden state dimension, which is detriment towards the construction of scalable, exp
ressive SSMs capturing complex state information. In this project, we revisit a convolutional perspective on SSMs that a
dditionally the leverage selection mechanism introduced by Mamba, and develop a variant of Mamba-2 type of model via a b
lock-Toeplitz matrix perspective, which allows for a near-linear scaling in the hidden state dimension both for training
 and inference. Tasks in this project include the implementation and modification of SSM code bases, the training of SSM
 models, and the structuring and presentations of resulting computational experiments.
* Title: Buiidling Visualizations
 of Real World Datasets using D3JS Description: The project will provide experience and benefits for building informatio
n visualizations of real world datasets using the D3JS Visualization toolkit, a Javascript based toolkit. The goal is to
 build complete applications that can demonstrate the significance and relevance of visualizations for datasets that are
 difficult to understand or very little is known about it. Possible applications would involve outputs of machine learni
ng models, medical data statistics. Visualizations related to an existing educational research project would also be con
sidered as part of the project. Applicants should be strong programmers in high level languages so that they can work in
dependently to complete assigned tasks. Experience with visualization tools and/or Web technologies is a plus.
* Title: 
Robotic Coverage and Informative Path Planning Description: In this project, the undergraduate researcher will learn abo
ut state-of-the-art algorithms for robot coverage and informative path planning. The goal is to develop and implement ne
w online approaches that incorporate sensor data. Applications include inspection of critical infrastructure (e.g., powe
r lines, roads) and search and rescue (e.g., after disasters). Students will work on cutting edge research in robotics a
nd learn about optimization and machine learning algorithms and ROS (robot operating system). The research will be condu
cted in the Robotics Laboratory in the Computer Science Department. In addition to validation of the algorithms in simul
ation, there will be opportunities to implement and demonstrate the algorithms on quadcopter drones and wheeled mobile r
obots.
* Title: Parameter-Efficient Training through Efficient Joint Sparse and Low-Rank Adaptation Description: With th
e advent of deep learning and large language models, which have delivered impressive results for a large number of machi
ne learning tasks, models with hundred of millions, billions or more parameters have been become main stream. While the 
hardware and energy requirements of a full-training process prevent state-of-the-art deep learning models to be trained 
on consumer hardware, it is possible to “optimize” a pre-trained model to excel for a particular task on consumer hardwa
re via Parameter-Efficient Fine-Tuning (PEFT). Among the most popular techniques for PEFT, low-rank adaptation and spars
e adaptation has merged in the last two years. The recent paper “RoSA: Accurate Parameter-Efficient Fine-Tuning via Robu
st Adaptation” (https://arxiv.org/pdf/2401.04679) has shown that the performance of methods that jointly optimize sparse
 and low-rank adapters outperform either of the two pure methods. In this projcet, we build on recent advances on low-ra
nk fine-tuning and training within our research group based on quadratic differentiable rank regularizers and plan to de
velop algorithms for PEFT that obtain improved performance over RoSA and other PEFT methods given the same parameter bud
get.
* Title: A Customizable Pathfinding Module for Lightning Network Clients Description: Since its conception in the w
ake of the global financial crisis in late 2008 by its pseudonymous creator, the Bitcoin cryptocurrency network has gain
ed a considerable amount of traction as the base layer of an alternative financial system with around $20\\%$ of America
n adults as owners. The Lightning network is a scaling solution in which payment channels backed by blockchain transacti
ons allow to overcome any blockchain's inherent throughput limitations and furthermore, instantaneous payments. In order
 to send a payment within the network, a participant picks one or more suitable payment paths that satisfy their needs. 
In this project, we design a software package that implements different pathfinding algorithms and underlying modelings 
to provide customized, user-friendly solutions for pathfinding problems faced by Lightning node operators. The software 
is meant to interface with as many different popular Lightning node implementations such as Rust-Lightning
* Title: Nove
l Solvers for Sparse Generalized Linear Models Description: High-dimensional, sparse generalized linear models are widel
y used in statistics and machine learning. However, optimizing and fitting these models to data poses significant comput
ational and algorithmic challenges for respective optimization algorithms. The framework of iteratively reweighted least
 squares (IRLS) \[Daubechies et al. 2010, https://doi.org/10.1002/cpa.20303; Peng et al. 2022 https://proceedings.neurip
s.cc/paper\_files/paper/2022/file/ba3354bcfeae4f166a8bfe75443ac8f7 Paper-Conference.pdf\] has been shown to be highly ef
fective and efficient for several sparse regression models, but has been under-explored in the context of sparse \_logis
tic\_ regression, which is the backbone of many classification models in machine learning. In this project, we will deve
lop a variant of IRLS that is specifically tailored for sparse logistic regression and benchmark it against other state-
of-the-art methods within the 'benchopt' benchmarking framework \[Moreau et al. 2021, https://arxiv.org/pdf/2206.13424\]
 and evaluate it on relevant datasets. If successful, this project will lead to a journal or conference publication.
* T
itle: AI Models for Nonlinear Rewriting of Narratives Description: Stories are often told in a non-linear fashion, in or
der to increase suspense, emotional involvement, engagement, and overall enjoyment. This is done across the various medi
ums used to tell the story, ranging from text (novels) to audio (radio, podcasts), to audio-visual (movies and TV series
). However, the deadline-driven environment where creators need to generate new content at a very high pace leads to a n
on-linear storytelling that feels rushed, that detracts from understanding and enjoying the story as a whole, and that d
oes not optimize the true potential of the non-linear technique. Additionally, readers and audiences enjoy different lev
els of non-linearity. In this context, we expect that a tool that can optimize non-linear story telling would have signi
ficant impact. However, for lack of access to the original linear version of a story, a pre requisite task is that of ta
king as input a story and creating a linear version of it. In this project, we propose to (1) develop LLM-based narrativ
e linearization methods that take as input the text of a story and produce as output a linearized version of it. (2) mod
els for nonlinear rewriting of narratives starting from their linear versions.
```
---

     
 
all -  [ AIML Conference coming up in 2025 ](https://www.reddit.com/r/WomenInAIML/comments/1h3xc5q/aiml_conference_coming_up_in_2025/) , 2024-12-06-0914
```
# AI, ML, and Data Science Conferences for 2025:

1. **AAAI Conference on Artificial Intelligence 2025**
   * **Dates**:
 February 2025
   * **Location**: To be confirmed (usually USA)
   * **Source**: [AAAI](https://aaai.org)
2. **Predictiv
e Analytics World 2025**
   * **Dates**: March 2025
   * **Location**: Las Vegas, NV
   * **Source**: [Predictive Analyt
ics World](https://www.predictiveanalyticsworld.com)
3. **Open Data Science Conference (ODSC) East 2025**
   * **Dates**
: April 14-17, 2025
   * **Location**: Boston, MA
   * **Source**: [ODSC](https://odsc.com)
4. **Machine Learning Week 2
025**
   * **Dates**: June 2-5, 2025
   * **Location**: Phoenix, AZ
   * **Source**: [Predictive Analytics World](https:
//www.predictiveanalyticsworld.com)
5. **Data Science Conference 2025**
   * **Dates**: June 2025
   * **Location**: Chi
cago, IL
   * **Source**: [The Data Science Conference](https://www.datascienceconference.com)
6. **International Confer
ence on Machine Learning (ICML 2025)**
   * **Dates**: July 2025
   * **Location**: To be announced
   * **Source**: [IC
ML](https://icml.cc)
7. **AI Summit 2025**
   * **Dates**: September 2025
   * **Location**: London, UK (TBC)
   * **Sou
rce**: [AI Summit](https://www.theaisummit.com)
8. **International Conference on Big Data 2025 (BigData 2025)**
   * **D
ates**: October 2025
   * **Location**: To be announced (likely USA)
   * **Source**: [BigData Conference](https://bigda
taieee.org)
9. **Open Data Science Conference (ODSC) West 2025**
   * **Dates**: November 2025
   * **Location**: San Fr
ancisco, CA
   * **Source**: [ODSC](https://odsc.com)
10. **IEEE International Conference on Data Mining (ICDM 2025)**
 
  * **Dates**: December 2025
   * **Location**: To be confirmed
   * **Source**: [IEEE ICDM](https://www.ieee.org)
11. *
*NeurIPS 2025**
   * **Dates**: December 2025
   * **Location**: To be confirmed
   * **Source**: [NeurIPS](https://nips
.cc)
```
---

     
 
all -  [ I have reasons to believe that Recursion (RXRX) will became quite popular in the next month. ](https://www.reddit.com/r/wallstreetbets/comments/1h1volv/i_have_reasons_to_believe_that_recursion_rxrx/) , 2024-12-06-0914
```
I believe that in the future, drugs will be highly customisable based on the patience’s health history. Based on your ph
ysiology, syndromes, and genetics, you may receive a drug that is well-suited for you and only you. 

How can you do tha
t? First and foremost, you need data, huge amounts of it. We all know how generative and predictive models had advanced 
in the last year. It wasn’t in fact, until the launch of AlphaFold (by Google, whose team was recently awarded with the 
Chemistry Nobel Prize), that AI drug discovery became prominent. This open source model is used for molecular discovery.
 Again, would be nice if a company could:

1. Generate proprietary synthetic, good quality molecular data using models l
ike AlphaFold.
2. Using this data to train models for drug discovery, reducing pipelines costs and times up to 50%.
3. E
ventually, with the possibility of bringing the first AI-aided drug to the market.

First two points have been achieved,
 and the company is Recursion. We may know them because NVIDIA invested 50m in them. Why then are at ATL? I think the an
swer is time. We all know there is no room for patience when it comes to money sometimes. Training and bringing such res
ults may take years.

However, I think another catalyst is coming. On 9. December, they will host a seminar for new read
outs in one of their most well-known drugs in development, CDK7, for advance solid tumours (an inhibitor, which are curr
ently none approved by the FDA).

Now, I am not saying that they will cure cancer - that’s BS. But over the years conver
ging to novel oncological solutions using AI? This is not the only drug they have (other 9 are in development).

They ha
ve more than 60 petabytes of data.
They combined forces with Exscientia recently, forming probably the most important po
werhouse of AI-drug research.
They are extremely active in the research field (see their presence in the upcoming NeuRIP
S conference) or their new open dataset for Quantum Computing (OpenQDC).

I started investing in IONQ in 2021 for a simi
lar impression. Now I am getting the same vibes with this. I feel that a small catalyst will put this to fly, although t
he real potencial will come in the next 5-10 years. If they can bring the first AI drug to the market,  this implodes.


Of course, no financial advice. I’m long 800 shares and loading as much as I possibly can.
```
---

     
 
all -  [ can I attend neurips as an enthusiast?  ](https://www.reddit.com/r/MLQuestions/comments/1h1kw31/can_i_attend_neurips_as_an_enthusiast/) , 2024-12-06-0914
```
neurips is coming to my hometown, can I just go? I want to hunt down all the recruiters lol 
```
---

     
 
all -  [ [0 YoE, Unemployed, Machine Learning Research Intern, Serbia] ](https://www.reddit.com/r/resumes/comments/1h0jscl/0_yoe_unemployed_machine_learning_research_intern/) , 2024-12-06-0914
```
&#x200B;

[CV](https://preview.redd.it/hv5mq2zkma3e1.png?width=5100&format=png&auto=webp&s=5afe5f21d9ec107c2f5d6cafffd7e
e872ebaa606)

Hello, I hope you are doing well!

I am a second year undergraduate student seeking to land a machine lear
ning research intern position next summer. The CV up there is shrunk to be 1-page length and contains only the most mach
ine learning-related stuff I have created in the past year.  
I am curious in what ways could this CV be bettered and de
tails provided, so I can increase my chances. I have already gotten plenty of industry offers, but I would like to maxim
ize my chances for research positions.

I am very much so aware that, after the second year of undergraduate studies, it
 is very hard to land one, but in case it happens, it can kickstart my career a lot.

I am also interested whether I sho
uld add 2 work in progress papers that I am aiming to publish in the following months - one is related to graph neural n
etworks in medicine, while the other is related to graph neural networks and categorical deep learning.

Thank you in ad
vance - every advice is helpful and appreciated!
```
---

     
 
all -  [ MS Thesis project at IBM Research-Zurich ](https://www.reddit.com/r/ethz/comments/1gzk140/ms_thesis_project_at_ibm_researchzurich/) , 2024-12-06-0914
```
Dear MS Students,

We have an opportunity for an MS Thesis project at IBM Research-Zurich.  

**Project description:** D
espite the breakthrough made by large language models (LLMs), they struggle with high-level reasoning tasks requiring de
liberate thinking and problem-solving skills. Particularly, the pretrained state-of-the-art Transformer language models 
fail at compositional generalization, multi-step deductive reasoning, and analogical reasoning \[1, 2, 3\]. As a potenti
al alternative, neuro-symbolic AI seeks complementary approaches that beneficially combine deep learning advancements wi
th symbolic computations to endorse their strengths and supplement their weaknesses. Key challenges in neuro-symbolic AI
 involve the potentially exponential time required to perform probabilistic inference and the difficulty in learning new
 symbolic programs. Our latest research results addressed these challenges by performing analogical reasoning over distr
ibuted representations \[4,5\]. In this project, the main objective is to develop methods that reduce the computational 
bottleneck in general neuro-symbolic AI systems, while maintaining learning rules/programs that exhibit out-of-distribut
ion generalization, flexibility, and interpretability. Other inputs or directions are welcomed.

**Requirements:** Stron
g motivation and self-drive. Strong analytical and problem-solving skills. Concrete knowledge in deep learning, or a sol
id background in machine learning. Experience with TensorFlow or PyTorch frameworks. Expertise with LLMs is an advantage
.

**Some administrative information:**  
o Earliest start date: Feb 2025  
o Duration: 6 months  
o Pay: None (prohibit
ed from ETH)

The thesis will be performed at the IBM Research-Zurich in Rüschlikon. If you are interested in this chall
enging position on an exciting new topic, please send your most recent curriculum vitae including a transcript of BS and
 MS grades by email to: Dr. Michael Hersche ([her@zurich.ibm.com](mailto:her@zurich.ibm.com)) and Dr. Abbas Rahimi ([abr
@zurich.ibm.com](mailto:abr@zurich.ibm.com))

\[1\] N. Dziri et al., ‘Faith and Fate: Limits of Transformers on Composit
ionality’, *Advances in* *Neural Information Processing Systems (NeurIPS),* 2023.

\[2\] J. Thomm et al., ‘Limits of Tra
nsformer Language Models on Learning to Compose Algorithms’, *Advances in* *Neural Information Processing Systems (NeurI
PS),* 2024.

\[3\] X. Chen, et al., ‘Premise Order Matters in Reasoning with Large Language Models’, *ICML*, 2024.

\[4\
] M. Hersche, et al., ‘A Neuro-Vector-Symbolic Architecture for Solving Raven’s Progressive Matrices’, *Nature Machine I
ntelligence*, 2023.

\[5\] G. Camposampiero, et al., ‘Towards Learning Abductive Reasoning using VSA Distributed Represe
ntations’, *International Conference on Neural-Symbolic Learning and Reasoning (NeSy*), 2024.
```
---

     
 
all -  [ Should i even try for my chances or is it just a waste of time applying with poor grades . Can my SO ](https://www.reddit.com/r/Indians_StudyAbroad/comments/1gzec5d/should_i_even_try_for_my_chances_or_is_it_just_a/) , 2024-12-06-0914
```
I have completed my undergrad from Osmania University (VCE) in electronics and communications ( a tier 2 ish college in 
India )

I have a very low GPA ( 3.18 / 4 ) , I have graduated in 2024 and am aspiring to apply for fall 2026 .

I have 
had severe health issues during my undergrad and did a lot of community outreach programs in my sophomore year , My grad
es were good in my junior year but it was just downhill after that , I was suffering from many health issues which spoil
ed my grades but got recovered in final year and had good grades.

After my health recovered I worked like hell and alre
ady published 4 papers in IEEE conferences and 2 in smaller conferences

**I am currently working at AT&T as senior asso
ciate software engineer with the field being machine learning . I have applied to CVPR 2025 conference and am sure of ge
tting my paper published there , I have 3 more papers ready for ICML and NeurIPS as well , these are the top most confer
ences in ML in the entire world . I am sure of having at least 15 paers published by end of 2025 ( 5 are Q1 level ) . I 
have 3 patents on my name and aspire to get more . It took me sleepless nights during my final year to accomplish all of
 this after my health recovered**

My\_qualifications :

2 research internships , strong LOR's from top international un
iversities where I worked with a professor , aiming to do at least 2 more internships at labs by end of 2025

Can I conv
ince the admission committee that my health affected my grades and can the other strong part of backup my grades part in
 my SOP or is it just a waste of time applying ??

dream target univs - Caltech MS EE ( ML track ) , Stanford MS EE ( ML
 track ) , Stanford MS CS

I recently read this [https://www-cs.stanford.edu/\~rkarthik/DAGAP.pdf](https://www-cs.stanfo
rd.edu/~rkarthik/DAGAP.pdf) where the writer says low GPA will be immediately rejected . Should i even try building my p
rofile or give up hope ?

Stanford and Caltech have been my dream univs since many years and life seems meaningless with
out them , I really need serious advice if i have to give up hope and change my path or still build profile . i have one
 year of time to apply .
```
---

     
 
all -  [ Should i even try ? ](https://www.reddit.com/r/gradadmissions/comments/1gze93d/should_i_even_try/) , 2024-12-06-0914
```
I have completed my undergrad from Osmania University (VCE) in electronics and communications ( a tier 2 ish college in 
India ) 



I have a very low GPA ( 3.18 ) , I have graduated in 2024 and am aspiring to apply for fall 2026 .

 I have 
had severe health issues during my undergrad and did a lot of community outreach programs in my sophomore year , My grad
es were good in my junior year but it was just downhill after that , I was suffering from many health issues which spoil
ed my grades but got recovered in final year and had good grades. 

After my health recovered I worked like hell and alr
eady published 4 papers in IEEE conferences and 2 in smaller conferences

**I am currently working at AT&T as senior ass
ociate software engineer with the field being machine learning . I have applied to CVPR 2025 conference and am sure of g
etting my paper published there , I have 3 more papers ready for ICML and NeurIPS as well , these are the top most confe
rences in ML in the entire world . I am sure of having at least 18 papers published by end of 2025 ( 5 are Q1 level ) . 
I have 3 patents on my name and aspire to get more . It took me sleepless nights during my final year to accomplish all 
of this after my health recovered**



other profile aspects -

2 research internships , strong LOR's from top internati
onal universities where I worked with a professor , aiming to do at least 2 more internships at labs by end of 2025

Can
 I convince the admission committee that my health affected my grades and can the other strong part of backup my grades 
part in my SOP or is it just a waste of time applying ??

dream target univs - Caltech MS EE ( ML track ) , Stanford MS 
EE ( ML track ) , Stanford MS CS

I recently read this [https://www-cs.stanford.edu/\~rkarthik/DAGAP.pdf](https://www-cs
.stanford.edu/~rkarthik/DAGAP.pdf) where the writer says low GPA will be immediately rejected . Should i even try buildi
ng my profile or give up hope ?

Stanford and Caltech have been my dream univs since many years and life seems meaningle
ss without them , I really need serious advice if i have to give up hope and change my path or still build profile . i h
ave one year of time to apply .
```
---

     
 
all -  [ Should I even apply for a PhD? ](https://www.reddit.com/r/PhD/comments/1gy1xp7/should_i_even_apply_for_a_phd/) , 2024-12-06-0914
```
Hi all

So I (23M, Indian) had the dream to pursue a MS+PhD in CS (AI) in the US (No masters, I just have a Bachelors de
gree in Electronics Engineering). I was aiming to get into universities like UCSD, John Hopkins, UIUC.

To make it happe
n, I applied to Indian professors and worked with them. Have spent over 1 year working in research, while managing my so
ftware engineering job in parallel. Got one paper published in ICPR 2024, and one in a small conference, not a big deal.
 I have managed to gather 3 Letters of Recommendation after working.

However, from some sample SOPs on the net, I see t
hat the applicants for these colleges have already 1st author publications in top-tier conferences like AAAI, NeurIPS et
c.

In this scenario, should I even apply? I feel like I have no chance to compete with these people. Am I aiming for to
o high? What would you suggest?

Thank you everyone.

  
Edit 1

Thank you everyone. I got overwhelmed by everything and
 became tensed. I will curate and apply. Whatever happens next, will happen. Let me do my part at least. thanks!
```
---

     
 
all -  [ Insight!  ](https://i.redd.it/3ub4hezgxl2e1.jpeg) , 2024-12-06-0914
```

```
---

     
 
all -  [ [D] Accepted NeurIPS 2024 paper claimed to be solving a novel problem as first work, but ignores 5 p ](https://www.reddit.com/r/MachineLearning/comments/1gxooqv/d_accepted_neurips_2024_paper_claimed_to_be/) , 2024-12-06-0914
```
At NeurIPS 2024 I found a paper that got accepted that positions its main contribution in the form of “Existing algorith
ms for X ignore Y. We adapt algorithm Z for X to account for Y”.

On OpenReview I see that the reviewers in particular p
raised the novelty of the work, and recognised Y as an important aspect that had been ignored in the field of X.

Now th
e interesting bit: co-authors and I published a paper in Springer’s Machine Learning journal in 2023 that also proposes 
an algorithm for X that account for Y. We were also not the first to study the problem setting of X with Y: our paper’s 
related work section discusses 4 papers that have all proposed algorithms for X that account for Y. One is even from Neu
rIPS (2017), and the oldest one dates back to 2012 (an AAAI paper).

The authors of this 2024 NeurIPS paper completely m
issed all this prior literature and believed they were the first, and so did all the reviewers.

This week I e-mailed th
e authors of this NeurIPS 2024 paper and they acknowledged that these works (mine + the 4 others) indeed were all workin
g on the same problem setting, mentioned that they were unaware of all these works, and acknowledged that they can no lo
nger claim novelty of the problem setting.

NeurIPS allows updating the camera ready paper after the conference, and the
 authors promised to use this opportunity to incorporate those related works and modify their contribution statements to
 no longer claim novelty of a first solution of X with Y.

At the one hand, it makes me happy that our work will get cre
dited appropriately.

At the other hand I have my doubts about the ethics of severely modifying contribution statements 
post-review. The authors will no longer claim novelty, but the reviewers in particular praised this novelty, which makes
 me uncertain whether reviewers would have recommended acceptance had they known that this paper will ultimately no long
er be able to claim the novelty that it claimed to have in the reviewed version.

Moreover this makes me wonder about th
e experimental section. Almost surely, reviewers would have demanded comparison to those 5 prior works as baselines. Thi
s paper did not compare against baselines, which will have seemed reasonable to a reviewer who reviewed this work under 
the assumption that the problem setting was completely novel and no prior methods exist that could function as a baselin
e.

Asking the group here about any thoughts on how such cases should get resolved:
- should the paper be retracted?
- s
hould the area chair / program committee be informed? who may or may not take action
- should the paper just get updated
 by authors in the way that was promised, and that is it?
- something else?

I redacted X, Y and Z in order to not publi
cly shame the authors, as they have engaged with my e-mails and I am convinced that there is no foul play and they truly
 were unaware of those works.
```
---

     
 
all -  [ Does anyone function more as a 'applied scientist' but have no research background? ](https://www.reddit.com/r/datascience/comments/1gxhjfr/does_anyone_function_more_as_a_applied_scientist/) , 2024-12-06-0914
```
**TLDR: DS profile is shifting to be more ML heavy, but lack research experience to compete with ML specialists.**

I've
 been a DS for several years, mostly in jack-of-all-trades functions: large-scale pipeline building, ad-hoc/bespoke stat
istical modeling for various stakeholders, ML applications, etc. More recently, I've started on a lot more GenAI/LLM wor
k alongside applied scientists. Leaving aside the negativity on LLM hype, most of the AS folks have heavy research backg
rounds: either PhDs or publications, attendance at conferences like ICLR, CVPR, NeurIPS, etc. I don't have any research 
experience except for a short stint in a lab during grad school but was never published. Luckily my AS peers have treate
d me as their own, which is good from credibility perspective.

That said, when I look at the market, DS jobs are either
 heavy on product analytics (hypothesis testing, experimentation, product sense, etc.) or DA/BI (dashboards, reporting, 
vis, etc.). The ones that are ML-heavier generally want much more research experience and involvement. I can explain the
 theory behind transformers, attention, decoders vs. encoders, etc. but I have zero publications and wouldn't stand a ch
ance against people with much deeper ML research experience.

I guess what I'm looking for is an applied/ML scientist-ad
jacent role, but still gives opportunity to flex to occasionally support other functions, like TPM'ing, DE, MLOps, etc. 
Aside from startups, there doesn't seem to be much out there. Anyone else?
```
---

     
 
all -  [ All the test environments used to benchmark BALROG. ](https://www.reddit.com/r/agi/comments/1gwqhry/all_the_test_environments_used_to_benchmark_balrog/) , 2024-12-06-0914
```
# BabyAI

+ Purpose is to facilitate research on *grounded language learning.*  The current domain of BabyAI is a 2D gri
dworld in which synthetic natural-looking instructions (e.g. “put the red ball next to the box on your left”) require th
e agent to navigate the world including unlocking doors) and move objects to specified locations.  

https://openreview.
net/forum?id=rJeXCo0cYX

----

# Crafter

+ Crafter features randomly generated 2D worlds where the player needs to fora
ge for food and water, find shelter to sleep, defend against monsters, collect materials, and build tools.

https://gith
ub.com/danijar/crafter?tab=readme-ov-file


----

# TextWorld

+ Microsoft TextWorld is an open-source, extensible engin
e that both generates and simulates text games. You can use it to train reinforcement learning (RL) agents to learn skil
ls such as language understanding and grounding, combined with sequential decision making.

https://www.microsoft.com/en
-us/research/project/textworld/

https://github.com/microsoft/TextWorld

https://arxiv.org/pdf/1806.11532

----

# Baba 
is AI 

+ Humans solve problems by following existing rules and procedures, and also by leaps of creativity to redefine 
those rules and objectives.    We test three ***state-of-the-art multi-modal large language models (OpenAI GPT-4o, Googl
e Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail dramatically*** when generalization requires that the rul
es of the game must be manipulated and combined. 


https://github.com/nacloos/baba-is-ai

https://arxiv.org/abs/2407.13
729

----

# MiniHack

+ MiniHack is a sandbox framework for easily designing rich and diverse environments for Reinforc
ement Learning (RL).   The motivation behind MiniHack is to be able to perform RL experiments in a controlled setting wh
ile being able to increasingly scale the complexity of the tasks.

https://github.com/facebookresearch/minihack

https:/
/minihack.readthedocs.io/en/latest/


----

# NetHack

+ NetHack is an attractive research platform as it contains hundr
eds of enemy and object types, has complex and stochastic environment dynamics, and has a clearly defined goal (descend 
the dungeon, retrieve an amulet, and ascend) which can be achieved in a diverse set of ways. The game is considered one 
of the hardest in the world1, with winning episodes lasting 100,000s of steps, and a permadeath setting that starts agen
ts at the beginning in a whole new world if they die in the dungeon. NetHack is even difficult to master for human playe
rs who often rely on external knowledge.


https://proceedings.neurips.cc/paper_files/paper/2023/file/764ba7236fb6374301
4fafbd87dd4f0e-Paper-Conference.pdf

https://github.com/upiterbarg/hihack

https://arxiv.org/pdf/2203.11889

https://www
.youtube.com/watch?v=8L8LiQ-cIWA
```
---

     
 
all -  [ Google Scholar Completely Disappeared Our Paper With 60+ Citations ](https://www.reddit.com/r/academia/comments/1gwjzrk/google_scholar_completely_disappeared_our_paper/) , 2024-12-06-0914
```
Our paper 'Real-Time Reinforcement Learning' published on [Arxiv](https://arxiv.org/abs/1911.04448) and [Neurips](https:
//papers.nips.cc/paper_files/paper/2019/hash/54e36c5ff5f6a1802925ca009f3ebb68-Abstract.html) was [correctly listed on Go
ogle Scholar](https://web.archive.org/web/20240603082519/https://scholar.google.com/citations?user=4_1LlbAAAAAJ&hl=en) s
ince 2019. At some point during the last few months it vanished from Google Scholar leaving only an info box without any
 links or citations on [my profile today](https://web.archive.org/web/20241121144849/https://scholar.google.com/citation
s?user=4_1LlbAAAAAJ&hl=en). Even [searching for it ](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=real+time+r
einforcement+learning+ramstedt+pal&btnG=)using the full title and author names yields no results now.  
  
It seems like
 Google Scholar erroneously and retroactively (after 5 years) merged our paper with another paper from 2019 with complet
ely different title and authors. The Google Scholar link on Arxiv explicitly referencing the Arxiv-ID now points to [ano
ther paper](https://scholar.google.com/scholar_lookup?arxiv_id=1911.04448). On that page, when clicking on 'All 14 Versi
ons', it then [shows versions of our paper](https://scholar.google.com/scholar?cluster=14219642840399587525&hl=en&as_sdt
=0,5). The only commonality between the two papers is that both papers were published at Neurips 2019.

Does anyone have
 an idea on how to fix this? As far as I know Google Scholar doesn't have a support email or support forum.


```
---

     
 
all -  [ [D] PhD in RL/ML Theory or LLM ](https://www.reddit.com/r/MachineLearning/comments/1gvx8vx/d_phd_in_rlml_theory_or_llm/) , 2024-12-06-0914
```
Hi guys,

I'm at a crossroads in my academic journey and would appreciate the community's insights. I'm trying to decide
 between pursuing a PhD focused on reinforcement learning/ML theory versus specializing in large language models with mo
re experimental/applied research (these are the only two offers I had).

# Key considerations are the following:

# Rese
arch Impact

* RL/ML Theory: Foundational work that could advance the field's mathematical understanding
* LLMs: Direct 
applications in today's most transformative AI systems

# Job Prospects

* Theory: Academia, research labs, potentially 
more limited industry roles
* LLMs: High industry demand, active research area in both academia and industry

# Long-ter
m Relevance

* Theory: Core principles likely to remain valuable regardless of specific technologies
* LLMs: Currently r
evolutionary but uncertain long-term trajectory

Personal background

* I'm an international student and about to finish
 my master program in US, so I no longer has enough time before making the final decision. I used to research in ml theo
ry, but did not end up with a real top conference publication in theory. I personally doubt if I have enough mathematica
l background to pursue a successful PhD in this area (e.g., at least publish 2 theory papers a year on ICML/NeurIPS/ICLR
/COLT/AISTATS). At the same time, I am personally doubting if theory works indeed advance the ML/AI community, as many p
apers are just proving vacuous bounds or propose some new algorithms that themselves cannot even implement or experiment
ally tested.
* I also used to research in more applied ml, with one aaai paper. My personal concerns is that I'm not fas
t at implementation and coding, the most strategic ability for a successful applied ML researcher. After we entered the 
LLM era, the pacing or applied ML research (especially in LLM and CV) becomes so fast. It's like competitive programming
 in research community (well, also the #GPUs competition).
```
---

     
 
all -  [ That’s it folks! ](https://i.redd.it/69mlt91aku1e1.jpeg) , 2024-12-06-0914
```
(Not the person in the post)
```
---

     
 
all -  [ [D] Expectation from Machine Learning Engineering jobs ](https://www.reddit.com/r/MachineLearning/comments/1gtt099/d_expectation_from_machine_learning_engineering/) , 2024-12-06-0914
```
Hey everyone,

I’ve seen a lot of posts here about careers in ML and landing internships or jobs, and two things come up
 a lot

1. Building a strong research portfolio and publishing at conferences like NeurIPS, ICLR, and ICML, which seems 
to focus more on getting research scientist roles.

2. The growing demand for Machine Learning Engineer (MLE) roles, whi
ch are apparently more in demand than research scientist positions.

I’m curious about the difference between these two 
roles and what kind of portfolio would be ideal for landing an MLE position. I know having a master’s degree is often pr
eferred, but is an impressive publication record necessary for MLE roles? Or is it not that big of a deal?

What are you
r thoughts?
```
---

     
 
all -  [ On the current state of robotics (ig?) (from a CSE perspective) (For all my homies out there) ](https://www.reddit.com/r/Btechtards/comments/1gsjxio/on_the_current_state_of_robotics_ig_from_a_cse/) , 2024-12-06-0914
```
Follow up on [https://www.reddit.com/r/Btechtards/comments/1gseqvq/cs\_roadmap\_for\_all\_my\_1st\_year\_homes\_out\_the
re/](https://www.reddit.com/r/Btechtards/comments/1gseqvq/cs_roadmap_for_all_my_1st_year_homes_out_there/)

Background -
 CSE 4th year, T1 (idk much about the electronics aspects of robotics and I kinda do computer vision not robotics)

\---
Profs---

I have like a research-ish approach to robotics cause of labs and stuff. Here's how I judge research - [https:
//csrankings.org/#/index?all&us](https://csrankings.org/#/index?all&us) (only considers the good conferences)

As for Ro
botics and CV in India - [https://csrankings.org/#/index?vision&robotics&in](https://csrankings.org/#/index?vision&robot
ics&in)

You get the usual research heavy unis (IIIT H, IISc, IIT K).

Let's go from a professor perspective, here are t
he absolute beasts in India (in no particular order) (CV + robotics):

1. K Madhava Krishna (IIIT H): [https://scholar.g
oogle.co.in/citations?user=QDuPGHwAAAAJ&hl=en](https://scholar.google.co.in/citations?user=QDuPGHwAAAAJ&hl=en)
2. C V Ja
wahar (IIIT H): [https://scholar.google.com/citations?user=U9dH-DoAAAAJ&hl=en](https://scholar.google.com/citations?user
=U9dH-DoAAAAJ&hl=en)
3. R. Venkatesh Babu (IISc): [https://cds.iisc.ac.in/faculty/venky](https://cds.iisc.ac.in/faculty/
venky)
4. Shishir N Y Kolathaya (IISc): [https://www.shishirny.com/](https://www.shishirny.com/)
5. Indranil Saha (IIT K
): [https://scholar.google.com/citations?user=F6QSFGkAAAAJ&hl=en](https://scholar.google.com/citations?user=F6QSFGkAAAAJ
&hl=en)
6. Avinash Sharma (IIT J): [https://3dcomputervision.github.io/](https://3dcomputervision.github.io/)
7. Chetan 
Arora (IIT D): [https://www.cse.iitd.ac.in/\~chetan/](https://www.cse.iitd.ac.in/~chetan/)

(Lmk if I should add any)

H
ere's how I would have started:

1. Look up their research and try to make sense out of it
2. Look at their top 5 newest
 papers and top 5 papers and see if you understand the abstract. If you don't relentelessly use Perplexity and get infor
mation.

Now you know the SOTA in India for robotics and CV. Then, look at these international profs (trying to add 5 in
 no order that have diverse research interests)

1. [https://www.cs.cmu.edu/\~./choset/](https://www.cs.cmu.edu/~./chose
t/)
2. [https://people.eecs.berkeley.edu/\~svlevine/](https://people.eecs.berkeley.edu/~svlevine/) (absolute fucking god
 imo)
3. [https://animesh.garg.tech/](https://animesh.garg.tech/)
4. [https://research.qut.edu.au/qcr/people/michael-mil
ford](https://research.qut.edu.au/qcr/people/michael-milford)
5. [https://people.eecs.berkeley.edu/\~anca/](https://peop
le.eecs.berkeley.edu/~anca/) (HCI stuff but I consider her robotics)

Good, now you know what's happening in academia. S
ince industry stems from academic esp. in robotics, you also know what will be happening there 5 years down the line. Lo
ok at cool stuff from Boston Dynamics (duh), Allen Institue for AI, Honda Research, etc. as well. Some pretty amazing Ch
inese and Israeli companies exist as well.

\---Starting with robotics---

I'm a sucker for mobile robotics -

1. [https
://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN\_](https://www.youtube.com/playlist?list=PLgnQpQtFTOG
QrZ4O5QzbIHgl3b1JHimN_)
2. [https://www.youtube.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp\_yMb4v](https://www.youtu
be.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp_yMb4v)
3. [https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh\_J16IM
wDlji18SWQ2PZ6](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh_J16IMwDlji18SWQ2PZ6)

All by C. Stachniss.

Then, q
uite literally do any course on robot manipulation and dynamics.

Then, start OpenCV - the docs are beautiful. Use them.
 Use Python. Learn PyTorch as well! (docs work).

Learn ROS using the docs (or any playlist tbh, all are pretty good).


Tie eveyrthing together by building a CV + Robotics pipeline using ROS simulations such as camera calibration, SLAM pipe
line, etc.

\---Going ahead---

Take a top-tier robotics paper (one that is not too math-y but more ML-y) and read their
 codebases. Literally just google any of the papers from the conferences listed below and choose one that sounds interes
ting (and has the codebase available).

Then, and I cannot emphasize this further, write your own implementation. It mig
ht take weeks (and ik the difficulties involved vis-a-vis hardware or GPUs - just simulate / do on a lower scale) but it
'll be worth it.

My fav repos are

1. [https://github.com/amaralibey/MixVPR](https://github.com/amaralibey/MixVPR)
2. [
https://github.com/robodhruv/visualnav-transformer](https://github.com/robodhruv/visualnav-transformer) (all three of th
e codebases)
3. [https://github.com/PRBonn/kiss-icp](https://github.com/PRBonn/kiss-icp)

(Again, lmk if you have any ad
ditions to this list)

Robotics honestly just diversifies at this point. Choose a direction that interests you (SLAM, ha
rdware, optimizations, vision, HCI, etc.)

\---Jobs?---

Join academia or a research lab (none in India unfortunately). 
You can cold-email profs asking for research internships or assistantships - that works sometimes. CAIR in Blr is also a
mazing.

Industry - some super cool stuff in India as well rn (minuszero, Swaayatt Robots, a bunch of drone companies, e
tc.). Nvidia also has some cool roles as well.

\---Should you do it?---

Idk. I'm an undergrad. This is what I've done 
and what some PhDs and MS people told me. Ask people on LinkedIn / Twitter to figure out whether robotics (and which par
t of robotics specifically) is what you want.

\---Conferences---

Robotics - ICRA, IROS, CORL, RSS

CV - CVPR, ICCV, EC
CV, BMVC, WACV (people also submit CV stuff to ICLR, NeurIPS, ICML, etc)


```
---

     
 
all -  [ [R] Convolutional Differentiable Logic Gate Networks ](https://www.reddit.com/r/MachineLearning/comments/1gs92mb/r_convolutional_differentiable_logic_gate_networks/) , 2024-12-06-0914
```
Abstract

With the increasing inference cost of machine learning models, there is a growing interest in models with fast
 and efficient inference. Recently, an approach for learning logic gate networks directly via a differentiable relaxatio
n was proposed.  Logic gate networks are faster than conventional neural network approaches be- cause their inference on
ly requires logic gate operators such as NAND, OR, and XOR, which are the underlying building blocks of current hardware
 and can be efficiently executed. We build on this idea, extending it by deep logic gate tree convolutions, logical OR p
ooling, and residual initializations. This allows scaling logic gate networks up by over one order of magnitude and util
izing the paradigm of convolution. On CIFAR-10, we achieve an accuracy of 86.29% using only 61 million logic gates, whic
h improves over the SOTA while being 29× smaller.

  
Accepted at Neurips 2024, 'SOTA' here means comparable approaches.
 I found this paper really interesting, even though non-toy networks seems like they would be very expensive to train. C
urious what others think?
```
---

     
 
all -  [ How is the ACL Conference? ](https://www.reddit.com/r/deeplearning/comments/1gs7he7/how_is_the_acl_conference/) , 2024-12-06-0914
```
Hello, I know it's a very noob question but I was wondering what the reputation of ACL is in the field. I have been writ
ing my first paper and my mentor recommended that I aim for the ACL deadline, I just wanted to know how prestigious it w
as relative to bigger conferences like NeurIPS, ICML, ICLR, etc.

Also, purely hypothetical, but what weight does an ACL
 acceptance hold for getting a summer internship/research? I'm an undergrad and I'm kind of cooked with my summer intern
ship prospects, so I was wondering if it would help in any regard.
```
---

     
 
all -  [ [D] Neurips 2024 Hotel Roommate Search ](https://www.reddit.com/r/MachineLearning/comments/1gs0gj8/d_neurips_2024_hotel_roommate_search/) , 2024-12-06-0914
```
The hotels around the venue for Neurips 2024 are pretty expensive, and I'm looking for a roommate to split the cost with
 (my university has a limit on the nightly hotel rate they are willing to reimburse). I currently have reserved a room f
or Tuesday-Sunday in the Century Plaza Hotel, which is 0.9 miles from the convention center. The nightly rate is $414. I
f anyone wants to split the cost of a room, please reach out! Also, it would be helpful if you could share this post wit
h your research group or other attendees that you know.

If you are unsure about rooming with a complete stranger, you c
an get to know me a little bit through my personal website (https://mtcrawshaw.github.io/), which has links to my google
 scholar page, CV, etc. I do have a paper at the conference in the area of federated learning/distributed optimization. 
Just a grad student trying to make conferences affordable! Thanks.
```
---

     
 
all -  [ Need an Advice ](https://www.reddit.com/r/PhD/comments/1grg73d/need_an_advice/) , 2024-12-06-0914
```
Hi everyone, I’m a first-year computer science PhD student in Europe from Asia, going into my second year soon. I wanted
 to ask for some advice on what I should do. First off, I’m an international student from a Southeast Asian country, and
 right now I’m really struggling with the lab environment.

First, my professor requires all PhD students to work in the
 lab from 9 to 5 every weekday, no exceptions except for weekends. We’re only allowed to take time off when the universi
ty is officially closed. Second, I found out from previous PhD students that my professor insists on a strict policy of 
“equal credit” in publications, meaning that even if I do all the work for a paper—from analysis to programming, writing
, and revisions—my name won’t be listed as the first author because authorship order is strictly alphabetical.

Third, s
ome of us in the lab (we’re all international students) aren’t allowed to submit our papers to conferences, even big one
s like ICML or NeurIPS. My professor only wants our publications in journals, even though conferences are important for 
PhD students to network and get feedback from experts in the field.

Lastly, and perhaps the most difficult part for me,
 is that I’m not allowed to collaborate with anyone outside the lab. I’m not even allowed to discuss my project or seek 
advice from people outside the lab group. This restriction makes me feel isolated, and for the past three months, I’ve h
ad recurring nightmares and panic attacks before going into the lab. I reached out to the PhD board to ask if I could tr
ansfer to a different lab, but they said it’s impossible.

I’m really at a loss here. Should I stick it out in this lab 
for the next 2-3 years, knowing I won’t have the chance to publish as the primary author and that, when I graduate, I’ll
 probably have no network beyond the people in this lab?
```
---

     
 
all -  [ [D] Looking for a project partner who's published in top conferences [cvpr, neurips, wacv, iccv, etc ](https://www.reddit.com/r/computervision/comments/1gpfcpk/d_looking_for_a_project_partner_whos_published_in/) , 2024-12-06-0914
```
Hello y'all. Deep into my master's degree, I am in a dire need of a mentor/partner for my research partner. Some of the 
professors at the academia who claim to specialize in the field of computer vision/ai doesnt know how to clone an existi
ng model from github or provide gpu alternatives and solutions who doesnt have fancy things to speed up the process. 

s
o if you do feel the same way and is interested to work on some cool research gap leading to a publication. drop a comme
nt on what excites you most. thankss.
```
---

     
 
all -  [ [D] How to Choose an AI-Focused Master's Program? ](https://www.reddit.com/r/computervision/comments/1gpba3y/d_how_to_choose_an_aifocused_masters_program/) , 2024-12-06-0914
```
I'm currently applying for AI-focused Master's programs, and I could really use some advice. I love working in computer 
vision, and I think I’m genuinely passionate about research. I presented my first paper at an affinity workshop at ICML,
 and I’ll be attending NeurIPS as a workshop presenter. This experience has been a blast, and I'm hoping to continue dow
n this path.

Right now, I'm feeling overwhelmed by all the options and the looming deadlines. The only program I’m trul
y excited about is at UvA (University of Amsterdam). But I know I need to consider more options to keep my career moving
 forward.

Here’s what I'm interested in:

* **Self-Supervised Learning (SSL):** I have experience in this area and woul
d love to deepen my expertise.
* **Video Understanding and GNNs:** These are becoming my newest interests, and I’d love 
to join a program where I can explore these topics.
* **Research-oriented environments:** I’m currently collaborating wi
th a professor and have found that I really enjoy the collaborative, exploratory nature of research.

The problem? I don
’t want to settle for a program that doesn’t align with these interests or doesn’t offer strong mentorship and research 
opportunities. I’m also worried I might be *too* picky, which is making the process even more stressful. I’d love to hea
r from anyone who’s been in a similar position:

1. **How did you prioritize which programs to apply to?**
2. **Did you 
find a strategy that helped you balance your interests with program options?**
3. **Any advice on picking a program that
 will help with a long-term research-focused career?**

Thanks so much for any insights you can share!
```
---

     
 
all -  [ [D] NeurIPS After Dark Networking Event ](https://www.reddit.com/r/MachineLearning/comments/1gpamvn/d_neurips_after_dark_networking_event/) , 2024-12-06-0914
```
Just got an email about an official ticketed after dark NeurIPS networking event - this will be my first time attending/
presenting, wondering if these events are worth going to. More generally, also interested in hearing about how to make t
he most of my time attending.
```
---

     
 
all -  [ NeuroAI - NeurIPS Workshop (Vancouver, Dec 15) ](https://www.reddit.com/r/corticallabs/comments/1gp8lg5/neuroai_neurips_workshop_vancouver_dec_15/) , 2024-12-06-0914
```
Hey all, just wanted to make the announcement that some of the Cortical Labs team will be in Vancouver for NeurIPS and C
TO Dave will be publishing the beta API spec for community feedback.

  
[https://neuroai-workshop.github.io](https://ne
uroai-workshop.github.io)
```
---

     
 
all -  [ Anyone's paper got selected for NeurIPS and are planning to go to Vancouver from Bengaluru??? ](https://www.reddit.com/r/Bengaluru/comments/1go3w7w/anyones_paper_got_selected_for_neurips_and_are/) , 2024-12-06-0914
```
If anyone is traveling, i really need your help in planning mine. 
```
---

     
 
all -  [ [R] Classic GNNs (GCNs, GraphSAGEs, GATs) are Strong Baselines on Node Classification ](https://www.reddit.com/r/MachineLearning/comments/1gnsn54/r_classic_gnns_gcns_graphsages_gats_are_strong/) , 2024-12-06-0914
```
We’re excited to share our recent paper '[\[NeurIPS 2024\] Classic GNNs are Strong Baselines: Reassessing GNNs for Node 
Classification](https://arxiv.org/pdf/2406.08993).'

In this study, we conduct a thorough review of classic GNNs for nod
e classification tasks. Our findings suggest that the superior performance often reported by state-of-the-art graph lear
ning models may be due to suboptimal hyperparameter configurations in classic GNNs. By fine-tuning these hyperparameters
, we show that classic GNNs outperform the latest models on 17 out of 18 widely used node classification datasets.

Code
: [https://github.com/LUOyk1999/tunedGNN](https://t.co/QeNSn2D9CN)  
Arxiv: [https://arxiv.org/abs/2406.08993](https://t
.co/MD4mVTnHk8)

If you find our work interesting, we’d greatly appreciate a ⭐️ on GitHub!
```
---

     
 
all -  [ CV Sugession ](https://www.reddit.com/r/gradadmissions/comments/1gnbr8g/cv_sugession/) , 2024-12-06-0914
```
I  tried to publish research papers twice—first at NeurIPS and recently at ICVGIP—but I got rejected both times 🥲.

Now,
 I am thinking of adding a section to my CV called “Appendix: Research Work Sample since I don’t have any published pape
rs yet. Should I include these papers and label them as “submitted” or “submitted to conf __”?

I would really appreciat
e your advice.
```
---

     
 
all -  [ Ok, for real how do I rank? ](https://www.reddit.com/r/eb_1a/comments/1gn2zo7/ok_for_real_how_do_i_rank/) , 2024-12-06-0914
```
I was pretty certain that my pathway to green card was gonna be smooth… until the Trump victory. I’m gearing up for EB1A
 but worried that the extra scrutiny during his term will close that door for me. Here are the stats.

- FAANG ML Engine
er with MSc
- Some media coverage of my work
- 4 papers, 3 preprints, 1 industrial demo, 1 thesis, first author on all b
ut 2; some are top-tier like CVPR and ACL
- 450+ citations
- have served as reviewer for about 50 manuscripts; all for t
he top tier conferences (CVPR, NeurIPS, ICML, ICLR)

Am I toast or can I gun for EB1A?
```
---

     
 
all -  [ [R] Most Time Series Anomaly Detection results are meaningless (two short videos explain why) ](https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/) , 2024-12-06-0914
```
Dear Colleagues

Time Series Anomaly Detection (TSAD) is hot right now, with dozens of  papers each year in NeurIPS, SIG
KDD, ICML, PVLDB etc.

However, I claim that much of the published results are meaningless, because the uncertainty of t
he ground truth labels dwarfs any claimed differences between algorithms or amount of claimed improvements.

I have made
 two 90-second-long videos that make this clear in a visual and intuitive way:

 1)      Why Most Time Series Anomaly De
tection Results are Meaningless (Dodgers)

[https://www.youtube.com/watch?v=iRN5oVNvZwk&ab\_channel=EamonnKeogh](https:/
/www.youtube.com/watch?v=iRN5oVNvZwk&ab_channel=EamonnKeogh)

  2)      Why Most Time Series Anomaly Detection Results a
re Meaningless (AnnGun)

[https://www.youtube.com/watch?v=3gH-65RCBDs&ab\_channel=EamonnKeogh](https://www.youtube.com/w
atch?v=3gH-65RCBDs&ab_channel=EamonnKeogh)

As always, corrections and comments welcome.

Eamonn

 EDIT: To be clear, my
 point is simply to prevent others from wasting time working with datasets with essentially random labels. In addition, 
we should be cautious of any claims in the literature that are based on such data (and that includes at least dozens of 
highly cited papers)

  


For a review of most of the commonly used TSAD datasets, see this file:

[https://www.dropbox
.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&dl=0](
https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyj
splu0u1t7ugg&dl=0)
```
---

     
 
all -  [ Boss wants me in Vancouver for neurips conference. Please take my 1 tix, 5 day pass. Selling at cost ](https://www.reddit.com/r/Wonderfruit/comments/1gmvwe0/boss_wants_me_in_vancouver_for_neurips_conference/) , 2024-12-06-0914
```
I have one 5 day pass, bought it during early bird. Can change name during pre-registration. I want to make no profit fr
om this. Heck, I’ll give you a discount. But I need to talk to you up front, and we need to figure out a payment situati
on. 

Best case scenario is that you’re in the United States.

Reply to this and I will reach out.
```
---

     
 
all -  [ Alaa Lab at UC Berkeley / UCSF Seeking PhD Students in ML/AI for Healthcare ](https://www.reddit.com/r/CompSocial/comments/1gmh3q6/alaa_lab_at_uc_berkeley_ucsf_seeking_phd_students/) , 2024-12-06-0914
```
Prof. Ahmad Alaa, who leads a [joint lab](https://alaalab.berkeley.edu/home) at UC Berkeley and UCSF is seeking PhD appl
icants interested in working at the intersection of ML/AI and Healthcare. They call out the following focus areas, with 
example papers:

* **Track 1:** **Machine Learning Theory, Statistics and Causal Inference** (Example papers: [NeurIPS 2
024](https://arxiv.org/abs/2402.07307), [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023/hash/94ab02
a30b0e4a692a42ccd0b4c55399-Abstract-Conference.html), [AISTATS 2023](https://proceedings.mlr.press/v206/alaa23a.html))
*
 **Track 2: Large Vision and Language Models for Medicine** (Example papers: [NeurIPS 2024 - 1](https://arxiv.org/abs/24
03.00177), [NeurIPS 2024 - 2](https://arxiv.org/pdf/2405.19567), [ICML 2024](https://arxiv.org/pdf/2406.05396), [ICLR 20
24](https://arxiv.org/abs/2310.00390), [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2b1d1e5
affe5fdb70372cd90dd8afd49-Abstract-Conference.html))
* **Track 3: Applied Machine Learning for Cardiology** (Example pap
ers: [Nature Machine Intelligence 2021](https://www.nature.com/articles/s42256-021-00353-8), [PLOS 2019](https://journal
s.plos.org/plosone/article?id=10.1371/journal.pone.0213653))

To learn more and connect with Dr. Alaa prior to submittin
g a PhD application, check out this Google Form: [https://docs.google.com/forms/d/e/1FAIpQLScgiULXsOJjsnK2y9av10ztg-gGCL
hCX\_eybpwHxwYv-ZmJmA/viewform](https://docs.google.com/forms/d/e/1FAIpQLScgiULXsOJjsnK2y9av10ztg-gGCLhCX_eybpwHxwYv-ZmJ
mA/viewform)
```
---

     
 
all -  [ CAN I GET INTO HARVARD + UC's ](https://www.reddit.com/r/chanceme/comments/1gm5icr/can_i_get_into_harvard_ucs/) , 2024-12-06-0914
```
**Demographics**:

* low ranking HS, 250 ish grad class
* Asian
* Hook: I play chess
* CS BA or BS

**GPA**: 3.7 W(good 
reasons why so low just trust)

No rank in my HS

7 APs, 8 Tests

SAT - 1500 composite

**Awards**:

* AP scholar with h
onors
* honor roll
* Top 100 nationally ranked chess players In age groups for the past 4 years
* USCF candidate master

* Won an international/national tournament + state champ in chess

**ECs:**

* High School Chess league president - 20+ 
schools, 100+ participants, $1k+ raised
* 1st author to Novel Ai paper - published and submitted to conferences like Neu
rips + COLING, available on arXiv
* Chess Club president - 3 peat champion in regional league, top 5 teams in State
* DE
CA - 3x state qualifier
* Motorola Solutions Intern - made a REST API for one of their apps in prod
* Paid Chess coach -
 Apart of non-profit group for underprivileged youth in chicago(not from there did remote)
* Volunteer Chess Coach - vol
unteered apart of local chess academy, 200 ish hours over the 4 years
* Wrestling - Varsity
* SASA(south asian student a
ssociation) treasurer - raised 10k from sponsors and events, provided scholarships for the first year to south asian stu
dents
* Inspirit AI scholars program(free) - Made Chess bot with GPT 4o capable of playing at an expert level

**Persona
l Statement:** 8.5/10 (not insanely good, but everyone who reads it likes it, and reviewers can't find problems with it,
 so conservative 7.5, but 9.5/10 liberally)

**Colleges**:  
Reach: HARVARD, UMICH, CMU, UMD, UWM, NEU,  UCLA, Cal, UCSD


Target: Ohio State, Penn State, Purdue, IU, Vtech, UMass Amherst

Safety: UPitt, RIT, Bentley, Rutgers

  

```
---

     
 
all -  [ Question about EB2 NIW and re-election of President Trump ](https://www.reddit.com/r/USCIS/comments/1glc0s5/question_about_eb2_niw_and_reelection_of/) , 2024-12-06-0914
```
Hey, I have a question about possible effects of the recent re-election on my application as an Iranian citizen (male) w
ho recently filed their I140. I'm wondering if I should apply for premium processing or not.

# About my profile:

I'm a
 PhD student (started in January 2024) in the states studying deep learning (theory). I have three first-author publishe
d works on deep learning theory that align well with my research interests and what I'm working on right now.:One at Neu
rIPS 2022, 26 citations.One at ICML 2023, 16 citations.One at ICML 2024, 4 citations.I have another submission that is n
ot published yet on which I'm the second author.I've received a masters in CS from a top-tier university in Canada (UBC)
.

# My Concern:

I've filed my I140 on October 20th this year. As an Iranian citizen, I’m worried about the possibility
 of my application being affected by the re-election of President Trump. Because of that, I’m considering applying for p
remium processing to get a decision on my I140 before potential new laws/orders come into effect. From talking to friend
s I’ve heard that there are possibilities that:

* The approval bar goes higher
* The processing time slows down
* etc


2805$ is not nothing for me, as I’m a PhD student. I can pay it, but it’s not easy on me.

I’m wondering if I should app
ly for PP nevertheless, or if the chances of my application getting affected by the re-election are slim. Any advice wou
ld be appreciated! Thanks.
```
---

     
 
all -  [ Question about EB2 NIW and re-election of President Trump ](https://www.reddit.com/r/EB2_NIW/comments/1glbyrt/question_about_eb2_niw_and_reelection_of/) , 2024-12-06-0914
```
Hey, I have a question about possible effects of the recent re-election on my application as an Iranian citizen (male) w
ho recently filed their I140. I'm wondering if I should apply for premium processing or not.

# About my profile:

I'm a
 PhD student (started in January 2024) in the states studying deep learning (theory). I have three first-author publishe
d works on deep learning theory that align well with my research interests and what I'm working on right now.:One at Neu
rIPS 2022, 26 citations.One at ICML 2023, 16 citations.One at ICML 2024, 4 citations.I have another submission that is n
ot published yet on which I'm the second author.I've received a masters in CS from a top-tier university in Canada (UBC)
.

# My Concern:

I've filed my I140 on October 20th this year. As an Iranian citizen, I’m worried about the possibility
 of my application being affected by the re-election of President Trump. Because of that, I’m considering applying for p
remium processing to get a decision on my I140 before potential new laws/orders come into effect. From talking to friend
s I’ve heard that there are possibilities that:

* The approval bar goes higher
* The processing time slows down
* etc


2805$ is not nothing for me, as I’m a PhD student. I can pay it, but it’s not easy on me. 

I’m wondering if I should ap
ply for PP nevertheless, or if the chances of my application getting affected by the re-election are slim. Any advice wo
uld be appreciated! Thanks.
```
---

     
 
all -  [ Ethics in AI ](https://www.reddit.com/r/ArtificialInteligence/comments/1gkndse/ethics_in_ai/) , 2024-12-06-0914
```
What are some good learning/certificate opportunities to enter the AI ethics space? Are there other volunteer opportunit
ies to do ethics reviews on papers besides NeurIPS (and what are the requirements to become an ethics reviewer?) 
```
---

     
 
all -  [ Is implementing famous research papers in ML worthy of writing in a resume? ](https://www.reddit.com/r/Btechtards/comments/1gjym1x/is_implementing_famous_research_papers_in_ml/) , 2024-12-06-0914
```
Title. I am currently in my 3rd year of BTech in CSE. I’ve been interested in ML/DL for quite some time now. And I was t
hinking of doing this. Is it okay to put them in resume for applying to research/industry internships?

Papers that I am
 thinking of implementing in no particular order:

- [Attention Is All You Need](https://proceedings.neurips.cc/paper_fi
les/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [Hand Written Digit Recognition Using Back Propagation
 Neural Network](https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf)
- [An IMage 
is worth 16x16 words](https://openreview.net/pdf?id=YicbFdNTTy) Vision Transformer
- [LoRA- Low-Rank Adaptation Method f
or LLMs](https://openreview.net/pdf?id=nZeVKeeFYf9)
- [RAG paper from 2020](https://arxiv.org/pdf/2005.11401)
- [ESRGAN]
(https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversar
ial_Networks_ECCVW_2018_paper.pdf)
```
---

     
 
all -  [ Do I have to upload a poster and a video recording for my accepted paper in NeurIPS 2024 to be publi ](https://www.reddit.com/r/learnmachinelearning/comments/1gjx8bv/do_i_have_to_upload_a_poster_and_a_video/) , 2024-12-06-0914
```
I registered the virtual pass of NeurIPS 2024. Do I have to upload a poster and a video recording for my accepted paper 
in NeurIPS 2024 to be published? The emails or the instructions do not make any clarification about this. 
```
---

     
