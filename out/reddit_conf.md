 
all -  [ Anyone's paper got selected for NeurIPS and are planning to go to Vancouver from Bengaluru??? ](https://www.reddit.com/r/Bengaluru/comments/1go3w7w/anyones_paper_got_selected_for_neurips_and_are/) , 2024-11-11-0913
```
If anyone is traveling, i really need your help in planning mine. 
```
---

     
 
all -  [ [R] Classic GNNs (GCNs, GraphSAGEs, GATs) are Strong Baselines on Node Classification ](https://www.reddit.com/r/MachineLearning/comments/1gnsn54/r_classic_gnns_gcns_graphsages_gats_are_strong/) , 2024-11-11-0913
```
We‚Äôre excited to share our recent paper '[\[NeurIPS 2024\] Classic GNNs are Strong Baselines: Reassessing GNNs for Node 
Classification](https://arxiv.org/pdf/2406.08993).'

In this study, we conduct a thorough review of classic GNNs for nod
e classification tasks. Our findings suggest that the superior performance often reported by state-of-the-art graph lear
ning models may be due to suboptimal hyperparameter configurations in classic GNNs. By fine-tuning these hyperparameters
, we show that classic GNNs outperform the latest models on 17 out of 18 widely used node classification datasets.

Arxi
v:¬†[https://arxiv.org/abs/2406.08993](https://t.co/MD4mVTnHk8)  
Code:¬†[https://github.com/LUOyk1999/tunedGNN](https://t
.co/QeNSn2D9CN)

If you find our work interesting, we‚Äôd greatly appreciate a ‚≠êÔ∏è on GitHub!
```
---

     
 
all -  [ CV Sugession ](https://www.reddit.com/r/gradadmissions/comments/1gnbr8g/cv_sugession/) , 2024-11-11-0913
```
I  tried to publish research papers twice‚Äîfirst at NeurIPS and recently at ICVGIP‚Äîbut I got rejected both times ü•≤.

Now,
 I am thinking of adding a section to my CV called ‚ÄúAppendix: Research Work Sample since I don‚Äôt have any published pape
rs yet. Should I include these papers and label them as ‚Äúsubmitted‚Äù or ‚Äúsubmitted to conf __‚Äù?

I would really appreciat
e your advice.
```
---

     
 
all -  [ Ok, for real how do I rank? ](https://www.reddit.com/r/eb_1a/comments/1gn2zo7/ok_for_real_how_do_i_rank/) , 2024-11-11-0913
```
I was pretty certain that my pathway to green card was gonna be smooth‚Ä¶ until the Trump victory. I‚Äôm gearing up for EB1A
 but worried that the extra scrutiny during his term will close that door for me. Here are the stats.

- FAANG ML Engine
er with MSc
- Some media coverage of my work
- 4 papers, 3 preprints, 1 industrial demo, 1 thesis, first author on all b
ut 2; some are top-tier like CVPR and ACL
- 450+ citations
- have served as reviewer for about 50 manuscripts; all for t
he top tier conferences (CVPR, NeurIPS, ICML, ICLR)

Am I toast or can I gun for EB1A?
```
---

     
 
all -  [ [R] Most Time Series Anomaly Detection results are meaningless (two short videos explain why) ](https://www.reddit.com/r/MachineLearning/comments/1gmwxnr/r_most_time_series_anomaly_detection_results_are/) , 2024-11-11-0913
```
Dear Colleagues

Time Series Anomaly Detection (TSAD) is hot right now, with dozens of ¬†papers each year in NeurIPS, SIG
KDD, ICML, PVLDB etc.

However, I claim that much of the published results are meaningless, because the uncertainty of t
he ground truth labels dwarfs any claimed differences between algorithms or amount of claimed improvements.

I have made
 two 90-second-long videos that make this clear in a visual and intuitive way:

¬†1)¬†¬†¬†¬†¬† Why Most Time Series Anomaly De
tection Results are Meaningless (Dodgers)

[https://www.youtube.com/watch?v=iRN5oVNvZwk&ab\_channel=EamonnKeogh](https:/
/www.youtube.com/watch?v=iRN5oVNvZwk&ab_channel=EamonnKeogh)

¬†¬†2)¬†¬†¬†¬†¬† Why Most Time Series Anomaly Detection Results a
re Meaningless (AnnGun)

[https://www.youtube.com/watch?v=3gH-65RCBDs&ab\_channel=EamonnKeogh](https://www.youtube.com/w
atch?v=3gH-65RCBDs&ab_channel=EamonnKeogh)

As always, corrections and comments welcome.

Eamonn

¬†EDIT: To be clear, my
 point is simply to prevent others from wasting time working with datasets with essentially random labels. In addition, 
we should be cautious of any claims in the literature that are based on such data (and that includes at least dozens of 
highly cited papers)

  


For a review of most of the commonly used TSAD datasets, see this file:

[https://www.dropbox
.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyjsplu0u1t7ugg&dl=0](
https://www.dropbox.com/scl/fi/cwduv5idkwx9ci328nfpy/Problems-with-Time-Series-Anomaly-Detection.pdf?rlkey=d9mnqw4tuayyj
splu0u1t7ugg&dl=0)
```
---

     
 
all -  [ Boss wants me in Vancouver for neurips conference. Please take my 1 tix, 5 day pass. Selling at cost ](https://www.reddit.com/r/Wonderfruit/comments/1gmvwe0/boss_wants_me_in_vancouver_for_neurips_conference/) , 2024-11-11-0913
```
I have one 5 day pass, bought it during early bird. Can change name during pre-registration. I want to make no profit fr
om this. Heck, I‚Äôll give you a discount. But I need to talk to you up front, and we need to figure out a payment situati
on. 

Best case scenario is that you‚Äôre in the United States.

Reply to this and I will reach out.
```
---

     
 
all -  [ Alaa Lab at UC Berkeley / UCSF Seeking PhD Students in ML/AI for Healthcare ](https://www.reddit.com/r/CompSocial/comments/1gmh3q6/alaa_lab_at_uc_berkeley_ucsf_seeking_phd_students/) , 2024-11-11-0913
```
Prof. Ahmad Alaa, who leads a [joint lab](https://alaalab.berkeley.edu/home) at UC Berkeley and UCSF is seeking PhD appl
icants interested in working at the intersection of ML/AI and Healthcare. They call out the following focus areas, with 
example papers:

* **Track 1:**¬†**Machine Learning Theory, Statistics and Causal Inference** (Example papers: [NeurIPS 2
024](https://arxiv.org/abs/2402.07307), [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023/hash/94ab02
a30b0e4a692a42ccd0b4c55399-Abstract-Conference.html), [AISTATS 2023](https://proceedings.mlr.press/v206/alaa23a.html))
*
 **Track 2: Large Vision and Language Models for Medicine**¬†(Example papers: [NeurIPS 2024 - 1](https://arxiv.org/abs/24
03.00177), [NeurIPS 2024 - 2](https://arxiv.org/pdf/2405.19567), [ICML 2024](https://arxiv.org/pdf/2406.05396),¬†[ICLR 20
24](https://arxiv.org/abs/2310.00390), [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023/hash/2b1d1e5
affe5fdb70372cd90dd8afd49-Abstract-Conference.html))
* **Track 3: Applied¬†Machine Learning for Cardiology**¬†(Example pap
ers: [Nature Machine Intelligence 2021](https://www.nature.com/articles/s42256-021-00353-8),¬†[PLOS 2019](https://journal
s.plos.org/plosone/article?id=10.1371/journal.pone.0213653))

To learn more and connect with Dr. Alaa prior to submittin
g a PhD application, check out this Google Form: [https://docs.google.com/forms/d/e/1FAIpQLScgiULXsOJjsnK2y9av10ztg-gGCL
hCX\_eybpwHxwYv-ZmJmA/viewform](https://docs.google.com/forms/d/e/1FAIpQLScgiULXsOJjsnK2y9av10ztg-gGCLhCX_eybpwHxwYv-ZmJ
mA/viewform)
```
---

     
 
all -  [ CAN I GET INTO HARVARD + UC's ](https://www.reddit.com/r/chanceme/comments/1gm5icr/can_i_get_into_harvard_ucs/) , 2024-11-11-0913
```
**Demographics**:

* low ranking HS, 250 ish grad class
* Asian
* Hook: I play chess
* CS BA or BS

**GPA**: 3.7 W(good 
reasons why so low just trust)

No rank in my HS

7 APs, 8 Tests

SAT - 1500 composite

**Awards**:

* AP scholar with h
onors
* honor roll
* Top 100 nationally ranked chess players In age groups for the past 4 years
* USCF candidate master

* Won an international/national tournament + state champ in chess

**ECs:**

* High School Chess league president - 20+ 
schools, 100+ participants, $1k+ raised
* 1st author to Novel Ai paper - published and submitted to conferences like Neu
rips + COLING, available on arXiv
* Chess Club president - 3 peat champion in regional league, top 5 teams in State
* DE
CA - 3x state qualifier
* Motorola Solutions Intern - made a REST API for one of their apps in prod
* Paid Chess coach -
 Apart of non-profit group for underprivileged youth in chicago(not from there did remote)
* Volunteer Chess Coach - vol
unteered apart of local chess academy, 200 ish hours over the 4 years
* Wrestling - Varsity
* SASA(south asian student a
ssociation) treasurer - raised 10k from sponsors and events, provided scholarships for the first year to south asian stu
dents
* Inspirit AI scholars program(free) - Made Chess bot with GPT 4o capable of playing at an expert level

**Persona
l Statement:**¬†8.5/10 (not insanely good, but everyone who reads it likes it, and reviewers can't find problems with it,
 so conservative 7.5, but 9.5/10 liberally)

**Colleges**:  
Reach: HARVARD, UMICH, CMU, UMD, UWM, NEU,  UCLA, Cal, UCSD


Target: Ohio State, Penn State, Purdue, IU, Vtech, UMass Amherst

Safety: UPitt, RIT, Bentley, Rutgers

  

```
---

     
 
all -  [ Question about EB2 NIW and re-election of President Trump ](https://www.reddit.com/r/USCIS/comments/1glc0s5/question_about_eb2_niw_and_reelection_of/) , 2024-11-11-0913
```
Hey, I have a question about possible effects of the recent re-election on my application as an Iranian citizen (male) w
ho recently filed their I140. I'm wondering if I should apply for premium processing or not.

# About my profile:

I'm a
 PhD student (started in January 2024) in the states studying deep learning (theory). I have three first-author publishe
d works on deep learning theory that align well with my research interests and what I'm working on right now.:One at Neu
rIPS 2022, 26 citations.One at ICML 2023, 16 citations.One at ICML 2024, 4 citations.I have another submission that is n
ot published yet on which I'm the second author.I've received a masters in CS from a top-tier university in Canada (UBC)
.

# My Concern:

I've filed my I140 on October 20th this year. As an Iranian citizen, I‚Äôm worried about the possibility
 of my application being affected by the re-election of President Trump. Because of that, I‚Äôm considering applying for p
remium processing to get a decision on my I140 before potential new laws/orders come into effect.¬†From talking to friend
s I‚Äôve heard that there are possibilities that:

* The approval bar goes higher
* The processing time slows down
* etc


2805$ is not nothing for me, as I‚Äôm a PhD student. I can pay it, but it‚Äôs not easy on me.

I‚Äôm wondering if I should app
ly for PP nevertheless, or if the chances of my application getting affected by the re-election are slim. Any advice wou
ld be appreciated! Thanks.
```
---

     
 
all -  [ Question about EB2 NIW and re-election of President Trump ](https://www.reddit.com/r/EB2_NIW/comments/1glbyrt/question_about_eb2_niw_and_reelection_of/) , 2024-11-11-0913
```
Hey, I have a question about possible effects of the recent re-election on my application as an Iranian citizen (male) w
ho recently filed their I140. I'm wondering if I should apply for premium processing or not.

# About my profile:

I'm a
 PhD student (started in January 2024) in the states studying deep learning (theory). I have three first-author publishe
d works on deep learning theory that align well with my research interests and what I'm working on right now.:One at Neu
rIPS 2022, 26 citations.One at ICML 2023, 16 citations.One at ICML 2024, 4 citations.I have another submission that is n
ot published yet on which I'm the second author.I've received a masters in CS from a top-tier university in Canada (UBC)
.

# My Concern:

I've filed my I140 on October 20th this year. As an Iranian citizen, I‚Äôm worried about the possibility
 of my application being affected by the re-election of President Trump. Because of that, I‚Äôm considering applying for p
remium processing to get a decision on my I140 before potential new laws/orders come into effect.¬†From talking to friend
s I‚Äôve heard that there are possibilities that:

* The approval bar goes higher
* The processing time slows down
* etc


2805$ is not nothing for me, as I‚Äôm a PhD student. I can pay it, but it‚Äôs not easy on me. 

I‚Äôm wondering if I should ap
ply for PP nevertheless, or if the chances of my application getting affected by the re-election are slim. Any advice wo
uld be appreciated! Thanks.
```
---

     
 
all -  [ Ethics in AI ](https://www.reddit.com/r/ArtificialInteligence/comments/1gkndse/ethics_in_ai/) , 2024-11-11-0913
```
What are some good learning/certificate opportunities to enter the AI ethics space? Are there other volunteer opportunit
ies to do ethics reviews on papers besides NeurIPS (and what are the requirements to become an ethics reviewer?) 
```
---

     
 
all -  [ Is implementing famous research papers in ML worthy of writing in a resume? ](https://www.reddit.com/r/Btechtards/comments/1gjym1x/is_implementing_famous_research_papers_in_ml/) , 2024-11-11-0913
```
Title. I am currently in my 3rd year of BTech in CSE. I‚Äôve been interested in ML/DL for quite some time now. And I was t
hinking of doing this. Is it okay to put them in resume for applying to research/industry internships?

Papers that I am
 thinking of implementing in no particular order:

- [Attention Is All You Need](https://proceedings.neurips.cc/paper_fi
les/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [Hand Written Digit Recognition Using Back Propagation
 Neural Network](https://proceedings.neurips.cc/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf)
- [An IMage 
is worth 16x16 words](https://openreview.net/pdf?id=YicbFdNTTy) Vision Transformer
- [LoRA- Low-Rank Adaptation Method f
or LLMs](https://openreview.net/pdf?id=nZeVKeeFYf9)
- [RAG paper from 2020](https://arxiv.org/pdf/2005.11401)
- [ESRGAN]
(https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversar
ial_Networks_ECCVW_2018_paper.pdf)
```
---

     
 
all -  [ Do I have to upload a poster and a video recording for my accepted paper in NeurIPS 2024 to be publi ](https://www.reddit.com/r/learnmachinelearning/comments/1gjx8bv/do_i_have_to_upload_a_poster_and_a_video/) , 2024-11-11-0913
```
I registered the virtual pass of NeurIPS 2024. Do I have to upload a poster and a video recording for my accepted paper 
in NeurIPS 2024 to be published? The emails or the instructions do not make any clarification about this. 
```
---

     
 
all -  [ [D] Looking for Research Internship in Applied RL & Robotics ](https://www.reddit.com/r/MachineLearning/comments/1giq0e8/d_looking_for_research_internship_in_applied_rl/) , 2024-11-11-0913
```
I am a PhD candidate at Mila, working on reinforcement learning for different robotic applications (worked on applicatio
ns like excavator automation, physics-based character animation, and autonomous driving). I'm currently seeking a summer
 research internship for 2025, and I'm really interested in any roles that focus on applied RL or embodied AI.

Here‚Äôs a
 bit about my research journey so far:

* **Automatic Reward Modeling**: Developed methods for deriving reward functions
 from expert demonstration for excavator automation in Vortex Simulator. (Presented at the NeurIPS RL for Real-life Appl
ications workshop.)
* **Sample-Efficient RL**: Improved sample efficiency on the Atari benchmark through transformer-bas
ed discrete world modeling. (ICML 2024)
* **Compositional Motion Priors for Multi-Task RL**: I'm currently working on mu
lti-task learning for robotic locomotion with compositional motion priors, using Isaac Gym.
* **RL for Autonomous Drivin
g**: Designed a curriculum learning method for autonomous driving on the CARLA simulator, eliminating the need for compl
ex reward shaping. (Inria research student).

I‚Äôm also exploring the use of Diffusion Models alongside RL for stable, di
verse control strategies.

If anyone knows of relevant openings or has any advice on places that may value applied RL re
search, I‚Äôd really appreciate it.

Thank you so much for any leads or suggestions!

*My CV and more details are on my*¬†h
ttps://pranaval.github.io/*.*
```
---

     
 
all -  [ Looking for Research Internship in Applied RL & Robotics ](https://www.reddit.com/r/reinforcementlearning/comments/1gipwq6/looking_for_research_internship_in_applied_rl/) , 2024-11-11-0913
```
I am a PhD candidate at Mila, working on reinforcement learning for different robotic applications (worked on applicatio
ns like excavator automation, physics-based character animation, and autonomous driving). I'm currently seeking a summer
 research internship for 2025, and I'm really interested in any roles that focus on applied RL or embodied AI.

Here‚Äôs a
 bit about my research journey so far:

* **Automatic Reward Modeling**: Developed methods for deriving reward functions
 from expert demonstration for excavator automation in Vortex Simulator. (Presented at the NeurIPS RL for Real-life Appl
ications workshop.)
* **Sample-Efficient RL**: Improved sample efficiency on the Atari benchmark through transformer-bas
ed discrete world modeling. (ICML 2024)
* **Compositional Motion Priors for Multi-Task RL**: I'm currently working on mu
lti-task learning for robotic locomotion with compositional motion priors, using Isaac Gym.
* **RL for Autonomous Drivin
g**: Designed a curriculum learning method for autonomous driving on the CARLA simulator, eliminating the need for compl
ex reward shaping. (Inria research student).

I‚Äôm also exploring the use of Diffusion Models alongside RL for stable, di
verse control strategies.

If anyone knows of relevant openings or has any advice on places that may value applied RL re
search, I‚Äôd really appreciate it.

Thank you so much for any leads or suggestions!

*My CV and more details are on my* *
https://pranaval.github.io/.*
```
---

     
 
all -  [ [D] Publishing in NeurIPS, ICML, ICLR as an Early Researcher: Any Advice? ](https://www.reddit.com/r/MachineLearning/comments/1gip4cf/d_publishing_in_neurips_icml_iclr_as_an_early/) , 2024-11-11-0913
```
I'm currently pursuing a master's degree, and my goal is to publish a paper in one of the top AI/ML venues, like NeurIPS
, ICML, or ICLR, before I finish my program. I'm studying at a Federal University in Brazil, which is well-regarded loca
lly but doesn‚Äôt have much international recognition. My research lab is somewhat unstructured‚Äîwe mainly share computatio
nal resources but don‚Äôt have collaborative or large-scale projects. Because of this, I don‚Äôt have an ongoing project I c
an join for guidance or support.

Additionally, my supervisor‚Äôs research focus is more on applied machine learning in ch
emistry, so he doesn‚Äôt have experience publishing in these top conferences. This means I don‚Äôt have direct mentorship on
 the publishing process specific to these venues. To give some context, NeurIPS's call for papers is expected around May
 2025, so I still have some time but want to prepare as thoroughly as possible.

I‚Äôd really appreciate any advice on how
 to increase my chances of getting published in these venues. For example, I‚Äôve heard that it helps to cite potential re
viewers in your work. Any tips on how to navigate the process, write in a way that aligns with these conferences, or und
erstand what reviewers might be looking for would be helpful. I‚Äôd also like advice on handling rejection, like potential
 backup venues to consider if my paper isn‚Äôt accepted.
```
---

     
 
all -  [ Visa rejected for No Proper reason ](https://www.reddit.com/r/CanadaVisitorVisa/comments/1ghdzz6/visa_rejected_for_no_proper_reason/) , 2024-11-11-0913
```
I was supposed to go for NeurIPS conference from India and I had Invitation letter as well as cover letter from my compa
ny. Yet they have rejected with absolutely no logical reasons. How to appeal this? 
```
---

     
 
all -  [ [R] QTIP: Quantization with Trellises and Incoherence Processing ](https://www.reddit.com/r/MachineLearning/comments/1ggyj3l/r_qtip_quantization_with_trellises_and/) , 2024-11-11-0913
```
We're pleased to introduce QTIP, a new LLM quantization algorithm that uses trellis coded quantization and incoherence p
rocessing to achieve a state of the art combination of speed and quantization quality.

Paper (NeurIPS 2024 Spotlight):¬†
[https://arxiv.org/pdf/2406.11235](https://arxiv.org/pdf/2406.11235)

Codebase + inference kernels:¬†[https://github.com/
Cornell-RelaxML/qtip](https://github.com/Cornell-RelaxML/qtip)

Prequantized models (including 2 Bit 405B Instruct):¬†[ht
tps://huggingface.co/collections/relaxml/qtip-quantized-models-66fa253ad3186746f4b62803](https://huggingface.co/collecti
ons/relaxml/qtip-quantized-models-66fa253ad3186746f4b62803)

QTIP has significantly better quality over QuIP# while bein
g just as fast. QTIP is also on par with or better than PV-Tuning while being much faster (\~2-3x).


```
---

     
 
all -  [ New Quantization Method -- QTIP: Quantization with Trellises and Incoherence Processing ](https://www.reddit.com/r/LocalLLaMA/comments/1ggwrx6/new_quantization_method_qtip_quantization_with/) , 2024-11-11-0913
```
We're pleased to introduce QTIP, a new LLM quantization algorithm that uses trellis coded quantization and incoherence p
rocessing to achieve a state of the art combination of speed and quantization quality.

Paper (NeurIPS 2024 Spotlight):¬†
[https://arxiv.org/pdf/2406.11235](https://arxiv.org/pdf/2406.11235)

Codebase + inference kernels:¬†[https://github.com/
Cornell-RelaxML/qtip](https://github.com/Cornell-RelaxML/qtip)

Prequantized models (including 2 Bit 405B Instruct):¬†[ht
tps://huggingface.co/collections/relaxml/qtip-quantized-models-66fa253ad3186746f4b62803](https://huggingface.co/collecti
ons/relaxml/qtip-quantized-models-66fa253ad3186746f4b62803)

QTIP has significantly better quality over QuIP# while bein
g just as fast. QTIP is also on par with or better than PV-Tuning while being much faster (\~2-3x).

[2 Bit 405B Instruc
t running pipelined on 2 GPUs. The inference backend uses torch.compile and HF so this should be much faster on somethin
g like llama.cpp.](https://reddit.com/link/1ggwrx6/video/rz8ghv5fc8yd1/player)
```
---

     
 
all -  [ Chance a Chess Fiend With Below Average Grades but Good EC's and SAT ](https://www.reddit.com/r/chanceme/comments/1ggukfh/chance_a_chess_fiend_with_below_average_grades/) , 2024-11-11-0913
```
**Demographics**:

* mid to low comp HS, 250 ish grad class
* Asian
* I play chess?
* CS BA or BS

**GPA**: 3.7 W(good r
easons why so low just trust)

No rank

7 APs, 8 Tests

SAT - 1510 composite

**Awards**:

* AP scholar with honors
* ho
nor roll
* Top 100 nationally ranked chess players In age groups for the past 4 years
* USCF candidate master
* Won an i
nternational/national tournament + state champs in chess

\*\*ECs(\*\*n·ªët **ordered properly):**

* High School Chess le
ague president - 20+ schools, 100+ participants, $1k+ raised
* 1st author to Novel Ai paper - published and submitted to
 conferences like Neurips + COLING, available on arXiv
* Chess Club president - 3 peat champion in regional league, top 
5 teams in State
* DECA - 3x state qualifier
* Motorola Solutions Intern - made a REST API for one of their apps in prod

* Paid Chess coach - Apart of non-profit group for underprivileged youth in chicago(not from there did remote)
* Volunt
eer Chess Coach - volunteered apart of local chess academy, 200 ish hours over the 4 years
* Wrestling - Varsity
* SASA(
south asian student association) treasurer - raised 10k from sponsors and events, provided scholarships for the first ye
ar to south asian students
* Inspirit AI scholars program(free) - Made Chess bot with GPT 4o capable of playing at an ex
pert level

**Personal Statement:** 7.5/10 (not insanely good, but everyone who reads it likes it, and reviewers can't f
ind problems with it, so conservative 7.5)

**Colleges**:  
Umass, UMD, UW Madison, BU, NEU, Ohio State, Penn State, Pur
due, IU, Vtech, UPitt, RIT, Bentley, Rutgers
```
---

     
 
all -  [ [D] Is TMLR good enough to consider as an alternative to A* conferences? ](https://www.reddit.com/r/MachineLearning/comments/1ggsief/d_is_tmlr_good_enough_to_consider_as_an/) , 2024-11-11-0913
```
Hi there, I am a current PhD student in Artificial Intelligence working on Multi-Armed Bandits. More recently, I have co
mpleted one of my works on the intersection of Bandits and LLMs and was wondering for a suitable venue for publication.


The closest conference I see is ICML having deadline of 31st January which is about two months from now, therefore was 
wondering about a suitable alternate venue. While previous reddit threads (a year back) claim that TMLR is better than A
AAI, IJCAI and similar conferences but falls way short compared to ICML, NeurIPS, ICLR, etc, I was wondering if it's sti
ll true. 

Does the ML community still considers TMLR to be a potential place to submit it, given that the deadline for 
the closest conference is too far?
```
---

     
 
all -  [ Neural network recognizer for hand-written zip code digits (1988): 'with a high-performance preproce ](https://www.reddit.com/r/mlscaling/comments/1ggr0j4/neural_network_recognizer_for_handwritten_zip/) , 2024-11-11-0913
```
This paper was published just before LeNet-1. Notable features:

* 18 hand-designed kernels (??).
* An early bitter less
on? 'In the early phases of the project, we found that neural network methods gave rather mediocre results. Later, with 
a high-performance preprocessor, plus a large training database, we found that a layered network gave the best results, 
surpassing even Parzen Windows.'
   * 'Several different classifiers were tried, including Parzen Windows, K nearest nei
ghbors, highly customized layered networks, expert systems, matrix associators, fea ture spins, and adaptive resonance. 
We performed preliminary studies to identify the most promising methods. We determined that the top three methods in thi
s list were significantly better suited to our task than the others, and we performed systematic comparisons only among 
those three \[Parzen Windows, KNN, neural networks\].'
* Nevermind, seems they didn't take the bitter lesson. 'Our metho
ds include low-precision and analog processing, massively parallel computation, extraction of biologically-motivated fea
tures, and learning from examples. We feel that this is, therefore, a fine example of a Neural Information Processing Sy
stem. We emphasize that old-fashioned engineering, classical pattern recognition, and the latest learning-from-examples 
methods were all absolutely necessary. Without the careful engineering, a direct adaptive network attack would not succe
ed, but by the same token, without learning from a very large database, it would have been excruciating to engineer a su
fficiently accurate representation of the probability space.'

Denker, John, et al. '[Neural network recognizer for hand
-written zip code digits](https://proceedings.neurips.cc/paper/1988/hash/a97da629b098b75c294dffdc3e463904-Abstract.html)
.'¬†*Advances in neural information processing systems*¬†1 (1988).
```
---

     
 
all -  [ Florence-2-as-a-Judge ](https://www.reddit.com/r/LocalLLaMA/comments/1gfv0me/florence2asajudge/) , 2024-11-11-0913
```
I learned about Judge Distillation from slide 14 in [this deck](https://nips.cc/media/neurips-2023/Slides/83968_5GxuY2z.
pdf) describing how Phi-2 researchers scaled their data quality filter to a large synthetic dataset.

I'm planning to sc
ale up data synthesis for the [OpenSpaces dataset](https://huggingface.co/datasets/remyxai/OpenSpaces) and have found I 
can use [SpaceLLaVA](https://huggingface.co/remyxai/SpaceLLaVA) in VLM-as-a-Judge with [prometheus-vision](https://githu
b.com/prometheus-eval/prometheus-vision). Check out the [SpaceJudge Dataset](https://huggingface.co/datasets/salma-remyx
/SpaceJudgeDataset) to see the an assessment of a small split.

Now, I'm fine-tuning Florence-2 on this dataset, introdu
cing the new <JUDGE> task to help filter out low-quality synthetic samples. Here's the [experiment collection](https://h
uggingface.co/collections/salma-remyx/vlm-judge-distillation-671fc8fe1925c49630307a82).

Will discuss some of this at OD
SC West tomorrow, let's connect!


```
---

     
 
all -  [ [0 YOE, Recent Grad, Machine learning engineer, United States] ](https://i.redd.it/yc7sqkex7txd1.png) , 2024-11-11-0913
```

```
---

     
 
all -  [ [D]ended up with a poster in NuerIPS-24 ](https://www.reddit.com/r/MachineLearning/comments/1gdxef5/dended_up_with_a_poster_in_nuerips24/) , 2024-11-11-0913
```
I have a poster in NuerIPS this year through the  journal track(MLRC) along with the main conference papers.I didnt expe
ct this to happen so i hadnt planned/researched about the expenses/funding prior.I already had my visa and conference re
gistration arranged but have no clue about further proceedings of Nuerips and how to fund it(i am an UG junior).If you h
ave already attended NeurIPS before please pour your ideas and experiences.
```
---

     
 
all -  [ Looking for collaborations on ongoing work-in-progress Full Papers targeting conferences like CVPR,  ](https://www.reddit.com/r/computervision/comments/1gd6812/looking_for_collaborations_on_ongoing/) , 2024-11-11-0913
```
Hey everyone,

Our group,¬†**Vision and Language Group, IIT Roorkee,**¬†recently got three workshop papers accepted at Neu
rIPS workshops! üöÄ We‚Äôve also set up a website üëâ¬†[VLG](https://vlgiitr.github.io/), featuring other publications we‚Äôve wo
rked on, so our group is steadily building a portfolio in ML and AI research. Right now, we‚Äôre collaborating on several 
work-in-progress papers with the aim of full submissions to top conferences like CVPR and ICML.

That said, we have even
 more ideas we‚Äôre excited about. Still, a few of our main limitations have been access to proper guidance and funding fo
r GPUs and APIs, which is crucial for experimenting and scaling some of our concepts. If you or your lab is interested i
n working together, we‚Äôd love to explore intersections in our fields of interest and any new ideas you might bring to th
e table!

If you have resources available or are interested in discussing potential collaborations, please feel free to 
reach out! Looking forward to connecting and building something impactful together! Here is the link for our Open Slack 
üëâ¬†[Open Slack](https://join.slack.com/t/vlgopenspace/shared_invite/zt-2t7kihcc6-uilU~y7lz7jdtqNc5M1VPA)
```
---

     
 
all -  [ Looking for collaborations on ongoing work-in-progress Full Papers targeting conferences like CVPR,  ](https://www.reddit.com/r/neuralnetworks/comments/1gd64zq/looking_for_collaborations_on_ongoing/) , 2024-11-11-0913
```
# Hey everyone,

Our group,¬†**Vision and Language Group, IIT Roorkee,**¬†recently got three workshop papers accepted at N
eurIPS workshops! üöÄ We‚Äôve also set up a website üëâ¬†[VLG](https://vlgiitr.github.io/), featuring other publications we‚Äôve 
worked on, so our group is steadily building a portfolio in ML and AI research. Right now, we‚Äôre collaborating on severa
l work-in-progress papers with the aim of full submissions to top conferences like CVPR and ICML.

That said, we have ev
en more ideas we‚Äôre excited about. Still, a few of our main limitations have been access to proper guidance and funding 
for GPUs and APIs, which is crucial for experimenting and scaling some of our concepts. If you or your lab is interested
 in working together, we‚Äôd love to explore intersections in our fields of interest and any new ideas you might bring to 
the table!

If you have resources available or are interested in discussing potential collaborations, please feel free t
o reach out! Looking forward to connecting and building something impactful together! Here is the link for our Open Slac
k üëâ¬†[Open Slack](https://join.slack.com/t/vlgopenspace/shared_invite/zt-2t7kihcc6-uilU~y7lz7jdtqNc5M1VPA)
```
---

     
 
all -  [ Some General Rules for Uni Selection Fall'25 ](https://www.reddit.com/r/MSCS/comments/1gcs53j/some_general_rules_for_uni_selection_fall25/) , 2024-11-11-0913
```
1. If you dont have 9+ GPA from tier 3 / 8.7 GPA from NIT / 8.5 GPA from IIT, do not apply to any of UC's MSCS (except U
C Riverside and UC Santa Cruz) .
2. Do not apply to Ivy Leagues MSCS if you don't have 9.5+ GPA from tier 3/ 9+ GPA from
 Tier 2.
3. If you are not from IIT NIT, do not apply to TAMU unless you have 9.5+ GPA.
4. The earlier you apply to NEU 
with a 8+ GPA/100+ TOEFL, the higher your chances of getting admit  for MSCS (Mostly full by Nov end). After that you wi
ll be offered alternate campuses.
5. Dont apply to Stony Brook MSCS if you dont have 8.5+ GPA, 315+ GRE, 167+ Quants. Yo
u can try MSDS though.
6. Dont apply to UMASS if you dont have 315+ GRE.
7. If you have 2+ years of work ex, try MCS in 
UC's, especially UCI, and TAMU.
8. Dont apply to USC if you cant afford extreme tuition fees and 1000$ deposit.
9. Use [
admits.fyi](http://admits.fyi), [https://gpa.eng.uci.edu/](https://gpa.eng.uci.edu/) to get estimates.
10. Conferences d
ont matter, no matter how many, unless they are NeurIPS, ICCV, CVPR etc. Especially conferences and journals like IJET, 
IJSER, IJRASET etc. can have negative impact on your profile. IEEE Access is another common Journal, its good, but wont 
create much of impact on your profile.
11. MSDS is much more gettable than MSCS.
12. You dont need to send you GRE and T
OEFL scores before application in most cases. You can upload unofficial copy, and send official scores after you get an 
admit. Dont waste money.
13. Work ex wont create much of a difference for MSCS, but def creates a great diff when it com
es to getting a job.
14. Prefer East coast for finance, West Coast for tech jobs ( Location matters more than rankings).
 For pure research, prefer reputation over anything else.
15. SJSU MSCS is best uni for getting a job in tech for those 
who have low gpa, low scores and financial issues. Be aware you need CS undergrad degree background to get MSCS at SJSU.

16. Purdue took very few people last year as they had funding issues. Purdue was harder than UCSD to get in.
17. GPA ma
tters more than anything else. 9 GPA tier 3 = 8.7 GPA tier 2 = 8.5 GPA tier 1.
18. [https://github.com/SimplifyJobs/Summ
er2025-Internships](https://github.com/SimplifyJobs/Summer2025-Internships),  [https://github.com/cvrve/Summer2025-Inter
nships](https://github.com/cvrve/Summer2025-Internships) . Get an Idea of what things are currently in demand in the US,
 dont just go for any branch or any specialization because you have interest in it.
19. Rankings along with minimum idea
l gpa according to tier 3 MIT, Stanford (9.9 GPA) > CMU, UC Berkeley, UIUC (9.8) > GATECH, UT Austin, UWash (9.6)> UCSD,
 Columbia, CalTech, UCLA, UPenn (9.5)> UWM, UMCP, Purdue (9.4)> UMass, TAMU, UCI, UCSB (9.3)> UCD, USC, NYU Courant (9.1
)> Stony Brook, Penn State, Virginia Tech (8.7\~9) > Rutgers, NEU, NYU Tandon (8.5) >  NCSU, BU (8.5)
20. Dont go for Co
nsultations, waste of money.

Anymore questions, feel free to ask.
```
---

     
 
all -  [ 'Foundations for Machine Learning' ](https://www.reddit.com/r/learnmachinelearning/comments/1gcc2fc/foundations_for_machine_learning/) , 2024-11-11-0913
```


https://preview.redd.it/pea5gbvrr0xd1.png?width=1280&format=png&auto=webp&s=452854ecdc3e378b5b4a5b57dbbf145cf093b551


In 2022, I graduated with a PhD in Mechanical Engineering from MIT. 



Although a big component of my research was pure
ly hands-on experiments, my exposure to foundational graduate-level ML courses at MIT, research courses, and Scientific 
Machine Learning via Julia gave me the confidence of a Machine Learning researcher. 



I incorporated ML into my resear
ch, and it solved a problem that is otherwise difficult to solve theoretically or experimentally. Now I have co-authored
 multiple AI-ML research papers and two of them are accepted to the upcoming NeurIPS workshop. 



Behind all of this ef
fort, there is the confidence that stems from knowing what happens underneath the ML algorithms.



Most of the online c
ourses have little emphasis on fundamentals. People are so used to spending time on toy Kaggle projects. Very few people
 I know can build a neural network from scratch or explain what happens behind them.



For the last 4 months, I have be
en working to launch a new course titled on 'Foundations for Machine Learning.' This will be a 45-hour course with \~65 
lectures. I will be hosting all lectures on this playlist: [https://www.youtube.com/playlist?list=PLPTV0NXA\_ZSiLI0ZfZYb
HM2FPHKIuMW6K](https://www.youtube.com/playlist?list=PLPTV0NXA_ZSiLI0ZfZYbHM2FPHKIuMW6K)



My singular goal with this c
ourse is to teach you the entire foundations required to learn ML from scratch.



There are no prerequisites. If you ha
ve basic logical thinking capability and a willingness to dedicate time, consistently, you can follow this course.



I 
have split the course into 5 modules.



1) First I will cover the 4 mathematical pillars of ML: Linear Algebra, Probabi
lity, Statistics, and Calculus.



2) In the second module I cover the basic programming fundamentals for a complete beg
inner. I will teach you Python from scratch and it's some of the most important packages for ML including NumPy and PyTo
rch.



3) In the 3rd module we will learn about optimization and gradient descent. I wanted to dedicate an entire modul
e to optimization because when you actually build ML models, you will be spending a lot of time on optimization.



4) I
n the 4th module, I will give you an overview of the AI landscape. What happened from 2010-2020 and what does it look li
ke from 2020-2030? This overview will help you understand overall where ML, DL, NLP, CV, and GenAI are heading.



5) In
 the final module, I will cover the most important 2 steps you will have to master as a Data Scientist or ML engineer: p
rocessing data and communication via storytelling. I will teach you some of the most powerful preprocessing and visualiz
ation techniques.



I have already published the first lecture. Check out here. I am sure you will enjoy and learn a lo
t: [https://youtu.be/C8hEa2qb46k?si=7dRHM6EZwlUBDC5C](https://youtu.be/C8hEa2qb46k?si=7dRHM6EZwlUBDC5C)
```
---

     
 
all -  [ [R] Looking for collaborations on ongoing work-in-progress Full Papers targeting conferences like CV ](https://www.reddit.com/r/u_vlg_iitr/comments/1gc2yzd/r_looking_for_collaborations_on_ongoing/) , 2024-11-11-0913
```
Hey everyone,

Our group, **Vision and Language Group, IIT Roorkee,** recently got three workshop papers accepted at Neu
rIPS workshops! üöÄ We‚Äôve also set up a website üëâ [VLG](https://vlgiitr.github.io/), featuring other publications we‚Äôve wo
rked on, so our group is steadily building a portfolio in ML and AI research. Right now, we‚Äôre collaborating on several 
work-in-progress papers with the aim of full submissions to top conferences like CVPR and ICML.

That said, we have even
 more ideas we‚Äôre excited about. Still, few of our main limitations have been access to proper guidance along with fundi
ng for GPUs and APIs, which is crucial for experimenting and scaling some of our concepts. If you or your lab is interes
ted in working together, we‚Äôd love to explore intersections in our fields of interest and any new ideas you might bring 
to the table! 

If you have resources available or are interested in discussing potential collaborations, please feel fr
ee to reach out! Looking forward to connecting and building something impactful together! Here, is the link for our Open
 Slack üëâ [Open Slack](https://join.slack.com/t/vlgopenspace/shared_invite/zt-2t7kihcc6-uilU~y7lz7jdtqNc5M1VPA)
```
---

     
 
all -  [ Paper summaries for some of our papers that recently got accepted in NeurIPS ](https://www.reddit.com/r/learnmachinelearning/comments/1gb78i9/paper_summaries_for_some_of_our_papers_that/) , 2024-11-11-0913
```
Hey everyone, here is the list of papers by our groups that got accepted recently in NeurIPS 2024; It is a proud moment 
for us as an all-UG group; all the papers were published without any external support from the academia; here is a summa
ry of our papers. We hope this inspires others to pursue AI and look into research as a perspective where we can work to
gether, and all you require is the right guidance (not even necessarily a PhD or a professor). If you find these papers 
useful and want to working/collabrating with us, feel free to connect with us!

* Give me a hint: Can LLMs take a hint t
o solve math problems? üëâ¬†[Arxiv link](https://arxiv.org/abs/2410.05915)
   * We propose improving LLM performance on adv
anced math problems using 'hints,' inspired by human pedagogy. We also test the model's robustness to incorrect hints. O
ur approach is evaluated on various LLMs using diverse problems from the MATH dataset, comparing it with one-shot, few-s
hot, and chain of thought prompting.
* Attention Shift: Steering AI Away from Unsafe Content üëâ¬†[Arxiv link](https://arxi
v.org/abs/2410.04447)
   * This study explores methods to restrict unsafe content in generative models. We propose a nov
el training-free approach using attention reweighing to remove unsafe concepts during inference. Our method is compared 
to existing techniques, evaluated on direct and adversarial jailbreak prompts. We also discuss potential causes, limitat
ions, and broader implications.
* Unmasking the Veil: An Investigation into Concept Ablation for Privacy and Copyright P
rotection in Images üëâ¬†[Arxiv link](https://arxiv.org/abs/2406.12592v1)
   * This paper extends the study of concept abla
tion in pre-trained models, as introduced by Kumari et al. (2022). We reproduce results from various concept ablation te
chniques and propose a novel variant, 'trademark ablation,' to address branded elements in model outputs. We also analyz
e the model's limitations, behavior under ablation leakage prompts, and performance degradation on unrelated concepts.


**The Vision Language Group at IIT Roorkee**¬†has compiled an excellent repository of¬†**comprehensive summaries**¬†for dee
p learning papers from top conferences like¬†**NeurIPS, CVPR, ICCV, and ICML (2016-2024)**. These summaries break down ke
y papers in computer vision, NLP, and machine learning‚Äîperfect if you want to stay updated without diving deep into the 
full papers.
```
---

     
 
all -  [ Paper summaries for some of our papers that recently got accepted in NeurIPS ](https://www.reddit.com/r/u_vlg_iitr/comments/1gb6csa/paper_summaries_for_some_of_our_papers_that/) , 2024-11-11-0913
```
Hey everyone, here is the list of papers by our groups that got accepted recently in NeurIPS 2024; It is a proud moment 
for us as an all-UG group; all the papers were published without any external support from the academia; here is a summa
ry of our papers. We hope this inspires others to pursue AI and look into research as a perspective where we can work to
gether, and all you require is the right guidance (not even necessarily a PhD or a professor). If you find these papers 
useful and want to working/collabrating with us, feel free to connect with us! 

* Give me a hint: Can LLMs take a hint 
to solve math problems? üëâ [Arxiv link](https://arxiv.org/abs/2410.05915)
   * We propose improving LLM performance on ad
vanced math problems using 'hints,' inspired by human pedagogy. We also test the model's robustness to incorrect hints. 
Our approach is evaluated on various LLMs using diverse problems from the MATH dataset, comparing it with one-shot, few-
shot, and chain of thought prompting.
* Attention Shift: Steering AI Away from Unsafe Content üëâ [Arxiv link](https://arx
iv.org/abs/2410.04447)
   * This study explores methods to restrict unsafe content in generative models. We propose a no
vel training-free approach using attention reweighing to remove unsafe concepts during inference. Our method is compared
 to existing techniques, evaluated on direct and adversarial jailbreak prompts. We also discuss potential causes, limita
tions, and broader implications.
* Unmasking the Veil: An Investigation into Concept Ablation for Privacy and Copyright 
Protection in Images üëâ [Arxiv link](https://arxiv.org/abs/2406.12592v1)
   * This paper extends the study of concept abl
ation in pre-trained models, as introduced by Kumari et al. (2022). We reproduce results from various concept ablation t
echniques and propose a novel variant, 'trademark ablation,' to address branded elements in model outputs. We also analy
ze the model's limitations, behavior under ablation leakage prompts, and performance degradation on unrelated concepts.


**The Vision Language Group at IIT Roorkee**¬†has compiled an excellent repository of¬†**comprehensive summaries**¬†for de
ep learning papers from top conferences like¬†**NeurIPS, CVPR, ICCV, and ICML (2016-2024)**. These summaries break down k
ey papers in computer vision, NLP, and machine learning‚Äîperfect if you want to stay updated without diving deep into the
 full papers.
```
---

     
 
all -  [ New to Research - Need Info on Publications [R][D] ](https://www.reddit.com/r/MachineLearning/comments/1gaa3o8/new_to_research_need_info_on_publications_rd/) , 2024-11-11-0913
```
I have been writing and publishing a few papers/journals in the field of AI for the last two years now, but I am really 
not sure what the best journals and conferences are. In my case, I usually write a paper, and my professor, based on the
 content of the paper, submits it to that conference/journal.

So would like to understand some info from this sub.

\->
 What are some really good journals/conferences where you can publish a paper? (How are the journals /conferences ranked
, is there a way to check? I heard ICML, NeurIPS are the top conferences in this field)

\-> What are the best publisher
s?

\-> What are sci Q1, Q2 journals and A\*  journals?

I have a paper that I am writing now which is in the field of m
edicine (In the speech domain), can anyone suggest to me, what the best Journals/Conferences in this field are?

Sorry, 
if these are some basic questions, (I only know about the publishers: IEEEXplore, Springer, Elseveir and used to think i
f it's Scopus-indexed, it is a good conference/journal).
```
---

     
 
all -  [ [D] Responses to false accusations of plagiarism for Gaunt Tensor Product paper ](https://www.reddit.com/r/MachineLearning/comments/1ga12d8/d_responses_to_false_accusations_of_plagiarism/) , 2024-11-11-0913
```
I‚Äôm posting this on behalf of the authors of the paper. The first author tried to make a post about this, but the post g
ot removed for some reason. The author reached out to me because I was one of the people defending them, so see below fo
r the author writeup about the accusations.

**TL;DR**: We're the authors of the Gaunt Tensor Product paper, and we want
 to directly address the false plagiarism accusations against our work. Our main contribution, a new perspective on tens
or products of irreducible representations (irreps) in machine learning and equivariant neural networks, is novel and or
iginal. The claimed 'similarity' are actually algorithms from elementary math and CS courses, and are not the main contr
ibution of our work: our independent implementation is clear if you look at our code, which is quite different because w
e had a completely different application area in mind. On the other hand, our core contributions, including establishing
 the connection between tensor products of irreps and integrals of products of spherical harmonics and various design pa
radigms of equivariant operations, are completely omitted. There is an oversight of citation due to the gap between fiel
ds (machine learning vs. graphics), but this is not plagiarism, and now that we know about this, we are updating the pap
er with the citation and discussion accordingly. This is similar situation to areas such as neural ODEs, where the origi
nal ideas were in engineering papers in the '90s, and not cited in ML papers (including the 2018 NeurIPS paper) until mu
ch later. The anonymous accuser is selectively replying, omitting key details, and controlling the narrative.

**More de
tails below**:

We are the authors of \['Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor
 Products'\](https://openreview.net/forum?id=mhyQXJ6JsK) . We are creating a new post to clearly outline our responses t
o the false accusations of plagiarism that we've received for the Gaunt Tensor Product paper in another thread. While we
 have replied on that thread, the anonymous OP of that thread is selectively replying and omitting a lot of information 
from our responses, and we don't think it is fair that they single-handedly control the narrative. Note that we never go
t any emails or posts on OpenReview from the author, who has instead decided to anonymously post on here.

Firstly, we w
ould like to comprehensively respond to the false accusations again:

\- **The contributions of our work**: as emphasize
d in our paper, our main contribution in this work is the new perspective on tensor products of irreps, which is novel a
nd original to the machine learning community (Equations 3 and 4). The whole Section 3.1 elaborates on how to establish 
the connection between tensor products of irreps and integrals of products of spherical harmonics. Although the OP claim
s 'However, it is important to note that this derivation accounts for less than one page of the nine-page paper.', the f
act is that our establishment and derivation are based on a series of rigorous deductions with many efforts on building 
a solid mathematical foundation including group theory and quantum mechanics (please refer to Appendix A.1-A.7, page 16-
28), which is not straightforward and trivial to obtain. Without these efforts, we cannot establish such connections, le
t alone the efficient algorithm. In the context of equivariant machine learning, this derivation presents significance t
o refresh the understanding of basic equivariant operations, which cannot be omitted.

\- **The similarities of the effi
cient algorithms between our work and FSHP work**: Firstly, we would like to apologize that we did not cite the FSHP wor
k in our submission, which is unintentional and due to the gap between these two communities (we are from the ML communi
ty, and they are from graphics, and the paper was not known to us until recently). We will update the arXiv version of o
ur paper asap by adding a discussion paragraph to carefully discuss the FSHP work and our work. **On the other hand, we 
also would like to clarify that there does not exist any plagiarism behavior of the FFT algorithm**: after we figure out
 the relation between the tensor product of irreps and integrals of the product of three spherical harmonics, it is rath
er natural to connect it with products of spherical functions. Moreover, there exist classical results for efficient com
putation of products of spherical functions, i.e., Convolution Theorem and FFT, which involve elementary knowledge that 
can be learned in several undergraduate classes: (1) change of basis, which can be learned in linear algebra and signal 
processing and is used in both paper to connect spherical harmonics and Fourier basis; (2) FFT, which is commonly taught
 in signal processing and numerical computation classes and is used for acceleration. Due to the basicness of these math
ematical tools, both works follow the standard way to formalize and present, which leads to similarity. As we said, this
 cannot be misrepresented as plagiarism because we independently worked on this, and did not know about the other work u
ntil later because of the different communities. This is similar to work in areas such as neural ODEs, where the origina
l ideas were in engineering papers in the '90s, and not cited in ML papers (including the 2018 NeurIPS paper) until much
 later.

\- **The differences in implementation**: it is noteworthy that, as a work for the equivariant machine learning
 community, it is not enough to simply propose an approach just for the tensor product operation. What we really care ab
out is the various design paradigms of equivariant operations, which are built upon tensor products. In Section 3.3, we 
categorize these paradigms into three classes in terms of their different characteristics and applied range. For each cl
ass of equivariant operations, we carefully specialize our approach by combining their properties and considering the re
strictions. For example, for the equivariant convolution, we figure out that we can further leverage eSCN/EquiformerV2's
 findings to achieve further acceleration; for the equivariant many-body interactions, a divide-and-conquer approach is 
natural, which is also generally taught in various CS courses and projects. There also exist different instantiation str
ategies in modern equivariant networks when applying these classes of operations, please refer to the Discussion paragra
ph in Section 3.3 and Appendix C. Simply proposing the efficient approach for tensor products is not feasible to these m
entioned points. Without these additional efforts and contributions, the efficient algorithm is not practical to be used
 for the equivariant machine learning community,  which cannot be omitted.

\- There is quite a lot of literature in the
 last few decades in the graphics community on this, and this is another general point is that work on the graphics comm
unity on efficient algorithms is not heard of and/or undercited in the rotationally equivariant neural networks communit
y, when these algorithms pop up in a lot of equivariant NN work. Additionally, this graphics paper is not in the field o
f ML, and this algorithm is being applied to a completely different area, which is why we did not see it originally and 
had an independent formalization. Perhaps an analogy here is that there are papers applying Transformers to different ar
eas like vision instead of language, but this shouldn't be 'plagiarism' at all. Likewise, neural ODEs shouldn't be consi
dered plagiarism of traditional ODE solvers simply because they are using the same method (and indeed, some of the origi
nal ideas of neural ODEs were in engineering papers from the '90s, and not discovered/cited in ML papers until later bec
ause of the different communities). One user on this thread also put it well that the concepts here like FFT are quite w
ell-known: 'After skimming, my impression is that those are well known results from textbooks and signal processing cour
ses that nobody bother to cite anymore. I could be wrong.'

\- The implementation in the GTP paper is fairly different f
rom the FSHP paper and was implemented independently because we derived our implementation based on being motivated by o
ur specific application area of ML for molecular modeling: their code is in C++, doesn't support efficient computations 
for lower rotation orders (L), and is not made for use with irreducible representations. This should be clear when you s
ee the code.

\- The main purpose of the Equiformerv2 experiment with the self-mix layer was a proof-of-concept to show 
that such a self-mix layer can be implemented because of the Gaunt Tensor Product formulation. Without this formulation 
(and using the more standard Clebsch-Gordan Tensor Product), it would have been very slow to add this layer (and not gre
at from a memory usage perspective). This can be made more clear in the arXiv version.

Secondly, we would like to point
 out that the anonymous OP of that thread is selectively replying to posts, and omitting a lot of information (including
 in how they are updating their own thread, they do not include all of the details of our responses). To us, the posts a
lso seem LLM generated but you should draw your own conclusions. We also posted this new topic because the authors respo
nses on the original thread are all folded, which cannot be directly seen by new readers.

Finally, we appreciate that m
any people have been commenting on the thread to defend us. These types of anonymous, sensational claims can have seriou
s implications and to post anonymously on Reddit before emailing us or posting on OpenReview is really problematic. We h
ope that you all read these threads carefully before jumping to conclusions.
```
---

     
 
all -  [ facechain open source TopoFR face embedding model ! ](https://www.reddit.com/r/StableDiffusion/comments/1g98si0/facechain_open_source_topofr_face_embedding_model/) , 2024-11-11-0913
```
Our work \[TopoFR\](https://github.com/modelscope/facechain/tree/main/face\_module/TopoFR) got accepted to NeurIPS 2024,
 welcome to try it out !
```
---

     
 
all -  [ Confused about where to submit the paper for a conference ](https://www.reddit.com/r/PhD/comments/1g8d9st/confused_about_where_to_submit_the_paper_for_a/) , 2024-11-11-0913
```
I started working on a specific category of power balance problem using reinforcement learning. RL in power quality is n
ot new but I‚Äôm working on community of microgrids using RL which can help supply electricity to remote areas in developi
ng countries so novelty is in how we formulate the optimization problem. My professor thinks it could be submitted to so
me ASME conferences but I want to try my luck at ICML or NeurIPS. Do you think this paper is worthy of those conferences
?
```
---

     
 
all -  [ How to finish PhD within 3 years ? ](https://www.reddit.com/r/PhD/comments/1g7w95o/how_to_finish_phd_within_3_years/) , 2024-11-11-0913
```
I am about to start a PhD in mechanistic interpretability (subfield of explainable AI) in Germany. I worked in industry 
before and am already 30 yo. I want to finish within 3 years. My graduation requirements are three journal papers. High 
prestige conference papers also count (Neurips, ICLR..) .

For those that finished early:

* What was your experience ?

* What was your strategy ?

My thoughts are:

* Pick up specific niche subject and do variations of it.
* Publish one pa
pers in first year and network as much as possible in conference to find collaborators
* Pick up work from lab mates and
 collaborate.
```
---

     
 
all -  [ [R] Molecular Topological Profile (MOLTOP) - Simple and Strong Baseline for Molecular Graph Classifi ](https://www.reddit.com/r/MachineLearning/comments/1g7gj4m/r_molecular_topological_profile_moltop_simple_and/) , 2024-11-11-0913
```
Accepted at ECAI 2024 conference, ArXiv: [https://arxiv.org/abs/2407.12136](https://arxiv.org/abs/2407.12136)

Some high
lights:

- simple feature engineering on graphs

- it outperforms GROVER (NeurIPS 2020) and GraphMVP (ICLR 2024) on Mole
culeNet, and all models on peptide function prediction on LRGB (e.g. SAN+RWSE graph transformer)

- no hyperparameters t
o tune, takes seconds on most datasets

- surprisingly powerful in distinguishing non-isomorphic graphs

In short, if yo
u need a good and simple baseline for molecular graph classification, MOLTOP may be a good choice. We designed it not to
 be the best, but to be fast, easy-to-use, and also give strong results on average.

Abstract:

>We revisit the effectiv
eness of topological descriptors for molecular graph classification and design a simple, yet strong baseline. We demonst
rate that a simple approach to feature engineering - employing histogram aggregation of edge descriptors and one-hot enc
oding for atomic numbers and bond types - when combined with a Random Forest classifier, can establish a strong baseline
 for Graph Neural Networks (GNNs). The novel algorithm, Molecular Topological Profile (MOLTOP), integrates Edge Betweenn
ess Centrality, Adjusted Rand Index and SCAN Structural Similarity score. This approach proves to be remarkably competit
ive when compared to modern GNNs, while also being simple, fast, low-variance and hyperparameter-free. Our approach is r
igorously tested on MoleculeNet datasets using fair evaluation protocol provided by Open Graph Benchmark. We additionall
y show out-of-domain generation capabilities on peptide classification task from Long Range Graph Benchmark. The evaluat
ions across eleven benchmark datasets reveal MOLTOP's strong discriminative capabilities, surpassing the¬†1-WL test and e
ven¬†3We revisit the effectiveness of topological descriptors for molecular graph classification and design a simple, yet
 strong baseline. We demonstrate that a simple approach to feature engineering - employing histogram aggregation of edge
 descriptors and one-hot encoding for atomic numbers and bond types - when combined with a Random Forest classifier, can
 establish a strong baseline for Graph Neural Networks (GNNs). The novel algorithm, Molecular Topological Profile (MOLTO
P), integrates Edge Betweenness Centrality, Adjusted Rand Index and SCAN Structural Similarity score. This approach prov
es to be remarkably competitive when compared to modern GNNs, while also being simple, fast, low-variance and hyperparam
eter-free. Our approach is rigorously tested on MoleculeNet datasets using fair evaluation protocol provided by Open Gra
ph Benchmark. We additionally show out-of-domain generation capabilities on peptide classification task from Long Range 
Graph Benchmark. The evaluations across eleven benchmark datasets reveal MOLTOP's strong discriminative capabilities, su
rpassing the¬†1-WL test and even¬†3-WL test for some classes of graphs. Our conclusion is that descriptor-based baselines,
 such as the one we propose, are still crucial for accurately assessing advancements in the GNN domain.

Happy to discus
s / answer any questions in the comments.
```
---

     
 
MachineLearning -  [ [D] Why do PhD Students in the US seem like overpowered final bosses  ](https://www.reddit.com/r/MachineLearning/comments/1g7dzkp/d_why_do_phd_students_in_the_us_seem_like/) , 2024-11-11-0913
```
Hello,

I'm a PhD student in a European university, working on AI/ML/CV ..etc. my PhD is 4 years. The first year I liter
ally just spent learning how to actually do research, teaching one course to learn how things work...etc. Second year, I
 published my first publication as a co-author in CVPR. By third year, I can manage research projects, I understand how 
to do grants applications, how funding works, the politics of it all ...etc. I added to my CV, 2 publications, one journ
al and another conference as first author. I'm very involved in industry and I also write a lot of production grade code
 in regard to AI, systems architecture, backend, cloud, deployment, etc for companies that have contracts with my lab.


The issue is when I see PhD students similar to me in the US, they be having 10 publications, 5 of them 1st author, all 
of them are either CVPR, ICML, ICLR, NeurIPS ...etc. I don't understand, do these people not sleep ? How are they able t
o achieve this crazy amount of work and still have 3 publications every year in A\* journals ?

I don't think these peop
le are smarter than I, usually I get ideas and I look up if something exists, and I can see that something was just publ
ished by some PhD student in Stanford or DeepMind ..etc like 1 month ago, So I can see that my reasoning isn't late in r
egard to SOTA. but the concepts that you would need to grasp to just have one of those publications + the effort and the
 time you need to invest and the resources to get everything done, wouldn't be possible for 2\~3 months project. How is 
it possible for these people to do this ?

Thank you !
```
---

     
 
MachineLearning -  [ [D] Will Scale be enough to get LLMs to Reason through Grokking? ](https://www.reddit.com/r/MachineLearning/comments/1g3cumr/d_will_scale_be_enough_to_get_llms_to_reason/) , 2024-11-11-0913
```
Currently there has been a lot of debate whether LLMs truly reason or just memorize their training data (see this recent
 paper from Apple [\[2410.05229\] GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Languag
e Models (arxiv.org)](https://arxiv.org/abs/2410.05229)).

On the other hand, there has been numerous papers showing tha
t models can generalize, if trained beyond the point where they overfit, known as '**grokking**' ([Towards Understanding
 Grokking: An Effective Theory of Representation Learning (neurips.cc)](https://proceedings.neurips.cc/paper_files/paper
/2022/hash/dfc310e81992d2e4cedc09ac47eff13e-Abstract-Conference.html)).

Based on grokking, we could argue that if we ju
st train current LLMs enough, they will always converge to generalization. Seemingly, **memorization is just a local min
ima** in which it can get stuck, and the true **global minima is generalization**.

How is this possible if memorization
 is already giving near perfect performance on the dataset for a **specific task**? Well, by looking at overall performa
nce opposed to task-specific performance, you can imagine how generalizing helps the model increase its overall performa
nce:

1. Generalizations use less parameter space than memorization, which the model then can use for other tasks, incre
asing its overall performance (reduction in effective dimension by generalization [\[2205.10343\] Towards Understanding 
Grokking: An Effective Theory of Representation Learning (arxiv.org)](https://arxiv.org/abs/2205.10343))
2. Generalizati
ons from one task can increase the performance on another unrelated task, increasing its overall performance (recent pap
er shows that GPT models get better at chess and reasoning by looking at the emergent behaviour of cellular automata: [I
ntelligence at the Edge of Chaos (arxiv.org)](https://arxiv.org/html/2410.02536)).

But then what happens if we grok the
 model not on a specific task, but on **all its data**? We can imagine that it would just memorize the whole dataset, wi
thout being incentivised to make generalization since it now has near perfect performance on the whole dataset. In this 
case, where the **global minima is memorization**, the model can still reach generalization by changing the loss landsca
pe using **weight-decay / regularization**. Regularization punishes big weights, forcing the model to prefer simpler sol
utions, reducing the minima around memorization, while leaving the minima around generalization in tact. This will make 
generalization the new global minima.

Considering this convergence towards generalization over training time, for both 
task-specific as overall performance, could we assume that scaling will logically make models generalize over time? In o
ther words, is scale really all we need to AGI? Or is there a flaw in my reasoning, grokking is not the end-all-be-all a
nd we will need new breakthroughs to get to AGI?
```
---

     
