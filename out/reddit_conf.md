 
all -  [ NeurIPS 2023: Recent and Upcoming Developments in Randomized Numerical Linear Algebra for ML ](https://neurips.cc/virtual/2023/tutorial/73954) , 2024-04-10-0910
```

```
---

     
 
all -  [ [R] A* venue workshop paper vs lower-rated venue conference paper ](https://www.reddit.com/r/MachineLearning/comments/1byg2n5/r_a_venue_workshop_paper_vs_lowerrated_venue/) , 2024-04-10-0910
```
NeurIPS24 is nearby and I've got a paper that got rejected last year at ICLR (5/5/6/3). While I'm addressing the feedbac
k from last conference (method was received positively, but they asked for more experimentation), I'm still unsure wheth
er the paper is strong enough to make it to an A\* conference such as NeurIPS. Also, to be honest, I've been working on 
it for almost a year and I feel I want to wrap this up already and look at other ideas.

&#x200B;

I was wondering which
 is better from these two:  


* Submitting to a workshop at NeurIPS or similar (ICLR, ICML..). I assume this should be 
doable with my paper given the feedback at ICLR but I don't know if that's correct?
* Aiming for a conference paper in a
 'lower-tier' venue such as AISTATS, IJCAI or similar. I assume this is more difficult to pull off than the workshop pap
er at NeurIPS but again I'm just guessing?

I am still not a PhD student, but I'm applying for PhDs regularly. Therefore
 I am kinda looking for the option that (in case my paper goes through) would give me more leverage as a PhD candidate i
n my future applications. 
```
---

     
 
all -  [ Career advice for someone hoping to transition to big tech ML after a PhD in ML for science? ](https://www.reddit.com/r/cscareerquestions/comments/1bxt76g/career_advice_for_someone_hoping_to_transition_to/) , 2024-04-10-0910
```
Hi all, this is going to be a somewhat long post. I am at a crossroads in my career and I highly appreciate any and all 
advice and pointers you can provide. Below I am going to describe my situation, but all my thoughts are a bit hazy and s
o don't shy away from offering your opinions even on topics that I am not asking for advice directly.

**My background:*
* I came to the US from another country to do my PhD. My PhD is in Mechanical Engineering (ME) in a solid (but not, say,
 top 20) university. Before starting my PhD, I did my BS and MS in Aerospace Engineering and worked in 2 aerospace compa
nies in my country for 4 years before coming here. Even though my PhD is in ME, I would say my PhD research is more in M
L than ME. I developed ML tools to solve problems in ME, basically. I am finalizing my PhD this year. At the risk of sou
nding arrogant, I will say that I am a very accomplished PhD student. My publication record is much higher than my peers
 and I have won numerous awards, fellowships, grants etc. I mention these because later on in this thread when I say I a
m trying to go into a research scientist in ML position in big tech, you will know that I have some things on my CV that
 make me believe I will (or should) be taken seriously.

As I said I had a job before coming here and I had a somewhat c
omfortable life. The 2 reasons that I decided to start a PhD were 1) life is much better in the US and a PhD would give 
me a solid path to come here, and 2) I realized that my job is extremely boring and my brain was rotting away. I needed 
to challenge myself and I found that challenge in academia. After four years of working in the industry (2 different eng
ineering companies), I fully realized that I belong in academia doing research.

That was until 1-2 years ago. Around 1-
2 years ago I started questioning if this much commitment to get an academic position is even worth it. In my field, the
 academic market is *extremely* oversaturated. Most open faculty positions get 250+ applications, with 50+ serious appli
cations, out of which 10-20 are shortlisted who all have 3-5 years of postdoc on top of their PhD. I am questioning if s
ubjecting myself to 3-5 years of postdoc with shit pay and high stress and moving from state to state for my next postdo
c every year is worth it. Plus, I have a family and I have an obligation towards my family (and parents) and instead of 
this pipe dream I should be looking for a solid job with a good pay.

**My current situation:** So, I started looking fo
r jobs. But jobs in ME or related fields sound very boring to me. I fully know that I will regret it if I go into an eng
ineering position. And once I go there, it is virtually impossible to come back to academia. Then I will have to endure 
a very miserable life for the rest of my life. On the other hand, I really like ML. I can see myself doing ML for the re
st of my life. If I can do research in ML and get a good pay, then that is literally heaven for me. Because 1) it combin
es my interests: research and ML, 2) it solves my problems (good pay), and 3) it leaves open the option to come back to 
academia later on even if I dislike it (if I can publish papers while away, I can still come back). So, I can't stress h
ow much I want a research scientist position in ML. The problem is, I have no background or training in computer science
. And my ML research is mostly 'applied ML', if that makes sense. My research is ML in nature, but not the kind of ML th
at companies need (say NLP, LLMs, image processing, etc). Rather, my research involves using ML for science. Therefore, 
probably, it will be very hard to convince companies to take my application to these positions seriously.

So after all 
this reflection, earlier this year I started applying for industry positions in ML. I didn't have much of a hope when ap
plying, but I still applied for the heck of it. But to my extreme surprise, a FAANG company offered to interview me for 
a Research Scientist in ML position! This was huuuge for me, and filled me with self confidence. I put everything aside 
to do some leetcode (because, as I said, I have no CS background and these leetcode-type problems are very new to me). I
 passed the screening round and went into full loop. I kept leetcoding and rigorously preparing for the ML system design
 and behavioral interviews. I thought I had done well in all of my interviews, but to my dismay they rejected my applica
tion at the end. This was a huge bummer for me. I was one step away from my dream job and I failed. And to make it worse
, this company was the only company to even interview me, all the other companies (10s of non-FAANG) companies that I ap
plied to, outright rejected me (which was surprising to be honest).

**What now?:** I apologize for the extremely long p
ost with my entire life story. I don't even know what I am saying or what questions I am asking clearly, but whatever it
 is, providing my full background may help. All I know at this point is I am in shambles. Maybe I am aiming too high and
 it was completely expected for this one chance to end up in failure. But I have no idea what I am going to do now. Mayb
e I have become myopic from hoping/looking at this company for so long. But right now, I feel like I should either becom
e a research scientist in ML or nothing at all. In my opinion, **the biggest obstacle in all of this is: I am looking fo
r a job in big tech where I can do research and publish which extremely limits my choices.** There are only 4-5 companie
s in the world that have these kinds of posts and those companies are so prestigious that they have no shortage of prope
r ML researchers applying to their posts. I think it is a miracle that I even got this one interview.

So I guess my mos
t important question to you guys is: **With my background in mind, what is the shortest path for me to obtain a research
 scientist position in ML?** My current plan is to start a postdoc but use my postdoc to publish a paper in NeurIPS/ICML
/ICLR (or at least aim for this) just to show potential recruiters that even though my PhD is in ME, I have what it take
s to do the research scientist jobs.

Thank you for looking at my post.

TLDR: Delusional (?) ME PhD graduate who thinks
 he is worthy of a research position in pure ML with those amazing FAANG salaries asking how he can get to his dream.
```
---

     
 
all -  [ Profile Evaluation for MS Fall 2025 ](https://www.reddit.com/r/MSCS/comments/1bxbjl6/profile_evaluation_for_ms_fall_2025/) , 2024-04-10-0910
```
International student from India. Currently doing my second bachelor's from an IIT in Data Science, and I have a Physics
 Honors degree from a Tier 2 college. 

CGPA - 8.73/10 in Physics Honors and 8/10 in Data Science

Research Experience -
 4 research internships in AI/ML: 1 at a startup, one at IIIT Hyderabad and one in Singapore (SIPGA) and one upcoming in
 Japan next year

Research Papers - 2 top conference published papers (CVPR and NeurIPS) 

Industry Internships - 2 inte
rnships at Fortune 100 companies (one as a business analyst and the second one as a data scientist)

I took GRE recently
 and scored 334 (Q-169, V-165, AWA- 4.5)

TOEFL - yet to take

LORs - all three would be from research supervisors

I wa
nt to target ML, AI and CS grad programmes. Any suggestions on which unis could be safe schools? Also, CMU is my dream s
chool but now I'm a bit nervous to apply as my cgpa is low, but can my research experience and gre make up for it?  
```
---

     
 
all -  [ [R] Up to 17% of Recent AI Conference Peer Reviews Written by ChatGPT ](https://www.reddit.com/r/machinelearningnews/comments/1bnsuxg/r_up_to_17_of_recent_ai_conference_peer_reviews/) , 2024-04-10-0910
```
A new study has uncovered that a significant fraction of peer reviews for top AI conferences in 2023-2024 likely include
d substantial AI-generated content from models like ChatGPT.

Using a novel statistical technique, researchers estimated
 the percentage of text generated by AI in large collections of documents. Analyzing peer reviews, they found:

* 10.6% 
of ICLR 2024 reviews had significant AI content
* 9.1% for NeurIPS 2023
* 6.5% for CoRL 2023
* 16.9% for EMNLP 2023

In 
contrast, only 1-2% of pre-ChatGPT reviews from 2022 and earlier were flagged as having substantial AI contribution.

So
me key findings:

1. AI-heavy reviews tended to come in close to the deadline
2. Fewer scholarly citations in AI-flavore
d reviews
3. Reviewers with AI-tinged reviews engaged less in author discussion
4. AI content made reviews more semantic
ally homogeneous
5. Lower reviewer confidence correlated with higher AI estimates

The study, I think, raises some quest
ions for proactive policy development in academia around responsible AI use in research. AI may be eroding the quality a
nd integrity of peer review through these 'shadow' influences. Open questions include:

* Should AI assistance in peer r
eview be disclosed?
* How should we incentivize good practices despite AI temptations?
* Can we preserve intellectual di
versity under AI homogenization?
* Should we rethink credit for hybrid human/AI knowledge work?

Overall, an interesting
 empirical glimpse into AI's rapidly growing tendrils in the foundations of scientific quality control! I thought the ap
proach of measuring the frequency of certain AI wording 'ticks' made a lot of sense (some of the adjectives GPT4 uses, f
or example, are clear tells).

I'm curious to read the comments on this one! I have a [much more detailed summary availa
ble here](https://aimodels.substack.com/p/new-study-finds-up-to-17-of-ai-conference) as well if you're interested, and t
he original paper is [here](https://arxiv.org/pdf/2403.07183.pdf).
```
---

     
 
all -  [ [R] Up to 17% of Recent AI Conference Peer Reviews Written by ChatGPT ](https://www.reddit.com/r/MachineLearning/comments/1bnsuea/r_up_to_17_of_recent_ai_conference_peer_reviews/) , 2024-04-10-0910
```
A new study has uncovered that a significant fraction of peer reviews for top AI conferences in 2023-2024 likely include
d substantial AI-generated content from models like ChatGPT.

Using a novel statistical technique, researchers estimated
 the percentage of text generated by AI in large collections of documents. Analyzing peer reviews, they found:

* 10.6% 
of ICLR 2024 reviews had significant AI content
* 9.1% for NeurIPS 2023
* 6.5% for CoRL 2023
* 16.9% for EMNLP 2023

In 
contrast, only 1-2% of pre-ChatGPT reviews from 2022 and earlier were flagged as having substantial AI contribution.

So
me key findings:

1. AI-heavy reviews tended to come in close to the deadline
2. Fewer scholarly citations in AI-flavore
d reviews
3. Reviewers with AI-tinged reviews engaged less in author discussion
4. AI content made reviews more semantic
ally homogeneous
5. Lower reviewer confidence correlated with higher AI estimates

The study, I think, raises some quest
ions for proactive policy development in academia around responsible AI use in research. AI may be eroding the quality a
nd integrity of peer review through these 'shadow' influences. Open questions include:

* Should AI assistance in peer r
eview be disclosed?
* How should we incentivize good practices despite AI temptations?
* Can we preserve intellectual di
versity under AI homogenization?
* Should we rethink credit for hybrid human/AI knowledge work?

Overall, an interesting
 empirical glimpse into AI's rapidly growing tendrils in the foundations of scientific quality control! I thought the ap
proach of measuring the frequency of certain AI wording 'ticks' made a lot of sense (some of the adjectives GPT4 uses, f
or example, are clear tells). 

I'm curious to read the comments on this one! I have a [much more detailed summary avail
able here](https://aimodels.substack.com/p/new-study-finds-up-to-17-of-ai-conference) as well if you're interested, and 
the original paper is [here](https://arxiv.org/pdf/2403.07183.pdf).
```
---

     
 
all -  [ [D] simple typos or errors in my understanding?! ](https://www.reddit.com/r/MachineLearning/comments/1bicphu/d_simple_typos_or_errors_in_my_understanding/) , 2024-04-10-0910
```
Though I mailed to all authors, I couldn't receive any reply...

&#x200B;

I really enjoyed reading paper, “Compositiona
l Visual Generation with Energy Based Models” (NeurIPS\`20; [https://arxiv.org/abs/2004.06030](https://arxiv.org/abs/200
4.06030)).

While I am following the idea in the paper, I am facing a problem in understanding the equation (8) in the p
aper.

According to the paper's notation, the EBM is defined as (1):

[Eq. \(1\)](https://preview.redd.it/lnerbdlm58pc1.
png?width=202&format=png&auto=webp&s=e7ce768304cafa8e0fb88202466ad7cf40d9d3e8)

i.e.,, the *energy function*, E\_\\theta
(x), is defined as the negative term on top of the exponent.

&#x200B;

In eq. (3) below, authors defines SGLD step for 
acquiring samples from any energy based model (EBM).

Next, according to 'concept disjunction' proposed by authors, the 
union-ized probability densities are defined in (7), in the form of the exponential of log-sum-exp of different EBMs' *e
nergy function*s.

https://preview.redd.it/sas3f4yg58pc1.png?width=1005&format=png&auto=webp&s=2bb0aa67cf2767ede091102ce
22965e8c8bdbe7c

From (7), I understood that the unionized energy function is accordingly -logsumexp(-E(x|c1), ...),  
t
hus corresponding SGLD should have plus sign.  
However, in the paper, authors stated the SGLD with ***minus sign***, an
d I've lost...

After looking through the official code implementation,   
([https://github.com/yilundu/ebm\_composition
ality/blob/c7ac54366d2d5a15f71871448bd720bf5b3eb82d/celeba\_combine.py#L150C9-L150C32](https://github.com/yilundu/ebm_co
mpositionality/blob/c7ac54366d2d5a15f71871448bd720bf5b3eb82d/celeba_combine.py#L150C9-L150C32))  
I found that the combi
ned energy function derivation of mine ( E(x|\\cup\_i c\_i) ) seems to be correct,  
according to the assignment of the 
\`e\_pos\` variable in the code.

&#x200B;

Still, I'd like to acquire some clarification on this flow.  
Can anybody sk
im through this post and check my thought?

Thank you in advance!
```
---

     
 
all -  [ Stanford MS/CS 2024 - REJECTED ](https://www.reddit.com/r/gradadmissions/comments/1bhwguc/stanford_mscs_2024_rejected/) , 2024-04-10-0910
```
I unfortunately got denied from Online Stanford MS in CS Today. I was fairly confident in my application. I had 4.00/4.0
0 GPA (ranked 1st in my graduation class from decent US college), ML Engineer at FAANG, published a paper in NeurIPS. My
 references include Dean of Engineering, My college Prof (Oxford grad) and my manager from work - MIT (PhD). I had alrea
dy got rejected 2 years ago, since then I made a publication switched to an ML oriented role and tailored my referrals a
ccordingly. It makes sense that a lot of people flooded in to AI track this year but I really want to get a sense of oth
er profiles who got admitted this year.

Maybe next year I will try again :/
```
---

     
 
all -  [ [D] papers that only evaluate on cifar10 ](https://www.reddit.com/r/MachineLearning/comments/1bhp54a/d_papers_that_only_evaluate_on_cifar10/) , 2024-04-10-0910
```
Hi everyone!

While reviewing for NeurIPS 2024, one of the things I keep noticing is that a lot of papers only evaluate 
on datasets of very small size, like Cifar-10. his feels weird to me: I consider Cifar10 to be a toy-dataset and testbed
 for my methods, not something I'd use to show that my method actually works/is relevant in practice. So my first intuit
ion is always 'this approach probably does not scale to larger datasets'. I mean, ImageNet is 12 years old now, and I've
 personally been giving results on imagenet for my papers since ~8 years. most computer vision applications I know requi
re larger resolutions than just 32x32. it's also my impression that almost all of the 'good' papers I read have results 
on larger scale data. But given how often I encounter this situation, I have to wonder: am  I just working in a very pri
vileged environment, or are the manuscript-authors just lazy? How much faith do you have in papers that only evaluate on
 MNIST and CIFAR10?
```
---

     
 
all -  [ 2 yoe in research labs only in computer vision. What should be my next steps? ](https://www.reddit.com/r/cscareerquestionsEU/comments/1bdslud/2_yoe_in_research_labs_only_in_computer_vision/) , 2024-04-10-0910
```
Hi,
Based in France. I have a masters where I did 2 internships in a good research lab and then started working as resea
rch engineer in a public lab for ~2 years. They only offer temporary contracts and there is a limit to how long you can 
work with these temporary contracts in France (you can try for the few research scientists positions but jts if you have
 phd/post doc plus good publiching track and experience, so i need to move on).
I didn't go for a phd and don't want to 
now since I felt I didn't have the right motivation and didn't want to do it for the sake of it. Didn't see myself as a 
researcher either publishing all my life. Research Engineer is a sweet spot.

From internships/job, I've so far co-autho
red 4 papers in computer vision conferences (neurips, iccv, cvpr, miccai) in the topics of 3d reconstruction and human m
odeling. But that's pretty much the achievement which is probably meaningless for jobs in the industry. And thing is, I 
feel my skill stack being also limited to research workflow might be little interesting to the industry (practical exper
ience with only python vs c++ for example). 

And i feel i should switch to industry (instead of another contract in a r
esearch lab) since honestly, even though these papers might seem nothing, they take a lot of effort and work and the who
le publishing cycle drains you mentally. And the compensation you get is really low I feel in these public labs (32k bru
t).

When I look around for jobs, I see mostly poorly defined descriptions but titled data scientist or mainly MLops. No
thing specifically related to what ive done being needed. I have 7 months left on my contract. What should I start learn
ing/doing or what could be an ideal focus for job search with such profile? Id like to stay in France and even in the sa
me city near lyon since im a foreigner and i feel more settled due to having made friends and understanding the language
. Your insights would be helpful. I feel very lost.
```
---

     
 
all -  [ ML Internships aren't supposed to be this difficult to get - Rant ](https://www.reddit.com/r/cscareerquestions/comments/1bd940o/ml_internships_arent_supposed_to_be_this/) , 2024-04-10-0910
```
As an international master's student, I'm on the verge of quitting my search as my internship hunt for the past 8 months
 has practically given 0 offers. I've applied to over 600 postings (every single ML/DS posting that has come). I did get
 3-4 callbacks but they never converted to offers despite the interviews going well. All I can say is that the competiti
on is unbelievably high, and the companies seem to be taking just 1 intern per team or none. Every position I am interes
ted in requires a Ph.D. candidate or papers in conferences like ICML, NeurIPS, or CVPR on the exact niche area the team 
works on. When there's a lack of jobs and an abundant supply of candidates, they can get choosy. But these are internshi
ps we are talking about, things meant to be entry-level positions.

Is it actually supposed to be this difficult? The wo
rst part is that all the callbacks I got so far are through direct contact with the hiring manager. None of the regular 
applications(even with referrals) gave me anything. As a final plea, if any of my fellow Redditors here have leads I'd r
eally appreciate some help.
```
---

     
