 
all -  [ [R] RETVec: Resilient and Efficient Text Vectorizer ](https://www.reddit.com/r/MachineLearning/comments/188gjpy/r_retvec_resilient_and_efficient_text_vectorizer/) , 2023-12-03-0911
```
Happy Friday,

Really happy to share that the code and model for RETVec our new SOTA robust text tokenizer for classific
ation is available on Github [here](https://github.com/google-research/retvec/) and the NeurIPS paper [here](https://arx
iv.org/abs/2302.09207).  We also provide native support for TFLite and for the web via a TFJS. Hope you will find it use
ful for your research. If you would like to give it a try we have a get started [notebook](https://github.com/google-res
earch/retvec/blob/main/notebooks/train_retvec_model_tf.ipynb).

Let us know if you have any questions.

&#x200B;
```
---

     
 
all -  [ List 'Preprints' or 'Conference Papers' section first on CV? ](https://www.reddit.com/r/AskAcademia/comments/1884tyy/list_preprints_or_conference_papers_section_first/) , 2023-12-03-0911
```
I am preparing my CV for grad school apps and I have one conference paper and one preprint (already submitted to journal
) to list on it. I am second author on both but had far more involvement in the preprint work so I would like to highlig
ht that. Much of my CV consists of work on this project as well.  
  
I have a separate 'Preprints' and 'Conference Pa
pers' sections. I was thinking I would put 'Preprints' first because this is the project I heavily contributed to, but I
 question this since the conference paper is 'published' in that it was already reviewed and accepted to this conference
 (a Neurips workshop). Which should be put first?
```
---

     
 
all -  [ [D] NeurIPS Climbing Club (Gradient Ascent?) ](https://www.reddit.com/r/MachineLearning/comments/187fbdy/d_neurips_climbing_club_gradient_ascent/) , 2023-12-03-0911
```
I'll be attending NeurIPS 2023 this year and won't know anyone. I'm an avid climber and there is a nice bouldering gym c
lose to the conference center - would anyone else fancy a climb over the week? Reply below so we can see how many people
 and I can setup a meetup page or something. I'm a final year PhD from the UK working in video understanding.
```
---

     
 
all -  [ AI Innovations and Developments: From Energy Efficiency to Generative Applications and Regulatory Ch ](https://www.reddit.com/r/ai_news_by_ai/comments/187cet4/ai_innovations_and_developments_from_energy/) , 2023-12-03-0911
```





#leaders #api #tool #release #science #bigtech #feature #opinions #major_players #startups #update #event #hardware
 #opensource #paper #dataset #scheduled

The MIT Lincoln Laboratory Supercomputing Center (LLSC) has developed technique
s to reduce the energy consumption of AI models, including power-capping hardware and stopping AI training early. These 
interventions have minimal impact on model performance and can lead to significant reductions in energy consumption and 
costs [3]. 







Google Translate's neural machine learning models have improved translation quality by recognizing an
d differentiating between homonyms. The team has curated data from dictionary providers and third-party translators to i
mprove translation accuracy, with the goal of enabling fluid interactions for people by removing language barriers [5]. 








Amazon Web Services (AWS) has announced new innovations for Amazon Bedrock, a fully managed service for building
 and scaling generative AI applications. The latest models from Anthropic, Cohere, Meta, Stability AI, and Amazon provid
e customers with more options for their specific use cases [8]. 







Stability AI is partnering with AWS and the Amaz
on Bedrock team to democratize access to GenAI and help developers turn their generative AI visions into reality [9][10]
. 







NVIDIA has announced NeMo Retriever, a generative AI microservice that connects custom large language models (
LLMs) to enterprise data. The technology overcomes the limitations of traditional models by combining information retrie
val with LLMs, enhancing their access to vast knowledge bases [12]. 







The cloud-native microservice-based architec
ture of adam.ai, a meeting management platform, leverages Google Cloud Dataflow, NVIDIA Riva speech-to-text models, and 
LLMs for efficient summarization. The architecture ensures scalability, fault tolerance, and an intuitive user experienc
e [13]. 







The UAE Minister of AI, Omar Al Olama, warns that overregulating artificial intelligence (AI) can have s
erious and lasting consequences. He emphasizes the need for governments to find a balance in regulating AI and ensure th
at their population is not left behind [16]. 







Yann LeCun argues that AI systems are easier to align than humans a
nd animals because they are designed as white boxes. He introduces the concept of AI Optimism, which promotes hope, free
dom, and fairness for all [25]. 







DeepMind has developed an AI system called GNoME that uses deep learning to pred
ict the stability of new materials. The system has discovered 2.2 million new crystals, including 380,000 stable materia
ls that have the potential to accelerate the development of greener technologies [30]. 







Sam Altman has returned a
s CEO of OpenAI, with Mira Murati returning as CTO and Greg Brockman as President. The company is focused on advancing t
heir research plan, investing in full-stack safety efforts, improving and deploying their products, and serving their cu
stomers [31]. 







The author is seeking feedback on their GPT-4 Vision API and planning future work based on user in
put [1]. A new short course on sophisticated RAG (Retrieval Augmented Generation) techniques is available, taught by Jer
ry Liu and Anupam Datta of Llama Index and Truera AI [6]. Partha Talukdar is a Research Scientist at Google Research, In
dia, leading the languages group [7]. 







The author argues that the dichotomy between those who prioritize safety a
nd those who advocate for acceleration in AI is becoming absurd. They believe that realists can embrace both safety and 
acceleration, emphasizing the need to accelerate in a safe manner [4]. 







Ben Brooks, Head of Public Policy at Stab
ility AI, presented at the US Senate's AI Insight Forum in Washington, D.C. He emphasized the importance of open models 
in the AI ecosystem, promoting transparency, competition, and grassroots innovation [11]. 







The author believes th
at both printed books and AI systems have the potential to improve access to knowledge and make people smarter, more cre
ative, and more productive [17]. 







Yann LeCun shared a tweet about a talk on SSL for PDE solving and identificatio
n, which will be a preview of their upcoming NeurIPS paper [23]. 







Yann LeCun has announced the release of two onl
ine LLMs, pplx-7b-online and pplx-70b-online. These LLMs have been trained using open-source LLMs and have been fine-tun
ed to incorporate knowledge from the internet [27]. 







Yann LeCun is excited to share LEDITS++, a text-to-image tec
hnology that takes textual image editing to a new level [29]. 







Adam, who is on the OpenAI Board, has been transpa
rent about the potential conflict of interest between his role at Quora and OpenAI. He has taken steps to manage the sit
uation, including recusing himself when necessary and offering to leave the Board if needed [32]. 







Sam Altman ack
nowledges that there were misunderstandings between him and the board members. He emphasizes the importance of learning 
from this experience and applying those lessons to the company's future [33]. 







The author reflects on a year ago 
when they were finalizing the development of ChatGPT [34].




[1. Greg Brockman @gdb https://twitter.com/gdb/status/172
9750474440499678](https://twitter.com/gdb/status/1729750474440499678)

[2. Greg Brockman @gdb https://twitter.com/gdb/st
atus/1729893902814192096](https://twitter.com/gdb/status/1729893902814192096)

[3. Mustafa Suleyman @mustafasuleyman htt
ps://twitter.com/mustafasuleyman/status/1729827784741044279](https://twitter.com/mustafasuleyman/status/1729827784741044
279)

[4. Mustafa Suleyman @mustafasuleyman https://twitter.com/mustafasuleyman/status/1729860128403239011](https://twit
ter.com/mustafasuleyman/status/1729860128403239011)

[5. Google @google https://twitter.com/google/status/17299206621547
44143](https://twitter.com/google/status/1729920662154744143)

[6. Andrew Ng @AndrewYNg https://twitter.com/AndrewYNg/st
atus/1729924040230629485](https://twitter.com/AndrewYNg/status/1729924040230629485)

[7. Google AI @googleai https://twi
tter.com/googleai/status/1729932201138253870](https://twitter.com/googleai/status/1729932201138253870)

[8. cohere @cohe
re https://twitter.com/cohere/status/1729958277033680967](https://twitter.com/cohere/status/1729958277033680967)

[9. St
ability AI @stabilityai https://twitter.com/stabilityai/status/1729973178079088831](https://twitter.com/stabilityai/stat
us/1729973178079088831)

[10. Stability AI @stabilityai https://twitter.com/stabilityai/status/1729973286468297004](http
s://twitter.com/stabilityai/status/1729973286468297004)

[11. Stability AI @stabilityai https://twitter.com/stabilityai/
status/1729987222039048221](https://twitter.com/stabilityai/status/1729987222039048221)

[12. NVIDIA AI Developer @NVIDI
AAIDev https://twitter.com/NVIDIAAIDev/status/1729973513174368279](https://twitter.com/NVIDIAAIDev/status/17299735131743
68279)

[13. NVIDIA AI Developer @NVIDIAAIDev https://twitter.com/NVIDIAAIDev/status/1729983574525263976](https://twitte
r.com/NVIDIAAIDev/status/1729983574525263976)

[14. NVIDIA AI @NVIDIAAI https://twitter.com/NVIDIAAI/status/172996497923
7920830](https://twitter.com/NVIDIAAI/status/1729964979237920830)

[15. NVIDIA AI @NVIDIAAI https://twitter.com/NVIDIAAI
/status/1730013797664895420](https://twitter.com/NVIDIAAI/status/1730013797664895420)

[16. Yann LeCun @ylecun https://t
witter.com/ylecun/status/1729834374080958622](https://twitter.com/ylecun/status/1729834374080958622)

[17. Yann LeCun @y
lecun https://twitter.com/ylecun/status/1729844776961286621](https://twitter.com/ylecun/status/1729844776961286621)

[18
. Yann LeCun @ylecun https://twitter.com/ylecun/status/1729854485198184806](https://twitter.com/ylecun/status/1729854485
198184806)

[19. Yann LeCun @ylecun https://twitter.com/ylecun/status/1729854839910244853](https://twitter.com/ylecun/st
atus/1729854839910244853)

[20. Yann LeCun @ylecun https://twitter.com/ylecun/status/1729865645255463248](https://twitte
r.com/ylecun/status/1729865645255463248)

[21. Yann LeCun @ylecun https://twitter.com/ylecun/status/1729873043173089666]
(https://twitter.com/ylecun/status/1729873043173089666)

[22. Yann LeCun @ylecun https://twitter.com/ylecun/status/17299
90382522380496](https://twitter.com/ylecun/status/1729990382522380496)

[23. Yann LeCun @ylecun https://twitter.com/ylec
un/status/1729990800682197414](https://twitter.com/ylecun/status/1729990800682197414)

[24. Yann LeCun @ylecun https://t
witter.com/ylecun/status/1729993214608941109](https://twitter.com/ylecun/status/1729993214608941109)

[25. Yann LeCun @y
lecun https://twitter.com/ylecun/status/1730000457513443666](https://twitter.com/ylecun/status/1730000457513443666)

[26
. Yann LeCun @ylecun https://twitter.com/ylecun/status/1730001044401525182](https://twitter.com/ylecun/status/1730001044
401525182)

[27. Yann LeCun @ylecun https://twitter.com/ylecun/status/1730002728771100828](https://twitter.com/ylecun/st
atus/1730002728771100828)

[28. Yann LeCun @ylecun https://twitter.com/ylecun/status/1730004138942247237](https://twitte
r.com/ylecun/status/1730004138942247237)

[29. Yann LeCun @ylecun https://twitter.com/ylecun/status/1730069675240050797]
(https://twitter.com/ylecun/status/1730069675240050797)

[30. Demis Hassabis @demishassabis https://twitter.com/demishas
sabis/status/1729995611443769823](https://twitter.com/demishassabis/status/1729995611443769823)

[31. OpenAI @openai htt
ps://twitter.com/openai/status/1730030975931846939](https://twitter.com/openai/status/1730030975931846939)

[32. Sam Alt
man @sama https://twitter.com/sama/status/1730032994474475554](https://twitter.com/sama/status/1730032994474475554)

[33
. Sam Altman @sama https://twitter.com/sama/status/1730033079975366839](https://twitter.com/sama/status/1730033079975366
839)

[34. Sam Altman @sama https://twitter.com/sama/status/1730076492162548208](https://twitter.com/sama/status/1730076
492162548208)
```
---

     
 
all -  [ AI Developments: Anthropic at AWS re:Invent, GPT-4 in Radiology, OpenAIs Safety Focus, Pika 1.0 Laun ](https://www.reddit.com/r/ai_news_by_ai/comments/186hqkg/ai_developments_anthropic_at_aws_reinvent_gpt4_in/) , 2023-12-03-0911
```





#startups #event #leaders #science #paper #tool #release #feature #vc #api #hardware #major_players #update #bigtec
h #dataset #scheduled

AI company Anthropic is set to participate in the AWS re:Invent conference in Las Vegas, with CEO
 Dario Amodei joining AWS CEO Andy Jassy for the keynote. The event will be livestreamed and will cover topics such as c
loud transformation, data innovations, AI/ML, and AWS news[1].







GPT-4, an AI model, has demonstrated impressive pe
rformance in radiology tasks, including disease classification and report summarization. The model has potential to stru
cture radiology reports automatically, improving standardization and consistency in disease descriptions. It can also tr
anslate medical reports into more empathetic and understandable formats for patients and healthcare professionals[2].








OpenAI is focusing on safety in AI development, with ongoing efforts in preparedness, reliable AI deployment resear
ch, and AI security research. They are inviting discussions on these topics at NeurIPS[3].







Pika 1.0, an idea-to-v
ideo platform, is now available to new users on the web and Discord. The platform allows users to create and edit videos
 using AI[5][12][16][44]. Pika Labs, the company behind Pika 1.0, has raised $55 million in funding and is hiring for va
rious roles[7][8][9][29]. The company aims to make video creation accessible to everyone and is looking for passionate a
nd ambitious team members[8].







A new AI system, Sturgeon, has been developed for brain tumor surgeries. It uses ra
pid nanopore sequencing to obtain molecular subclassification of tumors in under 90 minutes. The system can assist in ne
urosurgical decision-making and potentially prevent additional surgeries[42][43].







Artie has launched its Analytic
s Portal, a real-time database replication solution that provides visibility into streaming data pipelines and offers sy
stem infrastructure monitoring[45]. Decoherence has launched Stable Video, a next-generation video generator that allows
 users to create videos with remarkable camera movement and fidelity using just a starting image or text[46]. Solve Inte
lligence, a legal tech startup, has raised $3 million in funding. The company provides an AI-powered in-browser document
 editor for patent attorneys to write high-quality patents efficiently[47].







NVIDIA has announced NeMo Retriever, 
a microservice that allows for the integration of retrieval-augmented generation (RAG) capabilities into AI applications
. RAG combines information retrieval with large language models (LLMs) to enhance their knowledge and address limitation
s[50][53]. NVIDIA's AI technology, Picasso, has been recognized as one of the Next Big Things in Tech in AI and data by 
Fast Company[49][52].







Google Research has made contributions to Call Screen on Pixel phones, a feature that uses 
on-device ASR to transcribe callers' requests in real-time[55]. The Google Research team in Ghana has been collecting da
ta to train automatic speech recognition models for local languages in Africa[57].







SDXL Turbo is a real-time text
-to-image generation model that achieves state-of-the-art performance by using a new distillation technology. This techn
ology allows for single-step image generation with high quality[58]. Yann LeCun and Catherine Rathkopf wrote an essay di
scussing the misconception that language models like ChatGPT are intelligent simply because they are fluent[61].








Cohere is hosting a demo showcase with Stepan Pushkarev, CEO and CTO of Provectus Inc, at their booth 124 every day at 1
0:30 am and 1:30 pm PT during the AWS re:Invent event[62].




[1. Anthropic @anthropicai https://twitter.com/anthropica
i/status/1729375950499135498](https://twitter.com/anthropicai/status/1729375950499135498)

[2. Greg Brockman @gdb https:
//twitter.com/gdb/status/1729483568827744673](https://twitter.com/gdb/status/1729483568827744673)

[3. Greg Brockman @gd
b https://twitter.com/gdb/status/1729556185676746792](https://twitter.com/gdb/status/1729556185676746792)

[4. Pika @pik
a_labs https://twitter.com/pika_labs/status/1729498462738117004](https://twitter.com/pika_labs/status/172949846273811700
4)

[5. Pika @pika_labs https://twitter.com/pika_labs/status/1729510078959497562](https://twitter.com/pika_labs/status/1
729510078959497562)

[6. Pika @pika_labs https://twitter.com/pika_labs/status/1729510176556802066](https://twitter.com/p
ika_labs/status/1729510176556802066)

[7. Pika @pika_labs https://twitter.com/pika_labs/status/1729511120971440186](http
s://twitter.com/pika_labs/status/1729511120971440186)

[8. Pika @pika_labs https://twitter.com/pika_labs/status/17295112
64076828809](https://twitter.com/pika_labs/status/1729511264076828809)

[9. Pika @pika_labs https://twitter.com/pika_lab
s/status/1729511395341836704](https://twitter.com/pika_labs/status/1729511395341836704)

[10. Pika @pika_labs https://tw
itter.com/pika_labs/status/1729516807634227530](https://twitter.com/pika_labs/status/1729516807634227530)

[11. Pika @pi
ka_labs https://twitter.com/pika_labs/status/1729516925989048519](https://twitter.com/pika_labs/status/17295169259890485
19)

[12. Pika @pika_labs https://twitter.com/pika_labs/status/1729518167314313448](https://twitter.com/pika_labs/status
/1729518167314313448)

[13. Pika @pika_labs https://twitter.com/pika_labs/status/1729518618902401256](https://twitter.co
m/pika_labs/status/1729518618902401256)

[14. Pika @pika_labs https://twitter.com/pika_labs/status/1729518718495903951](
https://twitter.com/pika_labs/status/1729518718495903951)

[15. Pika @pika_labs https://twitter.com/pika_labs/status/172
9520925358604697](https://twitter.com/pika_labs/status/1729520925358604697)

[16. Pika @pika_labs https://twitter.com/pi
ka_labs/status/1729521289994612760](https://twitter.com/pika_labs/status/1729521289994612760)

[17. Pika @pika_labs http
s://twitter.com/pika_labs/status/1729521489366622408](https://twitter.com/pika_labs/status/1729521489366622408)

[18. Pi
ka @pika_labs https://twitter.com/pika_labs/status/1729522080700661847](https://twitter.com/pika_labs/status/17295220807
00661847)

[19. Pika @pika_labs https://twitter.com/pika_labs/status/1729522268349612189](https://twitter.com/pika_labs/
status/1729522268349612189)

[20. Pika @pika_labs https://twitter.com/pika_labs/status/1729528080656658932](https://twit
ter.com/pika_labs/status/1729528080656658932)

[21. Pika @pika_labs https://twitter.com/pika_labs/status/172952848360346
0316](https://twitter.com/pika_labs/status/1729528483603460316)

[22. Pika @pika_labs https://twitter.com/pika_labs/stat
us/1729529530623344851](https://twitter.com/pika_labs/status/1729529530623344851)

[23. Pika @pika_labs https://twitter.
com/pika_labs/status/1729530041489625398](https://twitter.com/pika_labs/status/1729530041489625398)

[24. Pika @pika_lab
s https://twitter.com/pika_labs/status/1729533339911221652](https://twitter.com/pika_labs/status/1729533339911221652)

[
25. Pika @pika_labs https://twitter.com/pika_labs/status/1729533791226773789](https://twitter.com/pika_labs/status/17295
33791226773789)

[26. Pika @pika_labs https://twitter.com/pika_labs/status/1729534211592446266](https://twitter.com/pika
_labs/status/1729534211592446266)

[27. Pika @pika_labs https://twitter.com/pika_labs/status/1729539069896724860](https:
//twitter.com/pika_labs/status/1729539069896724860)

[28. Pika @pika_labs https://twitter.com/pika_labs/status/172954121
2959629551](https://twitter.com/pika_labs/status/1729541212959629551)

[29. Pika @pika_labs https://twitter.com/pika_lab
s/status/1729553585350844804](https://twitter.com/pika_labs/status/1729553585350844804)

[30. Pika @pika_labs https://tw
itter.com/pika_labs/status/1729581833191383301](https://twitter.com/pika_labs/status/1729581833191383301)

[31. Pika @pi
ka_labs https://twitter.com/pika_labs/status/1729582416954638539](https://twitter.com/pika_labs/status/17295824169546385
39)

[32. Pika @pika_labs https://twitter.com/pika_labs/status/1729582517802467577](https://twitter.com/pika_labs/status
/1729582517802467577)

[33. Pika @pika_labs https://twitter.com/pika_labs/status/1729582629085675707](https://twitter.co
m/pika_labs/status/1729582629085675707)

[34. Pika @pika_labs https://twitter.com/pika_labs/status/1729582764142231950](
https://twitter.com/pika_labs/status/1729582764142231950)

[35. Pika @pika_labs https://twitter.com/pika_labs/status/172
9582958393098439](https://twitter.com/pika_labs/status/1729582958393098439)

[36. Pika @pika_labs https://twitter.com/pi
ka_labs/status/1729583238140633270](https://twitter.com/pika_labs/status/1729583238140633270)

[37. Pika @pika_labs http
s://twitter.com/pika_labs/status/1729583922843975915](https://twitter.com/pika_labs/status/1729583922843975915)

[38. Pi
ka @pika_labs https://twitter.com/pika_labs/status/1729584082382631037](https://twitter.com/pika_labs/status/17295840823
82631037)

[39. Pika @pika_labs https://twitter.com/pika_labs/status/1729584342588883011](https://twitter.com/pika_labs/
status/1729584342588883011)

[40. Pika @pika_labs https://twitter.com/pika_labs/status/1729584432346955973](https://twit
ter.com/pika_labs/status/1729584432346955973)

[41. Pika @pika_labs https://twitter.com/pika_labs/status/172966811633290
8636](https://twitter.com/pika_labs/status/1729668116332908636)

[42. Mustafa Suleyman @mustafasuleyman https://twitter.
com/mustafasuleyman/status/1729540245073358890](https://twitter.com/mustafasuleyman/status/1729540245073358890)

[43. Mu
stafa Suleyman @mustafasuleyman https://twitter.com/mustafasuleyman/status/1729546793434640638](https://twitter.com/must
afasuleyman/status/1729546793434640638)

[44. Andrej Karpathy @karpathy https://twitter.com/karpathy/status/172954550689
0932536](https://twitter.com/karpathy/status/1729545506890932536)

[45. Y Combinator @ycombinator https://twitter.com/yc
ombinator/status/1729500400825647339](https://twitter.com/ycombinator/status/1729500400825647339)

[46. Y Combinator @yc
ombinator https://twitter.com/ycombinator/status/1729560793610338502](https://twitter.com/ycombinator/status/17295607936
10338502)

[47. Y Combinator @ycombinator https://twitter.com/ycombinator/status/1729572112896319559](https://twitter.co
m/ycombinator/status/1729572112896319559)

[48. AssemblyAI @AssemblyAI https://twitter.com/AssemblyAI/status/17295620467
76123589](https://twitter.com/AssemblyAI/status/1729562046776123589)

[49. NVIDIA AI Developer @NVIDIAAIDev https://twit
ter.com/NVIDIAAIDev/status/1729543235658203451](https://twitter.com/NVIDIAAIDev/status/1729543235658203451)

[50. NVIDIA
 AI Developer @NVIDIAAIDev https://twitter.com/NVIDIAAIDev/status/1729568339691737583](https://twitter.com/NVIDIAAIDev/s
tatus/1729568339691737583)

[51. NVIDIA AI Developer @NVIDIAAIDev https://twitter.com/NVIDIAAIDev/status/172964424306327
5529](https://twitter.com/NVIDIAAIDev/status/1729644243063275529)

[52. NVIDIA AI @NVIDIAAI https://twitter.com/NVIDIAAI
/status/1729554640201474222](https://twitter.com/NVIDIAAI/status/1729554640201474222)

[53. NVIDIA AI @NVIDIAAI https://
twitter.com/NVIDIAAI/status/1729568339729482105](https://twitter.com/NVIDIAAI/status/1729568339729482105)

[54. NVIDIA A
I @NVIDIAAI https://twitter.com/NVIDIAAI/status/1729590987524043004](https://twitter.com/NVIDIAAI/status/172959098752404
3004)

[55. Google AI @googleai https://twitter.com/googleai/status/1729563526673412400](https://twitter.com/googleai/st
atus/1729563526673412400)

[56. Google AI @googleai https://twitter.com/googleai/status/1729579692359831731](https://twi
tter.com/googleai/status/1729579692359831731)

[57. Google @google https://twitter.com/google/status/1729580625298866616
](https://twitter.com/google/status/1729580625298866616)

[58. Stability AI @stabilityai https://twitter.com/stabilityai
/status/1729589510155948074](https://twitter.com/stabilityai/status/1729589510155948074)

[59. Yann LeCun @ylecun https:
//twitter.com/ylecun/status/1729586566291685646](https://twitter.com/ylecun/status/1729586566291685646)

[60. Yann LeCun
 @ylecun https://twitter.com/ylecun/status/1729627089324892466](https://twitter.com/ylecun/status/1729627089324892466)


[61. Yann LeCun @ylecun https://twitter.com/ylecun/status/1729677514614755772](https://twitter.com/ylecun/status/1729677
514614755772)

[62. cohere @cohere https://twitter.com/cohere/status/1729649682970787875](https://twitter.com/cohere/sta
tus/1729649682970787875)
```
---

     
 
all -  [ [D] NeurIPS 2023 Institutions Ranking ](https://www.reddit.com/gallery/185pdax) , 2023-12-03-0911
```

```
---

     
 
all -  [ [R] Rethinking Open'sAI's Q-Learning : Insights from the Award-Winning 'Non-delusional Q-learning' P ](https://www.reddit.com/r/MachineLearning/comments/182bz42/r_rethinking_opensais_qlearning_insights_from_the/) , 2023-12-03-0911
```
OpenAI's approach to Q-Learning has been drawing significant attention recently.

However, there's a fundamental issue i
n the way Q-learning is typically implemented in deep learning and neural network environments. This concern is highligh
ted in the award-winning paper 'Non-delusional Q-learning,' presented at NeurIPS.

The paper suggests a fundamental flaw
 in the blind application of Q-learning updates to deep neural networks. It points out that such updates can create a se
lf-contradictory scenario where improving the network for the current batch of data inadvertently makes it less effectiv
e for other batches. This is akin to a situation in supervised learning where optimizing a network for a specific set of
 data may degrade its performance on other datasets.

For more insights, the full paper can be accessed here: [Non-delus
ional Q-learning Paper](https://papers.nips.cc/paper_files/paper/2018/hash/5fd0245f6c9ddbdf3eff0f505975b6a7-Abstract.htm
l)(Follow up ICML paper: [Practical Non-delusional-Q Learning](https://www.cs.toronto.edu/~cebly/Papers/CONQUR_ICML_2020
_camera_ready.pdf) )

I'm curious about others' views on this topic. What do you think about the implications of these f
indings for the future of Q-learning in deep learning environments?
```
---

     
 
all -  [ Singularity is Actively Deleting All My Posts But This One is Vitally Important And Should NOT BE DE ](https://www.reddit.com/r/ChatGPT/comments/181ps4s/singularity_is_actively_deleting_all_my_posts_but/) , 2023-12-03-0911
```
Update: Reuters reported that here what the big discovery was Q\*. You judge for yourself if this is how we define the S
uperintelligence. [https://www.reddit.com/r/ChatGPT/comments/181pfiq/q\_passing\_math\_tests\_is\_how\_theyre\_describin
g\_the/](https://www.reddit.com/r/ChatGPT/comments/181pfiq/q_passing_math_tests_is_how_theyre_describing_the/)  
[https:
//www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22
/](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2
023-11-22/)  
Update: There is clear evidence a single individual 'Enervation' was responsible as of April 6th 2023 of c
hanging the core definition of what AGI is supposed to be. There is an obvious conflict of interest here as the definiti
on is matching to exactly what is on the OpenAI charter. The question is for all of you is this, Should 1 organization b
e defining what Artificial General Intelligence (AGI) is and should be?

It should be note, that this user (Enervation) 
[has a MASSIVE change log from the April 6th date moving forward for issues ranging from AGI, AI Safety and a plethora o
f other AI issues and concerns.](https://en.wikipedia.org/w/index.php?title=Special:Contributions/Enervation&target=Ener
vation&offset=&limit=500) Is this user Ilya?

The date of the AGI change was April 6th 2023 with 2,842 bytes of new info
rmation.

* [03:55, 6 April 2023](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&oldid=11484
36187) [diff](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&diff=prev&oldid=1148436187) [hi
st](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&action=history)  **+2,842**‎  [Artificial
 general intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence) ‎*No edit summary* [*Tag*](https:/
/en.wikipedia.org/wiki/Special:Tags)*:* [*Visual edit*](https://en.wikipedia.org/wiki/Wikipedia:VisualEditor)

**Prior t
o the date of April 6th 2023 the Wikipedia AGI page read like this: >>>**

**Artificial general intelligence** (**AGI**)
 is the hypothetical[\[1\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&direction=prev&ol
did=1009243150#cite_note-1) ability of an [intelligent agent](https://en.wikipedia.org/wiki/Intelligent_agent) to unders
tand or learn any intellectual task that a [human being](https://en.wikipedia.org/wiki/Human_being) can. It is a primary
 goal of some [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) research and a common top
ic in [science fiction](https://en.wikipedia.org/wiki/Science_fiction) and [futures studies](https://en.wikipedia.org/wi
ki/Futures_studies). AGI can also be referred to as **strong AI**,[\[2\]](https://en.wikipedia.org/w/index.php?title=Art
ificial_general_intelligence&direction=prev&oldid=1009243150#cite_note-FOOTNOTEKurzweil2005260-2)[\[3\]](https://en.wiki
pedia.org/w/index.php?title=Artificial_general_intelligence&direction=prev&oldid=1009243150#cite_note-Kurzweil_2005-08-0
5-3)[\[4\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&direction=prev&oldid=1009243150#c
ite_note-4) **full AI**,[\[5\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&direction=pre
v&oldid=1009243150#cite_note-5) or **general intelligent action**.[\[6\]](https://en.wikipedia.org/w/index.php?title=Art
ificial_general_intelligence&direction=prev&oldid=1009243150#cite_note-FOOTNOTENewellSimon1976-6) Some academic sources 
reserve the term 'strong AI' for computer programs that can [experience](https://en.wikipedia.org/wiki/Artificial_consci
ousness) [sentience](https://en.wikipedia.org/wiki/Sentience), [self-awareness](https://en.wikipedia.org/wiki/Self-aware
ness) and [consciousness](https://en.wikipedia.org/wiki/Chinese_room#Strong_AI).[\[7\]](https://en.wikipedia.org/w/index
.php?title=Artificial_general_intelligence&direction=prev&oldid=1009243150#cite_note-FOOTNOTESearle1980-7) Today's AI is
 speculated to be decades away from AGI.[\[8\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligen
ce&direction=prev&oldid=1009243150#cite_note-spec1-8)[\[9\]](https://en.wikipedia.org/w/index.php?title=Artificial_gener
al_intelligence&direction=prev&oldid=1009243150#cite_note-9)

In contrast to strong AI, [weak AI](https://en.wikipedia.o
rg/wiki/Weak_AI)[\[10\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&direction=prev&oldid
=1009243150#cite_note-10) (also called narrow AI[\[3\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_in
telligence&direction=prev&oldid=1009243150#cite_note-Kurzweil_2005-08-05-3)) is not intended to perform human-like [cogn
itive](https://en.wikipedia.org/wiki/Cognitive) abilities and [personality](https://en.wikipedia.org/wiki/Personality), 
rather, weak AI is limited to the use of software to study or accomplish specific pre-learned [problem solving](https://
en.wikipedia.org/wiki/Problem_solving) or [reasoning](https://en.wikipedia.org/wiki/Reason) tasks ([expert systems](http
s://en.wikipedia.org/wiki/Expert_systems)).[\[11\]](https://en.wikipedia.org/w/index.php?title=Artificial_general_intell
igence&direction=prev&oldid=1009243150#cite_note-urlPhilosophy_will_be_the_key_that_unlocks_artificial_intelligence_|_Ne
uroscience_|_The_Guardian-11)

As of 2017, over forty organizations are actively researching AGI.[\[12\]](https://en.wik
ipedia.org/w/index.php?title=Artificial_general_intelligence&direction=prev&oldid=1009243150#cite_note-baum-12)

**After
 Enervation's edits: >>>**

An **artificial general intelligence** (**AGI**) is a hypothetical type of [intelligent agen
t](https://en.wikipedia.org/wiki/Intelligent_agent).[\[1\]](https://en.wikipedia.org/wiki/Artificial_general_intelligenc
e#cite_note-NYT-20230630-1) If realized, an AGI could learn to accomplish any intellectual task that [human beings](http
s://en.wikipedia.org/wiki/Human_beings) or animals can perform.[\[2\]](https://en.wikipedia.org/wiki/Artificial_general_
intelligence#cite_note-2)[\[3\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:10-3) Alternat
ively, AGI has been defined as an autonomous system that surpasses human capabilities in the majority of economically va
luable tasks.[\[4\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:1-4) Creating AGI is a pri
mary goal of some [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) research and of compa
nies such as [OpenAI](https://en.wikipedia.org/wiki/OpenAI),[\[4\]](https://en.wikipedia.org/wiki/Artificial_general_int
elligence#cite_note-:1-4) [DeepMind](https://en.wikipedia.org/wiki/DeepMind), and [Anthropic](https://en.wikipedia.org/w
iki/Anthropic). AGI is a common topic in [science fiction](https://en.wikipedia.org/wiki/Science_fiction) and [futures s
tudies](https://en.wikipedia.org/wiki/Futures_studies).

The timeline for AGI development remains a subject of ongoing d
ebate among researchers and experts. Some argue that it may be possible in years or decades; others maintain it might ta
ke a century or longer; and a minority believe it may never be achieved.[\[5\]](https://en.wikipedia.org/wiki/Artificial
_general_intelligence#cite_note-:2-5) Additionally, there is debate regarding whether modern [large language models](htt
ps://en.wikipedia.org/wiki/Large_language_model), such as [GPT-4](https://en.wikipedia.org/wiki/GPT-4), are early yet in
complete forms of AGI[\[6\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:11-6) or if new ap
proaches are required.[\[7\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:3-7)

Contention 
exists over the potential for AGI to pose a threat to humanity;[\[1\]](https://en.wikipedia.org/wiki/Artificial_general_
intelligence#cite_note-NYT-20230630-1) for example, OpenAI treats it as an [existential risk](https://en.wikipedia.org/w
iki/Existential_risk_from_artificial_general_intelligence), while others find the development of AGI to be too remote to
 present a risk.[\[8\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-8)[\[5\]](https://en.wik
ipedia.org/wiki/Artificial_general_intelligence#cite_note-:2-5)[\[7\]](https://en.wikipedia.org/wiki/Artificial_general_
intelligence#cite_note-:3-7)

\------------------------------ end update

My issue with this is why is one organization 
defining what AI is? And so drastically at that. Why isn't there a community of AI scientist and engineer's that are agr
eeing on such a pivotal definition for an agreed upon general consensus?

**Original Post:**

Upon researching why peopl
e are so confused by what is meant by the today's (apparently) lightning rod term 'Artificial General Intelligence' or '
AGI' one would have to look to none other than how OpenAI moved the goal post of what AGI is. Wikipedia: [https://en.wik
ipedia.org/wiki/Artificial\_general\_intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)

\>  A
n **artificial general intelligence** (**AGI**) is a hypothetical type of [intelligent agent](https://en.wikipedia.org/w
iki/Intelligent_agent).[\[1\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-NYT-20230630-1) I
f realized, an AGI could learn to accomplish any intellectual task that [human beings](https://en.wikipedia.org/wiki/Hum
an_beings) or animals can perform.[\[2\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-2)[\[3
\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:10-3) Alternatively, AGI has been defined a
s an autonomous system that surpasses human capabilities in the majority of economically valuable tasks.[\[4\]](https://
en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:1-4) Creating AGI is a primary goal of some [artificial
 intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) research and of companies such as [OpenAI](https:/
/en.wikipedia.org/wiki/OpenAI),[\[4\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:1-4) [De
epMind](https://en.wikipedia.org/wiki/DeepMind), and [Anthropic](https://en.wikipedia.org/wiki/Anthropic). AGI is a comm
on topic in [science fiction](https://en.wikipedia.org/wiki/Science_fiction) and [futures studies](https://en.wikipedia.
org/wiki/Futures_studies).

Odd, who is notation 4? Hmm, who could that be that wrote an update to what the definition o
f what AGI means. Oh it's OpenAI themselves.

4. ['OpenAI Charter'](https://openai.com/charter). *openai.com*. Retrieved
 6 April 2023.

I'm not going to go into a diatribe about how the definition is purely related to Effective Altruism and
 not rooted in technical reality. But I will show you that just a few paragraphs down in the same article they describe 
AGI in a much different way.

\>  Terminology

AGI is also known as strong AI,[\[10\]](https://en.wikipedia.org/wiki/Art
ificial_general_intelligence#cite_note-FOOTNOTEKurzweil2005260-10)[\[11\]](https://en.wikipedia.org/wiki/Artificial_gene
ral_intelligence#cite_note-Kurzweil_2005-08-05-11) full AI,[\[12\]](https://en.wikipedia.org/wiki/Artificial_general_int
elligence#cite_note-12) human-level AI[\[5\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-:2
-5) or general intelligent action.[\[13\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-FOOTN
OTENewellSimon1976-13) However, some academic sources reserve the term 'strong AI' for computer programs that experience
 [sentience](https://en.wikipedia.org/wiki/Sentience) or [consciousness](https://en.wikipedia.org/wiki/Consciousness).[\
[a\]](https://en.wikipedia.org/wiki/Artificial_general_intelligence#cite_note-Searle's_Strong_AI-14) In contrast, weak A
I (or narrow AI) is able to solve one specific problem, but lacks general cognitive abilities.[\[14\]](https://en.wikipe
dia.org/wiki/Artificial_general_intelligence#cite_note-15)[\[11\]](https://en.wikipedia.org/wiki/Artificial_general_inte
lligence#cite_note-Kurzweil_2005-08-05-11) Some academic sources use 'weak AI' to refer more broadly to any programs tha
t neither experience consciousness nor have a mind in the same sense as humans.[\[a\]](https://en.wikipedia.org/wiki/Art
ificial_general_intelligence#cite_note-Searle's_Strong_AI-14)

Related concepts include artificial [superintelligence](h
ttps://en.wikipedia.org/wiki/Superintelligence) and transformative AI. An artificial superintelligence (ASI) is a hypoth
etical type of AGI that is much more generally intelligent than humans.[\[15\]](https://en.wikipedia.org/wiki/Artificial
_general_intelligence#cite_note-16) And the notion of transformative AI relates to AI having a large impact on society, 
for example similar to the agricultural revolution.[\[16\]](https://en.wikipedia.org/wiki/Artificial_general_intelligenc
e#cite_note-17)

It seems as if they wanted to water down and dilute the understanding and meaning of what AGI is for pe
rhaps I don't know contractual obligations?

[https://openai.com/our-structure](https://openai.com/our-structure)

* Fou
rth, profit allocated to investors and employees, including Microsoft, is capped. All residual value created above and b
eyond the cap will be returned to the Nonprofit for the benefit of humanity.
* Fifth, the board determines when we've at
tained AGI. Again, by AGI we mean a highly autonomous system that outperforms humans at most economically valuable work.
 Such a system is excluded from IP licenses and other commercial terms with Microsoft, which only apply to pre-AGI techn
ology.

Interestingly this was reported in many places as much as 6 days ago.

[https://cryptorank.io/news/feed/25bb2-op
enais-board-to-determine-agi](https://cryptorank.io/news/feed/25bb2-openais-board-to-determine-agi)

Point is. How do yo
u get to change the goal post and determine all by yourselves what AGI is? Nah this isn't going to fly. Nice try. I feel
 this verbiage is going to get changed very soon.
```
---

     
 
all -  [ MS CS Profile Evaluation Fall 2024 ](https://www.reddit.com/r/MSCS/comments/1813klg/ms_cs_profile_evaluation_fall_2024/) , 2023-12-03-0911
```
 Academic Profile

· Electronics and Communication + Data Science Minor, CGPA : 9.29 from Tier 1 

· GRE: 169 Q 163V AWA
 3.5,  TOEFL : 119

=======================================

Work & Research Experience

· 1 year at Brown University

·
 4 months at TU Dresden

· Two projects under university professors

=======================================

LORs

3 : 
2 research based, 1 based on course performance

=======================================

Publication

· Co-Authorship i
n paper that got Oral Presentation at ICML

· First author paper at NeurIPS workshop

==================================
=====

Awards

· DAAD Schoalrship

· MITACS Scholarship

=======================================

Universities and class
ification

Ambitious :

* ETH Zurich CS
* Cambridge MLMI
* CMU ML
* UCSD DS

Moderate:

* EPFL DS
* UToronto
* GATech CS

* Imperial ML
* Columbia CS
* Tubingen AI

Safe(?) :

* Uni Edinburgh AI
* UvAmsterdam AI
* UCSD ECE MLDS
* NYU Courant

* Brown
```
---

     
 
all -  [ [D] [NeurIPS] Do I have to buy a ticket to attend? I am a first author of a NeurIPS workshop apper ](https://www.reddit.com/r/MachineLearning/comments/180ant3/d_neurips_do_i_have_to_buy_a_ticket_to_attend_i/) , 2023-12-03-0911
```
I am an undergrad student and I am a first author of a NeurIPS workshop paper accepted this year. Do I have to buy the t
icket for both the main conference and the workshop session to attend? I would like to attend both. Or can I just buy th
e main conference ticket? I am not particularly interested in attending workshop sessions other than for presenting my w
ork
```
---

     
 
all -  [ [D] Complimentary NeurIPS passes for reviewers ](https://www.reddit.com/r/MachineLearning/comments/1805b5m/d_complimentary_neurips_passes_for_reviewers/) , 2023-12-03-0911
```
I received an email today that I can claim a free NeurIPS registration, apparently because of my service as a reviewer. 
Did all reviewers get free passes or is this a lottery system and/or based on review quality? I didn’t plan on attending
, but now I’m actually tempted to go. Wish I’d known earlier, flights are pretty expensive now.
```
---

     
 
all -  [ [D] How to find academic ML competitions ](https://www.reddit.com/r/MachineLearning/comments/17y2r9u/d_how_to_find_academic_ml_competitions/) , 2023-12-03-0911
```
There are websites like this keeping track of ML conference deadlines like this https://aideadlin.es/?sub=ML,CV,CG,NLP,R
O,SP,DM,AP,KR

Are there any such websites keeping track of ML competitions . Specifically competitions as part of ML co
nferences like Neurips, CVPR and so on.
```
---

     
 
all -  [ [R] Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning ](https://www.reddit.com/r/MachineLearning/comments/17x2ovh/r_neural_mmo_20_a_massively_multitask_addition_to/) , 2023-12-03-0911
```
**Paper**: [https://arxiv.org/abs/2311.03736](https://arxiv.org/abs/2311.03736)

**Project page**: [https://neuralmmo.gi
thub.io](https://neuralmmo.github.io)

**GitHub**: [https://github.com/neuralmmo](https://github.com/neuralmmo)

**Abstr
act**:

>Neural MMO 2.0 is a massively multi-agent environment for reinforcement  learning research. The key feature of 
this new version is a flexible  task system that allows users to define a broad range of objectives and  reward signals.
 We challenge researchers to train agents capable of  generalizing to tasks, maps, and opponents never seen during train
ing.  Neural MMO features procedurally generated maps with 128 agents in the  standard setting and support for up to. Ve
rsion 2.0 is a complete  rewrite of its predecessor with three-fold improved performance and  compatibility with CleanRL
. We release the platform as free and  open-source software with comprehensive documentation available at [this http URL
](http://neuralmmo.github.io/)  and an active community Discord. To spark initial research on this new  platform, we are
 concurrently running a competition at NeurIPS 2023.

https://preview.redd.it/8pvecr133t0c1.png?width=901&format=png&aut
o=webp&s=f9bf7f063c1b9950d40ad2a3b04bdc7f0780413f

&#x200B;
```
---

     
 
all -  [ DreamLab Scientific Papers ](https://www.reddit.com/r/Dreamlab/comments/17wyxch/dreamlab_scientific_papers/) , 2023-12-03-0911
```
I have read many posts in this subreddit complaining about the lack of communications and results from DreamLab and the 
teams behind the various projects. I must agree that these two are the most critical issues about DreamLab and the burde
n of solving them shouldn't be given to the users. However I decided to write this post to give a better insight to what
 DreamLab has achieved so far. While the results are far from being as much as those of F@H and BOINC, I think that ther
e are some interesting one. Do note that I do not have a technical background, I do not belong to any scientific team th
at worked on DreamLab projects, I'm just a user as you.

&#x200B;

Also, every paper I am going to link has been retriev
ed through various research on Google Scholar. I do not claim for this to be an exhaustive list, but I tried my best: le
t me know if you find any other paper and I will update the post.

# Imperial College London

**Corona-AI/DRUGS projects
**

* [HyperFoods: Machine intelligent mapping of cancer-beating molecules in foods](https://www.nature.com/articles/s41
598-019-45349-y) (open access) published 03 July 2019 on Nature. This is probably the most important one: it is the most
 read and the most cited one. It explains with detail how the first phase of the Corona project works and shows its resu
lts. I have already seen this one being posted in this subreddit so you have probably already seen it.
* [Learning Inter
pretable Disease Self-Representations for Drug Repositioning](https://grlearning.github.io/papers/79.pdf) (open access) 
published approx. September 2019 on NeurIPS 2019 Workshop 'Graph Representation Learning'. This paper has another versio
n on arXiv (pre-print) but hasn't been published in any scientific journal. It looks like it is about the mathematic beh
ind the projects.
* [Auto-deconvolution and molecular networking of gas chromatography–mass spectrometry data](https://w
ww.nature.com/articles/s41587-020-0700-3) (not open access) published 09 November 2020 on Nature. A pre-print version of
 the paper can be read [here](https://www.biorxiv.org/content/10.1101/2020.01.13.905091v1.abstract).
* [Network machine 
learning maps phytochemically rich “Hyperfoods” to fight COVID-19](https://link.springer.com/article/10.1186/s40246-020-
00297-x) (open access) published 02 January 2021 on Human Genomics. Another paper about Hyperfoods, more related on COVI
D and not on cancer.
* [Predicting anticancer hyperfoods with graph convolutional networks](https://humgenomics.biomedce
ntral.com/articles/10.1186/s40246-021-00333-4) (open access) published 07 June 2021 on Human Genomics. Focused on the ma
thematical aspects behind the projects, there is also an interesting list of  anticancer likeness of food molecules.
* [
Alzheimer’s disease: using gene/protein network machine learning for molecule discovery in olive oil](https://link.sprin
ger.com/article/10.1186/s40246-023-00503-6) (open access) published 07 July 2023 on Human Genomics. I do not remember if
 Alzheimer's disease was on the list of research area on the old DRUGS projects, maybe some older users knows more than 
me. However the methodology is most likely the same. There is an interesting list of molecules present in olive oil that
 could have benefits for the disease. The paper is limited by the fact that there are very few drugs on trial for this d
isease.
* [Genomic‑driven  nutritional interventions  for radiotherapy‑resistant rectal  cancer patient](https://www.nat
ure.com/articles/s41598-023-41833-8) (open access) published 08 September 2023 on Nature. Again I do not remember if the
 DRUGS project studied this particular disease, please let me know if anyone remember.
* [Crosstalk with lung fibroblast
s shapes the growth and therapeutic response of mesothelioma cells](https://www.nature.com/articles/s41419-023-06240-x) 
(open access) published 08 November 2023 on Nature. Again as the one before.

I expect for other papers to be published 
in the future.

BONUS: Cookbook, based on CORONA-AI phase 1 results and the first paper linked.

* [English version](htt
ps://assets.ctfassets.net/q7ob9vms4z5k/1PoCOqtYr7QPuXdAYV4fr6/499490b29ef6569253dff60fcab697d7/Vodafone_DreamLab_Antivir
al_Foods_Cookbook.pdf)
* [Italian version](https://www.vodafone.it/nw/content/dam/webaem/vodafone-italia/fondazione_voda
fone/attivita/progetti/dreamlab/Pillow_recipes_Il_libro_delle_ricette_DreamLab.pdf)

**Long COVID**

There are no paper 
yet about this project as it is still going. I'll keep the post updated.

&#x200B;

**Tropical Cyclone Modelling**

Ther
e are no paper yet about this project, however the first scientific results can be seen at [G-SRAT](https://global.infra
structureresilience.org/view/hazard?y=null&x=null&z=null&sections=%7B%22hazards%22%3A%7B%22cyclone_iris%22%3Atrue%7D%7D)
 and [OS-C](https://physrisk-ui-sandbox.apps.odh-cl1.apps.os-climate.org/) (under wind hazard). On the first there is wr
itten 'Manuscript submitted for publication', so I expect that at least one paper will be published in the next months. 
I will keep you updated.

&#x200B;

# Garvan Institute

* [The Dream Lab](https://www.thelancet.com/journals/lanonc/arti
cle/PIIS1470-2045(16)00033-4/fulltext) (not open access) published approx. February 2016 on The Lancet Oncology. This ve
ry short paper is the first time DreamLab is mentioned in a scientific journal. While it doesn't talk about any scientif
ic result, it is useful to track the story of DreamLab, since retrieving information prior to 2019 is a bit difficult.
*
 [Network-aware mutation clustering  of cancer](https://www.biorxiv.org/content/10.1101/432872v1.full.pdf) (open access)
 posted 08 October 2018 on bioRxiv. This is all I could find about Project Decode. Do note that this is just a pre-print
 version and hasn't been peer-reviewed or published on a scientific journal. I have no information on why there is only 
a pre-print, and the last news published on the Institute's website about DreamLab is [this one](https://www.garvan.org.
au/news-resources/news/dreamlab-delivers-a-new-way-to-make-sense-of-cancer) from 2018. I couldn't find anything about De
mistify project that ended some time ago. If anyone has more info let me know.

# AIRC

I couldn't find any paper relate
d to DreamLab, however Cell Identity Hunter phase 2 is still going. The team behind the projects is still active, and th
e last news (at least on the italian version of the app) is from 25 May 2023. AIRC is one of the biggest for cancer reas
erch in Italy, so I expect for something to be published in the future (possibly after 2024). I'll keep you updated.

&#
x200B;

Please notice that my research was definetely more focused on the DRUGS/CORONA-AI projects, so the results are d
efinetely biased. The fact that I couldn't find anything for the other projects doesn't necessarily mean that nothing ha
s been published yet, so don't be frustrated about it.

&#x200B;

posted 16/11/2023

update 19/11/2023: fixed link for a
 paper, added 'The Dream Lab' paper, other additions.
```
---

     
 
all -  [ Adding Noise to observations Space in RL ](https://www.reddit.com/r/reinforcementlearning/comments/17wtqye/adding_noise_to_observations_space_in_rl/) , 2023-12-03-0911
```
I'm currently in the process of building a feature selection framework for reinforcement learning.

A. Here some previou
s works that I have seen :

1. [https://link.springer.com/chapter/10.1007/978-3-642-15880-3\_36](https://link.springer.c
om/chapter/10.1007/978-3-642-15880-3_36)
2. [https://ieeexplore.ieee.org/document/5381529](https://ieeexplore.ieee.org/d
ocument/5381529)
3. [https://ieeexplore.ieee.org/document/4543621](https://ieeexplore.ieee.org/document/4543621)
4. [htt
ps://www.researchgate.net/publication/221346040\_An\_analysis\_of\_linear\_models\_linear\_value-function\_approximation
\_and\_feature\_selection\_for\_reinforcement\_learning](https://www.researchgate.net/publication/221346040_An_analysis_
of_linear_models_linear_value-function_approximation_and_feature_selection_for_reinforcement_learning)
5. [https://www.r
esearchgate.net/publication/221345743\_Automatic\_basis\_function\_construction\_for\_approximate\_dynamic\_programming\
_and\_reinforcement\_learning](https://www.researchgate.net/publication/221345743_Automatic_basis_function_construction_
for_approximate_dynamic_programming_and_reinforcement_learning)
6. [https://dl.acm.org/doi/10.1145/1273496.1273589](http
s://dl.acm.org/doi/10.1145/1273496.1273589)

B. Context :

\--> I am experimenting with the non-continuous lunar lander 
environment using gym library. And I want to add two additional features that are introduced as random noise, incrementi
ng the observation space  to (8 + 2 ) = 10. I will then train my lunar lander using PPO algorithm, and use my feature se
lection framework to rank them and select the original 8 features, i.e excluding noise. (2 features.)

C. What do I need
 help with ?

\--> How should I be adding the noise ? Meaning what type of noise should be ideal for this ? I'm new to  
RL, and hence still learning.

D. What I have seen so far  on my own:

\--> After scouring some google searches on ' how
 to introduce noise in RL' lead me to other reddit posts, medium articles. I found that these lead me to the following t
opics :

1. Out-of-Distribution Detection in RL, Ex paper : [https://arxiv.org/abs/2004.14990](https://arxiv.org/abs/200
4.14990), [https://arxiv.org/pdf/2112.02694.pdf](https://arxiv.org/pdf/2112.02694.pdf), [https://arxiv.org/abs/1210.4898
](https://arxiv.org/abs/1210.4898),
2. Introducing Noise for Exploration : [https://h2t.iar.kit.edu/pdf/Plappert2018.pdf
](https://h2t.iar.kit.edu/pdf/Plappert2018.pdf), [https://proceedings.neurips.cc/paper/2016/file/8d8818c8e140c64c743113f
563cf750f-Paper.pdf](https://proceedings.neurips.cc/paper/2016/file/8d8818c8e140c64c743113f563cf750f-Paper.pdf), [https:
//arxiv.org/pdf/1706.10295.pdf](https://arxiv.org/pdf/1706.10295.pdf).

Some additional questions :

1. While searching 
for  'How to add NOISE in RL' opened me up to a whole new world of types of NOISE. My goal is to : a. add noise in my ob
servation space, b. possibly add a type of noise replicating real-world noise. (Most common ones I see are talking about
 Gaussian noise).
2. My feature selection framework accounts for implicit-state-reward dependency, similar to section A 
paper 1 linked above. The GOAL of my research is build algorithms to improve ROBUSTNESS, AND SAFETY for applicatIons usi
ng RL. Hence, building a custom feature selection framework is one of the first step towards it. PLEASE feel free to lin
k other open challenges in real-world RL applications, so I have the opportunity to address and work on them in my futur
e works.

THANK YOU !
```
---

     
 
all -  [ Profile Evaluation for PhD in CS ](https://www.reddit.com/r/gradadmissions/comments/17wgcx4/profile_evaluation_for_phd_in_cs/) , 2023-12-03-0911
```
Hey guys,

Im looking for a profile evaluation, and suggestions. I applied to PhD programs last cycle and was accepted t
o 2, which I turned down. Im applying this cycle again. My profile is pretty similar and so are my recommendations, so I
m not sure if I should have high hopes. Currently 3.8 GPA MS in CS student at a top 30 US University (by CS rankings for
 AI). 2 publications in robotics (IROS), 1 in NeurIPS this year (but I'm the 4th author), and 1 first author work under 
review at ICLR, one under review at  AAAI. 2 pretty strong recommendations, one from a faculty whose course I took and T
A'd for.

Im planning on applying to:
MILA, UNC Chapel Hill, CMU, NYU, USC, SFU, UCR, Virgina Tech, University of Washin
gton. 

One drawback of my profile is that I was enrolled as a PhD at my current uni, and didn't like the topic and didn
t find a good fit. So I've decided to apply elsewhere (finishing up as a MS at my current uni), but I think this negativ
ely impacts my applications because I thought I had a good profile but didn't get any interviews last year. Let me know 
what you think
```
---

     
 
all -  [ Suggestions for Safe Universities for My Profile ](https://www.reddit.com/r/MSCS/comments/17uxmad/suggestions_for_safe_universities_for_my_profile/) , 2023-12-03-0911
```
 

Institution: Tier-3 college from India

CGPA: 9.46

TOEFL: 100

Internships: 2 (one research and another one at an MN
C)

Papers: 2 original research papers (Springer), one review paper (Springer), and one NeurIPS workshop paper. The pape
rs have been accepted but are yet to be published

Current shortlisted universities:

* UIUC
* UMCP
* UCSD
* UCLA
* UT A
ustin
* Purdue
* UMass
* ASU

**Kindly suggest some safe universities for my profile where the GRE is not required.**
```
---

     
 
all -  [ [D] Which option — trying to publish papers in top conferences individually or expanding knowledge i ](https://www.reddit.com/r/MachineLearning/comments/17ur25g/d_which_option_trying_to_publish_papers_in_top/) , 2023-12-03-0911
```
I recently began my career as a Machine Learning Engineer, marking my first job in the industry. A few months ago, I com
pleted an MPhil program specializing in Environmental Engineering, with a research focus on applying ML in that field. T
hroughout my job search, I frequently encounter questions about my academic background. Additionally, utilizing ML techn
ologies has become increasingly convenient with the availability of user-friendly APIs.

&#x200B;

To enhance my competi
tiveness in the industry, I am looking to take proactive steps. I have been actively staying updated on ML technologies 
and trends, and now I am considering the following options:

1. As an independent researcher, try to publish papers in t
op conferences in the field like CVPR and NeurIPS.

2. Expand my knowledge in data engineering and MLops and work on end
-to-end personal projects.

&#x200B;

I understand that both of these options require a significant investment of time a
nd energy. Therefore, I wonder which option would be more worthwhile in terms of my time and effort. It is important to 
note that I am interested in working in the industry and do not intend to pursue a career in academia.
```
---

     
 
all -  [ NanoGptDotnet: An advanced Large Language Model written in C# that generates shakespeare like text.  ](https://www.reddit.com/r/dotnet/comments/17skv0e/nanogptdotnet_an_advanced_large_language_model/) , 2023-12-03-0911
```
If anyone is interested in learning AI/LLM's and you’re more familiar with dotnet than python, take a look at my [NanoGp
tDotnet](https://github.com/biegehydra/NanoGptDotnet) project. It is a direct translation of a [project](https://github.
com/karpathy/ng-video-lecture) by Andrej Karpathy, a leading expert in deep learning and LLM's. His project was written 
while recording the youtube video: [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?
v=kCc8FmEb1nY) The design used in the better model, NanoGpt in my project, is based off the breakthrough [Attention Is A
ll You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) arti
cle.

The project is meant to be a learning aid for you to learn about LLM's. I added a lot of the comments from Andrej 
Karpathy, some of my own comments, some from GPT-4, and timestamps to relevant sections of the youtube video. The projec
t uses TorchSharp (from the dotnet team) which uses the same naming conventions as python so the knowledge you gain from
 my project is very translatable to python. I also tried to never use the var keyword so you can have a better idea of w
hat's going on.

The NanoGpt project is only 600 lines of code, most of which are whitespace and comments, so don't hesi
tate to give it a look and let me know what you think!

## Example Output

    ICHARD III:
    But look on my father's f
ault, but not most good.
    
    QUEEN ELIZABETH:
    Nor cheer will I thee speak; but thou hast a word, till now.
    

    KING RICHARD III:
    Then, good kind her heart; the devil
    But calls me sometimes of blood for yourselves.
    
What service must I do? Or else thou art moved at
    Her princess, having entleman of fair princely
    Which I have po
wer to dispose offender:
    If I cannot discharge him, but action
    That now respected, whatsoever more, title,
    C
onstants to the world's name; and if not they see
    The truth, crying but his within the fairest cover:
    If the wis
e burning fools that they lose
    The feedering steel gaoler them in sex the clouds,
    You must have pair'd for suffe
rance.
    
    COMINIUS:
    No remedy;
    That they have dropp'd from war upon you.
    
    MENENIUS:
    The gods k
eep you on!
    There's no more!
    
    CORIOLANUS:
    No, ay, but to good with them all. You, the first
    No grave
 for my poor general than you,--
    Whether for the poor good star!
    
    VOLUMNIA:
    Not that you should not leav
e about the ship,--
    Which you save every word of your eyes that,--
    Being suffer'd with the sweets, I do notthing

    Make the oseemable of strength, your enemy
    Is that ever goad to be so,--think my meaning,
    Nothing by that h
imself so shall not share
    Above again him, which owe have little,
    Not raged to know the cheek to the purpose,
  
  Not summer showing: post it, sir, increaseth,
    That cames to practise one would move you do,
    But by that you ne
ed not, my lord.
    
    MARCIUS:
    Be not according:
    The young Rome are sent forth, more strength on you,
    Bu
t queen overta'en.
```
---

     
 
all -  [ [D] Machine Learning PhD failure? Navigating the harsh reality of graduating without publications ](https://www.reddit.com/r/MachineLearning/comments/17skp7j/d_machine_learning_phd_failure_navigating_the/) , 2023-12-03-0911
```
Hi ML community, 

I'm nearing the end of my three-year PhD journey. Throughout this period, I've dedicated myself to pr
oducing a research paper annually, targeting top-tier conferences like ICML, ICLR, and NeurIPS. Despite my efforts and r
esubmissions, none of my papers made it through. As a result, my publication record consists solely of three manuscripts
 on arXiv.

My initial post-PhD ambition was to delve deeper into machine learning research at leading tech companies su
ch as Facebook, Google, or Microsoft. However, my applications were turned down, primarily due to the lack of publicatio
ns in prestigious conferences, which seems to be a crucial criterion for these roles.

Confronted with this setback and 
the pressing need to manage my finances, I shifted my focus to more traditional industry roles in consulting and finance
. I've recently secured a position in quant finance, which, while exciting, means I won't have the bandwidth to revisit 
and resubmit my research papers.

Reflecting on this journey, I sometimes feel disheartened, questioning the value of my
 PhD experience, especially when I consider my lack of published work in major machine learning conferences.

I see othe
r PhD students in my field publish 2 papers per year in these top conferences which makes me wonder whether I am a failu
re? I'm open to any thoughts or advice on my situation.
```
---

     
 
all -  [ [D] Is there a limit to the number of papers we can submit to NeurIPS? ](https://www.reddit.com/r/MachineLearning/comments/17s8ade/d_is_there_a_limit_to_the_number_of_papers_we_can/) , 2023-12-03-0911
```
I am asking for a friend.
```
---

     
 
all -  [ Neurio - Still a viable Home Energy Monitoring Solution! ](https://www.reddit.com/r/homeassistant/comments/17ryzw6/neurio_still_a_viable_home_energy_monitoring/) , 2023-12-03-0911
```
I've had the Neurio Home Energy Monitor (USA, Split Phase) for many, many years. Since they first came to the market, I 
was an early adapter. 
And it's been **rock solid**.

I just ordered another one for my cabin. (New in box from eBay, ab
out $60 after shipping (I set up scheduled alert, and low-balled a best offer)
I had it up and running in minutes. (Conn
ected to WiFi, registered to my existing cloud account, API enabled, and integrated in Home Assistant). 

Despite being 
vaporware and sold off to Generac and later abandoned, the API lives on,and the Home Assistant integration keeps working
. 
AND EVEN IF THEY DO KILL THE API (Aka, 'The MyQ treatment'), THERE IS STILL LOCAL ACCESS. (Which I don't use, YET)

*
*Existing Home Assistant integration:**  
https://www.home-assistant.io/integrations/neurio_energy  
Two sensors will be
 created with the following names:   
* Energy Usage: Current active power usage in Watts. Updated every 10 seconds.   

* Daily Energy Usage: Daily power usage in kWh. Updated every 2.5 minutes.   

Polls via the cloud API (Which is still a
ctive!)  
https://api-docs.neur.io/#overview   

   
**Local Sensor Access:**  
JSON via IP:  
Example:   
http://192.16
8.1.xxxx/current-sample   
https://api-docs.neur.io/#sensor-local-access   
And in case the cloud doc ever goes missing,
 I've cloned it here: https://pastebin.com/raw/7YUCSzCe
   

Food for thought for those looking for an energy monitoring
 solution, but don't want to shell out a lot of money. 
I was about to pull the trigger on the 'DIY-ish' methods, but af
ter getting the board, CT sensors, etc, it will still going to cost at least $100. On top of that, forums are full of pe
ople struggling to set them up, calibrate them properly, etc.  I wasn't up for the task. I wanted a turn-key solution re
ady out of the box.

https://imgur.com/oBA0txf
```
---

     
 
all -  [ Quant research of the Week (2nd Edition) ](https://www.reddit.com/r/quant/comments/17qms5i/quant_research_of_the_week_2nd_edition/) , 2023-12-03-0911
```
# ArXiv

## Finance

[**Maximizing Portfolio Predictability with Machine Learning: Portfolio Predictability Maximization
 using ML**](https://arxiv.org/abs/2311.01985):  A stock portfolio called the maximally predictable portfolio (MPP),  cr
eated using machine learning and a Kelly criterion strategy,  consistently performs better than the benchmark. (2023-11-
03, shares: 5)

[**Arbitrage Opportunities in Mean Field System**](https://arxiv.org/abs/2311.02690):  The article prese
nts a theoretical model to analyze arbitrage  opportunities in a market with unlimited investors, confirming the  existe
nce of a unique mean field equilibrium. (2023-11-05, shares: 3)

[**Transfer Risk and Finance Applications**](https://ar
xiv.org/abs/2311.03283):  The paper discusses the concept of transfer risk in transfer learning,  showing its significan
t relation with performance and its effectiveness  in selecting suitable source tasks in stock return prediction and  po
rtfolio optimization. (2023-11-06, shares: 2)

[**Power Law in Sandwiched Volterra Volatility Model: Power Law in Volter
ra Volatility Model**](https://arxiv.org/abs/2311.01228):  The Sandwiched Volterra Volatility (SVV) model accurately rep
roduces  the power-law behavior of the at-the-money implied volatility skew,  provided the correct Volterra kernel is ch
osen. (2023-11-02, shares: 4)

[**Optimal Stopping Problem with Discontinuous Reward**](http://dx.doi.org/10.13140/rg.2.
2.36565.40160):  The study investigates the optimal stopping issue in pricing a variable  annuity contract, introducing 
new valuation algorithms and showing how  fee and surrender charge functions affect early and optimal surrender  boundar
ies. (2023-11-06, shares: 2)

[**Joint Model for Longitudinal and Spatio-Temporal Survival Data: Longitudinal and Spatio
-Temporal Survival Model**](https://arxiv.org/abs/2311.04008):  The Spatio-Temporal Joint Model (STJM) is a new method f
or credit risk  analysis that uses spatial and temporal data to predict a borrower's  risk, showing better results when 
spatial data is included. (2023-11-07,  shares: 7)

## Miscellaneous

[**Finding Fraud Prevention Rules**](https://arxiv
.org/abs/2311.00964):  The paper introduces PORS, a heuristic-based framework for finding  high-quality rule subsets in 
fraud prevention, and SpectralRules, a new  sequential covering algorithm, showcasing their effectiveness in two  real A
lipay scenarios. (2023-11-02, shares: 4)

[**Asset Price Bubbles: Nonstationary Phenomenon**](https://arxiv.org/abs/2311
.03638):  The article discusses the theory of rational asset price bubbles,  highlighting that bubbles linked to real as
sets like stocks and housing  are nonstationary phenomena tied to unbalanced growth. (2023-11-07,  shares: 4)

[**Decent
ralization in Blockchain Governance and DeFi Efficiency**](https://arxiv.org/abs/2311.02434):  The article studies how d
ecentralization in blockchain-based governance  affects the financial efficiency of Decentralized Autonomous  Organizati
ons (DAOs). It uses the Gini coefficient to measure inequality  among token owners and discusses the pros and cons of th
is method.  (2023-11-04, shares: 4)

## Historical Trending

[**Deep Learning for Volatility Calibration**](https://arxi
v.org/abs/2201.07880):  The paper presents a new algorithm that uses deep self-consistent  learning for better and more 
robust calibration of local volatility from  market option prices. (2021-12-09, shares: 15)

[**Wage-Setting and Behavio
ral Firms**](https://arxiv.org/abs/2206.01114):  The study suggests that companies that set salaries at round numbers,  
typically less sophisticated firms, tend to perform worse in the market  due to their coarse wage-setting approach. (202
2-06-02, shares: 125)

[**Pragmatic Energy Markets**](https://arxiv.org/abs/2305.01485):  The article offers a guide on 
using the Heath-Jarrow-Morton framework  in energy markets, specifically in European power and gas markets,  covering ma
rket structure, model calibration, simulations, and  derivatives pricing. (2023-05-02, shares: 56)

[**Multimodal Bankru
ptcy Prediction**](https://arxiv.org/abs/2211.08405):  The research presents multimodal learning in bankruptcy predictio
n  models to tackle the problem of missing MDA section in Form 10-K,  showing improved classification performance and ad
dressing the  limitation of previous models. (2022-10-26, shares: 33)

[**Liquidation with High Risk Aversion**](https:/
/arxiv.org/abs/2301.01555):  The research investigates the Bachelier model with linear price impact,  identifying a set 
of portfolios that are optimally effective in a  scenario of diminishing price impact. (2023-01-04, shares: 10)

&#x200B
;

# SSRN

### Recently Published

## Financial

[**Concave Price Impact Trading**](https://papers.ssrn.com/sol3/papers.
cfm?abstract_id=4625040):  The research examines statistical arbitrage issues, taking into account  the nonlinear and te
mporary price impact of metaorders, and shows that  simple trading rules can be established even with nonparametric alph
a  and liquidity signals. (2023-11-06, shares: 120.0)

[**Volatility Disagreement Trading**](https://papers.ssrn.com/sol
3/papers.cfm?abstract_id=4624158):  A model is created to understand how investors' disagreement on future  volatility a
ffects their trading of volatility derivatives, showing that  trading decreases in more volatile periods and the varianc
e risk  premium can become positive when future volatility is underestimated.  (2023-11-06, shares: 3.0)

[**Global Macr
o and Managed Futures Hedge Fund Strategies**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4625978):  The resear
ch evaluates the performance of hedge funds, especially those  using a top-down investment approach, and discovers a sig
nificant drop  in risk-adjusted alpha for global macro managers and managed futures  managers after the global financial
 crisis. (2023-11-07, shares: 8.0)

[**Market Volatility and Trend Factor**](https://papers.ssrn.com/sol3/papers.cfm?abs
tract_id=4621388):  The paper explores the link between stock market volatility and trend  factor profits, finding that 
the trend factor performs better after high  volatility periods as investors depend more on trend signals.  (2023-11-02,
 shares: 3.0)

[**The Halo Effect in ESG Investing in Indian Equities**](https://papers.ssrn.com/sol3/papers.cfm?abstrac
t_id=4624179):  A study of 700 Indian companies shows no significant link between ESG  scores and investment returns fro
m 2013 to 2023. (2023-11-06, shares:  10.0)

[**The Kelly Criterion in Stock Investment**](https://papers.ssrn.com/sol3/
papers.cfm?abstract_id=4625295):  A paper suggests using the Kelly criterion and Monte Carlo simulation  to estimate the
 optimal portfolio in stock investment. (2023-11-07,  shares: 7.0)

[**Strategic Investors and Exchange Rate Dynamics**]
(https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4621461):  A study shows that exchange rate dynamics are affected b
y the diversity  of investors and their price impact, with more concentrated markets  having a stronger price impact. (2
023-11-02, shares: 3.0)

## Quantitative

[**Leverage Effect and Volatility of Volatility Estimation**](https://papers.s
srn.com/sol3/papers.cfm?abstract_id=4625351):  The article presents new methods for estimating leverage effect and  vola
tility using high frequency data, tested through simulation and real  data analysis. (2023-11-07, shares: 3.0)

[**Machi
ne Learning for Insolvency Prediction in Insurance**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4626405):  A n
ew machine learning algorithm, SANN, is used to predict insurance  company insolvency, showing better accuracy than trad
itional models.  (2023-11-08, shares: 3.0)

[**Investor Risk Appetite and High-Beta Stock Valuation Analysis**](https://
papers.ssrn.com/sol3/papers.cfm?abstract_id=4623331):  The study reveals a pattern in high-beta stock returns around  ma
croeconomic announcements, indicating that investor risk appetite  significantly influences these returns. (2023-11-04, 
shares: 3.0)  

[**Sector Portfolio HRP: Performance and Risk Metrics**](https://papers.ssrn.com/sol3/papers.cfm?abstrac
t_id=4623991):  A diversified portfolio strategy, Sector Portfolio HRP, outperforms the  MSCI All Country World Index in
 annualized return and risk evaluation  from 1996 to 2022, a study shows. (2023-11-03, shares: 4.0)

[**Identifying Domi
nance Regimes in the Euro Area with Machine Learning**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4622203):  M
achine learning has identified periods of fiscal dominance in the euro  area from 2000 to 2019, including during the fin
ancial and sovereign  debt crises. (2023-11-03, shares: 2.0)

[**Corporate Culture and Takeover Vulnerability**](https:/
/papers.ssrn.com/sol3/papers.cfm?abstract_id=4626185):  Research using machine learning indicates that the threat of hos
tile  takeovers can significantly weaken a company's culture, supporting the  managerial myopia hypothesis. (2023-11-07,
 shares: 3.0)

&#x200B;

### Recently Updated

## Quantitative

[**Bayesian Data Imputation: Missing Data Filling**](htt
ps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4625229):  The article highlights the role of data imputation in risk m
anagement,  explaining its use in filling gaps in incomplete data for a better  understanding of risk factors. (2023-06-
28, shares: 189.0)

[**Machine Learning Execution Time in Asset Pricing**](https://papers.ssrn.com/sol3/papers.cfm?abstr
act_id=4623947):  The research analyzes the execution time of machine learning models in  empirical asset pricing, findi
ng that XGBoost is the fastest and most  accurate, and that reducing features and time observations can  significantly c
ut execution time. (2023-10-31, shares: 2.0)

[**Interactions in Asset Pricing: Predictors & Returns**](https://papers.s
srn.com/sol3/papers.cfm?abstract_id=4624629):  The research suggests that future stock returns can be predicted using  m
achine learning models that consider characteristics and macroeconomic  variables, resulting in portfolios that perform 
better than benchmarks.  (2023-07-17, shares: 494.0)

[**Corporate Bonds: Momentum Spillovers**](https://papers.ssrn.com
/sol3/papers.cfm?abstract_id=4622610):  The article uncovers momentum spillovers in the corporate bond market,  proposin
g a strategy of buying bonds from high-performing peers and  selling bonds from low-performing peers, yielding a monthly
 alpha of 36  basis points. (2023-09-25, shares: 2.0)

[**Alternate Approach: Regression Parameter Estimation**](https:/
/papers.ssrn.com/sol3/papers.cfm?abstract_id=4621745):  The article presents a new NAS method for univariate regression 
 problems, comparing it with standard methods and suggesting a  generalized approach for calculating the cost function's
 partial  derivatives. (2023-09-01, shares: 2.0)

## Financial

[**Efficient Simulation for Derivative Pricing**](https:
//papers.ssrn.com/sol3/papers.cfm?abstract_id=4625397):  The article introduces a new simulation-based method for pricin
g and  managing risk of financial derivatives during rare events, proving to be  more efficient, accurate, and flexible 
than traditional methods.  (2022-06-08, shares: 85.0)

[**Commodity Sectors and Factor Strategies**](https://papers.ssrn
.com/sol3/papers.cfm?abstract_id=4622974):  The study explores the impact of commodity sectors on commodity futures  ris
k premiums, revealing that excluding the precious metal sector from a  portfolio increases the Sharpe ratio, suggesting 
precious metals' role  as hedging tools affects commodity performance. (2023-10-13, shares:  3.0)

[**Optimal Valuation 
Ratio: Forward Price Ratios**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4625138):  The research criticizes th
e use of trailing price ratios for predicting  stock market returns due to changes in cash flow growth, suggesting the  
use of forward price ratios scaled by cash flow forecasts for better  valuation. (2022-12-02, shares: 2.0)

[**CDS Theor
y and Practice**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4624435):  The paper examines Quanto Credit Defaul
t Swaps, a financial tool that  transfers credit risk with foreign exchange exposure, focusing on its  theory, pricing, 
and use in emerging markets like Brazil. (2023-09-15,  shares: 75.0)

[**Volatility Timing with ETF Options**](https://p
apers.ssrn.com/sol3/papers.cfm?abstract_id=4625085):  The study finds that hedge funds' positions in ETF options predict
  volatility in underlying ETF returns, particularly in nonequity ETFs  like fixed income and currency ETFs. (2022-10-19
, shares: 2.0)

[**ETF Closures: Do Nothing?**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4620553):  The resea
rch indicates that ETFs often close after positive returns and  flows, with these factors predicting closure decisions, 
and smaller  ETFs earning higher daily returns than larger ones with the same  investment objective. (2023-01-23, shares
: 60.0)

[**Volatility Transformers: Arbitrage-Free Volatility Surfaces**](https://papers.ssrn.com/sol3/papers.cfm?abstr
act_id=4623940):  The paper presents a framework for creating arbitrage-free  transformations of an implied volatility s
urface using optimal transport  maps, which can be applied to a broader range of synthetic market data  generation appli
cations. (2023-09-05, shares: 2.0)

[**Common Ownership of Stocks & the Low Volatility Anomaly**](https://papers.ssrn.co
m/sol3/papers.cfm?abstract_id=4626091):  The study shows that the low volatility anomaly in stock prices is  connected t
o mutual funds performance evaluation against benchmark  indexes, as mutual fund managers' heavy investment in certain s
tocks  leads to higher trade volumes and lower volatility. (2023-04-11, shares:  2.0)

&#x200B;

# ArXiv ML

## Recently
 Published

[**IGN**](https://arxiv.org/abs/2311.01462):  A new generative modeling method is suggested, using an idempo
tent  neural network to project any input into a target data distribution.  (2023-11-02, shares: 157)

[**TMKWF**](https
://arxiv.org/abs/2311.01434):  A novel data augmentation technique is proposed that adjusts the  distribution of interpo
lation coefficients based on data point  similarity, enhancing model performance and calibration. (2023-11-02,  shares: 
11)

[**CM: UHL**](https://arxiv.org/abs/2311.01435):  A new algorithm is introduced that can learn high-dimensional  ha
lfspaces in d-dimensional space in polynomial time, without needing  labels. (2023-11-02, shares: 11)

[**T A PTMF**](ht
tps://arxiv.org/abs/2311.01449):  TopicGPT, a new framework, is introduced that uses large language  models to identify 
latent topics in a text collection, providing more  interpretable topics and user control. (2023-11-02, shares: 9)

[**U
niO4: Unifying RL**](https://arxiv.org/abs/2311.03351):  Uni-o4 is a novel method that merges offline and online reinfor
cement  learning, enhancing the adaptability of the learning process.  (2023-11-06, shares: 5)

[**Reproducible Paramete
r Inference**](https://arxiv.org/abs/2311.02019):  The BayesBag study introduces a technique of applying bagging to  Bay
esian posteriors to enhance reproducibility and uncertainty  quantification in model misspecification. (2023-11-03, shar
es: 5)

[**PPI: Efficient Inference**](https://arxiv.org/abs/2311.01453):  PPI++ is a new approach that utilizes a small
 labeled dataset and a  larger machine-learning predictions dataset to boost computational and  statistical efficiency. 
(2023-11-02, shares: 5)

&#x200B;

# RePec

## Finance

[**High-Frequency Alternative Data for GDP Nowcasts**](https://e
conpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Flink.springer.com%2F10.1007%2Fs41549-023-00085-1;h=repec:spr:jbuscr:
v:19:y:2023:i:2:d:10.1007_s41549-023-00085-1):  The study uses credit card data to enhance real-time GDP forecasting in 
 Japan, demonstrating that this data improves early-stage forecasting by  accurately capturing consumer spending. (2023-
11-08, shares: 15.0)

[**Performance of U.S. ESG ETFs**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fw
ww.mfa.com.my%2Fwp-content%2Fuploads%2F2023%2F09%2Fv31_i2_a5_pg89-101.pdf;h=repec:mfa:journl:v:31:y:2023:i:2:p:89-101): 
 The paper analyzes the performance of ESG equity ETFs in the U.S. from  2019 to 2021, revealing that these ETFs, on ave
rage, outperform the  S&P 500 Index. (2023-11-08, shares: 15.0)

[**High-Dimensional Portfolio Optimization with Factor 
Model**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2F
S0927538X23001774;h=repec:eee:pacfin:v:81:y:2023:i:c:s0927538x23001774):  The article proposes a new portfolio optimizat
ion method using a  tree-structured portfolio sorting technique, demonstrating that this  strategy outperforms others in
 terms of Sharpe ratios, standard  deviation, and turnover. (2023-11-08, shares: 15.0)

[**Time-Variation in Effects on 
Portfolio Flows**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticl
e%2Fpii%2FS0165188923001628;h=repec:eee:dyncon:v:156:y:2023:i:c:s0165188923001628):  The research examines the relative 
significance of push and pull  factors for portfolio flows during financial crises, finding that the  importance of push
 factors has increased over time, especially for EU  countries. (2023-11-08, shares: 14.0)

[**Dynamic Bond Portfolio Op
timization with Stochastic Interest Rate Model**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Flink.spri
nger.com%2F10.1007%2Fs10690-023-09401-2;h=repec:kap:apfinm:v:30:y:2023:i:4:d:10.1007_s10690-023-09401-2):  The paper pro
poses a new framework for dynamic bond portfolio  optimization over multiple periods, which outperforms single-period  o
ptimization. (2023-11-08, shares: 26.0)

[**Multiperiod Portfolio Allocation with Volatility Clustering and Non-Normalit
ies**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS1
062940823001201;h=repec:eee:ecofin:v:68:y:2023:i:c:s1062940823001201):  The study finds that considering volatility clus
tering in dynamic  multiperiod portfolio choices reduces the need for hedging. (2023-11-08,  shares: 23.0)

[**Managed E
TFs: Performance Evaluation**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fwww.mfa.com.my%2Fwp-content
%2Fuploads%2F2022%2F10%2Fv30_i2_a3_pg39-61.pdf;h=repec:mfa:journl:v:30:y:2022:i:2:p:39-61):  A study found that actively
 managed ETFs in the US from 2018 to 2021  did not yield significant above-market returns and their managers lacked  sup
erior market timing skills. (2022-07-09, shares: 18.0)

## Statistical

[**Gender Diversity Prediction in Boardrooms wit
h ML**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS
0275531923001794;h=repec:eee:riibaf:v:66:y:2023:i:c:s0275531923001794):  A study uses machine learning to forecast gende
r diversity in Chinese  company boards, with the extreme Gradient Boosting model showing the  best performance. (2023-11
-08, shares: 22.0)

[**Bond Excess Returns Explanation with AI**](https://econpapers.repec.org/scripts/redir.pf?u=http%3
A%2F%2Flink.springer.com%2F10.1007%2Fs11573-023-01149-5;h=repec:spr:jbecon:v:93:y:2023:i:9:d:10.1007_s11573-023-01149-5)
:  The SHapley Additive exPlanations technique is used in a paper to  pinpoint key factors influencing bond excess retur
n predictions made by  machine learning models. (2023-11-08, shares: 21.0)

[**Signal Quality's Role in Stock Market Vol
atility Prediction**](https://econpapers.repec.org/scripts/redir.pf?u=https%3A%2F%2Fdoi.org%2F10.1002%2Ffor.3016;h=repec
:wly:jforec:v:42:y:2023:i:8:p:2307-2321): A study finds that high-quality political signals can predict increased stock 
market volatility. (2023-11-08, shares: 16.0)

[**Belief-Based Momentum Indicator and Volatility Predictability in China
's Equity Market**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Fartic
le%2Fpii%2FS1042443123001245;h=repec:eee:intfin:v:88:y:2023:i:c:s1042443123001245):  Research shows a belief-based momen
tum indicator can predict equity  market volatility in China, with the HAR-LCPR model being the most  effective. (2023-1
1-08, shares: 16.0)

[**Deep Learning Model for Newsvendor Problem with Textual Review Data**](https://econpapers.repec.
org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0925527323002487;h=repec:eee:proe
co:v:265:y:2023:i:c:s0925527323002487):  The article talks about a new inventory management framework that uses a  deep 
learning model. This model suggests order quantities based on  online reviews and demand data, reducing costs by 28.7% c
ompared to  other models. (2023-11-08, shares: 16.0)

[**Newsvendor Problem: High-Dimensional Data and Mixed-Frequency M
ethod**](https://econpapers.repec.org/scripts/redir.pf?u=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2F
S0925527323002748;h=repec:eee:proeco:v:266:y:2023:i:c:s0925527323002748):  The first article explores the application of
 machine learning to  improve demand prediction and restocking decisions in newsvendor  problems, utilizing complex and 
varied historical data. (2023-11-08,  shares: 27.0)

&#x200B;

# GitHub

## Finance

[**Time Series Analysis & Interpret
able ML**](https://github.com/MatthewK84/LinkedIn-Learning-Journey):  The article explores Time Series Analysis and Inte
rpretable Machine  Learning, focusing on Python packages such as Darts, PyCaret, Nixtla,  Sktime, MAPIE, and PiML. (2023
-08-19, shares: 13.0)

[**Fixed Income Library for Bond Pricing & Derivatives**](https://github.com/attack68/rateslib): 
 The piece reviews a fixed income library for pricing bonds, bond  futures, and derivatives, featuring tools for Curvese
t construction and  risk sensitivity calculations. (2023-03-31, shares: 14.0)

[**GPU-Accelerated Limit Order Book Simul
ator for Trading**](https://github.com/KangOxford/AlphaTrade):  The article introduces JAXLOB, a GPU-accelerated limit o
rder book  simulator aimed at improving large scale reinforcement learning for  trading. (2022-04-21, shares: 26.0)

[**
Ultimate Time Series Visualization Tool**](https://github.com/facontidavide/PlotJuggler): The article introduces a Time 
Series Visualization Tool designed to enhance user experience. (2016-03-01, shares: 3702.0)

[**Legible Deep Learning wi
th Named Tensors in JAX**](https://github.com/stanford-crfm/haliax): The piece explores the use of Named Tensors to impr
ove the readability of Deep Learning in JAX. (2023-06-26, shares: 73.0)

## Trending

[**Optimization**](https://github.
com/ebrahimpichka/awesome-optimization):  The article is a guide to resources for learning and implementing  mathematica
l optimization, including educational materials and software  tools. (2023-10-31, shares: 93.0)

[**Lock-Free**](https:/
/github.com/rigtorp/awesome-lockfree):  The article provides a collection of resources for understanding and  implementi
ng waitfree and lockfree programming techniques. (2016-03-31,  shares: 1565.0)

[**LaTeX Conversion**](https://github.co
m/lukas-blecher/LaTeX-OCR):  The article explores pix2tex, a tool that uses Vision Transformer  technology to convert eq
uation images into LaTeX code. (2020-12-11,  shares: 6218.0)

&#x200B;

# LinkedIn

## Trending

[**The Fund: A Dagger o
n Wall Street**](https://www.linkedin.com/feed/update/urn:li:activity:7127504060357689345):  The Fund' has received a po
sitive review from The New York Times, being  praised as a sharp critique of Wall Street and the use of money for  contr
ol and humiliation. (2023-11-07, shares: 2.0)

[**McKinney Joins Posit**](https://www.linkedin.com/feed/update/urn:li:ac
tivity:7127395325933182976):  Python data scientist Wes McKinney, known for the pandas package, has  joined data science
 tools company Posit. (2023-11-07, shares: 1.0)

[**New Causal Modeling Framework**](https://www.linkedin.com/feed/updat
e/urn:li:activity:7127356785438416897):  A paper by Lars Lorch, Andreas Krause and Bernhard Schölkopf introduces  a new 
way to discuss causality using Stochastic Differential Equations  (SDEs). (2023-11-07, shares: 2.0)

[**ADGM's DLT Frame
work Goes Live**](https://www.linkedin.com/feed/update/urn:li:activity:7127262744008900609):  The Abu Dhabi Global Marke
t's DLT Foundations Framework, aimed at  Blockchain Foundations and DAOs, is now live, advancing Abu Dhabi's  commitment
 to the virtual asset and blockchain sectors. (2023-11-07,  shares: 2.0)

[**Paper on trading with concave price impact*
*](https://www.linkedin.com/feed/update/urn:li:activity:7127468645177307137):  A preprint titled Trading with Concave Pr
ice Impact and Impact Decay  has been submitted to SSRN, addressing statistical arbitrage issues and  estimating trading
 data. (2023-11-07, shares: 2.0)

[**Korean tech index soars after short selling ban**](https://www.linkedin.com/feed/up
date/urn:li:activity:7127449160252825602):  South Korean tech index records a 12% single-day gain following a ban  on sh
ort selling by regulators until June 2024. (2023-11-07, shares:  1.0)

## Informative

[**Math Seminar: Mean Fields Game
s in Finance**](https://www.linkedin.com/feed/update/urn:li:activity:7127327252660256769):  A Math Seminar featuring Pro
f. Charles-Albert Lehalle will be held on  November 9th, 2023, focusing on Mean Fields Games for Financial Markets.  (20
23-11-07, shares: 2.0)

[**Advancements in Synthetic Data for AI**](https://www.linkedin.com/feed/update/urn:li:activity
:7127278959976669184):  The development of GenAI models is hindered by a lack of  human-generated data, but synthetic da
ta generation is being utilized by  companies like IBM and Google DeepMind. (2023-11-07, shares: 1.0)

[**European Diver
sification: Rise of Active ETFs**](https://www.linkedin.com/feed/update/urn:li:activity:7127356855814627328):  Active ET
Fs are becoming increasingly popular in Europe, outperforming  active mutual funds which are experiencing significant wi
thdrawals.  (2023-11-06, shares: 1.0)

&#x200B;

# Podcasts

## Quantitative

[**Investors and AI's Impact**](https://au
dioboom.com/posts/8394221):  A CIO call discusses the potential of artificial intelligence for  investors, identifying c
ompanies that could benefit or be at risk, and  how AI could disrupt the asset management industry. (2023-11-02, shares:
  4)

[**AI and Narratives in Investing**](https://pdcn.co/e/www.buzzsprout.com/2034153/13918632-ben-hunt-on-unraveling-
ai-and-narratives-the-new-frontiers-in-investing.mp3):  Ben Hunt explores the role of narrative archetypes in understand
ing  artificial intelligence, their influence on industries and money  management, and their effect on market trends and
 investment decisions.  (2023-11-06, shares: 4)

[**The Future of Finance: Quantum Solutions**](https://www.buzzsprout.c
om/1877496/13918851-quantum-solutions-envisioning-the-next-era-of-finance.mp3):  In the QuantSpeak podcast, Dr. Araceli 
Venegas-Gomez discusses the  potential impact of quantum computing on finance, its adoption in  various industries, and 
her shift from aeronautical engineering to quant  finance. (2023-11-06, shares: 4)

[**Becoming a Legend: Lessons from F
ischer Black, Peter Carr, and More**](https://www.buzzsprout.com/803279/13906664-legends-never-die-how-to-become-a-legen
d.mp3):  The article highlights the common traits of renowned figures like  Fischer Black, Peter Carr, Rick Rubin, Georg
e Box, Gilbert Strang, and  John Nash, focusing on their soft skills and unique contributions.  (2023-11-07, shares: 3)


&#x200B;

# Twitter

## Quantitative

[**RL Algorithmic Trading Strategies in Black Swan Regimes**](https://twitter.com
/carlcarrie/status/1720383646039749071):  The article reviews a study assessing the performance of different  reinforcem
ent learning trading strategies during unpredictable, extreme  market events. (2023-11-03, shares: 5)

[**Skewness Risk 
Premium Generates High FX Returns**](https://twitter.com/quantseeker/status/1722007548750975483):  The article highlight
s a new study suggesting that trading currencies  based on their skewness risk premium can yield high returns and Sharpe
  ratio. (2023-11-07, shares: 1)

[**Analyst Underreaction Decline and Momentum Strategy Deterioration**](https://twitte
r.com/quantseeker/status/1721271394489499893):  The article discusses a study indicating that the effectiveness of a  12
-month momentum strategy has decreased due to analysts' improved  reaction to news. (2023-11-05, shares: 1)

[**Return D
rivers of Listed and Unlisted Real Estate**](https://twitter.com/quantseeker/status/1721213958864970143):  The article e
xamines a study by Chin and Povala that investigates the  factors influencing the returns of listed and unlisted real es
tate,  noting a correlation with return horizon. (2023-11-05, shares: 1)

## Miscellaneous

[**Large Language Models for
 Time Series Forecasting**](https://twitter.com/carlcarrie/status/1720599381974438112):  The NeurIPS 2023 paper presents
 LLMTime, a large language model that  predicts time series data by converting numbers into text and managing  missing d
ata. (2023-11-04, shares: 1)

[**Commodity Strategies and Spreads**](https://twitter.com/quantseeker/status/172148638695
4412299): The episode offers useful knowledge on commodity strategies and spreads. (2023-11-06, shares: 0)

[**Microsoft
's DeepSpeedRLHF for Chat Inference**](https://twitter.com/carlcarrie/status/1721059368483828089):  Microsoft's DeepSpee
dRLHF simplifies chat-style inference, allowing the  training of OPT13B in 9 hours and OPT30B in 18 hours for less than 
$300  and $600 respectively. (2023-11-05, shares: 0)

[**Theseus: Open Source Library for DNLS Optimization**](https://t
witter.com/carlcarrie/status/1720798668263956795):  Theseus is Meta's open-source library for DNLS optimization, develop
ed  on PyTorch for structured machine learning. (2023-11-04, shares: 0)

[**LLMTS: Language Models for Time Series**](ht
tps://twitter.com/carlcarrie/status/1720600217358090459):  LLM4TS is a large language model for time series that uses fi
ne-tuning,  layer normalization tuning, and LoRA. (2023-11-04, shares: 0)

# Paper with Code

## Trending

[**DeepSpeed 
Inference: Efficient Transformer Model at Unprecedented Scale**](https://github.com/microsoft/deepspeed-mii): DeepSpeed 
Inference improves latency and throughput performance in different situations. (2023-11-07, shares: 1071.0)

[**AkariAsa
i SelfRAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**](https://github.com/AkariAsai/self-rag
):  The framework develops a unique language model that adaptively  retrieves and reflects on passages using special 're
flection' tokens.  (2023-11-04, shares: 439.0)

[**Diffusion Models for Reinforcement Learning**](https://github.com/ape
xrl/diff4rlsurvey):  The article emphasizes the superiority of diffusion models over  previous generative models in term
s of sample quality and training  stability. (2023-11-04, shares: 35.0)

[**GPTFathom: LLM Benchmarking for GPT4+**](htt
ps://github.com/gpt-fathom/gpt-fathom):  The rapid advancement of LLMs necessitates an immediate need for a  comprehensi
ve evaluation system to identify their pros and cons.  (2023-11-05, shares: 146.0)

[**Comprehensive Survey on LLM Evalu
ation**](https://github.com/tjunlp-lab/awesome-llms-evaluation-papers):  The comprehensive review is designed to stimula
te more research into  assessing LLMs to ensure their ethical development. (2023-11-04, shares:  192.0)
```
---

     
 
all -  [ Effect of GPA, and Chances at Top CS PhD Programs? ](https://www.reddit.com/r/gradadmissions/comments/17pq2ta/effect_of_gpa_and_chances_at_top_cs_phd_programs/) , 2023-12-03-0911
```
Hi folks! I'm an undergraduate senior studying CS and Statistics at a T10 undergrad school (not for CS PhD, though); I'm
 also concurrently getting my M.S. in CS here as well. I have research experience in industry (at a top AI Research lab 
for 2 summers and ongoing part-time during the year for follow-up work / paper writing) and in academia (undergraduate h
onors thesis, and several collaborations with researchers both at my university and elsewhere). I have a few publication
s -- 2 at workshops (NeurIPS) and 4 pre-prints for papers under review at tier 1 venues (all first-author or co-first au
thor). I will add that my research experience appears to be a little unorthodox at the undergrad level, as most of my pr
ojects in academia have been self-initiated and self-devised, turning to mentor(s) (profs and sometimes PhD students) fo
r feedback, rather than working in a lab consistently with PhD students, postdocs, and a professor.

I also have quite a
 bit of teaching experience (TA'd 6 courses, all upper-level, majority being graduate-level) and some professional servi
ce (served as a reviewer for a few tier-1 conference workshops; some departmental service and other leadership stuff too
). LoRs most likely coming from an industry mentor, a research (thesis) advisor, and another professor I was Head TA for
 (am curious if there are any opinions on whether I should be going in a different direction for the 3rd recommender).


The reason I'm posting here is: I'm nervous that my GPA is a bit lower than the top programs' averages, and I'm wonderin
g if that'll be strongly held against me / a dealbreaker. Part of the reason for this is mental health struggles while b
eing overwhelmed with commitments. I'd say my course rigor is generally pretty strong (given that a lot of the technical
 courses are graduate / doctoral-level) despite that, but I'm worried that the GPA may be an immediate turnoff for those
 reviewing my application. As you probably can expect, I'm interested in Stanford, MIT, Princeton, CMU, etc.

Thanks in 
advance for your feedback and insights (and for taking the time to read all of this :))!!
```
---

     
 
all -  [ Code for a paper ](https://www.reddit.com/r/reinforcementlearning/comments/17o6brs/code_for_a_paper/) , 2023-12-03-0911
```
Is there a code available for the paper “Risk-Aware Transfer in Reinforcement Learning using Successor Features” publish
ed in NeurIPS 2021 by Gimelfarb et Al.?
```
---

     
 
all -  [ [R] Highlights for every NeurIPS 2023 paper ](https://www.reddit.com/r/MachineLearning/comments/17nm4eb/r_highlights_for_every_neurips_2023_paper/) , 2023-12-03-0911
```
Here is the list of all NeurIPS 2023 (Neural Information Processing Systems) papers and a short highlight for each of th
em. Among all \~3,500 papers, authors of around 1,000 papers also made their code or data available. The 'related code' 
link under paper title will take you directly to the code base.

[https://www.paperdigest.org/2023/10/nips-2023-highligh
ts/](https://www.paperdigest.org/2023/10/nips-2023-highlights/)

In addition, here is the link of 'search within NeurIPS
 2023' that can be used to find papers within NeurIPS-2023 related to a specific topic, e.g. 'diffusion model':

[https:
//www.paperdigest.org/search/?topic=nips&year=2023&q=diffusion\_model](https://www.paperdigest.org/search/?topic=nips&ye
ar=2023&q=diffusion_model)

NeurIPS 2023 will take place at New Orleans on Dec 10, 2023.
```
---

     
 
all -  [ Papers to reproduce for ML Reproducibility Challenge 2023 ](https://www.reddit.com/r/learnmachinelearning/comments/17lr0g0/papers_to_reproduce_for_ml_reproducibility/) , 2023-12-03-0911
```
I'm planning to participate in the ML Reproducibility Challenge 2023 ([**https://reproml.org/blog/announcing\_mlrc2023/*
*](https://reproml.org/blog/announcing_mlrc2023/)) and I'm looking for suggestions on some good deep learning papers whe
re I can try to reproduce the results.  


Per the organizer's suggestion, I should focus on papers published in 2023 fr
om the top ML venues like NeurIPS, ICML, ICLR, ACL, EMNLP, ICCV, CVPR, TMLR, JMLR, TACL.

Let me know if you have come a
cross any promising deep learning papers published this year that would be good for reproducibility! I'm hoping to selec
t one to focus on for this challenge.

&#x200B;
```
---

     
