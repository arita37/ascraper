""	"title"	"body"	"url"	"comms_num"	"dt"	"score"	"id"
0	"[D] The machine learning community has a toxicity problem"	"It is omnipresent!

**First** of all, the peer-review proces
s is *broken*. Every fourth NeurIPS submission is put on arX
iv. There are DeepMind researchers publicly going after revi
ewers who are criticizing their ICLR submission. On top of t
hat, papers by well-known institutes that were put on arXiv 
are accepted at top conferences, despite the reviewers agree
ing on rejection. In contrast, vice versa, some papers with 
a majority of accepts are overruled by the AC. (I don't want
 to call any names, just have a look the openreview page of 
this year's ICRL).

**Secondly,** there is a *reproducibilit
y crisis*. Tuning hyperparameters on the test set seem to be
 the standard practice nowadays. Papers that do not beat the
 current state-of-the-art method have a zero chance of getti
ng accepted at a good conference. As a result, hyperparamete
rs get tuned and subtle tricks implemented to observe a gain
 in performance where there isn't any.

**Thirdly,** there i
s a *worshiping* problem. Every paper with a Stanford or Dee
pMind affiliation gets praised like a breakthrough. For inst
ance, BERT has seven times more citations than ULMfit. The G
oogle affiliation gives so much credibility and visibility t
o a paper. At every ICML conference, there is a crowd of peo
ple in front of every DeepMind poster, regardless of the con
tent of the work. The same story happened with the Zoom meet
ings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had tw
ice as many submissions as ICML, even though both are top-ti
er ML conferences. Why? Why is the name 'neural' praised so 
much? Next, Bengio, Hinton, and LeCun are truly deep learnin
g pioneers but calling them the 'godfathers' of AI is insane
. It has reached the level of a cult.

**Fourthly**, the way
 Yann LeCun talked about biases and fairness topics was inse
nsitive. However, the *toxicity* and backlash that he receiv
ed are beyond any reasonable quantity. Getting rid of LeCun 
and silencing people won't solve any issue.

**Fifthly**, ma
chine learning, and computer science in general, have a huge
 *diversity problem*. At our CS faculty, only 30% of undergr
ads and 15% of the professors are women. Going on parental l
eave during a PhD or post-doc usually means the end of an ac
ademic career. However, this lack of diversity is often abus
ed as an excuse to shield certain people from any form of cr
iticism.  Reducing every negative comment in a scientific di
scussion to race and gender creates a toxic environment. Peo
ple are becoming afraid to engage in fear of being called a 
racist or sexist, which in turn reinforces the diversity pro
blem.

**Sixthly**, moral and ethics are set *arbitrarily*. 
The U.S. domestic politics dominate every discussion. At thi
s very moment, thousands of Uyghurs are put into concentrati
on camps based on computer vision algorithms invented by thi
s community, and nobody seems even remotely to care. Adding 
a 'broader impact' section at the end of every people will n
ot make this stop. There are huge shitstorms because a resea
rcher wasn't mentioned in an article. Meanwhile, the 1-billi
on+ people continent of Africa is virtually excluded from an
y meaningful ML discussion (besides a few Indaba workshops).


**Seventhly**, there is a cut-throat publish-or-perish *me
ntality*. If you don't publish 5+ NeurIPS/ICML papers per ye
ar, you are a looser. Research groups have become so large t
hat the PI does not even know the name of every PhD student 
anymore. Certain people submit 50+ papers per year to NeurIP
S. The sole purpose of writing a paper has become to having 
one more NeurIPS paper in your CV. Quality is secondary; pas
sing the peer-preview stage has become the primary objective
.

**Finally**, discussions have become *disrespectful*. Sch
midhuber calls Hinton a thief, Gebru calls LeCun a white sup
remacist, Anandkumar calls Marcus a sexist, everybody is und
er attack, but nothing is improved.

Albert Einstein was opp
osing the theory of [quantum mechanics](https://en.wikipedia
.org/wiki/Albert_Einstein#Einstein's_objections_to_quantum_m
echanics). Can we please stop demonizing those who do not sh
are our exact views. We are allowed to disagree without goin
g for the jugular. 

The moment we start silencing people be
cause of their opinion is the moment scientific and societal
 progress dies. 

Best intentions, Yusuf"	"https://www.reddit.com/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/"	"571"	"1593547579.0"	"3827"	"hiv3vf"
1	"[R] Google has a credit assignment problem in research"	"Google has some serious cultural problems with proper credit
 assignment. They continue to rename methods discovered earl
ier DESPITE admitting the existence of this work.

See this 
new paper they released:

[https://arxiv.org/abs/2006.14536]
(https://arxiv.org/abs/2006.14536)

Stop calling this method
 SWISH; its original name is SILU. The original Swish author
s from Google even admitted to this mistake in the past ([ht
tps://www.reddit.com/r/MachineLearning/comments/773epu/r\_sw
ish\_a\_selfgated\_activation\_function\_google/](https://ww
w.reddit.com/r/MachineLearning/comments/773epu/r_swish_a_sel
fgated_activation_function_google/)). And the worst part is 
this new paper has the very same senior author as the previo
us Google paper.

And just a couple weeks ago, the same issu
e again with the SimCLR paper. See thread here:

[https://ww
w.reddit.com/r/MachineLearning/comments/hbzd5o/d\_on\_the\_p
ublic\_advertising\_of\_neurips/fvcet9j/?utm\_source=share&u
tm\_medium=web2x](https://www.reddit.com/r/MachineLearning/c
omments/hbzd5o/d_on_the_public_advertising_of_neurips/fvcet9
j/?utm_source=share&utm_medium=web2x)

They site only cite p
rior work with the same idea in the last paragraph of their 
supplementary and yet again rename the method to remove its 
association to the prior work. This is unfair. Unfair to the
 community and especially unfair to the lesser known researc
hers who do not have the advertising power of Geoff Hinton a
nd Quoc Le on their papers.

SiLU/Swish is by Stefan Elfwing
, Eiji Uchibe, Kenji Doya ([https://arxiv.org/abs/1702.03118
](https://arxiv.org/abs/1702.03118)).

Original work of SimC
LR is by Mang Ye, Xu Zhang, Pong C. Yuen, Shih-Fu Chang ([ht
tps://arxiv.org/abs/1904.03436](https://arxiv.org/abs/1904.0
3436))

Update:

Dan Hendrycks and Kevin Gimpel also propose
d the SiLU non-linearity in 2016 in their work Gaussian Erro
r Linear Units (GELUs) ([https://arxiv.org/abs/1606.08415](h
ttps://arxiv.org/abs/1606.08415))

Update 2:

'Smooth Advers
arial Training' by Cihang Xie is only an example of the rena
ming issue because of issues in the past by Google to proper
ly assign credit. Cihang Xie's work is not the cause of this
 issue. Their paper does not claim to discover a new activat
ion function. They are only using the SiLU activation functi
on in some of their experiments under the name Swish. [Cihan
g Xie will provide an update of the activation function nami
ng used in the paper](https://www.reddit.com/r/MachineLearni
ng/comments/hkiyir/r\_google\_has\_a\_credit\_assignment\_pr
oblem\_in/fwtttqo?utm\_source=share&utm\_medium=web2x) to re
flect the correct naming. 

The cause of the issue is Google
 in the past decided to continue with renaming the activatio
n as [Swish despite being made aware of the method already h
aving the name SiLU](https://arxiv.org/abs/1710.05941). Now 
it is stuck in our research community and stuck in our ML li
braries (https://github.com/tensorflow/tensorflow/issues/410
66)."	"https://www.reddit.com/r/MachineLearning/comments/hkiyir/r_google_has_a_credit_assignment_problem_in/"	"127"	"1593782531.0"	"824"	"hkiyir"
2	"[D] Advanced courses update"	"EDIT Jan 2021 : I am still updating the list as of Jan, 2021
 and will most probably continue to do so for foreseeable fu
ture. So, please feel free to message me any courses you fin
d interesting that fit here.

- - -

We have a [PhD level or
 Advanced courses](https://www.reddit.com/r/MachineLearning/
comments/51qhc8/phdlevel_courses/) thread in the sidebar but
 it's three year old now. There were two other 7-8 month old
 threads ([1](https://www.reddit.com/r/MachineLearning/comme
nts/cae59l/d_advanced_courses_update/), [2](https://www.redd
it.com/r/MachineLearning/comments/cjnund/d_what_are_your_fav
orite_videos_lectures_on/)) but they don't have many quality
 responses either. 

So, can we have a new one here?

To rei
terate - CS231n, CS229, ones from Udemy etc are not advanced
. 

Advanced ML/DL/RL, attempts at building theory of DL, op
timization theory, advanced applications etc are some exampl
es of what I believe should belong here, much like the origi
nal sidebar post.

You can also suggest (new) categories for
 the courses you share. :)

- - -

Here are some courses we'
ve found so far. 

ML >> 

* [Learning Discrete Latent Struc
ture - sta4273/csc2547 Spring'18](https://duvenaud.github.io
/learn-discrete/)
* [Learning to Search - csc2547 Fall'19](h
ttps://duvenaud.github.io/learning-to-search/)
* [Scalable a
nd Flexible Models of Uncertainty - csc2541](https://csc2541
-f17.github.io/)
* [Fundamentals of Machine Learning Over Ne
tworks - ep3260](https://sites.google.com/view/mlons/home)
*
 [Machine Learning on Graphs - cs224w](http://web.stanford.e
du/class/cs224w/), [videos](https://www.youtube.com/playlist
?list=PL-Y8zK4dwCrQyASidb2mjj_itW2-YYx6-)
* [Mining Massive 
Data Sets - cs246](http://web.stanford.edu/class/cs246/index
.html)
* [Interactive Learning - cse599](https://courses.cs.
washington.edu/courses/cse599i/20wi/)
* [Machine Learning fo
r Sequential Decision Making Under Uncertainty - ee290s/cs19
4](https://inst.eecs.berkeley.edu/%7Eee290s/fa18/resources.h
tml)
* [Probabilistic Graphical Methods - 10-708](https://ww
w.cs.cmu.edu/~epxing/Class/10708-20/)
* [Introduction to Cau
sal Inference](https://www.bradyneal.com/causal-inference-co
urse)

ML >> Theory

* [Statistical Machine Learning - 10-70
2/36-702 with videos](https://www.stat.cmu.edu/~ryantibs/sta
tml/), [2016 videos](https://www.youtube.com/playlist?list=P
LTB9VQq8WiaCBK2XrtYn5t9uuPdsNm7YE)
* [Statistical Learning T
heory - cs229T/stats231 Stanford Autumn'18-19](http://web.st
anford.edu/class/cs229t/)
* [Statistical Learning Theory - c
s281b /stat241b UC Berkeley, Spring'14 ](https://www.stat.be
rkeley.edu/%7Ebartlett/courses/2014spring-cs281bstat241b/)
*
 [Statistical Learning Theory - csc2532 Uni of Toronto, Spri
ng'20](https://erdogdu.github.io/csc2532/)

ML >> Bayesian


* [Bayesian Data Analysis](https://github.com/avehtari/BDA_c
ourse_Aalto)
* [Bayesian Methods Research Group, Moscow](htt
ps://bayesgroup.ru/), Bayesian Methods in ML - [spring2020](
https://www.youtube.com/playlist?list=PLe5rNUydzV9TjW6dol0gV
dWpr02hBicS0), [fall2020](https://www.youtube.com/playlist?l
ist=PLe5rNUydzV9THZg7-QnaLhcccIbQ5eQm8)
* [Deep Learning and
 Bayesian Methods - summer school](http://deepbayes.ru), vid
eos available for 2019 version

ML >> Systems and Operations


* [Stanford MLSys Seminar Series](https://mlsys.stanford.e
du/)
* [Visual Computing Systems- cs348v](http://graphics.st
anford.edu/courses/cs348v-18-winter/) - Another systems cour
se that discusses hardware from a persepective of visual com
puting but is relevant to ML as well 
* [Advanced Machine Le
arning Systems - cs6787](https://www.cs.cornell.edu/courses/
cs6787/2019fa/) - lecture 9 and onwards discuss hardware sid
e of things
* [Machine Learning Systems Design - cs329S](htt
ps://stanford-cs329s.github.io/)
* [Topics in Deployable ML 
- 6.S979](https://people.csail.mit.edu/madry/6.S979/)
* [Mac
hine Learning in Production / AI Engineering (17-445/17-645/
17-745/11-695)](https://ckaestne.github.io/seai/)
* [AutoML 
- Automated Machine Learning](https://ki-campus.org/courses/
automl-luh2021)

DL >>

* [Deep Unsupervised Learning - cs29
4](https://sites.google.com/view/berkeley-cs294-158-sp20/hom
e)
* [Deep Multi-task and Meta learning - cs330](https://cs3
30.stanford.edu/)
* [Topics in Deep Learning - stat991 UPenn
/Wharton](https://github.com/dobriban/Topics-in-deep-learnin
g) *most chapters start with introductory topics and dig int
o advanced ones towards the end. 
* [Deep Generative Models 
- cs236](https://deepgenerativemodels.github.io/)
* [Deep Ge
ometric Learning of Big Data and Applications](https://www.i
pam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-l
earning-of-big-data-and-applications/?tab=overview)
* [Deep 
Implicit Layers - NeurIPS 2020 tutorial](http://implicit-lay
ers-tutorial.org/)

DL >> Theory

* [Topics course on Mathem
atics of Deep Learning - CSCI-GA 3033](https://joanbruna.git
hub.io/MathsDL-spring19/)
* [Topics Course on Deep Learning 
- stat212b](http://joanbruna.github.io/stat212b/)
* [Analyse
s of Deep Learning - stats385](https://stats385.github.io/),
 [videos from 2017 version](https://www.researchgate.net/pro
ject/Theories-of-Deep-Learning)
* [Mathematics of Deep Learn
ing](http://www.vision.jhu.edu/teaching/learning/deeplearnin
g19/)
* [Geometry of Deep Learning](https://www.microsoft.co
m/en-us/research/event/ai-institute-2019/)

RL >>

* [Meta-L
earning - ICML 2019 Tutorial](https://sites.google.com/view/
icml19metalearning) , [Metalearning: Applications to Data Mi
ning - google books link](https://books.google.com/books?id=
DfZDAAAAQBAJ&printsec=copyright&redir_esc=y#v=onepage&q&f=fa
lse)
* [Deep Multi-Task and Meta Learning - cs330](http://cs
330.stanford.edu/), [videos](https://www.youtube.com/playlis
t?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)
* [Deep Reinforce
ment Learning - cs285](http://rail.eecs.berkeley.edu/deeprlc
ourse/)
* [Advanced robotics - cs287](https://people.eecs.be
rkeley.edu/%7Epabbeel/cs287-fa19/)
* [Reinforcement Learning
 - cs234](https://web.stanford.edu/class/cs234/), [videos fo
r 2019 run](https://www.youtube.com/playlist?list=PLoROMvodv
4rOSOPzutgyCTapiGlY2Nd8u)
* [Reinforcement Learning Summer S
chool 2019: Bandits, RL & Deep RL](https://rlss.inria.fr/pro
gram/)

Optimization >> 

* [Convex Optimization I - ee364a]
(http://stanford.edu/class/ee364a/), has quite recent [video
s](https://www.youtube.com/playlist?list=PLdrixi40lpQm5ksInX
lRon1eRwq_gzIcw) too. 
[Convex Optimization II - ee364b](htt
p://web.stanford.edu/class/ee364b/), [2008 videos](https://w
ww.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&i
ndex=20)
* [Convex Optimization and Approximation - ee227c](
https://ee227c.github.io/)
* [Convex Optimization - ee227bt]
(https://people.eecs.berkeley.edu/%7Eelghaoui/Teaching/EE227
BT/index.html)
* [Variational Methods for Computer Vision](h
ttps://vision.in.tum.de/teaching/ws2013/vmcv2013)
* [Advance
d Optimization and Randomized Algorithms - 10-801](http://ww
w.cs.cmu.edu/%7Esuvrit/teach/index.html), [videos](https://w
ww.youtube.com/playlist?list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICx
t0d)
* [Optimization Methods for Machine Learning and Engine
ering - Karlsruhe Institute of Technology](https://www.youtu
be.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5)

Ap
plications >> Computer Vision

* [Computational Video Manipu
lation - cs448v](https://magrawala.github.io/cs448v-sp19/)
*
 [Advanced Topics in ML: Modeling and Segmentation of Multiv
ariate Mixed Data](http://www.vision.jhu.edu/teaching/learni
ng/learning10/)
* [TUM AI Guest lecture series](https://www.
youtube.com/playlist?list=PLQ8Y4kIIbzy8kMlz7cRqz-BjbdyWsfLXt
) - many influential researchers in DL, vision, graphics tal
k about latest advances and their latest works.
* [Advanced 
Deep Learning for Computer Vision - TUM ADL4CV](https://www.
youtube.com/playlist?list=PLog3nOPCjKBkngkkF552-Hiwa5t_ZeDnh
)
* [Detection, Segmentation and Tracking - TUM CV3DST](http
s://www.youtube.com/playlist?list=PLog3nOPCjKBneGyffEktlXXMf
v1OtKmCs)
* [Guest lectures at TUM Dynamic Vision and Learni
ng group](https://www.youtube.com/playlist?list=PLog3nOPCjKB
nAuymJ7uTysuG357zVn7et)
* [Vision Seminar at MIT](https://ww
w.youtube.com/channel/UCLMiFkFyfcNnZs6iwYLPI9g/videos)
* [Au
tonomous Vision Group, Talk@Tübingen Seminar](https://www.yo
utube.com/playlist?list=PLeCNfJWZKqxu-BwwcR4tDBOFNkJEOPWb_)


Applications >> Natural Language Processing

* [Natural Lan
guage Processing with Deep Learning - cs224n](http://web.sta
nford.edu/class/cs224n/) (* not sure if it belongs here, peo
ple working in NLP can help me out)
* [Neural networks for N
LP - cs11-747](http://www.phontron.com/class/nn4nlp2020/sche
dule.html)
* [Natural Language Understanding - cs224u](https
://web.stanford.edu/class/cs224u/), [video](https://www.yout
ube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

A
pplications >> 3D Graphics 

* [Non-Euclidean Methods in Mac
hine Learning - cs468, 2020](http://graphics.stanford.edu/co
urses/cs468-20-fall/schedule.html)
* [Machine Learning for 3
D Data - cs468, spring 2017](http://graphics.stanford.edu/co
urses/cs468-17-spring/schedule.html)
* [Data-Driven Shape An
alysis - cs468, 2014](http://graphics.stanford.edu/courses/c
s468-14-spring/)
* [Geometric Deep Learning](http://geometri
cdeeplearning.com/) - Not a course but the website links a f
ew tutorials on Geometric DL
* [Deep Learning for Computer G
raphics - SIGGRAPH 2019](https://geometry.cs.ucl.ac.uk/creat
iveai/)
* [Machine Learning for Machine Vision as Inverse Gr
aphics - csc2547 Winter'20](http://www.cs.utoronto.ca/~bonne
r/courses/2020s/csc2547/) 
* [Machine Learning Meets Geometr
y, winter 2020](https://geoml.github.io/schedule.html); [Mac
hine Learning for 3D Data, winter 2018](https://cse291-i.git
hub.io/WI18/schedule.html)

---

Edit: Upon suggestion, cate
gorized the courses. There might be some misclassifications 
as I'm not trained on this task ;). Added some good ones fro
m older (linked above) discussions."	"https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/"	"85"	"1583418496.0"	"817"	"fdw0ax"
3	"[D] Some interesting observations about machine learning publication practices from an outsider"	"I come from a traditional engineering field, and here is my 
observation about ML publication practice lately:

I have no
ticed that there are groups of researchers working on the in
tersection of 'old' fields such as optimization, control, si
gnal processing and the like, who will all of a sudden publi
sh a massive amount of paper that purports to solve a certai
n problem. The problem itself is usually recent and sometime
s involves some deep neural network.

However, upon close ex
amination, the only novelty is the problem (usually proposed
 by other unaffiliated groups) but not the method proposed b
y the researchers that purports to solve it.

I was puzzled 
by why a very large amount of seemingly weak papers, literal
ly rehashing (occasionally, well-known) techniques from the 
1980s or even 60s are getting accepted, and I noticed the fo
llowing recipe:

1. **Only ML conferences.** These groups of
 researchers will only ever publish in machine learning conf
erences (and not to optimization and control conferences/jou
rnals, where the heart of their work might actually lie). Fo
r example, on a paper about adversarial machine learning, th
e entire paper was actually about solving an optimization pr
oblem, but the optimization routine is basically a slight va
riation of other well studied methods. ***Update***: I also 
noticed that if a paper does not go through NeurIPS or ICLR,
 they will be directly sent to AAAI and some other smaller n
ame conferences, where they will be accepted. So nothing goe
s to waste in this field.
2. **Peers don't know what's going
 on.** Through openreview, I found that the reviewers (not j
ust the researchers) are uninformed about their particular a
rea, and only seem to comment on the correctness of the pape
r, but not the novelty. In fact, I doubt the reviewers thems
elves know about the novelty of the method. ***Update***: by
 novelty I meant how novel it is with respect to the state-o
f-the-art of a certain technique, especially when it interse
cts with operations research, optimization, control, signal 
processing. The state-of-the-art *could be* far ahead than w
hat mainstream ML folks know about.
3. **Poor citation pract
ices.** Usually the researchers will only cite themselves or
 other 'machine learning people' (whatever this means) from 
the last couple of years. Occasionally, there will be 1 cita
tion from hundreds of years ago attributed to Cauchy, Newton
, Fourier, Cournot, Turing, Von Neumann and the like, and th
en a hundred year jump to 2018 or 2019. I see, 'This problem
 was studied by *some big name* in 1930 and *Random Guy XYZ*
 in 2018' a lot.
4. **Wall of math.** Frequently, there will
 be a massive wall of math, proving some esoteric condition 
on the eigenvalue, gradient, Jacobian, and other curious thi
ngs about their problem (under other esoteric assumptions). 
There will be several theorems, none of which are applicable
 because the moment they run their highly non-convex deep le
arning application, all conditions are violated. Hence the o
nly thing obtained from these intricate theorems + math wall
 are some faint intuition (which are violated immediately). 
And then nothing is said. 

***Update***: If I could add one
 more, it would be that certain techniques, after being prop
osed, and after the authors claim that it beats a lot of ben
chmarks, will be seemingly be abandoned and never used again
. ML researchers seem to like to jump around topics a lot, s
o that might be a factor. But usually in other fields, once 
a technique is proposed, it is refined by the same group of 
researchers over many years, sometimes over the course of a 
researcher's career.

In some ways, this makes certain area 
of ML sort of an echo chamber, where researchers are pushing
 through a large amount of known results rehashed and somewh
at disguised by the novelty of their problem and these paper
s are all getting accepted because no one can detect the lac
k of novelty (or when they do detect, it is only 1 guy out o
f 3 reviewers). I just feel like ML conferences are sort of 
being treated as some sort of automatic paper acceptance cas
h cow.

Just my two cents coming from outside of ML. My obse
rvation does not apply to all fields of ML."	"https://www.reddit.com/r/MachineLearning/comments/lvwt3l/d_some_interesting_observations_about_machine/"	"171"	"1614671503.0"	"667"	"lvwt3l"
4	"[D] Calling out the authors of 'Trajformer' paper for claiming they published code but never doing it"	"I read a paper from NeurIPS 2020 titled 'Trajformer: Traject
ory Prediction with Local Self-Attentive Contexts for Autono
mous Driving'. I found it interesting and the authors claim 
multiple times in the paper that 'we release our code at '[h
ttps://github.com/Manojbhat09/Trajformer](https://github.com
/Manojbhat09/Trajformer)'. Turns out they never did, fine, I
 thought perhaps they will in the future and starred the rep
o to check it out later.

Many others raised issues asking f
or update on code release and they never replied. Finally, i
t April they update the readme to say that they will release
 the code and that's been the last update.

I know this is a
 common trend in ML papers now, but what sucks is that I ema
iled the authors (both the grad student and the PI) multiple
 times asking for an update an they never replied. Their pap
er is literally based on empirical improvements and without 
working code to replicate the results it is their word again
st mine.

I strongly think things have to change, and I beli
eve they only will if we call them out. I waited long enough
, and made significant effort to contact the authors with no
 response. I mean I don't mind them not releasing their code
, but at least don't claim that you did in the paper/review 
phase and then disappear. An undergrad in my lab asked why s
he should take time to clean up the code and document it bef
ore release while others just move on to the next interestin
g project and I don't have an answer. "	"https://www.reddit.com/r/MachineLearning/comments/qrbkc7/d_calling_out_the_authors_of_trajformer_paper_for/"	"90"	"1636600691.0"	"543"	"qrbkc7"
5	"[D] NeurIPS 2019 Bengio Schmidhuber Meta-Learning Fiasco"	"The recent reddit post [Yoshua Bengio talks about what's nex
t for deep learning](https://www.reddit.com/r/MachineLearnin
g/comments/e92dp5/d_yoshua_bengio_talks_about_whats_next_for
_deep/) links to an interview with Bengio. User u/panties_in
_my_ass got many upvotes for this comment: 

>Spectrum: What
's the key to that kind of adaptability?***  
>  
>Bengio: [
Meta-learning](https://arxiv.org/pdf/1905.03030.pdf) is a ve
ry hot topic these days: Learning to learn. I wrote an [earl
y paper on this](http://bengio.abracadoudou.com/publications
/pdf/bengio_1991_ijcnn.pdf) in 1991, but only recently did w
e get the computational power to implement this kind of thin
g.  
>  
>Somewhere, on some laptop, Schmidhuber is screamin
g at his monitor right now.

because he introduced meta-lear
ning 4 years before Bengio: 

Jürgen Schmidhuber. Evolutiona
ry principles in self-referential learning, or on learning h
ow to learn: The meta-meta-... hook. Diploma thesis, Tech Un
iv. Munich, 1987.

Then Bengio gave his [NeurIPS 2019 talk](
https://slideslive.com/38921750/from-system-1-deep-learning-
to-system-2-deep-learning). Slide 71 says:

>Meta-learning o
r learning to learn (Bengio et al 1991; Schmidhuber 1992)

u
/y0hun commented:

>What a childish slight... The Schmidhube
r 1987 paper is clearly labeled and established and as a nas
ty slight he juxtaposes his paper against Schmidhuber with h
is preceding it by a year almost doing the opposite of givin
g him credit.

I detect a broader pattern here. Look at this
 highly upvoted post: [Jürgen Schmidhuber really had GANs in
 1990](https://www.reddit.com/r/MachineLearning/comments/djj
u8a/d_jurgen_schmidhuber_really_had_gans_in_1990/), 25 years
 before Bengio. u/siddarth2947 commented that

>GANs were ac
tually mentioned in the Turing laudation, it's both funny an
d sad that Yoshua Bengio got a Turing award for a principle 
that Jurgen invented decades before him

and that section 3 
of Schmidhuber's [post on their miraculous year 1990-1991](h
ttp://people.idsia.ch/~juergen/deep-learning-miraculous-year
-1990-1991.html) is actually about his former student Sepp H
ochreiter and Bengio:

> (In 1994, others published results 
[VAN2] essentially identical to the 1991 vanishing gradient 
results of Sepp [VAN1]. Even after a common publication [VAN
3], the first author of reference [VAN2] published papers (e
.g., [VAN4]) that cited only his own 1994 paper but not Sepp
's original work.)

So Bengio republished at least 3 importa
nt ideas from Schmidhuber's lab without giving credit: meta-
learning, vanishing gradients, GANs. What's going on?"	"https://www.reddit.com/r/MachineLearning/comments/ea2gap/d_neurips_2019_bengio_schmidhuber_metalearning/"	"170"	"1576233717.0"	"550"	"ea2gap"
6	"[R] Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/eilmxki09bd61.png"	"3"	"1611507295.0"	"516"	"l432gk"
7	"[R] A List of Best Papers from Top AI Conferences in 2020"	"Sharing a list of award-winning papers from this year's top 
conferences for anyone interested in catching up on the late
st machine learning research before the end of the year :)


**AAAI 2020**

* Best Paper: WinoGrande: An Adversarial Wino
grad Schema Challenge at Scale \[[Paper](https://arxiv.org/a
bs/1907.10641)\]
* Honorable Mention: A Unifying View on Ind
ividual Bounds and Heuristic Inaccuracies in Bidirectional S
earch \[[Paper](https://ojs.aaai.org//index.php/AAAI/article
/view/5611)\]

**CVPR 2020** 

* Best Paper: Unsupervised Le
arning of Probably Symmetric Deformable 3D Objects from Imag
es in the Wild \[[Paper](https://arxiv.org/pdf/1911.11130.pd
f)\] \[[Presentation](https://crossminds.ai/video/5ee96b86b1
267e24b0ec2354/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**
ACL 2020**

* Best Paper: Beyond Accuracy: Behavioral Testin
g of NLP Models with CheckList \[[Paper](https://www.aclweb.
org/anthology/2020.acl-main.442.pdf)\] \[[Video](https://cro
ssminds.ai/video/5f454437e1acdc4d12c4186e/?playlist_id=5fe2e
2ea56dab51eaff52eaf)\] 

**ICML 2020**

* Best Paper: On Lea
rning Sets of Symmetric Elements \[[Paper](https://arxiv.org
/abs/2002.08599)\]  \[[Presentation](https://icml.cc/virtual
/2020/poster/6022)\] 
* Best Paper: Tuning-free Plug-and-Pla
y Proximal Algorithm for Inverse Imaging Problems \[[Paper](
https://arxiv.org/abs/2012.05703)\]  \[[Presentation](https:
//icml.cc/virtual/2020/poster/6447)\] 
* Honorable Mention: 
Efficiently sampling functions from Gaussian process posteri
ors  \[[Paper](https://arxiv.org/abs/2002.09309)\]  \[[Prese
ntation](https://crossminds.ai/video/5f189c96c01f1dd70811ebe
f/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Honorable Ment
ion: Generative Pretraining From Pixels \[[Paper](https://cd
n.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pd
f)\]  \[[Presentation](https://crossminds.ai/video/5f0e0b67d
8b7c2e383e1077b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

*
*ECCV 2020**

* Best Paper: RAFT: Recurrent All-Pairs Field 
Transforms for Optical Flow \[[Paper](https://arxiv.org/abs/
2003.12039)\] \[[Video](https://crossminds.ai/video/5f5acf7f
7fa4bb2ca9d64e4d/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
*
 Honorable Mention: Towards Streaming Perception \[[Paper](h
ttps://arxiv.org/abs/2005.10420)\] \[[Presentation](https://
crossminds.ai/video/5f44390ae1acdc4d12c417e3/?playlist_id=5f
e2e2ea56dab51eaff52eaf)\] 
* Honorable Mention: NeRF: Repres
enting Scenes as Neural Radiance Fields for View Synthesis \
[[Paper](https://arxiv.org/abs/2003.08934)\] \[[Presentation
](https://crossminds.ai/video/5f3b294f96cfcc9d075e35b6/?play
list_id=5fe2e2ea56dab51eaff52eaf)\] 

**ICRA 2020**

* Best 
Paper: Preference-Based Learning for Exoskeleton Gait Optimi
zation \[[Paper](https://arxiv.org/abs/1909.12316)\] \[[Pres
entation](https://crossminds.ai/video/5f65488303c0894581947a
6b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Paper in
 Robot Vision: Graduated Non-Convexity for Robust Spatial Pe
rception: From Non-Minimal Solvers to Global Outlier Rejecti
on \[[Paper](https://arxiv.org/abs/1909.08605)\] \[[Presenta
tion](https://crossminds.ai/video/5f63f6c403c089458194705f/?
playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**CoRL 2020**

* B
est Paper: Learning Latent Representations to Influence Mult
i-Agent Interaction \[[Paper](https://arxiv.org/abs/2011.066
19)\] \[[Presentation](https://crossminds.ai/video/5fd9782a0
8be4fa7f41eabfe/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* 
Best Paper Presentation: Accelerating Reinforcement Learning
 with Learned Skill Priors \[[Paper](https://arxiv.org/abs/2
010.11944)\] \[[Presentation](https://crossminds.ai/video/5f
d9794308be4fa7f41eac54/?playlist_id=5fe2e2ea56dab51eaff52eaf
)\] 
* Best System Paper: SMARTS: An Open-Source Scalable Mu
lti-Agent RL Training School for Autonomous Driving \[[Paper
](https://arxiv.org/abs/2010.09776)\] \[[Presentation](https
://crossminds.ai/video/5fd9791f08be4fa7f41eac48/?playlist_id
=5fe2e2ea56dab51eaff52eaf)\] 

**RecSys 2020**

* Best Long 
Paper: Progressive Layered Extraction (PLE): A Novel Multi-T
ask Learning (MTL) Model for Personalized Recommendations \[
[Paper](https://github.com/guyulongcs/Awesome-Deep-Learning-
Papers-for-Search-Recommendation-Advertising/blob/master/0_N
ew_Papers_in_2020/2020%20%28Tencent%29%20%28Recsys%29%20%5BP
LE%5D%20Progressive%20Layered%20Extraction%20%28PLE%29%20-%2
0A%20Novel%20Multi-Task%20Learning%20%28MTL%29%20Model%20for
%20Personalized%20Recommendations.pdf)\] \[[Presentation](ht
tps://crossminds.ai/video/5f7fc247d81cf36f1a8e379c/?playlist
_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Short Paper: ADER: A
daptively Distilled Exemplar Replay Towards Continual Learni
ng for Session-based Recommendation \[[Paper](https://arxiv.
org/abs/2007.12000)\] \[[Presentation](https://crossminds.ai
/video/5f7fc27ad81cf36f1a8e37b6/?playlist_id=5fe2e2ea56dab51
eaff52eaf)\] 

**NeurIPS 2020**

* Best Paper: Language Mode
ls are Few-Shot Learners \[[Paper](https://arxiv.org/abs/200
5.14165)\] \[[Video](https://crossminds.ai/video/5f3179536d7
639fd8a7fc06a/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Be
st Paper: No-Regret Learning Dynamics for Extensive-Form Cor
related Equilibrium \[[Paper](https://arxiv.org/abs/2004.006
03)\] 
* Best Paper: Improved Guarantees and a Multiple-Desc
ent Curve for Column Subset Selection and the Nyström Method
 \[[Paper](https://arxiv.org/abs/2002.09073)\]

Here is a co
mprehensive collection of [research talks from all major AI 
conferences](https://crossminds.ai/c/conference/) this year 
if you'd like to explore further."	"https://www.reddit.com/r/MachineLearning/comments/knai5q/r_a_list_of_best_papers_from_top_ai_conferences/"	"48"	"1609361402.0"	"502"	"knai5q"
8	"[D] On the public advertising of NeurIPS submissions on Twitter"	"The deadline for submitting papers to the NeurIPS 2020 confe
rence was two weeks ago. Since then, almost everyday I come 
across long Twitter threads from ML researchers that publicl
y advertise their work (obviously NeurIPS submissions, from 
the template and date of the shared arXiv preprint). They ar
e often quite famous researchers from Google, Facebook... wi
th thousands of followers and therefore a high visibility on
 Twitter. These posts often get a lot of likes and retweets 
- see examples in comment.

While I am glad to discover new 
exciting works, I am also concerned by the impact of such pr
actice on the review process. I know that submissions of arX
iv preprints are not forbidden by NeurIPS, but this kind of 
very engaging public advertising brings the anonymity violat
ion to another level.

Besides harming the double-blind revi
ew process, I am concerned by the social pressure it puts on
 reviewers. It is definitely harder to reject or even critic
ise a work that already received praise across the community
 through such advertising, especially when it comes from the
 account of a famous researcher or a famous institution.

Ho
wever, in recent Twitter discussions associated to these thr
eads, I failed to find people caring about these aspects, no
tably among top researchers reacting to the posts. Would you
 also say that this is fine (as, anyway, we cannot really as
sume that a review is double-blind when arXiv public preprin
ts with authors names and affiliations are allowed)? Or do y
ou agree that this can be a problem?"	"https://www.reddit.com/r/MachineLearning/comments/hbzd5o/d_on_the_public_advertising_of_neurips/"	"127"	"1592567690.0"	"480"	"hbzd5o"
9	"[R] NeurIPS 2020 Spotlight, AdaBelief optimizer, trains fast as Adam, generalize well as SGD, stable to train GAN."	"**Abstract**

Optimization is at the core of modern deep lea
rning. We propose AdaBelief optimizer to simultaneously achi
eve three goals: fast convergence as in adaptive methods, go
od generalization as in SGD, and training stability.

The in
tuition for AdaBelief is to adapt the stepsize according to 
the 'belief' in the current gradient direction. Viewing the 
exponential moving average (EMA) of the noisy gradient as th
e prediction of the gradient at the next time step, if the o
bserved gradient greatly deviates from the prediction, we di
strust the current observation and take a small step; if the
 observed gradient is close to the prediction, we trust it a
nd take a large step.

We validate AdaBelief in extensive ex
periments, showing that it outperforms other methods with fa
st convergence and high accuracy on image classification and
 language modeling. Specifically, on ImageNet, AdaBelief ach
ieves comparable accuracy to SGD. Furthermore, in the traini
ng of a GAN on Cifar10, AdaBelief demonstrates high stabilit
y and improves the quality of generated samples compared to 
a well-tuned Adam optimizer.

**Links**

Project page: [http
s://juntang-zhuang.github.io/adabelief/](https://juntang-zhu
ang.github.io/adabelief/)

Paper: [https://arxiv.org/abs/201
0.07468](https://arxiv.org/abs/2010.07468)

Code: [https://g
ithub.com/juntang-zhuang/Adabelief-Optimizer](https://github
.com/juntang-zhuang/Adabelief-Optimizer)

Videos on toy exam
ples: [https://www.youtube.com/playlist?list=PL7KkG3n9bER6Ym
MLrKJ5wocjlvP7aWoOu](https://www.youtube.com/playlist?list=P
L7KkG3n9bER6YmMLrKJ5wocjlvP7aWoOu)

**Discussion**

You are 
very welcome to post your thoughts here or at the github rep
o, email me, and collaborate on implementation or improvemen
t. ( Currently I only have extensively tested in PyTorch, th
e Tensorflow implementation is rather naive since I seldom u
se Tensorflow. )

**Results (Comparison with SGD, Adam, Adam
W, AdaBound, RAdam, Yogi, Fromage, MSVAG)**

1. Image Classi
fication

https://preview.redd.it/9b90n5iv9dt51.png?width=14
48&format=png&auto=webp&s=c7c843b9eb32b1ed6501a1ed8c08578a31
325427

2. GAN training

&#x200B;

https://preview.redd.it/h
zzyycyz9dt51.png?width=1372&format=png&auto=webp&s=4f439660d
bbf3fe03cb0a130fc8573677b0bc779

3. LSTM

https://preview.re
dd.it/bj3mc8r2adt51.png?width=1420&format=png&auto=webp&s=bb
268674e47006d1ee439015f3e7d0b32da2ba34

4. Toy examples

&#x
200B;

https://reddit.com/link/jc1fp2/video/3oy0cbr4adt51/pl
ayer"	"https://www.reddit.com/r/MachineLearning/comments/jc1fp2/r_neurips_2020_spotlight_adabelief_optimizer/"	"140"	"1602815151.0"	"451"	"jc1fp2"
10	"[D] The machine learning community has a toxicity problem"	"It is omnipresent!

**First** of all, the peer-review proces
s is *broken*. Every fourth NeurIPS submission is put on arX
iv. There are DeepMind researchers publicly going after revi
ewers who are criticizing their ICLR submission. On top of t
hat, papers by well-known institutes that were put on arXiv 
are accepted at top conferences, despite the reviewers agree
ing on rejection. In contrast, vice versa, some papers with 
a majority of accepts are overruled by the AC. (I don't want
 to call any names, just have a look the openreview page of 
this year's ICRL).

**Secondly,** there is a *reproducibilit
y crisis*. Tuning hyperparameters on the test set seem to be
 the standard practice nowadays. Papers that do not beat the
 current state-of-the-art method have a zero chance of getti
ng accepted at a good conference. As a result, hyperparamete
rs get tuned and subtle tricks implemented to observe a gain
 in performance where there isn't any.

**Thirdly,** there i
s a *worshiping* problem. Every paper with a Stanford or Dee
pMind affiliation gets praised like a breakthrough. For inst
ance, BERT has seven times more citations than ULMfit. The G
oogle affiliation gives so much credibility and visibility t
o a paper. At every ICML conference, there is a crowd of peo
ple in front of every DeepMind poster, regardless of the con
tent of the work. The same story happened with the Zoom meet
ings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had tw
ice as many submissions as ICML, even though both are top-ti
er ML conferences. Why? Why is the name 'neural' praised so 
much? Next, Bengio, Hinton, and LeCun are truly deep learnin
g pioneers but calling them the 'godfathers' of AI is insane
. It has reached the level of a cult.

**Fourthly**, the way
 Yann LeCun talked about biases and fairness topics was inse
nsitive. However, the *toxicity* and backlash that he receiv
ed are beyond any reasonable quantity. Getting rid of LeCun 
and silencing people won't solve any issue.

**Fifthly**, ma
chine learning, and computer science in general, have a huge
 *diversity problem*. At our CS faculty, only 30% of undergr
ads and 15% of the professors are women. Going on parental l
eave during a PhD or post-doc usually means the end of an ac
ademic career. However, this lack of diversity is often abus
ed as an excuse to shield certain people from any form of cr
iticism.  Reducing every negative comment in a scientific di
scussion to race and gender creates a toxic environment. Peo
ple are becoming afraid to engage in fear of being called a 
racist or sexist, which in turn reinforces the diversity pro
blem.

**Sixthly**, moral and ethics are set *arbitrarily*. 
The U.S. domestic politics dominate every discussion. At thi
s very moment, thousands of Uyghurs are put into concentrati
on camps based on computer vision algorithms invented by thi
s community, and nobody seems even remotely to care. Adding 
a 'broader impact' section at the end of every people will n
ot make this stop. There are huge shitstorms because a resea
rcher wasn't mentioned in an article. Meanwhile, the 1-billi
on+ people continent of Africa is virtually excluded from an
y meaningful ML discussion (besides a few Indaba workshops).


**Seventhly**, there is a cut-throat publish-or-perish *me
ntality*. If you don't publish 5+ NeurIPS/ICML papers per ye
ar, you are a looser. Research groups have become so large t
hat the PI does not even know the name of every PhD student 
anymore. Certain people submit 50+ papers per year to NeurIP
S. The sole purpose of writing a paper has become to having 
one more NeurIPS paper in your CV. Quality is secondary; pas
sing the peer-preview stage has become the primary objective
.

**Finally**, discussions have become *disrespectful*. Sch
midhuber calls Hinton a thief, Gebru calls LeCun a white sup
remacist, Anandkumar calls Marcus a sexist, everybody is und
er attack, but nothing is improved.

Albert Einstein was opp
osing the theory of [quantum mechanics](https://en.wikipedia
.org/wiki/Albert_Einstein#Einstein's_objections_to_quantum_m
echanics). Can we please stop demonizing those who do not sh
are our exact views. We are allowed to disagree without goin
g for the jugular. 

The moment we start silencing people be
cause of their opinion is the moment scientific and societal
 progress dies. 

Best intentions, Yusuf"	"https://www.reddit.com/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/"	"571"	"1593547579.0"	"3826"	"hiv3vf"
11	"[R] Google has a credit assignment problem in research"	"Google has some serious cultural problems with proper credit
 assignment. They continue to rename methods discovered earl
ier DESPITE admitting the existence of this work.

See this 
new paper they released:

[https://arxiv.org/abs/2006.14536]
(https://arxiv.org/abs/2006.14536)

Stop calling this method
 SWISH; its original name is SILU. The original Swish author
s from Google even admitted to this mistake in the past ([ht
tps://www.reddit.com/r/MachineLearning/comments/773epu/r\_sw
ish\_a\_selfgated\_activation\_function\_google/](https://ww
w.reddit.com/r/MachineLearning/comments/773epu/r_swish_a_sel
fgated_activation_function_google/)). And the worst part is 
this new paper has the very same senior author as the previo
us Google paper.

And just a couple weeks ago, the same issu
e again with the SimCLR paper. See thread here:

[https://ww
w.reddit.com/r/MachineLearning/comments/hbzd5o/d\_on\_the\_p
ublic\_advertising\_of\_neurips/fvcet9j/?utm\_source=share&u
tm\_medium=web2x](https://www.reddit.com/r/MachineLearning/c
omments/hbzd5o/d_on_the_public_advertising_of_neurips/fvcet9
j/?utm_source=share&utm_medium=web2x)

They site only cite p
rior work with the same idea in the last paragraph of their 
supplementary and yet again rename the method to remove its 
association to the prior work. This is unfair. Unfair to the
 community and especially unfair to the lesser known researc
hers who do not have the advertising power of Geoff Hinton a
nd Quoc Le on their papers.

SiLU/Swish is by Stefan Elfwing
, Eiji Uchibe, Kenji Doya ([https://arxiv.org/abs/1702.03118
](https://arxiv.org/abs/1702.03118)).

Original work of SimC
LR is by Mang Ye, Xu Zhang, Pong C. Yuen, Shih-Fu Chang ([ht
tps://arxiv.org/abs/1904.03436](https://arxiv.org/abs/1904.0
3436))

Update:

Dan Hendrycks and Kevin Gimpel also propose
d the SiLU non-linearity in 2016 in their work Gaussian Erro
r Linear Units (GELUs) ([https://arxiv.org/abs/1606.08415](h
ttps://arxiv.org/abs/1606.08415))

Update 2:

'Smooth Advers
arial Training' by Cihang Xie is only an example of the rena
ming issue because of issues in the past by Google to proper
ly assign credit. Cihang Xie's work is not the cause of this
 issue. Their paper does not claim to discover a new activat
ion function. They are only using the SiLU activation functi
on in some of their experiments under the name Swish. [Cihan
g Xie will provide an update of the activation function nami
ng used in the paper](https://www.reddit.com/r/MachineLearni
ng/comments/hkiyir/r\_google\_has\_a\_credit\_assignment\_pr
oblem\_in/fwtttqo?utm\_source=share&utm\_medium=web2x) to re
flect the correct naming. 

The cause of the issue is Google
 in the past decided to continue with renaming the activatio
n as [Swish despite being made aware of the method already h
aving the name SiLU](https://arxiv.org/abs/1710.05941). Now 
it is stuck in our research community and stuck in our ML li
braries (https://github.com/tensorflow/tensorflow/issues/410
66)."	"https://www.reddit.com/r/MachineLearning/comments/hkiyir/r_google_has_a_credit_assignment_problem_in/"	"127"	"1593782531.0"	"827"	"hkiyir"
12	"[D] Advanced courses update"	"EDIT Jan 2021 : I am still updating the list as of Jan, 2021
 and will most probably continue to do so for foreseeable fu
ture. So, please feel free to message me any courses you fin
d interesting that fit here.

- - -

We have a [PhD level or
 Advanced courses](https://www.reddit.com/r/MachineLearning/
comments/51qhc8/phdlevel_courses/) thread in the sidebar but
 it's three year old now. There were two other 7-8 month old
 threads ([1](https://www.reddit.com/r/MachineLearning/comme
nts/cae59l/d_advanced_courses_update/), [2](https://www.redd
it.com/r/MachineLearning/comments/cjnund/d_what_are_your_fav
orite_videos_lectures_on/)) but they don't have many quality
 responses either. 

So, can we have a new one here?

To rei
terate - CS231n, CS229, ones from Udemy etc are not advanced
. 

Advanced ML/DL/RL, attempts at building theory of DL, op
timization theory, advanced applications etc are some exampl
es of what I believe should belong here, much like the origi
nal sidebar post.

You can also suggest (new) categories for
 the courses you share. :)

- - -

Here are some courses we'
ve found so far. 

ML >> 

* [Learning Discrete Latent Struc
ture - sta4273/csc2547 Spring'18](https://duvenaud.github.io
/learn-discrete/)
* [Learning to Search - csc2547 Fall'19](h
ttps://duvenaud.github.io/learning-to-search/)
* [Scalable a
nd Flexible Models of Uncertainty - csc2541](https://csc2541
-f17.github.io/)
* [Fundamentals of Machine Learning Over Ne
tworks - ep3260](https://sites.google.com/view/mlons/home)
*
 [Machine Learning on Graphs - cs224w](http://web.stanford.e
du/class/cs224w/), [videos](https://www.youtube.com/playlist
?list=PL-Y8zK4dwCrQyASidb2mjj_itW2-YYx6-)
* [Mining Massive 
Data Sets - cs246](http://web.stanford.edu/class/cs246/index
.html)
* [Interactive Learning - cse599](https://courses.cs.
washington.edu/courses/cse599i/20wi/)
* [Machine Learning fo
r Sequential Decision Making Under Uncertainty - ee290s/cs19
4](https://inst.eecs.berkeley.edu/%7Eee290s/fa18/resources.h
tml)
* [Probabilistic Graphical Methods - 10-708](https://ww
w.cs.cmu.edu/~epxing/Class/10708-20/)
* [Introduction to Cau
sal Inference](https://www.bradyneal.com/causal-inference-co
urse)

ML >> Theory

* [Statistical Machine Learning - 10-70
2/36-702 with videos](https://www.stat.cmu.edu/~ryantibs/sta
tml/), [2016 videos](https://www.youtube.com/playlist?list=P
LTB9VQq8WiaCBK2XrtYn5t9uuPdsNm7YE)
* [Statistical Learning T
heory - cs229T/stats231 Stanford Autumn'18-19](http://web.st
anford.edu/class/cs229t/)
* [Statistical Learning Theory - c
s281b /stat241b UC Berkeley, Spring'14 ](https://www.stat.be
rkeley.edu/%7Ebartlett/courses/2014spring-cs281bstat241b/)
*
 [Statistical Learning Theory - csc2532 Uni of Toronto, Spri
ng'20](https://erdogdu.github.io/csc2532/)

ML >> Bayesian


* [Bayesian Data Analysis](https://github.com/avehtari/BDA_c
ourse_Aalto)
* [Bayesian Methods Research Group, Moscow](htt
ps://bayesgroup.ru/), Bayesian Methods in ML - [spring2020](
https://www.youtube.com/playlist?list=PLe5rNUydzV9TjW6dol0gV
dWpr02hBicS0), [fall2020](https://www.youtube.com/playlist?l
ist=PLe5rNUydzV9THZg7-QnaLhcccIbQ5eQm8)
* [Deep Learning and
 Bayesian Methods - summer school](http://deepbayes.ru), vid
eos available for 2019 version

ML >> Systems and Operations


* [Stanford MLSys Seminar Series](https://mlsys.stanford.e
du/)
* [Visual Computing Systems- cs348v](http://graphics.st
anford.edu/courses/cs348v-18-winter/) - Another systems cour
se that discusses hardware from a persepective of visual com
puting but is relevant to ML as well 
* [Advanced Machine Le
arning Systems - cs6787](https://www.cs.cornell.edu/courses/
cs6787/2019fa/) - lecture 9 and onwards discuss hardware sid
e of things
* [Machine Learning Systems Design - cs329S](htt
ps://stanford-cs329s.github.io/)
* [Topics in Deployable ML 
- 6.S979](https://people.csail.mit.edu/madry/6.S979/)
* [Mac
hine Learning in Production / AI Engineering (17-445/17-645/
17-745/11-695)](https://ckaestne.github.io/seai/)
* [AutoML 
- Automated Machine Learning](https://ki-campus.org/courses/
automl-luh2021)

DL >>

* [Deep Unsupervised Learning - cs29
4](https://sites.google.com/view/berkeley-cs294-158-sp20/hom
e)
* [Deep Multi-task and Meta learning - cs330](https://cs3
30.stanford.edu/)
* [Topics in Deep Learning - stat991 UPenn
/Wharton](https://github.com/dobriban/Topics-in-deep-learnin
g) *most chapters start with introductory topics and dig int
o advanced ones towards the end. 
* [Deep Generative Models 
- cs236](https://deepgenerativemodels.github.io/)
* [Deep Ge
ometric Learning of Big Data and Applications](https://www.i
pam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-l
earning-of-big-data-and-applications/?tab=overview)
* [Deep 
Implicit Layers - NeurIPS 2020 tutorial](http://implicit-lay
ers-tutorial.org/)

DL >> Theory

* [Topics course on Mathem
atics of Deep Learning - CSCI-GA 3033](https://joanbruna.git
hub.io/MathsDL-spring19/)
* [Topics Course on Deep Learning 
- stat212b](http://joanbruna.github.io/stat212b/)
* [Analyse
s of Deep Learning - stats385](https://stats385.github.io/),
 [videos from 2017 version](https://www.researchgate.net/pro
ject/Theories-of-Deep-Learning)
* [Mathematics of Deep Learn
ing](http://www.vision.jhu.edu/teaching/learning/deeplearnin
g19/)
* [Geometry of Deep Learning](https://www.microsoft.co
m/en-us/research/event/ai-institute-2019/)

RL >>

* [Meta-L
earning - ICML 2019 Tutorial](https://sites.google.com/view/
icml19metalearning) , [Metalearning: Applications to Data Mi
ning - google books link](https://books.google.com/books?id=
DfZDAAAAQBAJ&printsec=copyright&redir_esc=y#v=onepage&q&f=fa
lse)
* [Deep Multi-Task and Meta Learning - cs330](http://cs
330.stanford.edu/), [videos](https://www.youtube.com/playlis
t?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)
* [Deep Reinforce
ment Learning - cs285](http://rail.eecs.berkeley.edu/deeprlc
ourse/)
* [Advanced robotics - cs287](https://people.eecs.be
rkeley.edu/%7Epabbeel/cs287-fa19/)
* [Reinforcement Learning
 - cs234](https://web.stanford.edu/class/cs234/), [videos fo
r 2019 run](https://www.youtube.com/playlist?list=PLoROMvodv
4rOSOPzutgyCTapiGlY2Nd8u)
* [Reinforcement Learning Summer S
chool 2019: Bandits, RL & Deep RL](https://rlss.inria.fr/pro
gram/)

Optimization >> 

* [Convex Optimization I - ee364a]
(http://stanford.edu/class/ee364a/), has quite recent [video
s](https://www.youtube.com/playlist?list=PLdrixi40lpQm5ksInX
lRon1eRwq_gzIcw) too. 
[Convex Optimization II - ee364b](htt
p://web.stanford.edu/class/ee364b/), [2008 videos](https://w
ww.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&i
ndex=20)
* [Convex Optimization and Approximation - ee227c](
https://ee227c.github.io/)
* [Convex Optimization - ee227bt]
(https://people.eecs.berkeley.edu/%7Eelghaoui/Teaching/EE227
BT/index.html)
* [Variational Methods for Computer Vision](h
ttps://vision.in.tum.de/teaching/ws2013/vmcv2013)
* [Advance
d Optimization and Randomized Algorithms - 10-801](http://ww
w.cs.cmu.edu/%7Esuvrit/teach/index.html), [videos](https://w
ww.youtube.com/playlist?list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICx
t0d)
* [Optimization Methods for Machine Learning and Engine
ering - Karlsruhe Institute of Technology](https://www.youtu
be.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5)

Ap
plications >> Computer Vision

* [Computational Video Manipu
lation - cs448v](https://magrawala.github.io/cs448v-sp19/)
*
 [Advanced Topics in ML: Modeling and Segmentation of Multiv
ariate Mixed Data](http://www.vision.jhu.edu/teaching/learni
ng/learning10/)
* [TUM AI Guest lecture series](https://www.
youtube.com/playlist?list=PLQ8Y4kIIbzy8kMlz7cRqz-BjbdyWsfLXt
) - many influential researchers in DL, vision, graphics tal
k about latest advances and their latest works.
* [Advanced 
Deep Learning for Computer Vision - TUM ADL4CV](https://www.
youtube.com/playlist?list=PLog3nOPCjKBkngkkF552-Hiwa5t_ZeDnh
)
* [Detection, Segmentation and Tracking - TUM CV3DST](http
s://www.youtube.com/playlist?list=PLog3nOPCjKBneGyffEktlXXMf
v1OtKmCs)
* [Guest lectures at TUM Dynamic Vision and Learni
ng group](https://www.youtube.com/playlist?list=PLog3nOPCjKB
nAuymJ7uTysuG357zVn7et)
* [Vision Seminar at MIT](https://ww
w.youtube.com/channel/UCLMiFkFyfcNnZs6iwYLPI9g/videos)
* [Au
tonomous Vision Group, Talk@Tübingen Seminar](https://www.yo
utube.com/playlist?list=PLeCNfJWZKqxu-BwwcR4tDBOFNkJEOPWb_)


Applications >> Natural Language Processing

* [Natural Lan
guage Processing with Deep Learning - cs224n](http://web.sta
nford.edu/class/cs224n/) (* not sure if it belongs here, peo
ple working in NLP can help me out)
* [Neural networks for N
LP - cs11-747](http://www.phontron.com/class/nn4nlp2020/sche
dule.html)
* [Natural Language Understanding - cs224u](https
://web.stanford.edu/class/cs224u/), [video](https://www.yout
ube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

A
pplications >> 3D Graphics 

* [Non-Euclidean Methods in Mac
hine Learning - cs468, 2020](http://graphics.stanford.edu/co
urses/cs468-20-fall/schedule.html)
* [Machine Learning for 3
D Data - cs468, spring 2017](http://graphics.stanford.edu/co
urses/cs468-17-spring/schedule.html)
* [Data-Driven Shape An
alysis - cs468, 2014](http://graphics.stanford.edu/courses/c
s468-14-spring/)
* [Geometric Deep Learning](http://geometri
cdeeplearning.com/) - Not a course but the website links a f
ew tutorials on Geometric DL
* [Deep Learning for Computer G
raphics - SIGGRAPH 2019](https://geometry.cs.ucl.ac.uk/creat
iveai/)
* [Machine Learning for Machine Vision as Inverse Gr
aphics - csc2547 Winter'20](http://www.cs.utoronto.ca/~bonne
r/courses/2020s/csc2547/) 
* [Machine Learning Meets Geometr
y, winter 2020](https://geoml.github.io/schedule.html); [Mac
hine Learning for 3D Data, winter 2018](https://cse291-i.git
hub.io/WI18/schedule.html)

---

Edit: Upon suggestion, cate
gorized the courses. There might be some misclassifications 
as I'm not trained on this task ;). Added some good ones fro
m older (linked above) discussions."	"https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/"	"85"	"1583418496.0"	"826"	"fdw0ax"
13	"[D] Some interesting observations about machine learning publication practices from an outsider"	"I come from a traditional engineering field, and here is my 
observation about ML publication practice lately:

I have no
ticed that there are groups of researchers working on the in
tersection of 'old' fields such as optimization, control, si
gnal processing and the like, who will all of a sudden publi
sh a massive amount of paper that purports to solve a certai
n problem. The problem itself is usually recent and sometime
s involves some deep neural network.

However, upon close ex
amination, the only novelty is the problem (usually proposed
 by other unaffiliated groups) but not the method proposed b
y the researchers that purports to solve it.

I was puzzled 
by why a very large amount of seemingly weak papers, literal
ly rehashing (occasionally, well-known) techniques from the 
1980s or even 60s are getting accepted, and I noticed the fo
llowing recipe:

1. **Only ML conferences.** These groups of
 researchers will only ever publish in machine learning conf
erences (and not to optimization and control conferences/jou
rnals, where the heart of their work might actually lie). Fo
r example, on a paper about adversarial machine learning, th
e entire paper was actually about solving an optimization pr
oblem, but the optimization routine is basically a slight va
riation of other well studied methods. ***Update***: I also 
noticed that if a paper does not go through NeurIPS or ICLR,
 they will be directly sent to AAAI and some other smaller n
ame conferences, where they will be accepted. So nothing goe
s to waste in this field.
2. **Peers don't know what's going
 on.** Through openreview, I found that the reviewers (not j
ust the researchers) are uninformed about their particular a
rea, and only seem to comment on the correctness of the pape
r, but not the novelty. In fact, I doubt the reviewers thems
elves know about the novelty of the method. ***Update***: by
 novelty I meant how novel it is with respect to the state-o
f-the-art of a certain technique, especially when it interse
cts with operations research, optimization, control, signal 
processing. The state-of-the-art *could be* far ahead than w
hat mainstream ML folks know about.
3. **Poor citation pract
ices.** Usually the researchers will only cite themselves or
 other 'machine learning people' (whatever this means) from 
the last couple of years. Occasionally, there will be 1 cita
tion from hundreds of years ago attributed to Cauchy, Newton
, Fourier, Cournot, Turing, Von Neumann and the like, and th
en a hundred year jump to 2018 or 2019. I see, 'This problem
 was studied by *some big name* in 1930 and *Random Guy XYZ*
 in 2018' a lot.
4. **Wall of math.** Frequently, there will
 be a massive wall of math, proving some esoteric condition 
on the eigenvalue, gradient, Jacobian, and other curious thi
ngs about their problem (under other esoteric assumptions). 
There will be several theorems, none of which are applicable
 because the moment they run their highly non-convex deep le
arning application, all conditions are violated. Hence the o
nly thing obtained from these intricate theorems + math wall
 are some faint intuition (which are violated immediately). 
And then nothing is said. 

***Update***: If I could add one
 more, it would be that certain techniques, after being prop
osed, and after the authors claim that it beats a lot of ben
chmarks, will be seemingly be abandoned and never used again
. ML researchers seem to like to jump around topics a lot, s
o that might be a factor. But usually in other fields, once 
a technique is proposed, it is refined by the same group of 
researchers over many years, sometimes over the course of a 
researcher's career.

In some ways, this makes certain area 
of ML sort of an echo chamber, where researchers are pushing
 through a large amount of known results rehashed and somewh
at disguised by the novelty of their problem and these paper
s are all getting accepted because no one can detect the lac
k of novelty (or when they do detect, it is only 1 guy out o
f 3 reviewers). I just feel like ML conferences are sort of 
being treated as some sort of automatic paper acceptance cas
h cow.

Just my two cents coming from outside of ML. My obse
rvation does not apply to all fields of ML."	"https://www.reddit.com/r/MachineLearning/comments/lvwt3l/d_some_interesting_observations_about_machine/"	"171"	"1614671503.0"	"659"	"lvwt3l"
14	"[D] Calling out the authors of 'Trajformer' paper for claiming they published code but never doing it"	"I read a paper from NeurIPS 2020 titled 'Trajformer: Traject
ory Prediction with Local Self-Attentive Contexts for Autono
mous Driving'. I found it interesting and the authors claim 
multiple times in the paper that 'we release our code at '[h
ttps://github.com/Manojbhat09/Trajformer](https://github.com
/Manojbhat09/Trajformer)'. Turns out they never did, fine, I
 thought perhaps they will in the future and starred the rep
o to check it out later.

Many others raised issues asking f
or update on code release and they never replied. Finally, i
t April they update the readme to say that they will release
 the code and that's been the last update.

I know this is a
 common trend in ML papers now, but what sucks is that I ema
iled the authors (both the grad student and the PI) multiple
 times asking for an update an they never replied. Their pap
er is literally based on empirical improvements and without 
working code to replicate the results it is their word again
st mine.

I strongly think things have to change, and I beli
eve they only will if we call them out. I waited long enough
, and made significant effort to contact the authors with no
 response. I mean I don't mind them not releasing their code
, but at least don't claim that you did in the paper/review 
phase and then disappear. An undergrad in my lab asked why s
he should take time to clean up the code and document it bef
ore release while others just move on to the next interestin
g project and I don't have an answer. "	"https://www.reddit.com/r/MachineLearning/comments/qrbkc7/d_calling_out_the_authors_of_trajformer_paper_for/"	"90"	"1636600691.0"	"549"	"qrbkc7"
15	"[D] NeurIPS 2019 Bengio Schmidhuber Meta-Learning Fiasco"	"The recent reddit post [Yoshua Bengio talks about what's nex
t for deep learning](https://www.reddit.com/r/MachineLearnin
g/comments/e92dp5/d_yoshua_bengio_talks_about_whats_next_for
_deep/) links to an interview with Bengio. User u/panties_in
_my_ass got many upvotes for this comment: 

>Spectrum: What
's the key to that kind of adaptability?***  
>  
>Bengio: [
Meta-learning](https://arxiv.org/pdf/1905.03030.pdf) is a ve
ry hot topic these days: Learning to learn. I wrote an [earl
y paper on this](http://bengio.abracadoudou.com/publications
/pdf/bengio_1991_ijcnn.pdf) in 1991, but only recently did w
e get the computational power to implement this kind of thin
g.  
>  
>Somewhere, on some laptop, Schmidhuber is screamin
g at his monitor right now.

because he introduced meta-lear
ning 4 years before Bengio: 

Jürgen Schmidhuber. Evolutiona
ry principles in self-referential learning, or on learning h
ow to learn: The meta-meta-... hook. Diploma thesis, Tech Un
iv. Munich, 1987.

Then Bengio gave his [NeurIPS 2019 talk](
https://slideslive.com/38921750/from-system-1-deep-learning-
to-system-2-deep-learning). Slide 71 says:

>Meta-learning o
r learning to learn (Bengio et al 1991; Schmidhuber 1992)

u
/y0hun commented:

>What a childish slight... The Schmidhube
r 1987 paper is clearly labeled and established and as a nas
ty slight he juxtaposes his paper against Schmidhuber with h
is preceding it by a year almost doing the opposite of givin
g him credit.

I detect a broader pattern here. Look at this
 highly upvoted post: [Jürgen Schmidhuber really had GANs in
 1990](https://www.reddit.com/r/MachineLearning/comments/djj
u8a/d_jurgen_schmidhuber_really_had_gans_in_1990/), 25 years
 before Bengio. u/siddarth2947 commented that

>GANs were ac
tually mentioned in the Turing laudation, it's both funny an
d sad that Yoshua Bengio got a Turing award for a principle 
that Jurgen invented decades before him

and that section 3 
of Schmidhuber's [post on their miraculous year 1990-1991](h
ttp://people.idsia.ch/~juergen/deep-learning-miraculous-year
-1990-1991.html) is actually about his former student Sepp H
ochreiter and Bengio:

> (In 1994, others published results 
[VAN2] essentially identical to the 1991 vanishing gradient 
results of Sepp [VAN1]. Even after a common publication [VAN
3], the first author of reference [VAN2] published papers (e
.g., [VAN4]) that cited only his own 1994 paper but not Sepp
's original work.)

So Bengio republished at least 3 importa
nt ideas from Schmidhuber's lab without giving credit: meta-
learning, vanishing gradients, GANs. What's going on?"	"https://www.reddit.com/r/MachineLearning/comments/ea2gap/d_neurips_2019_bengio_schmidhuber_metalearning/"	"170"	"1576233717.0"	"547"	"ea2gap"
16	"[R] Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/eilmxki09bd61.png"	"3"	"1611507295.0"	"515"	"l432gk"
17	"[R] A List of Best Papers from Top AI Conferences in 2020"	"Sharing a list of award-winning papers from this year's top 
conferences for anyone interested in catching up on the late
st machine learning research before the end of the year :)


**AAAI 2020**

* Best Paper: WinoGrande: An Adversarial Wino
grad Schema Challenge at Scale \[[Paper](https://arxiv.org/a
bs/1907.10641)\]
* Honorable Mention: A Unifying View on Ind
ividual Bounds and Heuristic Inaccuracies in Bidirectional S
earch \[[Paper](https://ojs.aaai.org//index.php/AAAI/article
/view/5611)\]

**CVPR 2020** 

* Best Paper: Unsupervised Le
arning of Probably Symmetric Deformable 3D Objects from Imag
es in the Wild \[[Paper](https://arxiv.org/pdf/1911.11130.pd
f)\] \[[Presentation](https://crossminds.ai/video/5ee96b86b1
267e24b0ec2354/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**
ACL 2020**

* Best Paper: Beyond Accuracy: Behavioral Testin
g of NLP Models with CheckList \[[Paper](https://www.aclweb.
org/anthology/2020.acl-main.442.pdf)\] \[[Video](https://cro
ssminds.ai/video/5f454437e1acdc4d12c4186e/?playlist_id=5fe2e
2ea56dab51eaff52eaf)\] 

**ICML 2020**

* Best Paper: On Lea
rning Sets of Symmetric Elements \[[Paper](https://arxiv.org
/abs/2002.08599)\]  \[[Presentation](https://icml.cc/virtual
/2020/poster/6022)\] 
* Best Paper: Tuning-free Plug-and-Pla
y Proximal Algorithm for Inverse Imaging Problems \[[Paper](
https://arxiv.org/abs/2012.05703)\]  \[[Presentation](https:
//icml.cc/virtual/2020/poster/6447)\] 
* Honorable Mention: 
Efficiently sampling functions from Gaussian process posteri
ors  \[[Paper](https://arxiv.org/abs/2002.09309)\]  \[[Prese
ntation](https://crossminds.ai/video/5f189c96c01f1dd70811ebe
f/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Honorable Ment
ion: Generative Pretraining From Pixels \[[Paper](https://cd
n.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pd
f)\]  \[[Presentation](https://crossminds.ai/video/5f0e0b67d
8b7c2e383e1077b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

*
*ECCV 2020**

* Best Paper: RAFT: Recurrent All-Pairs Field 
Transforms for Optical Flow \[[Paper](https://arxiv.org/abs/
2003.12039)\] \[[Video](https://crossminds.ai/video/5f5acf7f
7fa4bb2ca9d64e4d/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
*
 Honorable Mention: Towards Streaming Perception \[[Paper](h
ttps://arxiv.org/abs/2005.10420)\] \[[Presentation](https://
crossminds.ai/video/5f44390ae1acdc4d12c417e3/?playlist_id=5f
e2e2ea56dab51eaff52eaf)\] 
* Honorable Mention: NeRF: Repres
enting Scenes as Neural Radiance Fields for View Synthesis \
[[Paper](https://arxiv.org/abs/2003.08934)\] \[[Presentation
](https://crossminds.ai/video/5f3b294f96cfcc9d075e35b6/?play
list_id=5fe2e2ea56dab51eaff52eaf)\] 

**ICRA 2020**

* Best 
Paper: Preference-Based Learning for Exoskeleton Gait Optimi
zation \[[Paper](https://arxiv.org/abs/1909.12316)\] \[[Pres
entation](https://crossminds.ai/video/5f65488303c0894581947a
6b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Paper in
 Robot Vision: Graduated Non-Convexity for Robust Spatial Pe
rception: From Non-Minimal Solvers to Global Outlier Rejecti
on \[[Paper](https://arxiv.org/abs/1909.08605)\] \[[Presenta
tion](https://crossminds.ai/video/5f63f6c403c089458194705f/?
playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**CoRL 2020**

* B
est Paper: Learning Latent Representations to Influence Mult
i-Agent Interaction \[[Paper](https://arxiv.org/abs/2011.066
19)\] \[[Presentation](https://crossminds.ai/video/5fd9782a0
8be4fa7f41eabfe/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* 
Best Paper Presentation: Accelerating Reinforcement Learning
 with Learned Skill Priors \[[Paper](https://arxiv.org/abs/2
010.11944)\] \[[Presentation](https://crossminds.ai/video/5f
d9794308be4fa7f41eac54/?playlist_id=5fe2e2ea56dab51eaff52eaf
)\] 
* Best System Paper: SMARTS: An Open-Source Scalable Mu
lti-Agent RL Training School for Autonomous Driving \[[Paper
](https://arxiv.org/abs/2010.09776)\] \[[Presentation](https
://crossminds.ai/video/5fd9791f08be4fa7f41eac48/?playlist_id
=5fe2e2ea56dab51eaff52eaf)\] 

**RecSys 2020**

* Best Long 
Paper: Progressive Layered Extraction (PLE): A Novel Multi-T
ask Learning (MTL) Model for Personalized Recommendations \[
[Paper](https://github.com/guyulongcs/Awesome-Deep-Learning-
Papers-for-Search-Recommendation-Advertising/blob/master/0_N
ew_Papers_in_2020/2020%20%28Tencent%29%20%28Recsys%29%20%5BP
LE%5D%20Progressive%20Layered%20Extraction%20%28PLE%29%20-%2
0A%20Novel%20Multi-Task%20Learning%20%28MTL%29%20Model%20for
%20Personalized%20Recommendations.pdf)\] \[[Presentation](ht
tps://crossminds.ai/video/5f7fc247d81cf36f1a8e379c/?playlist
_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Short Paper: ADER: A
daptively Distilled Exemplar Replay Towards Continual Learni
ng for Session-based Recommendation \[[Paper](https://arxiv.
org/abs/2007.12000)\] \[[Presentation](https://crossminds.ai
/video/5f7fc27ad81cf36f1a8e37b6/?playlist_id=5fe2e2ea56dab51
eaff52eaf)\] 

**NeurIPS 2020**

* Best Paper: Language Mode
ls are Few-Shot Learners \[[Paper](https://arxiv.org/abs/200
5.14165)\] \[[Video](https://crossminds.ai/video/5f3179536d7
639fd8a7fc06a/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Be
st Paper: No-Regret Learning Dynamics for Extensive-Form Cor
related Equilibrium \[[Paper](https://arxiv.org/abs/2004.006
03)\] 
* Best Paper: Improved Guarantees and a Multiple-Desc
ent Curve for Column Subset Selection and the Nyström Method
 \[[Paper](https://arxiv.org/abs/2002.09073)\]

Here is a co
mprehensive collection of [research talks from all major AI 
conferences](https://crossminds.ai/c/conference/) this year 
if you'd like to explore further."	"https://www.reddit.com/r/MachineLearning/comments/knai5q/r_a_list_of_best_papers_from_top_ai_conferences/"	"48"	"1609361402.0"	"501"	"knai5q"
18	"[D] On the public advertising of NeurIPS submissions on Twitter"	"The deadline for submitting papers to the NeurIPS 2020 confe
rence was two weeks ago. Since then, almost everyday I come 
across long Twitter threads from ML researchers that publicl
y advertise their work (obviously NeurIPS submissions, from 
the template and date of the shared arXiv preprint). They ar
e often quite famous researchers from Google, Facebook... wi
th thousands of followers and therefore a high visibility on
 Twitter. These posts often get a lot of likes and retweets 
- see examples in comment.

While I am glad to discover new 
exciting works, I am also concerned by the impact of such pr
actice on the review process. I know that submissions of arX
iv preprints are not forbidden by NeurIPS, but this kind of 
very engaging public advertising brings the anonymity violat
ion to another level.

Besides harming the double-blind revi
ew process, I am concerned by the social pressure it puts on
 reviewers. It is definitely harder to reject or even critic
ise a work that already received praise across the community
 through such advertising, especially when it comes from the
 account of a famous researcher or a famous institution.

Ho
wever, in recent Twitter discussions associated to these thr
eads, I failed to find people caring about these aspects, no
tably among top researchers reacting to the posts. Would you
 also say that this is fine (as, anyway, we cannot really as
sume that a review is double-blind when arXiv public preprin
ts with authors names and affiliations are allowed)? Or do y
ou agree that this can be a problem?"	"https://www.reddit.com/r/MachineLearning/comments/hbzd5o/d_on_the_public_advertising_of_neurips/"	"127"	"1592567690.0"	"477"	"hbzd5o"
19	"[R] NeurIPS 2020 Spotlight, AdaBelief optimizer, trains fast as Adam, generalize well as SGD, stable to train GAN."	"**Abstract**

Optimization is at the core of modern deep lea
rning. We propose AdaBelief optimizer to simultaneously achi
eve three goals: fast convergence as in adaptive methods, go
od generalization as in SGD, and training stability.

The in
tuition for AdaBelief is to adapt the stepsize according to 
the 'belief' in the current gradient direction. Viewing the 
exponential moving average (EMA) of the noisy gradient as th
e prediction of the gradient at the next time step, if the o
bserved gradient greatly deviates from the prediction, we di
strust the current observation and take a small step; if the
 observed gradient is close to the prediction, we trust it a
nd take a large step.

We validate AdaBelief in extensive ex
periments, showing that it outperforms other methods with fa
st convergence and high accuracy on image classification and
 language modeling. Specifically, on ImageNet, AdaBelief ach
ieves comparable accuracy to SGD. Furthermore, in the traini
ng of a GAN on Cifar10, AdaBelief demonstrates high stabilit
y and improves the quality of generated samples compared to 
a well-tuned Adam optimizer.

**Links**

Project page: [http
s://juntang-zhuang.github.io/adabelief/](https://juntang-zhu
ang.github.io/adabelief/)

Paper: [https://arxiv.org/abs/201
0.07468](https://arxiv.org/abs/2010.07468)

Code: [https://g
ithub.com/juntang-zhuang/Adabelief-Optimizer](https://github
.com/juntang-zhuang/Adabelief-Optimizer)

Videos on toy exam
ples: [https://www.youtube.com/playlist?list=PL7KkG3n9bER6Ym
MLrKJ5wocjlvP7aWoOu](https://www.youtube.com/playlist?list=P
L7KkG3n9bER6YmMLrKJ5wocjlvP7aWoOu)

**Discussion**

You are 
very welcome to post your thoughts here or at the github rep
o, email me, and collaborate on implementation or improvemen
t. ( Currently I only have extensively tested in PyTorch, th
e Tensorflow implementation is rather naive since I seldom u
se Tensorflow. )

**Results (Comparison with SGD, Adam, Adam
W, AdaBound, RAdam, Yogi, Fromage, MSVAG)**

1. Image Classi
fication

https://preview.redd.it/9b90n5iv9dt51.png?width=14
48&format=png&auto=webp&s=c7c843b9eb32b1ed6501a1ed8c08578a31
325427

2. GAN training

&#x200B;

https://preview.redd.it/h
zzyycyz9dt51.png?width=1372&format=png&auto=webp&s=4f439660d
bbf3fe03cb0a130fc8573677b0bc779

3. LSTM

https://preview.re
dd.it/bj3mc8r2adt51.png?width=1420&format=png&auto=webp&s=bb
268674e47006d1ee439015f3e7d0b32da2ba34

4. Toy examples

&#x
200B;

https://reddit.com/link/jc1fp2/video/3oy0cbr4adt51/pl
ayer"	"https://www.reddit.com/r/MachineLearning/comments/jc1fp2/r_neurips_2020_spotlight_adabelief_optimizer/"	"140"	"1602815151.0"	"454"	"jc1fp2"
20	"[D] The machine learning community has a toxicity problem"	"It is omnipresent!

**First** of all, the peer-review proces
s is *broken*. Every fourth NeurIPS submission is put on arX
iv. There are DeepMind researchers publicly going after revi
ewers who are criticizing their ICLR submission. On top of t
hat, papers by well-known institutes that were put on arXiv 
are accepted at top conferences, despite the reviewers agree
ing on rejection. In contrast, vice versa, some papers with 
a majority of accepts are overruled by the AC. (I don't want
 to call any names, just have a look the openreview page of 
this year's ICRL).

**Secondly,** there is a *reproducibilit
y crisis*. Tuning hyperparameters on the test set seem to be
 the standard practice nowadays. Papers that do not beat the
 current state-of-the-art method have a zero chance of getti
ng accepted at a good conference. As a result, hyperparamete
rs get tuned and subtle tricks implemented to observe a gain
 in performance where there isn't any.

**Thirdly,** there i
s a *worshiping* problem. Every paper with a Stanford or Dee
pMind affiliation gets praised like a breakthrough. For inst
ance, BERT has seven times more citations than ULMfit. The G
oogle affiliation gives so much credibility and visibility t
o a paper. At every ICML conference, there is a crowd of peo
ple in front of every DeepMind poster, regardless of the con
tent of the work. The same story happened with the Zoom meet
ings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had tw
ice as many submissions as ICML, even though both are top-ti
er ML conferences. Why? Why is the name 'neural' praised so 
much? Next, Bengio, Hinton, and LeCun are truly deep learnin
g pioneers but calling them the 'godfathers' of AI is insane
. It has reached the level of a cult.

**Fourthly**, the way
 Yann LeCun talked about biases and fairness topics was inse
nsitive. However, the *toxicity* and backlash that he receiv
ed are beyond any reasonable quantity. Getting rid of LeCun 
and silencing people won't solve any issue.

**Fifthly**, ma
chine learning, and computer science in general, have a huge
 *diversity problem*. At our CS faculty, only 30% of undergr
ads and 15% of the professors are women. Going on parental l
eave during a PhD or post-doc usually means the end of an ac
ademic career. However, this lack of diversity is often abus
ed as an excuse to shield certain people from any form of cr
iticism.  Reducing every negative comment in a scientific di
scussion to race and gender creates a toxic environment. Peo
ple are becoming afraid to engage in fear of being called a 
racist or sexist, which in turn reinforces the diversity pro
blem.

**Sixthly**, moral and ethics are set *arbitrarily*. 
The U.S. domestic politics dominate every discussion. At thi
s very moment, thousands of Uyghurs are put into concentrati
on camps based on computer vision algorithms invented by thi
s community, and nobody seems even remotely to care. Adding 
a 'broader impact' section at the end of every people will n
ot make this stop. There are huge shitstorms because a resea
rcher wasn't mentioned in an article. Meanwhile, the 1-billi
on+ people continent of Africa is virtually excluded from an
y meaningful ML discussion (besides a few Indaba workshops).


**Seventhly**, there is a cut-throat publish-or-perish *me
ntality*. If you don't publish 5+ NeurIPS/ICML papers per ye
ar, you are a looser. Research groups have become so large t
hat the PI does not even know the name of every PhD student 
anymore. Certain people submit 50+ papers per year to NeurIP
S. The sole purpose of writing a paper has become to having 
one more NeurIPS paper in your CV. Quality is secondary; pas
sing the peer-preview stage has become the primary objective
.

**Finally**, discussions have become *disrespectful*. Sch
midhuber calls Hinton a thief, Gebru calls LeCun a white sup
remacist, Anandkumar calls Marcus a sexist, everybody is und
er attack, but nothing is improved.

Albert Einstein was opp
osing the theory of [quantum mechanics](https://en.wikipedia
.org/wiki/Albert_Einstein#Einstein's_objections_to_quantum_m
echanics). Can we please stop demonizing those who do not sh
are our exact views. We are allowed to disagree without goin
g for the jugular. 

The moment we start silencing people be
cause of their opinion is the moment scientific and societal
 progress dies. 

Best intentions, Yusuf"	"https://www.reddit.com/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/"	"571"	"1593547579.0"	"3835"	"hiv3vf"
21	"[R] Google has a credit assignment problem in research"	"Google has some serious cultural problems with proper credit
 assignment. They continue to rename methods discovered earl
ier DESPITE admitting the existence of this work.

See this 
new paper they released:

[https://arxiv.org/abs/2006.14536]
(https://arxiv.org/abs/2006.14536)

Stop calling this method
 SWISH; its original name is SILU. The original Swish author
s from Google even admitted to this mistake in the past ([ht
tps://www.reddit.com/r/MachineLearning/comments/773epu/r\_sw
ish\_a\_selfgated\_activation\_function\_google/](https://ww
w.reddit.com/r/MachineLearning/comments/773epu/r_swish_a_sel
fgated_activation_function_google/)). And the worst part is 
this new paper has the very same senior author as the previo
us Google paper.

And just a couple weeks ago, the same issu
e again with the SimCLR paper. See thread here:

[https://ww
w.reddit.com/r/MachineLearning/comments/hbzd5o/d\_on\_the\_p
ublic\_advertising\_of\_neurips/fvcet9j/?utm\_source=share&u
tm\_medium=web2x](https://www.reddit.com/r/MachineLearning/c
omments/hbzd5o/d_on_the_public_advertising_of_neurips/fvcet9
j/?utm_source=share&utm_medium=web2x)

They site only cite p
rior work with the same idea in the last paragraph of their 
supplementary and yet again rename the method to remove its 
association to the prior work. This is unfair. Unfair to the
 community and especially unfair to the lesser known researc
hers who do not have the advertising power of Geoff Hinton a
nd Quoc Le on their papers.

SiLU/Swish is by Stefan Elfwing
, Eiji Uchibe, Kenji Doya ([https://arxiv.org/abs/1702.03118
](https://arxiv.org/abs/1702.03118)).

Original work of SimC
LR is by Mang Ye, Xu Zhang, Pong C. Yuen, Shih-Fu Chang ([ht
tps://arxiv.org/abs/1904.03436](https://arxiv.org/abs/1904.0
3436))

Update:

Dan Hendrycks and Kevin Gimpel also propose
d the SiLU non-linearity in 2016 in their work Gaussian Erro
r Linear Units (GELUs) ([https://arxiv.org/abs/1606.08415](h
ttps://arxiv.org/abs/1606.08415))

Update 2:

'Smooth Advers
arial Training' by Cihang Xie is only an example of the rena
ming issue because of issues in the past by Google to proper
ly assign credit. Cihang Xie's work is not the cause of this
 issue. Their paper does not claim to discover a new activat
ion function. They are only using the SiLU activation functi
on in some of their experiments under the name Swish. [Cihan
g Xie will provide an update of the activation function nami
ng used in the paper](https://www.reddit.com/r/MachineLearni
ng/comments/hkiyir/r\_google\_has\_a\_credit\_assignment\_pr
oblem\_in/fwtttqo?utm\_source=share&utm\_medium=web2x) to re
flect the correct naming. 

The cause of the issue is Google
 in the past decided to continue with renaming the activatio
n as [Swish despite being made aware of the method already h
aving the name SiLU](https://arxiv.org/abs/1710.05941). Now 
it is stuck in our research community and stuck in our ML li
braries (https://github.com/tensorflow/tensorflow/issues/410
66)."	"https://www.reddit.com/r/MachineLearning/comments/hkiyir/r_google_has_a_credit_assignment_problem_in/"	"127"	"1593782531.0"	"827"	"hkiyir"
22	"[D] Advanced courses update"	"EDIT Jan 2021 : I am still updating the list as of Jan, 2021
 and will most probably continue to do so for foreseeable fu
ture. So, please feel free to message me any courses you fin
d interesting that fit here.

- - -

We have a [PhD level or
 Advanced courses](https://www.reddit.com/r/MachineLearning/
comments/51qhc8/phdlevel_courses/) thread in the sidebar but
 it's three year old now. There were two other 7-8 month old
 threads ([1](https://www.reddit.com/r/MachineLearning/comme
nts/cae59l/d_advanced_courses_update/), [2](https://www.redd
it.com/r/MachineLearning/comments/cjnund/d_what_are_your_fav
orite_videos_lectures_on/)) but they don't have many quality
 responses either. 

So, can we have a new one here?

To rei
terate - CS231n, CS229, ones from Udemy etc are not advanced
. 

Advanced ML/DL/RL, attempts at building theory of DL, op
timization theory, advanced applications etc are some exampl
es of what I believe should belong here, much like the origi
nal sidebar post.

You can also suggest (new) categories for
 the courses you share. :)

- - -

Here are some courses we'
ve found so far. 

ML >> 

* [Learning Discrete Latent Struc
ture - sta4273/csc2547 Spring'18](https://duvenaud.github.io
/learn-discrete/)
* [Learning to Search - csc2547 Fall'19](h
ttps://duvenaud.github.io/learning-to-search/)
* [Scalable a
nd Flexible Models of Uncertainty - csc2541](https://csc2541
-f17.github.io/)
* [Fundamentals of Machine Learning Over Ne
tworks - ep3260](https://sites.google.com/view/mlons/home)
*
 [Machine Learning on Graphs - cs224w](http://web.stanford.e
du/class/cs224w/), [videos](https://www.youtube.com/playlist
?list=PL-Y8zK4dwCrQyASidb2mjj_itW2-YYx6-)
* [Mining Massive 
Data Sets - cs246](http://web.stanford.edu/class/cs246/index
.html)
* [Interactive Learning - cse599](https://courses.cs.
washington.edu/courses/cse599i/20wi/)
* [Machine Learning fo
r Sequential Decision Making Under Uncertainty - ee290s/cs19
4](https://inst.eecs.berkeley.edu/%7Eee290s/fa18/resources.h
tml)
* [Probabilistic Graphical Methods - 10-708](https://ww
w.cs.cmu.edu/~epxing/Class/10708-20/)
* [Introduction to Cau
sal Inference](https://www.bradyneal.com/causal-inference-co
urse)

ML >> Theory

* [Statistical Machine Learning - 10-70
2/36-702 with videos](https://www.stat.cmu.edu/~ryantibs/sta
tml/), [2016 videos](https://www.youtube.com/playlist?list=P
LTB9VQq8WiaCBK2XrtYn5t9uuPdsNm7YE)
* [Statistical Learning T
heory - cs229T/stats231 Stanford Autumn'18-19](http://web.st
anford.edu/class/cs229t/)
* [Statistical Learning Theory - c
s281b /stat241b UC Berkeley, Spring'14 ](https://www.stat.be
rkeley.edu/%7Ebartlett/courses/2014spring-cs281bstat241b/)
*
 [Statistical Learning Theory - csc2532 Uni of Toronto, Spri
ng'20](https://erdogdu.github.io/csc2532/)

ML >> Bayesian


* [Bayesian Data Analysis](https://github.com/avehtari/BDA_c
ourse_Aalto)
* [Bayesian Methods Research Group, Moscow](htt
ps://bayesgroup.ru/), Bayesian Methods in ML - [spring2020](
https://www.youtube.com/playlist?list=PLe5rNUydzV9TjW6dol0gV
dWpr02hBicS0), [fall2020](https://www.youtube.com/playlist?l
ist=PLe5rNUydzV9THZg7-QnaLhcccIbQ5eQm8)
* [Deep Learning and
 Bayesian Methods - summer school](http://deepbayes.ru), vid
eos available for 2019 version

ML >> Systems and Operations


* [Stanford MLSys Seminar Series](https://mlsys.stanford.e
du/)
* [Visual Computing Systems- cs348v](http://graphics.st
anford.edu/courses/cs348v-18-winter/) - Another systems cour
se that discusses hardware from a persepective of visual com
puting but is relevant to ML as well 
* [Advanced Machine Le
arning Systems - cs6787](https://www.cs.cornell.edu/courses/
cs6787/2019fa/) - lecture 9 and onwards discuss hardware sid
e of things
* [Machine Learning Systems Design - cs329S](htt
ps://stanford-cs329s.github.io/)
* [Topics in Deployable ML 
- 6.S979](https://people.csail.mit.edu/madry/6.S979/)
* [Mac
hine Learning in Production / AI Engineering (17-445/17-645/
17-745/11-695)](https://ckaestne.github.io/seai/)
* [AutoML 
- Automated Machine Learning](https://ki-campus.org/courses/
automl-luh2021)

DL >>

* [Deep Unsupervised Learning - cs29
4](https://sites.google.com/view/berkeley-cs294-158-sp20/hom
e)
* [Deep Multi-task and Meta learning - cs330](https://cs3
30.stanford.edu/)
* [Topics in Deep Learning - stat991 UPenn
/Wharton](https://github.com/dobriban/Topics-in-deep-learnin
g) *most chapters start with introductory topics and dig int
o advanced ones towards the end. 
* [Deep Generative Models 
- cs236](https://deepgenerativemodels.github.io/)
* [Deep Ge
ometric Learning of Big Data and Applications](https://www.i
pam.ucla.edu/programs/workshops/workshop-iv-deep-geometric-l
earning-of-big-data-and-applications/?tab=overview)
* [Deep 
Implicit Layers - NeurIPS 2020 tutorial](http://implicit-lay
ers-tutorial.org/)

DL >> Theory

* [Topics course on Mathem
atics of Deep Learning - CSCI-GA 3033](https://joanbruna.git
hub.io/MathsDL-spring19/)
* [Topics Course on Deep Learning 
- stat212b](http://joanbruna.github.io/stat212b/)
* [Analyse
s of Deep Learning - stats385](https://stats385.github.io/),
 [videos from 2017 version](https://www.researchgate.net/pro
ject/Theories-of-Deep-Learning)
* [Mathematics of Deep Learn
ing](http://www.vision.jhu.edu/teaching/learning/deeplearnin
g19/)
* [Geometry of Deep Learning](https://www.microsoft.co
m/en-us/research/event/ai-institute-2019/)

RL >>

* [Meta-L
earning - ICML 2019 Tutorial](https://sites.google.com/view/
icml19metalearning) , [Metalearning: Applications to Data Mi
ning - google books link](https://books.google.com/books?id=
DfZDAAAAQBAJ&printsec=copyright&redir_esc=y#v=onepage&q&f=fa
lse)
* [Deep Multi-Task and Meta Learning - cs330](http://cs
330.stanford.edu/), [videos](https://www.youtube.com/playlis
t?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)
* [Deep Reinforce
ment Learning - cs285](http://rail.eecs.berkeley.edu/deeprlc
ourse/)
* [Advanced robotics - cs287](https://people.eecs.be
rkeley.edu/%7Epabbeel/cs287-fa19/)
* [Reinforcement Learning
 - cs234](https://web.stanford.edu/class/cs234/), [videos fo
r 2019 run](https://www.youtube.com/playlist?list=PLoROMvodv
4rOSOPzutgyCTapiGlY2Nd8u)
* [Reinforcement Learning Summer S
chool 2019: Bandits, RL & Deep RL](https://rlss.inria.fr/pro
gram/)

Optimization >> 

* [Convex Optimization I - ee364a]
(http://stanford.edu/class/ee364a/), has quite recent [video
s](https://www.youtube.com/playlist?list=PLdrixi40lpQm5ksInX
lRon1eRwq_gzIcw) too. 
[Convex Optimization II - ee364b](htt
p://web.stanford.edu/class/ee364b/), [2008 videos](https://w
ww.youtube.com/watch?v=U3lJAObbMFI&list=PL3940DD956CDF0622&i
ndex=20)
* [Convex Optimization and Approximation - ee227c](
https://ee227c.github.io/)
* [Convex Optimization - ee227bt]
(https://people.eecs.berkeley.edu/%7Eelghaoui/Teaching/EE227
BT/index.html)
* [Variational Methods for Computer Vision](h
ttps://vision.in.tum.de/teaching/ws2013/vmcv2013)
* [Advance
d Optimization and Randomized Algorithms - 10-801](http://ww
w.cs.cmu.edu/%7Esuvrit/teach/index.html), [videos](https://w
ww.youtube.com/playlist?list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICx
t0d)
* [Optimization Methods for Machine Learning and Engine
ering - Karlsruhe Institute of Technology](https://www.youtu
be.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5)

Ap
plications >> Computer Vision

* [Computational Video Manipu
lation - cs448v](https://magrawala.github.io/cs448v-sp19/)
*
 [Advanced Topics in ML: Modeling and Segmentation of Multiv
ariate Mixed Data](http://www.vision.jhu.edu/teaching/learni
ng/learning10/)
* [TUM AI Guest lecture series](https://www.
youtube.com/playlist?list=PLQ8Y4kIIbzy8kMlz7cRqz-BjbdyWsfLXt
) - many influential researchers in DL, vision, graphics tal
k about latest advances and their latest works.
* [Advanced 
Deep Learning for Computer Vision - TUM ADL4CV](https://www.
youtube.com/playlist?list=PLog3nOPCjKBkngkkF552-Hiwa5t_ZeDnh
)
* [Detection, Segmentation and Tracking - TUM CV3DST](http
s://www.youtube.com/playlist?list=PLog3nOPCjKBneGyffEktlXXMf
v1OtKmCs)
* [Guest lectures at TUM Dynamic Vision and Learni
ng group](https://www.youtube.com/playlist?list=PLog3nOPCjKB
nAuymJ7uTysuG357zVn7et)
* [Vision Seminar at MIT](https://ww
w.youtube.com/channel/UCLMiFkFyfcNnZs6iwYLPI9g/videos)
* [Au
tonomous Vision Group, Talk@Tübingen Seminar](https://www.yo
utube.com/playlist?list=PLeCNfJWZKqxu-BwwcR4tDBOFNkJEOPWb_)


Applications >> Natural Language Processing

* [Natural Lan
guage Processing with Deep Learning - cs224n](http://web.sta
nford.edu/class/cs224n/) (* not sure if it belongs here, peo
ple working in NLP can help me out)
* [Neural networks for N
LP - cs11-747](http://www.phontron.com/class/nn4nlp2020/sche
dule.html)
* [Natural Language Understanding - cs224u](https
://web.stanford.edu/class/cs224u/), [video](https://www.yout
ube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

A
pplications >> 3D Graphics 

* [Non-Euclidean Methods in Mac
hine Learning - cs468, 2020](http://graphics.stanford.edu/co
urses/cs468-20-fall/schedule.html)
* [Machine Learning for 3
D Data - cs468, spring 2017](http://graphics.stanford.edu/co
urses/cs468-17-spring/schedule.html)
* [Data-Driven Shape An
alysis - cs468, 2014](http://graphics.stanford.edu/courses/c
s468-14-spring/)
* [Geometric Deep Learning](http://geometri
cdeeplearning.com/) - Not a course but the website links a f
ew tutorials on Geometric DL
* [Deep Learning for Computer G
raphics - SIGGRAPH 2019](https://geometry.cs.ucl.ac.uk/creat
iveai/)
* [Machine Learning for Machine Vision as Inverse Gr
aphics - csc2547 Winter'20](http://www.cs.utoronto.ca/~bonne
r/courses/2020s/csc2547/) 
* [Machine Learning Meets Geometr
y, winter 2020](https://geoml.github.io/schedule.html); [Mac
hine Learning for 3D Data, winter 2018](https://cse291-i.git
hub.io/WI18/schedule.html)

---

Edit: Upon suggestion, cate
gorized the courses. There might be some misclassifications 
as I'm not trained on this task ;). Added some good ones fro
m older (linked above) discussions."	"https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/"	"85"	"1583418496.0"	"822"	"fdw0ax"
23	"[D] Some interesting observations about machine learning publication practices from an outsider"	"I come from a traditional engineering field, and here is my 
observation about ML publication practice lately:

I have no
ticed that there are groups of researchers working on the in
tersection of 'old' fields such as optimization, control, si
gnal processing and the like, who will all of a sudden publi
sh a massive amount of paper that purports to solve a certai
n problem. The problem itself is usually recent and sometime
s involves some deep neural network.

However, upon close ex
amination, the only novelty is the problem (usually proposed
 by other unaffiliated groups) but not the method proposed b
y the researchers that purports to solve it.

I was puzzled 
by why a very large amount of seemingly weak papers, literal
ly rehashing (occasionally, well-known) techniques from the 
1980s or even 60s are getting accepted, and I noticed the fo
llowing recipe:

1. **Only ML conferences.** These groups of
 researchers will only ever publish in machine learning conf
erences (and not to optimization and control conferences/jou
rnals, where the heart of their work might actually lie). Fo
r example, on a paper about adversarial machine learning, th
e entire paper was actually about solving an optimization pr
oblem, but the optimization routine is basically a slight va
riation of other well studied methods. ***Update***: I also 
noticed that if a paper does not go through NeurIPS or ICLR,
 they will be directly sent to AAAI and some other smaller n
ame conferences, where they will be accepted. So nothing goe
s to waste in this field.
2. **Peers don't know what's going
 on.** Through openreview, I found that the reviewers (not j
ust the researchers) are uninformed about their particular a
rea, and only seem to comment on the correctness of the pape
r, but not the novelty. In fact, I doubt the reviewers thems
elves know about the novelty of the method. ***Update***: by
 novelty I meant how novel it is with respect to the state-o
f-the-art of a certain technique, especially when it interse
cts with operations research, optimization, control, signal 
processing. The state-of-the-art *could be* far ahead than w
hat mainstream ML folks know about.
3. **Poor citation pract
ices.** Usually the researchers will only cite themselves or
 other 'machine learning people' (whatever this means) from 
the last couple of years. Occasionally, there will be 1 cita
tion from hundreds of years ago attributed to Cauchy, Newton
, Fourier, Cournot, Turing, Von Neumann and the like, and th
en a hundred year jump to 2018 or 2019. I see, 'This problem
 was studied by *some big name* in 1930 and *Random Guy XYZ*
 in 2018' a lot.
4. **Wall of math.** Frequently, there will
 be a massive wall of math, proving some esoteric condition 
on the eigenvalue, gradient, Jacobian, and other curious thi
ngs about their problem (under other esoteric assumptions). 
There will be several theorems, none of which are applicable
 because the moment they run their highly non-convex deep le
arning application, all conditions are violated. Hence the o
nly thing obtained from these intricate theorems + math wall
 are some faint intuition (which are violated immediately). 
And then nothing is said. 

***Update***: If I could add one
 more, it would be that certain techniques, after being prop
osed, and after the authors claim that it beats a lot of ben
chmarks, will be seemingly be abandoned and never used again
. ML researchers seem to like to jump around topics a lot, s
o that might be a factor. But usually in other fields, once 
a technique is proposed, it is refined by the same group of 
researchers over many years, sometimes over the course of a 
researcher's career.

In some ways, this makes certain area 
of ML sort of an echo chamber, where researchers are pushing
 through a large amount of known results rehashed and somewh
at disguised by the novelty of their problem and these paper
s are all getting accepted because no one can detect the lac
k of novelty (or when they do detect, it is only 1 guy out o
f 3 reviewers). I just feel like ML conferences are sort of 
being treated as some sort of automatic paper acceptance cas
h cow.

Just my two cents coming from outside of ML. My obse
rvation does not apply to all fields of ML."	"https://www.reddit.com/r/MachineLearning/comments/lvwt3l/d_some_interesting_observations_about_machine/"	"171"	"1614671503.0"	"667"	"lvwt3l"
24	"[D] Calling out the authors of 'Trajformer' paper for claiming they published code but never doing it"	"I read a paper from NeurIPS 2020 titled 'Trajformer: Traject
ory Prediction with Local Self-Attentive Contexts for Autono
mous Driving'. I found it interesting and the authors claim 
multiple times in the paper that 'we release our code at '[h
ttps://github.com/Manojbhat09/Trajformer](https://github.com
/Manojbhat09/Trajformer)'. Turns out they never did, fine, I
 thought perhaps they will in the future and starred the rep
o to check it out later.

Many others raised issues asking f
or update on code release and they never replied. Finally, i
t April they update the readme to say that they will release
 the code and that's been the last update.

I know this is a
 common trend in ML papers now, but what sucks is that I ema
iled the authors (both the grad student and the PI) multiple
 times asking for an update an they never replied. Their pap
er is literally based on empirical improvements and without 
working code to replicate the results it is their word again
st mine.

I strongly think things have to change, and I beli
eve they only will if we call them out. I waited long enough
, and made significant effort to contact the authors with no
 response. I mean I don't mind them not releasing their code
, but at least don't claim that you did in the paper/review 
phase and then disappear. An undergrad in my lab asked why s
he should take time to clean up the code and document it bef
ore release while others just move on to the next interestin
g project and I don't have an answer. "	"https://www.reddit.com/r/MachineLearning/comments/qrbkc7/d_calling_out_the_authors_of_trajformer_paper_for/"	"90"	"1636600691.0"	"553"	"qrbkc7"
25	"[D] NeurIPS 2019 Bengio Schmidhuber Meta-Learning Fiasco"	"The recent reddit post [Yoshua Bengio talks about what's nex
t for deep learning](https://www.reddit.com/r/MachineLearnin
g/comments/e92dp5/d_yoshua_bengio_talks_about_whats_next_for
_deep/) links to an interview with Bengio. User u/panties_in
_my_ass got many upvotes for this comment: 

>Spectrum: What
's the key to that kind of adaptability?***  
>  
>Bengio: [
Meta-learning](https://arxiv.org/pdf/1905.03030.pdf) is a ve
ry hot topic these days: Learning to learn. I wrote an [earl
y paper on this](http://bengio.abracadoudou.com/publications
/pdf/bengio_1991_ijcnn.pdf) in 1991, but only recently did w
e get the computational power to implement this kind of thin
g.  
>  
>Somewhere, on some laptop, Schmidhuber is screamin
g at his monitor right now.

because he introduced meta-lear
ning 4 years before Bengio: 

Jürgen Schmidhuber. Evolutiona
ry principles in self-referential learning, or on learning h
ow to learn: The meta-meta-... hook. Diploma thesis, Tech Un
iv. Munich, 1987.

Then Bengio gave his [NeurIPS 2019 talk](
https://slideslive.com/38921750/from-system-1-deep-learning-
to-system-2-deep-learning). Slide 71 says:

>Meta-learning o
r learning to learn (Bengio et al 1991; Schmidhuber 1992)

u
/y0hun commented:

>What a childish slight... The Schmidhube
r 1987 paper is clearly labeled and established and as a nas
ty slight he juxtaposes his paper against Schmidhuber with h
is preceding it by a year almost doing the opposite of givin
g him credit.

I detect a broader pattern here. Look at this
 highly upvoted post: [Jürgen Schmidhuber really had GANs in
 1990](https://www.reddit.com/r/MachineLearning/comments/djj
u8a/d_jurgen_schmidhuber_really_had_gans_in_1990/), 25 years
 before Bengio. u/siddarth2947 commented that

>GANs were ac
tually mentioned in the Turing laudation, it's both funny an
d sad that Yoshua Bengio got a Turing award for a principle 
that Jurgen invented decades before him

and that section 3 
of Schmidhuber's [post on their miraculous year 1990-1991](h
ttp://people.idsia.ch/~juergen/deep-learning-miraculous-year
-1990-1991.html) is actually about his former student Sepp H
ochreiter and Bengio:

> (In 1994, others published results 
[VAN2] essentially identical to the 1991 vanishing gradient 
results of Sepp [VAN1]. Even after a common publication [VAN
3], the first author of reference [VAN2] published papers (e
.g., [VAN4]) that cited only his own 1994 paper but not Sepp
's original work.)

So Bengio republished at least 3 importa
nt ideas from Schmidhuber's lab without giving credit: meta-
learning, vanishing gradients, GANs. What's going on?"	"https://www.reddit.com/r/MachineLearning/comments/ea2gap/d_neurips_2019_bengio_schmidhuber_metalearning/"	"170"	"1576233717.0"	"550"	"ea2gap"
26	"[R] Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/eilmxki09bd61.png"	"3"	"1611507295.0"	"513"	"l432gk"
27	"[R] A List of Best Papers from Top AI Conferences in 2020"	"Sharing a list of award-winning papers from this year's top 
conferences for anyone interested in catching up on the late
st machine learning research before the end of the year :)


**AAAI 2020**

* Best Paper: WinoGrande: An Adversarial Wino
grad Schema Challenge at Scale \[[Paper](https://arxiv.org/a
bs/1907.10641)\]
* Honorable Mention: A Unifying View on Ind
ividual Bounds and Heuristic Inaccuracies in Bidirectional S
earch \[[Paper](https://ojs.aaai.org//index.php/AAAI/article
/view/5611)\]

**CVPR 2020** 

* Best Paper: Unsupervised Le
arning of Probably Symmetric Deformable 3D Objects from Imag
es in the Wild \[[Paper](https://arxiv.org/pdf/1911.11130.pd
f)\] \[[Presentation](https://crossminds.ai/video/5ee96b86b1
267e24b0ec2354/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**
ACL 2020**

* Best Paper: Beyond Accuracy: Behavioral Testin
g of NLP Models with CheckList \[[Paper](https://www.aclweb.
org/anthology/2020.acl-main.442.pdf)\] \[[Video](https://cro
ssminds.ai/video/5f454437e1acdc4d12c4186e/?playlist_id=5fe2e
2ea56dab51eaff52eaf)\] 

**ICML 2020**

* Best Paper: On Lea
rning Sets of Symmetric Elements \[[Paper](https://arxiv.org
/abs/2002.08599)\]  \[[Presentation](https://icml.cc/virtual
/2020/poster/6022)\] 
* Best Paper: Tuning-free Plug-and-Pla
y Proximal Algorithm for Inverse Imaging Problems \[[Paper](
https://arxiv.org/abs/2012.05703)\]  \[[Presentation](https:
//icml.cc/virtual/2020/poster/6447)\] 
* Honorable Mention: 
Efficiently sampling functions from Gaussian process posteri
ors  \[[Paper](https://arxiv.org/abs/2002.09309)\]  \[[Prese
ntation](https://crossminds.ai/video/5f189c96c01f1dd70811ebe
f/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Honorable Ment
ion: Generative Pretraining From Pixels \[[Paper](https://cd
n.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pd
f)\]  \[[Presentation](https://crossminds.ai/video/5f0e0b67d
8b7c2e383e1077b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

*
*ECCV 2020**

* Best Paper: RAFT: Recurrent All-Pairs Field 
Transforms for Optical Flow \[[Paper](https://arxiv.org/abs/
2003.12039)\] \[[Video](https://crossminds.ai/video/5f5acf7f
7fa4bb2ca9d64e4d/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
*
 Honorable Mention: Towards Streaming Perception \[[Paper](h
ttps://arxiv.org/abs/2005.10420)\] \[[Presentation](https://
crossminds.ai/video/5f44390ae1acdc4d12c417e3/?playlist_id=5f
e2e2ea56dab51eaff52eaf)\] 
* Honorable Mention: NeRF: Repres
enting Scenes as Neural Radiance Fields for View Synthesis \
[[Paper](https://arxiv.org/abs/2003.08934)\] \[[Presentation
](https://crossminds.ai/video/5f3b294f96cfcc9d075e35b6/?play
list_id=5fe2e2ea56dab51eaff52eaf)\] 

**ICRA 2020**

* Best 
Paper: Preference-Based Learning for Exoskeleton Gait Optimi
zation \[[Paper](https://arxiv.org/abs/1909.12316)\] \[[Pres
entation](https://crossminds.ai/video/5f65488303c0894581947a
6b/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Paper in
 Robot Vision: Graduated Non-Convexity for Robust Spatial Pe
rception: From Non-Minimal Solvers to Global Outlier Rejecti
on \[[Paper](https://arxiv.org/abs/1909.08605)\] \[[Presenta
tion](https://crossminds.ai/video/5f63f6c403c089458194705f/?
playlist_id=5fe2e2ea56dab51eaff52eaf)\] 

**CoRL 2020**

* B
est Paper: Learning Latent Representations to Influence Mult
i-Agent Interaction \[[Paper](https://arxiv.org/abs/2011.066
19)\] \[[Presentation](https://crossminds.ai/video/5fd9782a0
8be4fa7f41eabfe/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* 
Best Paper Presentation: Accelerating Reinforcement Learning
 with Learned Skill Priors \[[Paper](https://arxiv.org/abs/2
010.11944)\] \[[Presentation](https://crossminds.ai/video/5f
d9794308be4fa7f41eac54/?playlist_id=5fe2e2ea56dab51eaff52eaf
)\] 
* Best System Paper: SMARTS: An Open-Source Scalable Mu
lti-Agent RL Training School for Autonomous Driving \[[Paper
](https://arxiv.org/abs/2010.09776)\] \[[Presentation](https
://crossminds.ai/video/5fd9791f08be4fa7f41eac48/?playlist_id
=5fe2e2ea56dab51eaff52eaf)\] 

**RecSys 2020**

* Best Long 
Paper: Progressive Layered Extraction (PLE): A Novel Multi-T
ask Learning (MTL) Model for Personalized Recommendations \[
[Paper](https://github.com/guyulongcs/Awesome-Deep-Learning-
Papers-for-Search-Recommendation-Advertising/blob/master/0_N
ew_Papers_in_2020/2020%20%28Tencent%29%20%28Recsys%29%20%5BP
LE%5D%20Progressive%20Layered%20Extraction%20%28PLE%29%20-%2
0A%20Novel%20Multi-Task%20Learning%20%28MTL%29%20Model%20for
%20Personalized%20Recommendations.pdf)\] \[[Presentation](ht
tps://crossminds.ai/video/5f7fc247d81cf36f1a8e379c/?playlist
_id=5fe2e2ea56dab51eaff52eaf)\] 
* Best Short Paper: ADER: A
daptively Distilled Exemplar Replay Towards Continual Learni
ng for Session-based Recommendation \[[Paper](https://arxiv.
org/abs/2007.12000)\] \[[Presentation](https://crossminds.ai
/video/5f7fc27ad81cf36f1a8e37b6/?playlist_id=5fe2e2ea56dab51
eaff52eaf)\] 

**NeurIPS 2020**

* Best Paper: Language Mode
ls are Few-Shot Learners \[[Paper](https://arxiv.org/abs/200
5.14165)\] \[[Video](https://crossminds.ai/video/5f3179536d7
639fd8a7fc06a/?playlist_id=5fe2e2ea56dab51eaff52eaf)\] 
* Be
st Paper: No-Regret Learning Dynamics for Extensive-Form Cor
related Equilibrium \[[Paper](https://arxiv.org/abs/2004.006
03)\] 
* Best Paper: Improved Guarantees and a Multiple-Desc
ent Curve for Column Subset Selection and the Nyström Method
 \[[Paper](https://arxiv.org/abs/2002.09073)\]

Here is a co
mprehensive collection of [research talks from all major AI 
conferences](https://crossminds.ai/c/conference/) this year 
if you'd like to explore further."	"https://www.reddit.com/r/MachineLearning/comments/knai5q/r_a_list_of_best_papers_from_top_ai_conferences/"	"48"	"1609361402.0"	"510"	"knai5q"
28	"[D] On the public advertising of NeurIPS submissions on Twitter"	"The deadline for submitting papers to the NeurIPS 2020 confe
rence was two weeks ago. Since then, almost everyday I come 
across long Twitter threads from ML researchers that publicl
y advertise their work (obviously NeurIPS submissions, from 
the template and date of the shared arXiv preprint). They ar
e often quite famous researchers from Google, Facebook... wi
th thousands of followers and therefore a high visibility on
 Twitter. These posts often get a lot of likes and retweets 
- see examples in comment.

While I am glad to discover new 
exciting works, I am also concerned by the impact of such pr
actice on the review process. I know that submissions of arX
iv preprints are not forbidden by NeurIPS, but this kind of 
very engaging public advertising brings the anonymity violat
ion to another level.

Besides harming the double-blind revi
ew process, I am concerned by the social pressure it puts on
 reviewers. It is definitely harder to reject or even critic
ise a work that already received praise across the community
 through such advertising, especially when it comes from the
 account of a famous researcher or a famous institution.

Ho
wever, in recent Twitter discussions associated to these thr
eads, I failed to find people caring about these aspects, no
tably among top researchers reacting to the posts. Would you
 also say that this is fine (as, anyway, we cannot really as
sume that a review is double-blind when arXiv public preprin
ts with authors names and affiliations are allowed)? Or do y
ou agree that this can be a problem?"	"https://www.reddit.com/r/MachineLearning/comments/hbzd5o/d_on_the_public_advertising_of_neurips/"	"127"	"1592567690.0"	"474"	"hbzd5o"
29	"[R] NeurIPS 2020 Spotlight, AdaBelief optimizer, trains fast as Adam, generalize well as SGD, stable to train GAN."	"**Abstract**

Optimization is at the core of modern deep lea
rning. We propose AdaBelief optimizer to simultaneously achi
eve three goals: fast convergence as in adaptive methods, go
od generalization as in SGD, and training stability.

The in
tuition for AdaBelief is to adapt the stepsize according to 
the 'belief' in the current gradient direction. Viewing the 
exponential moving average (EMA) of the noisy gradient as th
e prediction of the gradient at the next time step, if the o
bserved gradient greatly deviates from the prediction, we di
strust the current observation and take a small step; if the
 observed gradient is close to the prediction, we trust it a
nd take a large step.

We validate AdaBelief in extensive ex
periments, showing that it outperforms other methods with fa
st convergence and high accuracy on image classification and
 language modeling. Specifically, on ImageNet, AdaBelief ach
ieves comparable accuracy to SGD. Furthermore, in the traini
ng of a GAN on Cifar10, AdaBelief demonstrates high stabilit
y and improves the quality of generated samples compared to 
a well-tuned Adam optimizer.

**Links**

Project page: [http
s://juntang-zhuang.github.io/adabelief/](https://juntang-zhu
ang.github.io/adabelief/)

Paper: [https://arxiv.org/abs/201
0.07468](https://arxiv.org/abs/2010.07468)

Code: [https://g
ithub.com/juntang-zhuang/Adabelief-Optimizer](https://github
.com/juntang-zhuang/Adabelief-Optimizer)

Videos on toy exam
ples: [https://www.youtube.com/playlist?list=PL7KkG3n9bER6Ym
MLrKJ5wocjlvP7aWoOu](https://www.youtube.com/playlist?list=P
L7KkG3n9bER6YmMLrKJ5wocjlvP7aWoOu)

**Discussion**

You are 
very welcome to post your thoughts here or at the github rep
o, email me, and collaborate on implementation or improvemen
t. ( Currently I only have extensively tested in PyTorch, th
e Tensorflow implementation is rather naive since I seldom u
se Tensorflow. )

**Results (Comparison with SGD, Adam, Adam
W, AdaBound, RAdam, Yogi, Fromage, MSVAG)**

1. Image Classi
fication

https://preview.redd.it/9b90n5iv9dt51.png?width=14
48&format=png&auto=webp&s=c7c843b9eb32b1ed6501a1ed8c08578a31
325427

2. GAN training

&#x200B;

https://preview.redd.it/h
zzyycyz9dt51.png?width=1372&format=png&auto=webp&s=4f439660d
bbf3fe03cb0a130fc8573677b0bc779

3. LSTM

https://preview.re
dd.it/bj3mc8r2adt51.png?width=1420&format=png&auto=webp&s=bb
268674e47006d1ee439015f3e7d0b32da2ba34

4. Toy examples

&#x
200B;

https://reddit.com/link/jc1fp2/video/3oy0cbr4adt51/pl
ayer"	"https://www.reddit.com/r/MachineLearning/comments/jc1fp2/r_neurips_2020_spotlight_adabelief_optimizer/"	"140"	"1602815151.0"	"456"	"jc1fp2"
30	"Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/5a6us2cs5pf61.png"	"1"	"1612547405.0"	"69"	"ldcrq0"
31	"NeurIPS Conference talks are available online"	"NeurIPS conference is flagship Artificial Intelligence confe
rence currently being held at Canada. 

If anyone couldn't m
ake it to @NeurIPSConf,  the talks are available online.

H/
T Suzana Ilić 

#machinelearning #deeplearning #AI #neurips 
#neurips2019

https://slideslive.com/neurips#!feed=latest"	"https://www.reddit.com/r/deeplearning/comments/e8olbt/neurips_conference_talks_are_available_online/"	"0"	"1575971021.0"	"52"	"e8olbt"
32	"'Math is forever.' - Interview with NeurIPS 2018 Best Paper team"	""	"https://medium.com/syncedreview/neurips-2018-best-paper-team-math-is-forever-55d9b6ead977"	"0"	"1545424642.0"	"50"	"a8e4vf"
33	"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026"	""	"https://v.redd.it/ogaocpecf0141"	"3"	"1574765814.0"	"46"	"e1wew5"
34	"Yoshua Bengio: From System 1 Deep Learning to System 2 Deep Learning (NeurIPS 2019)"	""	"https://www.youtube.com/watch?v=T3sxeTgT4qc"	"2"	"1577077842.0"	"36"	"eefze8"
35	"How does publishing in the Deep Learning world works, with respect to Journals and ArXive?"	"Let's say I implemented a new Deep Learning model that pushe
d some SOTA a little bit further, and I wrote a new paper ab
out for publication.

How does it work now? I pictured three
 options:

1. **Submit it to a Conference**. Ok that's the e
asy one, I submit it to something like NeurIPS or ICML and h
ope to get accepted. At that point, how do you make your pap
er accessible? Are there problems in uploading it to ArXive 
later, in order to get read by more people?

2. **Upload it 
on ArXive directly**. If I do that it would not be peer revi
ewed, and technically speaking it would be devoid of 'academ
ic value'... right? It could easily by anyone, but there wou
ld be no formal 'proof' of its 'scientific quality'. Please 
correct me if I'm wrong.

3. **Submit it to a peer reviewed 
Journal**. Dodge desk rejection, dodge reviewers' rejection,
 after a long painful process it ends up on some internation
al scientific Journal. At that point, since the article is f
ormally Editor's property, can you still upload it on ArXive
, or on your blog, so that it can be accessible by many peop
le?

&#x200B;

How do the big stars of Deep Learning researc
h do when they have some  hot new paper ready for publicatio
n? And what publications are the most  valued in the profess
ional and the academic world?"	"https://www.reddit.com/r/deeplearning/comments/gmns0l/how_does_publishing_in_the_deep_learning_world/"	"15"	"1589892029.0"	"37"	"gmns0l"
36	"Gradient boosting research papers from the last 25 years"	"&#x200B;

[https://github.com/benedekrozemberczki/awesome-gr
adient-boosting-papers](https://github.com/benedekrozembercz
ki/awesome-gradient-boosting-papers)

A curated list of grad
ient boosting research papers with implementations from the 
following conferences.

Machine learning:

1. NeurIPS
2. ICM
L
3. ICLR

Computer vision:

1. CVPR
2. ICCV
3. ECCV

Natura
l language processing:

1. ACL
2. NAACL
3. EMNLP

Data Minin
g:

1. KDD
2. ICDM
3. CIKM
4. WWW

Artificial intelligence:


1. AAAI
2. IJCAI
3. UAI
4. AISTATS"	"https://www.reddit.com/r/deeplearning/comments/bt57e3/gradient_boosting_research_papers_from_the_last/"	"2"	"1558855939.0"	"37"	"bt57e3"
37	"NeurIPS 2019 Outstanding Machine Learning Paper Awards"	""	"https://rubikscode.net/2019/12/30/neurips-2019-outstanding-machine-learning-paper-awards/"	"0"	"1577695041.0"	"36"	"ehjj1x"
38	"Google, Stanford, & MIT Top NeurIPS 2020 Accepted Papers List"	"After months marred by controversies over poorly-explained [
desk-rejects](https://syncedreview.com/2020/07/16/poorly-exp
lained-neurips-2020-desk-rejects-peeve-ml-researchers/) and 
other problematic aspects of its [review process](https://sy
ncedreview.com/2020/08/13/neurips-paper-reviews-released-con
troversies-resurface/), the 34th Conference on Neural Inform
ation Processing Systems (NeurIPS 2020) has finally released
 its [list](https://neurips.cc/Conferences/2020/AcceptedPape
rsInitial) of accepted papers.

With 38 percent more paper s
ubmissions than 2019, this has been another record-breaking 
year for NeurIPS. A total of 1,903 papers were accepted, com
pared to 1,428 last year.

The NeurIPS 2020 Program Chairs r
eport that 12,115 paper abstracts were submitted, leading to
 9,467 full submissions. After 184 submissions were withdraw
n by authors or rejected for violations such as being non-an
onymous or exceeding the maximum page count, 11 percent were
 desk-rejected, leaving 8,186 papers assigned to reviewers. 
**The NeurIPS 2020 paper acceptance rate is 20.1 percent — s
lightly lower than last year’s 21 percent.**

Here is a quic
k read: [Google, Stanford, & MIT Top NeurIPS 2020 Accepted P
apers List](https://syncedreview.com/2020/10/08/google-stanf
ord-mit-top-neurips-2020-accepted-papers-list/)"	"https://www.reddit.com/r/deeplearning/comments/j7ig7y/google_stanford_mit_top_neurips_2020_accepted/"	"6"	"1602181407.0"	"29"	"j7ig7y"
39	"[Research] Awesome Paper List of Vision Transformer & Attention"	" 

Hello all,

Are you looking for **Vision Transformer** pa
pers in various areas?

Check out this list of papers includ
ing a broad range of different tasks:

[https://github.com/c
mhungsteve/Awesome-Transformer-Attention](https://github.com
/cmhungsteve/Awesome-Transformer-Attention)

This repo conta
ins a comprehensive paper list of **Vision Transformer & Att
ention**, including papers (e.g., CVPR, NeurIPS, etc.), code
s, and related websites.

Feel free to check it, and share i
t with others

If you find this repo useful, I would be appr
eciative if you can STAR it :)

Any comments and contributio
ns in any form are welcome!!"	"https://www.reddit.com/r/deeplearning/comments/utwm3a/research_awesome_paper_list_of_vision_transformer/"	"6"	"1653054791.0"	"26"	"utwm3a"
40	"Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/5a6us2cs5pf61.png"	"1"	"1612547405.0"	"68"	"ldcrq0"
41	"NeurIPS Conference talks are available online"	"NeurIPS conference is flagship Artificial Intelligence confe
rence currently being held at Canada. 

If anyone couldn't m
ake it to @NeurIPSConf,  the talks are available online.

H/
T Suzana Ilić 

#machinelearning #deeplearning #AI #neurips 
#neurips2019

https://slideslive.com/neurips#!feed=latest"	"https://www.reddit.com/r/deeplearning/comments/e8olbt/neurips_conference_talks_are_available_online/"	"0"	"1575971021.0"	"52"	"e8olbt"
42	"'Math is forever.' - Interview with NeurIPS 2018 Best Paper team"	""	"https://medium.com/syncedreview/neurips-2018-best-paper-team-math-is-forever-55d9b6ead977"	"0"	"1545424642.0"	"47"	"a8e4vf"
43	"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026"	""	"https://v.redd.it/ogaocpecf0141"	"3"	"1574765814.0"	"45"	"e1wew5"
44	"Yoshua Bengio: From System 1 Deep Learning to System 2 Deep Learning (NeurIPS 2019)"	""	"https://www.youtube.com/watch?v=T3sxeTgT4qc"	"2"	"1577077842.0"	"35"	"eefze8"
45	"How does publishing in the Deep Learning world works, with respect to Journals and ArXive?"	"Let's say I implemented a new Deep Learning model that pushe
d some SOTA a little bit further, and I wrote a new paper ab
out for publication.

How does it work now? I pictured three
 options:

1. **Submit it to a Conference**. Ok that's the e
asy one, I submit it to something like NeurIPS or ICML and h
ope to get accepted. At that point, how do you make your pap
er accessible? Are there problems in uploading it to ArXive 
later, in order to get read by more people?

2. **Upload it 
on ArXive directly**. If I do that it would not be peer revi
ewed, and technically speaking it would be devoid of 'academ
ic value'... right? It could easily by anyone, but there wou
ld be no formal 'proof' of its 'scientific quality'. Please 
correct me if I'm wrong.

3. **Submit it to a peer reviewed 
Journal**. Dodge desk rejection, dodge reviewers' rejection,
 after a long painful process it ends up on some internation
al scientific Journal. At that point, since the article is f
ormally Editor's property, can you still upload it on ArXive
, or on your blog, so that it can be accessible by many peop
le?

&#x200B;

How do the big stars of Deep Learning researc
h do when they have some  hot new paper ready for publicatio
n? And what publications are the most  valued in the profess
ional and the academic world?"	"https://www.reddit.com/r/deeplearning/comments/gmns0l/how_does_publishing_in_the_deep_learning_world/"	"15"	"1589892029.0"	"38"	"gmns0l"
46	"Gradient boosting research papers from the last 25 years"	"&#x200B;

[https://github.com/benedekrozemberczki/awesome-gr
adient-boosting-papers](https://github.com/benedekrozembercz
ki/awesome-gradient-boosting-papers)

A curated list of grad
ient boosting research papers with implementations from the 
following conferences.

Machine learning:

1. NeurIPS
2. ICM
L
3. ICLR

Computer vision:

1. CVPR
2. ICCV
3. ECCV

Natura
l language processing:

1. ACL
2. NAACL
3. EMNLP

Data Minin
g:

1. KDD
2. ICDM
3. CIKM
4. WWW

Artificial intelligence:


1. AAAI
2. IJCAI
3. UAI
4. AISTATS"	"https://www.reddit.com/r/deeplearning/comments/bt57e3/gradient_boosting_research_papers_from_the_last/"	"2"	"1558855939.0"	"35"	"bt57e3"
47	"NeurIPS 2019 Outstanding Machine Learning Paper Awards"	""	"https://rubikscode.net/2019/12/30/neurips-2019-outstanding-machine-learning-paper-awards/"	"0"	"1577695041.0"	"36"	"ehjj1x"
48	"Google, Stanford, & MIT Top NeurIPS 2020 Accepted Papers List"	"After months marred by controversies over poorly-explained [
desk-rejects](https://syncedreview.com/2020/07/16/poorly-exp
lained-neurips-2020-desk-rejects-peeve-ml-researchers/) and 
other problematic aspects of its [review process](https://sy
ncedreview.com/2020/08/13/neurips-paper-reviews-released-con
troversies-resurface/), the 34th Conference on Neural Inform
ation Processing Systems (NeurIPS 2020) has finally released
 its [list](https://neurips.cc/Conferences/2020/AcceptedPape
rsInitial) of accepted papers.

With 38 percent more paper s
ubmissions than 2019, this has been another record-breaking 
year for NeurIPS. A total of 1,903 papers were accepted, com
pared to 1,428 last year.

The NeurIPS 2020 Program Chairs r
eport that 12,115 paper abstracts were submitted, leading to
 9,467 full submissions. After 184 submissions were withdraw
n by authors or rejected for violations such as being non-an
onymous or exceeding the maximum page count, 11 percent were
 desk-rejected, leaving 8,186 papers assigned to reviewers. 
**The NeurIPS 2020 paper acceptance rate is 20.1 percent — s
lightly lower than last year’s 21 percent.**

Here is a quic
k read: [Google, Stanford, & MIT Top NeurIPS 2020 Accepted P
apers List](https://syncedreview.com/2020/10/08/google-stanf
ord-mit-top-neurips-2020-accepted-papers-list/)"	"https://www.reddit.com/r/deeplearning/comments/j7ig7y/google_stanford_mit_top_neurips_2020_accepted/"	"6"	"1602181407.0"	"29"	"j7ig7y"
49	"[Research] Awesome Paper List of Vision Transformer & Attention"	" 

Hello all,

Are you looking for **Vision Transformer** pa
pers in various areas?

Check out this list of papers includ
ing a broad range of different tasks:

[https://github.com/c
mhungsteve/Awesome-Transformer-Attention](https://github.com
/cmhungsteve/Awesome-Transformer-Attention)

This repo conta
ins a comprehensive paper list of **Vision Transformer & Att
ention**, including papers (e.g., CVPR, NeurIPS, etc.), code
s, and related websites.

Feel free to check it, and share i
t with others

If you find this repo useful, I would be appr
eciative if you can STAR it :)

Any comments and contributio
ns in any form are welcome!!"	"https://www.reddit.com/r/deeplearning/comments/utwm3a/research_awesome_paper_list_of_vision_transformer/"	"6"	"1653054791.0"	"26"	"utwm3a"
50	"Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments"	""	"https://i.redd.it/5a6us2cs5pf61.png"	"1"	"1612547405.0"	"70"	"ldcrq0"
51	"NeurIPS Conference talks are available online"	"NeurIPS conference is flagship Artificial Intelligence confe
rence currently being held at Canada. 

If anyone couldn't m
ake it to @NeurIPSConf,  the talks are available online.

H/
T Suzana Ilić 

#machinelearning #deeplearning #AI #neurips 
#neurips2019

https://slideslive.com/neurips#!feed=latest"	"https://www.reddit.com/r/deeplearning/comments/e8olbt/neurips_conference_talks_are_available_online/"	"0"	"1575971021.0"	"50"	"e8olbt"
52	"'Math is forever.' - Interview with NeurIPS 2018 Best Paper team"	""	"https://medium.com/syncedreview/neurips-2018-best-paper-team-math-is-forever-55d9b6ead977"	"0"	"1545424642.0"	"46"	"a8e4vf"
53	"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026"	""	"https://v.redd.it/ogaocpecf0141"	"3"	"1574765814.0"	"45"	"e1wew5"
54	"Yoshua Bengio: From System 1 Deep Learning to System 2 Deep Learning (NeurIPS 2019)"	""	"https://www.youtube.com/watch?v=T3sxeTgT4qc"	"2"	"1577077842.0"	"40"	"eefze8"
55	"How does publishing in the Deep Learning world works, with respect to Journals and ArXive?"	"Let's say I implemented a new Deep Learning model that pushe
d some SOTA a little bit further, and I wrote a new paper ab
out for publication.

How does it work now? I pictured three
 options:

1. **Submit it to a Conference**. Ok that's the e
asy one, I submit it to something like NeurIPS or ICML and h
ope to get accepted. At that point, how do you make your pap
er accessible? Are there problems in uploading it to ArXive 
later, in order to get read by more people?

2. **Upload it 
on ArXive directly**. If I do that it would not be peer revi
ewed, and technically speaking it would be devoid of 'academ
ic value'... right? It could easily by anyone, but there wou
ld be no formal 'proof' of its 'scientific quality'. Please 
correct me if I'm wrong.

3. **Submit it to a peer reviewed 
Journal**. Dodge desk rejection, dodge reviewers' rejection,
 after a long painful process it ends up on some internation
al scientific Journal. At that point, since the article is f
ormally Editor's property, can you still upload it on ArXive
, or on your blog, so that it can be accessible by many peop
le?

&#x200B;

How do the big stars of Deep Learning researc
h do when they have some  hot new paper ready for publicatio
n? And what publications are the most  valued in the profess
ional and the academic world?"	"https://www.reddit.com/r/deeplearning/comments/gmns0l/how_does_publishing_in_the_deep_learning_world/"	"15"	"1589892029.0"	"39"	"gmns0l"
56	"Gradient boosting research papers from the last 25 years"	"&#x200B;

[https://github.com/benedekrozemberczki/awesome-gr
adient-boosting-papers](https://github.com/benedekrozembercz
ki/awesome-gradient-boosting-papers)

A curated list of grad
ient boosting research papers with implementations from the 
following conferences.

Machine learning:

1. NeurIPS
2. ICM
L
3. ICLR

Computer vision:

1. CVPR
2. ICCV
3. ECCV

Natura
l language processing:

1. ACL
2. NAACL
3. EMNLP

Data Minin
g:

1. KDD
2. ICDM
3. CIKM
4. WWW

Artificial intelligence:


1. AAAI
2. IJCAI
3. UAI
4. AISTATS"	"https://www.reddit.com/r/deeplearning/comments/bt57e3/gradient_boosting_research_papers_from_the_last/"	"2"	"1558855939.0"	"35"	"bt57e3"
57	"NeurIPS 2019 Outstanding Machine Learning Paper Awards"	""	"https://rubikscode.net/2019/12/30/neurips-2019-outstanding-machine-learning-paper-awards/"	"0"	"1577695041.0"	"37"	"ehjj1x"
58	"Google, Stanford, & MIT Top NeurIPS 2020 Accepted Papers List"	"After months marred by controversies over poorly-explained [
desk-rejects](https://syncedreview.com/2020/07/16/poorly-exp
lained-neurips-2020-desk-rejects-peeve-ml-researchers/) and 
other problematic aspects of its [review process](https://sy
ncedreview.com/2020/08/13/neurips-paper-reviews-released-con
troversies-resurface/), the 34th Conference on Neural Inform
ation Processing Systems (NeurIPS 2020) has finally released
 its [list](https://neurips.cc/Conferences/2020/AcceptedPape
rsInitial) of accepted papers.

With 38 percent more paper s
ubmissions than 2019, this has been another record-breaking 
year for NeurIPS. A total of 1,903 papers were accepted, com
pared to 1,428 last year.

The NeurIPS 2020 Program Chairs r
eport that 12,115 paper abstracts were submitted, leading to
 9,467 full submissions. After 184 submissions were withdraw
n by authors or rejected for violations such as being non-an
onymous or exceeding the maximum page count, 11 percent were
 desk-rejected, leaving 8,186 papers assigned to reviewers. 
**The NeurIPS 2020 paper acceptance rate is 20.1 percent — s
lightly lower than last year’s 21 percent.**

Here is a quic
k read: [Google, Stanford, & MIT Top NeurIPS 2020 Accepted P
apers List](https://syncedreview.com/2020/10/08/google-stanf
ord-mit-top-neurips-2020-accepted-papers-list/)"	"https://www.reddit.com/r/deeplearning/comments/j7ig7y/google_stanford_mit_top_neurips_2020_accepted/"	"6"	"1602181407.0"	"32"	"j7ig7y"
59	"[Research] Awesome Paper List of Vision Transformer & Attention"	" 

Hello all,

Are you looking for **Vision Transformer** pa
pers in various areas?

Check out this list of papers includ
ing a broad range of different tasks:

[https://github.com/c
mhungsteve/Awesome-Transformer-Attention](https://github.com
/cmhungsteve/Awesome-Transformer-Attention)

This repo conta
ins a comprehensive paper list of **Vision Transformer & Att
ention**, including papers (e.g., CVPR, NeurIPS, etc.), code
s, and related websites.

Feel free to check it, and share i
t with others

If you find this repo useful, I would be appr
eciative if you can STAR it :)

Any comments and contributio
ns in any form are welcome!!"	"https://www.reddit.com/r/deeplearning/comments/utwm3a/research_awesome_paper_list_of_vision_transformer/"	"6"	"1653054791.0"	"24"	"utwm3a"
