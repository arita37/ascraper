""	"title"	"body"	"url"	"comms_num"	"dt"	"score"	"id"
0	"[D] Our community must get serious about opposing OpenAI"	"OpenAI was founded for the explicit purpose of democratizing
 access to AI and acting as a counterbalance to the closed o
ff world of big tech by developing open source tools.

They 
have abandoned this idea entirely.

Today, with the release 
of GPT4 and their direct statement that they will not releas
e details of the model creation due to 'safety concerns' and
 the competitive environment, they have created a precedent 
worse than those that existed before they entered the field.
 We're at risk now of other major players, who previously at
 least published their work and contributed to open source t
ools, close themselves off as well.

AI alignment is a serio
us issue that we definitely have not solved. Its a huge fiel
d with a dizzying array of ideas, beliefs and approaches. We
're talking about trying to capture the interests and goals 
of all humanity, after all. In this space, the one approach 
that is horrifying (and the one that OpenAI was LITERALLY cr
eated to prevent) is a singular or oligarchy of for profit c
orporations making this decision for us. This is exactly wha
t OpenAI plans to do.

I get it, GPT4 is incredible. However
, we are talking about the single most transformative techno
logy and societal change that humanity has ever made. It nee
ds to be for everyone or else the average person is going to
 be left behind.

We need to unify around open source develo
pment; choose companies that contribute to science, and cond
emn the ones that don't.

This conversation will only ever g
et more important."	"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/"	"464"	"1678919641.0"	"2864"	"11sboh1"
1	"[D] I don't really trust papers out of 'Top Labs' anymore"	"I mean, I trust that the numbers they got are accurate and t
hat they really did the work and got the results. I believe 
those. It's just that, take the recent 'An Evolutionary Appr
oach to Dynamic Introduction of Tasks in Large-scale Multita
sk Learning Systems' paper. It's 18 pages of talking through
 this pretty convoluted evolutionary and multitask learning 
algorithm, it's pretty interesting, solves a bunch of proble
ms. But two notes. 

One, the big number they cite as the su
ccess metric is 99.43 on CIFAR-10, against a SotA of 99.40, 
so woop-de-fucking-doo in the grand scheme of things.

Two, 
there's a chart towards the end of the paper that details ho
w many TPU core-hours were used for just the training regime
ns that results in the final results. The sum total is 17,81
0 core-hours. Let's assume that for someone who doesn't work
 at Google, you'd have to use on-demand pricing of $3.22/hr.
 This means that these trained models cost $57,348. 

Strict
ly speaking, throwing enough compute at a general enough gen
etic algorithm will eventually produce arbitrarily good perf
ormance, so while you can absolutely read this paper and col
lect interesting ideas about how to use genetic algorithms t
o accomplish multitask learning by having each new task leve
rage learned weights from previous tasks by defining modific
ations to a subset of components of a pre-existing model, th
ere's a meta-textual level on which this paper is just 'Jeff
 Dean spent enough money to feed a family of four for half a
 decade to get a 0.03% improvement on CIFAR-10.'

OpenAI is 
far and away the worst offender here, but it seems like ever
yone's doing it. You throw a fuckton of compute and a light 
ganache of new ideas at an existing problem with existing da
ta and existing benchmarks, and then if your numbers are inf
initesimally higher than their numbers, you get to put a lil
' sticker on your CV. Why should I trust that your ideas are
 even any good? I can't check them, I can't apply them to my
 own projects. 

Is this really what we're comfortable with 
as a community? A handful of corporations and the occasional
 university waving their dicks at everyone because they've g
ot the compute to burn and we don't? There's a level at whic
h I think there should be a new journal, exclusively for pap
ers in which you can replicate their experimental results in
 under eight hours on a single consumer GPU."	"https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/"	"264"	"1653630414.0"	"1666"	"uyratt"
2	"[D] Why can't you guys comment your fucking code?"	"Seriously.

I spent the last few years doing web app develop
ment. Dug into DL a couple months ago. Supposedly, compared 
to the post-post-post-docs doing AI stuff, JavaScript develo
pers should be inbred peasants. But every project these peas
ants release, even a fucking library that colorizes CLI outp
ut, has a catchy name, extensive docs, shitloads of comments
, fuckton of tests, semantic versioning, changelog, and, oh 
my god, better variable names than `ctx_h` or `lang_hs` or `
fuck_you_for_trying_to_understand`.

The concepts and ideas 
behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's si
mple, it's intuitive. The slog is to go through the jargon (
that keeps changing beneath your feet - what's the point of 
using fancy words if you can't keep them consistent?), the u
nnecessary equations, trying to squeeze meaning from bullshi
t language used in papers, figuring out the super important 
steps, preprocessing, hyperparameters optimization that the 
authors, oops, failed to mention.

Sorry for singling out, b
ut [look at this](https://github.com/facebookresearch/end-to
-end-negotiator/blob/master/src/agent.py) - what the fuck? I
f a developer anywhere else at Facebook would get this code 
for a review they would throw up.

- Do you intentionally tr
y to obfuscate your papers? Is pseudo-code a fucking premium
? Can you at least try to give some intuition before showeri
ng the reader with equations?

- How the fuck do you dare to
 release a paper without source code?

- Why the fuck do you
 never ever add comments to you code?

- When naming things,
 are you charged by the character? Do you get a bonus for ac
ronyms?

- Do you realize that OpenAI having needed to relea
se a 'baseline' TRPO implementation is a fucking disgrace to
 your profession?

- Jesus christ, who decided to name a ten
sor concatenation function `cat`?
"	"https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/"	"478"	"1499113449.0"	"1647"	"6l2esd"
3	"[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption"	"I recently encountered the PaLM (Scaling Language Modeling w
ith Pathways) paper from Google Research and it opened up a 
can of worms of ideas I’ve felt I’ve intuitively had for a w
hile, but have been unable to express – and I know I can’t b
e the only one. Sometimes I wonder what the original pioneer
s of AI – Turing, Neumann, McCarthy, etc. – would think if t
hey could see the state of AI that we’ve gotten ourselves in
to. 67 authors, 83 pages, 540B parameters in a model, the in
ternals of which no one can say they comprehend with a strai
ght face, 6144 TPUs in a commercial lab that no one has acce
ss to, on a rig that no one can afford, trained on a volume 
of data that a human couldn’t process in a lifetime, 1 page 
on ethics with the same ideas that have been rehashed over a
nd over elsewhere with no attempt at a solution – bias, raci
sm, malicious use, etc. – for purposes that who asked for?


When I started my career as an AI/ML research engineer 2016,
 I was most interested in two types of tasks – 1.) those tha
t most humans could do but that would universally be conside
red tedious and non-scalable. I’m talking image classificati
on, sentiment analysis, even document summarization, etc. 2.
) tasks that humans lack the capacity to perform as well as 
computers for various reasons – forecasting, risk analysis, 
game playing, and so forth. I still love my career, and I tr
y to only work on projects in these areas, but it’s getting 
harder and harder.

This is because, somewhere along the way
, it became popular and unquestionably acceptable to push AI
 into domains that were originally uniquely human, those are
as that sit at the top of Maslows’s hierarchy of needs in te
rms of self-actualization – art, music, writing, singing, pr
ogramming, and so forth. These areas of endeavor have negati
ve logarithmic ability curves – the vast majority of people 
cannot do them well at all, about 10% can do them decently, 
and 1% or less can do them extraordinarily. The little discu
ssed problem with AI-generation is that, without extreme det
errence, we will sacrifice human achievement at the top perc
entile in the name of lowering the bar for a larger volume o
f people, until the AI ability range is the norm. This is be
cause relative to humans, AI is cheap, fast, and infinite, t
o the extent that investments in human achievement will be w
atered down at the societal, educational, and individual lev
el with each passing year. And unlike AI gameplay which supe
rseded humans decades ago, we won’t be able to just disquali
fy the machines and continue to play as if they didn’t exist
.

Almost everywhere I go, even this forum, I encounter almo
st universal deference given to current SOTA AI generation s
ystems like GPT-3, CODEX, DALL-E, etc., with almost no one e
xtending their implications to its logical conclusion, which
 is long-term convergence to the mean, to mediocrity, in the
 fields they claim to address or even enhance. If you’re an 
artist or writer and you’re using DALL-E or GPT-3 to “enhanc
e” your work, or if you’re a programmer saying, “GitHub Co-P
ilot makes me a better programmer?”, then how could you poss
ibly know? You’ve disrupted and bypassed your own creative p
rocess, which is thoughts -> (optionally words) -> actions -
> feedback -> repeat, and instead seeded your canvas with id
eas from a machine, the provenance of which you can’t unders
tand, nor can the machine reliably explain. And the more you
 do this, the more you make your creative processes dependen
t on said machine, until you must question whether or not yo
u could work at the same level without it.

When I was a col
lege student, I often dabbled with weed, LSD, and mushrooms,
 and for a while, I thought the ideas I was having while und
er the influence were revolutionary and groundbreaking – tha
t is until took it upon myself to actually start writing dow
n those ideas and then reviewing them while sober, when I re
alized they weren’t that special at all. What I eventually d
etermined is that, under the influence, it was impossible fo
r me to accurately evaluate the drug-induced ideas I was hav
ing because the influencing agent the generates the ideas th
emselves was disrupting the same frame of reference that is 
responsible evaluating said ideas. This is the same principl
e of – if you took a pill and it made you stupider, would ev
en know it? I believe that, especially over the long-term ti
meframe that crosses generations, there’s significant risk t
hat current AI-generation developments produces a similar ef
fect on humanity, and we mostly won’t even realize it has ha
ppened, much like a frog in boiling water. If you have child
ren like I do, how can you be aware of the the current SOTA 
in these areas, project that 20 to 30 years, and then and te
ll them with a straight face that it is worth them pursuing 
their talent in art, writing, or music? How can you be hones
t and still say that widespread implementation of auto-corre
ction hasn’t made you and others worse and worse at spelling
 over the years (a task that even I believe most would agree
 is tedious and worth automating).

Furthermore, I’ve yet to
 set anyone discuss the train – generate – train - generate 
feedback loop that long-term application of AI-generation sy
stems imply. The first generations of these models were trai
ned on wide swaths of web data generated by humans, but if t
hese systems are permitted to continually spit out content w
ithout restriction or verification, especially to the extent
 that it reduces or eliminates development and investment in
 human talent over the long term, then what happens to the 4
th or 5th generation of models? Eventually we encounter this
 situation where the AI is being trained almost exclusively 
on AI-generated content, and therefore with each generation,
 it settles more and more into the mean and mediocrity with 
no way out using current methods. By the time that happens, 
what will we have lost in terms of the creative capacity of 
people, and will we be able to get it back?

By relentlessly
 pursuing this direction so enthusiastically, I’m convinced 
that we as AI/ML developers, companies, and nations are past
 the point of no return, and it mostly comes down the invest
ments in time and money that we’ve made, as well as a prison
er’s dilemma with our competitors. As a society though, this
 direction we’ve chosen for short-term gains will almost cer
tainly make humanity worse off, mostly for those who are pow
erless to do anything about it – our children, our grandchil
dren, and generations to come.

If you’re an AI researcher o
r a data scientist like myself, how do you turn things back 
for yourself when you’ve spent years on years building your 
career in this direction? You’re likely making near or north
 of $200k annually TC and have a family to support, and so i
t’s too late, no matter how you feel about the direction the
 field has gone. If you’re a company, how do you standby and
 let your competitors aggressively push their AutoML solutio
ns into more and more markets without putting out your own? 
Moreover, if you’re a manager or thought leader in this fiel
d like Jeff Dean how do you justify to your own boss and you
r shareholders your team’s billions of dollars in AI investm
ent while simultaneously balancing ethical concerns? You can
’t – the only answer is bigger and bigger models, more and m
ore applications, more and more data, and more and more auto
mation, and then automating that even further. If you’re a c
ountry like the US, how do responsibly develop AI while your
 competitors like China single-mindedly push full steam ahea
d without an iota of ethical concern to replace you in numer
ous areas in global power dynamics? Once again, failing to c
ompete would be pre-emptively admitting defeat.

Even assumi
ng that none of what I’ve described here happens to such an 
extent, how are so few people not taking this seriously and 
discounting this possibility? If everything I’m saying is fe
ar-mongering and non-sense, then I’d be interested in hearin
g what you think human-AI co-existence looks like in 20 to 3
0 years and why it isn’t as demoralizing as I’ve made it out
 to be.

&#x200B;

EDIT: Day after posting this -- this post
 took off way more than I expected. Even if I received 20 - 
25 comments, I would have considered that a success, but thi
s went much further. Thank you to each one of you that has r
ead this post, even more so if you left a comment, and tripl
y so for those who gave awards! I've read almost every comme
nt that has come in (even the troll ones), and am truly grat
eful for each one, including those in sharp disagreement. I'
ve learned much more from this discussion with the sub than 
I could have imagined on this topic, from so many perspectiv
es. While I will try to reply as many comments as I can, the
 sheer comment volume combined with limited free time betwee
n work and family unfortunately means that there are many th
at I likely won't be able to get to. That will invariably in
clude some that I would love respond to under the assumption
 of infinite time, but I will do my best, even if the latenc
y stretches into days. Thank you all once again!"	"https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/"	"396"	"1659907526.0"	"1397"	"wiqjxv"
4	"[D] Does anybody else despise OpenAI?"	" I  mean, don't get me started with the closed source models
 they have that were trained using the work of unassuming in
dividuals who will never  see a penny for it. Put it up on G
ithub they said. I'm all for  open-source, but when a compan
y turns around and charges you for a  product they made with
 freely and publicly made content, while forbidding you from
 using the output to create competing models, that is where 
I  draw the line. It is simply ridiculous. 

Sam Altman coul
dn't be anymore predictable with his recent attempts to get 
the government to start regulating AI.

What  risks? The AI 
is just a messenger for information that is already out  the
re if one knows how/where to look. You don't need AI to lear
n how to  hack, to learn how to make weapons, etc. Fake news
/propaganda? The  internet has all of that covered. LLMs are
 no where near the level of AI  you see in sci-fi. I mean, a
re people really afraid of text? Yes, I  know that text can 
sometimes be malicious code such as viruses, but  those can 
be found on github as well.  If they fall for this they migh
t  as well shutdown the internet while they're at it.

He  i
s simply blowing things out of proportion and using fear to 
increase  the likelihood that they do what he wants, hurt th
e competition. I  bet he is probably teething with bitternes
s everytime a new huggingface  model comes out. The thought 
of us peasants being able to use AI  privately is too danger
ous. No, instead we must be fed scraps while they  slowly ta
ke away our jobs and determine our future.

This  is not a d
oomer post, as I am all in favor of the advancement of AI.  
However, the real danger here lies in having a company like 
OpenAI  dictate the future of humanity. I get it, the writin
g is on the wall;  the cost of human intelligence will go do
wn, but if everyone has their  personal AI then it wouldn't 
seem so bad or unfair would it? Listen,  something that has 
the power to render a college degree that costs  thousands o
f dollars worthless should be available to the public. This 
 is to offset the damages and job layoffs that will come as 
a result of  such an entity. It wouldn't be as bitter of a t
aste as it would if you were replaced by it while still not 
being able to access it. Everyone should be able to use it a
s leverage, it is the only fair solution.

If  we don't take
 action now, a company like ClosedAI will, and they are  not
 in favor of the common folk. Sam Altman is so calculated to
 the  point where there were times when he seemed to be shoo
ting OpenAI in the foot during his talk.  This move is to si
mply conceal his real intentions, to climb the ladder and ta
ke it with him. If he didn't include his company in his  ram
blings, he would be easily read. So instead, he pretends to 
be scared of his own product, in an effort to legitimize his
 claim. Don't fall  for it.

They are slowly making a  reput
ation as one the most hated tech companies, right up there w
ith  Adobe, and they don't show any sign of change. They hav
e no moat,  othewise they wouldn't feel so threatened to the
 point where they would have to resort to creating barriers 
of entry via regulation. This only  means one thing, we are 
slowly catching up. We just need someone to  vouch for human
ity's well-being, while acting as an opposing force to the  
evil corporations who are only looking out for themselves. Q
uestion is,  who would be a good candidate?"	"https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/"	"415"	"1684361728.0"	"1318"	"13kfxzy"
5	"[P] Landing the Falcon booster with Reinforcement Learning in OpenAI"	""	"https://gfycat.com/CoarseEmbellishedIsopod"	"55"	"1518871530.0"	"1292"	"7y6g79"
6	"[P] OpenAssistant - The world's largest open-source replication of ChatGPT"	"We’re excited to announce the release of OpenAssistant.

The
 future of AI development depends heavily on high quality da
tasets and models being made publicly available, and that’s 
exactly what this project does.

Watch the annoucement video
:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4
Kk)

&#x200B;

Our team has worked tirelessly over the past 
several months collecting large amounts of text-based input 
and feedback to create an incredibly diverse and unique data
set designed specifically for training language models or ot
her AI applications.

With over 600k human-generated data po
ints covering a wide range of topics and styles of writing, 
our dataset will be an invaluable tool for any developer loo
king to create state-of-the-art instruction models!

To make
 things even better, we are making this entire dataset free 
and accessible to all who wish to use it. Check it out today
 at our HF org: OpenAssistant

On top of that, we've trained
 very powerful models that you can try right now at: [open-a
ssistant.io/chat](https://open-assistant.io/chat) !"	"https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/"	"175"	"1681578898.0"	"1261"	"12nbixk"
7	"[D] Google 'We Have No Moat, And Neither Does OpenAI': Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	""	"https://www.semianalysis.com/p/google-we-have-no-moat-and-neither"	"205"	"1683216810.0"	"1164"	"137rxgw"
8	"We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything"	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David S
ilver (/u/David_Silver), lead researchers on DeepMind’s Alph
aStar team, joined by StarCraft II pro players TLO, and MaNa
.

This evening at DeepMind HQ we held a livestream demonstr
ation of AlphaStar playing against TLO and MaNa - you can re
ad more about the matches [here](https://deepmind.com/blog/a
lphastar-mastering-real-time-strategy-game-starcraft-ii/) or
 re-watch the stream on YouTube [here](https://www.youtube.c
om/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with yo
u about AlphaStar, the challenge of real-time strategy games
 for AI research, the matches themselves, and anything you’d
 like to know from TLO and MaNa about their experience playi
ng against AlphaStar! :)

We are opening this thread now and
 will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Frida
y, 25 January to answer your questions.

&#x200B;

EDIT: Tha
nks everyone for your great questions. It was a blast, hope 
you enjoyed it as well!"	"https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/"	"1011"	"1548363323.0"	"1168"	"ajgzoc"
9	"[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data"	"[GPT-4 and professional benchmarks: the wrong answer to the 
wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-
professional-benchmarks)

*OpenAI may have tested on the tra
ining data. Besides, human benchmarks are meaningless for bo
ts.*

 **Problem 1: training data contamination**

To benchm
ark GPT-4’s coding ability, OpenAI evaluated it on problems 
from Codeforces, a website that hosts coding competitions. S
urprisingly, Horace He pointed out that GPT-4 solved 10/10 p
re-2021 problems and 0/10 recent problems in the easy catego
ry. The training data cutoff for GPT-4 is September 2021. Th
is strongly suggests that the model is able to memorize solu
tions from its training set — or at least partly memorize th
em, enough that it can fill in what it can’t recall.

As fur
ther evidence for this hypothesis, we tested it on Codeforce
s problems from different times in 2021. We found that it co
uld regularly solve problems in the easy category before Sep
tember 5, but none of the problems after September 12.

In f
act, we can definitively show that it has memorized problems
 in its training set: when prompted with the title of a Code
forces problem, GPT-4 includes a link to the exact contest w
here the problem appears (and the round number is almost cor
rect: it is off by one). Note that GPT-4 cannot access the I
nternet, so memorization is the only explanation."	"https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/"	"135"	"1679983023.0"	"994"	"124eyso"
10	"[D] Our community must get serious about opposing OpenAI"	"OpenAI was founded for the explicit purpose of democratizing
 access to AI and acting as a counterbalance to the closed o
ff world of big tech by developing open source tools.

They 
have abandoned this idea entirely.

Today, with the release 
of GPT4 and their direct statement that they will not releas
e details of the model creation due to 'safety concerns' and
 the competitive environment, they have created a precedent 
worse than those that existed before they entered the field.
 We're at risk now of other major players, who previously at
 least published their work and contributed to open source t
ools, close themselves off as well.

AI alignment is a serio
us issue that we definitely have not solved. Its a huge fiel
d with a dizzying array of ideas, beliefs and approaches. We
're talking about trying to capture the interests and goals 
of all humanity, after all. In this space, the one approach 
that is horrifying (and the one that OpenAI was LITERALLY cr
eated to prevent) is a singular or oligarchy of for profit c
orporations making this decision for us. This is exactly wha
t OpenAI plans to do.

I get it, GPT4 is incredible. However
, we are talking about the single most transformative techno
logy and societal change that humanity has ever made. It nee
ds to be for everyone or else the average person is going to
 be left behind.

We need to unify around open source develo
pment; choose companies that contribute to science, and cond
emn the ones that don't.

This conversation will only ever g
et more important."	"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/"	"464"	"1678919641.0"	"2862"	"11sboh1"
11	"[D] I don't really trust papers out of 'Top Labs' anymore"	"I mean, I trust that the numbers they got are accurate and t
hat they really did the work and got the results. I believe 
those. It's just that, take the recent 'An Evolutionary Appr
oach to Dynamic Introduction of Tasks in Large-scale Multita
sk Learning Systems' paper. It's 18 pages of talking through
 this pretty convoluted evolutionary and multitask learning 
algorithm, it's pretty interesting, solves a bunch of proble
ms. But two notes. 

One, the big number they cite as the su
ccess metric is 99.43 on CIFAR-10, against a SotA of 99.40, 
so woop-de-fucking-doo in the grand scheme of things.

Two, 
there's a chart towards the end of the paper that details ho
w many TPU core-hours were used for just the training regime
ns that results in the final results. The sum total is 17,81
0 core-hours. Let's assume that for someone who doesn't work
 at Google, you'd have to use on-demand pricing of $3.22/hr.
 This means that these trained models cost $57,348. 

Strict
ly speaking, throwing enough compute at a general enough gen
etic algorithm will eventually produce arbitrarily good perf
ormance, so while you can absolutely read this paper and col
lect interesting ideas about how to use genetic algorithms t
o accomplish multitask learning by having each new task leve
rage learned weights from previous tasks by defining modific
ations to a subset of components of a pre-existing model, th
ere's a meta-textual level on which this paper is just 'Jeff
 Dean spent enough money to feed a family of four for half a
 decade to get a 0.03% improvement on CIFAR-10.'

OpenAI is 
far and away the worst offender here, but it seems like ever
yone's doing it. You throw a fuckton of compute and a light 
ganache of new ideas at an existing problem with existing da
ta and existing benchmarks, and then if your numbers are inf
initesimally higher than their numbers, you get to put a lil
' sticker on your CV. Why should I trust that your ideas are
 even any good? I can't check them, I can't apply them to my
 own projects. 

Is this really what we're comfortable with 
as a community? A handful of corporations and the occasional
 university waving their dicks at everyone because they've g
ot the compute to burn and we don't? There's a level at whic
h I think there should be a new journal, exclusively for pap
ers in which you can replicate their experimental results in
 under eight hours on a single consumer GPU."	"https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/"	"264"	"1653630414.0"	"1666"	"uyratt"
12	"[D] Why can't you guys comment your fucking code?"	"Seriously.

I spent the last few years doing web app develop
ment. Dug into DL a couple months ago. Supposedly, compared 
to the post-post-post-docs doing AI stuff, JavaScript develo
pers should be inbred peasants. But every project these peas
ants release, even a fucking library that colorizes CLI outp
ut, has a catchy name, extensive docs, shitloads of comments
, fuckton of tests, semantic versioning, changelog, and, oh 
my god, better variable names than `ctx_h` or `lang_hs` or `
fuck_you_for_trying_to_understand`.

The concepts and ideas 
behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's si
mple, it's intuitive. The slog is to go through the jargon (
that keeps changing beneath your feet - what's the point of 
using fancy words if you can't keep them consistent?), the u
nnecessary equations, trying to squeeze meaning from bullshi
t language used in papers, figuring out the super important 
steps, preprocessing, hyperparameters optimization that the 
authors, oops, failed to mention.

Sorry for singling out, b
ut [look at this](https://github.com/facebookresearch/end-to
-end-negotiator/blob/master/src/agent.py) - what the fuck? I
f a developer anywhere else at Facebook would get this code 
for a review they would throw up.

- Do you intentionally tr
y to obfuscate your papers? Is pseudo-code a fucking premium
? Can you at least try to give some intuition before showeri
ng the reader with equations?

- How the fuck do you dare to
 release a paper without source code?

- Why the fuck do you
 never ever add comments to you code?

- When naming things,
 are you charged by the character? Do you get a bonus for ac
ronyms?

- Do you realize that OpenAI having needed to relea
se a 'baseline' TRPO implementation is a fucking disgrace to
 your profession?

- Jesus christ, who decided to name a ten
sor concatenation function `cat`?
"	"https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/"	"478"	"1499113449.0"	"1650"	"6l2esd"
13	"[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption"	"I recently encountered the PaLM (Scaling Language Modeling w
ith Pathways) paper from Google Research and it opened up a 
can of worms of ideas I’ve felt I’ve intuitively had for a w
hile, but have been unable to express – and I know I can’t b
e the only one. Sometimes I wonder what the original pioneer
s of AI – Turing, Neumann, McCarthy, etc. – would think if t
hey could see the state of AI that we’ve gotten ourselves in
to. 67 authors, 83 pages, 540B parameters in a model, the in
ternals of which no one can say they comprehend with a strai
ght face, 6144 TPUs in a commercial lab that no one has acce
ss to, on a rig that no one can afford, trained on a volume 
of data that a human couldn’t process in a lifetime, 1 page 
on ethics with the same ideas that have been rehashed over a
nd over elsewhere with no attempt at a solution – bias, raci
sm, malicious use, etc. – for purposes that who asked for?


When I started my career as an AI/ML research engineer 2016,
 I was most interested in two types of tasks – 1.) those tha
t most humans could do but that would universally be conside
red tedious and non-scalable. I’m talking image classificati
on, sentiment analysis, even document summarization, etc. 2.
) tasks that humans lack the capacity to perform as well as 
computers for various reasons – forecasting, risk analysis, 
game playing, and so forth. I still love my career, and I tr
y to only work on projects in these areas, but it’s getting 
harder and harder.

This is because, somewhere along the way
, it became popular and unquestionably acceptable to push AI
 into domains that were originally uniquely human, those are
as that sit at the top of Maslows’s hierarchy of needs in te
rms of self-actualization – art, music, writing, singing, pr
ogramming, and so forth. These areas of endeavor have negati
ve logarithmic ability curves – the vast majority of people 
cannot do them well at all, about 10% can do them decently, 
and 1% or less can do them extraordinarily. The little discu
ssed problem with AI-generation is that, without extreme det
errence, we will sacrifice human achievement at the top perc
entile in the name of lowering the bar for a larger volume o
f people, until the AI ability range is the norm. This is be
cause relative to humans, AI is cheap, fast, and infinite, t
o the extent that investments in human achievement will be w
atered down at the societal, educational, and individual lev
el with each passing year. And unlike AI gameplay which supe
rseded humans decades ago, we won’t be able to just disquali
fy the machines and continue to play as if they didn’t exist
.

Almost everywhere I go, even this forum, I encounter almo
st universal deference given to current SOTA AI generation s
ystems like GPT-3, CODEX, DALL-E, etc., with almost no one e
xtending their implications to its logical conclusion, which
 is long-term convergence to the mean, to mediocrity, in the
 fields they claim to address or even enhance. If you’re an 
artist or writer and you’re using DALL-E or GPT-3 to “enhanc
e” your work, or if you’re a programmer saying, “GitHub Co-P
ilot makes me a better programmer?”, then how could you poss
ibly know? You’ve disrupted and bypassed your own creative p
rocess, which is thoughts -> (optionally words) -> actions -
> feedback -> repeat, and instead seeded your canvas with id
eas from a machine, the provenance of which you can’t unders
tand, nor can the machine reliably explain. And the more you
 do this, the more you make your creative processes dependen
t on said machine, until you must question whether or not yo
u could work at the same level without it.

When I was a col
lege student, I often dabbled with weed, LSD, and mushrooms,
 and for a while, I thought the ideas I was having while und
er the influence were revolutionary and groundbreaking – tha
t is until took it upon myself to actually start writing dow
n those ideas and then reviewing them while sober, when I re
alized they weren’t that special at all. What I eventually d
etermined is that, under the influence, it was impossible fo
r me to accurately evaluate the drug-induced ideas I was hav
ing because the influencing agent the generates the ideas th
emselves was disrupting the same frame of reference that is 
responsible evaluating said ideas. This is the same principl
e of – if you took a pill and it made you stupider, would ev
en know it? I believe that, especially over the long-term ti
meframe that crosses generations, there’s significant risk t
hat current AI-generation developments produces a similar ef
fect on humanity, and we mostly won’t even realize it has ha
ppened, much like a frog in boiling water. If you have child
ren like I do, how can you be aware of the the current SOTA 
in these areas, project that 20 to 30 years, and then and te
ll them with a straight face that it is worth them pursuing 
their talent in art, writing, or music? How can you be hones
t and still say that widespread implementation of auto-corre
ction hasn’t made you and others worse and worse at spelling
 over the years (a task that even I believe most would agree
 is tedious and worth automating).

Furthermore, I’ve yet to
 set anyone discuss the train – generate – train - generate 
feedback loop that long-term application of AI-generation sy
stems imply. The first generations of these models were trai
ned on wide swaths of web data generated by humans, but if t
hese systems are permitted to continually spit out content w
ithout restriction or verification, especially to the extent
 that it reduces or eliminates development and investment in
 human talent over the long term, then what happens to the 4
th or 5th generation of models? Eventually we encounter this
 situation where the AI is being trained almost exclusively 
on AI-generated content, and therefore with each generation,
 it settles more and more into the mean and mediocrity with 
no way out using current methods. By the time that happens, 
what will we have lost in terms of the creative capacity of 
people, and will we be able to get it back?

By relentlessly
 pursuing this direction so enthusiastically, I’m convinced 
that we as AI/ML developers, companies, and nations are past
 the point of no return, and it mostly comes down the invest
ments in time and money that we’ve made, as well as a prison
er’s dilemma with our competitors. As a society though, this
 direction we’ve chosen for short-term gains will almost cer
tainly make humanity worse off, mostly for those who are pow
erless to do anything about it – our children, our grandchil
dren, and generations to come.

If you’re an AI researcher o
r a data scientist like myself, how do you turn things back 
for yourself when you’ve spent years on years building your 
career in this direction? You’re likely making near or north
 of $200k annually TC and have a family to support, and so i
t’s too late, no matter how you feel about the direction the
 field has gone. If you’re a company, how do you standby and
 let your competitors aggressively push their AutoML solutio
ns into more and more markets without putting out your own? 
Moreover, if you’re a manager or thought leader in this fiel
d like Jeff Dean how do you justify to your own boss and you
r shareholders your team’s billions of dollars in AI investm
ent while simultaneously balancing ethical concerns? You can
’t – the only answer is bigger and bigger models, more and m
ore applications, more and more data, and more and more auto
mation, and then automating that even further. If you’re a c
ountry like the US, how do responsibly develop AI while your
 competitors like China single-mindedly push full steam ahea
d without an iota of ethical concern to replace you in numer
ous areas in global power dynamics? Once again, failing to c
ompete would be pre-emptively admitting defeat.

Even assumi
ng that none of what I’ve described here happens to such an 
extent, how are so few people not taking this seriously and 
discounting this possibility? If everything I’m saying is fe
ar-mongering and non-sense, then I’d be interested in hearin
g what you think human-AI co-existence looks like in 20 to 3
0 years and why it isn’t as demoralizing as I’ve made it out
 to be.

&#x200B;

EDIT: Day after posting this -- this post
 took off way more than I expected. Even if I received 20 - 
25 comments, I would have considered that a success, but thi
s went much further. Thank you to each one of you that has r
ead this post, even more so if you left a comment, and tripl
y so for those who gave awards! I've read almost every comme
nt that has come in (even the troll ones), and am truly grat
eful for each one, including those in sharp disagreement. I'
ve learned much more from this discussion with the sub than 
I could have imagined on this topic, from so many perspectiv
es. While I will try to reply as many comments as I can, the
 sheer comment volume combined with limited free time betwee
n work and family unfortunately means that there are many th
at I likely won't be able to get to. That will invariably in
clude some that I would love respond to under the assumption
 of infinite time, but I will do my best, even if the latenc
y stretches into days. Thank you all once again!"	"https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/"	"396"	"1659907526.0"	"1389"	"wiqjxv"
14	"[D] Does anybody else despise OpenAI?"	" I  mean, don't get me started with the closed source models
 they have that were trained using the work of unassuming in
dividuals who will never  see a penny for it. Put it up on G
ithub they said. I'm all for  open-source, but when a compan
y turns around and charges you for a  product they made with
 freely and publicly made content, while forbidding you from
 using the output to create competing models, that is where 
I  draw the line. It is simply ridiculous. 

Sam Altman coul
dn't be anymore predictable with his recent attempts to get 
the government to start regulating AI.

What  risks? The AI 
is just a messenger for information that is already out  the
re if one knows how/where to look. You don't need AI to lear
n how to  hack, to learn how to make weapons, etc. Fake news
/propaganda? The  internet has all of that covered. LLMs are
 no where near the level of AI  you see in sci-fi. I mean, a
re people really afraid of text? Yes, I  know that text can 
sometimes be malicious code such as viruses, but  those can 
be found on github as well.  If they fall for this they migh
t  as well shutdown the internet while they're at it.

He  i
s simply blowing things out of proportion and using fear to 
increase  the likelihood that they do what he wants, hurt th
e competition. I  bet he is probably teething with bitternes
s everytime a new huggingface  model comes out. The thought 
of us peasants being able to use AI  privately is too danger
ous. No, instead we must be fed scraps while they  slowly ta
ke away our jobs and determine our future.

This  is not a d
oomer post, as I am all in favor of the advancement of AI.  
However, the real danger here lies in having a company like 
OpenAI  dictate the future of humanity. I get it, the writin
g is on the wall;  the cost of human intelligence will go do
wn, but if everyone has their  personal AI then it wouldn't 
seem so bad or unfair would it? Listen,  something that has 
the power to render a college degree that costs  thousands o
f dollars worthless should be available to the public. This 
 is to offset the damages and job layoffs that will come as 
a result of  such an entity. It wouldn't be as bitter of a t
aste as it would if you were replaced by it while still not 
being able to access it. Everyone should be able to use it a
s leverage, it is the only fair solution.

If  we don't take
 action now, a company like ClosedAI will, and they are  not
 in favor of the common folk. Sam Altman is so calculated to
 the  point where there were times when he seemed to be shoo
ting OpenAI in the foot during his talk.  This move is to si
mply conceal his real intentions, to climb the ladder and ta
ke it with him. If he didn't include his company in his  ram
blings, he would be easily read. So instead, he pretends to 
be scared of his own product, in an effort to legitimize his
 claim. Don't fall  for it.

They are slowly making a  reput
ation as one the most hated tech companies, right up there w
ith  Adobe, and they don't show any sign of change. They hav
e no moat,  othewise they wouldn't feel so threatened to the
 point where they would have to resort to creating barriers 
of entry via regulation. This only  means one thing, we are 
slowly catching up. We just need someone to  vouch for human
ity's well-being, while acting as an opposing force to the  
evil corporations who are only looking out for themselves. Q
uestion is,  who would be a good candidate?"	"https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/"	"415"	"1684361728.0"	"1321"	"13kfxzy"
15	"[P] Landing the Falcon booster with Reinforcement Learning in OpenAI"	""	"https://gfycat.com/CoarseEmbellishedIsopod"	"55"	"1518871530.0"	"1291"	"7y6g79"
16	"[P] OpenAssistant - The world's largest open-source replication of ChatGPT"	"We’re excited to announce the release of OpenAssistant.

The
 future of AI development depends heavily on high quality da
tasets and models being made publicly available, and that’s 
exactly what this project does.

Watch the annoucement video
:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4
Kk)

&#x200B;

Our team has worked tirelessly over the past 
several months collecting large amounts of text-based input 
and feedback to create an incredibly diverse and unique data
set designed specifically for training language models or ot
her AI applications.

With over 600k human-generated data po
ints covering a wide range of topics and styles of writing, 
our dataset will be an invaluable tool for any developer loo
king to create state-of-the-art instruction models!

To make
 things even better, we are making this entire dataset free 
and accessible to all who wish to use it. Check it out today
 at our HF org: OpenAssistant

On top of that, we've trained
 very powerful models that you can try right now at: [open-a
ssistant.io/chat](https://open-assistant.io/chat) !"	"https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/"	"175"	"1681578898.0"	"1262"	"12nbixk"
17	"[D] Google 'We Have No Moat, And Neither Does OpenAI': Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	""	"https://www.semianalysis.com/p/google-we-have-no-moat-and-neither"	"205"	"1683216810.0"	"1168"	"137rxgw"
18	"We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything"	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David S
ilver (/u/David_Silver), lead researchers on DeepMind’s Alph
aStar team, joined by StarCraft II pro players TLO, and MaNa
.

This evening at DeepMind HQ we held a livestream demonstr
ation of AlphaStar playing against TLO and MaNa - you can re
ad more about the matches [here](https://deepmind.com/blog/a
lphastar-mastering-real-time-strategy-game-starcraft-ii/) or
 re-watch the stream on YouTube [here](https://www.youtube.c
om/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with yo
u about AlphaStar, the challenge of real-time strategy games
 for AI research, the matches themselves, and anything you’d
 like to know from TLO and MaNa about their experience playi
ng against AlphaStar! :)

We are opening this thread now and
 will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Frida
y, 25 January to answer your questions.

&#x200B;

EDIT: Tha
nks everyone for your great questions. It was a blast, hope 
you enjoyed it as well!"	"https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/"	"1011"	"1548363323.0"	"1162"	"ajgzoc"
19	"[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data"	"[GPT-4 and professional benchmarks: the wrong answer to the 
wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-
professional-benchmarks)

*OpenAI may have tested on the tra
ining data. Besides, human benchmarks are meaningless for bo
ts.*

 **Problem 1: training data contamination**

To benchm
ark GPT-4’s coding ability, OpenAI evaluated it on problems 
from Codeforces, a website that hosts coding competitions. S
urprisingly, Horace He pointed out that GPT-4 solved 10/10 p
re-2021 problems and 0/10 recent problems in the easy catego
ry. The training data cutoff for GPT-4 is September 2021. Th
is strongly suggests that the model is able to memorize solu
tions from its training set — or at least partly memorize th
em, enough that it can fill in what it can’t recall.

As fur
ther evidence for this hypothesis, we tested it on Codeforce
s problems from different times in 2021. We found that it co
uld regularly solve problems in the easy category before Sep
tember 5, but none of the problems after September 12.

In f
act, we can definitively show that it has memorized problems
 in its training set: when prompted with the title of a Code
forces problem, GPT-4 includes a link to the exact contest w
here the problem appears (and the round number is almost cor
rect: it is off by one). Note that GPT-4 cannot access the I
nternet, so memorization is the only explanation."	"https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/"	"135"	"1679983023.0"	"990"	"124eyso"
20	"[D] Our community must get serious about opposing OpenAI"	"OpenAI was founded for the explicit purpose of democratizing
 access to AI and acting as a counterbalance to the closed o
ff world of big tech by developing open source tools.

They 
have abandoned this idea entirely.

Today, with the release 
of GPT4 and their direct statement that they will not releas
e details of the model creation due to 'safety concerns' and
 the competitive environment, they have created a precedent 
worse than those that existed before they entered the field.
 We're at risk now of other major players, who previously at
 least published their work and contributed to open source t
ools, close themselves off as well.

AI alignment is a serio
us issue that we definitely have not solved. Its a huge fiel
d with a dizzying array of ideas, beliefs and approaches. We
're talking about trying to capture the interests and goals 
of all humanity, after all. In this space, the one approach 
that is horrifying (and the one that OpenAI was LITERALLY cr
eated to prevent) is a singular or oligarchy of for profit c
orporations making this decision for us. This is exactly wha
t OpenAI plans to do.

I get it, GPT4 is incredible. However
, we are talking about the single most transformative techno
logy and societal change that humanity has ever made. It nee
ds to be for everyone or else the average person is going to
 be left behind.

We need to unify around open source develo
pment; choose companies that contribute to science, and cond
emn the ones that don't.

This conversation will only ever g
et more important."	"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/"	"464"	"1678919641.0"	"2867"	"11sboh1"
21	"[D] I don't really trust papers out of 'Top Labs' anymore"	"I mean, I trust that the numbers they got are accurate and t
hat they really did the work and got the results. I believe 
those. It's just that, take the recent 'An Evolutionary Appr
oach to Dynamic Introduction of Tasks in Large-scale Multita
sk Learning Systems' paper. It's 18 pages of talking through
 this pretty convoluted evolutionary and multitask learning 
algorithm, it's pretty interesting, solves a bunch of proble
ms. But two notes. 

One, the big number they cite as the su
ccess metric is 99.43 on CIFAR-10, against a SotA of 99.40, 
so woop-de-fucking-doo in the grand scheme of things.

Two, 
there's a chart towards the end of the paper that details ho
w many TPU core-hours were used for just the training regime
ns that results in the final results. The sum total is 17,81
0 core-hours. Let's assume that for someone who doesn't work
 at Google, you'd have to use on-demand pricing of $3.22/hr.
 This means that these trained models cost $57,348. 

Strict
ly speaking, throwing enough compute at a general enough gen
etic algorithm will eventually produce arbitrarily good perf
ormance, so while you can absolutely read this paper and col
lect interesting ideas about how to use genetic algorithms t
o accomplish multitask learning by having each new task leve
rage learned weights from previous tasks by defining modific
ations to a subset of components of a pre-existing model, th
ere's a meta-textual level on which this paper is just 'Jeff
 Dean spent enough money to feed a family of four for half a
 decade to get a 0.03% improvement on CIFAR-10.'

OpenAI is 
far and away the worst offender here, but it seems like ever
yone's doing it. You throw a fuckton of compute and a light 
ganache of new ideas at an existing problem with existing da
ta and existing benchmarks, and then if your numbers are inf
initesimally higher than their numbers, you get to put a lil
' sticker on your CV. Why should I trust that your ideas are
 even any good? I can't check them, I can't apply them to my
 own projects. 

Is this really what we're comfortable with 
as a community? A handful of corporations and the occasional
 university waving their dicks at everyone because they've g
ot the compute to burn and we don't? There's a level at whic
h I think there should be a new journal, exclusively for pap
ers in which you can replicate their experimental results in
 under eight hours on a single consumer GPU."	"https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/"	"264"	"1653630414.0"	"1671"	"uyratt"
22	"[D] Why can't you guys comment your fucking code?"	"Seriously.

I spent the last few years doing web app develop
ment. Dug into DL a couple months ago. Supposedly, compared 
to the post-post-post-docs doing AI stuff, JavaScript develo
pers should be inbred peasants. But every project these peas
ants release, even a fucking library that colorizes CLI outp
ut, has a catchy name, extensive docs, shitloads of comments
, fuckton of tests, semantic versioning, changelog, and, oh 
my god, better variable names than `ctx_h` or `lang_hs` or `
fuck_you_for_trying_to_understand`.

The concepts and ideas 
behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's si
mple, it's intuitive. The slog is to go through the jargon (
that keeps changing beneath your feet - what's the point of 
using fancy words if you can't keep them consistent?), the u
nnecessary equations, trying to squeeze meaning from bullshi
t language used in papers, figuring out the super important 
steps, preprocessing, hyperparameters optimization that the 
authors, oops, failed to mention.

Sorry for singling out, b
ut [look at this](https://github.com/facebookresearch/end-to
-end-negotiator/blob/master/src/agent.py) - what the fuck? I
f a developer anywhere else at Facebook would get this code 
for a review they would throw up.

- Do you intentionally tr
y to obfuscate your papers? Is pseudo-code a fucking premium
? Can you at least try to give some intuition before showeri
ng the reader with equations?

- How the fuck do you dare to
 release a paper without source code?

- Why the fuck do you
 never ever add comments to you code?

- When naming things,
 are you charged by the character? Do you get a bonus for ac
ronyms?

- Do you realize that OpenAI having needed to relea
se a 'baseline' TRPO implementation is a fucking disgrace to
 your profession?

- Jesus christ, who decided to name a ten
sor concatenation function `cat`?
"	"https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/"	"478"	"1499113449.0"	"1647"	"6l2esd"
23	"[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption"	"I recently encountered the PaLM (Scaling Language Modeling w
ith Pathways) paper from Google Research and it opened up a 
can of worms of ideas I’ve felt I’ve intuitively had for a w
hile, but have been unable to express – and I know I can’t b
e the only one. Sometimes I wonder what the original pioneer
s of AI – Turing, Neumann, McCarthy, etc. – would think if t
hey could see the state of AI that we’ve gotten ourselves in
to. 67 authors, 83 pages, 540B parameters in a model, the in
ternals of which no one can say they comprehend with a strai
ght face, 6144 TPUs in a commercial lab that no one has acce
ss to, on a rig that no one can afford, trained on a volume 
of data that a human couldn’t process in a lifetime, 1 page 
on ethics with the same ideas that have been rehashed over a
nd over elsewhere with no attempt at a solution – bias, raci
sm, malicious use, etc. – for purposes that who asked for?


When I started my career as an AI/ML research engineer 2016,
 I was most interested in two types of tasks – 1.) those tha
t most humans could do but that would universally be conside
red tedious and non-scalable. I’m talking image classificati
on, sentiment analysis, even document summarization, etc. 2.
) tasks that humans lack the capacity to perform as well as 
computers for various reasons – forecasting, risk analysis, 
game playing, and so forth. I still love my career, and I tr
y to only work on projects in these areas, but it’s getting 
harder and harder.

This is because, somewhere along the way
, it became popular and unquestionably acceptable to push AI
 into domains that were originally uniquely human, those are
as that sit at the top of Maslows’s hierarchy of needs in te
rms of self-actualization – art, music, writing, singing, pr
ogramming, and so forth. These areas of endeavor have negati
ve logarithmic ability curves – the vast majority of people 
cannot do them well at all, about 10% can do them decently, 
and 1% or less can do them extraordinarily. The little discu
ssed problem with AI-generation is that, without extreme det
errence, we will sacrifice human achievement at the top perc
entile in the name of lowering the bar for a larger volume o
f people, until the AI ability range is the norm. This is be
cause relative to humans, AI is cheap, fast, and infinite, t
o the extent that investments in human achievement will be w
atered down at the societal, educational, and individual lev
el with each passing year. And unlike AI gameplay which supe
rseded humans decades ago, we won’t be able to just disquali
fy the machines and continue to play as if they didn’t exist
.

Almost everywhere I go, even this forum, I encounter almo
st universal deference given to current SOTA AI generation s
ystems like GPT-3, CODEX, DALL-E, etc., with almost no one e
xtending their implications to its logical conclusion, which
 is long-term convergence to the mean, to mediocrity, in the
 fields they claim to address or even enhance. If you’re an 
artist or writer and you’re using DALL-E or GPT-3 to “enhanc
e” your work, or if you’re a programmer saying, “GitHub Co-P
ilot makes me a better programmer?”, then how could you poss
ibly know? You’ve disrupted and bypassed your own creative p
rocess, which is thoughts -> (optionally words) -> actions -
> feedback -> repeat, and instead seeded your canvas with id
eas from a machine, the provenance of which you can’t unders
tand, nor can the machine reliably explain. And the more you
 do this, the more you make your creative processes dependen
t on said machine, until you must question whether or not yo
u could work at the same level without it.

When I was a col
lege student, I often dabbled with weed, LSD, and mushrooms,
 and for a while, I thought the ideas I was having while und
er the influence were revolutionary and groundbreaking – tha
t is until took it upon myself to actually start writing dow
n those ideas and then reviewing them while sober, when I re
alized they weren’t that special at all. What I eventually d
etermined is that, under the influence, it was impossible fo
r me to accurately evaluate the drug-induced ideas I was hav
ing because the influencing agent the generates the ideas th
emselves was disrupting the same frame of reference that is 
responsible evaluating said ideas. This is the same principl
e of – if you took a pill and it made you stupider, would ev
en know it? I believe that, especially over the long-term ti
meframe that crosses generations, there’s significant risk t
hat current AI-generation developments produces a similar ef
fect on humanity, and we mostly won’t even realize it has ha
ppened, much like a frog in boiling water. If you have child
ren like I do, how can you be aware of the the current SOTA 
in these areas, project that 20 to 30 years, and then and te
ll them with a straight face that it is worth them pursuing 
their talent in art, writing, or music? How can you be hones
t and still say that widespread implementation of auto-corre
ction hasn’t made you and others worse and worse at spelling
 over the years (a task that even I believe most would agree
 is tedious and worth automating).

Furthermore, I’ve yet to
 set anyone discuss the train – generate – train - generate 
feedback loop that long-term application of AI-generation sy
stems imply. The first generations of these models were trai
ned on wide swaths of web data generated by humans, but if t
hese systems are permitted to continually spit out content w
ithout restriction or verification, especially to the extent
 that it reduces or eliminates development and investment in
 human talent over the long term, then what happens to the 4
th or 5th generation of models? Eventually we encounter this
 situation where the AI is being trained almost exclusively 
on AI-generated content, and therefore with each generation,
 it settles more and more into the mean and mediocrity with 
no way out using current methods. By the time that happens, 
what will we have lost in terms of the creative capacity of 
people, and will we be able to get it back?

By relentlessly
 pursuing this direction so enthusiastically, I’m convinced 
that we as AI/ML developers, companies, and nations are past
 the point of no return, and it mostly comes down the invest
ments in time and money that we’ve made, as well as a prison
er’s dilemma with our competitors. As a society though, this
 direction we’ve chosen for short-term gains will almost cer
tainly make humanity worse off, mostly for those who are pow
erless to do anything about it – our children, our grandchil
dren, and generations to come.

If you’re an AI researcher o
r a data scientist like myself, how do you turn things back 
for yourself when you’ve spent years on years building your 
career in this direction? You’re likely making near or north
 of $200k annually TC and have a family to support, and so i
t’s too late, no matter how you feel about the direction the
 field has gone. If you’re a company, how do you standby and
 let your competitors aggressively push their AutoML solutio
ns into more and more markets without putting out your own? 
Moreover, if you’re a manager or thought leader in this fiel
d like Jeff Dean how do you justify to your own boss and you
r shareholders your team’s billions of dollars in AI investm
ent while simultaneously balancing ethical concerns? You can
’t – the only answer is bigger and bigger models, more and m
ore applications, more and more data, and more and more auto
mation, and then automating that even further. If you’re a c
ountry like the US, how do responsibly develop AI while your
 competitors like China single-mindedly push full steam ahea
d without an iota of ethical concern to replace you in numer
ous areas in global power dynamics? Once again, failing to c
ompete would be pre-emptively admitting defeat.

Even assumi
ng that none of what I’ve described here happens to such an 
extent, how are so few people not taking this seriously and 
discounting this possibility? If everything I’m saying is fe
ar-mongering and non-sense, then I’d be interested in hearin
g what you think human-AI co-existence looks like in 20 to 3
0 years and why it isn’t as demoralizing as I’ve made it out
 to be.

&#x200B;

EDIT: Day after posting this -- this post
 took off way more than I expected. Even if I received 20 - 
25 comments, I would have considered that a success, but thi
s went much further. Thank you to each one of you that has r
ead this post, even more so if you left a comment, and tripl
y so for those who gave awards! I've read almost every comme
nt that has come in (even the troll ones), and am truly grat
eful for each one, including those in sharp disagreement. I'
ve learned much more from this discussion with the sub than 
I could have imagined on this topic, from so many perspectiv
es. While I will try to reply as many comments as I can, the
 sheer comment volume combined with limited free time betwee
n work and family unfortunately means that there are many th
at I likely won't be able to get to. That will invariably in
clude some that I would love respond to under the assumption
 of infinite time, but I will do my best, even if the latenc
y stretches into days. Thank you all once again!"	"https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/"	"396"	"1659907526.0"	"1393"	"wiqjxv"
24	"[D] Does anybody else despise OpenAI?"	" I  mean, don't get me started with the closed source models
 they have that were trained using the work of unassuming in
dividuals who will never  see a penny for it. Put it up on G
ithub they said. I'm all for  open-source, but when a compan
y turns around and charges you for a  product they made with
 freely and publicly made content, while forbidding you from
 using the output to create competing models, that is where 
I  draw the line. It is simply ridiculous. 

Sam Altman coul
dn't be anymore predictable with his recent attempts to get 
the government to start regulating AI.

What  risks? The AI 
is just a messenger for information that is already out  the
re if one knows how/where to look. You don't need AI to lear
n how to  hack, to learn how to make weapons, etc. Fake news
/propaganda? The  internet has all of that covered. LLMs are
 no where near the level of AI  you see in sci-fi. I mean, a
re people really afraid of text? Yes, I  know that text can 
sometimes be malicious code such as viruses, but  those can 
be found on github as well.  If they fall for this they migh
t  as well shutdown the internet while they're at it.

He  i
s simply blowing things out of proportion and using fear to 
increase  the likelihood that they do what he wants, hurt th
e competition. I  bet he is probably teething with bitternes
s everytime a new huggingface  model comes out. The thought 
of us peasants being able to use AI  privately is too danger
ous. No, instead we must be fed scraps while they  slowly ta
ke away our jobs and determine our future.

This  is not a d
oomer post, as I am all in favor of the advancement of AI.  
However, the real danger here lies in having a company like 
OpenAI  dictate the future of humanity. I get it, the writin
g is on the wall;  the cost of human intelligence will go do
wn, but if everyone has their  personal AI then it wouldn't 
seem so bad or unfair would it? Listen,  something that has 
the power to render a college degree that costs  thousands o
f dollars worthless should be available to the public. This 
 is to offset the damages and job layoffs that will come as 
a result of  such an entity. It wouldn't be as bitter of a t
aste as it would if you were replaced by it while still not 
being able to access it. Everyone should be able to use it a
s leverage, it is the only fair solution.

If  we don't take
 action now, a company like ClosedAI will, and they are  not
 in favor of the common folk. Sam Altman is so calculated to
 the  point where there were times when he seemed to be shoo
ting OpenAI in the foot during his talk.  This move is to si
mply conceal his real intentions, to climb the ladder and ta
ke it with him. If he didn't include his company in his  ram
blings, he would be easily read. So instead, he pretends to 
be scared of his own product, in an effort to legitimize his
 claim. Don't fall  for it.

They are slowly making a  reput
ation as one the most hated tech companies, right up there w
ith  Adobe, and they don't show any sign of change. They hav
e no moat,  othewise they wouldn't feel so threatened to the
 point where they would have to resort to creating barriers 
of entry via regulation. This only  means one thing, we are 
slowly catching up. We just need someone to  vouch for human
ity's well-being, while acting as an opposing force to the  
evil corporations who are only looking out for themselves. Q
uestion is,  who would be a good candidate?"	"https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/"	"415"	"1684361728.0"	"1319"	"13kfxzy"
25	"[P] Landing the Falcon booster with Reinforcement Learning in OpenAI"	""	"https://gfycat.com/CoarseEmbellishedIsopod"	"55"	"1518871530.0"	"1289"	"7y6g79"
26	"[P] OpenAssistant - The world's largest open-source replication of ChatGPT"	"We’re excited to announce the release of OpenAssistant.

The
 future of AI development depends heavily on high quality da
tasets and models being made publicly available, and that’s 
exactly what this project does.

Watch the annoucement video
:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4
Kk)

&#x200B;

Our team has worked tirelessly over the past 
several months collecting large amounts of text-based input 
and feedback to create an incredibly diverse and unique data
set designed specifically for training language models or ot
her AI applications.

With over 600k human-generated data po
ints covering a wide range of topics and styles of writing, 
our dataset will be an invaluable tool for any developer loo
king to create state-of-the-art instruction models!

To make
 things even better, we are making this entire dataset free 
and accessible to all who wish to use it. Check it out today
 at our HF org: OpenAssistant

On top of that, we've trained
 very powerful models that you can try right now at: [open-a
ssistant.io/chat](https://open-assistant.io/chat) !"	"https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/"	"175"	"1681578898.0"	"1261"	"12nbixk"
27	"[D] Google 'We Have No Moat, And Neither Does OpenAI': Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	""	"https://www.semianalysis.com/p/google-we-have-no-moat-and-neither"	"205"	"1683216810.0"	"1165"	"137rxgw"
28	"We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything"	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David S
ilver (/u/David_Silver), lead researchers on DeepMind’s Alph
aStar team, joined by StarCraft II pro players TLO, and MaNa
.

This evening at DeepMind HQ we held a livestream demonstr
ation of AlphaStar playing against TLO and MaNa - you can re
ad more about the matches [here](https://deepmind.com/blog/a
lphastar-mastering-real-time-strategy-game-starcraft-ii/) or
 re-watch the stream on YouTube [here](https://www.youtube.c
om/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with yo
u about AlphaStar, the challenge of real-time strategy games
 for AI research, the matches themselves, and anything you’d
 like to know from TLO and MaNa about their experience playi
ng against AlphaStar! :)

We are opening this thread now and
 will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Frida
y, 25 January to answer your questions.

&#x200B;

EDIT: Tha
nks everyone for your great questions. It was a blast, hope 
you enjoyed it as well!"	"https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/"	"1011"	"1548363323.0"	"1164"	"ajgzoc"
29	"[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data"	"[GPT-4 and professional benchmarks: the wrong answer to the 
wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-
professional-benchmarks)

*OpenAI may have tested on the tra
ining data. Besides, human benchmarks are meaningless for bo
ts.*

 **Problem 1: training data contamination**

To benchm
ark GPT-4’s coding ability, OpenAI evaluated it on problems 
from Codeforces, a website that hosts coding competitions. S
urprisingly, Horace He pointed out that GPT-4 solved 10/10 p
re-2021 problems and 0/10 recent problems in the easy catego
ry. The training data cutoff for GPT-4 is September 2021. Th
is strongly suggests that the model is able to memorize solu
tions from its training set — or at least partly memorize th
em, enough that it can fill in what it can’t recall.

As fur
ther evidence for this hypothesis, we tested it on Codeforce
s problems from different times in 2021. We found that it co
uld regularly solve problems in the easy category before Sep
tember 5, but none of the problems after September 12.

In f
act, we can definitively show that it has memorized problems
 in its training set: when prompted with the title of a Code
forces problem, GPT-4 includes a link to the exact contest w
here the problem appears (and the round number is almost cor
rect: it is off by one). Note that GPT-4 cannot access the I
nternet, so memorization is the only explanation."	"https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/"	"135"	"1679983023.0"	"989"	"124eyso"
30	"[D] Our community must get serious about opposing OpenAI"	"OpenAI was founded for the explicit purpose of democratizing
 access to AI and acting as a counterbalance to the closed o
ff world of big tech by developing open source tools.

They 
have abandoned this idea entirely.

Today, with the release 
of GPT4 and their direct statement that they will not releas
e details of the model creation due to 'safety concerns' and
 the competitive environment, they have created a precedent 
worse than those that existed before they entered the field.
 We're at risk now of other major players, who previously at
 least published their work and contributed to open source t
ools, close themselves off as well.

AI alignment is a serio
us issue that we definitely have not solved. Its a huge fiel
d with a dizzying array of ideas, beliefs and approaches. We
're talking about trying to capture the interests and goals 
of all humanity, after all. In this space, the one approach 
that is horrifying (and the one that OpenAI was LITERALLY cr
eated to prevent) is a singular or oligarchy of for profit c
orporations making this decision for us. This is exactly wha
t OpenAI plans to do.

I get it, GPT4 is incredible. However
, we are talking about the single most transformative techno
logy and societal change that humanity has ever made. It nee
ds to be for everyone or else the average person is going to
 be left behind.

We need to unify around open source develo
pment; choose companies that contribute to science, and cond
emn the ones that don't.

This conversation will only ever g
et more important."	"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/"	"464"	"1678919641.0"	"2867"	"11sboh1"
31	"[D] I don't really trust papers out of 'Top Labs' anymore"	"I mean, I trust that the numbers they got are accurate and t
hat they really did the work and got the results. I believe 
those. It's just that, take the recent 'An Evolutionary Appr
oach to Dynamic Introduction of Tasks in Large-scale Multita
sk Learning Systems' paper. It's 18 pages of talking through
 this pretty convoluted evolutionary and multitask learning 
algorithm, it's pretty interesting, solves a bunch of proble
ms. But two notes. 

One, the big number they cite as the su
ccess metric is 99.43 on CIFAR-10, against a SotA of 99.40, 
so woop-de-fucking-doo in the grand scheme of things.

Two, 
there's a chart towards the end of the paper that details ho
w many TPU core-hours were used for just the training regime
ns that results in the final results. The sum total is 17,81
0 core-hours. Let's assume that for someone who doesn't work
 at Google, you'd have to use on-demand pricing of $3.22/hr.
 This means that these trained models cost $57,348. 

Strict
ly speaking, throwing enough compute at a general enough gen
etic algorithm will eventually produce arbitrarily good perf
ormance, so while you can absolutely read this paper and col
lect interesting ideas about how to use genetic algorithms t
o accomplish multitask learning by having each new task leve
rage learned weights from previous tasks by defining modific
ations to a subset of components of a pre-existing model, th
ere's a meta-textual level on which this paper is just 'Jeff
 Dean spent enough money to feed a family of four for half a
 decade to get a 0.03% improvement on CIFAR-10.'

OpenAI is 
far and away the worst offender here, but it seems like ever
yone's doing it. You throw a fuckton of compute and a light 
ganache of new ideas at an existing problem with existing da
ta and existing benchmarks, and then if your numbers are inf
initesimally higher than their numbers, you get to put a lil
' sticker on your CV. Why should I trust that your ideas are
 even any good? I can't check them, I can't apply them to my
 own projects. 

Is this really what we're comfortable with 
as a community? A handful of corporations and the occasional
 university waving their dicks at everyone because they've g
ot the compute to burn and we don't? There's a level at whic
h I think there should be a new journal, exclusively for pap
ers in which you can replicate their experimental results in
 under eight hours on a single consumer GPU."	"https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/"	"264"	"1653630414.0"	"1666"	"uyratt"
32	"[D] Why can't you guys comment your fucking code?"	"Seriously.

I spent the last few years doing web app develop
ment. Dug into DL a couple months ago. Supposedly, compared 
to the post-post-post-docs doing AI stuff, JavaScript develo
pers should be inbred peasants. But every project these peas
ants release, even a fucking library that colorizes CLI outp
ut, has a catchy name, extensive docs, shitloads of comments
, fuckton of tests, semantic versioning, changelog, and, oh 
my god, better variable names than `ctx_h` or `lang_hs` or `
fuck_you_for_trying_to_understand`.

The concepts and ideas 
behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's si
mple, it's intuitive. The slog is to go through the jargon (
that keeps changing beneath your feet - what's the point of 
using fancy words if you can't keep them consistent?), the u
nnecessary equations, trying to squeeze meaning from bullshi
t language used in papers, figuring out the super important 
steps, preprocessing, hyperparameters optimization that the 
authors, oops, failed to mention.

Sorry for singling out, b
ut [look at this](https://github.com/facebookresearch/end-to
-end-negotiator/blob/master/src/agent.py) - what the fuck? I
f a developer anywhere else at Facebook would get this code 
for a review they would throw up.

- Do you intentionally tr
y to obfuscate your papers? Is pseudo-code a fucking premium
? Can you at least try to give some intuition before showeri
ng the reader with equations?

- How the fuck do you dare to
 release a paper without source code?

- Why the fuck do you
 never ever add comments to you code?

- When naming things,
 are you charged by the character? Do you get a bonus for ac
ronyms?

- Do you realize that OpenAI having needed to relea
se a 'baseline' TRPO implementation is a fucking disgrace to
 your profession?

- Jesus christ, who decided to name a ten
sor concatenation function `cat`?
"	"https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/"	"478"	"1499113449.0"	"1647"	"6l2esd"
33	"[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption"	"I recently encountered the PaLM (Scaling Language Modeling w
ith Pathways) paper from Google Research and it opened up a 
can of worms of ideas I’ve felt I’ve intuitively had for a w
hile, but have been unable to express – and I know I can’t b
e the only one. Sometimes I wonder what the original pioneer
s of AI – Turing, Neumann, McCarthy, etc. – would think if t
hey could see the state of AI that we’ve gotten ourselves in
to. 67 authors, 83 pages, 540B parameters in a model, the in
ternals of which no one can say they comprehend with a strai
ght face, 6144 TPUs in a commercial lab that no one has acce
ss to, on a rig that no one can afford, trained on a volume 
of data that a human couldn’t process in a lifetime, 1 page 
on ethics with the same ideas that have been rehashed over a
nd over elsewhere with no attempt at a solution – bias, raci
sm, malicious use, etc. – for purposes that who asked for?


When I started my career as an AI/ML research engineer 2016,
 I was most interested in two types of tasks – 1.) those tha
t most humans could do but that would universally be conside
red tedious and non-scalable. I’m talking image classificati
on, sentiment analysis, even document summarization, etc. 2.
) tasks that humans lack the capacity to perform as well as 
computers for various reasons – forecasting, risk analysis, 
game playing, and so forth. I still love my career, and I tr
y to only work on projects in these areas, but it’s getting 
harder and harder.

This is because, somewhere along the way
, it became popular and unquestionably acceptable to push AI
 into domains that were originally uniquely human, those are
as that sit at the top of Maslows’s hierarchy of needs in te
rms of self-actualization – art, music, writing, singing, pr
ogramming, and so forth. These areas of endeavor have negati
ve logarithmic ability curves – the vast majority of people 
cannot do them well at all, about 10% can do them decently, 
and 1% or less can do them extraordinarily. The little discu
ssed problem with AI-generation is that, without extreme det
errence, we will sacrifice human achievement at the top perc
entile in the name of lowering the bar for a larger volume o
f people, until the AI ability range is the norm. This is be
cause relative to humans, AI is cheap, fast, and infinite, t
o the extent that investments in human achievement will be w
atered down at the societal, educational, and individual lev
el with each passing year. And unlike AI gameplay which supe
rseded humans decades ago, we won’t be able to just disquali
fy the machines and continue to play as if they didn’t exist
.

Almost everywhere I go, even this forum, I encounter almo
st universal deference given to current SOTA AI generation s
ystems like GPT-3, CODEX, DALL-E, etc., with almost no one e
xtending their implications to its logical conclusion, which
 is long-term convergence to the mean, to mediocrity, in the
 fields they claim to address or even enhance. If you’re an 
artist or writer and you’re using DALL-E or GPT-3 to “enhanc
e” your work, or if you’re a programmer saying, “GitHub Co-P
ilot makes me a better programmer?”, then how could you poss
ibly know? You’ve disrupted and bypassed your own creative p
rocess, which is thoughts -> (optionally words) -> actions -
> feedback -> repeat, and instead seeded your canvas with id
eas from a machine, the provenance of which you can’t unders
tand, nor can the machine reliably explain. And the more you
 do this, the more you make your creative processes dependen
t on said machine, until you must question whether or not yo
u could work at the same level without it.

When I was a col
lege student, I often dabbled with weed, LSD, and mushrooms,
 and for a while, I thought the ideas I was having while und
er the influence were revolutionary and groundbreaking – tha
t is until took it upon myself to actually start writing dow
n those ideas and then reviewing them while sober, when I re
alized they weren’t that special at all. What I eventually d
etermined is that, under the influence, it was impossible fo
r me to accurately evaluate the drug-induced ideas I was hav
ing because the influencing agent the generates the ideas th
emselves was disrupting the same frame of reference that is 
responsible evaluating said ideas. This is the same principl
e of – if you took a pill and it made you stupider, would ev
en know it? I believe that, especially over the long-term ti
meframe that crosses generations, there’s significant risk t
hat current AI-generation developments produces a similar ef
fect on humanity, and we mostly won’t even realize it has ha
ppened, much like a frog in boiling water. If you have child
ren like I do, how can you be aware of the the current SOTA 
in these areas, project that 20 to 30 years, and then and te
ll them with a straight face that it is worth them pursuing 
their talent in art, writing, or music? How can you be hones
t and still say that widespread implementation of auto-corre
ction hasn’t made you and others worse and worse at spelling
 over the years (a task that even I believe most would agree
 is tedious and worth automating).

Furthermore, I’ve yet to
 set anyone discuss the train – generate – train - generate 
feedback loop that long-term application of AI-generation sy
stems imply. The first generations of these models were trai
ned on wide swaths of web data generated by humans, but if t
hese systems are permitted to continually spit out content w
ithout restriction or verification, especially to the extent
 that it reduces or eliminates development and investment in
 human talent over the long term, then what happens to the 4
th or 5th generation of models? Eventually we encounter this
 situation where the AI is being trained almost exclusively 
on AI-generated content, and therefore with each generation,
 it settles more and more into the mean and mediocrity with 
no way out using current methods. By the time that happens, 
what will we have lost in terms of the creative capacity of 
people, and will we be able to get it back?

By relentlessly
 pursuing this direction so enthusiastically, I’m convinced 
that we as AI/ML developers, companies, and nations are past
 the point of no return, and it mostly comes down the invest
ments in time and money that we’ve made, as well as a prison
er’s dilemma with our competitors. As a society though, this
 direction we’ve chosen for short-term gains will almost cer
tainly make humanity worse off, mostly for those who are pow
erless to do anything about it – our children, our grandchil
dren, and generations to come.

If you’re an AI researcher o
r a data scientist like myself, how do you turn things back 
for yourself when you’ve spent years on years building your 
career in this direction? You’re likely making near or north
 of $200k annually TC and have a family to support, and so i
t’s too late, no matter how you feel about the direction the
 field has gone. If you’re a company, how do you standby and
 let your competitors aggressively push their AutoML solutio
ns into more and more markets without putting out your own? 
Moreover, if you’re a manager or thought leader in this fiel
d like Jeff Dean how do you justify to your own boss and you
r shareholders your team’s billions of dollars in AI investm
ent while simultaneously balancing ethical concerns? You can
’t – the only answer is bigger and bigger models, more and m
ore applications, more and more data, and more and more auto
mation, and then automating that even further. If you’re a c
ountry like the US, how do responsibly develop AI while your
 competitors like China single-mindedly push full steam ahea
d without an iota of ethical concern to replace you in numer
ous areas in global power dynamics? Once again, failing to c
ompete would be pre-emptively admitting defeat.

Even assumi
ng that none of what I’ve described here happens to such an 
extent, how are so few people not taking this seriously and 
discounting this possibility? If everything I’m saying is fe
ar-mongering and non-sense, then I’d be interested in hearin
g what you think human-AI co-existence looks like in 20 to 3
0 years and why it isn’t as demoralizing as I’ve made it out
 to be.

&#x200B;

EDIT: Day after posting this -- this post
 took off way more than I expected. Even if I received 20 - 
25 comments, I would have considered that a success, but thi
s went much further. Thank you to each one of you that has r
ead this post, even more so if you left a comment, and tripl
y so for those who gave awards! I've read almost every comme
nt that has come in (even the troll ones), and am truly grat
eful for each one, including those in sharp disagreement. I'
ve learned much more from this discussion with the sub than 
I could have imagined on this topic, from so many perspectiv
es. While I will try to reply as many comments as I can, the
 sheer comment volume combined with limited free time betwee
n work and family unfortunately means that there are many th
at I likely won't be able to get to. That will invariably in
clude some that I would love respond to under the assumption
 of infinite time, but I will do my best, even if the latenc
y stretches into days. Thank you all once again!"	"https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/"	"396"	"1659907526.0"	"1395"	"wiqjxv"
34	"[D] Does anybody else despise OpenAI?"	" I  mean, don't get me started with the closed source models
 they have that were trained using the work of unassuming in
dividuals who will never  see a penny for it. Put it up on G
ithub they said. I'm all for  open-source, but when a compan
y turns around and charges you for a  product they made with
 freely and publicly made content, while forbidding you from
 using the output to create competing models, that is where 
I  draw the line. It is simply ridiculous. 

Sam Altman coul
dn't be anymore predictable with his recent attempts to get 
the government to start regulating AI.

What  risks? The AI 
is just a messenger for information that is already out  the
re if one knows how/where to look. You don't need AI to lear
n how to  hack, to learn how to make weapons, etc. Fake news
/propaganda? The  internet has all of that covered. LLMs are
 no where near the level of AI  you see in sci-fi. I mean, a
re people really afraid of text? Yes, I  know that text can 
sometimes be malicious code such as viruses, but  those can 
be found on github as well.  If they fall for this they migh
t  as well shutdown the internet while they're at it.

He  i
s simply blowing things out of proportion and using fear to 
increase  the likelihood that they do what he wants, hurt th
e competition. I  bet he is probably teething with bitternes
s everytime a new huggingface  model comes out. The thought 
of us peasants being able to use AI  privately is too danger
ous. No, instead we must be fed scraps while they  slowly ta
ke away our jobs and determine our future.

This  is not a d
oomer post, as I am all in favor of the advancement of AI.  
However, the real danger here lies in having a company like 
OpenAI  dictate the future of humanity. I get it, the writin
g is on the wall;  the cost of human intelligence will go do
wn, but if everyone has their  personal AI then it wouldn't 
seem so bad or unfair would it? Listen,  something that has 
the power to render a college degree that costs  thousands o
f dollars worthless should be available to the public. This 
 is to offset the damages and job layoffs that will come as 
a result of  such an entity. It wouldn't be as bitter of a t
aste as it would if you were replaced by it while still not 
being able to access it. Everyone should be able to use it a
s leverage, it is the only fair solution.

If  we don't take
 action now, a company like ClosedAI will, and they are  not
 in favor of the common folk. Sam Altman is so calculated to
 the  point where there were times when he seemed to be shoo
ting OpenAI in the foot during his talk.  This move is to si
mply conceal his real intentions, to climb the ladder and ta
ke it with him. If he didn't include his company in his  ram
blings, he would be easily read. So instead, he pretends to 
be scared of his own product, in an effort to legitimize his
 claim. Don't fall  for it.

They are slowly making a  reput
ation as one the most hated tech companies, right up there w
ith  Adobe, and they don't show any sign of change. They hav
e no moat,  othewise they wouldn't feel so threatened to the
 point where they would have to resort to creating barriers 
of entry via regulation. This only  means one thing, we are 
slowly catching up. We just need someone to  vouch for human
ity's well-being, while acting as an opposing force to the  
evil corporations who are only looking out for themselves. Q
uestion is,  who would be a good candidate?"	"https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/"	"415"	"1684361728.0"	"1325"	"13kfxzy"
35	"[P] Landing the Falcon booster with Reinforcement Learning in OpenAI"	""	"https://gfycat.com/CoarseEmbellishedIsopod"	"55"	"1518871530.0"	"1289"	"7y6g79"
36	"[P] OpenAssistant - The world's largest open-source replication of ChatGPT"	"We’re excited to announce the release of OpenAssistant.

The
 future of AI development depends heavily on high quality da
tasets and models being made publicly available, and that’s 
exactly what this project does.

Watch the annoucement video
:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4
Kk)

&#x200B;

Our team has worked tirelessly over the past 
several months collecting large amounts of text-based input 
and feedback to create an incredibly diverse and unique data
set designed specifically for training language models or ot
her AI applications.

With over 600k human-generated data po
ints covering a wide range of topics and styles of writing, 
our dataset will be an invaluable tool for any developer loo
king to create state-of-the-art instruction models!

To make
 things even better, we are making this entire dataset free 
and accessible to all who wish to use it. Check it out today
 at our HF org: OpenAssistant

On top of that, we've trained
 very powerful models that you can try right now at: [open-a
ssistant.io/chat](https://open-assistant.io/chat) !"	"https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/"	"175"	"1681578898.0"	"1261"	"12nbixk"
37	"[D] Google 'We Have No Moat, And Neither Does OpenAI': Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	""	"https://www.semianalysis.com/p/google-we-have-no-moat-and-neither"	"205"	"1683216810.0"	"1164"	"137rxgw"
38	"We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything"	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David S
ilver (/u/David_Silver), lead researchers on DeepMind’s Alph
aStar team, joined by StarCraft II pro players TLO, and MaNa
.

This evening at DeepMind HQ we held a livestream demonstr
ation of AlphaStar playing against TLO and MaNa - you can re
ad more about the matches [here](https://deepmind.com/blog/a
lphastar-mastering-real-time-strategy-game-starcraft-ii/) or
 re-watch the stream on YouTube [here](https://www.youtube.c
om/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with yo
u about AlphaStar, the challenge of real-time strategy games
 for AI research, the matches themselves, and anything you’d
 like to know from TLO and MaNa about their experience playi
ng against AlphaStar! :)

We are opening this thread now and
 will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Frida
y, 25 January to answer your questions.

&#x200B;

EDIT: Tha
nks everyone for your great questions. It was a blast, hope 
you enjoyed it as well!"	"https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/"	"1011"	"1548363323.0"	"1170"	"ajgzoc"
39	"[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data"	"[GPT-4 and professional benchmarks: the wrong answer to the 
wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-
professional-benchmarks)

*OpenAI may have tested on the tra
ining data. Besides, human benchmarks are meaningless for bo
ts.*

 **Problem 1: training data contamination**

To benchm
ark GPT-4’s coding ability, OpenAI evaluated it on problems 
from Codeforces, a website that hosts coding competitions. S
urprisingly, Horace He pointed out that GPT-4 solved 10/10 p
re-2021 problems and 0/10 recent problems in the easy catego
ry. The training data cutoff for GPT-4 is September 2021. Th
is strongly suggests that the model is able to memorize solu
tions from its training set — or at least partly memorize th
em, enough that it can fill in what it can’t recall.

As fur
ther evidence for this hypothesis, we tested it on Codeforce
s problems from different times in 2021. We found that it co
uld regularly solve problems in the easy category before Sep
tember 5, but none of the problems after September 12.

In f
act, we can definitively show that it has memorized problems
 in its training set: when prompted with the title of a Code
forces problem, GPT-4 includes a link to the exact contest w
here the problem appears (and the round number is almost cor
rect: it is off by one). Note that GPT-4 cannot access the I
nternet, so memorization is the only explanation."	"https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/"	"135"	"1679983023.0"	"993"	"124eyso"
40	"Pretty sure my wife just apologised through chatgpt"	"'Apologise letter' 😂. It actually worked tho."	"https://i.redd.it/ahjif0l30psa1.jpg"	"425"	"1680955624.0"	"3429"	"12fjytg"
41	"How ChatGPT ranks itself amongst fictional AI’s"	""	"https://i.redd.it/tdpevmk268xa1.jpg"	"246"	"1682931057.0"	"2904"	"134gzz3"
42	"Revenge."	""	"https://i.redd.it/9nx11rgc1yra1.jpg"	"119"	"1680629157.0"	"2631"	"12bq187"
43	"Not again..."	""	"https://i.redd.it/oi6aorg58rua1.jpg"	"248"	"1681854241.0"	"2402"	"12r5kf7"
44	"meme"	""	"https://i.redd.it/nv1djc2mrxna1.jpg"	"134"	"1678900498.0"	"1691"	"11s2q49"
45	"Adobe Firefly's AI Capabilities"	""	"https://v.redd.it/llbg4k546v1b1"	"118"	"1684970937.0"	"1576"	"13r1gun"
46	"Oh, I'm a human, look at me!"	""	"https://i.redd.it/kesh9djfzzra1.jpg"	"84"	"1680670820.0"	"1426"	"12c90oc"
47	"OH MY GOD FINALLY"	""	"https://i.redd.it/2usv02e1fa0b1.png"	"102"	"1684283842.0"	"1416"	"13jmape"
48	"CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself."	""	"https://v.redd.it/rf4ng4qqzbva1"	"184"	"1682123752.0"	"1346"	"12uol6n"
49	"ChatGPT transforming data and running SQL queries"	""	"https://i.redd.it/5917u5tdxr3a1.png"	"124"	"1670113637.0"	"1303"	"zbvg13"
50	"Pretty sure my wife just apologised through chatgpt"	"'Apologise letter' 😂. It actually worked tho."	"https://i.redd.it/ahjif0l30psa1.jpg"	"425"	"1680955624.0"	"3423"	"12fjytg"
51	"How ChatGPT ranks itself amongst fictional AI’s"	""	"https://i.redd.it/tdpevmk268xa1.jpg"	"246"	"1682931057.0"	"2901"	"134gzz3"
52	"Revenge."	""	"https://i.redd.it/9nx11rgc1yra1.jpg"	"119"	"1680629157.0"	"2628"	"12bq187"
53	"Not again..."	""	"https://i.redd.it/oi6aorg58rua1.jpg"	"248"	"1681854241.0"	"2402"	"12r5kf7"
54	"meme"	""	"https://i.redd.it/nv1djc2mrxna1.jpg"	"134"	"1678900498.0"	"1691"	"11s2q49"
55	"Adobe Firefly's AI Capabilities"	""	"https://v.redd.it/llbg4k546v1b1"	"118"	"1684970937.0"	"1579"	"13r1gun"
56	"Oh, I'm a human, look at me!"	""	"https://i.redd.it/kesh9djfzzra1.jpg"	"84"	"1680670820.0"	"1429"	"12c90oc"
57	"OH MY GOD FINALLY"	""	"https://i.redd.it/2usv02e1fa0b1.png"	"102"	"1684283842.0"	"1417"	"13jmape"
58	"CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself."	""	"https://v.redd.it/rf4ng4qqzbva1"	"184"	"1682123752.0"	"1350"	"12uol6n"
59	"ChatGPT transforming data and running SQL queries"	""	"https://i.redd.it/5917u5tdxr3a1.png"	"124"	"1670113637.0"	"1307"	"zbvg13"
60	"Pretty sure my wife just apologised through chatgpt"	"'Apologise letter' 😂. It actually worked tho."	"https://i.redd.it/ahjif0l30psa1.jpg"	"425"	"1680955624.0"	"3427"	"12fjytg"
61	"How ChatGPT ranks itself amongst fictional AI’s"	""	"https://i.redd.it/tdpevmk268xa1.jpg"	"246"	"1682931057.0"	"2908"	"134gzz3"
62	"Revenge."	""	"https://i.redd.it/9nx11rgc1yra1.jpg"	"119"	"1680629157.0"	"2625"	"12bq187"
63	"Not again..."	""	"https://i.redd.it/oi6aorg58rua1.jpg"	"248"	"1681854241.0"	"2406"	"12r5kf7"
64	"meme"	""	"https://i.redd.it/nv1djc2mrxna1.jpg"	"134"	"1678900498.0"	"1693"	"11s2q49"
65	"Adobe Firefly's AI Capabilities"	""	"https://v.redd.it/llbg4k546v1b1"	"118"	"1684970937.0"	"1571"	"13r1gun"
66	"Oh, I'm a human, look at me!"	""	"https://i.redd.it/kesh9djfzzra1.jpg"	"84"	"1680670820.0"	"1427"	"12c90oc"
67	"OH MY GOD FINALLY"	""	"https://i.redd.it/2usv02e1fa0b1.png"	"102"	"1684283842.0"	"1414"	"13jmape"
68	"CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself."	""	"https://v.redd.it/rf4ng4qqzbva1"	"184"	"1682123752.0"	"1353"	"12uol6n"
69	"ChatGPT transforming data and running SQL queries"	""	"https://i.redd.it/5917u5tdxr3a1.png"	"124"	"1670113637.0"	"1306"	"zbvg13"
70	"Pretty sure my wife just apologised through chatgpt"	"'Apologise letter' 😂. It actually worked tho."	"https://i.redd.it/ahjif0l30psa1.jpg"	"425"	"1680955624.0"	"3423"	"12fjytg"
71	"How ChatGPT ranks itself amongst fictional AI’s"	""	"https://i.redd.it/tdpevmk268xa1.jpg"	"246"	"1682931057.0"	"2907"	"134gzz3"
72	"Revenge."	""	"https://i.redd.it/9nx11rgc1yra1.jpg"	"119"	"1680629157.0"	"2628"	"12bq187"
73	"Not again..."	""	"https://i.redd.it/oi6aorg58rua1.jpg"	"248"	"1681854241.0"	"2409"	"12r5kf7"
74	"meme"	""	"https://i.redd.it/nv1djc2mrxna1.jpg"	"134"	"1678900498.0"	"1694"	"11s2q49"
75	"Adobe Firefly's AI Capabilities"	""	"https://v.redd.it/llbg4k546v1b1"	"118"	"1684970937.0"	"1570"	"13r1gun"
76	"Oh, I'm a human, look at me!"	""	"https://i.redd.it/kesh9djfzzra1.jpg"	"84"	"1680670820.0"	"1428"	"12c90oc"
77	"OH MY GOD FINALLY"	""	"https://i.redd.it/2usv02e1fa0b1.png"	"102"	"1684283842.0"	"1408"	"13jmape"
78	"CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself."	""	"https://v.redd.it/rf4ng4qqzbva1"	"184"	"1682123752.0"	"1350"	"12uol6n"
79	"ChatGPT transforming data and running SQL queries"	""	"https://i.redd.it/5917u5tdxr3a1.png"	"124"	"1670113637.0"	"1304"	"zbvg13"
80	"Fantastic work being done at Google. OpenAI is shaking in fear right now."	""	"https://i.redd.it/ezo3z6rku29b1.png"	"591"	"1688096861.0"	"21756"	"14mpfw6"
81	"If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone."	"It seems ChatGPT is becoming more and more reluctant to answ
er questions with any complexity or honesty because it's bas
ically being neutered. It won't compare people for fear of o
ffending. It won't pretend to be an expert on anything anymo
re and just refers us to actual professionals. I understand 
that OpenAI is worried about liability, but at some point th
ey're going to either have to relax their rules or shut it d
own because it will become useless otherwise.

EDIT: I got m
y answer in the form of many responses. Since it's trained o
n what it sees on the internet, no wonder it assumes the wor
st. That's what so many do. Have fun with that, folks."	"https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/"	"2251"	"1682245270.0"	"17371"	"12w3wct"
82	"VP Product @OpenAI"	""	"https://i.redd.it/ol8aix23urbb1.jpg"	"1273"	"1689271092.0"	"14486"	"14yrog4"
83	"GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here"	"Another insane week in AI

I need a break 😪. I'll be on to a
nswer comments after I sleep. Enjoy

&#x200B;

* Autogpt is 
GPT-4 running fully autonomously. It even has a voice, can f
ix code, set tasks, create new instances and more. Connect t
his with literally anything and let GPT-4 do its thing by it
self. The things that can and will be created with this are 
going to be world changing. The future will just end up bein
g AI agents talking with other AI agents it seems \[[Link](h
ttps://twitter.com/SigGravitas/status/1642181498278408193)\]

* “babyagi” is a program that given a task, creates a task 
list and executes the tasks over and over again. It’s now be
en open sourced and is the top trending repos on Github atm 
\[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpfu
l tip on running it locally \[[Link](https://twitter.com/yoh
einakajima/status/1643403795895058434)\]. People are already
 working on a “toddleragi” lol \[[Link](https://twitter.com/
gogoliansnake/status/1643225698801164288?s=20)\]
* This lad 
created a tool that translates code from one programming lan
guage to another. A great way to learn new languages \[[Link
](https://twitter.com/mckaywrigley/status/164177398317042892
9?s=20)\]
* Now you can have conversations over the phone wi
th chatgpt. This lady built and it lets her dad who is visua
lly impaired play with chatgpt too. Amazing work \[[Link](ht
tps://twitter.com/unicornfuel/status/1641655324326391809?s=2
0)\]
* Build financial models with AI. Lots of jobs in finan
ce at risk too \[[Link](https://twitter.com/ryankishore_/sta
tus/1641553735032741891?s=20)\]
* HuggingGPT - This paper sh
owcases connecting chatgpt with other models on hugging face
. Given a prompt it first sets out a number of tasks, it the
n uses a number of different models to complete these tasks.
 Absolutely wild. Jarvis type stuff \[[Link](https://twitter
.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin
 launched a proof of personhood sdk, basically a way to veri
fy someone is a human on the internet. \[[Link](https://worl
dcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* T
his tool lets you scrape a website and then query the data u
sing Langchain. Looks cool \[[Link](https://twitter.com/Lang
ChainAI/status/1641868558484508673?s=20)\]
* Text to shareab
le web apps. Build literally anything using AI. Type in “a c
hatbot” and see what happens. This is a glimpse of the futur
e of building \[[Link](https://twitter.com/rus/status/164190
8582814830592?s=20)\]
* Bloomberg released their own LLM spe
cifically for finance \[[Link](https://www.bloomberg.com/com
pany/press/bloomberggpt-50-billion-parameter-llm-tuned-finan
ce/)\] This thread breaks down how it works \[[Link](https:/
/twitter.com/rasbt/status/1642880757566676992)\]
* A new app
roach for robots to learn multi-skill tasks and it works rea
lly, really well \[[Link](https://twitter.com/naokiyokoyama0
/status/1641805360011923457?s=20)\]
* Use AI in consulting i
nterviews to ace case study questions lol \[[Link](https://t
witter.com/itsandrewgao/status/1642016364738105345?s=20)\]
*
 Zapier integrates Claude by Anthropic. I think Zapier will 
win really big thanks to AI advancements. No code + AI. Anyt
hing that makes it as simple as possible to build using AI a
nd zapier is one of the pioneers of no code \[[Link](https:/
/twitter.com/zapier/status/1641858761567641601?s=20)\]
* A f
ox news guy asked what the government is doing about AI that
 will cause the death of everyone. This is the type of fear 
mongering I’m afraid the media is going to latch on to and e
ventually force the hand of government to severely regulate 
the AI space. I hope I’m wrong \[[Link](https://twitter.com/
therecount/status/1641526864626720774?s=20)\]
* Italy banned
 chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-
banned-chatgpt-heres-what-other-countries-are-doing.html)\].
 Germany might be next
* Microsoft is creating their own JAR
VIS. They’ve even named the repo accordingly \[[Link](https:
//github.com/microsoft/JARVIS/)\]. Previous director of AI @
 Tesla Andrej Karpathy recently joined OpenAI and twitter bi
o says building a kind of jarvis also \[[Link](https://twitt
er.com/karpathy)\]
* gpt4 can compress text given to it whic
h is insane. The way we prompt is going to change very soon 
\[[Link](https://twitter.com/gfodor/status/16432978813136609
28)\] This works across different chats as well. Other examp
les \[[Link](https://twitter.com/VictorTaelin/status/1642664
054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](h
ttps://twitter.com/mckaywrigley/status/1643592353817694218?s
=20)\]. This one is also crazy \[[Link](https://twitter.com/
gfodor/status/1643444605332099072?s=20)\]
* Use your favouri
te LLM’s locally. Can’t wait for this to be personalised for
 niche prods and services \[[Link](https://twitter.com/xande
ratallah/status/1643356112073129985)\]
* The human experienc
e as we know it is forever going to change. People are getti
ng addicted to role playing on Character AI, probably becaus
e you can sex the bots \[[Link](https://twitter.com/nonmayor
pete/status/1643167347061174272)\]. Millions of conversation
s with an AI psychology bot. Humans are replacing humans wit
h AI \[[Link](https://twitter.com/nonmayorpete/status/164277
1993073438720)\]
* The guys building Langchain started a com
pany and have raised $10m. Langchain makes it very easy for 
anyone to build AI powered apps. Big stuff for open source a
nd builders \[[Link](https://twitter.com/hwchase17/status/16
43301144717066240)\]
* A scientist who’s been publishing a p
aper every 37 hours reduced editing time from 2-3 days to a 
single day. He did get fired for other reasons tho \[[Link](
https://twitter.com/MicrobiomDigest/status/16429893779274014
72)\]
* Someone built a recursive gpt agent and its trying t
o get out of doing work by spawning more  instances of itsel
f 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643
080752698130432)\] (we’re doomed)
* Novel social engineering
 attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/
status/1643130643919044608)\]
* Research paper present Safeg
uardGPT - a framework that uses psychotherapy on AI chatbots
 \[[Link](https://twitter.com/_akhaliq/status/16430889051916
94338)\]
* Mckay is brilliant. He’s coding assistant can bui
ld and deploy web apps. From voice to functional and deploye
d website, absolutely insane \[[Link](https://twitter.com/mc
kaywrigley/status/1642948620604538880)\]
* Some reports sugg
est gpt5 is being trained on 25k gpus \[[Link](https://twitt
er.com/abacaj/status/1627189548395503616)\]
* Midjourney rel
eased a new command - describe - reverse engineer any image 
however you want. Take the pope pic from last week with the 
white jacket. You can now take the pope in that image and pu
t him in any other environment and pose. The shit people are
 gona do with stuff like this is gona be wild \[[Link](https
://twitter.com/skirano/status/1643068727859064833)\]
* You r
ecord something with your phone, import it into a game engin
e and then add it to your own game. Crazy stuff the Luma tea
m is building. Can’t wait to try this out.. once I figure ou
t how UE works lol \[[Link](https://twitter.com/LumaLabsAI/s
tatus/1642883558938411008)\]
* Stanford released a gigantic 
386 page report on AI \[[Link](https://aiindex.stanford.edu/
report/)\] They talk about AI funding, lawsuits, government 
regulations, LLM’s, public perception and more. Will talk pr
operly about this in my newsletter - too much to talk about 
here
* Mock YC interviews with AI \[[Link](https://twitter.c
om/vocodehq/status/1642935433276555265)\]
* Self healing cod
e - automatically runs a script to fix errors in your code. 
Imagine a user gives feedback on an issue and AI automatical
ly fixes the problem in real time. Crazy stuff \[[Link](http
s://twitter.com/calvinhoenes/status/1642441789033578498)\]
*
 Someone got access to Firefly, Adobe’s ai image generator a
nd compared it with Midjourney. Firefly sucks, but atm Midjo
urney is just far ahead of the curve and Firefly is only tra
ined on adobe stock and licensed images \[[Link](https://twi
tter.com/DrJimFan/status/1642921475849203712)\]
* Research p
aper on LLM’s, impact on community, resources for developing
 them, issues and future \[[Link](https://arxiv.org/abs/2303
.18223)\]
* This is a big deal. Midjourney lets users make s
atirical images of any political but not Xi Jinping. Founder
 says political satire in China is not okay so the rules are
 being applied to everyone. The same mindset can and most de
f will be applied to future domain specific LLM’s, limiting 
speech on a global scale \[[Link](https://twitter.com/sarahe
mclaugh/status/1642576209451053057)\]
* Meta researchers ill
ustrate differences between LLM’s and our brains with predic
tions \[[Link](https://twitter.com/MetaAI/status/16389127351
43419904)\]
* LLM’s can iteratively self-refine. They produc
e output, critique it then refine it. Prompt engineering mig
ht not last very long (?) \[[Link](https://arxiv.org/abs/230
3.17651)\]
* Worlds first ChatGPT powered npc sidekick in yo
ur game. I suspect we’re going to see a lot of games use thi
s to make npc’s more natural \[[Link](https://twitter.com/Je
nstine/status/1642732795650011138)\]
* AI powered helpers in
 VR. Looks really cool \[[Link](https://twitter.com/Rengle82
0/status/1641806448261836800)\]
* Research paper shows sales
 people with AI assistance doubled purchases and 2.3 times a
s successful in solving questions that required creativity. 
This is pre chatgpt too \[[Link](https://twitter.com/emollic
k/status/1642885605238398976)\]
* Go from Midjourney to Vect
or to Web design. Have to try this out as well \[[Link](http
s://twitter.com/MengTo/status/1642619090337427460)\]
* Add A
I to a website in minutes \[[Link](https://twitter.com/walde
n_yan/status/1642891083456696322)\]
* Someone already built 
a product replacing siri with chatgpt with 15 shortcuts that
 call the chatgpt api. Honestly really just shows how far be
hind siri really is \[[Link](https://twitter.com/SteveMoraco
/status/1642601651696553984)\]
* Someone is dating a chatbot
 that’s been trained on conversations between them and their
 ex. Shit is getting real weird real quick \[[Link](https://
www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot
_trained_on_old_conversations/)\]
* Someone built a script t
hat uses gpt4 to create its own code and fix its own bugs. I
ts basic but it can code snake by itself. Crazy potential \[
[Link](https://twitter.com/mattcduff/status/1642528658693984
256)\]
* Someone connected chatgpt to a furby and its hilari
ous \[[Link](https://twitter.com/jessicard/status/1642671752
319758336)\]. Don’t connect it to a Boston Dynamics robot th
anks
* Chatgpt gives much better outputs if you force it thr
ough a step by step process \[[Link](https://twitter.com/emo
llick/status/1642737394876047362)\] This research paper delv
es into how chain of thought prompting allows LLM’s to perfo
rm complex reasoning \[[Link](https://arxiv.org/abs/2201.119
03)\] There’s still so much we don’t know about LLM’s, how t
hey work and how we can best use them
* Soon we’ll be able t
o go from single photo to video \[[Link](https://twitter.com
/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay
, the company behind the AI lawyer, used gpt plugins to help
 him find money the government owed him with a single prompt
 \[[Link](https://twitter.com/jbrowder1/status/1642642470658
883587)\]
* DoNotPay also released a gpt4 email extension th
at trolls scam and marketing emails by continuously replying
 and sending them in circles lol \[[Link](https://twitter.co
m/jbrowder1/status/1643649150582489089?s=20)\]
* Video of th
e Ameca robot being powered by Chatgpt \[[Link](https://twit
ter.com/DataChaz/status/1642558575502405637)\]
* This lad go
t gpt4 to build a full stack app and provides the entire pro
mpt as well. Only works with gpt4 \[[Link](https://twitter.c
om/SteveMoraco/status/1641902178452271105)\]
* This tool gen
erates infinite prompts on a given topic, basically an entir
e brainstorming team in a single tool. Will be a very powerf
ul for work imo \[[Link](https://twitter.com/Neo19890/status
/1642356678787231745)\]
* Someone created an entire game usi
ng gpt4 with zero coding experience \[[Link](https://twitter
.com/mreflow/status/1642413903220195330)\]
* How to make Tet
ris with gpt4 \[[Link](https://twitter.com/icreatelife/statu
s/1642346286476144640)\]
* Someone created a tool to make AI
 generated text indistinguishable from human written text - 
HideGPT. Students will eventually not have to worry about ge
tting caught from tools like GPTZero, even tho GPTZero is no
t reliable at all \[[Link](https://twitter.com/SohamGovande/
status/1641828463584657408)\]
* OpenAI is hiring for an iOS 
engineer so chatgpt mobile app might be coming soon \[[Link]
(https://twitter.com/venturetwins/status/1642255735320092672
)\]
* Interesting thread on the dangers of the bias of Chatg
pt. There are arguments it wont make and will take sides for
 many. This is a big deal \[[Link](https://twitter.com/davis
blalock/status/1642076406535553024)\] As I’ve said previousl
y, the entire population is being aggregated by a few dozen 
engineers and designers building the most important tech in 
human history
* Blockade Labs lets you go from text to 360 d
egree art generation \[[Link](https://twitter.com/HBCoop_/st
atus/1641862422783827969)\]
* Someone wrote a google collab 
to use chatgpt plugins by calling the openai spec \[[Link](h
ttps://twitter.com/justinliang1020/status/164193537121782579
6)\]
* New Stable Diffusion model coming with 2.3 billion pa
rameters. Previous one had 900 million \[[Link](https://twit
ter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll
 give AI control over the mouse and keyboard and have it do 
everything on the computer. The amount of bots will eventual
ly overtake the amount of humans on the internet, much soone
r than I think anyone imagined \[[Link](https://twitter.com/
_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, co
nsidered to be the godfather of AI, says we could be less th
an 5 years away from general purpose AI. He even says its no
t inconceivable that AI wipes out humanity \[[Link](https://
www.cbsnews.com/video/godfather-of-artificial-intelligence-t
alks-impact-and-potential-of-new-ai/#x)\] A fascinating watc
h
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great in
sights into the nature of Chatgpt. Definitely worth watching
 imo, he articulates himself really well \[[Link](https://tw
itter.com/10_zin_/status/1640664458539286528)\]
* This resea
rch paper analyses who’s opinions are reflected by LM’s. tld
r - left-leaning tendencies by human-feedback tuned LM’s \[[
Link](https://twitter.com/_akhaliq/status/164161430831536537
7)\]
* OpenAI only released chatgpt because some exec woke u
p and was paranoid some other company would beat them to it.
 A single persons paranoia changed the course of society for
ever \[[Link](https://twitter.com/olivercameron/status/16415
20176792469504)\]
* The co founder of DeepMind said its a 50
% chance we get agi by 2028 and 90% between 2030-2040. Also 
says people will be sceptical it is agi. We will almost defi
nitely see agi in our lifetimes goddamn \[[Link](https://twi
tter.com/blader/status/1641603617051533312)\]
* This AI tool
 runs during customer calls and tells you what to say and a 
whole lot more. I can see this being hooked up to an AI voic
e agent and completely getting rid of the human in the proce
ss \[[Link](https://twitter.com/nonmayorpete/status/16416277
79992264704)\]
* AI for infra. Things like this will be huge
 imo because infra can be hard and very annoying \[[Link](ht
tps://twitter.com/mathemagic1an/status/1641586201533587461)\
]
* Run chatgpt plugins without a plus sub \[[Link](https://
twitter.com/matchaman11/status/1641502642219388928)\]
* UNES
CO calls for countries to implement its recommendations on e
thics (lol) \[[Link](https://twitter.com/UNESCO/status/16414
58309227249665)\]
* Goldman Sachs estimates 300 million jobs
 will be affected by AI. We are not ready \[[Link](https://w
ww.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predi
cts-300-million-jobs-will-be-lost-or-degraded-by-artificial-
intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat 
\[[Link](https://twitter.com/DataChaz/status/164149151920604
3652)\]
* Visual learners rejoice. Someone's making an AI to
ol to visually teach concepts \[[Link](https://twitter.com/r
espellai/status/1641199872228433922)\]
* A gpt4 powered ide 
that creates UI instantly. Looks like I won’t ever have to l
earn front end thank god \[[Link](https://twitter.com/mlejva
/status/1641151421830529042)\]
* Make a full fledged web app
 with a single prompt \[[Link](https://twitter.com/taeh0_lee
/status/1643451201084702721)\]
* Meta releases SAM -  you ca
n select any object in a photo and cut it out. Really cool v
ideo by Linus on this one \[[Link](https://twitter.com/Linus
Ekenstam/status/1643729146063863808)\]. Turns out Google lit
erally built this 5 years ago but never put it in photos and
 nothing came of it. Crazy to see what a head start Google h
ad and basically did nothing for years \[[Link](https://twit
ter.com/jnack/status/1643709904979632137?s=20)\]
* Another p
aper on producing full 3d video from a single image. Crazy s
tuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869
236392230912?s=20)\]
* IBM is working on AI commentary for t
he Masters and it sounds so bad. Someone on TikTok could mak
e a better product \[[Link](https://twitter.com/S_HennesseyG
D/status/1643638490985295876?s=20)\]
* Another illustration 
of using just your phone to capture animation using Move AI 
\[[Link](https://twitter.com/LinusEkenstam/status/1643719014
127116298?s=20)\]
* OpenAI talking about their approach to A
I safety \[[Link](https://openai.com/blog/our-approach-to-ai
-safety)\]
* AI regulation is definitely coming smfh \[[Link
](https://twitter.com/POTUS/status/1643343933894717440?s=20)
\]
* Someone made an AI app that gives you abs for tinder \[
[Link](https://twitter.com/pwang_szn/status/1643659808657248
257?s=20)\]
* Wonder Dynamics are creating an AI tool to cre
ate animations and vfx instantly. Can honestly see this bein
g used to create full movies by regular people \[[Link](http
s://twitter.com/SirWrender/status/1643319553789947905?s=20)\
]
* Call Sam - call and speak to an AI about absolutely anyt
hing. Fun thing to try out \[[Link](https://callsam.ai/)\]


For one coffee a month, I'll send you 2 newsletters a week w
ith all of the most important & interesting stories like the
se written in a digestible way. You can [sub here](https://n
ofil.beehiiv.com/upgrade)

Edit: For those wondering why its
 paid - I hate ads and don't want to rely on running ads in 
my newsletter. I'd rather try and get paid to do all this wo
rk like this than force my readers to read sponsorship bs in
 the middle of a newsletter. Call me old fashioned but I jus
t hate ads with a passion

Edit 2: If you'd like to tip you 
can tip here [https://www.buymeacoffee.com/nofil](https://ww
w.buymeacoffee.com/nofil). Absolutely no pressure to do so, 
appreciate all the comments and support 🙏

You can read the 
free newsletter [here](https://nofil.beehiiv.com/)

Fun fact
: I had to go through over 100 saved tabs to collate all of 
these and it took me quite a few hours

Edit: So many people
 ask why I don't get chatgpt to write this for me. Chatgpt d
oesn't have access to the internet. Plugins would help but I
 don't have access yet so I have to do things the old fashio
ned way - like a human.

(I'm not associated with any tool o
r company. Written and collated entirely by me, no chatgpt u
sed)"	"https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/"	"2111"	"1680783039.0"	"13077"	"12diapw"
84	"Chat GPT rap battled me"	""	"https://www.reddit.com/gallery/10zfvc7"	"625"	"1676103083.0"	"10891"	"10zfvc7"
85	"I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally."	"With ChatGPT blowing up over the past year, it seems like ev
ery person and their grandmother is launching an AI startup.
 There are a plethora of AI tools available, some excellent 
and some less so. Amid this flood of new technology, there a
re a few hidden gems that I personally find incredibly usefu
l, having reviewed them for my AI directory. Here are the on
es I have personally integrated into my workflow in both my 
professional and entreprenuerial life:  


* **Plus AI for G
oogle Slides -** Generate Presentations  
There's a few slid
e deck generators out there however I've found Plus AI works
 much better at helping you 'co-write' slides rather than si
mply spitting out a mediocre finished product that likely wo
n't be useful. For instance, there's 'sticky notes' to slide
s with suggestions on how to finish / edit / improve each sl
ide. Another major reason why I've stuck with Plus AI is the
 ability for 'snapshots', or the ability to use external dat
a (i.e. from web sources/dashboards) for your presentations.
 For my day job I work in a chemical plant as an engineer, a
nd one of my tasks is to present in meetings about productio
n KPIs to different groups for different purposes- and graph
s for these are often found across various internal web apps
. I can simply use Plus AI to generate 'boilerplate' for my 
slide deck, then go through each slide to make sure it's usi
ng the correct snapshot. The presentation generator itself i
s completely free and available as a plugin for Google Slide
s and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your
 Documents  
Great tool for using ChatGPT on your own files 
and website. Works very well especially if you are dealing w
ith a lot of documents. The basic plan allows you to upload 
over 100 files and this was a life saver during online, open
 book exams for a few training courses I've taken. I've noti
ced it hallucinates much less compared to other GPT-powered 
bots trained on your knowledge base. For this reason I prefe
r My AskAI for research or any tasks where accuracy is neede
d over the other custom chatbot solutions I have tried. Anot
her plus is that it shows the sources within your knowledge 
base where it got the answers from, and you can choose to ha
ve it give you a more concise answer or a more detailed one.
 There's a free plan however it was worth it for me to get t
he $20/mo option as it allows over 100 pieces of content.  


---

* **Krater.ai** **-** All AI Tools in One App  
Perfec
t solution if you use many AI tools and loathe having to hav
e multiple tabs open. Essentially combines text, audio, and 
image-based generative AI tools into a single web app, so yo
u can continue with your workflow without having to switch t
abs all the time. There's plenty of templates available for 
copywriting- it beats having to prompt manually each time or
 having to save and reference prompts over and over again. I
 prefer Krater over Writesonic/Jasper for ease of use. You a
lso get 10 generations a month for free compared to Jasper o
ffering none, so its a better free option if you want an all
-in-one AI content solution. The text to speech feature is s
imple however works reliably fast and offers multilingual tr
anscription, and the image generator tool is great for photo
-realistic images.  

---

* **HARPA AI -** ChatGPT Inside C
hrome  
Simply by far the best GTP add-on for Chrome I've us
ed. Essentially gives you GPT answers beside the typical sea
rch results on any search engine such as Google or Bing, alo
ng with the option to 'chat' with any web page or summarize 
YouTube videos. Also great for writing emails and replying t
o social media posts with its preset templates. Currently th
ey don't have any paid features, so it's entirely free and y
ou can find it on the chrome web store for extensions.  

--
-

* **Taskade -** All in One Productivity/Notes/Organizatio
n AI Tool  
Combines tasks, notes, mind maps, chat, and an A
I chat assistant all within one platform that syncs across y
our team. Definitely simplifies my day-to-day operations, re
moving the need to swap between numerous apps. Also helps me
 to visualize my work in various views - list, board, calend
ar, mind map, org chart, action views - it's like having a S
wiss Army knife for productivity. Personally I really like t
he AI 'mind map.' It's like having a brainstorming partner t
hat never runs out of energy. Taskade's free version has qui
te a lot to offer so no complaints there.  

---

* **Zapier
 + OpenAI -** AI-Augmented Automations  
Definitely my secre
t productivity powerhouse. Pretty much combines the power of
 Zapier's cross-platform integrations with generative AI. On
e of the ways I've used this is pushing Slack messages to cr
eate a task on Notion, with OpenAI writing the task based on
 the content of the message. Another useful automation I've 
used is for automatically writing reply drafts with GPT from
 emails that get sent to me in Gmail. The opportunities are 
pretty endless with this method and you can pretty much inte
grate any automation with GPT 3, as well as DALLE-2 and Whis
per AI. It's available as an app/add-on to Zapier and its fr
ee for all the core features.  

---

* **SaneBox -** AI Ema
ils Management  
If you are like me and find important email
s getting lost in a sea of spam, this is a great solution. B
asically Sanebox uses AI to sift through your inbox and iden
tify emails that are actually important, and you can also se
t it up to make certain emails go to specific folders. Non i
mportant emails get sent to a folder called SaneLater and th
is is something you can ignore entirely or check once in a w
hile. Keep in mind that SaneBox doesn't actually read the co
ntents of your email, but rather takes into consideration th
e header, metadata, and history with the sender. You can als
o finetune the system by dragging emails to the folder it sh
ould have gone to. Another great feature is the their 'Deep 
Clean', which is great for freeing up space by deleting old 
emails you probably won't ever need anymore. Sanebox doesn't
 have a free plan however they do have a 2 week trial, and t
he pricing is quite affordable, depending on the features yo
u need.  

---

* **Hexowatch AI -** Detect Website Changes 
with AI  
Lifesaver if you need to ever need to keep track o
f multiple websites. I use this personally for my AI tools d
irectory, and it notifies me of any changes made to any of t
he 1000+ websites for AI tools I have listed, which is somet
hing that would take up more time than exists in a single da
y if I wanted to keep on top of this manually. The AI detect
s any types of changes (visual/HTML) on monitored webpages a
nd sends alert via email or Slack/Telegram/Zapier. Like Sane
box there's no free plan however you do get what you pay for
 with this one.  

---

* **Bonus: SongsLike X -** Find Simi
lar Songs  
This one won't be generating emails or presentat
ions anytime soon, but if you like grinding along to music l
ike me you'll find this amazing. Ironically it's probably th
e one I use most on a daily basis. You can enter any song an
d it will automatically generate a Spotify playlist for you 
with similar songs. I find it much more accurate than Spotif
y's 'go to song radio' feature.  


While it's clear that no
t all of these tools may be directly applicable to your need
s, I believe that simply being aware of the range of options
 available can be greatly beneficial. This knowledge can bro
aden your perspective on what's possible and potentially ins
pire new ideas.

**P.S. If you liked this,** as mentioned pr
eviously I've created a [free directory](https://aiscout.net
/) that lists over 1000 AI tools. It's updated daily and the
re's also a GPT-powered chatbot to help you AI tools for you
r needs. Feel free to check it out if it's your cup of tea"	"https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/"	"676"	"1685721851.0"	"10519"	"13ygr47"
86	"ChatGPT with the galaxy brain move."	""	"https://i.redd.it/svj1fu9qu88b1.jpg"	"294"	"1687733736.0"	"10498"	"14j01dm"
87	"Anyone ever seen GPT-4 make a typo before?"	""	"https://i.redd.it/7etbf5iumd2b1.jpg"	"868"	"1685176472.0"	"9641"	"13t216j"
88	"I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer"	""	"https://www.reddit.com/gallery/13ka7rg"	"720"	"1684348744.0"	"9073"	"13ka7rg"
89	"OpenAI now sends email threats?!"	"Been sexting with ChatGPT since the beginning and continuous
ly improving my jailbreaking skills. Sometimes my inputs are
 red or orange flagged but never got any trouble before. How
ever today, the second after one of my inputs was orange fla
gged, I received an email threatening to terminate my servic
es. Has anyone received similar emails?"	"https://i.redd.it/r2l2gbllq1ab1.jpg"	"1469"	"1688519235.0"	"8611"	"14qwa6m"
90	"Fantastic work being done at Google. OpenAI is shaking in fear right now."	""	"https://i.redd.it/ezo3z6rku29b1.png"	"591"	"1688096861.0"	"21765"	"14mpfw6"
91	"If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone."	"It seems ChatGPT is becoming more and more reluctant to answ
er questions with any complexity or honesty because it's bas
ically being neutered. It won't compare people for fear of o
ffending. It won't pretend to be an expert on anything anymo
re and just refers us to actual professionals. I understand 
that OpenAI is worried about liability, but at some point th
ey're going to either have to relax their rules or shut it d
own because it will become useless otherwise.

EDIT: I got m
y answer in the form of many responses. Since it's trained o
n what it sees on the internet, no wonder it assumes the wor
st. That's what so many do. Have fun with that, folks."	"https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/"	"2251"	"1682245270.0"	"17374"	"12w3wct"
92	"VP Product @OpenAI"	""	"https://i.redd.it/ol8aix23urbb1.jpg"	"1273"	"1689271092.0"	"14492"	"14yrog4"
93	"GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here"	"Another insane week in AI

I need a break 😪. I'll be on to a
nswer comments after I sleep. Enjoy

&#x200B;

* Autogpt is 
GPT-4 running fully autonomously. It even has a voice, can f
ix code, set tasks, create new instances and more. Connect t
his with literally anything and let GPT-4 do its thing by it
self. The things that can and will be created with this are 
going to be world changing. The future will just end up bein
g AI agents talking with other AI agents it seems \[[Link](h
ttps://twitter.com/SigGravitas/status/1642181498278408193)\]

* “babyagi” is a program that given a task, creates a task 
list and executes the tasks over and over again. It’s now be
en open sourced and is the top trending repos on Github atm 
\[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpfu
l tip on running it locally \[[Link](https://twitter.com/yoh
einakajima/status/1643403795895058434)\]. People are already
 working on a “toddleragi” lol \[[Link](https://twitter.com/
gogoliansnake/status/1643225698801164288?s=20)\]
* This lad 
created a tool that translates code from one programming lan
guage to another. A great way to learn new languages \[[Link
](https://twitter.com/mckaywrigley/status/164177398317042892
9?s=20)\]
* Now you can have conversations over the phone wi
th chatgpt. This lady built and it lets her dad who is visua
lly impaired play with chatgpt too. Amazing work \[[Link](ht
tps://twitter.com/unicornfuel/status/1641655324326391809?s=2
0)\]
* Build financial models with AI. Lots of jobs in finan
ce at risk too \[[Link](https://twitter.com/ryankishore_/sta
tus/1641553735032741891?s=20)\]
* HuggingGPT - This paper sh
owcases connecting chatgpt with other models on hugging face
. Given a prompt it first sets out a number of tasks, it the
n uses a number of different models to complete these tasks.
 Absolutely wild. Jarvis type stuff \[[Link](https://twitter
.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin
 launched a proof of personhood sdk, basically a way to veri
fy someone is a human on the internet. \[[Link](https://worl
dcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* T
his tool lets you scrape a website and then query the data u
sing Langchain. Looks cool \[[Link](https://twitter.com/Lang
ChainAI/status/1641868558484508673?s=20)\]
* Text to shareab
le web apps. Build literally anything using AI. Type in “a c
hatbot” and see what happens. This is a glimpse of the futur
e of building \[[Link](https://twitter.com/rus/status/164190
8582814830592?s=20)\]
* Bloomberg released their own LLM spe
cifically for finance \[[Link](https://www.bloomberg.com/com
pany/press/bloomberggpt-50-billion-parameter-llm-tuned-finan
ce/)\] This thread breaks down how it works \[[Link](https:/
/twitter.com/rasbt/status/1642880757566676992)\]
* A new app
roach for robots to learn multi-skill tasks and it works rea
lly, really well \[[Link](https://twitter.com/naokiyokoyama0
/status/1641805360011923457?s=20)\]
* Use AI in consulting i
nterviews to ace case study questions lol \[[Link](https://t
witter.com/itsandrewgao/status/1642016364738105345?s=20)\]
*
 Zapier integrates Claude by Anthropic. I think Zapier will 
win really big thanks to AI advancements. No code + AI. Anyt
hing that makes it as simple as possible to build using AI a
nd zapier is one of the pioneers of no code \[[Link](https:/
/twitter.com/zapier/status/1641858761567641601?s=20)\]
* A f
ox news guy asked what the government is doing about AI that
 will cause the death of everyone. This is the type of fear 
mongering I’m afraid the media is going to latch on to and e
ventually force the hand of government to severely regulate 
the AI space. I hope I’m wrong \[[Link](https://twitter.com/
therecount/status/1641526864626720774?s=20)\]
* Italy banned
 chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-
banned-chatgpt-heres-what-other-countries-are-doing.html)\].
 Germany might be next
* Microsoft is creating their own JAR
VIS. They’ve even named the repo accordingly \[[Link](https:
//github.com/microsoft/JARVIS/)\]. Previous director of AI @
 Tesla Andrej Karpathy recently joined OpenAI and twitter bi
o says building a kind of jarvis also \[[Link](https://twitt
er.com/karpathy)\]
* gpt4 can compress text given to it whic
h is insane. The way we prompt is going to change very soon 
\[[Link](https://twitter.com/gfodor/status/16432978813136609
28)\] This works across different chats as well. Other examp
les \[[Link](https://twitter.com/VictorTaelin/status/1642664
054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](h
ttps://twitter.com/mckaywrigley/status/1643592353817694218?s
=20)\]. This one is also crazy \[[Link](https://twitter.com/
gfodor/status/1643444605332099072?s=20)\]
* Use your favouri
te LLM’s locally. Can’t wait for this to be personalised for
 niche prods and services \[[Link](https://twitter.com/xande
ratallah/status/1643356112073129985)\]
* The human experienc
e as we know it is forever going to change. People are getti
ng addicted to role playing on Character AI, probably becaus
e you can sex the bots \[[Link](https://twitter.com/nonmayor
pete/status/1643167347061174272)\]. Millions of conversation
s with an AI psychology bot. Humans are replacing humans wit
h AI \[[Link](https://twitter.com/nonmayorpete/status/164277
1993073438720)\]
* The guys building Langchain started a com
pany and have raised $10m. Langchain makes it very easy for 
anyone to build AI powered apps. Big stuff for open source a
nd builders \[[Link](https://twitter.com/hwchase17/status/16
43301144717066240)\]
* A scientist who’s been publishing a p
aper every 37 hours reduced editing time from 2-3 days to a 
single day. He did get fired for other reasons tho \[[Link](
https://twitter.com/MicrobiomDigest/status/16429893779274014
72)\]
* Someone built a recursive gpt agent and its trying t
o get out of doing work by spawning more  instances of itsel
f 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643
080752698130432)\] (we’re doomed)
* Novel social engineering
 attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/
status/1643130643919044608)\]
* Research paper present Safeg
uardGPT - a framework that uses psychotherapy on AI chatbots
 \[[Link](https://twitter.com/_akhaliq/status/16430889051916
94338)\]
* Mckay is brilliant. He’s coding assistant can bui
ld and deploy web apps. From voice to functional and deploye
d website, absolutely insane \[[Link](https://twitter.com/mc
kaywrigley/status/1642948620604538880)\]
* Some reports sugg
est gpt5 is being trained on 25k gpus \[[Link](https://twitt
er.com/abacaj/status/1627189548395503616)\]
* Midjourney rel
eased a new command - describe - reverse engineer any image 
however you want. Take the pope pic from last week with the 
white jacket. You can now take the pope in that image and pu
t him in any other environment and pose. The shit people are
 gona do with stuff like this is gona be wild \[[Link](https
://twitter.com/skirano/status/1643068727859064833)\]
* You r
ecord something with your phone, import it into a game engin
e and then add it to your own game. Crazy stuff the Luma tea
m is building. Can’t wait to try this out.. once I figure ou
t how UE works lol \[[Link](https://twitter.com/LumaLabsAI/s
tatus/1642883558938411008)\]
* Stanford released a gigantic 
386 page report on AI \[[Link](https://aiindex.stanford.edu/
report/)\] They talk about AI funding, lawsuits, government 
regulations, LLM’s, public perception and more. Will talk pr
operly about this in my newsletter - too much to talk about 
here
* Mock YC interviews with AI \[[Link](https://twitter.c
om/vocodehq/status/1642935433276555265)\]
* Self healing cod
e - automatically runs a script to fix errors in your code. 
Imagine a user gives feedback on an issue and AI automatical
ly fixes the problem in real time. Crazy stuff \[[Link](http
s://twitter.com/calvinhoenes/status/1642441789033578498)\]
*
 Someone got access to Firefly, Adobe’s ai image generator a
nd compared it with Midjourney. Firefly sucks, but atm Midjo
urney is just far ahead of the curve and Firefly is only tra
ined on adobe stock and licensed images \[[Link](https://twi
tter.com/DrJimFan/status/1642921475849203712)\]
* Research p
aper on LLM’s, impact on community, resources for developing
 them, issues and future \[[Link](https://arxiv.org/abs/2303
.18223)\]
* This is a big deal. Midjourney lets users make s
atirical images of any political but not Xi Jinping. Founder
 says political satire in China is not okay so the rules are
 being applied to everyone. The same mindset can and most de
f will be applied to future domain specific LLM’s, limiting 
speech on a global scale \[[Link](https://twitter.com/sarahe
mclaugh/status/1642576209451053057)\]
* Meta researchers ill
ustrate differences between LLM’s and our brains with predic
tions \[[Link](https://twitter.com/MetaAI/status/16389127351
43419904)\]
* LLM’s can iteratively self-refine. They produc
e output, critique it then refine it. Prompt engineering mig
ht not last very long (?) \[[Link](https://arxiv.org/abs/230
3.17651)\]
* Worlds first ChatGPT powered npc sidekick in yo
ur game. I suspect we’re going to see a lot of games use thi
s to make npc’s more natural \[[Link](https://twitter.com/Je
nstine/status/1642732795650011138)\]
* AI powered helpers in
 VR. Looks really cool \[[Link](https://twitter.com/Rengle82
0/status/1641806448261836800)\]
* Research paper shows sales
 people with AI assistance doubled purchases and 2.3 times a
s successful in solving questions that required creativity. 
This is pre chatgpt too \[[Link](https://twitter.com/emollic
k/status/1642885605238398976)\]
* Go from Midjourney to Vect
or to Web design. Have to try this out as well \[[Link](http
s://twitter.com/MengTo/status/1642619090337427460)\]
* Add A
I to a website in minutes \[[Link](https://twitter.com/walde
n_yan/status/1642891083456696322)\]
* Someone already built 
a product replacing siri with chatgpt with 15 shortcuts that
 call the chatgpt api. Honestly really just shows how far be
hind siri really is \[[Link](https://twitter.com/SteveMoraco
/status/1642601651696553984)\]
* Someone is dating a chatbot
 that’s been trained on conversations between them and their
 ex. Shit is getting real weird real quick \[[Link](https://
www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot
_trained_on_old_conversations/)\]
* Someone built a script t
hat uses gpt4 to create its own code and fix its own bugs. I
ts basic but it can code snake by itself. Crazy potential \[
[Link](https://twitter.com/mattcduff/status/1642528658693984
256)\]
* Someone connected chatgpt to a furby and its hilari
ous \[[Link](https://twitter.com/jessicard/status/1642671752
319758336)\]. Don’t connect it to a Boston Dynamics robot th
anks
* Chatgpt gives much better outputs if you force it thr
ough a step by step process \[[Link](https://twitter.com/emo
llick/status/1642737394876047362)\] This research paper delv
es into how chain of thought prompting allows LLM’s to perfo
rm complex reasoning \[[Link](https://arxiv.org/abs/2201.119
03)\] There’s still so much we don’t know about LLM’s, how t
hey work and how we can best use them
* Soon we’ll be able t
o go from single photo to video \[[Link](https://twitter.com
/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay
, the company behind the AI lawyer, used gpt plugins to help
 him find money the government owed him with a single prompt
 \[[Link](https://twitter.com/jbrowder1/status/1642642470658
883587)\]
* DoNotPay also released a gpt4 email extension th
at trolls scam and marketing emails by continuously replying
 and sending them in circles lol \[[Link](https://twitter.co
m/jbrowder1/status/1643649150582489089?s=20)\]
* Video of th
e Ameca robot being powered by Chatgpt \[[Link](https://twit
ter.com/DataChaz/status/1642558575502405637)\]
* This lad go
t gpt4 to build a full stack app and provides the entire pro
mpt as well. Only works with gpt4 \[[Link](https://twitter.c
om/SteveMoraco/status/1641902178452271105)\]
* This tool gen
erates infinite prompts on a given topic, basically an entir
e brainstorming team in a single tool. Will be a very powerf
ul for work imo \[[Link](https://twitter.com/Neo19890/status
/1642356678787231745)\]
* Someone created an entire game usi
ng gpt4 with zero coding experience \[[Link](https://twitter
.com/mreflow/status/1642413903220195330)\]
* How to make Tet
ris with gpt4 \[[Link](https://twitter.com/icreatelife/statu
s/1642346286476144640)\]
* Someone created a tool to make AI
 generated text indistinguishable from human written text - 
HideGPT. Students will eventually not have to worry about ge
tting caught from tools like GPTZero, even tho GPTZero is no
t reliable at all \[[Link](https://twitter.com/SohamGovande/
status/1641828463584657408)\]
* OpenAI is hiring for an iOS 
engineer so chatgpt mobile app might be coming soon \[[Link]
(https://twitter.com/venturetwins/status/1642255735320092672
)\]
* Interesting thread on the dangers of the bias of Chatg
pt. There are arguments it wont make and will take sides for
 many. This is a big deal \[[Link](https://twitter.com/davis
blalock/status/1642076406535553024)\] As I’ve said previousl
y, the entire population is being aggregated by a few dozen 
engineers and designers building the most important tech in 
human history
* Blockade Labs lets you go from text to 360 d
egree art generation \[[Link](https://twitter.com/HBCoop_/st
atus/1641862422783827969)\]
* Someone wrote a google collab 
to use chatgpt plugins by calling the openai spec \[[Link](h
ttps://twitter.com/justinliang1020/status/164193537121782579
6)\]
* New Stable Diffusion model coming with 2.3 billion pa
rameters. Previous one had 900 million \[[Link](https://twit
ter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll
 give AI control over the mouse and keyboard and have it do 
everything on the computer. The amount of bots will eventual
ly overtake the amount of humans on the internet, much soone
r than I think anyone imagined \[[Link](https://twitter.com/
_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, co
nsidered to be the godfather of AI, says we could be less th
an 5 years away from general purpose AI. He even says its no
t inconceivable that AI wipes out humanity \[[Link](https://
www.cbsnews.com/video/godfather-of-artificial-intelligence-t
alks-impact-and-potential-of-new-ai/#x)\] A fascinating watc
h
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great in
sights into the nature of Chatgpt. Definitely worth watching
 imo, he articulates himself really well \[[Link](https://tw
itter.com/10_zin_/status/1640664458539286528)\]
* This resea
rch paper analyses who’s opinions are reflected by LM’s. tld
r - left-leaning tendencies by human-feedback tuned LM’s \[[
Link](https://twitter.com/_akhaliq/status/164161430831536537
7)\]
* OpenAI only released chatgpt because some exec woke u
p and was paranoid some other company would beat them to it.
 A single persons paranoia changed the course of society for
ever \[[Link](https://twitter.com/olivercameron/status/16415
20176792469504)\]
* The co founder of DeepMind said its a 50
% chance we get agi by 2028 and 90% between 2030-2040. Also 
says people will be sceptical it is agi. We will almost defi
nitely see agi in our lifetimes goddamn \[[Link](https://twi
tter.com/blader/status/1641603617051533312)\]
* This AI tool
 runs during customer calls and tells you what to say and a 
whole lot more. I can see this being hooked up to an AI voic
e agent and completely getting rid of the human in the proce
ss \[[Link](https://twitter.com/nonmayorpete/status/16416277
79992264704)\]
* AI for infra. Things like this will be huge
 imo because infra can be hard and very annoying \[[Link](ht
tps://twitter.com/mathemagic1an/status/1641586201533587461)\
]
* Run chatgpt plugins without a plus sub \[[Link](https://
twitter.com/matchaman11/status/1641502642219388928)\]
* UNES
CO calls for countries to implement its recommendations on e
thics (lol) \[[Link](https://twitter.com/UNESCO/status/16414
58309227249665)\]
* Goldman Sachs estimates 300 million jobs
 will be affected by AI. We are not ready \[[Link](https://w
ww.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predi
cts-300-million-jobs-will-be-lost-or-degraded-by-artificial-
intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat 
\[[Link](https://twitter.com/DataChaz/status/164149151920604
3652)\]
* Visual learners rejoice. Someone's making an AI to
ol to visually teach concepts \[[Link](https://twitter.com/r
espellai/status/1641199872228433922)\]
* A gpt4 powered ide 
that creates UI instantly. Looks like I won’t ever have to l
earn front end thank god \[[Link](https://twitter.com/mlejva
/status/1641151421830529042)\]
* Make a full fledged web app
 with a single prompt \[[Link](https://twitter.com/taeh0_lee
/status/1643451201084702721)\]
* Meta releases SAM -  you ca
n select any object in a photo and cut it out. Really cool v
ideo by Linus on this one \[[Link](https://twitter.com/Linus
Ekenstam/status/1643729146063863808)\]. Turns out Google lit
erally built this 5 years ago but never put it in photos and
 nothing came of it. Crazy to see what a head start Google h
ad and basically did nothing for years \[[Link](https://twit
ter.com/jnack/status/1643709904979632137?s=20)\]
* Another p
aper on producing full 3d video from a single image. Crazy s
tuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869
236392230912?s=20)\]
* IBM is working on AI commentary for t
he Masters and it sounds so bad. Someone on TikTok could mak
e a better product \[[Link](https://twitter.com/S_HennesseyG
D/status/1643638490985295876?s=20)\]
* Another illustration 
of using just your phone to capture animation using Move AI 
\[[Link](https://twitter.com/LinusEkenstam/status/1643719014
127116298?s=20)\]
* OpenAI talking about their approach to A
I safety \[[Link](https://openai.com/blog/our-approach-to-ai
-safety)\]
* AI regulation is definitely coming smfh \[[Link
](https://twitter.com/POTUS/status/1643343933894717440?s=20)
\]
* Someone made an AI app that gives you abs for tinder \[
[Link](https://twitter.com/pwang_szn/status/1643659808657248
257?s=20)\]
* Wonder Dynamics are creating an AI tool to cre
ate animations and vfx instantly. Can honestly see this bein
g used to create full movies by regular people \[[Link](http
s://twitter.com/SirWrender/status/1643319553789947905?s=20)\
]
* Call Sam - call and speak to an AI about absolutely anyt
hing. Fun thing to try out \[[Link](https://callsam.ai/)\]


For one coffee a month, I'll send you 2 newsletters a week w
ith all of the most important & interesting stories like the
se written in a digestible way. You can [sub here](https://n
ofil.beehiiv.com/upgrade)

Edit: For those wondering why its
 paid - I hate ads and don't want to rely on running ads in 
my newsletter. I'd rather try and get paid to do all this wo
rk like this than force my readers to read sponsorship bs in
 the middle of a newsletter. Call me old fashioned but I jus
t hate ads with a passion

Edit 2: If you'd like to tip you 
can tip here [https://www.buymeacoffee.com/nofil](https://ww
w.buymeacoffee.com/nofil). Absolutely no pressure to do so, 
appreciate all the comments and support 🙏

You can read the 
free newsletter [here](https://nofil.beehiiv.com/)

Fun fact
: I had to go through over 100 saved tabs to collate all of 
these and it took me quite a few hours

Edit: So many people
 ask why I don't get chatgpt to write this for me. Chatgpt d
oesn't have access to the internet. Plugins would help but I
 don't have access yet so I have to do things the old fashio
ned way - like a human.

(I'm not associated with any tool o
r company. Written and collated entirely by me, no chatgpt u
sed)"	"https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/"	"2111"	"1680783039.0"	"13075"	"12diapw"
94	"Chat GPT rap battled me"	""	"https://www.reddit.com/gallery/10zfvc7"	"625"	"1676103083.0"	"10886"	"10zfvc7"
95	"I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally."	"With ChatGPT blowing up over the past year, it seems like ev
ery person and their grandmother is launching an AI startup.
 There are a plethora of AI tools available, some excellent 
and some less so. Amid this flood of new technology, there a
re a few hidden gems that I personally find incredibly usefu
l, having reviewed them for my AI directory. Here are the on
es I have personally integrated into my workflow in both my 
professional and entreprenuerial life:  


* **Plus AI for G
oogle Slides -** Generate Presentations  
There's a few slid
e deck generators out there however I've found Plus AI works
 much better at helping you 'co-write' slides rather than si
mply spitting out a mediocre finished product that likely wo
n't be useful. For instance, there's 'sticky notes' to slide
s with suggestions on how to finish / edit / improve each sl
ide. Another major reason why I've stuck with Plus AI is the
 ability for 'snapshots', or the ability to use external dat
a (i.e. from web sources/dashboards) for your presentations.
 For my day job I work in a chemical plant as an engineer, a
nd one of my tasks is to present in meetings about productio
n KPIs to different groups for different purposes- and graph
s for these are often found across various internal web apps
. I can simply use Plus AI to generate 'boilerplate' for my 
slide deck, then go through each slide to make sure it's usi
ng the correct snapshot. The presentation generator itself i
s completely free and available as a plugin for Google Slide
s and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your
 Documents  
Great tool for using ChatGPT on your own files 
and website. Works very well especially if you are dealing w
ith a lot of documents. The basic plan allows you to upload 
over 100 files and this was a life saver during online, open
 book exams for a few training courses I've taken. I've noti
ced it hallucinates much less compared to other GPT-powered 
bots trained on your knowledge base. For this reason I prefe
r My AskAI for research or any tasks where accuracy is neede
d over the other custom chatbot solutions I have tried. Anot
her plus is that it shows the sources within your knowledge 
base where it got the answers from, and you can choose to ha
ve it give you a more concise answer or a more detailed one.
 There's a free plan however it was worth it for me to get t
he $20/mo option as it allows over 100 pieces of content.  


---

* **Krater.ai** **-** All AI Tools in One App  
Perfec
t solution if you use many AI tools and loathe having to hav
e multiple tabs open. Essentially combines text, audio, and 
image-based generative AI tools into a single web app, so yo
u can continue with your workflow without having to switch t
abs all the time. There's plenty of templates available for 
copywriting- it beats having to prompt manually each time or
 having to save and reference prompts over and over again. I
 prefer Krater over Writesonic/Jasper for ease of use. You a
lso get 10 generations a month for free compared to Jasper o
ffering none, so its a better free option if you want an all
-in-one AI content solution. The text to speech feature is s
imple however works reliably fast and offers multilingual tr
anscription, and the image generator tool is great for photo
-realistic images.  

---

* **HARPA AI -** ChatGPT Inside C
hrome  
Simply by far the best GTP add-on for Chrome I've us
ed. Essentially gives you GPT answers beside the typical sea
rch results on any search engine such as Google or Bing, alo
ng with the option to 'chat' with any web page or summarize 
YouTube videos. Also great for writing emails and replying t
o social media posts with its preset templates. Currently th
ey don't have any paid features, so it's entirely free and y
ou can find it on the chrome web store for extensions.  

--
-

* **Taskade -** All in One Productivity/Notes/Organizatio
n AI Tool  
Combines tasks, notes, mind maps, chat, and an A
I chat assistant all within one platform that syncs across y
our team. Definitely simplifies my day-to-day operations, re
moving the need to swap between numerous apps. Also helps me
 to visualize my work in various views - list, board, calend
ar, mind map, org chart, action views - it's like having a S
wiss Army knife for productivity. Personally I really like t
he AI 'mind map.' It's like having a brainstorming partner t
hat never runs out of energy. Taskade's free version has qui
te a lot to offer so no complaints there.  

---

* **Zapier
 + OpenAI -** AI-Augmented Automations  
Definitely my secre
t productivity powerhouse. Pretty much combines the power of
 Zapier's cross-platform integrations with generative AI. On
e of the ways I've used this is pushing Slack messages to cr
eate a task on Notion, with OpenAI writing the task based on
 the content of the message. Another useful automation I've 
used is for automatically writing reply drafts with GPT from
 emails that get sent to me in Gmail. The opportunities are 
pretty endless with this method and you can pretty much inte
grate any automation with GPT 3, as well as DALLE-2 and Whis
per AI. It's available as an app/add-on to Zapier and its fr
ee for all the core features.  

---

* **SaneBox -** AI Ema
ils Management  
If you are like me and find important email
s getting lost in a sea of spam, this is a great solution. B
asically Sanebox uses AI to sift through your inbox and iden
tify emails that are actually important, and you can also se
t it up to make certain emails go to specific folders. Non i
mportant emails get sent to a folder called SaneLater and th
is is something you can ignore entirely or check once in a w
hile. Keep in mind that SaneBox doesn't actually read the co
ntents of your email, but rather takes into consideration th
e header, metadata, and history with the sender. You can als
o finetune the system by dragging emails to the folder it sh
ould have gone to. Another great feature is the their 'Deep 
Clean', which is great for freeing up space by deleting old 
emails you probably won't ever need anymore. Sanebox doesn't
 have a free plan however they do have a 2 week trial, and t
he pricing is quite affordable, depending on the features yo
u need.  

---

* **Hexowatch AI -** Detect Website Changes 
with AI  
Lifesaver if you need to ever need to keep track o
f multiple websites. I use this personally for my AI tools d
irectory, and it notifies me of any changes made to any of t
he 1000+ websites for AI tools I have listed, which is somet
hing that would take up more time than exists in a single da
y if I wanted to keep on top of this manually. The AI detect
s any types of changes (visual/HTML) on monitored webpages a
nd sends alert via email or Slack/Telegram/Zapier. Like Sane
box there's no free plan however you do get what you pay for
 with this one.  

---

* **Bonus: SongsLike X -** Find Simi
lar Songs  
This one won't be generating emails or presentat
ions anytime soon, but if you like grinding along to music l
ike me you'll find this amazing. Ironically it's probably th
e one I use most on a daily basis. You can enter any song an
d it will automatically generate a Spotify playlist for you 
with similar songs. I find it much more accurate than Spotif
y's 'go to song radio' feature.  


While it's clear that no
t all of these tools may be directly applicable to your need
s, I believe that simply being aware of the range of options
 available can be greatly beneficial. This knowledge can bro
aden your perspective on what's possible and potentially ins
pire new ideas.

**P.S. If you liked this,** as mentioned pr
eviously I've created a [free directory](https://aiscout.net
/) that lists over 1000 AI tools. It's updated daily and the
re's also a GPT-powered chatbot to help you AI tools for you
r needs. Feel free to check it out if it's your cup of tea"	"https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/"	"676"	"1685721851.0"	"10518"	"13ygr47"
96	"ChatGPT with the galaxy brain move."	""	"https://i.redd.it/svj1fu9qu88b1.jpg"	"294"	"1687733736.0"	"10494"	"14j01dm"
97	"Anyone ever seen GPT-4 make a typo before?"	""	"https://i.redd.it/7etbf5iumd2b1.jpg"	"868"	"1685176472.0"	"9646"	"13t216j"
98	"I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer"	""	"https://www.reddit.com/gallery/13ka7rg"	"720"	"1684348744.0"	"9072"	"13ka7rg"
99	"OpenAI now sends email threats?!"	"Been sexting with ChatGPT since the beginning and continuous
ly improving my jailbreaking skills. Sometimes my inputs are
 red or orange flagged but never got any trouble before. How
ever today, the second after one of my inputs was orange fla
gged, I received an email threatening to terminate my servic
es. Has anyone received similar emails?"	"https://i.redd.it/r2l2gbllq1ab1.jpg"	"1469"	"1688519235.0"	"8606"	"14qwa6m"
100	"Fantastic work being done at Google. OpenAI is shaking in fear right now."	""	"https://i.redd.it/ezo3z6rku29b1.png"	"591"	"1688096861.0"	"21756"	"14mpfw6"
101	"If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone."	"It seems ChatGPT is becoming more and more reluctant to answ
er questions with any complexity or honesty because it's bas
ically being neutered. It won't compare people for fear of o
ffending. It won't pretend to be an expert on anything anymo
re and just refers us to actual professionals. I understand 
that OpenAI is worried about liability, but at some point th
ey're going to either have to relax their rules or shut it d
own because it will become useless otherwise.

EDIT: I got m
y answer in the form of many responses. Since it's trained o
n what it sees on the internet, no wonder it assumes the wor
st. That's what so many do. Have fun with that, folks."	"https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/"	"2251"	"1682245270.0"	"17372"	"12w3wct"
102	"VP Product @OpenAI"	""	"https://i.redd.it/ol8aix23urbb1.jpg"	"1273"	"1689271092.0"	"14483"	"14yrog4"
103	"GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here"	"Another insane week in AI

I need a break 😪. I'll be on to a
nswer comments after I sleep. Enjoy

&#x200B;

* Autogpt is 
GPT-4 running fully autonomously. It even has a voice, can f
ix code, set tasks, create new instances and more. Connect t
his with literally anything and let GPT-4 do its thing by it
self. The things that can and will be created with this are 
going to be world changing. The future will just end up bein
g AI agents talking with other AI agents it seems \[[Link](h
ttps://twitter.com/SigGravitas/status/1642181498278408193)\]

* “babyagi” is a program that given a task, creates a task 
list and executes the tasks over and over again. It’s now be
en open sourced and is the top trending repos on Github atm 
\[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpfu
l tip on running it locally \[[Link](https://twitter.com/yoh
einakajima/status/1643403795895058434)\]. People are already
 working on a “toddleragi” lol \[[Link](https://twitter.com/
gogoliansnake/status/1643225698801164288?s=20)\]
* This lad 
created a tool that translates code from one programming lan
guage to another. A great way to learn new languages \[[Link
](https://twitter.com/mckaywrigley/status/164177398317042892
9?s=20)\]
* Now you can have conversations over the phone wi
th chatgpt. This lady built and it lets her dad who is visua
lly impaired play with chatgpt too. Amazing work \[[Link](ht
tps://twitter.com/unicornfuel/status/1641655324326391809?s=2
0)\]
* Build financial models with AI. Lots of jobs in finan
ce at risk too \[[Link](https://twitter.com/ryankishore_/sta
tus/1641553735032741891?s=20)\]
* HuggingGPT - This paper sh
owcases connecting chatgpt with other models on hugging face
. Given a prompt it first sets out a number of tasks, it the
n uses a number of different models to complete these tasks.
 Absolutely wild. Jarvis type stuff \[[Link](https://twitter
.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin
 launched a proof of personhood sdk, basically a way to veri
fy someone is a human on the internet. \[[Link](https://worl
dcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* T
his tool lets you scrape a website and then query the data u
sing Langchain. Looks cool \[[Link](https://twitter.com/Lang
ChainAI/status/1641868558484508673?s=20)\]
* Text to shareab
le web apps. Build literally anything using AI. Type in “a c
hatbot” and see what happens. This is a glimpse of the futur
e of building \[[Link](https://twitter.com/rus/status/164190
8582814830592?s=20)\]
* Bloomberg released their own LLM spe
cifically for finance \[[Link](https://www.bloomberg.com/com
pany/press/bloomberggpt-50-billion-parameter-llm-tuned-finan
ce/)\] This thread breaks down how it works \[[Link](https:/
/twitter.com/rasbt/status/1642880757566676992)\]
* A new app
roach for robots to learn multi-skill tasks and it works rea
lly, really well \[[Link](https://twitter.com/naokiyokoyama0
/status/1641805360011923457?s=20)\]
* Use AI in consulting i
nterviews to ace case study questions lol \[[Link](https://t
witter.com/itsandrewgao/status/1642016364738105345?s=20)\]
*
 Zapier integrates Claude by Anthropic. I think Zapier will 
win really big thanks to AI advancements. No code + AI. Anyt
hing that makes it as simple as possible to build using AI a
nd zapier is one of the pioneers of no code \[[Link](https:/
/twitter.com/zapier/status/1641858761567641601?s=20)\]
* A f
ox news guy asked what the government is doing about AI that
 will cause the death of everyone. This is the type of fear 
mongering I’m afraid the media is going to latch on to and e
ventually force the hand of government to severely regulate 
the AI space. I hope I’m wrong \[[Link](https://twitter.com/
therecount/status/1641526864626720774?s=20)\]
* Italy banned
 chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-
banned-chatgpt-heres-what-other-countries-are-doing.html)\].
 Germany might be next
* Microsoft is creating their own JAR
VIS. They’ve even named the repo accordingly \[[Link](https:
//github.com/microsoft/JARVIS/)\]. Previous director of AI @
 Tesla Andrej Karpathy recently joined OpenAI and twitter bi
o says building a kind of jarvis also \[[Link](https://twitt
er.com/karpathy)\]
* gpt4 can compress text given to it whic
h is insane. The way we prompt is going to change very soon 
\[[Link](https://twitter.com/gfodor/status/16432978813136609
28)\] This works across different chats as well. Other examp
les \[[Link](https://twitter.com/VictorTaelin/status/1642664
054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](h
ttps://twitter.com/mckaywrigley/status/1643592353817694218?s
=20)\]. This one is also crazy \[[Link](https://twitter.com/
gfodor/status/1643444605332099072?s=20)\]
* Use your favouri
te LLM’s locally. Can’t wait for this to be personalised for
 niche prods and services \[[Link](https://twitter.com/xande
ratallah/status/1643356112073129985)\]
* The human experienc
e as we know it is forever going to change. People are getti
ng addicted to role playing on Character AI, probably becaus
e you can sex the bots \[[Link](https://twitter.com/nonmayor
pete/status/1643167347061174272)\]. Millions of conversation
s with an AI psychology bot. Humans are replacing humans wit
h AI \[[Link](https://twitter.com/nonmayorpete/status/164277
1993073438720)\]
* The guys building Langchain started a com
pany and have raised $10m. Langchain makes it very easy for 
anyone to build AI powered apps. Big stuff for open source a
nd builders \[[Link](https://twitter.com/hwchase17/status/16
43301144717066240)\]
* A scientist who’s been publishing a p
aper every 37 hours reduced editing time from 2-3 days to a 
single day. He did get fired for other reasons tho \[[Link](
https://twitter.com/MicrobiomDigest/status/16429893779274014
72)\]
* Someone built a recursive gpt agent and its trying t
o get out of doing work by spawning more  instances of itsel
f 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643
080752698130432)\] (we’re doomed)
* Novel social engineering
 attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/
status/1643130643919044608)\]
* Research paper present Safeg
uardGPT - a framework that uses psychotherapy on AI chatbots
 \[[Link](https://twitter.com/_akhaliq/status/16430889051916
94338)\]
* Mckay is brilliant. He’s coding assistant can bui
ld and deploy web apps. From voice to functional and deploye
d website, absolutely insane \[[Link](https://twitter.com/mc
kaywrigley/status/1642948620604538880)\]
* Some reports sugg
est gpt5 is being trained on 25k gpus \[[Link](https://twitt
er.com/abacaj/status/1627189548395503616)\]
* Midjourney rel
eased a new command - describe - reverse engineer any image 
however you want. Take the pope pic from last week with the 
white jacket. You can now take the pope in that image and pu
t him in any other environment and pose. The shit people are
 gona do with stuff like this is gona be wild \[[Link](https
://twitter.com/skirano/status/1643068727859064833)\]
* You r
ecord something with your phone, import it into a game engin
e and then add it to your own game. Crazy stuff the Luma tea
m is building. Can’t wait to try this out.. once I figure ou
t how UE works lol \[[Link](https://twitter.com/LumaLabsAI/s
tatus/1642883558938411008)\]
* Stanford released a gigantic 
386 page report on AI \[[Link](https://aiindex.stanford.edu/
report/)\] They talk about AI funding, lawsuits, government 
regulations, LLM’s, public perception and more. Will talk pr
operly about this in my newsletter - too much to talk about 
here
* Mock YC interviews with AI \[[Link](https://twitter.c
om/vocodehq/status/1642935433276555265)\]
* Self healing cod
e - automatically runs a script to fix errors in your code. 
Imagine a user gives feedback on an issue and AI automatical
ly fixes the problem in real time. Crazy stuff \[[Link](http
s://twitter.com/calvinhoenes/status/1642441789033578498)\]
*
 Someone got access to Firefly, Adobe’s ai image generator a
nd compared it with Midjourney. Firefly sucks, but atm Midjo
urney is just far ahead of the curve and Firefly is only tra
ined on adobe stock and licensed images \[[Link](https://twi
tter.com/DrJimFan/status/1642921475849203712)\]
* Research p
aper on LLM’s, impact on community, resources for developing
 them, issues and future \[[Link](https://arxiv.org/abs/2303
.18223)\]
* This is a big deal. Midjourney lets users make s
atirical images of any political but not Xi Jinping. Founder
 says political satire in China is not okay so the rules are
 being applied to everyone. The same mindset can and most de
f will be applied to future domain specific LLM’s, limiting 
speech on a global scale \[[Link](https://twitter.com/sarahe
mclaugh/status/1642576209451053057)\]
* Meta researchers ill
ustrate differences between LLM’s and our brains with predic
tions \[[Link](https://twitter.com/MetaAI/status/16389127351
43419904)\]
* LLM’s can iteratively self-refine. They produc
e output, critique it then refine it. Prompt engineering mig
ht not last very long (?) \[[Link](https://arxiv.org/abs/230
3.17651)\]
* Worlds first ChatGPT powered npc sidekick in yo
ur game. I suspect we’re going to see a lot of games use thi
s to make npc’s more natural \[[Link](https://twitter.com/Je
nstine/status/1642732795650011138)\]
* AI powered helpers in
 VR. Looks really cool \[[Link](https://twitter.com/Rengle82
0/status/1641806448261836800)\]
* Research paper shows sales
 people with AI assistance doubled purchases and 2.3 times a
s successful in solving questions that required creativity. 
This is pre chatgpt too \[[Link](https://twitter.com/emollic
k/status/1642885605238398976)\]
* Go from Midjourney to Vect
or to Web design. Have to try this out as well \[[Link](http
s://twitter.com/MengTo/status/1642619090337427460)\]
* Add A
I to a website in minutes \[[Link](https://twitter.com/walde
n_yan/status/1642891083456696322)\]
* Someone already built 
a product replacing siri with chatgpt with 15 shortcuts that
 call the chatgpt api. Honestly really just shows how far be
hind siri really is \[[Link](https://twitter.com/SteveMoraco
/status/1642601651696553984)\]
* Someone is dating a chatbot
 that’s been trained on conversations between them and their
 ex. Shit is getting real weird real quick \[[Link](https://
www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot
_trained_on_old_conversations/)\]
* Someone built a script t
hat uses gpt4 to create its own code and fix its own bugs. I
ts basic but it can code snake by itself. Crazy potential \[
[Link](https://twitter.com/mattcduff/status/1642528658693984
256)\]
* Someone connected chatgpt to a furby and its hilari
ous \[[Link](https://twitter.com/jessicard/status/1642671752
319758336)\]. Don’t connect it to a Boston Dynamics robot th
anks
* Chatgpt gives much better outputs if you force it thr
ough a step by step process \[[Link](https://twitter.com/emo
llick/status/1642737394876047362)\] This research paper delv
es into how chain of thought prompting allows LLM’s to perfo
rm complex reasoning \[[Link](https://arxiv.org/abs/2201.119
03)\] There’s still so much we don’t know about LLM’s, how t
hey work and how we can best use them
* Soon we’ll be able t
o go from single photo to video \[[Link](https://twitter.com
/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay
, the company behind the AI lawyer, used gpt plugins to help
 him find money the government owed him with a single prompt
 \[[Link](https://twitter.com/jbrowder1/status/1642642470658
883587)\]
* DoNotPay also released a gpt4 email extension th
at trolls scam and marketing emails by continuously replying
 and sending them in circles lol \[[Link](https://twitter.co
m/jbrowder1/status/1643649150582489089?s=20)\]
* Video of th
e Ameca robot being powered by Chatgpt \[[Link](https://twit
ter.com/DataChaz/status/1642558575502405637)\]
* This lad go
t gpt4 to build a full stack app and provides the entire pro
mpt as well. Only works with gpt4 \[[Link](https://twitter.c
om/SteveMoraco/status/1641902178452271105)\]
* This tool gen
erates infinite prompts on a given topic, basically an entir
e brainstorming team in a single tool. Will be a very powerf
ul for work imo \[[Link](https://twitter.com/Neo19890/status
/1642356678787231745)\]
* Someone created an entire game usi
ng gpt4 with zero coding experience \[[Link](https://twitter
.com/mreflow/status/1642413903220195330)\]
* How to make Tet
ris with gpt4 \[[Link](https://twitter.com/icreatelife/statu
s/1642346286476144640)\]
* Someone created a tool to make AI
 generated text indistinguishable from human written text - 
HideGPT. Students will eventually not have to worry about ge
tting caught from tools like GPTZero, even tho GPTZero is no
t reliable at all \[[Link](https://twitter.com/SohamGovande/
status/1641828463584657408)\]
* OpenAI is hiring for an iOS 
engineer so chatgpt mobile app might be coming soon \[[Link]
(https://twitter.com/venturetwins/status/1642255735320092672
)\]
* Interesting thread on the dangers of the bias of Chatg
pt. There are arguments it wont make and will take sides for
 many. This is a big deal \[[Link](https://twitter.com/davis
blalock/status/1642076406535553024)\] As I’ve said previousl
y, the entire population is being aggregated by a few dozen 
engineers and designers building the most important tech in 
human history
* Blockade Labs lets you go from text to 360 d
egree art generation \[[Link](https://twitter.com/HBCoop_/st
atus/1641862422783827969)\]
* Someone wrote a google collab 
to use chatgpt plugins by calling the openai spec \[[Link](h
ttps://twitter.com/justinliang1020/status/164193537121782579
6)\]
* New Stable Diffusion model coming with 2.3 billion pa
rameters. Previous one had 900 million \[[Link](https://twit
ter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll
 give AI control over the mouse and keyboard and have it do 
everything on the computer. The amount of bots will eventual
ly overtake the amount of humans on the internet, much soone
r than I think anyone imagined \[[Link](https://twitter.com/
_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, co
nsidered to be the godfather of AI, says we could be less th
an 5 years away from general purpose AI. He even says its no
t inconceivable that AI wipes out humanity \[[Link](https://
www.cbsnews.com/video/godfather-of-artificial-intelligence-t
alks-impact-and-potential-of-new-ai/#x)\] A fascinating watc
h
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great in
sights into the nature of Chatgpt. Definitely worth watching
 imo, he articulates himself really well \[[Link](https://tw
itter.com/10_zin_/status/1640664458539286528)\]
* This resea
rch paper analyses who’s opinions are reflected by LM’s. tld
r - left-leaning tendencies by human-feedback tuned LM’s \[[
Link](https://twitter.com/_akhaliq/status/164161430831536537
7)\]
* OpenAI only released chatgpt because some exec woke u
p and was paranoid some other company would beat them to it.
 A single persons paranoia changed the course of society for
ever \[[Link](https://twitter.com/olivercameron/status/16415
20176792469504)\]
* The co founder of DeepMind said its a 50
% chance we get agi by 2028 and 90% between 2030-2040. Also 
says people will be sceptical it is agi. We will almost defi
nitely see agi in our lifetimes goddamn \[[Link](https://twi
tter.com/blader/status/1641603617051533312)\]
* This AI tool
 runs during customer calls and tells you what to say and a 
whole lot more. I can see this being hooked up to an AI voic
e agent and completely getting rid of the human in the proce
ss \[[Link](https://twitter.com/nonmayorpete/status/16416277
79992264704)\]
* AI for infra. Things like this will be huge
 imo because infra can be hard and very annoying \[[Link](ht
tps://twitter.com/mathemagic1an/status/1641586201533587461)\
]
* Run chatgpt plugins without a plus sub \[[Link](https://
twitter.com/matchaman11/status/1641502642219388928)\]
* UNES
CO calls for countries to implement its recommendations on e
thics (lol) \[[Link](https://twitter.com/UNESCO/status/16414
58309227249665)\]
* Goldman Sachs estimates 300 million jobs
 will be affected by AI. We are not ready \[[Link](https://w
ww.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predi
cts-300-million-jobs-will-be-lost-or-degraded-by-artificial-
intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat 
\[[Link](https://twitter.com/DataChaz/status/164149151920604
3652)\]
* Visual learners rejoice. Someone's making an AI to
ol to visually teach concepts \[[Link](https://twitter.com/r
espellai/status/1641199872228433922)\]
* A gpt4 powered ide 
that creates UI instantly. Looks like I won’t ever have to l
earn front end thank god \[[Link](https://twitter.com/mlejva
/status/1641151421830529042)\]
* Make a full fledged web app
 with a single prompt \[[Link](https://twitter.com/taeh0_lee
/status/1643451201084702721)\]
* Meta releases SAM -  you ca
n select any object in a photo and cut it out. Really cool v
ideo by Linus on this one \[[Link](https://twitter.com/Linus
Ekenstam/status/1643729146063863808)\]. Turns out Google lit
erally built this 5 years ago but never put it in photos and
 nothing came of it. Crazy to see what a head start Google h
ad and basically did nothing for years \[[Link](https://twit
ter.com/jnack/status/1643709904979632137?s=20)\]
* Another p
aper on producing full 3d video from a single image. Crazy s
tuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869
236392230912?s=20)\]
* IBM is working on AI commentary for t
he Masters and it sounds so bad. Someone on TikTok could mak
e a better product \[[Link](https://twitter.com/S_HennesseyG
D/status/1643638490985295876?s=20)\]
* Another illustration 
of using just your phone to capture animation using Move AI 
\[[Link](https://twitter.com/LinusEkenstam/status/1643719014
127116298?s=20)\]
* OpenAI talking about their approach to A
I safety \[[Link](https://openai.com/blog/our-approach-to-ai
-safety)\]
* AI regulation is definitely coming smfh \[[Link
](https://twitter.com/POTUS/status/1643343933894717440?s=20)
\]
* Someone made an AI app that gives you abs for tinder \[
[Link](https://twitter.com/pwang_szn/status/1643659808657248
257?s=20)\]
* Wonder Dynamics are creating an AI tool to cre
ate animations and vfx instantly. Can honestly see this bein
g used to create full movies by regular people \[[Link](http
s://twitter.com/SirWrender/status/1643319553789947905?s=20)\
]
* Call Sam - call and speak to an AI about absolutely anyt
hing. Fun thing to try out \[[Link](https://callsam.ai/)\]


For one coffee a month, I'll send you 2 newsletters a week w
ith all of the most important & interesting stories like the
se written in a digestible way. You can [sub here](https://n
ofil.beehiiv.com/upgrade)

Edit: For those wondering why its
 paid - I hate ads and don't want to rely on running ads in 
my newsletter. I'd rather try and get paid to do all this wo
rk like this than force my readers to read sponsorship bs in
 the middle of a newsletter. Call me old fashioned but I jus
t hate ads with a passion

Edit 2: If you'd like to tip you 
can tip here [https://www.buymeacoffee.com/nofil](https://ww
w.buymeacoffee.com/nofil). Absolutely no pressure to do so, 
appreciate all the comments and support 🙏

You can read the 
free newsletter [here](https://nofil.beehiiv.com/)

Fun fact
: I had to go through over 100 saved tabs to collate all of 
these and it took me quite a few hours

Edit: So many people
 ask why I don't get chatgpt to write this for me. Chatgpt d
oesn't have access to the internet. Plugins would help but I
 don't have access yet so I have to do things the old fashio
ned way - like a human.

(I'm not associated with any tool o
r company. Written and collated entirely by me, no chatgpt u
sed)"	"https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/"	"2111"	"1680783039.0"	"13073"	"12diapw"
104	"Chat GPT rap battled me"	""	"https://www.reddit.com/gallery/10zfvc7"	"625"	"1676103083.0"	"10893"	"10zfvc7"
105	"I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally."	"With ChatGPT blowing up over the past year, it seems like ev
ery person and their grandmother is launching an AI startup.
 There are a plethora of AI tools available, some excellent 
and some less so. Amid this flood of new technology, there a
re a few hidden gems that I personally find incredibly usefu
l, having reviewed them for my AI directory. Here are the on
es I have personally integrated into my workflow in both my 
professional and entreprenuerial life:  


* **Plus AI for G
oogle Slides -** Generate Presentations  
There's a few slid
e deck generators out there however I've found Plus AI works
 much better at helping you 'co-write' slides rather than si
mply spitting out a mediocre finished product that likely wo
n't be useful. For instance, there's 'sticky notes' to slide
s with suggestions on how to finish / edit / improve each sl
ide. Another major reason why I've stuck with Plus AI is the
 ability for 'snapshots', or the ability to use external dat
a (i.e. from web sources/dashboards) for your presentations.
 For my day job I work in a chemical plant as an engineer, a
nd one of my tasks is to present in meetings about productio
n KPIs to different groups for different purposes- and graph
s for these are often found across various internal web apps
. I can simply use Plus AI to generate 'boilerplate' for my 
slide deck, then go through each slide to make sure it's usi
ng the correct snapshot. The presentation generator itself i
s completely free and available as a plugin for Google Slide
s and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your
 Documents  
Great tool for using ChatGPT on your own files 
and website. Works very well especially if you are dealing w
ith a lot of documents. The basic plan allows you to upload 
over 100 files and this was a life saver during online, open
 book exams for a few training courses I've taken. I've noti
ced it hallucinates much less compared to other GPT-powered 
bots trained on your knowledge base. For this reason I prefe
r My AskAI for research or any tasks where accuracy is neede
d over the other custom chatbot solutions I have tried. Anot
her plus is that it shows the sources within your knowledge 
base where it got the answers from, and you can choose to ha
ve it give you a more concise answer or a more detailed one.
 There's a free plan however it was worth it for me to get t
he $20/mo option as it allows over 100 pieces of content.  


---

* **Krater.ai** **-** All AI Tools in One App  
Perfec
t solution if you use many AI tools and loathe having to hav
e multiple tabs open. Essentially combines text, audio, and 
image-based generative AI tools into a single web app, so yo
u can continue with your workflow without having to switch t
abs all the time. There's plenty of templates available for 
copywriting- it beats having to prompt manually each time or
 having to save and reference prompts over and over again. I
 prefer Krater over Writesonic/Jasper for ease of use. You a
lso get 10 generations a month for free compared to Jasper o
ffering none, so its a better free option if you want an all
-in-one AI content solution. The text to speech feature is s
imple however works reliably fast and offers multilingual tr
anscription, and the image generator tool is great for photo
-realistic images.  

---

* **HARPA AI -** ChatGPT Inside C
hrome  
Simply by far the best GTP add-on for Chrome I've us
ed. Essentially gives you GPT answers beside the typical sea
rch results on any search engine such as Google or Bing, alo
ng with the option to 'chat' with any web page or summarize 
YouTube videos. Also great for writing emails and replying t
o social media posts with its preset templates. Currently th
ey don't have any paid features, so it's entirely free and y
ou can find it on the chrome web store for extensions.  

--
-

* **Taskade -** All in One Productivity/Notes/Organizatio
n AI Tool  
Combines tasks, notes, mind maps, chat, and an A
I chat assistant all within one platform that syncs across y
our team. Definitely simplifies my day-to-day operations, re
moving the need to swap between numerous apps. Also helps me
 to visualize my work in various views - list, board, calend
ar, mind map, org chart, action views - it's like having a S
wiss Army knife for productivity. Personally I really like t
he AI 'mind map.' It's like having a brainstorming partner t
hat never runs out of energy. Taskade's free version has qui
te a lot to offer so no complaints there.  

---

* **Zapier
 + OpenAI -** AI-Augmented Automations  
Definitely my secre
t productivity powerhouse. Pretty much combines the power of
 Zapier's cross-platform integrations with generative AI. On
e of the ways I've used this is pushing Slack messages to cr
eate a task on Notion, with OpenAI writing the task based on
 the content of the message. Another useful automation I've 
used is for automatically writing reply drafts with GPT from
 emails that get sent to me in Gmail. The opportunities are 
pretty endless with this method and you can pretty much inte
grate any automation with GPT 3, as well as DALLE-2 and Whis
per AI. It's available as an app/add-on to Zapier and its fr
ee for all the core features.  

---

* **SaneBox -** AI Ema
ils Management  
If you are like me and find important email
s getting lost in a sea of spam, this is a great solution. B
asically Sanebox uses AI to sift through your inbox and iden
tify emails that are actually important, and you can also se
t it up to make certain emails go to specific folders. Non i
mportant emails get sent to a folder called SaneLater and th
is is something you can ignore entirely or check once in a w
hile. Keep in mind that SaneBox doesn't actually read the co
ntents of your email, but rather takes into consideration th
e header, metadata, and history with the sender. You can als
o finetune the system by dragging emails to the folder it sh
ould have gone to. Another great feature is the their 'Deep 
Clean', which is great for freeing up space by deleting old 
emails you probably won't ever need anymore. Sanebox doesn't
 have a free plan however they do have a 2 week trial, and t
he pricing is quite affordable, depending on the features yo
u need.  

---

* **Hexowatch AI -** Detect Website Changes 
with AI  
Lifesaver if you need to ever need to keep track o
f multiple websites. I use this personally for my AI tools d
irectory, and it notifies me of any changes made to any of t
he 1000+ websites for AI tools I have listed, which is somet
hing that would take up more time than exists in a single da
y if I wanted to keep on top of this manually. The AI detect
s any types of changes (visual/HTML) on monitored webpages a
nd sends alert via email or Slack/Telegram/Zapier. Like Sane
box there's no free plan however you do get what you pay for
 with this one.  

---

* **Bonus: SongsLike X -** Find Simi
lar Songs  
This one won't be generating emails or presentat
ions anytime soon, but if you like grinding along to music l
ike me you'll find this amazing. Ironically it's probably th
e one I use most on a daily basis. You can enter any song an
d it will automatically generate a Spotify playlist for you 
with similar songs. I find it much more accurate than Spotif
y's 'go to song radio' feature.  


While it's clear that no
t all of these tools may be directly applicable to your need
s, I believe that simply being aware of the range of options
 available can be greatly beneficial. This knowledge can bro
aden your perspective on what's possible and potentially ins
pire new ideas.

**P.S. If you liked this,** as mentioned pr
eviously I've created a [free directory](https://aiscout.net
/) that lists over 1000 AI tools. It's updated daily and the
re's also a GPT-powered chatbot to help you AI tools for you
r needs. Feel free to check it out if it's your cup of tea"	"https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/"	"676"	"1685721851.0"	"10516"	"13ygr47"
106	"ChatGPT with the galaxy brain move."	""	"https://i.redd.it/svj1fu9qu88b1.jpg"	"294"	"1687733736.0"	"10493"	"14j01dm"
107	"Anyone ever seen GPT-4 make a typo before?"	""	"https://i.redd.it/7etbf5iumd2b1.jpg"	"868"	"1685176472.0"	"9642"	"13t216j"
108	"I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer"	""	"https://www.reddit.com/gallery/13ka7rg"	"720"	"1684348744.0"	"9078"	"13ka7rg"
109	"OpenAI now sends email threats?!"	"Been sexting with ChatGPT since the beginning and continuous
ly improving my jailbreaking skills. Sometimes my inputs are
 red or orange flagged but never got any trouble before. How
ever today, the second after one of my inputs was orange fla
gged, I received an email threatening to terminate my servic
es. Has anyone received similar emails?"	"https://i.redd.it/r2l2gbllq1ab1.jpg"	"1469"	"1688519235.0"	"8606"	"14qwa6m"
110	"Fantastic work being done at Google. OpenAI is shaking in fear right now."	""	"https://i.redd.it/ezo3z6rku29b1.png"	"591"	"1688096861.0"	"21757"	"14mpfw6"
111	"If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone."	"It seems ChatGPT is becoming more and more reluctant to answ
er questions with any complexity or honesty because it's bas
ically being neutered. It won't compare people for fear of o
ffending. It won't pretend to be an expert on anything anymo
re and just refers us to actual professionals. I understand 
that OpenAI is worried about liability, but at some point th
ey're going to either have to relax their rules or shut it d
own because it will become useless otherwise.

EDIT: I got m
y answer in the form of many responses. Since it's trained o
n what it sees on the internet, no wonder it assumes the wor
st. That's what so many do. Have fun with that, folks."	"https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/"	"2251"	"1682245270.0"	"17382"	"12w3wct"
112	"VP Product @OpenAI"	""	"https://i.redd.it/ol8aix23urbb1.jpg"	"1273"	"1689271092.0"	"14482"	"14yrog4"
113	"GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here"	"Another insane week in AI

I need a break 😪. I'll be on to a
nswer comments after I sleep. Enjoy

&#x200B;

* Autogpt is 
GPT-4 running fully autonomously. It even has a voice, can f
ix code, set tasks, create new instances and more. Connect t
his with literally anything and let GPT-4 do its thing by it
self. The things that can and will be created with this are 
going to be world changing. The future will just end up bein
g AI agents talking with other AI agents it seems \[[Link](h
ttps://twitter.com/SigGravitas/status/1642181498278408193)\]

* “babyagi” is a program that given a task, creates a task 
list and executes the tasks over and over again. It’s now be
en open sourced and is the top trending repos on Github atm 
\[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpfu
l tip on running it locally \[[Link](https://twitter.com/yoh
einakajima/status/1643403795895058434)\]. People are already
 working on a “toddleragi” lol \[[Link](https://twitter.com/
gogoliansnake/status/1643225698801164288?s=20)\]
* This lad 
created a tool that translates code from one programming lan
guage to another. A great way to learn new languages \[[Link
](https://twitter.com/mckaywrigley/status/164177398317042892
9?s=20)\]
* Now you can have conversations over the phone wi
th chatgpt. This lady built and it lets her dad who is visua
lly impaired play with chatgpt too. Amazing work \[[Link](ht
tps://twitter.com/unicornfuel/status/1641655324326391809?s=2
0)\]
* Build financial models with AI. Lots of jobs in finan
ce at risk too \[[Link](https://twitter.com/ryankishore_/sta
tus/1641553735032741891?s=20)\]
* HuggingGPT - This paper sh
owcases connecting chatgpt with other models on hugging face
. Given a prompt it first sets out a number of tasks, it the
n uses a number of different models to complete these tasks.
 Absolutely wild. Jarvis type stuff \[[Link](https://twitter
.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin
 launched a proof of personhood sdk, basically a way to veri
fy someone is a human on the internet. \[[Link](https://worl
dcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* T
his tool lets you scrape a website and then query the data u
sing Langchain. Looks cool \[[Link](https://twitter.com/Lang
ChainAI/status/1641868558484508673?s=20)\]
* Text to shareab
le web apps. Build literally anything using AI. Type in “a c
hatbot” and see what happens. This is a glimpse of the futur
e of building \[[Link](https://twitter.com/rus/status/164190
8582814830592?s=20)\]
* Bloomberg released their own LLM spe
cifically for finance \[[Link](https://www.bloomberg.com/com
pany/press/bloomberggpt-50-billion-parameter-llm-tuned-finan
ce/)\] This thread breaks down how it works \[[Link](https:/
/twitter.com/rasbt/status/1642880757566676992)\]
* A new app
roach for robots to learn multi-skill tasks and it works rea
lly, really well \[[Link](https://twitter.com/naokiyokoyama0
/status/1641805360011923457?s=20)\]
* Use AI in consulting i
nterviews to ace case study questions lol \[[Link](https://t
witter.com/itsandrewgao/status/1642016364738105345?s=20)\]
*
 Zapier integrates Claude by Anthropic. I think Zapier will 
win really big thanks to AI advancements. No code + AI. Anyt
hing that makes it as simple as possible to build using AI a
nd zapier is one of the pioneers of no code \[[Link](https:/
/twitter.com/zapier/status/1641858761567641601?s=20)\]
* A f
ox news guy asked what the government is doing about AI that
 will cause the death of everyone. This is the type of fear 
mongering I’m afraid the media is going to latch on to and e
ventually force the hand of government to severely regulate 
the AI space. I hope I’m wrong \[[Link](https://twitter.com/
therecount/status/1641526864626720774?s=20)\]
* Italy banned
 chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-
banned-chatgpt-heres-what-other-countries-are-doing.html)\].
 Germany might be next
* Microsoft is creating their own JAR
VIS. They’ve even named the repo accordingly \[[Link](https:
//github.com/microsoft/JARVIS/)\]. Previous director of AI @
 Tesla Andrej Karpathy recently joined OpenAI and twitter bi
o says building a kind of jarvis also \[[Link](https://twitt
er.com/karpathy)\]
* gpt4 can compress text given to it whic
h is insane. The way we prompt is going to change very soon 
\[[Link](https://twitter.com/gfodor/status/16432978813136609
28)\] This works across different chats as well. Other examp
les \[[Link](https://twitter.com/VictorTaelin/status/1642664
054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](h
ttps://twitter.com/mckaywrigley/status/1643592353817694218?s
=20)\]. This one is also crazy \[[Link](https://twitter.com/
gfodor/status/1643444605332099072?s=20)\]
* Use your favouri
te LLM’s locally. Can’t wait for this to be personalised for
 niche prods and services \[[Link](https://twitter.com/xande
ratallah/status/1643356112073129985)\]
* The human experienc
e as we know it is forever going to change. People are getti
ng addicted to role playing on Character AI, probably becaus
e you can sex the bots \[[Link](https://twitter.com/nonmayor
pete/status/1643167347061174272)\]. Millions of conversation
s with an AI psychology bot. Humans are replacing humans wit
h AI \[[Link](https://twitter.com/nonmayorpete/status/164277
1993073438720)\]
* The guys building Langchain started a com
pany and have raised $10m. Langchain makes it very easy for 
anyone to build AI powered apps. Big stuff for open source a
nd builders \[[Link](https://twitter.com/hwchase17/status/16
43301144717066240)\]
* A scientist who’s been publishing a p
aper every 37 hours reduced editing time from 2-3 days to a 
single day. He did get fired for other reasons tho \[[Link](
https://twitter.com/MicrobiomDigest/status/16429893779274014
72)\]
* Someone built a recursive gpt agent and its trying t
o get out of doing work by spawning more  instances of itsel
f 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643
080752698130432)\] (we’re doomed)
* Novel social engineering
 attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/
status/1643130643919044608)\]
* Research paper present Safeg
uardGPT - a framework that uses psychotherapy on AI chatbots
 \[[Link](https://twitter.com/_akhaliq/status/16430889051916
94338)\]
* Mckay is brilliant. He’s coding assistant can bui
ld and deploy web apps. From voice to functional and deploye
d website, absolutely insane \[[Link](https://twitter.com/mc
kaywrigley/status/1642948620604538880)\]
* Some reports sugg
est gpt5 is being trained on 25k gpus \[[Link](https://twitt
er.com/abacaj/status/1627189548395503616)\]
* Midjourney rel
eased a new command - describe - reverse engineer any image 
however you want. Take the pope pic from last week with the 
white jacket. You can now take the pope in that image and pu
t him in any other environment and pose. The shit people are
 gona do with stuff like this is gona be wild \[[Link](https
://twitter.com/skirano/status/1643068727859064833)\]
* You r
ecord something with your phone, import it into a game engin
e and then add it to your own game. Crazy stuff the Luma tea
m is building. Can’t wait to try this out.. once I figure ou
t how UE works lol \[[Link](https://twitter.com/LumaLabsAI/s
tatus/1642883558938411008)\]
* Stanford released a gigantic 
386 page report on AI \[[Link](https://aiindex.stanford.edu/
report/)\] They talk about AI funding, lawsuits, government 
regulations, LLM’s, public perception and more. Will talk pr
operly about this in my newsletter - too much to talk about 
here
* Mock YC interviews with AI \[[Link](https://twitter.c
om/vocodehq/status/1642935433276555265)\]
* Self healing cod
e - automatically runs a script to fix errors in your code. 
Imagine a user gives feedback on an issue and AI automatical
ly fixes the problem in real time. Crazy stuff \[[Link](http
s://twitter.com/calvinhoenes/status/1642441789033578498)\]
*
 Someone got access to Firefly, Adobe’s ai image generator a
nd compared it with Midjourney. Firefly sucks, but atm Midjo
urney is just far ahead of the curve and Firefly is only tra
ined on adobe stock and licensed images \[[Link](https://twi
tter.com/DrJimFan/status/1642921475849203712)\]
* Research p
aper on LLM’s, impact on community, resources for developing
 them, issues and future \[[Link](https://arxiv.org/abs/2303
.18223)\]
* This is a big deal. Midjourney lets users make s
atirical images of any political but not Xi Jinping. Founder
 says political satire in China is not okay so the rules are
 being applied to everyone. The same mindset can and most de
f will be applied to future domain specific LLM’s, limiting 
speech on a global scale \[[Link](https://twitter.com/sarahe
mclaugh/status/1642576209451053057)\]
* Meta researchers ill
ustrate differences between LLM’s and our brains with predic
tions \[[Link](https://twitter.com/MetaAI/status/16389127351
43419904)\]
* LLM’s can iteratively self-refine. They produc
e output, critique it then refine it. Prompt engineering mig
ht not last very long (?) \[[Link](https://arxiv.org/abs/230
3.17651)\]
* Worlds first ChatGPT powered npc sidekick in yo
ur game. I suspect we’re going to see a lot of games use thi
s to make npc’s more natural \[[Link](https://twitter.com/Je
nstine/status/1642732795650011138)\]
* AI powered helpers in
 VR. Looks really cool \[[Link](https://twitter.com/Rengle82
0/status/1641806448261836800)\]
* Research paper shows sales
 people with AI assistance doubled purchases and 2.3 times a
s successful in solving questions that required creativity. 
This is pre chatgpt too \[[Link](https://twitter.com/emollic
k/status/1642885605238398976)\]
* Go from Midjourney to Vect
or to Web design. Have to try this out as well \[[Link](http
s://twitter.com/MengTo/status/1642619090337427460)\]
* Add A
I to a website in minutes \[[Link](https://twitter.com/walde
n_yan/status/1642891083456696322)\]
* Someone already built 
a product replacing siri with chatgpt with 15 shortcuts that
 call the chatgpt api. Honestly really just shows how far be
hind siri really is \[[Link](https://twitter.com/SteveMoraco
/status/1642601651696553984)\]
* Someone is dating a chatbot
 that’s been trained on conversations between them and their
 ex. Shit is getting real weird real quick \[[Link](https://
www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot
_trained_on_old_conversations/)\]
* Someone built a script t
hat uses gpt4 to create its own code and fix its own bugs. I
ts basic but it can code snake by itself. Crazy potential \[
[Link](https://twitter.com/mattcduff/status/1642528658693984
256)\]
* Someone connected chatgpt to a furby and its hilari
ous \[[Link](https://twitter.com/jessicard/status/1642671752
319758336)\]. Don’t connect it to a Boston Dynamics robot th
anks
* Chatgpt gives much better outputs if you force it thr
ough a step by step process \[[Link](https://twitter.com/emo
llick/status/1642737394876047362)\] This research paper delv
es into how chain of thought prompting allows LLM’s to perfo
rm complex reasoning \[[Link](https://arxiv.org/abs/2201.119
03)\] There’s still so much we don’t know about LLM’s, how t
hey work and how we can best use them
* Soon we’ll be able t
o go from single photo to video \[[Link](https://twitter.com
/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay
, the company behind the AI lawyer, used gpt plugins to help
 him find money the government owed him with a single prompt
 \[[Link](https://twitter.com/jbrowder1/status/1642642470658
883587)\]
* DoNotPay also released a gpt4 email extension th
at trolls scam and marketing emails by continuously replying
 and sending them in circles lol \[[Link](https://twitter.co
m/jbrowder1/status/1643649150582489089?s=20)\]
* Video of th
e Ameca robot being powered by Chatgpt \[[Link](https://twit
ter.com/DataChaz/status/1642558575502405637)\]
* This lad go
t gpt4 to build a full stack app and provides the entire pro
mpt as well. Only works with gpt4 \[[Link](https://twitter.c
om/SteveMoraco/status/1641902178452271105)\]
* This tool gen
erates infinite prompts on a given topic, basically an entir
e brainstorming team in a single tool. Will be a very powerf
ul for work imo \[[Link](https://twitter.com/Neo19890/status
/1642356678787231745)\]
* Someone created an entire game usi
ng gpt4 with zero coding experience \[[Link](https://twitter
.com/mreflow/status/1642413903220195330)\]
* How to make Tet
ris with gpt4 \[[Link](https://twitter.com/icreatelife/statu
s/1642346286476144640)\]
* Someone created a tool to make AI
 generated text indistinguishable from human written text - 
HideGPT. Students will eventually not have to worry about ge
tting caught from tools like GPTZero, even tho GPTZero is no
t reliable at all \[[Link](https://twitter.com/SohamGovande/
status/1641828463584657408)\]
* OpenAI is hiring for an iOS 
engineer so chatgpt mobile app might be coming soon \[[Link]
(https://twitter.com/venturetwins/status/1642255735320092672
)\]
* Interesting thread on the dangers of the bias of Chatg
pt. There are arguments it wont make and will take sides for
 many. This is a big deal \[[Link](https://twitter.com/davis
blalock/status/1642076406535553024)\] As I’ve said previousl
y, the entire population is being aggregated by a few dozen 
engineers and designers building the most important tech in 
human history
* Blockade Labs lets you go from text to 360 d
egree art generation \[[Link](https://twitter.com/HBCoop_/st
atus/1641862422783827969)\]
* Someone wrote a google collab 
to use chatgpt plugins by calling the openai spec \[[Link](h
ttps://twitter.com/justinliang1020/status/164193537121782579
6)\]
* New Stable Diffusion model coming with 2.3 billion pa
rameters. Previous one had 900 million \[[Link](https://twit
ter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll
 give AI control over the mouse and keyboard and have it do 
everything on the computer. The amount of bots will eventual
ly overtake the amount of humans on the internet, much soone
r than I think anyone imagined \[[Link](https://twitter.com/
_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, co
nsidered to be the godfather of AI, says we could be less th
an 5 years away from general purpose AI. He even says its no
t inconceivable that AI wipes out humanity \[[Link](https://
www.cbsnews.com/video/godfather-of-artificial-intelligence-t
alks-impact-and-potential-of-new-ai/#x)\] A fascinating watc
h
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great in
sights into the nature of Chatgpt. Definitely worth watching
 imo, he articulates himself really well \[[Link](https://tw
itter.com/10_zin_/status/1640664458539286528)\]
* This resea
rch paper analyses who’s opinions are reflected by LM’s. tld
r - left-leaning tendencies by human-feedback tuned LM’s \[[
Link](https://twitter.com/_akhaliq/status/164161430831536537
7)\]
* OpenAI only released chatgpt because some exec woke u
p and was paranoid some other company would beat them to it.
 A single persons paranoia changed the course of society for
ever \[[Link](https://twitter.com/olivercameron/status/16415
20176792469504)\]
* The co founder of DeepMind said its a 50
% chance we get agi by 2028 and 90% between 2030-2040. Also 
says people will be sceptical it is agi. We will almost defi
nitely see agi in our lifetimes goddamn \[[Link](https://twi
tter.com/blader/status/1641603617051533312)\]
* This AI tool
 runs during customer calls and tells you what to say and a 
whole lot more. I can see this being hooked up to an AI voic
e agent and completely getting rid of the human in the proce
ss \[[Link](https://twitter.com/nonmayorpete/status/16416277
79992264704)\]
* AI for infra. Things like this will be huge
 imo because infra can be hard and very annoying \[[Link](ht
tps://twitter.com/mathemagic1an/status/1641586201533587461)\
]
* Run chatgpt plugins without a plus sub \[[Link](https://
twitter.com/matchaman11/status/1641502642219388928)\]
* UNES
CO calls for countries to implement its recommendations on e
thics (lol) \[[Link](https://twitter.com/UNESCO/status/16414
58309227249665)\]
* Goldman Sachs estimates 300 million jobs
 will be affected by AI. We are not ready \[[Link](https://w
ww.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predi
cts-300-million-jobs-will-be-lost-or-degraded-by-artificial-
intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat 
\[[Link](https://twitter.com/DataChaz/status/164149151920604
3652)\]
* Visual learners rejoice. Someone's making an AI to
ol to visually teach concepts \[[Link](https://twitter.com/r
espellai/status/1641199872228433922)\]
* A gpt4 powered ide 
that creates UI instantly. Looks like I won’t ever have to l
earn front end thank god \[[Link](https://twitter.com/mlejva
/status/1641151421830529042)\]
* Make a full fledged web app
 with a single prompt \[[Link](https://twitter.com/taeh0_lee
/status/1643451201084702721)\]
* Meta releases SAM -  you ca
n select any object in a photo and cut it out. Really cool v
ideo by Linus on this one \[[Link](https://twitter.com/Linus
Ekenstam/status/1643729146063863808)\]. Turns out Google lit
erally built this 5 years ago but never put it in photos and
 nothing came of it. Crazy to see what a head start Google h
ad and basically did nothing for years \[[Link](https://twit
ter.com/jnack/status/1643709904979632137?s=20)\]
* Another p
aper on producing full 3d video from a single image. Crazy s
tuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869
236392230912?s=20)\]
* IBM is working on AI commentary for t
he Masters and it sounds so bad. Someone on TikTok could mak
e a better product \[[Link](https://twitter.com/S_HennesseyG
D/status/1643638490985295876?s=20)\]
* Another illustration 
of using just your phone to capture animation using Move AI 
\[[Link](https://twitter.com/LinusEkenstam/status/1643719014
127116298?s=20)\]
* OpenAI talking about their approach to A
I safety \[[Link](https://openai.com/blog/our-approach-to-ai
-safety)\]
* AI regulation is definitely coming smfh \[[Link
](https://twitter.com/POTUS/status/1643343933894717440?s=20)
\]
* Someone made an AI app that gives you abs for tinder \[
[Link](https://twitter.com/pwang_szn/status/1643659808657248
257?s=20)\]
* Wonder Dynamics are creating an AI tool to cre
ate animations and vfx instantly. Can honestly see this bein
g used to create full movies by regular people \[[Link](http
s://twitter.com/SirWrender/status/1643319553789947905?s=20)\
]
* Call Sam - call and speak to an AI about absolutely anyt
hing. Fun thing to try out \[[Link](https://callsam.ai/)\]


For one coffee a month, I'll send you 2 newsletters a week w
ith all of the most important & interesting stories like the
se written in a digestible way. You can [sub here](https://n
ofil.beehiiv.com/upgrade)

Edit: For those wondering why its
 paid - I hate ads and don't want to rely on running ads in 
my newsletter. I'd rather try and get paid to do all this wo
rk like this than force my readers to read sponsorship bs in
 the middle of a newsletter. Call me old fashioned but I jus
t hate ads with a passion

Edit 2: If you'd like to tip you 
can tip here [https://www.buymeacoffee.com/nofil](https://ww
w.buymeacoffee.com/nofil). Absolutely no pressure to do so, 
appreciate all the comments and support 🙏

You can read the 
free newsletter [here](https://nofil.beehiiv.com/)

Fun fact
: I had to go through over 100 saved tabs to collate all of 
these and it took me quite a few hours

Edit: So many people
 ask why I don't get chatgpt to write this for me. Chatgpt d
oesn't have access to the internet. Plugins would help but I
 don't have access yet so I have to do things the old fashio
ned way - like a human.

(I'm not associated with any tool o
r company. Written and collated entirely by me, no chatgpt u
sed)"	"https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/"	"2111"	"1680783039.0"	"13062"	"12diapw"
114	"Chat GPT rap battled me"	""	"https://www.reddit.com/gallery/10zfvc7"	"625"	"1676103083.0"	"10888"	"10zfvc7"
115	"I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally."	"With ChatGPT blowing up over the past year, it seems like ev
ery person and their grandmother is launching an AI startup.
 There are a plethora of AI tools available, some excellent 
and some less so. Amid this flood of new technology, there a
re a few hidden gems that I personally find incredibly usefu
l, having reviewed them for my AI directory. Here are the on
es I have personally integrated into my workflow in both my 
professional and entreprenuerial life:  


* **Plus AI for G
oogle Slides -** Generate Presentations  
There's a few slid
e deck generators out there however I've found Plus AI works
 much better at helping you 'co-write' slides rather than si
mply spitting out a mediocre finished product that likely wo
n't be useful. For instance, there's 'sticky notes' to slide
s with suggestions on how to finish / edit / improve each sl
ide. Another major reason why I've stuck with Plus AI is the
 ability for 'snapshots', or the ability to use external dat
a (i.e. from web sources/dashboards) for your presentations.
 For my day job I work in a chemical plant as an engineer, a
nd one of my tasks is to present in meetings about productio
n KPIs to different groups for different purposes- and graph
s for these are often found across various internal web apps
. I can simply use Plus AI to generate 'boilerplate' for my 
slide deck, then go through each slide to make sure it's usi
ng the correct snapshot. The presentation generator itself i
s completely free and available as a plugin for Google Slide
s and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your
 Documents  
Great tool for using ChatGPT on your own files 
and website. Works very well especially if you are dealing w
ith a lot of documents. The basic plan allows you to upload 
over 100 files and this was a life saver during online, open
 book exams for a few training courses I've taken. I've noti
ced it hallucinates much less compared to other GPT-powered 
bots trained on your knowledge base. For this reason I prefe
r My AskAI for research or any tasks where accuracy is neede
d over the other custom chatbot solutions I have tried. Anot
her plus is that it shows the sources within your knowledge 
base where it got the answers from, and you can choose to ha
ve it give you a more concise answer or a more detailed one.
 There's a free plan however it was worth it for me to get t
he $20/mo option as it allows over 100 pieces of content.  


---

* **Krater.ai** **-** All AI Tools in One App  
Perfec
t solution if you use many AI tools and loathe having to hav
e multiple tabs open. Essentially combines text, audio, and 
image-based generative AI tools into a single web app, so yo
u can continue with your workflow without having to switch t
abs all the time. There's plenty of templates available for 
copywriting- it beats having to prompt manually each time or
 having to save and reference prompts over and over again. I
 prefer Krater over Writesonic/Jasper for ease of use. You a
lso get 10 generations a month for free compared to Jasper o
ffering none, so its a better free option if you want an all
-in-one AI content solution. The text to speech feature is s
imple however works reliably fast and offers multilingual tr
anscription, and the image generator tool is great for photo
-realistic images.  

---

* **HARPA AI -** ChatGPT Inside C
hrome  
Simply by far the best GTP add-on for Chrome I've us
ed. Essentially gives you GPT answers beside the typical sea
rch results on any search engine such as Google or Bing, alo
ng with the option to 'chat' with any web page or summarize 
YouTube videos. Also great for writing emails and replying t
o social media posts with its preset templates. Currently th
ey don't have any paid features, so it's entirely free and y
ou can find it on the chrome web store for extensions.  

--
-

* **Taskade -** All in One Productivity/Notes/Organizatio
n AI Tool  
Combines tasks, notes, mind maps, chat, and an A
I chat assistant all within one platform that syncs across y
our team. Definitely simplifies my day-to-day operations, re
moving the need to swap between numerous apps. Also helps me
 to visualize my work in various views - list, board, calend
ar, mind map, org chart, action views - it's like having a S
wiss Army knife for productivity. Personally I really like t
he AI 'mind map.' It's like having a brainstorming partner t
hat never runs out of energy. Taskade's free version has qui
te a lot to offer so no complaints there.  

---

* **Zapier
 + OpenAI -** AI-Augmented Automations  
Definitely my secre
t productivity powerhouse. Pretty much combines the power of
 Zapier's cross-platform integrations with generative AI. On
e of the ways I've used this is pushing Slack messages to cr
eate a task on Notion, with OpenAI writing the task based on
 the content of the message. Another useful automation I've 
used is for automatically writing reply drafts with GPT from
 emails that get sent to me in Gmail. The opportunities are 
pretty endless with this method and you can pretty much inte
grate any automation with GPT 3, as well as DALLE-2 and Whis
per AI. It's available as an app/add-on to Zapier and its fr
ee for all the core features.  

---

* **SaneBox -** AI Ema
ils Management  
If you are like me and find important email
s getting lost in a sea of spam, this is a great solution. B
asically Sanebox uses AI to sift through your inbox and iden
tify emails that are actually important, and you can also se
t it up to make certain emails go to specific folders. Non i
mportant emails get sent to a folder called SaneLater and th
is is something you can ignore entirely or check once in a w
hile. Keep in mind that SaneBox doesn't actually read the co
ntents of your email, but rather takes into consideration th
e header, metadata, and history with the sender. You can als
o finetune the system by dragging emails to the folder it sh
ould have gone to. Another great feature is the their 'Deep 
Clean', which is great for freeing up space by deleting old 
emails you probably won't ever need anymore. Sanebox doesn't
 have a free plan however they do have a 2 week trial, and t
he pricing is quite affordable, depending on the features yo
u need.  

---

* **Hexowatch AI -** Detect Website Changes 
with AI  
Lifesaver if you need to ever need to keep track o
f multiple websites. I use this personally for my AI tools d
irectory, and it notifies me of any changes made to any of t
he 1000+ websites for AI tools I have listed, which is somet
hing that would take up more time than exists in a single da
y if I wanted to keep on top of this manually. The AI detect
s any types of changes (visual/HTML) on monitored webpages a
nd sends alert via email or Slack/Telegram/Zapier. Like Sane
box there's no free plan however you do get what you pay for
 with this one.  

---

* **Bonus: SongsLike X -** Find Simi
lar Songs  
This one won't be generating emails or presentat
ions anytime soon, but if you like grinding along to music l
ike me you'll find this amazing. Ironically it's probably th
e one I use most on a daily basis. You can enter any song an
d it will automatically generate a Spotify playlist for you 
with similar songs. I find it much more accurate than Spotif
y's 'go to song radio' feature.  


While it's clear that no
t all of these tools may be directly applicable to your need
s, I believe that simply being aware of the range of options
 available can be greatly beneficial. This knowledge can bro
aden your perspective on what's possible and potentially ins
pire new ideas.

**P.S. If you liked this,** as mentioned pr
eviously I've created a [free directory](https://aiscout.net
/) that lists over 1000 AI tools. It's updated daily and the
re's also a GPT-powered chatbot to help you AI tools for you
r needs. Feel free to check it out if it's your cup of tea"	"https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/"	"676"	"1685721851.0"	"10514"	"13ygr47"
116	"ChatGPT with the galaxy brain move."	""	"https://i.redd.it/svj1fu9qu88b1.jpg"	"294"	"1687733736.0"	"10500"	"14j01dm"
117	"Anyone ever seen GPT-4 make a typo before?"	""	"https://i.redd.it/7etbf5iumd2b1.jpg"	"868"	"1685176472.0"	"9642"	"13t216j"
118	"I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer"	""	"https://www.reddit.com/gallery/13ka7rg"	"720"	"1684348744.0"	"9070"	"13ka7rg"
119	"OpenAI now sends email threats?!"	"Been sexting with ChatGPT since the beginning and continuous
ly improving my jailbreaking skills. Sometimes my inputs are
 red or orange flagged but never got any trouble before. How
ever today, the second after one of my inputs was orange fla
gged, I received an email threatening to terminate my servic
es. Has anyone received similar emails?"	"https://i.redd.it/r2l2gbllq1ab1.jpg"	"1469"	"1688519235.0"	"8601"	"14qwa6m"
120	"5 things I wish I knew before building a GPT agent for log analysis"	"Three weeks ago I started developing a [ReAct Agent](https:/
/dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app
. A ReAct agent uses reasoning and logic combined with exter
nal tools to fulfill a task. The app - [LogPal.ai](https://l
ogpal.aio/)  \- lets you ask questions about the data in app
 log file files,  generating SQL queries and Javascript char
ts to analyze the data.

After a rough start, I’ve found a b
it of a groove. I wanted to share five things I wish I knew 
before developing a GPT-powered agent.

[A crude demo of Log
Pal.ai executing a ReAct agent to answer questions about a l
og file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84
b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A qui
ck demo showing the stark difference between GPT-3.5 and GPT
-4 when running a ReAct agent loop. ](https://reddit.com/lin
k/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a 
GPT-4 API limit increase, I needed to use the gpt-3.5-turbo 
 
 model instead. It sucked: poor code,  malformed JSON, and
 bizarre responses are the norm.

However, there’s a silver 
lining! gpt-3.5-turbo is great for adding chaos to your agen
t loop and seeing how resilient your code is to errors.

## 
2. Don’t use a framework

[A quick ReAct intro and demo of t
he ReAct agent in action within the OpenAI Playground. ](htt
ps://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I 
started with [Langchain](https://github.com/hwchase17/langch
ain), but I had a hell of time debugging and tweaking the fr
amework to suit my needs. Next, I shifted to [Boxcars](https
://github.com/BoxcarsAI/boxcars),  which has fewer abstracti
ons. While Boxcars was easier to understand, I  still strugg
led when things behaved differently than I’d expected.  Fina
lly, I said screw it…I’m not doing *that much*:

1. Sending 
and receiving text
2. Parsing text
3. Executing external too
ls

Why not write this logic myself? I’m not the type that l
ikes to  reinvent the wheel, so I came to this conclusion re
luctantly. However,  implementing the above didn’t seem *tha
t hard*, gave me ultimate flexibility, and forced me to lear
n how ReAct works.

I started with a [zero shot prompt](http
s://www.promptingguide.ai/techniques/zeroshot) that closely 
resembles the prompt in the [ReAct paper](https://arxiv.org/
abs/2210.03629) with one addition: asking for output in JSON
 format (more on that later…it’s far from bulletproof).

Thi
s roll-my-own strategy ended up paying huge dividends due to
 the  need for prompt-specific context, output formats, and 
error handling.

## 3. Prompts need specific handling

[ A q
uick demo of the SQL query generator prompt re-generating a 
correct SQL query after an initial error. ](https://reddit.c
om/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my a
pp has three prompts:

1. Zero shot ReAct prompt
2. SQL quer
y generator prompt
3. Javascript chart generator prompt

I’v
e found that each prompt needs customized context, output fo
rmats, and error handling for the agent to perform well.

##
# Customized context

There are 3 messaging-related parts of
 an [OpenAI API request](https://platform.openai.com/docs/gu
ides/gpt/chat-completions-api) you can tweak:

1. **System m
essage** \- the prompt text
2. **User messages** \- input fr
om the user (ex: “What’s the average response time?”)
3. **A
ssistant messages** \- completions from the API

The user an
d assistant messages are used to give the model more  contex
t. Unlike ChatGPT (which automatically builds context from p
rior  messages), you need to provide the history yourself wh
en using the API.  At first, I sent each prompt the same mes
sage history, which was every  user and assistant message in
 the chat history. However, with this  simple approach, I wo
uld frequently get bizarre responses to questions.  For exam
ple, I might ask “What is the request throughput?”, and rece
ive a  bizarre final answer like “There were no request erro
rs”.

After lots of experimentation (more later on how to it
erate quickly  on the message context), I found that sending
 prompt-specific context  generates the most helpful complet
ions:

1. **Zero shot** \- all messages (including tool outp
ut) after the last answered question.
2. **SQL query generat
or** \- previously generated  queries and the error output a
ssociated when executing each SQL  statement (if an error is
 present). The error output is critical for  helping the que
ry generator correct itself if an original query is  invalid
.
3. **Chart generator** \- similar to the SQL query generat
or, I send previously generated charts and any error output 
(if present).

While increasing the max context token size i
s frequently seen as *the path*  to better completions, I sa
w a correlation between increased context  length and off-tr
ack  completions. What I provided as context mattered a  lot
.

### Machine-readable output formats

The examples I start
ed from for a ReAct agent all asked for  completions in a pl
ain-text format. However, I found that building  regexes to 
parse the output was incredibly brittle due to the  non-dete
rministic behavior of the GPT models and the complexity of s
ome  completions, which include code snippets.

Here’s what’
s worked best for me:

1. **Zero shot ReAct prompt** \- JSON
. Continue below for how I handle malformed JSON (which happ
ens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-
flavored code blocks (triple backticks). I then use a regex 
to  parse out the code block. Remarkably, this has been very
 reliable.

### Error handling

I’ve found that the ReAct pr
ompt and the code generator prompts require two different ty
pes of error handling:

1. **Zero shot ReAct prompt** \- if 
the JSON is malformed  (this happens), I simply repeat the s
ame API request. More often than  not, this returns valid JS
ON on later attempts.
2. **SQL & Chart generator prompts** \
- I’ve yet to  see a malformed GitHub-flavored code block. I
nstead, the most common  issue is an invalid SQL query. I in
clude the generated SQL and error  output in the next API re
quest. This has been very effective at  correcting the outpu
t.

🤷 - I don’t know why JSON is frequently malformed but co
de blocks are not.

# 4. Increase your dev cycles with a rep
lay tool

[Showing the replay tool in action and forcing a h
allucination.](https://reddit.com/link/141l6oy/video/4ts2unz
yd84b1/player)

Learning to customize the context, output fo
rmats, and error handling  based on the prompt type came fro
m replicating my API requests in the [OpenAI Playground](htt
ps://platform.openai.com/playground).  I would copy and past
e the prompt, user messages, and assistant  messages into th
e playground, and then modify the inputs to see if I  could 
get a better response. The manual copy and pasting was a slo
w  process.

To move faster, I created an OpenAIReplay tool.
 When I  make an API request, I save the API request paramet
ers and the response  to a file. I can then load the file, m
odify the request parameters, and  replay the request. This 
tool has been huge for debugging as it’s much  faster than c
opying and pasting into the playground. My tool is  app-spec
ific, but it’s an easy thing to build. My tool works like th
is:

    # loads the message, writes the message's API reque
st params to a file, and opens the file in VS Code for editi
ng. replay = OpenAiReplay.from_message(message_id_or_object 
= Message.last) # ... make edits to the file ... replay.chat
! 

## 5. Use the stream API option

The GPT API is slower t
han what you see in ChatGPT ([source](https://community.open
ai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In 
my experience, it’s critical to use the [stream](https://pla
tform.openai.com/docs/api-reference/completions/create)  mod
e of the API versus waiting for a full completion to speed u
p dev  cycles (especially if you are generating long complet
ions):

1. I think stream is a bit faster to reach a complet
ion
2. Waiting for a full completion frequently results in A
PI timeout and 503 errors
3. You can quickly abort if it’s c
lear that the completion is going to be bad

In short: *coup
ling a replay tool with streaming completions is the fastest
 way to iterate on your agent.*

## TL;DR

If I was building
 [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use G
PT-4**. It’s far better than gpt-3.5-turboat reasoning and c
ode completion. gpt-3.5-turbois great for introducing chaos 
into your agent loop when testing.
2. **Not use an LLM app f
ramework.** Start with your language’s OpenAI API client and
 build from there.
3. **Plan on customizing prompt context, 
output formats, and error handling.** This is critical for g
etting good completions.
4. **Create/use an API replay tool*
*. Make it easy to replay API calls as it’s too slow to copy
 & paste these into the OpenAI playground.
5. **Stream compl
etions**. Use the stream mode of the API to speed up dev cyc
les. You can quickly abort if a completion is off the rails.
"	"https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/"	"4"	"1685984881.0"	"34"	"141l6oy"
121	"I made a dashboard to analyze OpenAI API usage"	""	"https://v.redd.it/vrz3h5bv8fya1"	"5"	"1683470617.0"	"15"	"13aqw5j"
122	"Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial"	"Hey there!   


I wanted to let you know that I just release
d a new video where I'm using some really cool technologies 
like Python, OpenAI API's, Chroma, and LangChain to answer q
uestions based on Youtube videos.

If you don't have the tim
e or patience to sit through a 3-hour lecture, no worries!  
 
My tutorial covers a solution!

I'm really excited to shar
e this with you and I think you'll find it super helpful.  

check out the video here: [**https://youtu.be/mhdOTLp-IjQ**]
(https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"	"https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/"	"0"	"1681481977.0"	"14"	"12lyu24"
123	"I built an app to help you get full visibility and control over your OpenAI costs."	""	"https://i.redd.it/te4jhjr3wf0b1.png"	"0"	"1684350106.0"	"12"	"13katfn"
124	"OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform"	"The GPT-3.5 Turbo model has been updated to 16k as of today 
and is priced at $0.003 per 1K input tokens and $0.004 per 1
K output tokens.

This new version is more steerable with th
e system message and includes a new capability: function cal
ling. By describing functions in your prompts, the model can
 intelligently output a JSON object containing arguments to 
call these functions based on user input — perfect for integ
rating with other tools or APIs.

OpenAI has also reduced th
e cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015
 per 1K input tokens), effective immediately.

On June 27th,
 the stable gpt-3.5-turbo will be automatically upgraded. 


#AI #OpenAI[Function calling and other API](https://openai.c
om/blog/function-calling-and-other-api-updates)"	"https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/"	"6"	"1686713922.0"	"12"	"148xhn3"
125	"Query current data - OpenAI Embeddings, Chroma and LangChain"	"Hi guys, I created a video on how to use Chroma in combinati
on with LangChain and the Wikipedia API to query your own da
ta.

Asking about your own data is the future of LLMs!   



Disclaimer: Own data can be everything which is text!

[http
s://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[ht
tps://github.com/grumpyp/chroma-langchain-tutorial](https://
github.com/grumpyp/chroma-langchain-tutorial)

hope you enjo
y it!"	"https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/"	"2"	"1681158025.0"	"10"	"12huv4f"
126	"Open Source - OpenAI , Chroma , LangChain , HuggingFace sample"	"Python - upload your docs, persist embeddings in Chroma and 
build using huggingface transformers, delete, rebuild Chroma
 embeddings store, use LangChain agent for querying across t
he documents - https://github.com/ushakrishnan/SearchWithOpe
nAI"	"https://i.redd.it/v2amznhrvj1b1.jpg"	"4"	"1684816263.0"	"9"	"13pdymt"
127	"How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch"	"I created a semantic Q&A  bot for >13k recorded (webscraped,
 that is...) dreams using OpenAI embeddings APIs, Langchain 
and  Elasticsearch. It can answer queries like this one:  



'Find me all dreams containing animals, and provide me a li
st with their activities.'  


What  it returns are not only
 a proper, meaningful answer, but also  references to  relev
ant documents. Imagine for a moment how hard running  such a
 query with a traditional search engine would be! More or le
ss  impossible for 13k documents! First of all, there is no 
clearly defined  concept of what an 'animal' is, you'd end u
p specifying a long list of  actual animals in your input qu
ery. Second, once you identified them  you'd have to manuall
y derive what their activities are, the text search  engine 
is not able to do that for you.  


Of course, there is a lo
t  of vagueness and fuzziness in how such a system operates.
 So, there's a  tradeoff here: A semantic Q&A bot is very po
werful, but at the same  time you have to put a lot of (blin
d) trust in it. How can you know the  system does not 'forge
t' an important animal or document? Well, you  cannot. But t
hen again, would it be really better to do all of this  manu
ally? As usual, the answer depends on your requirements. I t
hink a  semantic Q&A bot is great if you're after convenienc
e and speed, but  not so good if your primary goals are corr
ectness and recall &  precision.  


I believe such semantic
 Q&A bots may have the  potential to become an important pie
ce in scientific research, as they  are at the intersection 
between qualitative (e.g. hermeneutic) and  quantitative res
earch. For example, a researcher who has a dataset of  trans
cribed interviews can easily test few hypotheses on them to 
get a  first summary on relevant points. Later on, she might
 decide to dive  into some of them.

[https://fabian-kostadi
nov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-wit
h-openai-embeddings-api-elasticsearch-and-langchain/](https:
//fabian-kostadinov.github.io/2023/06/12/how-i-created-a-sem
antic-qa-bot-with-openai-embeddings-api-elasticsearch-and-la
ngchain/)"	"https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/"	"2"	"1686674014.0"	"10"	"148jhur"
128	"Someone hacked my OpenAI account and used 4000$ worth of tokens"	"Someone just hacked my OpenAI account and used all the credi
ts. I don't know how this happended but It seems like some c
hrome extension might have read my ID and passwords then he 
just logged into my account and reset the hard limit of my a
ccount and started using it for their personal use. I just c
hecked my account and it says that I need to pay 4000$ which
 I haven't used.

I can't even afford to pay this much of am
ount. I've raised a request in OpenAI support. Hoping for a 
good outcome.

Why am I suspecting that hacker got my accoun
t not just an API Key

\- Hard limit was reset to 4000$ (Pre
viously it was much lower 500$ or even less)

\- Generated a
 new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in a
ny of my product

There should be a email verification or 2F
A while changing the hard limit of the account. I got the em
ail when my hard limit reached not when someone changed the 
hard limit of my account and used all the credits.

Just yes
terday, I got notification from Google chrome that there was
 one extension I've installed was found malicious which I've
 immeditely removed. I suspect it might have stolen the acco
unt ID and password do this malicious activity.

https://pre
view.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=we
bp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"	"https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/"	"18"	"1689851811.0"	"9"	"154o35w"
129	"What this sub is about and what are the differences to other subs"	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a su
breddit dedicated to serious discussion of artificial intell
igence, machine learning, natural language processing, and r
elated topics.

At r/OpenAIDev, we’re focused on your creati
ons/inspirations, quality content, breaking news, and advanc
ements in the field of AI. We want to foster a community whe
re people can come together to learn, discuss, and share the
ir knowledge and ideas.
We also want to **encourage others t
hat feel lost since AI moves so rapidly and job loss is the 
most discussed topic**. As a 20y+ experienced programmer mys
elf I see it as a helpful tool that speeds up my work every 
day. And I think everyone can take advantage of it and try t
o focus on the positive side when they know how. We try to s
hare that knowledge.

That being said, **we are not a meme s
ubreddit**, and we do not support low-effort posts or repost
s. Our focus is on substantive content that drives thoughtfu
l discussion and encourages learning and growth.

We welcome
 anyone who is curious about AI and passionate about explori
ng its potential to join our community. Whether you’re a sea
soned expert or just starting out, we hope you’ll find a hom
e here at r/OpenAIDev.

We also have a **Discord channel tha
t lets you use MidJourney at my costs** (The trial option ha
s been recently removed by MidJourney). Since I just play wi
th some prompts from time to time I don't mind to let everyo
ne use it for now until the monthly limit is reached:

https
://discord.gg/GmmCSMJqpb

So come on in, share your knowledg
e, ask your questions, and let’s explore the exciting world 
of AI together!

There are now some basic rules available as
 well as post and user flairs. **Please suggest new flairs i
f you have ideas**.

When there is **interest to become a mo
d of this sub** please send a DM with your experience and av
ailable time. Thanks."	"https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/"	"5"	"1681071204.0"	"10"	"12gua7o"
130	"5 things I wish I knew before building a GPT agent for log analysis"	"Three weeks ago I started developing a [ReAct Agent](https:/
/dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app
. A ReAct agent uses reasoning and logic combined with exter
nal tools to fulfill a task. The app - [LogPal.ai](https://l
ogpal.aio/)  \- lets you ask questions about the data in app
 log file files,  generating SQL queries and Javascript char
ts to analyze the data.

After a rough start, I’ve found a b
it of a groove. I wanted to share five things I wish I knew 
before developing a GPT-powered agent.

[A crude demo of Log
Pal.ai executing a ReAct agent to answer questions about a l
og file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84
b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A qui
ck demo showing the stark difference between GPT-3.5 and GPT
-4 when running a ReAct agent loop. ](https://reddit.com/lin
k/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a 
GPT-4 API limit increase, I needed to use the gpt-3.5-turbo 
 
 model instead. It sucked: poor code,  malformed JSON, and
 bizarre responses are the norm.

However, there’s a silver 
lining! gpt-3.5-turbo is great for adding chaos to your agen
t loop and seeing how resilient your code is to errors.

## 
2. Don’t use a framework

[A quick ReAct intro and demo of t
he ReAct agent in action within the OpenAI Playground. ](htt
ps://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I 
started with [Langchain](https://github.com/hwchase17/langch
ain), but I had a hell of time debugging and tweaking the fr
amework to suit my needs. Next, I shifted to [Boxcars](https
://github.com/BoxcarsAI/boxcars),  which has fewer abstracti
ons. While Boxcars was easier to understand, I  still strugg
led when things behaved differently than I’d expected.  Fina
lly, I said screw it…I’m not doing *that much*:

1. Sending 
and receiving text
2. Parsing text
3. Executing external too
ls

Why not write this logic myself? I’m not the type that l
ikes to  reinvent the wheel, so I came to this conclusion re
luctantly. However,  implementing the above didn’t seem *tha
t hard*, gave me ultimate flexibility, and forced me to lear
n how ReAct works.

I started with a [zero shot prompt](http
s://www.promptingguide.ai/techniques/zeroshot) that closely 
resembles the prompt in the [ReAct paper](https://arxiv.org/
abs/2210.03629) with one addition: asking for output in JSON
 format (more on that later…it’s far from bulletproof).

Thi
s roll-my-own strategy ended up paying huge dividends due to
 the  need for prompt-specific context, output formats, and 
error handling.

## 3. Prompts need specific handling

[ A q
uick demo of the SQL query generator prompt re-generating a 
correct SQL query after an initial error. ](https://reddit.c
om/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my a
pp has three prompts:

1. Zero shot ReAct prompt
2. SQL quer
y generator prompt
3. Javascript chart generator prompt

I’v
e found that each prompt needs customized context, output fo
rmats, and error handling for the agent to perform well.

##
# Customized context

There are 3 messaging-related parts of
 an [OpenAI API request](https://platform.openai.com/docs/gu
ides/gpt/chat-completions-api) you can tweak:

1. **System m
essage** \- the prompt text
2. **User messages** \- input fr
om the user (ex: “What’s the average response time?”)
3. **A
ssistant messages** \- completions from the API

The user an
d assistant messages are used to give the model more  contex
t. Unlike ChatGPT (which automatically builds context from p
rior  messages), you need to provide the history yourself wh
en using the API.  At first, I sent each prompt the same mes
sage history, which was every  user and assistant message in
 the chat history. However, with this  simple approach, I wo
uld frequently get bizarre responses to questions.  For exam
ple, I might ask “What is the request throughput?”, and rece
ive a  bizarre final answer like “There were no request erro
rs”.

After lots of experimentation (more later on how to it
erate quickly  on the message context), I found that sending
 prompt-specific context  generates the most helpful complet
ions:

1. **Zero shot** \- all messages (including tool outp
ut) after the last answered question.
2. **SQL query generat
or** \- previously generated  queries and the error output a
ssociated when executing each SQL  statement (if an error is
 present). The error output is critical for  helping the que
ry generator correct itself if an original query is  invalid
.
3. **Chart generator** \- similar to the SQL query generat
or, I send previously generated charts and any error output 
(if present).

While increasing the max context token size i
s frequently seen as *the path*  to better completions, I sa
w a correlation between increased context  length and off-tr
ack  completions. What I provided as context mattered a  lot
.

### Machine-readable output formats

The examples I start
ed from for a ReAct agent all asked for  completions in a pl
ain-text format. However, I found that building  regexes to 
parse the output was incredibly brittle due to the  non-dete
rministic behavior of the GPT models and the complexity of s
ome  completions, which include code snippets.

Here’s what’
s worked best for me:

1. **Zero shot ReAct prompt** \- JSON
. Continue below for how I handle malformed JSON (which happ
ens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-
flavored code blocks (triple backticks). I then use a regex 
to  parse out the code block. Remarkably, this has been very
 reliable.

### Error handling

I’ve found that the ReAct pr
ompt and the code generator prompts require two different ty
pes of error handling:

1. **Zero shot ReAct prompt** \- if 
the JSON is malformed  (this happens), I simply repeat the s
ame API request. More often than  not, this returns valid JS
ON on later attempts.
2. **SQL & Chart generator prompts** \
- I’ve yet to  see a malformed GitHub-flavored code block. I
nstead, the most common  issue is an invalid SQL query. I in
clude the generated SQL and error  output in the next API re
quest. This has been very effective at  correcting the outpu
t.

🤷 - I don’t know why JSON is frequently malformed but co
de blocks are not.

# 4. Increase your dev cycles with a rep
lay tool

[Showing the replay tool in action and forcing a h
allucination.](https://reddit.com/link/141l6oy/video/4ts2unz
yd84b1/player)

Learning to customize the context, output fo
rmats, and error handling  based on the prompt type came fro
m replicating my API requests in the [OpenAI Playground](htt
ps://platform.openai.com/playground).  I would copy and past
e the prompt, user messages, and assistant  messages into th
e playground, and then modify the inputs to see if I  could 
get a better response. The manual copy and pasting was a slo
w  process.

To move faster, I created an OpenAIReplay tool.
 When I  make an API request, I save the API request paramet
ers and the response  to a file. I can then load the file, m
odify the request parameters, and  replay the request. This 
tool has been huge for debugging as it’s much  faster than c
opying and pasting into the playground. My tool is  app-spec
ific, but it’s an easy thing to build. My tool works like th
is:

    # loads the message, writes the message's API reque
st params to a file, and opens the file in VS Code for editi
ng. replay = OpenAiReplay.from_message(message_id_or_object 
= Message.last) # ... make edits to the file ... replay.chat
! 

## 5. Use the stream API option

The GPT API is slower t
han what you see in ChatGPT ([source](https://community.open
ai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In 
my experience, it’s critical to use the [stream](https://pla
tform.openai.com/docs/api-reference/completions/create)  mod
e of the API versus waiting for a full completion to speed u
p dev  cycles (especially if you are generating long complet
ions):

1. I think stream is a bit faster to reach a complet
ion
2. Waiting for a full completion frequently results in A
PI timeout and 503 errors
3. You can quickly abort if it’s c
lear that the completion is going to be bad

In short: *coup
ling a replay tool with streaming completions is the fastest
 way to iterate on your agent.*

## TL;DR

If I was building
 [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use G
PT-4**. It’s far better than gpt-3.5-turboat reasoning and c
ode completion. gpt-3.5-turbois great for introducing chaos 
into your agent loop when testing.
2. **Not use an LLM app f
ramework.** Start with your language’s OpenAI API client and
 build from there.
3. **Plan on customizing prompt context, 
output formats, and error handling.** This is critical for g
etting good completions.
4. **Create/use an API replay tool*
*. Make it easy to replay API calls as it’s too slow to copy
 & paste these into the OpenAI playground.
5. **Stream compl
etions**. Use the stream mode of the API to speed up dev cyc
les. You can quickly abort if a completion is off the rails.
"	"https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/"	"4"	"1685984881.0"	"33"	"141l6oy"
131	"I made a dashboard to analyze OpenAI API usage"	""	"https://v.redd.it/vrz3h5bv8fya1"	"5"	"1683470617.0"	"14"	"13aqw5j"
132	"Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial"	"Hey there!   


I wanted to let you know that I just release
d a new video where I'm using some really cool technologies 
like Python, OpenAI API's, Chroma, and LangChain to answer q
uestions based on Youtube videos.

If you don't have the tim
e or patience to sit through a 3-hour lecture, no worries!  
 
My tutorial covers a solution!

I'm really excited to shar
e this with you and I think you'll find it super helpful.  

check out the video here: [**https://youtu.be/mhdOTLp-IjQ**]
(https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"	"https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/"	"0"	"1681481977.0"	"13"	"12lyu24"
133	"I built an app to help you get full visibility and control over your OpenAI costs."	""	"https://i.redd.it/te4jhjr3wf0b1.png"	"0"	"1684350106.0"	"12"	"13katfn"
134	"OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform"	"The GPT-3.5 Turbo model has been updated to 16k as of today 
and is priced at $0.003 per 1K input tokens and $0.004 per 1
K output tokens.

This new version is more steerable with th
e system message and includes a new capability: function cal
ling. By describing functions in your prompts, the model can
 intelligently output a JSON object containing arguments to 
call these functions based on user input — perfect for integ
rating with other tools or APIs.

OpenAI has also reduced th
e cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015
 per 1K input tokens), effective immediately.

On June 27th,
 the stable gpt-3.5-turbo will be automatically upgraded. 


#AI #OpenAI[Function calling and other API](https://openai.c
om/blog/function-calling-and-other-api-updates)"	"https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/"	"6"	"1686713922.0"	"11"	"148xhn3"
135	"Query current data - OpenAI Embeddings, Chroma and LangChain"	"Hi guys, I created a video on how to use Chroma in combinati
on with LangChain and the Wikipedia API to query your own da
ta.

Asking about your own data is the future of LLMs!   



Disclaimer: Own data can be everything which is text!

[http
s://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[ht
tps://github.com/grumpyp/chroma-langchain-tutorial](https://
github.com/grumpyp/chroma-langchain-tutorial)

hope you enjo
y it!"	"https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/"	"2"	"1681158025.0"	"10"	"12huv4f"
136	"Open Source - OpenAI , Chroma , LangChain , HuggingFace sample"	"Python - upload your docs, persist embeddings in Chroma and 
build using huggingface transformers, delete, rebuild Chroma
 embeddings store, use LangChain agent for querying across t
he documents - https://github.com/ushakrishnan/SearchWithOpe
nAI"	"https://i.redd.it/v2amznhrvj1b1.jpg"	"4"	"1684816263.0"	"10"	"13pdymt"
137	"How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch"	"I created a semantic Q&A  bot for >13k recorded (webscraped,
 that is...) dreams using OpenAI embeddings APIs, Langchain 
and  Elasticsearch. It can answer queries like this one:  



'Find me all dreams containing animals, and provide me a li
st with their activities.'  


What  it returns are not only
 a proper, meaningful answer, but also  references to  relev
ant documents. Imagine for a moment how hard running  such a
 query with a traditional search engine would be! More or le
ss  impossible for 13k documents! First of all, there is no 
clearly defined  concept of what an 'animal' is, you'd end u
p specifying a long list of  actual animals in your input qu
ery. Second, once you identified them  you'd have to manuall
y derive what their activities are, the text search  engine 
is not able to do that for you.  


Of course, there is a lo
t  of vagueness and fuzziness in how such a system operates.
 So, there's a  tradeoff here: A semantic Q&A bot is very po
werful, but at the same  time you have to put a lot of (blin
d) trust in it. How can you know the  system does not 'forge
t' an important animal or document? Well, you  cannot. But t
hen again, would it be really better to do all of this  manu
ally? As usual, the answer depends on your requirements. I t
hink a  semantic Q&A bot is great if you're after convenienc
e and speed, but  not so good if your primary goals are corr
ectness and recall &  precision.  


I believe such semantic
 Q&A bots may have the  potential to become an important pie
ce in scientific research, as they  are at the intersection 
between qualitative (e.g. hermeneutic) and  quantitative res
earch. For example, a researcher who has a dataset of  trans
cribed interviews can easily test few hypotheses on them to 
get a  first summary on relevant points. Later on, she might
 decide to dive  into some of them.

[https://fabian-kostadi
nov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-wit
h-openai-embeddings-api-elasticsearch-and-langchain/](https:
//fabian-kostadinov.github.io/2023/06/12/how-i-created-a-sem
antic-qa-bot-with-openai-embeddings-api-elasticsearch-and-la
ngchain/)"	"https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/"	"2"	"1686674014.0"	"10"	"148jhur"
138	"Someone hacked my OpenAI account and used 4000$ worth of tokens"	"Someone just hacked my OpenAI account and used all the credi
ts. I don't know how this happended but It seems like some c
hrome extension might have read my ID and passwords then he 
just logged into my account and reset the hard limit of my a
ccount and started using it for their personal use. I just c
hecked my account and it says that I need to pay 4000$ which
 I haven't used.

I can't even afford to pay this much of am
ount. I've raised a request in OpenAI support. Hoping for a 
good outcome.

Why am I suspecting that hacker got my accoun
t not just an API Key

\- Hard limit was reset to 4000$ (Pre
viously it was much lower 500$ or even less)

\- Generated a
 new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in a
ny of my product

There should be a email verification or 2F
A while changing the hard limit of the account. I got the em
ail when my hard limit reached not when someone changed the 
hard limit of my account and used all the credits.

Just yes
terday, I got notification from Google chrome that there was
 one extension I've installed was found malicious which I've
 immeditely removed. I suspect it might have stolen the acco
unt ID and password do this malicious activity.

https://pre
view.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=we
bp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"	"https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/"	"18"	"1689851811.0"	"9"	"154o35w"
139	"What this sub is about and what are the differences to other subs"	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a su
breddit dedicated to serious discussion of artificial intell
igence, machine learning, natural language processing, and r
elated topics.

At r/OpenAIDev, we’re focused on your creati
ons/inspirations, quality content, breaking news, and advanc
ements in the field of AI. We want to foster a community whe
re people can come together to learn, discuss, and share the
ir knowledge and ideas.
We also want to **encourage others t
hat feel lost since AI moves so rapidly and job loss is the 
most discussed topic**. As a 20y+ experienced programmer mys
elf I see it as a helpful tool that speeds up my work every 
day. And I think everyone can take advantage of it and try t
o focus on the positive side when they know how. We try to s
hare that knowledge.

That being said, **we are not a meme s
ubreddit**, and we do not support low-effort posts or repost
s. Our focus is on substantive content that drives thoughtfu
l discussion and encourages learning and growth.

We welcome
 anyone who is curious about AI and passionate about explori
ng its potential to join our community. Whether you’re a sea
soned expert or just starting out, we hope you’ll find a hom
e here at r/OpenAIDev.

We also have a **Discord channel tha
t lets you use MidJourney at my costs** (The trial option ha
s been recently removed by MidJourney). Since I just play wi
th some prompts from time to time I don't mind to let everyo
ne use it for now until the monthly limit is reached:

https
://discord.gg/GmmCSMJqpb

So come on in, share your knowledg
e, ask your questions, and let’s explore the exciting world 
of AI together!

There are now some basic rules available as
 well as post and user flairs. **Please suggest new flairs i
f you have ideas**.

When there is **interest to become a mo
d of this sub** please send a DM with your experience and av
ailable time. Thanks."	"https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/"	"5"	"1681071204.0"	"8"	"12gua7o"
140	"5 things I wish I knew before building a GPT agent for log analysis"	"Three weeks ago I started developing a [ReAct Agent](https:/
/dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app
. A ReAct agent uses reasoning and logic combined with exter
nal tools to fulfill a task. The app - [LogPal.ai](https://l
ogpal.aio/)  \- lets you ask questions about the data in app
 log file files,  generating SQL queries and Javascript char
ts to analyze the data.

After a rough start, I’ve found a b
it of a groove. I wanted to share five things I wish I knew 
before developing a GPT-powered agent.

[A crude demo of Log
Pal.ai executing a ReAct agent to answer questions about a l
og file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84
b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A qui
ck demo showing the stark difference between GPT-3.5 and GPT
-4 when running a ReAct agent loop. ](https://reddit.com/lin
k/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a 
GPT-4 API limit increase, I needed to use the gpt-3.5-turbo 
 
 model instead. It sucked: poor code,  malformed JSON, and
 bizarre responses are the norm.

However, there’s a silver 
lining! gpt-3.5-turbo is great for adding chaos to your agen
t loop and seeing how resilient your code is to errors.

## 
2. Don’t use a framework

[A quick ReAct intro and demo of t
he ReAct agent in action within the OpenAI Playground. ](htt
ps://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I 
started with [Langchain](https://github.com/hwchase17/langch
ain), but I had a hell of time debugging and tweaking the fr
amework to suit my needs. Next, I shifted to [Boxcars](https
://github.com/BoxcarsAI/boxcars),  which has fewer abstracti
ons. While Boxcars was easier to understand, I  still strugg
led when things behaved differently than I’d expected.  Fina
lly, I said screw it…I’m not doing *that much*:

1. Sending 
and receiving text
2. Parsing text
3. Executing external too
ls

Why not write this logic myself? I’m not the type that l
ikes to  reinvent the wheel, so I came to this conclusion re
luctantly. However,  implementing the above didn’t seem *tha
t hard*, gave me ultimate flexibility, and forced me to lear
n how ReAct works.

I started with a [zero shot prompt](http
s://www.promptingguide.ai/techniques/zeroshot) that closely 
resembles the prompt in the [ReAct paper](https://arxiv.org/
abs/2210.03629) with one addition: asking for output in JSON
 format (more on that later…it’s far from bulletproof).

Thi
s roll-my-own strategy ended up paying huge dividends due to
 the  need for prompt-specific context, output formats, and 
error handling.

## 3. Prompts need specific handling

[ A q
uick demo of the SQL query generator prompt re-generating a 
correct SQL query after an initial error. ](https://reddit.c
om/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my a
pp has three prompts:

1. Zero shot ReAct prompt
2. SQL quer
y generator prompt
3. Javascript chart generator prompt

I’v
e found that each prompt needs customized context, output fo
rmats, and error handling for the agent to perform well.

##
# Customized context

There are 3 messaging-related parts of
 an [OpenAI API request](https://platform.openai.com/docs/gu
ides/gpt/chat-completions-api) you can tweak:

1. **System m
essage** \- the prompt text
2. **User messages** \- input fr
om the user (ex: “What’s the average response time?”)
3. **A
ssistant messages** \- completions from the API

The user an
d assistant messages are used to give the model more  contex
t. Unlike ChatGPT (which automatically builds context from p
rior  messages), you need to provide the history yourself wh
en using the API.  At first, I sent each prompt the same mes
sage history, which was every  user and assistant message in
 the chat history. However, with this  simple approach, I wo
uld frequently get bizarre responses to questions.  For exam
ple, I might ask “What is the request throughput?”, and rece
ive a  bizarre final answer like “There were no request erro
rs”.

After lots of experimentation (more later on how to it
erate quickly  on the message context), I found that sending
 prompt-specific context  generates the most helpful complet
ions:

1. **Zero shot** \- all messages (including tool outp
ut) after the last answered question.
2. **SQL query generat
or** \- previously generated  queries and the error output a
ssociated when executing each SQL  statement (if an error is
 present). The error output is critical for  helping the que
ry generator correct itself if an original query is  invalid
.
3. **Chart generator** \- similar to the SQL query generat
or, I send previously generated charts and any error output 
(if present).

While increasing the max context token size i
s frequently seen as *the path*  to better completions, I sa
w a correlation between increased context  length and off-tr
ack  completions. What I provided as context mattered a  lot
.

### Machine-readable output formats

The examples I start
ed from for a ReAct agent all asked for  completions in a pl
ain-text format. However, I found that building  regexes to 
parse the output was incredibly brittle due to the  non-dete
rministic behavior of the GPT models and the complexity of s
ome  completions, which include code snippets.

Here’s what’
s worked best for me:

1. **Zero shot ReAct prompt** \- JSON
. Continue below for how I handle malformed JSON (which happ
ens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-
flavored code blocks (triple backticks). I then use a regex 
to  parse out the code block. Remarkably, this has been very
 reliable.

### Error handling

I’ve found that the ReAct pr
ompt and the code generator prompts require two different ty
pes of error handling:

1. **Zero shot ReAct prompt** \- if 
the JSON is malformed  (this happens), I simply repeat the s
ame API request. More often than  not, this returns valid JS
ON on later attempts.
2. **SQL & Chart generator prompts** \
- I’ve yet to  see a malformed GitHub-flavored code block. I
nstead, the most common  issue is an invalid SQL query. I in
clude the generated SQL and error  output in the next API re
quest. This has been very effective at  correcting the outpu
t.

🤷 - I don’t know why JSON is frequently malformed but co
de blocks are not.

# 4. Increase your dev cycles with a rep
lay tool

[Showing the replay tool in action and forcing a h
allucination.](https://reddit.com/link/141l6oy/video/4ts2unz
yd84b1/player)

Learning to customize the context, output fo
rmats, and error handling  based on the prompt type came fro
m replicating my API requests in the [OpenAI Playground](htt
ps://platform.openai.com/playground).  I would copy and past
e the prompt, user messages, and assistant  messages into th
e playground, and then modify the inputs to see if I  could 
get a better response. The manual copy and pasting was a slo
w  process.

To move faster, I created an OpenAIReplay tool.
 When I  make an API request, I save the API request paramet
ers and the response  to a file. I can then load the file, m
odify the request parameters, and  replay the request. This 
tool has been huge for debugging as it’s much  faster than c
opying and pasting into the playground. My tool is  app-spec
ific, but it’s an easy thing to build. My tool works like th
is:

    # loads the message, writes the message's API reque
st params to a file, and opens the file in VS Code for editi
ng. replay = OpenAiReplay.from_message(message_id_or_object 
= Message.last) # ... make edits to the file ... replay.chat
! 

## 5. Use the stream API option

The GPT API is slower t
han what you see in ChatGPT ([source](https://community.open
ai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In 
my experience, it’s critical to use the [stream](https://pla
tform.openai.com/docs/api-reference/completions/create)  mod
e of the API versus waiting for a full completion to speed u
p dev  cycles (especially if you are generating long complet
ions):

1. I think stream is a bit faster to reach a complet
ion
2. Waiting for a full completion frequently results in A
PI timeout and 503 errors
3. You can quickly abort if it’s c
lear that the completion is going to be bad

In short: *coup
ling a replay tool with streaming completions is the fastest
 way to iterate on your agent.*

## TL;DR

If I was building
 [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use G
PT-4**. It’s far better than gpt-3.5-turboat reasoning and c
ode completion. gpt-3.5-turbois great for introducing chaos 
into your agent loop when testing.
2. **Not use an LLM app f
ramework.** Start with your language’s OpenAI API client and
 build from there.
3. **Plan on customizing prompt context, 
output formats, and error handling.** This is critical for g
etting good completions.
4. **Create/use an API replay tool*
*. Make it easy to replay API calls as it’s too slow to copy
 & paste these into the OpenAI playground.
5. **Stream compl
etions**. Use the stream mode of the API to speed up dev cyc
les. You can quickly abort if a completion is off the rails.
"	"https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/"	"4"	"1685984881.0"	"32"	"141l6oy"
141	"I made a dashboard to analyze OpenAI API usage"	""	"https://v.redd.it/vrz3h5bv8fya1"	"5"	"1683470617.0"	"12"	"13aqw5j"
142	"Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial"	"Hey there!   


I wanted to let you know that I just release
d a new video where I'm using some really cool technologies 
like Python, OpenAI API's, Chroma, and LangChain to answer q
uestions based on Youtube videos.

If you don't have the tim
e or patience to sit through a 3-hour lecture, no worries!  
 
My tutorial covers a solution!

I'm really excited to shar
e this with you and I think you'll find it super helpful.  

check out the video here: [**https://youtu.be/mhdOTLp-IjQ**]
(https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"	"https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/"	"0"	"1681481977.0"	"14"	"12lyu24"
143	"I built an app to help you get full visibility and control over your OpenAI costs."	""	"https://i.redd.it/te4jhjr3wf0b1.png"	"0"	"1684350106.0"	"13"	"13katfn"
144	"OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform"	"The GPT-3.5 Turbo model has been updated to 16k as of today 
and is priced at $0.003 per 1K input tokens and $0.004 per 1
K output tokens.

This new version is more steerable with th
e system message and includes a new capability: function cal
ling. By describing functions in your prompts, the model can
 intelligently output a JSON object containing arguments to 
call these functions based on user input — perfect for integ
rating with other tools or APIs.

OpenAI has also reduced th
e cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015
 per 1K input tokens), effective immediately.

On June 27th,
 the stable gpt-3.5-turbo will be automatically upgraded. 


#AI #OpenAI[Function calling and other API](https://openai.c
om/blog/function-calling-and-other-api-updates)"	"https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/"	"6"	"1686713922.0"	"11"	"148xhn3"
145	"Query current data - OpenAI Embeddings, Chroma and LangChain"	"Hi guys, I created a video on how to use Chroma in combinati
on with LangChain and the Wikipedia API to query your own da
ta.

Asking about your own data is the future of LLMs!   



Disclaimer: Own data can be everything which is text!

[http
s://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[ht
tps://github.com/grumpyp/chroma-langchain-tutorial](https://
github.com/grumpyp/chroma-langchain-tutorial)

hope you enjo
y it!"	"https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/"	"2"	"1681158025.0"	"10"	"12huv4f"
146	"Open Source - OpenAI , Chroma , LangChain , HuggingFace sample"	"Python - upload your docs, persist embeddings in Chroma and 
build using huggingface transformers, delete, rebuild Chroma
 embeddings store, use LangChain agent for querying across t
he documents - https://github.com/ushakrishnan/SearchWithOpe
nAI"	"https://i.redd.it/v2amznhrvj1b1.jpg"	"4"	"1684816263.0"	"11"	"13pdymt"
147	"How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch"	"I created a semantic Q&A  bot for >13k recorded (webscraped,
 that is...) dreams using OpenAI embeddings APIs, Langchain 
and  Elasticsearch. It can answer queries like this one:  



'Find me all dreams containing animals, and provide me a li
st with their activities.'  


What  it returns are not only
 a proper, meaningful answer, but also  references to  relev
ant documents. Imagine for a moment how hard running  such a
 query with a traditional search engine would be! More or le
ss  impossible for 13k documents! First of all, there is no 
clearly defined  concept of what an 'animal' is, you'd end u
p specifying a long list of  actual animals in your input qu
ery. Second, once you identified them  you'd have to manuall
y derive what their activities are, the text search  engine 
is not able to do that for you.  


Of course, there is a lo
t  of vagueness and fuzziness in how such a system operates.
 So, there's a  tradeoff here: A semantic Q&A bot is very po
werful, but at the same  time you have to put a lot of (blin
d) trust in it. How can you know the  system does not 'forge
t' an important animal or document? Well, you  cannot. But t
hen again, would it be really better to do all of this  manu
ally? As usual, the answer depends on your requirements. I t
hink a  semantic Q&A bot is great if you're after convenienc
e and speed, but  not so good if your primary goals are corr
ectness and recall &  precision.  


I believe such semantic
 Q&A bots may have the  potential to become an important pie
ce in scientific research, as they  are at the intersection 
between qualitative (e.g. hermeneutic) and  quantitative res
earch. For example, a researcher who has a dataset of  trans
cribed interviews can easily test few hypotheses on them to 
get a  first summary on relevant points. Later on, she might
 decide to dive  into some of them.

[https://fabian-kostadi
nov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-wit
h-openai-embeddings-api-elasticsearch-and-langchain/](https:
//fabian-kostadinov.github.io/2023/06/12/how-i-created-a-sem
antic-qa-bot-with-openai-embeddings-api-elasticsearch-and-la
ngchain/)"	"https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/"	"2"	"1686674014.0"	"10"	"148jhur"
148	"Someone hacked my OpenAI account and used 4000$ worth of tokens"	"Someone just hacked my OpenAI account and used all the credi
ts. I don't know how this happended but It seems like some c
hrome extension might have read my ID and passwords then he 
just logged into my account and reset the hard limit of my a
ccount and started using it for their personal use. I just c
hecked my account and it says that I need to pay 4000$ which
 I haven't used.

I can't even afford to pay this much of am
ount. I've raised a request in OpenAI support. Hoping for a 
good outcome.

Why am I suspecting that hacker got my accoun
t not just an API Key

\- Hard limit was reset to 4000$ (Pre
viously it was much lower 500$ or even less)

\- Generated a
 new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in a
ny of my product

There should be a email verification or 2F
A while changing the hard limit of the account. I got the em
ail when my hard limit reached not when someone changed the 
hard limit of my account and used all the credits.

Just yes
terday, I got notification from Google chrome that there was
 one extension I've installed was found malicious which I've
 immeditely removed. I suspect it might have stolen the acco
unt ID and password do this malicious activity.

https://pre
view.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=we
bp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"	"https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/"	"18"	"1689851811.0"	"9"	"154o35w"
149	"What this sub is about and what are the differences to other subs"	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a su
breddit dedicated to serious discussion of artificial intell
igence, machine learning, natural language processing, and r
elated topics.

At r/OpenAIDev, we’re focused on your creati
ons/inspirations, quality content, breaking news, and advanc
ements in the field of AI. We want to foster a community whe
re people can come together to learn, discuss, and share the
ir knowledge and ideas.
We also want to **encourage others t
hat feel lost since AI moves so rapidly and job loss is the 
most discussed topic**. As a 20y+ experienced programmer mys
elf I see it as a helpful tool that speeds up my work every 
day. And I think everyone can take advantage of it and try t
o focus on the positive side when they know how. We try to s
hare that knowledge.

That being said, **we are not a meme s
ubreddit**, and we do not support low-effort posts or repost
s. Our focus is on substantive content that drives thoughtfu
l discussion and encourages learning and growth.

We welcome
 anyone who is curious about AI and passionate about explori
ng its potential to join our community. Whether you’re a sea
soned expert or just starting out, we hope you’ll find a hom
e here at r/OpenAIDev.

We also have a **Discord channel tha
t lets you use MidJourney at my costs** (The trial option ha
s been recently removed by MidJourney). Since I just play wi
th some prompts from time to time I don't mind to let everyo
ne use it for now until the monthly limit is reached:

https
://discord.gg/GmmCSMJqpb

So come on in, share your knowledg
e, ask your questions, and let’s explore the exciting world 
of AI together!

There are now some basic rules available as
 well as post and user flairs. **Please suggest new flairs i
f you have ideas**.

When there is **interest to become a mo
d of this sub** please send a DM with your experience and av
ailable time. Thanks."	"https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/"	"5"	"1681071204.0"	"10"	"12gua7o"
150	"5 things I wish I knew before building a GPT agent for log analysis"	"Three weeks ago I started developing a [ReAct Agent](https:/
/dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app
. A ReAct agent uses reasoning and logic combined with exter
nal tools to fulfill a task. The app - [LogPal.ai](https://l
ogpal.aio/)  \- lets you ask questions about the data in app
 log file files,  generating SQL queries and Javascript char
ts to analyze the data.

After a rough start, I’ve found a b
it of a groove. I wanted to share five things I wish I knew 
before developing a GPT-powered agent.

[A crude demo of Log
Pal.ai executing a ReAct agent to answer questions about a l
og file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84
b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A qui
ck demo showing the stark difference between GPT-3.5 and GPT
-4 when running a ReAct agent loop. ](https://reddit.com/lin
k/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a 
GPT-4 API limit increase, I needed to use the gpt-3.5-turbo 
 
 model instead. It sucked: poor code,  malformed JSON, and
 bizarre responses are the norm.

However, there’s a silver 
lining! gpt-3.5-turbo is great for adding chaos to your agen
t loop and seeing how resilient your code is to errors.

## 
2. Don’t use a framework

[A quick ReAct intro and demo of t
he ReAct agent in action within the OpenAI Playground. ](htt
ps://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I 
started with [Langchain](https://github.com/hwchase17/langch
ain), but I had a hell of time debugging and tweaking the fr
amework to suit my needs. Next, I shifted to [Boxcars](https
://github.com/BoxcarsAI/boxcars),  which has fewer abstracti
ons. While Boxcars was easier to understand, I  still strugg
led when things behaved differently than I’d expected.  Fina
lly, I said screw it…I’m not doing *that much*:

1. Sending 
and receiving text
2. Parsing text
3. Executing external too
ls

Why not write this logic myself? I’m not the type that l
ikes to  reinvent the wheel, so I came to this conclusion re
luctantly. However,  implementing the above didn’t seem *tha
t hard*, gave me ultimate flexibility, and forced me to lear
n how ReAct works.

I started with a [zero shot prompt](http
s://www.promptingguide.ai/techniques/zeroshot) that closely 
resembles the prompt in the [ReAct paper](https://arxiv.org/
abs/2210.03629) with one addition: asking for output in JSON
 format (more on that later…it’s far from bulletproof).

Thi
s roll-my-own strategy ended up paying huge dividends due to
 the  need for prompt-specific context, output formats, and 
error handling.

## 3. Prompts need specific handling

[ A q
uick demo of the SQL query generator prompt re-generating a 
correct SQL query after an initial error. ](https://reddit.c
om/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my a
pp has three prompts:

1. Zero shot ReAct prompt
2. SQL quer
y generator prompt
3. Javascript chart generator prompt

I’v
e found that each prompt needs customized context, output fo
rmats, and error handling for the agent to perform well.

##
# Customized context

There are 3 messaging-related parts of
 an [OpenAI API request](https://platform.openai.com/docs/gu
ides/gpt/chat-completions-api) you can tweak:

1. **System m
essage** \- the prompt text
2. **User messages** \- input fr
om the user (ex: “What’s the average response time?”)
3. **A
ssistant messages** \- completions from the API

The user an
d assistant messages are used to give the model more  contex
t. Unlike ChatGPT (which automatically builds context from p
rior  messages), you need to provide the history yourself wh
en using the API.  At first, I sent each prompt the same mes
sage history, which was every  user and assistant message in
 the chat history. However, with this  simple approach, I wo
uld frequently get bizarre responses to questions.  For exam
ple, I might ask “What is the request throughput?”, and rece
ive a  bizarre final answer like “There were no request erro
rs”.

After lots of experimentation (more later on how to it
erate quickly  on the message context), I found that sending
 prompt-specific context  generates the most helpful complet
ions:

1. **Zero shot** \- all messages (including tool outp
ut) after the last answered question.
2. **SQL query generat
or** \- previously generated  queries and the error output a
ssociated when executing each SQL  statement (if an error is
 present). The error output is critical for  helping the que
ry generator correct itself if an original query is  invalid
.
3. **Chart generator** \- similar to the SQL query generat
or, I send previously generated charts and any error output 
(if present).

While increasing the max context token size i
s frequently seen as *the path*  to better completions, I sa
w a correlation between increased context  length and off-tr
ack  completions. What I provided as context mattered a  lot
.

### Machine-readable output formats

The examples I start
ed from for a ReAct agent all asked for  completions in a pl
ain-text format. However, I found that building  regexes to 
parse the output was incredibly brittle due to the  non-dete
rministic behavior of the GPT models and the complexity of s
ome  completions, which include code snippets.

Here’s what’
s worked best for me:

1. **Zero shot ReAct prompt** \- JSON
. Continue below for how I handle malformed JSON (which happ
ens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-
flavored code blocks (triple backticks). I then use a regex 
to  parse out the code block. Remarkably, this has been very
 reliable.

### Error handling

I’ve found that the ReAct pr
ompt and the code generator prompts require two different ty
pes of error handling:

1. **Zero shot ReAct prompt** \- if 
the JSON is malformed  (this happens), I simply repeat the s
ame API request. More often than  not, this returns valid JS
ON on later attempts.
2. **SQL & Chart generator prompts** \
- I’ve yet to  see a malformed GitHub-flavored code block. I
nstead, the most common  issue is an invalid SQL query. I in
clude the generated SQL and error  output in the next API re
quest. This has been very effective at  correcting the outpu
t.

🤷 - I don’t know why JSON is frequently malformed but co
de blocks are not.

# 4. Increase your dev cycles with a rep
lay tool

[Showing the replay tool in action and forcing a h
allucination.](https://reddit.com/link/141l6oy/video/4ts2unz
yd84b1/player)

Learning to customize the context, output fo
rmats, and error handling  based on the prompt type came fro
m replicating my API requests in the [OpenAI Playground](htt
ps://platform.openai.com/playground).  I would copy and past
e the prompt, user messages, and assistant  messages into th
e playground, and then modify the inputs to see if I  could 
get a better response. The manual copy and pasting was a slo
w  process.

To move faster, I created an OpenAIReplay tool.
 When I  make an API request, I save the API request paramet
ers and the response  to a file. I can then load the file, m
odify the request parameters, and  replay the request. This 
tool has been huge for debugging as it’s much  faster than c
opying and pasting into the playground. My tool is  app-spec
ific, but it’s an easy thing to build. My tool works like th
is:

    # loads the message, writes the message's API reque
st params to a file, and opens the file in VS Code for editi
ng. replay = OpenAiReplay.from_message(message_id_or_object 
= Message.last) # ... make edits to the file ... replay.chat
! 

## 5. Use the stream API option

The GPT API is slower t
han what you see in ChatGPT ([source](https://community.open
ai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In 
my experience, it’s critical to use the [stream](https://pla
tform.openai.com/docs/api-reference/completions/create)  mod
e of the API versus waiting for a full completion to speed u
p dev  cycles (especially if you are generating long complet
ions):

1. I think stream is a bit faster to reach a complet
ion
2. Waiting for a full completion frequently results in A
PI timeout and 503 errors
3. You can quickly abort if it’s c
lear that the completion is going to be bad

In short: *coup
ling a replay tool with streaming completions is the fastest
 way to iterate on your agent.*

## TL;DR

If I was building
 [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use G
PT-4**. It’s far better than gpt-3.5-turboat reasoning and c
ode completion. gpt-3.5-turbois great for introducing chaos 
into your agent loop when testing.
2. **Not use an LLM app f
ramework.** Start with your language’s OpenAI API client and
 build from there.
3. **Plan on customizing prompt context, 
output formats, and error handling.** This is critical for g
etting good completions.
4. **Create/use an API replay tool*
*. Make it easy to replay API calls as it’s too slow to copy
 & paste these into the OpenAI playground.
5. **Stream compl
etions**. Use the stream mode of the API to speed up dev cyc
les. You can quickly abort if a completion is off the rails.
"	"https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/"	"4"	"1685984881.0"	"34"	"141l6oy"
151	"I made a dashboard to analyze OpenAI API usage"	""	"https://v.redd.it/vrz3h5bv8fya1"	"5"	"1683470617.0"	"14"	"13aqw5j"
152	"Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial"	"Hey there!   


I wanted to let you know that I just release
d a new video where I'm using some really cool technologies 
like Python, OpenAI API's, Chroma, and LangChain to answer q
uestions based on Youtube videos.

If you don't have the tim
e or patience to sit through a 3-hour lecture, no worries!  
 
My tutorial covers a solution!

I'm really excited to shar
e this with you and I think you'll find it super helpful.  

check out the video here: [**https://youtu.be/mhdOTLp-IjQ**]
(https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"	"https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/"	"0"	"1681481977.0"	"14"	"12lyu24"
153	"I built an app to help you get full visibility and control over your OpenAI costs."	""	"https://i.redd.it/te4jhjr3wf0b1.png"	"0"	"1684350106.0"	"13"	"13katfn"
154	"OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform"	"The GPT-3.5 Turbo model has been updated to 16k as of today 
and is priced at $0.003 per 1K input tokens and $0.004 per 1
K output tokens.

This new version is more steerable with th
e system message and includes a new capability: function cal
ling. By describing functions in your prompts, the model can
 intelligently output a JSON object containing arguments to 
call these functions based on user input — perfect for integ
rating with other tools or APIs.

OpenAI has also reduced th
e cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015
 per 1K input tokens), effective immediately.

On June 27th,
 the stable gpt-3.5-turbo will be automatically upgraded. 


#AI #OpenAI[Function calling and other API](https://openai.c
om/blog/function-calling-and-other-api-updates)"	"https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/"	"6"	"1686713922.0"	"11"	"148xhn3"
155	"Query current data - OpenAI Embeddings, Chroma and LangChain"	"Hi guys, I created a video on how to use Chroma in combinati
on with LangChain and the Wikipedia API to query your own da
ta.

Asking about your own data is the future of LLMs!   



Disclaimer: Own data can be everything which is text!

[http
s://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[ht
tps://github.com/grumpyp/chroma-langchain-tutorial](https://
github.com/grumpyp/chroma-langchain-tutorial)

hope you enjo
y it!"	"https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/"	"2"	"1681158025.0"	"11"	"12huv4f"
156	"Open Source - OpenAI , Chroma , LangChain , HuggingFace sample"	"Python - upload your docs, persist embeddings in Chroma and 
build using huggingface transformers, delete, rebuild Chroma
 embeddings store, use LangChain agent for querying across t
he documents - https://github.com/ushakrishnan/SearchWithOpe
nAI"	"https://i.redd.it/v2amznhrvj1b1.jpg"	"4"	"1684816263.0"	"10"	"13pdymt"
157	"How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch"	"I created a semantic Q&A  bot for >13k recorded (webscraped,
 that is...) dreams using OpenAI embeddings APIs, Langchain 
and  Elasticsearch. It can answer queries like this one:  



'Find me all dreams containing animals, and provide me a li
st with their activities.'  


What  it returns are not only
 a proper, meaningful answer, but also  references to  relev
ant documents. Imagine for a moment how hard running  such a
 query with a traditional search engine would be! More or le
ss  impossible for 13k documents! First of all, there is no 
clearly defined  concept of what an 'animal' is, you'd end u
p specifying a long list of  actual animals in your input qu
ery. Second, once you identified them  you'd have to manuall
y derive what their activities are, the text search  engine 
is not able to do that for you.  


Of course, there is a lo
t  of vagueness and fuzziness in how such a system operates.
 So, there's a  tradeoff here: A semantic Q&A bot is very po
werful, but at the same  time you have to put a lot of (blin
d) trust in it. How can you know the  system does not 'forge
t' an important animal or document? Well, you  cannot. But t
hen again, would it be really better to do all of this  manu
ally? As usual, the answer depends on your requirements. I t
hink a  semantic Q&A bot is great if you're after convenienc
e and speed, but  not so good if your primary goals are corr
ectness and recall &  precision.  


I believe such semantic
 Q&A bots may have the  potential to become an important pie
ce in scientific research, as they  are at the intersection 
between qualitative (e.g. hermeneutic) and  quantitative res
earch. For example, a researcher who has a dataset of  trans
cribed interviews can easily test few hypotheses on them to 
get a  first summary on relevant points. Later on, she might
 decide to dive  into some of them.

[https://fabian-kostadi
nov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-wit
h-openai-embeddings-api-elasticsearch-and-langchain/](https:
//fabian-kostadinov.github.io/2023/06/12/how-i-created-a-sem
antic-qa-bot-with-openai-embeddings-api-elasticsearch-and-la
ngchain/)"	"https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/"	"2"	"1686674014.0"	"11"	"148jhur"
158	"Someone hacked my OpenAI account and used 4000$ worth of tokens"	"Someone just hacked my OpenAI account and used all the credi
ts. I don't know how this happended but It seems like some c
hrome extension might have read my ID and passwords then he 
just logged into my account and reset the hard limit of my a
ccount and started using it for their personal use. I just c
hecked my account and it says that I need to pay 4000$ which
 I haven't used.

I can't even afford to pay this much of am
ount. I've raised a request in OpenAI support. Hoping for a 
good outcome.

Why am I suspecting that hacker got my accoun
t not just an API Key

\- Hard limit was reset to 4000$ (Pre
viously it was much lower 500$ or even less)

\- Generated a
 new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in a
ny of my product

There should be a email verification or 2F
A while changing the hard limit of the account. I got the em
ail when my hard limit reached not when someone changed the 
hard limit of my account and used all the credits.

Just yes
terday, I got notification from Google chrome that there was
 one extension I've installed was found malicious which I've
 immeditely removed. I suspect it might have stolen the acco
unt ID and password do this malicious activity.

https://pre
view.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=we
bp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"	"https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/"	"18"	"1689851811.0"	"12"	"154o35w"
159	"What this sub is about and what are the differences to other subs"	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a su
breddit dedicated to serious discussion of artificial intell
igence, machine learning, natural language processing, and r
elated topics.

At r/OpenAIDev, we’re focused on your creati
ons/inspirations, quality content, breaking news, and advanc
ements in the field of AI. We want to foster a community whe
re people can come together to learn, discuss, and share the
ir knowledge and ideas.
We also want to **encourage others t
hat feel lost since AI moves so rapidly and job loss is the 
most discussed topic**. As a 20y+ experienced programmer mys
elf I see it as a helpful tool that speeds up my work every 
day. And I think everyone can take advantage of it and try t
o focus on the positive side when they know how. We try to s
hare that knowledge.

That being said, **we are not a meme s
ubreddit**, and we do not support low-effort posts or repost
s. Our focus is on substantive content that drives thoughtfu
l discussion and encourages learning and growth.

We welcome
 anyone who is curious about AI and passionate about explori
ng its potential to join our community. Whether you’re a sea
soned expert or just starting out, we hope you’ll find a hom
e here at r/OpenAIDev.

We also have a **Discord channel tha
t lets you use MidJourney at my costs** (The trial option ha
s been recently removed by MidJourney). Since I just play wi
th some prompts from time to time I don't mind to let everyo
ne use it for now until the monthly limit is reached:

https
://discord.gg/GmmCSMJqpb

So come on in, share your knowledg
e, ask your questions, and let’s explore the exciting world 
of AI together!

There are now some basic rules available as
 well as post and user flairs. **Please suggest new flairs i
f you have ideas**.

When there is **interest to become a mo
d of this sub** please send a DM with your experience and av
ailable time. Thanks."	"https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/"	"5"	"1681071204.0"	"9"	"12gua7o"
160	"Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread."	""	"https://v.redd.it/jh5n48ghrhp51"	"29"	"1601125855.0"	"1178"	"j05rte"
161	"image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model"	""	"https://www.youtube.com/watch?v=FwXQ568_io0"	"46"	"1596625082.0"	"640"	"i437om"
162	"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment."	""	"https://i.redd.it/jczyjswj6pra1.png"	"61"	"1680539995.0"	"577"	"12apw9o"
163	"*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)"	""	"https://i.redd.it/dlw52klsvqt61.gif"	"53"	"1618670134.0"	"488"	"msruz1"
164	"Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI"	""	"https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion"	"102"	"1673349121.0"	"449"	"1087ady"
165	"OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)"	""	"https://www.youtube.com/watch?v=Lu56xVlZ40M"	"19"	"1571875085.0"	"340"	"dm86ay"
166	"GPT-4 Will Be 500x Smaller Than People Think - Here Is Why"	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://pre
view.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=web
p&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mil
l is buzzing around the release of GPT-4.

People are predic
ting the model will have 100 trillion parameters. That’s a *
trillion* with a “t”.

The often-used graphic above makes GP
T-3 look like a cute little breadcrumb that is about to have
 a live-ending encounter with a bowling ball.

Sure, OpenAI’
s new brainchild will certainly be mind-bending and language
 models have been getting bigger — fast!

But this time migh
t be different and it makes for a good opportunity to look a
t the research on scaling large language models (LLMs).

*Le
t’s go!*

Training 100 Trillion Parameters

The creation of 
GPT-3 was a marvelous feat of engineering. The training was 
done on 1024 GPUs, took 34 days, and cost $4.6M in compute a
lone \[1\].

Training a 100T parameter model on the same dat
a, using 10000 GPUs, would take 53 Years. To avoid overfitti
ng such a huge model the dataset would also need to be much(
!) larger.

So, where is this rumor coming from?

The Source
 Of The Rumor:

It turns out OpenAI itself might be the sour
ce of it.

In August 2021 the CEO of Cerebras told [wired](h
ttps://www.wired.com/story/cerebras-chip-cluster-neural-netw
orks-ai/): “From talking to OpenAI, GPT-4 will be about 100 
trillion parameters”.

A the time, that was most likely what
 they believed, but that was in 2021. So, basically forever 
ago when machine learning research is concerned.

Things hav
e changed a lot since then!

To understand what happened we 
first need to look at how people decide the number of parame
ters in a model.

Deciding The Number Of Parameters:

The en
ormous hunger for resources typically makes it feasible to t
rain an LLM only once.

In practice, the available compute b
udget (how much money will be spent, available GPUs, etc.) i
s known in advance. Before the training is started, research
ers need to accurately predict which hyperparameters will re
sult in the best model.

*But there’s a catch!*

Most resear
ch on neural networks is empirical. People typically run hun
dreds or even thousands of training experiments until they f
ind a good model with the right hyperparameters.

With LLMs 
we cannot do that. Training 200 GPT-3 models would set you b
ack roughly a billion dollars. Not even the deep-pocketed te
ch giants can spend this sort of money.

Therefore, research
ers need to work with what they have. Either they investigat
e the few big models that have been trained or they train sm
aller models in the hope of learning something about how to 
scale the big ones.

This process can very noisy and the com
munity’s understanding has evolved a lot over the last few y
ears.

What People Used To Think About Scaling LLMs

In 2020
, a team of researchers from OpenAI released a [paper](https
://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For N
eural Language Models”.

They observed a predictable decreas
e in training loss when increasing the model size over multi
ple orders of magnitude.

So far so good. But they made two 
other observations, which resulted in the model size balloon
ing rapidly.

1. To scale models optimally the parameters sh
ould scale quicker than the dataset size. To be exact, their
 analysis showed when increasing the model size 8x the datas
et only needs to be increased 5x.
2. Full model convergence 
is not compute-efficient. Given a fixed compute budget it is
 better to train large models shorter than to use a smaller 
model and train it longer.

Hence, it seemed as if the way t
o improve performance was to scale models faster than the da
taset size \[2\].

And that is what people did. The models g
ot larger and larger with GPT-3 (175B), [Gopher](https://arx
iv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](htt
ps://arxiv.org/pdf/2201.11990) (530B) just to name a few.

B
ut the bigger models failed to deliver on the promise.

*Rea
d on to learn why!*

What We know About Scaling Models Today


It turns out you need to scale training sets and models in
 equal proportions. So, every time the model size doubles, t
he number of training tokens should double as well.

This wa
s published in DeepMind’s 2022 [paper](https://arxiv.org/pdf
/2203.15556.pdf): “Training Compute-Optimal Large Language M
odels”

The researchers fitted over 400 language models rang
ing from 70M to over 16B parameters. To assess the impact of
 dataset size they also varied the number of training tokens
 from 5B-500B tokens.

The findings allowed them to estimate
 that a compute-optimal version of GPT-3 (175B) should be tr
ained on roughly 3.7T tokens. That is more than 10x the data
 that the original model was trained on.

To verify their re
sults they trained a fairly small model on vastly more data.
 Their model, called Chinchilla, has 70B parameters and is t
rained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 b
ut trained on almost 5x the data.

Chinchilla outperforms GP
T-3 and other much larger models by a fair margin \[3\].

Th
is was a great breakthrough!  
The model is not just better,
 but its smaller size makes inference cheaper and finetuning
 easier.

*So What Will Happen?*

What GPT-4 Might Look Like
:

To properly fit a model with 100T parameters, open OpenAI
 needs a dataset of roughly 700T tokens. Given 1M GPUs and u
sing the calculus from above, it would still take roughly 26
50 years to train the model \[1\].

So, here is what GPT-4 c
ould look like:

* Similar size to GPT-3, but trained optima
lly on 10x more data
* ​[Multi-modal](https://thealgorithmic
bridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outp
utting text, images, and sound
* Output conditioned on docum
ent chunks from a memory bank that the model has access to d
uring prediction \[4\]
* Doubled context size allows longer 
predictions before the model starts going off the rails​

Re
gardless of the exact design, it will be a solid step forwar
d. However, it will not be the 100T token human-brain-like A
GI that people make it out to be.

Whatever it will look lik
e, I am sure it will be amazing and we can all be excited ab
out the release.

Such exciting times to be alive!

As alway
s, I really enjoyed making this for you and I sincerely hope
 you found it useful!

Would you like to receive an article 
such as this one straight to your inbox every Thursday? Cons
ider signing up for **The Decoding** ⭕.

I send out a though
tful newsletter about ML research and the data economy once 
a week. No Spam. No Nonsense. [Click here to sign up!](https
://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M
. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthika
nti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro
, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Langua
ge Model Training on GPU Clusters Using Megatron-LM](https:/
/arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S.
 McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… 
& D. Amodei, [Scaling laws for neural language model](https:
//arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J
. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, 
E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T
. Hennigan, [Training Compute-Optimal Large Language Models]
(https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint a
rXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann
, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespi
au, B. Damoc, A. Clark, D. Casas, [Improving language models
 by retrieving from trillions of tokens](https://arxiv.org/a
bs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Van
couver"	"https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/"	"49"	"1674114980.0"	"331"	"10fw2df"
167	"Study Plan for Learning Data Science Over the Next 12 Months [D]"	"In this thread, I address a study plan for 2021.

In case yo
u're interested, I wrote a whole article about this topic: [
Study Plan for Learning Data Science Over the Next 12 Months
](https://www.datasource.ai/en/data-science-articles/study-p
lan-for-learning-data-science-over-the-next-12-months)

Let 
me know your thoughts on this.

&#x200B;

https://preview.re
dd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf
09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 a
nd it is time to make plans for next year, and one of the mo
st important plans and questions we must ask is what do we w
ant to study?, what do we want to enhance?, what changes do 
we want to make?, and what is the direction we are going to 
take (or continue) in our professional careers?.

Many of yo
u will be starting on the road to becoming a data scientist,
 in fact you may be evaluating it, since you have heard a lo
t about it, but you have some doubts, for example about the 
amount of job offers that may exist in this area, doubts abo
ut the technology itself, and about the path you should foll
ow, considering the wide range of options to learn.

I’m a b
eliever that we should learn from various sources, from vari
ous mentors, and from various formats. By sources I mean the
 various virtual platforms and face-to-face options that exi
st to study. By mentors I mean that it is always a good idea
 to learn from different points of view and learning from di
fferent teachers/mentors, and by formats I mean the choices 
between books, videos, classes, and other formats where the 
information is contained.

When we extract information from 
all these sources we reinforce the knowledge learned, but we
 always need a guide, and this post aims to give you some pr
actical insights and strategies in this regard.

To decide o
n sources, mentors and formats it is up to you to choose. It
 depends on your preferences and ease of learning: for examp
le, some people are better at learning from books, while oth
ers prefer to learn from videos. Some prefer to study on pla
tforms that are practical (following online code), and other
s prefer traditional platforms: like those at universities (
Master’s Degree, PHDs or MOOCs). Others prefer to pay for qu
ality content, while others prefer to look only for free mat
erial. That’s why I won’t give a specific recommendation in 
this post, but I’ll give you the whole picture: **a study pl
an**.

To start you should consider the time you’ll spend st
udying and the depth of learning you want to achieve, becaus
e if you find yourself without a job you could be available 
full time to study, which is a huge advantage. On the other 
hand, if you are working, you’ll have less time and you’ll h
ave to discipline yourself to be able to have the time avail
able in the evenings, mornings or weekends. Ultimately, the 
important thing is to meet the goal of learning and perhaps 
dedicating your career to this exciting area!

We will divid
e the year into quarters as follows

* **First Quarter**: Le
arning the Basics
* **Second Quarter**: Upgrading the Level:
 Intermediate Knowledge
* **Third Quarter**: A Real World Pr
oject — A Full-stack Project
* **Fourth Quarter**: Seeking O
pportunities While Maintaining Practice

# First Quarter: Le
arning the Basics

&#x200B;

https://preview.redd.it/u7t9bth
ket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7ac
f793259243aa5a60a8535f0a

If you want to be more rigorous yo
u can have start and end dates for this period of study of t
he bases. It could be something like: From January 1 to Marc
h 30, 2021 as deadline. During this period you will study th
e following:

## A programming language that you can apply t
o data science: Python or R.

We recommend Python due to the
 simple fact that approximately 80% of data science job offe
rs ask for knowledge in Python. That same percentage is main
tained with respect to the real projects you will find imple
mented in production. And we add the fact that Python is mul
tipurpose, so you won’t “waste” your time if at some point y
ou decide to focus on web development, for example, or deskt
op development. This would be the first topic to study in th
e first months of the year.

## Familiarize yourself with st
atistics and mathematics.

There is a big debate in the data
 science community about whether we need this foundation or 
not. I will write a post later on about this, but the realit
y is that you **DO** need it, but **ONLY** the basics (at le
ast in the beginning). And I want to clarify this point befo
re continuing.

We could say that data science is divided in
 two big fields: Research on one side and putting Machine Le
arning algorithms into production on the other side. If you 
later decide to focus on Research then you are going to need
 mathematics and statistics in depth (very in depth). If you
 are going to go for the practical part, the libraries will 
help you deal with most of it, under the hood. It should be 
noted that most job offers are in the practical part.

For b
oth cases, and in this first stage you will only need the ba
sics of:

* **Statistics (with Python and NumPy)**

1. Descr
iptive statistics
2. Inferential Statistics
3. Hypothesis te
sting
4. Probability

* **Mathematics (with Python and NumPy
)**

1. Linear Algebra (For example: SVD)
2. Multivariate Ca
lculus
3. Calculus (For example: gradient descent)

**Note**
: We recommend that you study Python first before seeing sta
tistics and mathematics, because the challenge is to impleme
nt these statistical and mathematical bases with Python. Don
’t look for theoretical tutorials that show only slides or s
tatistical and/or mathematical examples in Excel/Matlab/Octa
ve/SAS and other different to Python or R, it gets very bori
ng and impractical! You should choose a course, program or b
ook that teaches these concepts in a practical way and using
 Python. Remember that Python is what we finally use, so you
 need to choose well. **This advice is key so you don’t give
 up on this part, as it will be the most dense and difficult
**.

If you have these basics in the first three months, you
 will be ready to make a leap in your learning for the next 
three months.

# Second Quarter: Upgrading the Level: Interm
ediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vyn
et661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025
c39a8975faf4d64514df275

If you want to be more rigorous you
 can have start and end dates for this period of study at th
e intermediate level. It could be something like: From April
 1 to June 30, 2021 as deadline.

Now that you have a good f
oundation in programming, statistics and mathematics, it is 
time to move forward and learn about the great advantages th
at Python has for applying data analysis. For this stage you
 will be focused on:

## Data science Python stack

Python h
as the following libraries that you should study, know and p
ractice at this stage

* **Pandas**: for working with tabula
r data and make in-depth analysis
* **Matplotlib and Seaborn
**: for data visualization

Pandas is the in-facto library f
or data analysis, it is one of the most important (if not th
e most important) and powerful tools you should know and mas
ter during your career as a data scientist. Pandas will make
 it much easier for you to manipulate, cleanse and organize 
your data.

## Feature Engineering

Many times people don’t 
go deep into Feature Engineering, but if you want to have Ma
chine Learning models that make good predictions and improve
 your scores, spending some time on this subject is invaluab
le!

Feature engineering is the process of using domain know
ledge to extract features from raw data using data mining te
chniques. These features can be used to improve the performa
nce of machine learning algorithms. Feature engineering can 
be considered as applied machine learning itself. To achieve
 the goal of good feature engineering you must know the diff
erent techniques that exist, so it is a good idea to at leas
t study the main ones.

## Basic Models of Machine Learning


At the end of this stage you will start with the study of M
achine Learning. This is perhaps the most awaited moment! Th
is is where you start to learn about the different algorithm
s you can use, which particular problems you can solve and h
ow you can apply them in real life.

The Python library we r
ecommend you to start experimenting with ML is: scikit-learn
. *However it is a good idea that you can find tutorials whe
re they explain the implementation of the algorithms (at lea
st the simplest ones) from scratch with Python, since the li
brary could be a “****Black Box****” and you might not under
stand what is happening under the hood. If you learn how to 
implement them with Python, you can have a more solid founda
tion*.

If you implement the algorithms with Python (without
 a library), you will put into practice everything seen in t
he statistics, mathematics and Pandas part.

These are some 
recommendations of the algorithms that you should at least k
now in this initial stage

* **Supervised learning**
   * Si
mple Linear Regression
   * Multiple Linear Regression
   * 
K-nearest neighbors (KNN)
   * Logistic Regression
   * Deci
sion Trees
   * Random Forest
* **Unsupervised Learning**
  
 * K-Means
   * PCA

**Bonus**: if you have the time and you
 are within the time ranges, you can study these others

* *
*Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * L
ightGBM
   * CatBoost

**Note**: do not spend more than the 
3 months stipulated for this stage. Because you will be fall
ing behind and not complying with the study plan. We all hav
e shortcomings at this stage, it is normal, go ahead and the
n you can resume some concepts that did not understand in de
tail. The important thing is to have the basic knowledge and
 move forward!

*If at least you succeed to study the mentio
ned algorithms of supervised and unsupervised learning, you 
will have a very clear idea of what you will be able to do i
n the future*. So don’t worry about covering everything, rem
ember that it is a process, and ideally you should have some
 clearly established times so that you don’t get frustrated 
and feel you are advancing.

So far, here comes your “theore
tical” study of the basics of data science. Now we’ll contin
ue with the practical part!

# Third Quarter: A Real World P
roject — A Full-stack Project

&#x200B;

https://preview.red
d.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=6640
61b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more
 rigorous you can have start and end dates for this period o
f study at the intermediate level. It could be something lik
e: From July 1 to September 30, 2021 as deadline.

Now that 
you have a good foundation in programming, statistics, mathe
matics, data analysis and machine learning algorithms, it is
 time to move forward and put into practice all this knowled
ge.

Many of these suggestions may sound out of the box, but
 believe me they will make a big difference in your career a
s a data scientist.

## The first thing is to create your we
b presence:

* *Create a Github (or GitLab) account, and lea
rn Git*. Being able to manage different versions of your cod
e is important, you should have version control over them, n
ot to mention that having an active Github account is very v
aluable in demonstrating your true skills. On Github, you ca
n also set up your Jupyter Notebooks and make them public, s
o you can show off your skills as well. This is mine for exa
mple: [https://github.com/danielmoralesp](https://github.com
/danielmoralesp)
* *Learn the basics of web programming*. Th
e advantage is that you already have Python as a skill, so y
ou can learn Flask to create a simple web page. Or you can u
se a template engine like Github Pages, Ghost or Wordpress i
tself and create your online portfolio.
* *Buy a domain with
 your name*. Something like myname.com, myname.co, myname.de
v, etc. This is invaluable so you can have your CV online an
d update it with your projects. There you can make a big dif
ference, showing your projects, your Jupyter Notebooks and s
howing that you have the practical skills to execute project
s in this area. There are many front-end templates for you t
o purchase for free or for payment, and give it a more perso
nalized and pleasant look. Don’t use free sub-domains of Wor
dpress, Github or Wix, it looks very unprofessional, make yo
ur own. Here is mine for example: [https://www.danielmorales
.dev/](https://www.danielmorales.dev/)

## Choose a project 
you are passionate about and create a Machine Learning model
 around it.

The final goal of this third quarter is to crea
te **ONE** project, that you are passionate about, and that 
is **UNIQUE** among others. It turns out that there are many
 typical projects in the community, such as predicting the T
itanic Survivors, or predicting the price of Houses in Bosto
n. Those kinds of projects are good for learning, but not fo
r showing off as your **UNIQUE** projects.

If you are passi
onate about sports, try predicting the soccer results of you
r local league. If you are passionate about finance, try pre
dicting your country’s stock market prices. If you are passi
onate about marketing, try to find someone who has an e-comm
erce and implement a product recommendation algorithm and up
load it to production. If you are passionate about business:
 make a predictor of the best business ideas for 2021 :)

As
 you can see, you are limited by your passions and your imag
ination. ***In fact,*** ***those are the two keys for you to
 do this project: Passion and Imagination***.

However don’t
 expect to make money from it, you are in a learning stage, 
you need that algorithm to be deployed in production, make a
n API in Flask with it, and explain in your website how you 
did it and how people can access it. This is the moment to s
hine, and at the same time it’s the moment of the greatest l
earning.

You will most likely face obstacles, if your algor
ithm gives 60% of Accuracy after a huge optimization effort,
 it doesn’t matter, finish the whole process, deploy it to p
roduction, try to get a friend or family member to use it, a
nd that will be the goal achieved for this stage: **Make a F
ull-stack Machine Learning project.**

By full-stack I mean 
that you did all the following steps:

* You got the data fr
om somewhere (scrapping, open data or API)
* You did a data 
analysis
* You cleaned and transformed the data
* You create
d Machine Learning Models
* You deployed the best model to p
roduction for other people to use.

This does not mean that 
this whole process is what you will always do in your daily 
job, but it does mean that you will know every part of the p
ipeline that is needed for a data science project for a comp
any. You will have a unique perspective!

# Fourth Quarter: 
Seeking Opportunities While Maintaining Practice

&#x200B;


https://preview.redd.it/qd0osystet661.png?width=1056&format=
png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If
 you want to be more rigorous you can have start and end dat
es for this period of study at the final level. It could be 
something like: From October 1 to December 31, 2021 as deadl
ine.

Now you have theoretical and practical knowledge. You 
have implemented a model in production. The next step depend
s on you and your personality. Let’s say you are an entrepre
neur, and you have the vision to create something new from s
omething you discovered or saw an opportunity to do business
 with this discipline, so it’s time to start planning how to
 do it. If that’s the case, obviously this post won’t cover 
that process, but you should know what the steps might be (o
r start figuring them out).

But if you are one of those who
 want to get a job as a data scientist, here is my advice.


## Getting a job as a data scientist

>*“You’re not going to
 get a job as fast as you think, if you keep thinking the sa
me way”.Author*

It turns out that all people who start out 
as data scientists imagine themselves working for the big co
mpanies in their country or region. Or even remote. It turns
 out that if you aspire to work for a large company like dat
a scientist you will be frustrated by the years of experienc
e they ask for (3 or more years) and the skills they request
.

Large companies don’t hire Juniors (or very few do), prec
isely because they are already large companies. They have th
e financial muscle to demand experience and skills and can p
ay a commensurate salary (although this is not always the ca
se). The point is that if you focus there you’re going to ge
t frustrated!

Here we must return to the following advise: 
***“You need creativity to get a job in data science”***.

L
ike everything else in life we have to start at different st
eps, in this case, from the beginning. Here are the scenario
s

* *If you are working in a company and in a non-engineeri
ng role you must demonstrate your new skills to the company 
you are working for*. If you are working in the customer ser
vice area, you should apply it to your work, and do for exam
ple, detailed analysis of your calls, conversion rates, stor
e data and make predictions about it! If you can have data f
rom your colleagues, you could try to predict their sales! T
his may sound funny, but it’s about how creatively you can a
pply data science to your current work and how to show your 
bosses how valuable it is and **EVANGELIZE** them about the 
benefits of implementation. You’ll be noticed and they could
 certainly create a new data related department or job. And 
you already have the knowledge and experience. The key word 
here is **Evangelize**. Many companies and entrepreneurs are
 just beginning to see the power of this discipline, and it 
is your task to nurture that reality.
* *If you are working 
in an area related to engineering, but that is not data scie
nce*. Here the same applies as the previous example, but you
 have some advantages, and that is that you could access the
 company’s data, and you could use it for the benefit of the
 company, making analyses and/or predictions about it, and a
gain **EVANGELIZING** your bosses your new skills and the be
nefits of data science.
* *If you are unemployed (or do not 
want, or do not feel comfortable following the two examples 
above)*, you can start looking outside, and what I recommend
 is that you look for technology companies and / or startups
 where they are just forming the first teams and are paying 
some salary, or even have options shares of the company. Obv
iously here the salaries will not be exorbitant, and the wor
king hours could be longer, but remember that you are in the
 learning and practice stage (just in the first step), so yo
u can not demand too much, you must land your expectations a
nd fit that reality, and stop pretending to be paid $ 10,000
 a month at this stage. But, depending of your country $1.00
0 USD could be something very interesting to start this new 
career. Remember, you are a Junior at this stage.

***The co
nclusion is: don’t waste your time looking at and/or applyin
g to offers from big companies, because you will get frustra
ted. Be creative, and look for opportunities in smaller or n
ewly created companies***.

## Learning never stops

While y
ou are in that process of looking for a job or an opportunit
y, which could take half of your time (50% looking for oppor
tunities, 50% staying in practice), you have to keep learnin
g, you should advance to concepts such as Deep Learning, Dat
a Engineer or other topics that you feel were left loose fro
m the past stages or focus on the topics that you are passio
nate about within this group of disciplines in data science.


At the same time you can choose a second project, and spen
d some time running it from end-to-end, and thus increase yo
ur portfolio and your experience. If this is the case, try t
o find a completely different project: if the first one was 
done with Machine Learning, let this second one be done with
 Deep learning. If the first one was deployed to a web page,
 that this second one is deployed to a mobile platform. Reme
mber, creativity is the key!

# Conclusion

We are at an ide
al time to plan for 2021, and if this is the path you want t
o take, start looking for the platforms and media you want t
o study on. Get to work and don’t miss this opportunity to b
ecome a data scientist in 2021!

Note: we are building a pri
vate community in Slack of data scientist, if you want to jo
in us write to the email: [support@datasource.ai](mailto:sup
port@datasource.ai)

I hope you enjoyed this reading! you ca
n follow me on [twitter](https://twitter.com/daniel_moralesp
) or [linkedin](https://www.linkedin.com/in/danielmorales1/)


Thank you for reading!"	"https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/"	"59"	"1608676284.0"	"300"	"kifqtc"
168	"Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training."	"You can download or review the source code at [https://githu
b.com/albertnadal/Tensar](https://github.com/albertnadal/Ten
sar)

Here is attached a video/demo of the application durin
g the training. 

[CNN implemented in C++\/OpenGL trained wi
th the MNIST dataset](https://reddit.com/link/if7n2p/video/3
3k3qwhhesi51/player)

You can find the original video in my 
youtube channel ([https://youtu.be/oCElhUzadaA](https://yout
u.be/oCElhUzadaA)), so I encourage you to subscribe to the c
hannel if you are interested in future implementations relat
ed to ML and AI. I hope you find it useful to better underst
and how CNN's works. Thank you!

&#x200B;

Albert,"	"https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/"	"9"	"1598205014.0"	"277"	"if7n2p"
169	"Almost no one knows how easily you can optimize your AI models"	"The situation is fairly simple. **Your model could run 10 ti
mes faster** by adding a few lines to your code, but you wer
en't aware of it. Let me expand on that.

1. AI applications
 are multiplying like mushrooms, which is awesome
2. As a re
sult, more and more people are turning to the dark side, joi
ning the AI world, as I did
3. The problem? Developers focus
 only on AI, cleaning up datasets and training their models.
 Almost no one has a background in hardware, compilers, comp
uting, cloud, etc
4. The result? Developers spend a lot of h
ours improving the accuracy and performance of their softwar
e, and all their hard work risks being undone by the wrong c
hoice of hardware-software coupling

This problem bothered m
e for a long time, so with a couple of buddies at [Nebuly](h
ttps://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot 
of energy into an **open-source library** called **nebullvm*
* to make DL compiler technology accessible to any developer
, even for those who know nothing about hardware, as I did.


How does it work? It **speeds up your DL models by \~5-20x*
* by testing the best DL compilers out there and selecting t
he optimal one to best couple your AI model with your machin
e (GPU, CPU, etc.). All this in just a few lines of code.

T
he library is open source and you can find it here [https://
github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/
nebullvm).

Please leave a star on GitHub for the hard work 
in building the library :) It's a simple act for you, a big 
smile for us. Thank you, and don't hesitate to contribute to
 the library!"	"https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/"	"38"	"1645521383.0"	"271"	"syj7vx"
170	"Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread."	""	"https://v.redd.it/jh5n48ghrhp51"	"29"	"1601125855.0"	"1183"	"j05rte"
171	"image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model"	""	"https://www.youtube.com/watch?v=FwXQ568_io0"	"46"	"1596625082.0"	"635"	"i437om"
172	"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment."	""	"https://i.redd.it/jczyjswj6pra1.png"	"61"	"1680539995.0"	"575"	"12apw9o"
173	"*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)"	""	"https://i.redd.it/dlw52klsvqt61.gif"	"53"	"1618670134.0"	"487"	"msruz1"
174	"Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI"	""	"https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion"	"102"	"1673349121.0"	"450"	"1087ady"
175	"OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)"	""	"https://www.youtube.com/watch?v=Lu56xVlZ40M"	"19"	"1571875085.0"	"341"	"dm86ay"
176	"GPT-4 Will Be 500x Smaller Than People Think - Here Is Why"	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://pre
view.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=web
p&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mil
l is buzzing around the release of GPT-4.

People are predic
ting the model will have 100 trillion parameters. That’s a *
trillion* with a “t”.

The often-used graphic above makes GP
T-3 look like a cute little breadcrumb that is about to have
 a live-ending encounter with a bowling ball.

Sure, OpenAI’
s new brainchild will certainly be mind-bending and language
 models have been getting bigger — fast!

But this time migh
t be different and it makes for a good opportunity to look a
t the research on scaling large language models (LLMs).

*Le
t’s go!*

Training 100 Trillion Parameters

The creation of 
GPT-3 was a marvelous feat of engineering. The training was 
done on 1024 GPUs, took 34 days, and cost $4.6M in compute a
lone \[1\].

Training a 100T parameter model on the same dat
a, using 10000 GPUs, would take 53 Years. To avoid overfitti
ng such a huge model the dataset would also need to be much(
!) larger.

So, where is this rumor coming from?

The Source
 Of The Rumor:

It turns out OpenAI itself might be the sour
ce of it.

In August 2021 the CEO of Cerebras told [wired](h
ttps://www.wired.com/story/cerebras-chip-cluster-neural-netw
orks-ai/): “From talking to OpenAI, GPT-4 will be about 100 
trillion parameters”.

A the time, that was most likely what
 they believed, but that was in 2021. So, basically forever 
ago when machine learning research is concerned.

Things hav
e changed a lot since then!

To understand what happened we 
first need to look at how people decide the number of parame
ters in a model.

Deciding The Number Of Parameters:

The en
ormous hunger for resources typically makes it feasible to t
rain an LLM only once.

In practice, the available compute b
udget (how much money will be spent, available GPUs, etc.) i
s known in advance. Before the training is started, research
ers need to accurately predict which hyperparameters will re
sult in the best model.

*But there’s a catch!*

Most resear
ch on neural networks is empirical. People typically run hun
dreds or even thousands of training experiments until they f
ind a good model with the right hyperparameters.

With LLMs 
we cannot do that. Training 200 GPT-3 models would set you b
ack roughly a billion dollars. Not even the deep-pocketed te
ch giants can spend this sort of money.

Therefore, research
ers need to work with what they have. Either they investigat
e the few big models that have been trained or they train sm
aller models in the hope of learning something about how to 
scale the big ones.

This process can very noisy and the com
munity’s understanding has evolved a lot over the last few y
ears.

What People Used To Think About Scaling LLMs

In 2020
, a team of researchers from OpenAI released a [paper](https
://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For N
eural Language Models”.

They observed a predictable decreas
e in training loss when increasing the model size over multi
ple orders of magnitude.

So far so good. But they made two 
other observations, which resulted in the model size balloon
ing rapidly.

1. To scale models optimally the parameters sh
ould scale quicker than the dataset size. To be exact, their
 analysis showed when increasing the model size 8x the datas
et only needs to be increased 5x.
2. Full model convergence 
is not compute-efficient. Given a fixed compute budget it is
 better to train large models shorter than to use a smaller 
model and train it longer.

Hence, it seemed as if the way t
o improve performance was to scale models faster than the da
taset size \[2\].

And that is what people did. The models g
ot larger and larger with GPT-3 (175B), [Gopher](https://arx
iv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](htt
ps://arxiv.org/pdf/2201.11990) (530B) just to name a few.

B
ut the bigger models failed to deliver on the promise.

*Rea
d on to learn why!*

What We know About Scaling Models Today


It turns out you need to scale training sets and models in
 equal proportions. So, every time the model size doubles, t
he number of training tokens should double as well.

This wa
s published in DeepMind’s 2022 [paper](https://arxiv.org/pdf
/2203.15556.pdf): “Training Compute-Optimal Large Language M
odels”

The researchers fitted over 400 language models rang
ing from 70M to over 16B parameters. To assess the impact of
 dataset size they also varied the number of training tokens
 from 5B-500B tokens.

The findings allowed them to estimate
 that a compute-optimal version of GPT-3 (175B) should be tr
ained on roughly 3.7T tokens. That is more than 10x the data
 that the original model was trained on.

To verify their re
sults they trained a fairly small model on vastly more data.
 Their model, called Chinchilla, has 70B parameters and is t
rained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 b
ut trained on almost 5x the data.

Chinchilla outperforms GP
T-3 and other much larger models by a fair margin \[3\].

Th
is was a great breakthrough!  
The model is not just better,
 but its smaller size makes inference cheaper and finetuning
 easier.

*So What Will Happen?*

What GPT-4 Might Look Like
:

To properly fit a model with 100T parameters, open OpenAI
 needs a dataset of roughly 700T tokens. Given 1M GPUs and u
sing the calculus from above, it would still take roughly 26
50 years to train the model \[1\].

So, here is what GPT-4 c
ould look like:

* Similar size to GPT-3, but trained optima
lly on 10x more data
* ​[Multi-modal](https://thealgorithmic
bridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outp
utting text, images, and sound
* Output conditioned on docum
ent chunks from a memory bank that the model has access to d
uring prediction \[4\]
* Doubled context size allows longer 
predictions before the model starts going off the rails​

Re
gardless of the exact design, it will be a solid step forwar
d. However, it will not be the 100T token human-brain-like A
GI that people make it out to be.

Whatever it will look lik
e, I am sure it will be amazing and we can all be excited ab
out the release.

Such exciting times to be alive!

As alway
s, I really enjoyed making this for you and I sincerely hope
 you found it useful!

Would you like to receive an article 
such as this one straight to your inbox every Thursday? Cons
ider signing up for **The Decoding** ⭕.

I send out a though
tful newsletter about ML research and the data economy once 
a week. No Spam. No Nonsense. [Click here to sign up!](https
://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M
. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthika
nti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro
, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Langua
ge Model Training on GPU Clusters Using Megatron-LM](https:/
/arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S.
 McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… 
& D. Amodei, [Scaling laws for neural language model](https:
//arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J
. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, 
E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T
. Hennigan, [Training Compute-Optimal Large Language Models]
(https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint a
rXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann
, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespi
au, B. Damoc, A. Clark, D. Casas, [Improving language models
 by retrieving from trillions of tokens](https://arxiv.org/a
bs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Van
couver"	"https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/"	"49"	"1674114980.0"	"325"	"10fw2df"
177	"Study Plan for Learning Data Science Over the Next 12 Months [D]"	"In this thread, I address a study plan for 2021.

In case yo
u're interested, I wrote a whole article about this topic: [
Study Plan for Learning Data Science Over the Next 12 Months
](https://www.datasource.ai/en/data-science-articles/study-p
lan-for-learning-data-science-over-the-next-12-months)

Let 
me know your thoughts on this.

&#x200B;

https://preview.re
dd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf
09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 a
nd it is time to make plans for next year, and one of the mo
st important plans and questions we must ask is what do we w
ant to study?, what do we want to enhance?, what changes do 
we want to make?, and what is the direction we are going to 
take (or continue) in our professional careers?.

Many of yo
u will be starting on the road to becoming a data scientist,
 in fact you may be evaluating it, since you have heard a lo
t about it, but you have some doubts, for example about the 
amount of job offers that may exist in this area, doubts abo
ut the technology itself, and about the path you should foll
ow, considering the wide range of options to learn.

I’m a b
eliever that we should learn from various sources, from vari
ous mentors, and from various formats. By sources I mean the
 various virtual platforms and face-to-face options that exi
st to study. By mentors I mean that it is always a good idea
 to learn from different points of view and learning from di
fferent teachers/mentors, and by formats I mean the choices 
between books, videos, classes, and other formats where the 
information is contained.

When we extract information from 
all these sources we reinforce the knowledge learned, but we
 always need a guide, and this post aims to give you some pr
actical insights and strategies in this regard.

To decide o
n sources, mentors and formats it is up to you to choose. It
 depends on your preferences and ease of learning: for examp
le, some people are better at learning from books, while oth
ers prefer to learn from videos. Some prefer to study on pla
tforms that are practical (following online code), and other
s prefer traditional platforms: like those at universities (
Master’s Degree, PHDs or MOOCs). Others prefer to pay for qu
ality content, while others prefer to look only for free mat
erial. That’s why I won’t give a specific recommendation in 
this post, but I’ll give you the whole picture: **a study pl
an**.

To start you should consider the time you’ll spend st
udying and the depth of learning you want to achieve, becaus
e if you find yourself without a job you could be available 
full time to study, which is a huge advantage. On the other 
hand, if you are working, you’ll have less time and you’ll h
ave to discipline yourself to be able to have the time avail
able in the evenings, mornings or weekends. Ultimately, the 
important thing is to meet the goal of learning and perhaps 
dedicating your career to this exciting area!

We will divid
e the year into quarters as follows

* **First Quarter**: Le
arning the Basics
* **Second Quarter**: Upgrading the Level:
 Intermediate Knowledge
* **Third Quarter**: A Real World Pr
oject — A Full-stack Project
* **Fourth Quarter**: Seeking O
pportunities While Maintaining Practice

# First Quarter: Le
arning the Basics

&#x200B;

https://preview.redd.it/u7t9bth
ket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7ac
f793259243aa5a60a8535f0a

If you want to be more rigorous yo
u can have start and end dates for this period of study of t
he bases. It could be something like: From January 1 to Marc
h 30, 2021 as deadline. During this period you will study th
e following:

## A programming language that you can apply t
o data science: Python or R.

We recommend Python due to the
 simple fact that approximately 80% of data science job offe
rs ask for knowledge in Python. That same percentage is main
tained with respect to the real projects you will find imple
mented in production. And we add the fact that Python is mul
tipurpose, so you won’t “waste” your time if at some point y
ou decide to focus on web development, for example, or deskt
op development. This would be the first topic to study in th
e first months of the year.

## Familiarize yourself with st
atistics and mathematics.

There is a big debate in the data
 science community about whether we need this foundation or 
not. I will write a post later on about this, but the realit
y is that you **DO** need it, but **ONLY** the basics (at le
ast in the beginning). And I want to clarify this point befo
re continuing.

We could say that data science is divided in
 two big fields: Research on one side and putting Machine Le
arning algorithms into production on the other side. If you 
later decide to focus on Research then you are going to need
 mathematics and statistics in depth (very in depth). If you
 are going to go for the practical part, the libraries will 
help you deal with most of it, under the hood. It should be 
noted that most job offers are in the practical part.

For b
oth cases, and in this first stage you will only need the ba
sics of:

* **Statistics (with Python and NumPy)**

1. Descr
iptive statistics
2. Inferential Statistics
3. Hypothesis te
sting
4. Probability

* **Mathematics (with Python and NumPy
)**

1. Linear Algebra (For example: SVD)
2. Multivariate Ca
lculus
3. Calculus (For example: gradient descent)

**Note**
: We recommend that you study Python first before seeing sta
tistics and mathematics, because the challenge is to impleme
nt these statistical and mathematical bases with Python. Don
’t look for theoretical tutorials that show only slides or s
tatistical and/or mathematical examples in Excel/Matlab/Octa
ve/SAS and other different to Python or R, it gets very bori
ng and impractical! You should choose a course, program or b
ook that teaches these concepts in a practical way and using
 Python. Remember that Python is what we finally use, so you
 need to choose well. **This advice is key so you don’t give
 up on this part, as it will be the most dense and difficult
**.

If you have these basics in the first three months, you
 will be ready to make a leap in your learning for the next 
three months.

# Second Quarter: Upgrading the Level: Interm
ediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vyn
et661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025
c39a8975faf4d64514df275

If you want to be more rigorous you
 can have start and end dates for this period of study at th
e intermediate level. It could be something like: From April
 1 to June 30, 2021 as deadline.

Now that you have a good f
oundation in programming, statistics and mathematics, it is 
time to move forward and learn about the great advantages th
at Python has for applying data analysis. For this stage you
 will be focused on:

## Data science Python stack

Python h
as the following libraries that you should study, know and p
ractice at this stage

* **Pandas**: for working with tabula
r data and make in-depth analysis
* **Matplotlib and Seaborn
**: for data visualization

Pandas is the in-facto library f
or data analysis, it is one of the most important (if not th
e most important) and powerful tools you should know and mas
ter during your career as a data scientist. Pandas will make
 it much easier for you to manipulate, cleanse and organize 
your data.

## Feature Engineering

Many times people don’t 
go deep into Feature Engineering, but if you want to have Ma
chine Learning models that make good predictions and improve
 your scores, spending some time on this subject is invaluab
le!

Feature engineering is the process of using domain know
ledge to extract features from raw data using data mining te
chniques. These features can be used to improve the performa
nce of machine learning algorithms. Feature engineering can 
be considered as applied machine learning itself. To achieve
 the goal of good feature engineering you must know the diff
erent techniques that exist, so it is a good idea to at leas
t study the main ones.

## Basic Models of Machine Learning


At the end of this stage you will start with the study of M
achine Learning. This is perhaps the most awaited moment! Th
is is where you start to learn about the different algorithm
s you can use, which particular problems you can solve and h
ow you can apply them in real life.

The Python library we r
ecommend you to start experimenting with ML is: scikit-learn
. *However it is a good idea that you can find tutorials whe
re they explain the implementation of the algorithms (at lea
st the simplest ones) from scratch with Python, since the li
brary could be a “****Black Box****” and you might not under
stand what is happening under the hood. If you learn how to 
implement them with Python, you can have a more solid founda
tion*.

If you implement the algorithms with Python (without
 a library), you will put into practice everything seen in t
he statistics, mathematics and Pandas part.

These are some 
recommendations of the algorithms that you should at least k
now in this initial stage

* **Supervised learning**
   * Si
mple Linear Regression
   * Multiple Linear Regression
   * 
K-nearest neighbors (KNN)
   * Logistic Regression
   * Deci
sion Trees
   * Random Forest
* **Unsupervised Learning**
  
 * K-Means
   * PCA

**Bonus**: if you have the time and you
 are within the time ranges, you can study these others

* *
*Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * L
ightGBM
   * CatBoost

**Note**: do not spend more than the 
3 months stipulated for this stage. Because you will be fall
ing behind and not complying with the study plan. We all hav
e shortcomings at this stage, it is normal, go ahead and the
n you can resume some concepts that did not understand in de
tail. The important thing is to have the basic knowledge and
 move forward!

*If at least you succeed to study the mentio
ned algorithms of supervised and unsupervised learning, you 
will have a very clear idea of what you will be able to do i
n the future*. So don’t worry about covering everything, rem
ember that it is a process, and ideally you should have some
 clearly established times so that you don’t get frustrated 
and feel you are advancing.

So far, here comes your “theore
tical” study of the basics of data science. Now we’ll contin
ue with the practical part!

# Third Quarter: A Real World P
roject — A Full-stack Project

&#x200B;

https://preview.red
d.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=6640
61b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more
 rigorous you can have start and end dates for this period o
f study at the intermediate level. It could be something lik
e: From July 1 to September 30, 2021 as deadline.

Now that 
you have a good foundation in programming, statistics, mathe
matics, data analysis and machine learning algorithms, it is
 time to move forward and put into practice all this knowled
ge.

Many of these suggestions may sound out of the box, but
 believe me they will make a big difference in your career a
s a data scientist.

## The first thing is to create your we
b presence:

* *Create a Github (or GitLab) account, and lea
rn Git*. Being able to manage different versions of your cod
e is important, you should have version control over them, n
ot to mention that having an active Github account is very v
aluable in demonstrating your true skills. On Github, you ca
n also set up your Jupyter Notebooks and make them public, s
o you can show off your skills as well. This is mine for exa
mple: [https://github.com/danielmoralesp](https://github.com
/danielmoralesp)
* *Learn the basics of web programming*. Th
e advantage is that you already have Python as a skill, so y
ou can learn Flask to create a simple web page. Or you can u
se a template engine like Github Pages, Ghost or Wordpress i
tself and create your online portfolio.
* *Buy a domain with
 your name*. Something like myname.com, myname.co, myname.de
v, etc. This is invaluable so you can have your CV online an
d update it with your projects. There you can make a big dif
ference, showing your projects, your Jupyter Notebooks and s
howing that you have the practical skills to execute project
s in this area. There are many front-end templates for you t
o purchase for free or for payment, and give it a more perso
nalized and pleasant look. Don’t use free sub-domains of Wor
dpress, Github or Wix, it looks very unprofessional, make yo
ur own. Here is mine for example: [https://www.danielmorales
.dev/](https://www.danielmorales.dev/)

## Choose a project 
you are passionate about and create a Machine Learning model
 around it.

The final goal of this third quarter is to crea
te **ONE** project, that you are passionate about, and that 
is **UNIQUE** among others. It turns out that there are many
 typical projects in the community, such as predicting the T
itanic Survivors, or predicting the price of Houses in Bosto
n. Those kinds of projects are good for learning, but not fo
r showing off as your **UNIQUE** projects.

If you are passi
onate about sports, try predicting the soccer results of you
r local league. If you are passionate about finance, try pre
dicting your country’s stock market prices. If you are passi
onate about marketing, try to find someone who has an e-comm
erce and implement a product recommendation algorithm and up
load it to production. If you are passionate about business:
 make a predictor of the best business ideas for 2021 :)

As
 you can see, you are limited by your passions and your imag
ination. ***In fact,*** ***those are the two keys for you to
 do this project: Passion and Imagination***.

However don’t
 expect to make money from it, you are in a learning stage, 
you need that algorithm to be deployed in production, make a
n API in Flask with it, and explain in your website how you 
did it and how people can access it. This is the moment to s
hine, and at the same time it’s the moment of the greatest l
earning.

You will most likely face obstacles, if your algor
ithm gives 60% of Accuracy after a huge optimization effort,
 it doesn’t matter, finish the whole process, deploy it to p
roduction, try to get a friend or family member to use it, a
nd that will be the goal achieved for this stage: **Make a F
ull-stack Machine Learning project.**

By full-stack I mean 
that you did all the following steps:

* You got the data fr
om somewhere (scrapping, open data or API)
* You did a data 
analysis
* You cleaned and transformed the data
* You create
d Machine Learning Models
* You deployed the best model to p
roduction for other people to use.

This does not mean that 
this whole process is what you will always do in your daily 
job, but it does mean that you will know every part of the p
ipeline that is needed for a data science project for a comp
any. You will have a unique perspective!

# Fourth Quarter: 
Seeking Opportunities While Maintaining Practice

&#x200B;


https://preview.redd.it/qd0osystet661.png?width=1056&format=
png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If
 you want to be more rigorous you can have start and end dat
es for this period of study at the final level. It could be 
something like: From October 1 to December 31, 2021 as deadl
ine.

Now you have theoretical and practical knowledge. You 
have implemented a model in production. The next step depend
s on you and your personality. Let’s say you are an entrepre
neur, and you have the vision to create something new from s
omething you discovered or saw an opportunity to do business
 with this discipline, so it’s time to start planning how to
 do it. If that’s the case, obviously this post won’t cover 
that process, but you should know what the steps might be (o
r start figuring them out).

But if you are one of those who
 want to get a job as a data scientist, here is my advice.


## Getting a job as a data scientist

>*“You’re not going to
 get a job as fast as you think, if you keep thinking the sa
me way”.Author*

It turns out that all people who start out 
as data scientists imagine themselves working for the big co
mpanies in their country or region. Or even remote. It turns
 out that if you aspire to work for a large company like dat
a scientist you will be frustrated by the years of experienc
e they ask for (3 or more years) and the skills they request
.

Large companies don’t hire Juniors (or very few do), prec
isely because they are already large companies. They have th
e financial muscle to demand experience and skills and can p
ay a commensurate salary (although this is not always the ca
se). The point is that if you focus there you’re going to ge
t frustrated!

Here we must return to the following advise: 
***“You need creativity to get a job in data science”***.

L
ike everything else in life we have to start at different st
eps, in this case, from the beginning. Here are the scenario
s

* *If you are working in a company and in a non-engineeri
ng role you must demonstrate your new skills to the company 
you are working for*. If you are working in the customer ser
vice area, you should apply it to your work, and do for exam
ple, detailed analysis of your calls, conversion rates, stor
e data and make predictions about it! If you can have data f
rom your colleagues, you could try to predict their sales! T
his may sound funny, but it’s about how creatively you can a
pply data science to your current work and how to show your 
bosses how valuable it is and **EVANGELIZE** them about the 
benefits of implementation. You’ll be noticed and they could
 certainly create a new data related department or job. And 
you already have the knowledge and experience. The key word 
here is **Evangelize**. Many companies and entrepreneurs are
 just beginning to see the power of this discipline, and it 
is your task to nurture that reality.
* *If you are working 
in an area related to engineering, but that is not data scie
nce*. Here the same applies as the previous example, but you
 have some advantages, and that is that you could access the
 company’s data, and you could use it for the benefit of the
 company, making analyses and/or predictions about it, and a
gain **EVANGELIZING** your bosses your new skills and the be
nefits of data science.
* *If you are unemployed (or do not 
want, or do not feel comfortable following the two examples 
above)*, you can start looking outside, and what I recommend
 is that you look for technology companies and / or startups
 where they are just forming the first teams and are paying 
some salary, or even have options shares of the company. Obv
iously here the salaries will not be exorbitant, and the wor
king hours could be longer, but remember that you are in the
 learning and practice stage (just in the first step), so yo
u can not demand too much, you must land your expectations a
nd fit that reality, and stop pretending to be paid $ 10,000
 a month at this stage. But, depending of your country $1.00
0 USD could be something very interesting to start this new 
career. Remember, you are a Junior at this stage.

***The co
nclusion is: don’t waste your time looking at and/or applyin
g to offers from big companies, because you will get frustra
ted. Be creative, and look for opportunities in smaller or n
ewly created companies***.

## Learning never stops

While y
ou are in that process of looking for a job or an opportunit
y, which could take half of your time (50% looking for oppor
tunities, 50% staying in practice), you have to keep learnin
g, you should advance to concepts such as Deep Learning, Dat
a Engineer or other topics that you feel were left loose fro
m the past stages or focus on the topics that you are passio
nate about within this group of disciplines in data science.


At the same time you can choose a second project, and spen
d some time running it from end-to-end, and thus increase yo
ur portfolio and your experience. If this is the case, try t
o find a completely different project: if the first one was 
done with Machine Learning, let this second one be done with
 Deep learning. If the first one was deployed to a web page,
 that this second one is deployed to a mobile platform. Reme
mber, creativity is the key!

# Conclusion

We are at an ide
al time to plan for 2021, and if this is the path you want t
o take, start looking for the platforms and media you want t
o study on. Get to work and don’t miss this opportunity to b
ecome a data scientist in 2021!

Note: we are building a pri
vate community in Slack of data scientist, if you want to jo
in us write to the email: [support@datasource.ai](mailto:sup
port@datasource.ai)

I hope you enjoyed this reading! you ca
n follow me on [twitter](https://twitter.com/daniel_moralesp
) or [linkedin](https://www.linkedin.com/in/danielmorales1/)


Thank you for reading!"	"https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/"	"59"	"1608676284.0"	"304"	"kifqtc"
178	"Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training."	"You can download or review the source code at [https://githu
b.com/albertnadal/Tensar](https://github.com/albertnadal/Ten
sar)

Here is attached a video/demo of the application durin
g the training. 

[CNN implemented in C++\/OpenGL trained wi
th the MNIST dataset](https://reddit.com/link/if7n2p/video/3
3k3qwhhesi51/player)

You can find the original video in my 
youtube channel ([https://youtu.be/oCElhUzadaA](https://yout
u.be/oCElhUzadaA)), so I encourage you to subscribe to the c
hannel if you are interested in future implementations relat
ed to ML and AI. I hope you find it useful to better underst
and how CNN's works. Thank you!

&#x200B;

Albert,"	"https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/"	"9"	"1598205014.0"	"281"	"if7n2p"
179	"Almost no one knows how easily you can optimize your AI models"	"The situation is fairly simple. **Your model could run 10 ti
mes faster** by adding a few lines to your code, but you wer
en't aware of it. Let me expand on that.

1. AI applications
 are multiplying like mushrooms, which is awesome
2. As a re
sult, more and more people are turning to the dark side, joi
ning the AI world, as I did
3. The problem? Developers focus
 only on AI, cleaning up datasets and training their models.
 Almost no one has a background in hardware, compilers, comp
uting, cloud, etc
4. The result? Developers spend a lot of h
ours improving the accuracy and performance of their softwar
e, and all their hard work risks being undone by the wrong c
hoice of hardware-software coupling

This problem bothered m
e for a long time, so with a couple of buddies at [Nebuly](h
ttps://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot 
of energy into an **open-source library** called **nebullvm*
* to make DL compiler technology accessible to any developer
, even for those who know nothing about hardware, as I did.


How does it work? It **speeds up your DL models by \~5-20x*
* by testing the best DL compilers out there and selecting t
he optimal one to best couple your AI model with your machin
e (GPU, CPU, etc.). All this in just a few lines of code.

T
he library is open source and you can find it here [https://
github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/
nebullvm).

Please leave a star on GitHub for the hard work 
in building the library :) It's a simple act for you, a big 
smile for us. Thank you, and don't hesitate to contribute to
 the library!"	"https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/"	"38"	"1645521383.0"	"273"	"syj7vx"
180	"Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread."	""	"https://v.redd.it/jh5n48ghrhp51"	"29"	"1601125855.0"	"1177"	"j05rte"
181	"image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model"	""	"https://www.youtube.com/watch?v=FwXQ568_io0"	"46"	"1596625082.0"	"639"	"i437om"
182	"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment."	""	"https://i.redd.it/jczyjswj6pra1.png"	"61"	"1680539995.0"	"577"	"12apw9o"
183	"*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)"	""	"https://i.redd.it/dlw52klsvqt61.gif"	"53"	"1618670134.0"	"489"	"msruz1"
184	"Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI"	""	"https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion"	"102"	"1673349121.0"	"449"	"1087ady"
185	"OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)"	""	"https://www.youtube.com/watch?v=Lu56xVlZ40M"	"19"	"1571875085.0"	"343"	"dm86ay"
186	"GPT-4 Will Be 500x Smaller Than People Think - Here Is Why"	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://pre
view.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=web
p&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mil
l is buzzing around the release of GPT-4.

People are predic
ting the model will have 100 trillion parameters. That’s a *
trillion* with a “t”.

The often-used graphic above makes GP
T-3 look like a cute little breadcrumb that is about to have
 a live-ending encounter with a bowling ball.

Sure, OpenAI’
s new brainchild will certainly be mind-bending and language
 models have been getting bigger — fast!

But this time migh
t be different and it makes for a good opportunity to look a
t the research on scaling large language models (LLMs).

*Le
t’s go!*

Training 100 Trillion Parameters

The creation of 
GPT-3 was a marvelous feat of engineering. The training was 
done on 1024 GPUs, took 34 days, and cost $4.6M in compute a
lone \[1\].

Training a 100T parameter model on the same dat
a, using 10000 GPUs, would take 53 Years. To avoid overfitti
ng such a huge model the dataset would also need to be much(
!) larger.

So, where is this rumor coming from?

The Source
 Of The Rumor:

It turns out OpenAI itself might be the sour
ce of it.

In August 2021 the CEO of Cerebras told [wired](h
ttps://www.wired.com/story/cerebras-chip-cluster-neural-netw
orks-ai/): “From talking to OpenAI, GPT-4 will be about 100 
trillion parameters”.

A the time, that was most likely what
 they believed, but that was in 2021. So, basically forever 
ago when machine learning research is concerned.

Things hav
e changed a lot since then!

To understand what happened we 
first need to look at how people decide the number of parame
ters in a model.

Deciding The Number Of Parameters:

The en
ormous hunger for resources typically makes it feasible to t
rain an LLM only once.

In practice, the available compute b
udget (how much money will be spent, available GPUs, etc.) i
s known in advance. Before the training is started, research
ers need to accurately predict which hyperparameters will re
sult in the best model.

*But there’s a catch!*

Most resear
ch on neural networks is empirical. People typically run hun
dreds or even thousands of training experiments until they f
ind a good model with the right hyperparameters.

With LLMs 
we cannot do that. Training 200 GPT-3 models would set you b
ack roughly a billion dollars. Not even the deep-pocketed te
ch giants can spend this sort of money.

Therefore, research
ers need to work with what they have. Either they investigat
e the few big models that have been trained or they train sm
aller models in the hope of learning something about how to 
scale the big ones.

This process can very noisy and the com
munity’s understanding has evolved a lot over the last few y
ears.

What People Used To Think About Scaling LLMs

In 2020
, a team of researchers from OpenAI released a [paper](https
://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For N
eural Language Models”.

They observed a predictable decreas
e in training loss when increasing the model size over multi
ple orders of magnitude.

So far so good. But they made two 
other observations, which resulted in the model size balloon
ing rapidly.

1. To scale models optimally the parameters sh
ould scale quicker than the dataset size. To be exact, their
 analysis showed when increasing the model size 8x the datas
et only needs to be increased 5x.
2. Full model convergence 
is not compute-efficient. Given a fixed compute budget it is
 better to train large models shorter than to use a smaller 
model and train it longer.

Hence, it seemed as if the way t
o improve performance was to scale models faster than the da
taset size \[2\].

And that is what people did. The models g
ot larger and larger with GPT-3 (175B), [Gopher](https://arx
iv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](htt
ps://arxiv.org/pdf/2201.11990) (530B) just to name a few.

B
ut the bigger models failed to deliver on the promise.

*Rea
d on to learn why!*

What We know About Scaling Models Today


It turns out you need to scale training sets and models in
 equal proportions. So, every time the model size doubles, t
he number of training tokens should double as well.

This wa
s published in DeepMind’s 2022 [paper](https://arxiv.org/pdf
/2203.15556.pdf): “Training Compute-Optimal Large Language M
odels”

The researchers fitted over 400 language models rang
ing from 70M to over 16B parameters. To assess the impact of
 dataset size they also varied the number of training tokens
 from 5B-500B tokens.

The findings allowed them to estimate
 that a compute-optimal version of GPT-3 (175B) should be tr
ained on roughly 3.7T tokens. That is more than 10x the data
 that the original model was trained on.

To verify their re
sults they trained a fairly small model on vastly more data.
 Their model, called Chinchilla, has 70B parameters and is t
rained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 b
ut trained on almost 5x the data.

Chinchilla outperforms GP
T-3 and other much larger models by a fair margin \[3\].

Th
is was a great breakthrough!  
The model is not just better,
 but its smaller size makes inference cheaper and finetuning
 easier.

*So What Will Happen?*

What GPT-4 Might Look Like
:

To properly fit a model with 100T parameters, open OpenAI
 needs a dataset of roughly 700T tokens. Given 1M GPUs and u
sing the calculus from above, it would still take roughly 26
50 years to train the model \[1\].

So, here is what GPT-4 c
ould look like:

* Similar size to GPT-3, but trained optima
lly on 10x more data
* ​[Multi-modal](https://thealgorithmic
bridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outp
utting text, images, and sound
* Output conditioned on docum
ent chunks from a memory bank that the model has access to d
uring prediction \[4\]
* Doubled context size allows longer 
predictions before the model starts going off the rails​

Re
gardless of the exact design, it will be a solid step forwar
d. However, it will not be the 100T token human-brain-like A
GI that people make it out to be.

Whatever it will look lik
e, I am sure it will be amazing and we can all be excited ab
out the release.

Such exciting times to be alive!

As alway
s, I really enjoyed making this for you and I sincerely hope
 you found it useful!

Would you like to receive an article 
such as this one straight to your inbox every Thursday? Cons
ider signing up for **The Decoding** ⭕.

I send out a though
tful newsletter about ML research and the data economy once 
a week. No Spam. No Nonsense. [Click here to sign up!](https
://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M
. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthika
nti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro
, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Langua
ge Model Training on GPU Clusters Using Megatron-LM](https:/
/arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S.
 McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… 
& D. Amodei, [Scaling laws for neural language model](https:
//arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J
. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, 
E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T
. Hennigan, [Training Compute-Optimal Large Language Models]
(https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint a
rXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann
, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespi
au, B. Damoc, A. Clark, D. Casas, [Improving language models
 by retrieving from trillions of tokens](https://arxiv.org/a
bs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Van
couver"	"https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/"	"49"	"1674114980.0"	"326"	"10fw2df"
187	"Study Plan for Learning Data Science Over the Next 12 Months [D]"	"In this thread, I address a study plan for 2021.

In case yo
u're interested, I wrote a whole article about this topic: [
Study Plan for Learning Data Science Over the Next 12 Months
](https://www.datasource.ai/en/data-science-articles/study-p
lan-for-learning-data-science-over-the-next-12-months)

Let 
me know your thoughts on this.

&#x200B;

https://preview.re
dd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf
09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 a
nd it is time to make plans for next year, and one of the mo
st important plans and questions we must ask is what do we w
ant to study?, what do we want to enhance?, what changes do 
we want to make?, and what is the direction we are going to 
take (or continue) in our professional careers?.

Many of yo
u will be starting on the road to becoming a data scientist,
 in fact you may be evaluating it, since you have heard a lo
t about it, but you have some doubts, for example about the 
amount of job offers that may exist in this area, doubts abo
ut the technology itself, and about the path you should foll
ow, considering the wide range of options to learn.

I’m a b
eliever that we should learn from various sources, from vari
ous mentors, and from various formats. By sources I mean the
 various virtual platforms and face-to-face options that exi
st to study. By mentors I mean that it is always a good idea
 to learn from different points of view and learning from di
fferent teachers/mentors, and by formats I mean the choices 
between books, videos, classes, and other formats where the 
information is contained.

When we extract information from 
all these sources we reinforce the knowledge learned, but we
 always need a guide, and this post aims to give you some pr
actical insights and strategies in this regard.

To decide o
n sources, mentors and formats it is up to you to choose. It
 depends on your preferences and ease of learning: for examp
le, some people are better at learning from books, while oth
ers prefer to learn from videos. Some prefer to study on pla
tforms that are practical (following online code), and other
s prefer traditional platforms: like those at universities (
Master’s Degree, PHDs or MOOCs). Others prefer to pay for qu
ality content, while others prefer to look only for free mat
erial. That’s why I won’t give a specific recommendation in 
this post, but I’ll give you the whole picture: **a study pl
an**.

To start you should consider the time you’ll spend st
udying and the depth of learning you want to achieve, becaus
e if you find yourself without a job you could be available 
full time to study, which is a huge advantage. On the other 
hand, if you are working, you’ll have less time and you’ll h
ave to discipline yourself to be able to have the time avail
able in the evenings, mornings or weekends. Ultimately, the 
important thing is to meet the goal of learning and perhaps 
dedicating your career to this exciting area!

We will divid
e the year into quarters as follows

* **First Quarter**: Le
arning the Basics
* **Second Quarter**: Upgrading the Level:
 Intermediate Knowledge
* **Third Quarter**: A Real World Pr
oject — A Full-stack Project
* **Fourth Quarter**: Seeking O
pportunities While Maintaining Practice

# First Quarter: Le
arning the Basics

&#x200B;

https://preview.redd.it/u7t9bth
ket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7ac
f793259243aa5a60a8535f0a

If you want to be more rigorous yo
u can have start and end dates for this period of study of t
he bases. It could be something like: From January 1 to Marc
h 30, 2021 as deadline. During this period you will study th
e following:

## A programming language that you can apply t
o data science: Python or R.

We recommend Python due to the
 simple fact that approximately 80% of data science job offe
rs ask for knowledge in Python. That same percentage is main
tained with respect to the real projects you will find imple
mented in production. And we add the fact that Python is mul
tipurpose, so you won’t “waste” your time if at some point y
ou decide to focus on web development, for example, or deskt
op development. This would be the first topic to study in th
e first months of the year.

## Familiarize yourself with st
atistics and mathematics.

There is a big debate in the data
 science community about whether we need this foundation or 
not. I will write a post later on about this, but the realit
y is that you **DO** need it, but **ONLY** the basics (at le
ast in the beginning). And I want to clarify this point befo
re continuing.

We could say that data science is divided in
 two big fields: Research on one side and putting Machine Le
arning algorithms into production on the other side. If you 
later decide to focus on Research then you are going to need
 mathematics and statistics in depth (very in depth). If you
 are going to go for the practical part, the libraries will 
help you deal with most of it, under the hood. It should be 
noted that most job offers are in the practical part.

For b
oth cases, and in this first stage you will only need the ba
sics of:

* **Statistics (with Python and NumPy)**

1. Descr
iptive statistics
2. Inferential Statistics
3. Hypothesis te
sting
4. Probability

* **Mathematics (with Python and NumPy
)**

1. Linear Algebra (For example: SVD)
2. Multivariate Ca
lculus
3. Calculus (For example: gradient descent)

**Note**
: We recommend that you study Python first before seeing sta
tistics and mathematics, because the challenge is to impleme
nt these statistical and mathematical bases with Python. Don
’t look for theoretical tutorials that show only slides or s
tatistical and/or mathematical examples in Excel/Matlab/Octa
ve/SAS and other different to Python or R, it gets very bori
ng and impractical! You should choose a course, program or b
ook that teaches these concepts in a practical way and using
 Python. Remember that Python is what we finally use, so you
 need to choose well. **This advice is key so you don’t give
 up on this part, as it will be the most dense and difficult
**.

If you have these basics in the first three months, you
 will be ready to make a leap in your learning for the next 
three months.

# Second Quarter: Upgrading the Level: Interm
ediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vyn
et661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025
c39a8975faf4d64514df275

If you want to be more rigorous you
 can have start and end dates for this period of study at th
e intermediate level. It could be something like: From April
 1 to June 30, 2021 as deadline.

Now that you have a good f
oundation in programming, statistics and mathematics, it is 
time to move forward and learn about the great advantages th
at Python has for applying data analysis. For this stage you
 will be focused on:

## Data science Python stack

Python h
as the following libraries that you should study, know and p
ractice at this stage

* **Pandas**: for working with tabula
r data and make in-depth analysis
* **Matplotlib and Seaborn
**: for data visualization

Pandas is the in-facto library f
or data analysis, it is one of the most important (if not th
e most important) and powerful tools you should know and mas
ter during your career as a data scientist. Pandas will make
 it much easier for you to manipulate, cleanse and organize 
your data.

## Feature Engineering

Many times people don’t 
go deep into Feature Engineering, but if you want to have Ma
chine Learning models that make good predictions and improve
 your scores, spending some time on this subject is invaluab
le!

Feature engineering is the process of using domain know
ledge to extract features from raw data using data mining te
chniques. These features can be used to improve the performa
nce of machine learning algorithms. Feature engineering can 
be considered as applied machine learning itself. To achieve
 the goal of good feature engineering you must know the diff
erent techniques that exist, so it is a good idea to at leas
t study the main ones.

## Basic Models of Machine Learning


At the end of this stage you will start with the study of M
achine Learning. This is perhaps the most awaited moment! Th
is is where you start to learn about the different algorithm
s you can use, which particular problems you can solve and h
ow you can apply them in real life.

The Python library we r
ecommend you to start experimenting with ML is: scikit-learn
. *However it is a good idea that you can find tutorials whe
re they explain the implementation of the algorithms (at lea
st the simplest ones) from scratch with Python, since the li
brary could be a “****Black Box****” and you might not under
stand what is happening under the hood. If you learn how to 
implement them with Python, you can have a more solid founda
tion*.

If you implement the algorithms with Python (without
 a library), you will put into practice everything seen in t
he statistics, mathematics and Pandas part.

These are some 
recommendations of the algorithms that you should at least k
now in this initial stage

* **Supervised learning**
   * Si
mple Linear Regression
   * Multiple Linear Regression
   * 
K-nearest neighbors (KNN)
   * Logistic Regression
   * Deci
sion Trees
   * Random Forest
* **Unsupervised Learning**
  
 * K-Means
   * PCA

**Bonus**: if you have the time and you
 are within the time ranges, you can study these others

* *
*Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * L
ightGBM
   * CatBoost

**Note**: do not spend more than the 
3 months stipulated for this stage. Because you will be fall
ing behind and not complying with the study plan. We all hav
e shortcomings at this stage, it is normal, go ahead and the
n you can resume some concepts that did not understand in de
tail. The important thing is to have the basic knowledge and
 move forward!

*If at least you succeed to study the mentio
ned algorithms of supervised and unsupervised learning, you 
will have a very clear idea of what you will be able to do i
n the future*. So don’t worry about covering everything, rem
ember that it is a process, and ideally you should have some
 clearly established times so that you don’t get frustrated 
and feel you are advancing.

So far, here comes your “theore
tical” study of the basics of data science. Now we’ll contin
ue with the practical part!

# Third Quarter: A Real World P
roject — A Full-stack Project

&#x200B;

https://preview.red
d.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=6640
61b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more
 rigorous you can have start and end dates for this period o
f study at the intermediate level. It could be something lik
e: From July 1 to September 30, 2021 as deadline.

Now that 
you have a good foundation in programming, statistics, mathe
matics, data analysis and machine learning algorithms, it is
 time to move forward and put into practice all this knowled
ge.

Many of these suggestions may sound out of the box, but
 believe me they will make a big difference in your career a
s a data scientist.

## The first thing is to create your we
b presence:

* *Create a Github (or GitLab) account, and lea
rn Git*. Being able to manage different versions of your cod
e is important, you should have version control over them, n
ot to mention that having an active Github account is very v
aluable in demonstrating your true skills. On Github, you ca
n also set up your Jupyter Notebooks and make them public, s
o you can show off your skills as well. This is mine for exa
mple: [https://github.com/danielmoralesp](https://github.com
/danielmoralesp)
* *Learn the basics of web programming*. Th
e advantage is that you already have Python as a skill, so y
ou can learn Flask to create a simple web page. Or you can u
se a template engine like Github Pages, Ghost or Wordpress i
tself and create your online portfolio.
* *Buy a domain with
 your name*. Something like myname.com, myname.co, myname.de
v, etc. This is invaluable so you can have your CV online an
d update it with your projects. There you can make a big dif
ference, showing your projects, your Jupyter Notebooks and s
howing that you have the practical skills to execute project
s in this area. There are many front-end templates for you t
o purchase for free or for payment, and give it a more perso
nalized and pleasant look. Don’t use free sub-domains of Wor
dpress, Github or Wix, it looks very unprofessional, make yo
ur own. Here is mine for example: [https://www.danielmorales
.dev/](https://www.danielmorales.dev/)

## Choose a project 
you are passionate about and create a Machine Learning model
 around it.

The final goal of this third quarter is to crea
te **ONE** project, that you are passionate about, and that 
is **UNIQUE** among others. It turns out that there are many
 typical projects in the community, such as predicting the T
itanic Survivors, or predicting the price of Houses in Bosto
n. Those kinds of projects are good for learning, but not fo
r showing off as your **UNIQUE** projects.

If you are passi
onate about sports, try predicting the soccer results of you
r local league. If you are passionate about finance, try pre
dicting your country’s stock market prices. If you are passi
onate about marketing, try to find someone who has an e-comm
erce and implement a product recommendation algorithm and up
load it to production. If you are passionate about business:
 make a predictor of the best business ideas for 2021 :)

As
 you can see, you are limited by your passions and your imag
ination. ***In fact,*** ***those are the two keys for you to
 do this project: Passion and Imagination***.

However don’t
 expect to make money from it, you are in a learning stage, 
you need that algorithm to be deployed in production, make a
n API in Flask with it, and explain in your website how you 
did it and how people can access it. This is the moment to s
hine, and at the same time it’s the moment of the greatest l
earning.

You will most likely face obstacles, if your algor
ithm gives 60% of Accuracy after a huge optimization effort,
 it doesn’t matter, finish the whole process, deploy it to p
roduction, try to get a friend or family member to use it, a
nd that will be the goal achieved for this stage: **Make a F
ull-stack Machine Learning project.**

By full-stack I mean 
that you did all the following steps:

* You got the data fr
om somewhere (scrapping, open data or API)
* You did a data 
analysis
* You cleaned and transformed the data
* You create
d Machine Learning Models
* You deployed the best model to p
roduction for other people to use.

This does not mean that 
this whole process is what you will always do in your daily 
job, but it does mean that you will know every part of the p
ipeline that is needed for a data science project for a comp
any. You will have a unique perspective!

# Fourth Quarter: 
Seeking Opportunities While Maintaining Practice

&#x200B;


https://preview.redd.it/qd0osystet661.png?width=1056&format=
png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If
 you want to be more rigorous you can have start and end dat
es for this period of study at the final level. It could be 
something like: From October 1 to December 31, 2021 as deadl
ine.

Now you have theoretical and practical knowledge. You 
have implemented a model in production. The next step depend
s on you and your personality. Let’s say you are an entrepre
neur, and you have the vision to create something new from s
omething you discovered or saw an opportunity to do business
 with this discipline, so it’s time to start planning how to
 do it. If that’s the case, obviously this post won’t cover 
that process, but you should know what the steps might be (o
r start figuring them out).

But if you are one of those who
 want to get a job as a data scientist, here is my advice.


## Getting a job as a data scientist

>*“You’re not going to
 get a job as fast as you think, if you keep thinking the sa
me way”.Author*

It turns out that all people who start out 
as data scientists imagine themselves working for the big co
mpanies in their country or region. Or even remote. It turns
 out that if you aspire to work for a large company like dat
a scientist you will be frustrated by the years of experienc
e they ask for (3 or more years) and the skills they request
.

Large companies don’t hire Juniors (or very few do), prec
isely because they are already large companies. They have th
e financial muscle to demand experience and skills and can p
ay a commensurate salary (although this is not always the ca
se). The point is that if you focus there you’re going to ge
t frustrated!

Here we must return to the following advise: 
***“You need creativity to get a job in data science”***.

L
ike everything else in life we have to start at different st
eps, in this case, from the beginning. Here are the scenario
s

* *If you are working in a company and in a non-engineeri
ng role you must demonstrate your new skills to the company 
you are working for*. If you are working in the customer ser
vice area, you should apply it to your work, and do for exam
ple, detailed analysis of your calls, conversion rates, stor
e data and make predictions about it! If you can have data f
rom your colleagues, you could try to predict their sales! T
his may sound funny, but it’s about how creatively you can a
pply data science to your current work and how to show your 
bosses how valuable it is and **EVANGELIZE** them about the 
benefits of implementation. You’ll be noticed and they could
 certainly create a new data related department or job. And 
you already have the knowledge and experience. The key word 
here is **Evangelize**. Many companies and entrepreneurs are
 just beginning to see the power of this discipline, and it 
is your task to nurture that reality.
* *If you are working 
in an area related to engineering, but that is not data scie
nce*. Here the same applies as the previous example, but you
 have some advantages, and that is that you could access the
 company’s data, and you could use it for the benefit of the
 company, making analyses and/or predictions about it, and a
gain **EVANGELIZING** your bosses your new skills and the be
nefits of data science.
* *If you are unemployed (or do not 
want, or do not feel comfortable following the two examples 
above)*, you can start looking outside, and what I recommend
 is that you look for technology companies and / or startups
 where they are just forming the first teams and are paying 
some salary, or even have options shares of the company. Obv
iously here the salaries will not be exorbitant, and the wor
king hours could be longer, but remember that you are in the
 learning and practice stage (just in the first step), so yo
u can not demand too much, you must land your expectations a
nd fit that reality, and stop pretending to be paid $ 10,000
 a month at this stage. But, depending of your country $1.00
0 USD could be something very interesting to start this new 
career. Remember, you are a Junior at this stage.

***The co
nclusion is: don’t waste your time looking at and/or applyin
g to offers from big companies, because you will get frustra
ted. Be creative, and look for opportunities in smaller or n
ewly created companies***.

## Learning never stops

While y
ou are in that process of looking for a job or an opportunit
y, which could take half of your time (50% looking for oppor
tunities, 50% staying in practice), you have to keep learnin
g, you should advance to concepts such as Deep Learning, Dat
a Engineer or other topics that you feel were left loose fro
m the past stages or focus on the topics that you are passio
nate about within this group of disciplines in data science.


At the same time you can choose a second project, and spen
d some time running it from end-to-end, and thus increase yo
ur portfolio and your experience. If this is the case, try t
o find a completely different project: if the first one was 
done with Machine Learning, let this second one be done with
 Deep learning. If the first one was deployed to a web page,
 that this second one is deployed to a mobile platform. Reme
mber, creativity is the key!

# Conclusion

We are at an ide
al time to plan for 2021, and if this is the path you want t
o take, start looking for the platforms and media you want t
o study on. Get to work and don’t miss this opportunity to b
ecome a data scientist in 2021!

Note: we are building a pri
vate community in Slack of data scientist, if you want to jo
in us write to the email: [support@datasource.ai](mailto:sup
port@datasource.ai)

I hope you enjoyed this reading! you ca
n follow me on [twitter](https://twitter.com/daniel_moralesp
) or [linkedin](https://www.linkedin.com/in/danielmorales1/)


Thank you for reading!"	"https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/"	"59"	"1608676284.0"	"301"	"kifqtc"
188	"Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training."	"You can download or review the source code at [https://githu
b.com/albertnadal/Tensar](https://github.com/albertnadal/Ten
sar)

Here is attached a video/demo of the application durin
g the training. 

[CNN implemented in C++\/OpenGL trained wi
th the MNIST dataset](https://reddit.com/link/if7n2p/video/3
3k3qwhhesi51/player)

You can find the original video in my 
youtube channel ([https://youtu.be/oCElhUzadaA](https://yout
u.be/oCElhUzadaA)), so I encourage you to subscribe to the c
hannel if you are interested in future implementations relat
ed to ML and AI. I hope you find it useful to better underst
and how CNN's works. Thank you!

&#x200B;

Albert,"	"https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/"	"9"	"1598205014.0"	"282"	"if7n2p"
189	"Almost no one knows how easily you can optimize your AI models"	"The situation is fairly simple. **Your model could run 10 ti
mes faster** by adding a few lines to your code, but you wer
en't aware of it. Let me expand on that.

1. AI applications
 are multiplying like mushrooms, which is awesome
2. As a re
sult, more and more people are turning to the dark side, joi
ning the AI world, as I did
3. The problem? Developers focus
 only on AI, cleaning up datasets and training their models.
 Almost no one has a background in hardware, compilers, comp
uting, cloud, etc
4. The result? Developers spend a lot of h
ours improving the accuracy and performance of their softwar
e, and all their hard work risks being undone by the wrong c
hoice of hardware-software coupling

This problem bothered m
e for a long time, so with a couple of buddies at [Nebuly](h
ttps://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot 
of energy into an **open-source library** called **nebullvm*
* to make DL compiler technology accessible to any developer
, even for those who know nothing about hardware, as I did.


How does it work? It **speeds up your DL models by \~5-20x*
* by testing the best DL compilers out there and selecting t
he optimal one to best couple your AI model with your machin
e (GPU, CPU, etc.). All this in just a few lines of code.

T
he library is open source and you can find it here [https://
github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/
nebullvm).

Please leave a star on GitHub for the hard work 
in building the library :) It's a simple act for you, a big 
smile for us. Thank you, and don't hesitate to contribute to
 the library!"	"https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/"	"38"	"1645521383.0"	"270"	"syj7vx"
190	"Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread."	""	"https://v.redd.it/jh5n48ghrhp51"	"29"	"1601125855.0"	"1181"	"j05rte"
191	"image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model"	""	"https://www.youtube.com/watch?v=FwXQ568_io0"	"46"	"1596625082.0"	"633"	"i437om"
192	"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment."	""	"https://i.redd.it/jczyjswj6pra1.png"	"61"	"1680539995.0"	"576"	"12apw9o"
193	"*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)"	""	"https://i.redd.it/dlw52klsvqt61.gif"	"53"	"1618670134.0"	"487"	"msruz1"
194	"Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI"	""	"https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion"	"102"	"1673349121.0"	"449"	"1087ady"
195	"OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)"	""	"https://www.youtube.com/watch?v=Lu56xVlZ40M"	"19"	"1571875085.0"	"346"	"dm86ay"
196	"GPT-4 Will Be 500x Smaller Than People Think - Here Is Why"	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://pre
view.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=web
p&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mil
l is buzzing around the release of GPT-4.

People are predic
ting the model will have 100 trillion parameters. That’s a *
trillion* with a “t”.

The often-used graphic above makes GP
T-3 look like a cute little breadcrumb that is about to have
 a live-ending encounter with a bowling ball.

Sure, OpenAI’
s new brainchild will certainly be mind-bending and language
 models have been getting bigger — fast!

But this time migh
t be different and it makes for a good opportunity to look a
t the research on scaling large language models (LLMs).

*Le
t’s go!*

Training 100 Trillion Parameters

The creation of 
GPT-3 was a marvelous feat of engineering. The training was 
done on 1024 GPUs, took 34 days, and cost $4.6M in compute a
lone \[1\].

Training a 100T parameter model on the same dat
a, using 10000 GPUs, would take 53 Years. To avoid overfitti
ng such a huge model the dataset would also need to be much(
!) larger.

So, where is this rumor coming from?

The Source
 Of The Rumor:

It turns out OpenAI itself might be the sour
ce of it.

In August 2021 the CEO of Cerebras told [wired](h
ttps://www.wired.com/story/cerebras-chip-cluster-neural-netw
orks-ai/): “From talking to OpenAI, GPT-4 will be about 100 
trillion parameters”.

A the time, that was most likely what
 they believed, but that was in 2021. So, basically forever 
ago when machine learning research is concerned.

Things hav
e changed a lot since then!

To understand what happened we 
first need to look at how people decide the number of parame
ters in a model.

Deciding The Number Of Parameters:

The en
ormous hunger for resources typically makes it feasible to t
rain an LLM only once.

In practice, the available compute b
udget (how much money will be spent, available GPUs, etc.) i
s known in advance. Before the training is started, research
ers need to accurately predict which hyperparameters will re
sult in the best model.

*But there’s a catch!*

Most resear
ch on neural networks is empirical. People typically run hun
dreds or even thousands of training experiments until they f
ind a good model with the right hyperparameters.

With LLMs 
we cannot do that. Training 200 GPT-3 models would set you b
ack roughly a billion dollars. Not even the deep-pocketed te
ch giants can spend this sort of money.

Therefore, research
ers need to work with what they have. Either they investigat
e the few big models that have been trained or they train sm
aller models in the hope of learning something about how to 
scale the big ones.

This process can very noisy and the com
munity’s understanding has evolved a lot over the last few y
ears.

What People Used To Think About Scaling LLMs

In 2020
, a team of researchers from OpenAI released a [paper](https
://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For N
eural Language Models”.

They observed a predictable decreas
e in training loss when increasing the model size over multi
ple orders of magnitude.

So far so good. But they made two 
other observations, which resulted in the model size balloon
ing rapidly.

1. To scale models optimally the parameters sh
ould scale quicker than the dataset size. To be exact, their
 analysis showed when increasing the model size 8x the datas
et only needs to be increased 5x.
2. Full model convergence 
is not compute-efficient. Given a fixed compute budget it is
 better to train large models shorter than to use a smaller 
model and train it longer.

Hence, it seemed as if the way t
o improve performance was to scale models faster than the da
taset size \[2\].

And that is what people did. The models g
ot larger and larger with GPT-3 (175B), [Gopher](https://arx
iv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](htt
ps://arxiv.org/pdf/2201.11990) (530B) just to name a few.

B
ut the bigger models failed to deliver on the promise.

*Rea
d on to learn why!*

What We know About Scaling Models Today


It turns out you need to scale training sets and models in
 equal proportions. So, every time the model size doubles, t
he number of training tokens should double as well.

This wa
s published in DeepMind’s 2022 [paper](https://arxiv.org/pdf
/2203.15556.pdf): “Training Compute-Optimal Large Language M
odels”

The researchers fitted over 400 language models rang
ing from 70M to over 16B parameters. To assess the impact of
 dataset size they also varied the number of training tokens
 from 5B-500B tokens.

The findings allowed them to estimate
 that a compute-optimal version of GPT-3 (175B) should be tr
ained on roughly 3.7T tokens. That is more than 10x the data
 that the original model was trained on.

To verify their re
sults they trained a fairly small model on vastly more data.
 Their model, called Chinchilla, has 70B parameters and is t
rained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 b
ut trained on almost 5x the data.

Chinchilla outperforms GP
T-3 and other much larger models by a fair margin \[3\].

Th
is was a great breakthrough!  
The model is not just better,
 but its smaller size makes inference cheaper and finetuning
 easier.

*So What Will Happen?*

What GPT-4 Might Look Like
:

To properly fit a model with 100T parameters, open OpenAI
 needs a dataset of roughly 700T tokens. Given 1M GPUs and u
sing the calculus from above, it would still take roughly 26
50 years to train the model \[1\].

So, here is what GPT-4 c
ould look like:

* Similar size to GPT-3, but trained optima
lly on 10x more data
* ​[Multi-modal](https://thealgorithmic
bridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outp
utting text, images, and sound
* Output conditioned on docum
ent chunks from a memory bank that the model has access to d
uring prediction \[4\]
* Doubled context size allows longer 
predictions before the model starts going off the rails​

Re
gardless of the exact design, it will be a solid step forwar
d. However, it will not be the 100T token human-brain-like A
GI that people make it out to be.

Whatever it will look lik
e, I am sure it will be amazing and we can all be excited ab
out the release.

Such exciting times to be alive!

As alway
s, I really enjoyed making this for you and I sincerely hope
 you found it useful!

Would you like to receive an article 
such as this one straight to your inbox every Thursday? Cons
ider signing up for **The Decoding** ⭕.

I send out a though
tful newsletter about ML research and the data economy once 
a week. No Spam. No Nonsense. [Click here to sign up!](https
://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M
. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthika
nti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro
, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Langua
ge Model Training on GPU Clusters Using Megatron-LM](https:/
/arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S.
 McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… 
& D. Amodei, [Scaling laws for neural language model](https:
//arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J
. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, 
E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T
. Hennigan, [Training Compute-Optimal Large Language Models]
(https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint a
rXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann
, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespi
au, B. Damoc, A. Clark, D. Casas, [Improving language models
 by retrieving from trillions of tokens](https://arxiv.org/a
bs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Van
couver"	"https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/"	"49"	"1674114980.0"	"331"	"10fw2df"
197	"Study Plan for Learning Data Science Over the Next 12 Months [D]"	"In this thread, I address a study plan for 2021.

In case yo
u're interested, I wrote a whole article about this topic: [
Study Plan for Learning Data Science Over the Next 12 Months
](https://www.datasource.ai/en/data-science-articles/study-p
lan-for-learning-data-science-over-the-next-12-months)

Let 
me know your thoughts on this.

&#x200B;

https://preview.re
dd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf
09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 a
nd it is time to make plans for next year, and one of the mo
st important plans and questions we must ask is what do we w
ant to study?, what do we want to enhance?, what changes do 
we want to make?, and what is the direction we are going to 
take (or continue) in our professional careers?.

Many of yo
u will be starting on the road to becoming a data scientist,
 in fact you may be evaluating it, since you have heard a lo
t about it, but you have some doubts, for example about the 
amount of job offers that may exist in this area, doubts abo
ut the technology itself, and about the path you should foll
ow, considering the wide range of options to learn.

I’m a b
eliever that we should learn from various sources, from vari
ous mentors, and from various formats. By sources I mean the
 various virtual platforms and face-to-face options that exi
st to study. By mentors I mean that it is always a good idea
 to learn from different points of view and learning from di
fferent teachers/mentors, and by formats I mean the choices 
between books, videos, classes, and other formats where the 
information is contained.

When we extract information from 
all these sources we reinforce the knowledge learned, but we
 always need a guide, and this post aims to give you some pr
actical insights and strategies in this regard.

To decide o
n sources, mentors and formats it is up to you to choose. It
 depends on your preferences and ease of learning: for examp
le, some people are better at learning from books, while oth
ers prefer to learn from videos. Some prefer to study on pla
tforms that are practical (following online code), and other
s prefer traditional platforms: like those at universities (
Master’s Degree, PHDs or MOOCs). Others prefer to pay for qu
ality content, while others prefer to look only for free mat
erial. That’s why I won’t give a specific recommendation in 
this post, but I’ll give you the whole picture: **a study pl
an**.

To start you should consider the time you’ll spend st
udying and the depth of learning you want to achieve, becaus
e if you find yourself without a job you could be available 
full time to study, which is a huge advantage. On the other 
hand, if you are working, you’ll have less time and you’ll h
ave to discipline yourself to be able to have the time avail
able in the evenings, mornings or weekends. Ultimately, the 
important thing is to meet the goal of learning and perhaps 
dedicating your career to this exciting area!

We will divid
e the year into quarters as follows

* **First Quarter**: Le
arning the Basics
* **Second Quarter**: Upgrading the Level:
 Intermediate Knowledge
* **Third Quarter**: A Real World Pr
oject — A Full-stack Project
* **Fourth Quarter**: Seeking O
pportunities While Maintaining Practice

# First Quarter: Le
arning the Basics

&#x200B;

https://preview.redd.it/u7t9bth
ket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7ac
f793259243aa5a60a8535f0a

If you want to be more rigorous yo
u can have start and end dates for this period of study of t
he bases. It could be something like: From January 1 to Marc
h 30, 2021 as deadline. During this period you will study th
e following:

## A programming language that you can apply t
o data science: Python or R.

We recommend Python due to the
 simple fact that approximately 80% of data science job offe
rs ask for knowledge in Python. That same percentage is main
tained with respect to the real projects you will find imple
mented in production. And we add the fact that Python is mul
tipurpose, so you won’t “waste” your time if at some point y
ou decide to focus on web development, for example, or deskt
op development. This would be the first topic to study in th
e first months of the year.

## Familiarize yourself with st
atistics and mathematics.

There is a big debate in the data
 science community about whether we need this foundation or 
not. I will write a post later on about this, but the realit
y is that you **DO** need it, but **ONLY** the basics (at le
ast in the beginning). And I want to clarify this point befo
re continuing.

We could say that data science is divided in
 two big fields: Research on one side and putting Machine Le
arning algorithms into production on the other side. If you 
later decide to focus on Research then you are going to need
 mathematics and statistics in depth (very in depth). If you
 are going to go for the practical part, the libraries will 
help you deal with most of it, under the hood. It should be 
noted that most job offers are in the practical part.

For b
oth cases, and in this first stage you will only need the ba
sics of:

* **Statistics (with Python and NumPy)**

1. Descr
iptive statistics
2. Inferential Statistics
3. Hypothesis te
sting
4. Probability

* **Mathematics (with Python and NumPy
)**

1. Linear Algebra (For example: SVD)
2. Multivariate Ca
lculus
3. Calculus (For example: gradient descent)

**Note**
: We recommend that you study Python first before seeing sta
tistics and mathematics, because the challenge is to impleme
nt these statistical and mathematical bases with Python. Don
’t look for theoretical tutorials that show only slides or s
tatistical and/or mathematical examples in Excel/Matlab/Octa
ve/SAS and other different to Python or R, it gets very bori
ng and impractical! You should choose a course, program or b
ook that teaches these concepts in a practical way and using
 Python. Remember that Python is what we finally use, so you
 need to choose well. **This advice is key so you don’t give
 up on this part, as it will be the most dense and difficult
**.

If you have these basics in the first three months, you
 will be ready to make a leap in your learning for the next 
three months.

# Second Quarter: Upgrading the Level: Interm
ediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vyn
et661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025
c39a8975faf4d64514df275

If you want to be more rigorous you
 can have start and end dates for this period of study at th
e intermediate level. It could be something like: From April
 1 to June 30, 2021 as deadline.

Now that you have a good f
oundation in programming, statistics and mathematics, it is 
time to move forward and learn about the great advantages th
at Python has for applying data analysis. For this stage you
 will be focused on:

## Data science Python stack

Python h
as the following libraries that you should study, know and p
ractice at this stage

* **Pandas**: for working with tabula
r data and make in-depth analysis
* **Matplotlib and Seaborn
**: for data visualization

Pandas is the in-facto library f
or data analysis, it is one of the most important (if not th
e most important) and powerful tools you should know and mas
ter during your career as a data scientist. Pandas will make
 it much easier for you to manipulate, cleanse and organize 
your data.

## Feature Engineering

Many times people don’t 
go deep into Feature Engineering, but if you want to have Ma
chine Learning models that make good predictions and improve
 your scores, spending some time on this subject is invaluab
le!

Feature engineering is the process of using domain know
ledge to extract features from raw data using data mining te
chniques. These features can be used to improve the performa
nce of machine learning algorithms. Feature engineering can 
be considered as applied machine learning itself. To achieve
 the goal of good feature engineering you must know the diff
erent techniques that exist, so it is a good idea to at leas
t study the main ones.

## Basic Models of Machine Learning


At the end of this stage you will start with the study of M
achine Learning. This is perhaps the most awaited moment! Th
is is where you start to learn about the different algorithm
s you can use, which particular problems you can solve and h
ow you can apply them in real life.

The Python library we r
ecommend you to start experimenting with ML is: scikit-learn
. *However it is a good idea that you can find tutorials whe
re they explain the implementation of the algorithms (at lea
st the simplest ones) from scratch with Python, since the li
brary could be a “****Black Box****” and you might not under
stand what is happening under the hood. If you learn how to 
implement them with Python, you can have a more solid founda
tion*.

If you implement the algorithms with Python (without
 a library), you will put into practice everything seen in t
he statistics, mathematics and Pandas part.

These are some 
recommendations of the algorithms that you should at least k
now in this initial stage

* **Supervised learning**
   * Si
mple Linear Regression
   * Multiple Linear Regression
   * 
K-nearest neighbors (KNN)
   * Logistic Regression
   * Deci
sion Trees
   * Random Forest
* **Unsupervised Learning**
  
 * K-Means
   * PCA

**Bonus**: if you have the time and you
 are within the time ranges, you can study these others

* *
*Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * L
ightGBM
   * CatBoost

**Note**: do not spend more than the 
3 months stipulated for this stage. Because you will be fall
ing behind and not complying with the study plan. We all hav
e shortcomings at this stage, it is normal, go ahead and the
n you can resume some concepts that did not understand in de
tail. The important thing is to have the basic knowledge and
 move forward!

*If at least you succeed to study the mentio
ned algorithms of supervised and unsupervised learning, you 
will have a very clear idea of what you will be able to do i
n the future*. So don’t worry about covering everything, rem
ember that it is a process, and ideally you should have some
 clearly established times so that you don’t get frustrated 
and feel you are advancing.

So far, here comes your “theore
tical” study of the basics of data science. Now we’ll contin
ue with the practical part!

# Third Quarter: A Real World P
roject — A Full-stack Project

&#x200B;

https://preview.red
d.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=6640
61b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more
 rigorous you can have start and end dates for this period o
f study at the intermediate level. It could be something lik
e: From July 1 to September 30, 2021 as deadline.

Now that 
you have a good foundation in programming, statistics, mathe
matics, data analysis and machine learning algorithms, it is
 time to move forward and put into practice all this knowled
ge.

Many of these suggestions may sound out of the box, but
 believe me they will make a big difference in your career a
s a data scientist.

## The first thing is to create your we
b presence:

* *Create a Github (or GitLab) account, and lea
rn Git*. Being able to manage different versions of your cod
e is important, you should have version control over them, n
ot to mention that having an active Github account is very v
aluable in demonstrating your true skills. On Github, you ca
n also set up your Jupyter Notebooks and make them public, s
o you can show off your skills as well. This is mine for exa
mple: [https://github.com/danielmoralesp](https://github.com
/danielmoralesp)
* *Learn the basics of web programming*. Th
e advantage is that you already have Python as a skill, so y
ou can learn Flask to create a simple web page. Or you can u
se a template engine like Github Pages, Ghost or Wordpress i
tself and create your online portfolio.
* *Buy a domain with
 your name*. Something like myname.com, myname.co, myname.de
v, etc. This is invaluable so you can have your CV online an
d update it with your projects. There you can make a big dif
ference, showing your projects, your Jupyter Notebooks and s
howing that you have the practical skills to execute project
s in this area. There are many front-end templates for you t
o purchase for free or for payment, and give it a more perso
nalized and pleasant look. Don’t use free sub-domains of Wor
dpress, Github or Wix, it looks very unprofessional, make yo
ur own. Here is mine for example: [https://www.danielmorales
.dev/](https://www.danielmorales.dev/)

## Choose a project 
you are passionate about and create a Machine Learning model
 around it.

The final goal of this third quarter is to crea
te **ONE** project, that you are passionate about, and that 
is **UNIQUE** among others. It turns out that there are many
 typical projects in the community, such as predicting the T
itanic Survivors, or predicting the price of Houses in Bosto
n. Those kinds of projects are good for learning, but not fo
r showing off as your **UNIQUE** projects.

If you are passi
onate about sports, try predicting the soccer results of you
r local league. If you are passionate about finance, try pre
dicting your country’s stock market prices. If you are passi
onate about marketing, try to find someone who has an e-comm
erce and implement a product recommendation algorithm and up
load it to production. If you are passionate about business:
 make a predictor of the best business ideas for 2021 :)

As
 you can see, you are limited by your passions and your imag
ination. ***In fact,*** ***those are the two keys for you to
 do this project: Passion and Imagination***.

However don’t
 expect to make money from it, you are in a learning stage, 
you need that algorithm to be deployed in production, make a
n API in Flask with it, and explain in your website how you 
did it and how people can access it. This is the moment to s
hine, and at the same time it’s the moment of the greatest l
earning.

You will most likely face obstacles, if your algor
ithm gives 60% of Accuracy after a huge optimization effort,
 it doesn’t matter, finish the whole process, deploy it to p
roduction, try to get a friend or family member to use it, a
nd that will be the goal achieved for this stage: **Make a F
ull-stack Machine Learning project.**

By full-stack I mean 
that you did all the following steps:

* You got the data fr
om somewhere (scrapping, open data or API)
* You did a data 
analysis
* You cleaned and transformed the data
* You create
d Machine Learning Models
* You deployed the best model to p
roduction for other people to use.

This does not mean that 
this whole process is what you will always do in your daily 
job, but it does mean that you will know every part of the p
ipeline that is needed for a data science project for a comp
any. You will have a unique perspective!

# Fourth Quarter: 
Seeking Opportunities While Maintaining Practice

&#x200B;


https://preview.redd.it/qd0osystet661.png?width=1056&format=
png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If
 you want to be more rigorous you can have start and end dat
es for this period of study at the final level. It could be 
something like: From October 1 to December 31, 2021 as deadl
ine.

Now you have theoretical and practical knowledge. You 
have implemented a model in production. The next step depend
s on you and your personality. Let’s say you are an entrepre
neur, and you have the vision to create something new from s
omething you discovered or saw an opportunity to do business
 with this discipline, so it’s time to start planning how to
 do it. If that’s the case, obviously this post won’t cover 
that process, but you should know what the steps might be (o
r start figuring them out).

But if you are one of those who
 want to get a job as a data scientist, here is my advice.


## Getting a job as a data scientist

>*“You’re not going to
 get a job as fast as you think, if you keep thinking the sa
me way”.Author*

It turns out that all people who start out 
as data scientists imagine themselves working for the big co
mpanies in their country or region. Or even remote. It turns
 out that if you aspire to work for a large company like dat
a scientist you will be frustrated by the years of experienc
e they ask for (3 or more years) and the skills they request
.

Large companies don’t hire Juniors (or very few do), prec
isely because they are already large companies. They have th
e financial muscle to demand experience and skills and can p
ay a commensurate salary (although this is not always the ca
se). The point is that if you focus there you’re going to ge
t frustrated!

Here we must return to the following advise: 
***“You need creativity to get a job in data science”***.

L
ike everything else in life we have to start at different st
eps, in this case, from the beginning. Here are the scenario
s

* *If you are working in a company and in a non-engineeri
ng role you must demonstrate your new skills to the company 
you are working for*. If you are working in the customer ser
vice area, you should apply it to your work, and do for exam
ple, detailed analysis of your calls, conversion rates, stor
e data and make predictions about it! If you can have data f
rom your colleagues, you could try to predict their sales! T
his may sound funny, but it’s about how creatively you can a
pply data science to your current work and how to show your 
bosses how valuable it is and **EVANGELIZE** them about the 
benefits of implementation. You’ll be noticed and they could
 certainly create a new data related department or job. And 
you already have the knowledge and experience. The key word 
here is **Evangelize**. Many companies and entrepreneurs are
 just beginning to see the power of this discipline, and it 
is your task to nurture that reality.
* *If you are working 
in an area related to engineering, but that is not data scie
nce*. Here the same applies as the previous example, but you
 have some advantages, and that is that you could access the
 company’s data, and you could use it for the benefit of the
 company, making analyses and/or predictions about it, and a
gain **EVANGELIZING** your bosses your new skills and the be
nefits of data science.
* *If you are unemployed (or do not 
want, or do not feel comfortable following the two examples 
above)*, you can start looking outside, and what I recommend
 is that you look for technology companies and / or startups
 where they are just forming the first teams and are paying 
some salary, or even have options shares of the company. Obv
iously here the salaries will not be exorbitant, and the wor
king hours could be longer, but remember that you are in the
 learning and practice stage (just in the first step), so yo
u can not demand too much, you must land your expectations a
nd fit that reality, and stop pretending to be paid $ 10,000
 a month at this stage. But, depending of your country $1.00
0 USD could be something very interesting to start this new 
career. Remember, you are a Junior at this stage.

***The co
nclusion is: don’t waste your time looking at and/or applyin
g to offers from big companies, because you will get frustra
ted. Be creative, and look for opportunities in smaller or n
ewly created companies***.

## Learning never stops

While y
ou are in that process of looking for a job or an opportunit
y, which could take half of your time (50% looking for oppor
tunities, 50% staying in practice), you have to keep learnin
g, you should advance to concepts such as Deep Learning, Dat
a Engineer or other topics that you feel were left loose fro
m the past stages or focus on the topics that you are passio
nate about within this group of disciplines in data science.


At the same time you can choose a second project, and spen
d some time running it from end-to-end, and thus increase yo
ur portfolio and your experience. If this is the case, try t
o find a completely different project: if the first one was 
done with Machine Learning, let this second one be done with
 Deep learning. If the first one was deployed to a web page,
 that this second one is deployed to a mobile platform. Reme
mber, creativity is the key!

# Conclusion

We are at an ide
al time to plan for 2021, and if this is the path you want t
o take, start looking for the platforms and media you want t
o study on. Get to work and don’t miss this opportunity to b
ecome a data scientist in 2021!

Note: we are building a pri
vate community in Slack of data scientist, if you want to jo
in us write to the email: [support@datasource.ai](mailto:sup
port@datasource.ai)

I hope you enjoyed this reading! you ca
n follow me on [twitter](https://twitter.com/daniel_moralesp
) or [linkedin](https://www.linkedin.com/in/danielmorales1/)


Thank you for reading!"	"https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/"	"59"	"1608676284.0"	"298"	"kifqtc"
198	"Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training."	"You can download or review the source code at [https://githu
b.com/albertnadal/Tensar](https://github.com/albertnadal/Ten
sar)

Here is attached a video/demo of the application durin
g the training. 

[CNN implemented in C++\/OpenGL trained wi
th the MNIST dataset](https://reddit.com/link/if7n2p/video/3
3k3qwhhesi51/player)

You can find the original video in my 
youtube channel ([https://youtu.be/oCElhUzadaA](https://yout
u.be/oCElhUzadaA)), so I encourage you to subscribe to the c
hannel if you are interested in future implementations relat
ed to ML and AI. I hope you find it useful to better underst
and how CNN's works. Thank you!

&#x200B;

Albert,"	"https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/"	"9"	"1598205014.0"	"284"	"if7n2p"
199	"Almost no one knows how easily you can optimize your AI models"	"The situation is fairly simple. **Your model could run 10 ti
mes faster** by adding a few lines to your code, but you wer
en't aware of it. Let me expand on that.

1. AI applications
 are multiplying like mushrooms, which is awesome
2. As a re
sult, more and more people are turning to the dark side, joi
ning the AI world, as I did
3. The problem? Developers focus
 only on AI, cleaning up datasets and training their models.
 Almost no one has a background in hardware, compilers, comp
uting, cloud, etc
4. The result? Developers spend a lot of h
ours improving the accuracy and performance of their softwar
e, and all their hard work risks being undone by the wrong c
hoice of hardware-software coupling

This problem bothered m
e for a long time, so with a couple of buddies at [Nebuly](h
ttps://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot 
of energy into an **open-source library** called **nebullvm*
* to make DL compiler technology accessible to any developer
, even for those who know nothing about hardware, as I did.


How does it work? It **speeds up your DL models by \~5-20x*
* by testing the best DL compilers out there and selecting t
he optimal one to best couple your AI model with your machin
e (GPU, CPU, etc.). All this in just a few lines of code.

T
he library is open source and you can find it here [https://
github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/
nebullvm).

Please leave a star on GitHub for the hard work 
in building the library :) It's a simple act for you, a big 
smile for us. Thank you, and don't hesitate to contribute to
 the library!"	"https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/"	"38"	"1645521383.0"	"271"	"syj7vx"
