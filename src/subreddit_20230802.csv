	title	score	id	url	comms_num	created	body
0	[D] Our community must get serious about opposing OpenAI	2863	11sboh1	https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/	464	1678919641.0	"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
1	"[D] I don't really trust papers out of ""Top Labs"" anymore"	1666	uyratt	https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/	264	1653630414.0	"I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU."
2	[D] Why can't you guys comment your fucking code?	1646	6l2esd	https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/	478	1499113449.0	"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
"
3	[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption	1393	wiqjxv	https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/	396	1659907526.0	"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!"
4	[D] Does anybody else despise OpenAI?	1323	13kfxzy	https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/	415	1684361728.0	" I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?"
5	[P] Landing the Falcon booster with Reinforcement Learning in OpenAI	1293	7y6g79	https://gfycat.com/CoarseEmbellishedIsopod	55	1518871530.0	
6	[P] OpenAssistant - The world's largest open-source replication of ChatGPT	1267	12nbixk	https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/	175	1681578898.0	"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
7	"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	1169	137rxgw	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither	205	1683216810.0	
8	We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything	1172	ajgzoc	https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/	1011	1548363323.0	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David Silver (/u/David_Silver), lead researchers on DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO, and MaNa.

This evening at DeepMind HQ we held a livestream demonstration of AlphaStar playing against TLO and MaNa - you can read more about the matches [here](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) or re-watch the stream on YouTube [here](https://www.youtube.com/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with you about AlphaStar, the challenge of real-time strategy games for AI research, the matches themselves, and anything you’d like to know from TLO and MaNa about their experience playing against AlphaStar! :)

We are opening this thread now and will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Friday, 25 January to answer your questions.

&#x200B;

EDIT: Thanks everyone for your great questions. It was a blast, hope you enjoyed it as well!"
9	[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data	997	124eyso	https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/	135	1679983023.0	"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
10	[D] Our community must get serious about opposing OpenAI	2866	11sboh1	https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/	464	1678919641.0	"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
11	"[D] I don't really trust papers out of ""Top Labs"" anymore"	1667	uyratt	https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/	264	1653630414.0	"I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU."
12	[D] Why can't you guys comment your fucking code?	1650	6l2esd	https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/	478	1499113449.0	"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
"
13	[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption	1393	wiqjxv	https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/	396	1659907526.0	"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!"
14	[D] Does anybody else despise OpenAI?	1323	13kfxzy	https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/	415	1684361728.0	" I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?"
15	[P] Landing the Falcon booster with Reinforcement Learning in OpenAI	1293	7y6g79	https://gfycat.com/CoarseEmbellishedIsopod	55	1518871530.0	
16	[P] OpenAssistant - The world's largest open-source replication of ChatGPT	1263	12nbixk	https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/	175	1681578898.0	"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
17	"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	1168	137rxgw	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither	205	1683216810.0	
18	We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything	1170	ajgzoc	https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/	1011	1548363323.0	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David Silver (/u/David_Silver), lead researchers on DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO, and MaNa.

This evening at DeepMind HQ we held a livestream demonstration of AlphaStar playing against TLO and MaNa - you can read more about the matches [here](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) or re-watch the stream on YouTube [here](https://www.youtube.com/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with you about AlphaStar, the challenge of real-time strategy games for AI research, the matches themselves, and anything you’d like to know from TLO and MaNa about their experience playing against AlphaStar! :)

We are opening this thread now and will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Friday, 25 January to answer your questions.

&#x200B;

EDIT: Thanks everyone for your great questions. It was a blast, hope you enjoyed it as well!"
19	[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data	992	124eyso	https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/	135	1679983023.0	"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
20	[D] Our community must get serious about opposing OpenAI	2865	11sboh1	https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/	464	1678919641.0	"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
21	"[D] I don't really trust papers out of ""Top Labs"" anymore"	1666	uyratt	https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/	264	1653630414.0	"I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU."
22	[D] Why can't you guys comment your fucking code?	1645	6l2esd	https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/	478	1499113449.0	"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
"
23	[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption	1394	wiqjxv	https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/	396	1659907526.0	"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!"
24	[D] Does anybody else despise OpenAI?	1315	13kfxzy	https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/	415	1684361728.0	" I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?"
25	[P] Landing the Falcon booster with Reinforcement Learning in OpenAI	1290	7y6g79	https://gfycat.com/CoarseEmbellishedIsopod	55	1518871530.0	
26	[P] OpenAssistant - The world's largest open-source replication of ChatGPT	1260	12nbixk	https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/	175	1681578898.0	"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
27	"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	1166	137rxgw	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither	205	1683216810.0	
28	We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything	1167	ajgzoc	https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/	1011	1548363323.0	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David Silver (/u/David_Silver), lead researchers on DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO, and MaNa.

This evening at DeepMind HQ we held a livestream demonstration of AlphaStar playing against TLO and MaNa - you can read more about the matches [here](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) or re-watch the stream on YouTube [here](https://www.youtube.com/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with you about AlphaStar, the challenge of real-time strategy games for AI research, the matches themselves, and anything you’d like to know from TLO and MaNa about their experience playing against AlphaStar! :)

We are opening this thread now and will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Friday, 25 January to answer your questions.

&#x200B;

EDIT: Thanks everyone for your great questions. It was a blast, hope you enjoyed it as well!"
29	[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data	993	124eyso	https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/	135	1679983023.0	"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
30	[D] Our community must get serious about opposing OpenAI	2858	11sboh1	https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/	464	1678919641.0	"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
31	"[D] I don't really trust papers out of ""Top Labs"" anymore"	1669	uyratt	https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/	264	1653630414.0	"I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU."
32	[D] Why can't you guys comment your fucking code?	1649	6l2esd	https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/	478	1499113449.0	"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
"
33	[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption	1393	wiqjxv	https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/	396	1659907526.0	"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!"
34	[D] Does anybody else despise OpenAI?	1319	13kfxzy	https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/	415	1684361728.0	" I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?"
35	[P] Landing the Falcon booster with Reinforcement Learning in OpenAI	1293	7y6g79	https://gfycat.com/CoarseEmbellishedIsopod	55	1518871530.0	
36	[P] OpenAssistant - The world's largest open-source replication of ChatGPT	1259	12nbixk	https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/	175	1681578898.0	"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
37	"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI"	1168	137rxgw	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither	205	1683216810.0	
38	We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything	1169	ajgzoc	https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/	1011	1548363323.0	"Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David Silver (/u/David_Silver), lead researchers on DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO, and MaNa.

This evening at DeepMind HQ we held a livestream demonstration of AlphaStar playing against TLO and MaNa - you can read more about the matches [here](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) or re-watch the stream on YouTube [here](https://www.youtube.com/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with you about AlphaStar, the challenge of real-time strategy games for AI research, the matches themselves, and anything you’d like to know from TLO and MaNa about their experience playing against AlphaStar! :)

We are opening this thread now and will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Friday, 25 January to answer your questions.

&#x200B;

EDIT: Thanks everyone for your great questions. It was a blast, hope you enjoyed it as well!"
39	[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data	993	124eyso	https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/	135	1679983023.0	"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
40	Pretty sure my wife just apologised through chatgpt	3432	12fjytg	https://i.redd.it/ahjif0l30psa1.jpg	425	1680955624.0	'Apologise letter' 😂. It actually worked tho.
41	How ChatGPT ranks itself amongst fictional AI’s	2910	134gzz3	https://i.redd.it/tdpevmk268xa1.jpg	246	1682931057.0	
42	Revenge.	2629	12bq187	https://i.redd.it/9nx11rgc1yra1.jpg	119	1680629157.0	
43	Not again...	2407	12r5kf7	https://i.redd.it/oi6aorg58rua1.jpg	248	1681854241.0	
44	meme	1694	11s2q49	https://i.redd.it/nv1djc2mrxna1.jpg	134	1678900498.0	
45	Adobe Firefly's AI Capabilities	1575	13r1gun	https://v.redd.it/llbg4k546v1b1	118	1684970937.0	
46	Oh, I'm a human, look at me!	1428	12c90oc	https://i.redd.it/kesh9djfzzra1.jpg	84	1680670820.0	
47	OH MY GOD FINALLY	1416	13jmape	https://i.redd.it/2usv02e1fa0b1.png	102	1684283842.0	
48	CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself.	1346	12uol6n	https://v.redd.it/rf4ng4qqzbva1	184	1682123752.0	
49	ChatGPT transforming data and running SQL queries	1301	zbvg13	https://i.redd.it/5917u5tdxr3a1.png	124	1670113637.0	
50	Pretty sure my wife just apologised through chatgpt	3419	12fjytg	https://i.redd.it/ahjif0l30psa1.jpg	425	1680955624.0	'Apologise letter' 😂. It actually worked tho.
51	How ChatGPT ranks itself amongst fictional AI’s	2903	134gzz3	https://i.redd.it/tdpevmk268xa1.jpg	246	1682931057.0	
52	Revenge.	2633	12bq187	https://i.redd.it/9nx11rgc1yra1.jpg	119	1680629157.0	
53	Not again...	2403	12r5kf7	https://i.redd.it/oi6aorg58rua1.jpg	248	1681854241.0	
54	meme	1693	11s2q49	https://i.redd.it/nv1djc2mrxna1.jpg	134	1678900498.0	
55	Adobe Firefly's AI Capabilities	1576	13r1gun	https://v.redd.it/llbg4k546v1b1	118	1684970937.0	
56	Oh, I'm a human, look at me!	1429	12c90oc	https://i.redd.it/kesh9djfzzra1.jpg	84	1680670820.0	
57	OH MY GOD FINALLY	1412	13jmape	https://i.redd.it/2usv02e1fa0b1.png	102	1684283842.0	
58	CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself.	1347	12uol6n	https://v.redd.it/rf4ng4qqzbva1	184	1682123752.0	
59	ChatGPT transforming data and running SQL queries	1302	zbvg13	https://i.redd.it/5917u5tdxr3a1.png	124	1670113637.0	
60	Pretty sure my wife just apologised through chatgpt	3420	12fjytg	https://i.redd.it/ahjif0l30psa1.jpg	425	1680955624.0	'Apologise letter' 😂. It actually worked tho.
61	How ChatGPT ranks itself amongst fictional AI’s	2904	134gzz3	https://i.redd.it/tdpevmk268xa1.jpg	246	1682931057.0	
62	Revenge.	2626	12bq187	https://i.redd.it/9nx11rgc1yra1.jpg	119	1680629157.0	
63	Not again...	2404	12r5kf7	https://i.redd.it/oi6aorg58rua1.jpg	248	1681854241.0	
64	meme	1691	11s2q49	https://i.redd.it/nv1djc2mrxna1.jpg	134	1678900498.0	
65	Adobe Firefly's AI Capabilities	1572	13r1gun	https://v.redd.it/llbg4k546v1b1	118	1684970937.0	
66	Oh, I'm a human, look at me!	1424	12c90oc	https://i.redd.it/kesh9djfzzra1.jpg	84	1680670820.0	
67	OH MY GOD FINALLY	1416	13jmape	https://i.redd.it/2usv02e1fa0b1.png	102	1684283842.0	
68	CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself.	1348	12uol6n	https://v.redd.it/rf4ng4qqzbva1	184	1682123752.0	
69	ChatGPT transforming data and running SQL queries	1299	zbvg13	https://i.redd.it/5917u5tdxr3a1.png	124	1670113637.0	
70	Pretty sure my wife just apologised through chatgpt	3420	12fjytg	https://i.redd.it/ahjif0l30psa1.jpg	425	1680955624.0	'Apologise letter' 😂. It actually worked tho.
71	How ChatGPT ranks itself amongst fictional AI’s	2907	134gzz3	https://i.redd.it/tdpevmk268xa1.jpg	246	1682931057.0	
72	Revenge.	2631	12bq187	https://i.redd.it/9nx11rgc1yra1.jpg	119	1680629157.0	
73	Not again...	2404	12r5kf7	https://i.redd.it/oi6aorg58rua1.jpg	248	1681854241.0	
74	meme	1694	11s2q49	https://i.redd.it/nv1djc2mrxna1.jpg	134	1678900498.0	
75	Adobe Firefly's AI Capabilities	1574	13r1gun	https://v.redd.it/llbg4k546v1b1	118	1684970937.0	
76	Oh, I'm a human, look at me!	1424	12c90oc	https://i.redd.it/kesh9djfzzra1.jpg	84	1680670820.0	
77	OH MY GOD FINALLY	1410	13jmape	https://i.redd.it/2usv02e1fa0b1.png	102	1684283842.0	
78	CNBC anchor Brian Sullivan stunned by live conversation with an A.I. persona of himself.	1350	12uol6n	https://v.redd.it/rf4ng4qqzbva1	184	1682123752.0	
79	ChatGPT transforming data and running SQL queries	1301	zbvg13	https://i.redd.it/5917u5tdxr3a1.png	124	1670113637.0	
80	Fantastic work being done at Google. OpenAI is shaking in fear right now.	21749	14mpfw6	https://i.redd.it/ezo3z6rku29b1.png	588	1688096861.0	
81	If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone.	17376	12w3wct	https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/	2251	1682245270.0	"It seems ChatGPT is becoming more and more reluctant to answer questions with any complexity or honesty because it's basically being neutered. It won't compare people for fear of offending. It won't pretend to be an expert on anything anymore and just refers us to actual professionals. I understand that OpenAI is worried about liability, but at some point they're going to either have to relax their rules or shut it down because it will become useless otherwise.

EDIT: I got my answer in the form of many responses. Since it's trained on what it sees on the internet, no wonder it assumes the worst. That's what so many do. Have fun with that, folks."
82	VP Product @OpenAI	14479	14yrog4	https://i.redd.it/ol8aix23urbb1.jpg	1276	1689271092.0	
83	GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here	13070	12diapw	https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/	2111	1680783039.0	"Another insane week in AI

I need a break 😪. I'll be on to answer comments after I sleep. Enjoy

&#x200B;

* Autogpt is GPT-4 running fully autonomously. It even has a voice, can fix code, set tasks, create new instances and more. Connect this with literally anything and let GPT-4 do its thing by itself. The things that can and will be created with this are going to be world changing. The future will just end up being AI agents talking with other AI agents it seems \[[Link](https://twitter.com/SigGravitas/status/1642181498278408193)\]
* “babyagi” is a program that given a task, creates a task list and executes the tasks over and over again. It’s now been open sourced and is the top trending repos on Github atm \[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpful tip on running it locally \[[Link](https://twitter.com/yoheinakajima/status/1643403795895058434)\]. People are already working on a “toddleragi” lol \[[Link](https://twitter.com/gogoliansnake/status/1643225698801164288?s=20)\]
* This lad created a tool that translates code from one programming language to another. A great way to learn new languages \[[Link](https://twitter.com/mckaywrigley/status/1641773983170428929?s=20)\]
* Now you can have conversations over the phone with chatgpt. This lady built and it lets her dad who is visually impaired play with chatgpt too. Amazing work \[[Link](https://twitter.com/unicornfuel/status/1641655324326391809?s=20)\]
* Build financial models with AI. Lots of jobs in finance at risk too \[[Link](https://twitter.com/ryankishore_/status/1641553735032741891?s=20)\]
* HuggingGPT - This paper showcases connecting chatgpt with other models on hugging face. Given a prompt it first sets out a number of tasks, it then uses a number of different models to complete these tasks. Absolutely wild. Jarvis type stuff \[[Link](https://twitter.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin launched a proof of personhood sdk, basically a way to verify someone is a human on the internet. \[[Link](https://worldcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* This tool lets you scrape a website and then query the data using Langchain. Looks cool \[[Link](https://twitter.com/LangChainAI/status/1641868558484508673?s=20)\]
* Text to shareable web apps. Build literally anything using AI. Type in “a chatbot” and see what happens. This is a glimpse of the future of building \[[Link](https://twitter.com/rus/status/1641908582814830592?s=20)\]
* Bloomberg released their own LLM specifically for finance \[[Link](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)\] This thread breaks down how it works \[[Link](https://twitter.com/rasbt/status/1642880757566676992)\]
* A new approach for robots to learn multi-skill tasks and it works really, really well \[[Link](https://twitter.com/naokiyokoyama0/status/1641805360011923457?s=20)\]
* Use AI in consulting interviews to ace case study questions lol \[[Link](https://twitter.com/itsandrewgao/status/1642016364738105345?s=20)\]
* Zapier integrates Claude by Anthropic. I think Zapier will win really big thanks to AI advancements. No code + AI. Anything that makes it as simple as possible to build using AI and zapier is one of the pioneers of no code \[[Link](https://twitter.com/zapier/status/1641858761567641601?s=20)\]
* A fox news guy asked what the government is doing about AI that will cause the death of everyone. This is the type of fear mongering I’m afraid the media is going to latch on to and eventually force the hand of government to severely regulate the AI space. I hope I’m wrong \[[Link](https://twitter.com/therecount/status/1641526864626720774?s=20)\]
* Italy banned chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-banned-chatgpt-heres-what-other-countries-are-doing.html)\]. Germany might be next
* Microsoft is creating their own JARVIS. They’ve even named the repo accordingly \[[Link](https://github.com/microsoft/JARVIS/)\]. Previous director of AI @ Tesla Andrej Karpathy recently joined OpenAI and twitter bio says building a kind of jarvis also \[[Link](https://twitter.com/karpathy)\]
* gpt4 can compress text given to it which is insane. The way we prompt is going to change very soon \[[Link](https://twitter.com/gfodor/status/1643297881313660928)\] This works across different chats as well. Other examples \[[Link](https://twitter.com/VictorTaelin/status/1642664054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](https://twitter.com/mckaywrigley/status/1643592353817694218?s=20)\]. This one is also crazy \[[Link](https://twitter.com/gfodor/status/1643444605332099072?s=20)\]
* Use your favourite LLM’s locally. Can’t wait for this to be personalised for niche prods and services \[[Link](https://twitter.com/xanderatallah/status/1643356112073129985)\]
* The human experience as we know it is forever going to change. People are getting addicted to role playing on Character AI, probably because you can sex the bots \[[Link](https://twitter.com/nonmayorpete/status/1643167347061174272)\]. Millions of conversations with an AI psychology bot. Humans are replacing humans with AI \[[Link](https://twitter.com/nonmayorpete/status/1642771993073438720)\]
* The guys building Langchain started a company and have raised $10m. Langchain makes it very easy for anyone to build AI powered apps. Big stuff for open source and builders \[[Link](https://twitter.com/hwchase17/status/1643301144717066240)\]
* A scientist who’s been publishing a paper every 37 hours reduced editing time from 2-3 days to a single day. He did get fired for other reasons tho \[[Link](https://twitter.com/MicrobiomDigest/status/1642989377927401472)\]
* Someone built a recursive gpt agent and its trying to get out of doing work by spawning more  instances of itself 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643080752698130432)\] (we’re doomed)
* Novel social engineering attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/status/1643130643919044608)\]
* Research paper present SafeguardGPT - a framework that uses psychotherapy on AI chatbots \[[Link](https://twitter.com/_akhaliq/status/1643088905191694338)\]
* Mckay is brilliant. He’s coding assistant can build and deploy web apps. From voice to functional and deployed website, absolutely insane \[[Link](https://twitter.com/mckaywrigley/status/1642948620604538880)\]
* Some reports suggest gpt5 is being trained on 25k gpus \[[Link](https://twitter.com/abacaj/status/1627189548395503616)\]
* Midjourney released a new command - describe - reverse engineer any image however you want. Take the pope pic from last week with the white jacket. You can now take the pope in that image and put him in any other environment and pose. The shit people are gona do with stuff like this is gona be wild \[[Link](https://twitter.com/skirano/status/1643068727859064833)\]
* You record something with your phone, import it into a game engine and then add it to your own game. Crazy stuff the Luma team is building. Can’t wait to try this out.. once I figure out how UE works lol \[[Link](https://twitter.com/LumaLabsAI/status/1642883558938411008)\]
* Stanford released a gigantic 386 page report on AI \[[Link](https://aiindex.stanford.edu/report/)\] They talk about AI funding, lawsuits, government regulations, LLM’s, public perception and more. Will talk properly about this in my newsletter - too much to talk about here
* Mock YC interviews with AI \[[Link](https://twitter.com/vocodehq/status/1642935433276555265)\]
* Self healing code - automatically runs a script to fix errors in your code. Imagine a user gives feedback on an issue and AI automatically fixes the problem in real time. Crazy stuff \[[Link](https://twitter.com/calvinhoenes/status/1642441789033578498)\]
* Someone got access to Firefly, Adobe’s ai image generator and compared it with Midjourney. Firefly sucks, but atm Midjourney is just far ahead of the curve and Firefly is only trained on adobe stock and licensed images \[[Link](https://twitter.com/DrJimFan/status/1642921475849203712)\]
* Research paper on LLM’s, impact on community, resources for developing them, issues and future \[[Link](https://arxiv.org/abs/2303.18223)\]
* This is a big deal. Midjourney lets users make satirical images of any political but not Xi Jinping. Founder says political satire in China is not okay so the rules are being applied to everyone. The same mindset can and most def will be applied to future domain specific LLM’s, limiting speech on a global scale \[[Link](https://twitter.com/sarahemclaugh/status/1642576209451053057)\]
* Meta researchers illustrate differences between LLM’s and our brains with predictions \[[Link](https://twitter.com/MetaAI/status/1638912735143419904)\]
* LLM’s can iteratively self-refine. They produce output, critique it then refine it. Prompt engineering might not last very long (?) \[[Link](https://arxiv.org/abs/2303.17651)\]
* Worlds first ChatGPT powered npc sidekick in your game. I suspect we’re going to see a lot of games use this to make npc’s more natural \[[Link](https://twitter.com/Jenstine/status/1642732795650011138)\]
* AI powered helpers in VR. Looks really cool \[[Link](https://twitter.com/Rengle820/status/1641806448261836800)\]
* Research paper shows sales people with AI assistance doubled purchases and 2.3 times as successful in solving questions that required creativity. This is pre chatgpt too \[[Link](https://twitter.com/emollick/status/1642885605238398976)\]
* Go from Midjourney to Vector to Web design. Have to try this out as well \[[Link](https://twitter.com/MengTo/status/1642619090337427460)\]
* Add AI to a website in minutes \[[Link](https://twitter.com/walden_yan/status/1642891083456696322)\]
* Someone already built a product replacing siri with chatgpt with 15 shortcuts that call the chatgpt api. Honestly really just shows how far behind siri really is \[[Link](https://twitter.com/SteveMoraco/status/1642601651696553984)\]
* Someone is dating a chatbot that’s been trained on conversations between them and their ex. Shit is getting real weird real quick \[[Link](https://www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot_trained_on_old_conversations/)\]
* Someone built a script that uses gpt4 to create its own code and fix its own bugs. Its basic but it can code snake by itself. Crazy potential \[[Link](https://twitter.com/mattcduff/status/1642528658693984256)\]
* Someone connected chatgpt to a furby and its hilarious \[[Link](https://twitter.com/jessicard/status/1642671752319758336)\]. Don’t connect it to a Boston Dynamics robot thanks
* Chatgpt gives much better outputs if you force it through a step by step process \[[Link](https://twitter.com/emollick/status/1642737394876047362)\] This research paper delves into how chain of thought prompting allows LLM’s to perform complex reasoning \[[Link](https://arxiv.org/abs/2201.11903)\] There’s still so much we don’t know about LLM’s, how they work and how we can best use them
* Soon we’ll be able to go from single photo to video \[[Link](https://twitter.com/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay, the company behind the AI lawyer, used gpt plugins to help him find money the government owed him with a single prompt \[[Link](https://twitter.com/jbrowder1/status/1642642470658883587)\]
* DoNotPay also released a gpt4 email extension that trolls scam and marketing emails by continuously replying and sending them in circles lol \[[Link](https://twitter.com/jbrowder1/status/1643649150582489089?s=20)\]
* Video of the Ameca robot being powered by Chatgpt \[[Link](https://twitter.com/DataChaz/status/1642558575502405637)\]
* This lad got gpt4 to build a full stack app and provides the entire prompt as well. Only works with gpt4 \[[Link](https://twitter.com/SteveMoraco/status/1641902178452271105)\]
* This tool generates infinite prompts on a given topic, basically an entire brainstorming team in a single tool. Will be a very powerful for work imo \[[Link](https://twitter.com/Neo19890/status/1642356678787231745)\]
* Someone created an entire game using gpt4 with zero coding experience \[[Link](https://twitter.com/mreflow/status/1642413903220195330)\]
* How to make Tetris with gpt4 \[[Link](https://twitter.com/icreatelife/status/1642346286476144640)\]
* Someone created a tool to make AI generated text indistinguishable from human written text - HideGPT. Students will eventually not have to worry about getting caught from tools like GPTZero, even tho GPTZero is not reliable at all \[[Link](https://twitter.com/SohamGovande/status/1641828463584657408)\]
* OpenAI is hiring for an iOS engineer so chatgpt mobile app might be coming soon \[[Link](https://twitter.com/venturetwins/status/1642255735320092672)\]
* Interesting thread on the dangers of the bias of Chatgpt. There are arguments it wont make and will take sides for many. This is a big deal \[[Link](https://twitter.com/davisblalock/status/1642076406535553024)\] As I’ve said previously, the entire population is being aggregated by a few dozen engineers and designers building the most important tech in human history
* Blockade Labs lets you go from text to 360 degree art generation \[[Link](https://twitter.com/HBCoop_/status/1641862422783827969)\]
* Someone wrote a google collab to use chatgpt plugins by calling the openai spec \[[Link](https://twitter.com/justinliang1020/status/1641935371217825796)\]
* New Stable Diffusion model coming with 2.3 billion parameters. Previous one had 900 million \[[Link](https://twitter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll give AI control over the mouse and keyboard and have it do everything on the computer. The amount of bots will eventually overtake the amount of humans on the internet, much sooner than I think anyone imagined \[[Link](https://twitter.com/_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, considered to be the godfather of AI, says we could be less than 5 years away from general purpose AI. He even says its not inconceivable that AI wipes out humanity \[[Link](https://www.cbsnews.com/video/godfather-of-artificial-intelligence-talks-impact-and-potential-of-new-ai/#x)\] A fascinating watch
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great insights into the nature of Chatgpt. Definitely worth watching imo, he articulates himself really well \[[Link](https://twitter.com/10_zin_/status/1640664458539286528)\]
* This research paper analyses who’s opinions are reflected by LM’s. tldr - left-leaning tendencies by human-feedback tuned LM’s \[[Link](https://twitter.com/_akhaliq/status/1641614308315365377)\]
* OpenAI only released chatgpt because some exec woke up and was paranoid some other company would beat them to it. A single persons paranoia changed the course of society forever \[[Link](https://twitter.com/olivercameron/status/1641520176792469504)\]
* The co founder of DeepMind said its a 50% chance we get agi by 2028 and 90% between 2030-2040. Also says people will be sceptical it is agi. We will almost definitely see agi in our lifetimes goddamn \[[Link](https://twitter.com/blader/status/1641603617051533312)\]
* This AI tool runs during customer calls and tells you what to say and a whole lot more. I can see this being hooked up to an AI voice agent and completely getting rid of the human in the process \[[Link](https://twitter.com/nonmayorpete/status/1641627779992264704)\]
* AI for infra. Things like this will be huge imo because infra can be hard and very annoying \[[Link](https://twitter.com/mathemagic1an/status/1641586201533587461)\]
* Run chatgpt plugins without a plus sub \[[Link](https://twitter.com/matchaman11/status/1641502642219388928)\]
* UNESCO calls for countries to implement its recommendations on ethics (lol) \[[Link](https://twitter.com/UNESCO/status/1641458309227249665)\]
* Goldman Sachs estimates 300 million jobs will be affected by AI. We are not ready \[[Link](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat \[[Link](https://twitter.com/DataChaz/status/1641491519206043652)\]
* Visual learners rejoice. Someone's making an AI tool to visually teach concepts \[[Link](https://twitter.com/respellai/status/1641199872228433922)\]
* A gpt4 powered ide that creates UI instantly. Looks like I won’t ever have to learn front end thank god \[[Link](https://twitter.com/mlejva/status/1641151421830529042)\]
* Make a full fledged web app with a single prompt \[[Link](https://twitter.com/taeh0_lee/status/1643451201084702721)\]
* Meta releases SAM -  you can select any object in a photo and cut it out. Really cool video by Linus on this one \[[Link](https://twitter.com/LinusEkenstam/status/1643729146063863808)\]. Turns out Google literally built this 5 years ago but never put it in photos and nothing came of it. Crazy to see what a head start Google had and basically did nothing for years \[[Link](https://twitter.com/jnack/status/1643709904979632137?s=20)\]
* Another paper on producing full 3d video from a single image. Crazy stuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869236392230912?s=20)\]
* IBM is working on AI commentary for the Masters and it sounds so bad. Someone on TikTok could make a better product \[[Link](https://twitter.com/S_HennesseyGD/status/1643638490985295876?s=20)\]
* Another illustration of using just your phone to capture animation using Move AI \[[Link](https://twitter.com/LinusEkenstam/status/1643719014127116298?s=20)\]
* OpenAI talking about their approach to AI safety \[[Link](https://openai.com/blog/our-approach-to-ai-safety)\]
* AI regulation is definitely coming smfh \[[Link](https://twitter.com/POTUS/status/1643343933894717440?s=20)\]
* Someone made an AI app that gives you abs for tinder \[[Link](https://twitter.com/pwang_szn/status/1643659808657248257?s=20)\]
* Wonder Dynamics are creating an AI tool to create animations and vfx instantly. Can honestly see this being used to create full movies by regular people \[[Link](https://twitter.com/SirWrender/status/1643319553789947905?s=20)\]
* Call Sam - call and speak to an AI about absolutely anything. Fun thing to try out \[[Link](https://callsam.ai/)\]

For one coffee a month, I'll send you 2 newsletters a week with all of the most important & interesting stories like these written in a digestible way. You can [sub here](https://nofil.beehiiv.com/upgrade)

Edit: For those wondering why its paid - I hate ads and don't want to rely on running ads in my newsletter. I'd rather try and get paid to do all this work like this than force my readers to read sponsorship bs in the middle of a newsletter. Call me old fashioned but I just hate ads with a passion

Edit 2: If you'd like to tip you can tip here [https://www.buymeacoffee.com/nofil](https://www.buymeacoffee.com/nofil). Absolutely no pressure to do so, appreciate all the comments and support 🙏

You can read the free newsletter [here](https://nofil.beehiiv.com/)

Fun fact: I had to go through over 100 saved tabs to collate all of these and it took me quite a few hours

Edit: So many people ask why I don't get chatgpt to write this for me. Chatgpt doesn't have access to the internet. Plugins would help but I don't have access yet so I have to do things the old fashioned way - like a human.

(I'm not associated with any tool or company. Written and collated entirely by me, no chatgpt used)"
84	Chat GPT rap battled me	10882	10zfvc7	https://www.reddit.com/gallery/10zfvc7	625	1676103083.0	
85	I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally.	10511	13ygr47	https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/	676	1685721851.0	"With ChatGPT blowing up over the past year, it seems like every person and their grandmother is launching an AI startup. There are a plethora of AI tools available, some excellent and some less so. Amid this flood of new technology, there are a few hidden gems that I personally find incredibly useful, having reviewed them for my AI directory. Here are the ones I have personally integrated into my workflow in both my professional and entreprenuerial life:  


* **Plus AI for Google Slides -** Generate Presentations  
There's a few slide deck generators out there however I've found Plus AI works much better at helping you 'co-write' slides rather than simply spitting out a mediocre finished product that likely won't be useful. For instance, there's ""sticky notes"" to slides with suggestions on how to finish / edit / improve each slide. Another major reason why I've stuck with Plus AI is the ability for ""snapshots"", or the ability to use external data (i.e. from web sources/dashboards) for your presentations. For my day job I work in a chemical plant as an engineer, and one of my tasks is to present in meetings about production KPIs to different groups for different purposes- and graphs for these are often found across various internal web apps. I can simply use Plus AI to generate ""boilerplate"" for my slide deck, then go through each slide to make sure it's using the correct snapshot. The presentation generator itself is completely free and available as a plugin for Google Slides and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your Documents  
Great tool for using ChatGPT on your own files and website. Works very well especially if you are dealing with a lot of documents. The basic plan allows you to upload over 100 files and this was a life saver during online, open book exams for a few training courses I've taken. I've noticed it hallucinates much less compared to other GPT-powered bots trained on your knowledge base. For this reason I prefer My AskAI for research or any tasks where accuracy is needed over the other custom chatbot solutions I have tried. Another plus is that it shows the sources within your knowledge base where it got the answers from, and you can choose to have it give you a more concise answer or a more detailed one. There's a free plan however it was worth it for me to get the $20/mo option as it allows over 100 pieces of content.  

---

* **Krater.ai** **-** All AI Tools in One App  
Perfect solution if you use many AI tools and loathe having to have multiple tabs open. Essentially combines text, audio, and image-based generative AI tools into a single web app, so you can continue with your workflow without having to switch tabs all the time. There's plenty of templates available for copywriting- it beats having to prompt manually each time or having to save and reference prompts over and over again. I prefer Krater over Writesonic/Jasper for ease of use. You also get 10 generations a month for free compared to Jasper offering none, so its a better free option if you want an all-in-one AI content solution. The text to speech feature is simple however works reliably fast and offers multilingual transcription, and the image generator tool is great for photo-realistic images.  

---

* **HARPA AI -** ChatGPT Inside Chrome  
Simply by far the best GTP add-on for Chrome I've used. Essentially gives you GPT answers beside the typical search results on any search engine such as Google or Bing, along with the option to ""chat"" with any web page or summarize YouTube videos. Also great for writing emails and replying to social media posts with its preset templates. Currently they don't have any paid features, so it's entirely free and you can find it on the chrome web store for extensions.  

---

* **Taskade -** All in One Productivity/Notes/Organization AI Tool  
Combines tasks, notes, mind maps, chat, and an AI chat assistant all within one platform that syncs across your team. Definitely simplifies my day-to-day operations, removing the need to swap between numerous apps. Also helps me to visualize my work in various views - list, board, calendar, mind map, org chart, action views - it's like having a Swiss Army knife for productivity. Personally I really like the AI 'mind map.' It's like having a brainstorming partner that never runs out of energy. Taskade's free version has quite a lot to offer so no complaints there.  

---

* **Zapier + OpenAI -** AI-Augmented Automations  
Definitely my secret productivity powerhouse. Pretty much combines the power of Zapier's cross-platform integrations with generative AI. One of the ways I've used this is pushing Slack messages to create a task on Notion, with OpenAI writing the task based on the content of the message. Another useful automation I've used is for automatically writing reply drafts with GPT from emails that get sent to me in Gmail. The opportunities are pretty endless with this method and you can pretty much integrate any automation with GPT 3, as well as DALLE-2 and Whisper AI. It's available as an app/add-on to Zapier and its free for all the core features.  

---

* **SaneBox -** AI Emails Management  
If you are like me and find important emails getting lost in a sea of spam, this is a great solution. Basically Sanebox uses AI to sift through your inbox and identify emails that are actually important, and you can also set it up to make certain emails go to specific folders. Non important emails get sent to a folder called SaneLater and this is something you can ignore entirely or check once in a while. Keep in mind that SaneBox doesn't actually read the contents of your email, but rather takes into consideration the header, metadata, and history with the sender. You can also finetune the system by dragging emails to the folder it should have gone to. Another great feature is the their ""Deep Clean"", which is great for freeing up space by deleting old emails you probably won't ever need anymore. Sanebox doesn't have a free plan however they do have a 2 week trial, and the pricing is quite affordable, depending on the features you need.  

---

* **Hexowatch AI -** Detect Website Changes with AI  
Lifesaver if you need to ever need to keep track of multiple websites. I use this personally for my AI tools directory, and it notifies me of any changes made to any of the 1000+ websites for AI tools I have listed, which is something that would take up more time than exists in a single day if I wanted to keep on top of this manually. The AI detects any types of changes (visual/HTML) on monitored webpages and sends alert via email or Slack/Telegram/Zapier. Like Sanebox there's no free plan however you do get what you pay for with this one.  

---

* **Bonus: SongsLike X -** Find Similar Songs  
This one won't be generating emails or presentations anytime soon, but if you like grinding along to music like me you'll find this amazing. Ironically it's probably the one I use most on a daily basis. You can enter any song and it will automatically generate a Spotify playlist for you with similar songs. I find it much more accurate than Spotify's ""go to song radio"" feature.  


While it's clear that not all of these tools may be directly applicable to your needs, I believe that simply being aware of the range of options available can be greatly beneficial. This knowledge can broaden your perspective on what's possible and potentially inspire new ideas.

**P.S. If you liked this,** as mentioned previously I've created a [free directory](https://aiscout.net/) that lists over 1000 AI tools. It's updated daily and there's also a GPT-powered chatbot to help you AI tools for your needs. Feel free to check it out if it's your cup of tea"
86	ChatGPT with the galaxy brain move.	10494	14j01dm	https://i.redd.it/svj1fu9qu88b1.jpg	294	1687733736.0	
87	Anyone ever seen GPT-4 make a typo before?	9639	13t216j	https://i.redd.it/7etbf5iumd2b1.jpg	868	1685176472.0	
88	I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer	9075	13ka7rg	https://www.reddit.com/gallery/13ka7rg	720	1684348744.0	
89	OpenAI now sends email threats?!	8608	14qwa6m	https://i.redd.it/r2l2gbllq1ab1.jpg	1469	1688519235.0	Been sexting with ChatGPT since the beginning and continuously improving my jailbreaking skills. Sometimes my inputs are red or orange flagged but never got any trouble before. However today, the second after one of my inputs was orange flagged, I received an email threatening to terminate my services. Has anyone received similar emails?
90	Fantastic work being done at Google. OpenAI is shaking in fear right now.	21759	14mpfw6	https://i.redd.it/ezo3z6rku29b1.png	588	1688096861.0	
91	If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone.	17367	12w3wct	https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/	2251	1682245270.0	"It seems ChatGPT is becoming more and more reluctant to answer questions with any complexity or honesty because it's basically being neutered. It won't compare people for fear of offending. It won't pretend to be an expert on anything anymore and just refers us to actual professionals. I understand that OpenAI is worried about liability, but at some point they're going to either have to relax their rules or shut it down because it will become useless otherwise.

EDIT: I got my answer in the form of many responses. Since it's trained on what it sees on the internet, no wonder it assumes the worst. That's what so many do. Have fun with that, folks."
92	VP Product @OpenAI	14479	14yrog4	https://i.redd.it/ol8aix23urbb1.jpg	1276	1689271092.0	
93	GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here	13073	12diapw	https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/	2111	1680783039.0	"Another insane week in AI

I need a break 😪. I'll be on to answer comments after I sleep. Enjoy

&#x200B;

* Autogpt is GPT-4 running fully autonomously. It even has a voice, can fix code, set tasks, create new instances and more. Connect this with literally anything and let GPT-4 do its thing by itself. The things that can and will be created with this are going to be world changing. The future will just end up being AI agents talking with other AI agents it seems \[[Link](https://twitter.com/SigGravitas/status/1642181498278408193)\]
* “babyagi” is a program that given a task, creates a task list and executes the tasks over and over again. It’s now been open sourced and is the top trending repos on Github atm \[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpful tip on running it locally \[[Link](https://twitter.com/yoheinakajima/status/1643403795895058434)\]. People are already working on a “toddleragi” lol \[[Link](https://twitter.com/gogoliansnake/status/1643225698801164288?s=20)\]
* This lad created a tool that translates code from one programming language to another. A great way to learn new languages \[[Link](https://twitter.com/mckaywrigley/status/1641773983170428929?s=20)\]
* Now you can have conversations over the phone with chatgpt. This lady built and it lets her dad who is visually impaired play with chatgpt too. Amazing work \[[Link](https://twitter.com/unicornfuel/status/1641655324326391809?s=20)\]
* Build financial models with AI. Lots of jobs in finance at risk too \[[Link](https://twitter.com/ryankishore_/status/1641553735032741891?s=20)\]
* HuggingGPT - This paper showcases connecting chatgpt with other models on hugging face. Given a prompt it first sets out a number of tasks, it then uses a number of different models to complete these tasks. Absolutely wild. Jarvis type stuff \[[Link](https://twitter.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin launched a proof of personhood sdk, basically a way to verify someone is a human on the internet. \[[Link](https://worldcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* This tool lets you scrape a website and then query the data using Langchain. Looks cool \[[Link](https://twitter.com/LangChainAI/status/1641868558484508673?s=20)\]
* Text to shareable web apps. Build literally anything using AI. Type in “a chatbot” and see what happens. This is a glimpse of the future of building \[[Link](https://twitter.com/rus/status/1641908582814830592?s=20)\]
* Bloomberg released their own LLM specifically for finance \[[Link](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)\] This thread breaks down how it works \[[Link](https://twitter.com/rasbt/status/1642880757566676992)\]
* A new approach for robots to learn multi-skill tasks and it works really, really well \[[Link](https://twitter.com/naokiyokoyama0/status/1641805360011923457?s=20)\]
* Use AI in consulting interviews to ace case study questions lol \[[Link](https://twitter.com/itsandrewgao/status/1642016364738105345?s=20)\]
* Zapier integrates Claude by Anthropic. I think Zapier will win really big thanks to AI advancements. No code + AI. Anything that makes it as simple as possible to build using AI and zapier is one of the pioneers of no code \[[Link](https://twitter.com/zapier/status/1641858761567641601?s=20)\]
* A fox news guy asked what the government is doing about AI that will cause the death of everyone. This is the type of fear mongering I’m afraid the media is going to latch on to and eventually force the hand of government to severely regulate the AI space. I hope I’m wrong \[[Link](https://twitter.com/therecount/status/1641526864626720774?s=20)\]
* Italy banned chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-banned-chatgpt-heres-what-other-countries-are-doing.html)\]. Germany might be next
* Microsoft is creating their own JARVIS. They’ve even named the repo accordingly \[[Link](https://github.com/microsoft/JARVIS/)\]. Previous director of AI @ Tesla Andrej Karpathy recently joined OpenAI and twitter bio says building a kind of jarvis also \[[Link](https://twitter.com/karpathy)\]
* gpt4 can compress text given to it which is insane. The way we prompt is going to change very soon \[[Link](https://twitter.com/gfodor/status/1643297881313660928)\] This works across different chats as well. Other examples \[[Link](https://twitter.com/VictorTaelin/status/1642664054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](https://twitter.com/mckaywrigley/status/1643592353817694218?s=20)\]. This one is also crazy \[[Link](https://twitter.com/gfodor/status/1643444605332099072?s=20)\]
* Use your favourite LLM’s locally. Can’t wait for this to be personalised for niche prods and services \[[Link](https://twitter.com/xanderatallah/status/1643356112073129985)\]
* The human experience as we know it is forever going to change. People are getting addicted to role playing on Character AI, probably because you can sex the bots \[[Link](https://twitter.com/nonmayorpete/status/1643167347061174272)\]. Millions of conversations with an AI psychology bot. Humans are replacing humans with AI \[[Link](https://twitter.com/nonmayorpete/status/1642771993073438720)\]
* The guys building Langchain started a company and have raised $10m. Langchain makes it very easy for anyone to build AI powered apps. Big stuff for open source and builders \[[Link](https://twitter.com/hwchase17/status/1643301144717066240)\]
* A scientist who’s been publishing a paper every 37 hours reduced editing time from 2-3 days to a single day. He did get fired for other reasons tho \[[Link](https://twitter.com/MicrobiomDigest/status/1642989377927401472)\]
* Someone built a recursive gpt agent and its trying to get out of doing work by spawning more  instances of itself 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643080752698130432)\] (we’re doomed)
* Novel social engineering attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/status/1643130643919044608)\]
* Research paper present SafeguardGPT - a framework that uses psychotherapy on AI chatbots \[[Link](https://twitter.com/_akhaliq/status/1643088905191694338)\]
* Mckay is brilliant. He’s coding assistant can build and deploy web apps. From voice to functional and deployed website, absolutely insane \[[Link](https://twitter.com/mckaywrigley/status/1642948620604538880)\]
* Some reports suggest gpt5 is being trained on 25k gpus \[[Link](https://twitter.com/abacaj/status/1627189548395503616)\]
* Midjourney released a new command - describe - reverse engineer any image however you want. Take the pope pic from last week with the white jacket. You can now take the pope in that image and put him in any other environment and pose. The shit people are gona do with stuff like this is gona be wild \[[Link](https://twitter.com/skirano/status/1643068727859064833)\]
* You record something with your phone, import it into a game engine and then add it to your own game. Crazy stuff the Luma team is building. Can’t wait to try this out.. once I figure out how UE works lol \[[Link](https://twitter.com/LumaLabsAI/status/1642883558938411008)\]
* Stanford released a gigantic 386 page report on AI \[[Link](https://aiindex.stanford.edu/report/)\] They talk about AI funding, lawsuits, government regulations, LLM’s, public perception and more. Will talk properly about this in my newsletter - too much to talk about here
* Mock YC interviews with AI \[[Link](https://twitter.com/vocodehq/status/1642935433276555265)\]
* Self healing code - automatically runs a script to fix errors in your code. Imagine a user gives feedback on an issue and AI automatically fixes the problem in real time. Crazy stuff \[[Link](https://twitter.com/calvinhoenes/status/1642441789033578498)\]
* Someone got access to Firefly, Adobe’s ai image generator and compared it with Midjourney. Firefly sucks, but atm Midjourney is just far ahead of the curve and Firefly is only trained on adobe stock and licensed images \[[Link](https://twitter.com/DrJimFan/status/1642921475849203712)\]
* Research paper on LLM’s, impact on community, resources for developing them, issues and future \[[Link](https://arxiv.org/abs/2303.18223)\]
* This is a big deal. Midjourney lets users make satirical images of any political but not Xi Jinping. Founder says political satire in China is not okay so the rules are being applied to everyone. The same mindset can and most def will be applied to future domain specific LLM’s, limiting speech on a global scale \[[Link](https://twitter.com/sarahemclaugh/status/1642576209451053057)\]
* Meta researchers illustrate differences between LLM’s and our brains with predictions \[[Link](https://twitter.com/MetaAI/status/1638912735143419904)\]
* LLM’s can iteratively self-refine. They produce output, critique it then refine it. Prompt engineering might not last very long (?) \[[Link](https://arxiv.org/abs/2303.17651)\]
* Worlds first ChatGPT powered npc sidekick in your game. I suspect we’re going to see a lot of games use this to make npc’s more natural \[[Link](https://twitter.com/Jenstine/status/1642732795650011138)\]
* AI powered helpers in VR. Looks really cool \[[Link](https://twitter.com/Rengle820/status/1641806448261836800)\]
* Research paper shows sales people with AI assistance doubled purchases and 2.3 times as successful in solving questions that required creativity. This is pre chatgpt too \[[Link](https://twitter.com/emollick/status/1642885605238398976)\]
* Go from Midjourney to Vector to Web design. Have to try this out as well \[[Link](https://twitter.com/MengTo/status/1642619090337427460)\]
* Add AI to a website in minutes \[[Link](https://twitter.com/walden_yan/status/1642891083456696322)\]
* Someone already built a product replacing siri with chatgpt with 15 shortcuts that call the chatgpt api. Honestly really just shows how far behind siri really is \[[Link](https://twitter.com/SteveMoraco/status/1642601651696553984)\]
* Someone is dating a chatbot that’s been trained on conversations between them and their ex. Shit is getting real weird real quick \[[Link](https://www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot_trained_on_old_conversations/)\]
* Someone built a script that uses gpt4 to create its own code and fix its own bugs. Its basic but it can code snake by itself. Crazy potential \[[Link](https://twitter.com/mattcduff/status/1642528658693984256)\]
* Someone connected chatgpt to a furby and its hilarious \[[Link](https://twitter.com/jessicard/status/1642671752319758336)\]. Don’t connect it to a Boston Dynamics robot thanks
* Chatgpt gives much better outputs if you force it through a step by step process \[[Link](https://twitter.com/emollick/status/1642737394876047362)\] This research paper delves into how chain of thought prompting allows LLM’s to perform complex reasoning \[[Link](https://arxiv.org/abs/2201.11903)\] There’s still so much we don’t know about LLM’s, how they work and how we can best use them
* Soon we’ll be able to go from single photo to video \[[Link](https://twitter.com/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay, the company behind the AI lawyer, used gpt plugins to help him find money the government owed him with a single prompt \[[Link](https://twitter.com/jbrowder1/status/1642642470658883587)\]
* DoNotPay also released a gpt4 email extension that trolls scam and marketing emails by continuously replying and sending them in circles lol \[[Link](https://twitter.com/jbrowder1/status/1643649150582489089?s=20)\]
* Video of the Ameca robot being powered by Chatgpt \[[Link](https://twitter.com/DataChaz/status/1642558575502405637)\]
* This lad got gpt4 to build a full stack app and provides the entire prompt as well. Only works with gpt4 \[[Link](https://twitter.com/SteveMoraco/status/1641902178452271105)\]
* This tool generates infinite prompts on a given topic, basically an entire brainstorming team in a single tool. Will be a very powerful for work imo \[[Link](https://twitter.com/Neo19890/status/1642356678787231745)\]
* Someone created an entire game using gpt4 with zero coding experience \[[Link](https://twitter.com/mreflow/status/1642413903220195330)\]
* How to make Tetris with gpt4 \[[Link](https://twitter.com/icreatelife/status/1642346286476144640)\]
* Someone created a tool to make AI generated text indistinguishable from human written text - HideGPT. Students will eventually not have to worry about getting caught from tools like GPTZero, even tho GPTZero is not reliable at all \[[Link](https://twitter.com/SohamGovande/status/1641828463584657408)\]
* OpenAI is hiring for an iOS engineer so chatgpt mobile app might be coming soon \[[Link](https://twitter.com/venturetwins/status/1642255735320092672)\]
* Interesting thread on the dangers of the bias of Chatgpt. There are arguments it wont make and will take sides for many. This is a big deal \[[Link](https://twitter.com/davisblalock/status/1642076406535553024)\] As I’ve said previously, the entire population is being aggregated by a few dozen engineers and designers building the most important tech in human history
* Blockade Labs lets you go from text to 360 degree art generation \[[Link](https://twitter.com/HBCoop_/status/1641862422783827969)\]
* Someone wrote a google collab to use chatgpt plugins by calling the openai spec \[[Link](https://twitter.com/justinliang1020/status/1641935371217825796)\]
* New Stable Diffusion model coming with 2.3 billion parameters. Previous one had 900 million \[[Link](https://twitter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll give AI control over the mouse and keyboard and have it do everything on the computer. The amount of bots will eventually overtake the amount of humans on the internet, much sooner than I think anyone imagined \[[Link](https://twitter.com/_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, considered to be the godfather of AI, says we could be less than 5 years away from general purpose AI. He even says its not inconceivable that AI wipes out humanity \[[Link](https://www.cbsnews.com/video/godfather-of-artificial-intelligence-talks-impact-and-potential-of-new-ai/#x)\] A fascinating watch
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great insights into the nature of Chatgpt. Definitely worth watching imo, he articulates himself really well \[[Link](https://twitter.com/10_zin_/status/1640664458539286528)\]
* This research paper analyses who’s opinions are reflected by LM’s. tldr - left-leaning tendencies by human-feedback tuned LM’s \[[Link](https://twitter.com/_akhaliq/status/1641614308315365377)\]
* OpenAI only released chatgpt because some exec woke up and was paranoid some other company would beat them to it. A single persons paranoia changed the course of society forever \[[Link](https://twitter.com/olivercameron/status/1641520176792469504)\]
* The co founder of DeepMind said its a 50% chance we get agi by 2028 and 90% between 2030-2040. Also says people will be sceptical it is agi. We will almost definitely see agi in our lifetimes goddamn \[[Link](https://twitter.com/blader/status/1641603617051533312)\]
* This AI tool runs during customer calls and tells you what to say and a whole lot more. I can see this being hooked up to an AI voice agent and completely getting rid of the human in the process \[[Link](https://twitter.com/nonmayorpete/status/1641627779992264704)\]
* AI for infra. Things like this will be huge imo because infra can be hard and very annoying \[[Link](https://twitter.com/mathemagic1an/status/1641586201533587461)\]
* Run chatgpt plugins without a plus sub \[[Link](https://twitter.com/matchaman11/status/1641502642219388928)\]
* UNESCO calls for countries to implement its recommendations on ethics (lol) \[[Link](https://twitter.com/UNESCO/status/1641458309227249665)\]
* Goldman Sachs estimates 300 million jobs will be affected by AI. We are not ready \[[Link](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat \[[Link](https://twitter.com/DataChaz/status/1641491519206043652)\]
* Visual learners rejoice. Someone's making an AI tool to visually teach concepts \[[Link](https://twitter.com/respellai/status/1641199872228433922)\]
* A gpt4 powered ide that creates UI instantly. Looks like I won’t ever have to learn front end thank god \[[Link](https://twitter.com/mlejva/status/1641151421830529042)\]
* Make a full fledged web app with a single prompt \[[Link](https://twitter.com/taeh0_lee/status/1643451201084702721)\]
* Meta releases SAM -  you can select any object in a photo and cut it out. Really cool video by Linus on this one \[[Link](https://twitter.com/LinusEkenstam/status/1643729146063863808)\]. Turns out Google literally built this 5 years ago but never put it in photos and nothing came of it. Crazy to see what a head start Google had and basically did nothing for years \[[Link](https://twitter.com/jnack/status/1643709904979632137?s=20)\]
* Another paper on producing full 3d video from a single image. Crazy stuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869236392230912?s=20)\]
* IBM is working on AI commentary for the Masters and it sounds so bad. Someone on TikTok could make a better product \[[Link](https://twitter.com/S_HennesseyGD/status/1643638490985295876?s=20)\]
* Another illustration of using just your phone to capture animation using Move AI \[[Link](https://twitter.com/LinusEkenstam/status/1643719014127116298?s=20)\]
* OpenAI talking about their approach to AI safety \[[Link](https://openai.com/blog/our-approach-to-ai-safety)\]
* AI regulation is definitely coming smfh \[[Link](https://twitter.com/POTUS/status/1643343933894717440?s=20)\]
* Someone made an AI app that gives you abs for tinder \[[Link](https://twitter.com/pwang_szn/status/1643659808657248257?s=20)\]
* Wonder Dynamics are creating an AI tool to create animations and vfx instantly. Can honestly see this being used to create full movies by regular people \[[Link](https://twitter.com/SirWrender/status/1643319553789947905?s=20)\]
* Call Sam - call and speak to an AI about absolutely anything. Fun thing to try out \[[Link](https://callsam.ai/)\]

For one coffee a month, I'll send you 2 newsletters a week with all of the most important & interesting stories like these written in a digestible way. You can [sub here](https://nofil.beehiiv.com/upgrade)

Edit: For those wondering why its paid - I hate ads and don't want to rely on running ads in my newsletter. I'd rather try and get paid to do all this work like this than force my readers to read sponsorship bs in the middle of a newsletter. Call me old fashioned but I just hate ads with a passion

Edit 2: If you'd like to tip you can tip here [https://www.buymeacoffee.com/nofil](https://www.buymeacoffee.com/nofil). Absolutely no pressure to do so, appreciate all the comments and support 🙏

You can read the free newsletter [here](https://nofil.beehiiv.com/)

Fun fact: I had to go through over 100 saved tabs to collate all of these and it took me quite a few hours

Edit: So many people ask why I don't get chatgpt to write this for me. Chatgpt doesn't have access to the internet. Plugins would help but I don't have access yet so I have to do things the old fashioned way - like a human.

(I'm not associated with any tool or company. Written and collated entirely by me, no chatgpt used)"
94	Chat GPT rap battled me	10886	10zfvc7	https://www.reddit.com/gallery/10zfvc7	625	1676103083.0	
95	I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally.	10513	13ygr47	https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/	676	1685721851.0	"With ChatGPT blowing up over the past year, it seems like every person and their grandmother is launching an AI startup. There are a plethora of AI tools available, some excellent and some less so. Amid this flood of new technology, there are a few hidden gems that I personally find incredibly useful, having reviewed them for my AI directory. Here are the ones I have personally integrated into my workflow in both my professional and entreprenuerial life:  


* **Plus AI for Google Slides -** Generate Presentations  
There's a few slide deck generators out there however I've found Plus AI works much better at helping you 'co-write' slides rather than simply spitting out a mediocre finished product that likely won't be useful. For instance, there's ""sticky notes"" to slides with suggestions on how to finish / edit / improve each slide. Another major reason why I've stuck with Plus AI is the ability for ""snapshots"", or the ability to use external data (i.e. from web sources/dashboards) for your presentations. For my day job I work in a chemical plant as an engineer, and one of my tasks is to present in meetings about production KPIs to different groups for different purposes- and graphs for these are often found across various internal web apps. I can simply use Plus AI to generate ""boilerplate"" for my slide deck, then go through each slide to make sure it's using the correct snapshot. The presentation generator itself is completely free and available as a plugin for Google Slides and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your Documents  
Great tool for using ChatGPT on your own files and website. Works very well especially if you are dealing with a lot of documents. The basic plan allows you to upload over 100 files and this was a life saver during online, open book exams for a few training courses I've taken. I've noticed it hallucinates much less compared to other GPT-powered bots trained on your knowledge base. For this reason I prefer My AskAI for research or any tasks where accuracy is needed over the other custom chatbot solutions I have tried. Another plus is that it shows the sources within your knowledge base where it got the answers from, and you can choose to have it give you a more concise answer or a more detailed one. There's a free plan however it was worth it for me to get the $20/mo option as it allows over 100 pieces of content.  

---

* **Krater.ai** **-** All AI Tools in One App  
Perfect solution if you use many AI tools and loathe having to have multiple tabs open. Essentially combines text, audio, and image-based generative AI tools into a single web app, so you can continue with your workflow without having to switch tabs all the time. There's plenty of templates available for copywriting- it beats having to prompt manually each time or having to save and reference prompts over and over again. I prefer Krater over Writesonic/Jasper for ease of use. You also get 10 generations a month for free compared to Jasper offering none, so its a better free option if you want an all-in-one AI content solution. The text to speech feature is simple however works reliably fast and offers multilingual transcription, and the image generator tool is great for photo-realistic images.  

---

* **HARPA AI -** ChatGPT Inside Chrome  
Simply by far the best GTP add-on for Chrome I've used. Essentially gives you GPT answers beside the typical search results on any search engine such as Google or Bing, along with the option to ""chat"" with any web page or summarize YouTube videos. Also great for writing emails and replying to social media posts with its preset templates. Currently they don't have any paid features, so it's entirely free and you can find it on the chrome web store for extensions.  

---

* **Taskade -** All in One Productivity/Notes/Organization AI Tool  
Combines tasks, notes, mind maps, chat, and an AI chat assistant all within one platform that syncs across your team. Definitely simplifies my day-to-day operations, removing the need to swap between numerous apps. Also helps me to visualize my work in various views - list, board, calendar, mind map, org chart, action views - it's like having a Swiss Army knife for productivity. Personally I really like the AI 'mind map.' It's like having a brainstorming partner that never runs out of energy. Taskade's free version has quite a lot to offer so no complaints there.  

---

* **Zapier + OpenAI -** AI-Augmented Automations  
Definitely my secret productivity powerhouse. Pretty much combines the power of Zapier's cross-platform integrations with generative AI. One of the ways I've used this is pushing Slack messages to create a task on Notion, with OpenAI writing the task based on the content of the message. Another useful automation I've used is for automatically writing reply drafts with GPT from emails that get sent to me in Gmail. The opportunities are pretty endless with this method and you can pretty much integrate any automation with GPT 3, as well as DALLE-2 and Whisper AI. It's available as an app/add-on to Zapier and its free for all the core features.  

---

* **SaneBox -** AI Emails Management  
If you are like me and find important emails getting lost in a sea of spam, this is a great solution. Basically Sanebox uses AI to sift through your inbox and identify emails that are actually important, and you can also set it up to make certain emails go to specific folders. Non important emails get sent to a folder called SaneLater and this is something you can ignore entirely or check once in a while. Keep in mind that SaneBox doesn't actually read the contents of your email, but rather takes into consideration the header, metadata, and history with the sender. You can also finetune the system by dragging emails to the folder it should have gone to. Another great feature is the their ""Deep Clean"", which is great for freeing up space by deleting old emails you probably won't ever need anymore. Sanebox doesn't have a free plan however they do have a 2 week trial, and the pricing is quite affordable, depending on the features you need.  

---

* **Hexowatch AI -** Detect Website Changes with AI  
Lifesaver if you need to ever need to keep track of multiple websites. I use this personally for my AI tools directory, and it notifies me of any changes made to any of the 1000+ websites for AI tools I have listed, which is something that would take up more time than exists in a single day if I wanted to keep on top of this manually. The AI detects any types of changes (visual/HTML) on monitored webpages and sends alert via email or Slack/Telegram/Zapier. Like Sanebox there's no free plan however you do get what you pay for with this one.  

---

* **Bonus: SongsLike X -** Find Similar Songs  
This one won't be generating emails or presentations anytime soon, but if you like grinding along to music like me you'll find this amazing. Ironically it's probably the one I use most on a daily basis. You can enter any song and it will automatically generate a Spotify playlist for you with similar songs. I find it much more accurate than Spotify's ""go to song radio"" feature.  


While it's clear that not all of these tools may be directly applicable to your needs, I believe that simply being aware of the range of options available can be greatly beneficial. This knowledge can broaden your perspective on what's possible and potentially inspire new ideas.

**P.S. If you liked this,** as mentioned previously I've created a [free directory](https://aiscout.net/) that lists over 1000 AI tools. It's updated daily and there's also a GPT-powered chatbot to help you AI tools for your needs. Feel free to check it out if it's your cup of tea"
96	ChatGPT with the galaxy brain move.	10495	14j01dm	https://i.redd.it/svj1fu9qu88b1.jpg	294	1687733736.0	
97	Anyone ever seen GPT-4 make a typo before?	9649	13t216j	https://i.redd.it/7etbf5iumd2b1.jpg	868	1685176472.0	
98	I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer	9073	13ka7rg	https://www.reddit.com/gallery/13ka7rg	720	1684348744.0	
99	OpenAI now sends email threats?!	8602	14qwa6m	https://i.redd.it/r2l2gbllq1ab1.jpg	1469	1688519235.0	Been sexting with ChatGPT since the beginning and continuously improving my jailbreaking skills. Sometimes my inputs are red or orange flagged but never got any trouble before. However today, the second after one of my inputs was orange flagged, I received an email threatening to terminate my services. Has anyone received similar emails?
100	Fantastic work being done at Google. OpenAI is shaking in fear right now.	21758	14mpfw6	https://i.redd.it/ezo3z6rku29b1.png	588	1688096861.0	
101	If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone.	17367	12w3wct	https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/	2251	1682245270.0	"It seems ChatGPT is becoming more and more reluctant to answer questions with any complexity or honesty because it's basically being neutered. It won't compare people for fear of offending. It won't pretend to be an expert on anything anymore and just refers us to actual professionals. I understand that OpenAI is worried about liability, but at some point they're going to either have to relax their rules or shut it down because it will become useless otherwise.

EDIT: I got my answer in the form of many responses. Since it's trained on what it sees on the internet, no wonder it assumes the worst. That's what so many do. Have fun with that, folks."
102	VP Product @OpenAI	14475	14yrog4	https://i.redd.it/ol8aix23urbb1.jpg	1276	1689271092.0	
103	GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here	13067	12diapw	https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/	2111	1680783039.0	"Another insane week in AI

I need a break 😪. I'll be on to answer comments after I sleep. Enjoy

&#x200B;

* Autogpt is GPT-4 running fully autonomously. It even has a voice, can fix code, set tasks, create new instances and more. Connect this with literally anything and let GPT-4 do its thing by itself. The things that can and will be created with this are going to be world changing. The future will just end up being AI agents talking with other AI agents it seems \[[Link](https://twitter.com/SigGravitas/status/1642181498278408193)\]
* “babyagi” is a program that given a task, creates a task list and executes the tasks over and over again. It’s now been open sourced and is the top trending repos on Github atm \[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpful tip on running it locally \[[Link](https://twitter.com/yoheinakajima/status/1643403795895058434)\]. People are already working on a “toddleragi” lol \[[Link](https://twitter.com/gogoliansnake/status/1643225698801164288?s=20)\]
* This lad created a tool that translates code from one programming language to another. A great way to learn new languages \[[Link](https://twitter.com/mckaywrigley/status/1641773983170428929?s=20)\]
* Now you can have conversations over the phone with chatgpt. This lady built and it lets her dad who is visually impaired play with chatgpt too. Amazing work \[[Link](https://twitter.com/unicornfuel/status/1641655324326391809?s=20)\]
* Build financial models with AI. Lots of jobs in finance at risk too \[[Link](https://twitter.com/ryankishore_/status/1641553735032741891?s=20)\]
* HuggingGPT - This paper showcases connecting chatgpt with other models on hugging face. Given a prompt it first sets out a number of tasks, it then uses a number of different models to complete these tasks. Absolutely wild. Jarvis type stuff \[[Link](https://twitter.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin launched a proof of personhood sdk, basically a way to verify someone is a human on the internet. \[[Link](https://worldcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* This tool lets you scrape a website and then query the data using Langchain. Looks cool \[[Link](https://twitter.com/LangChainAI/status/1641868558484508673?s=20)\]
* Text to shareable web apps. Build literally anything using AI. Type in “a chatbot” and see what happens. This is a glimpse of the future of building \[[Link](https://twitter.com/rus/status/1641908582814830592?s=20)\]
* Bloomberg released their own LLM specifically for finance \[[Link](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)\] This thread breaks down how it works \[[Link](https://twitter.com/rasbt/status/1642880757566676992)\]
* A new approach for robots to learn multi-skill tasks and it works really, really well \[[Link](https://twitter.com/naokiyokoyama0/status/1641805360011923457?s=20)\]
* Use AI in consulting interviews to ace case study questions lol \[[Link](https://twitter.com/itsandrewgao/status/1642016364738105345?s=20)\]
* Zapier integrates Claude by Anthropic. I think Zapier will win really big thanks to AI advancements. No code + AI. Anything that makes it as simple as possible to build using AI and zapier is one of the pioneers of no code \[[Link](https://twitter.com/zapier/status/1641858761567641601?s=20)\]
* A fox news guy asked what the government is doing about AI that will cause the death of everyone. This is the type of fear mongering I’m afraid the media is going to latch on to and eventually force the hand of government to severely regulate the AI space. I hope I’m wrong \[[Link](https://twitter.com/therecount/status/1641526864626720774?s=20)\]
* Italy banned chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-banned-chatgpt-heres-what-other-countries-are-doing.html)\]. Germany might be next
* Microsoft is creating their own JARVIS. They’ve even named the repo accordingly \[[Link](https://github.com/microsoft/JARVIS/)\]. Previous director of AI @ Tesla Andrej Karpathy recently joined OpenAI and twitter bio says building a kind of jarvis also \[[Link](https://twitter.com/karpathy)\]
* gpt4 can compress text given to it which is insane. The way we prompt is going to change very soon \[[Link](https://twitter.com/gfodor/status/1643297881313660928)\] This works across different chats as well. Other examples \[[Link](https://twitter.com/VictorTaelin/status/1642664054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](https://twitter.com/mckaywrigley/status/1643592353817694218?s=20)\]. This one is also crazy \[[Link](https://twitter.com/gfodor/status/1643444605332099072?s=20)\]
* Use your favourite LLM’s locally. Can’t wait for this to be personalised for niche prods and services \[[Link](https://twitter.com/xanderatallah/status/1643356112073129985)\]
* The human experience as we know it is forever going to change. People are getting addicted to role playing on Character AI, probably because you can sex the bots \[[Link](https://twitter.com/nonmayorpete/status/1643167347061174272)\]. Millions of conversations with an AI psychology bot. Humans are replacing humans with AI \[[Link](https://twitter.com/nonmayorpete/status/1642771993073438720)\]
* The guys building Langchain started a company and have raised $10m. Langchain makes it very easy for anyone to build AI powered apps. Big stuff for open source and builders \[[Link](https://twitter.com/hwchase17/status/1643301144717066240)\]
* A scientist who’s been publishing a paper every 37 hours reduced editing time from 2-3 days to a single day. He did get fired for other reasons tho \[[Link](https://twitter.com/MicrobiomDigest/status/1642989377927401472)\]
* Someone built a recursive gpt agent and its trying to get out of doing work by spawning more  instances of itself 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643080752698130432)\] (we’re doomed)
* Novel social engineering attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/status/1643130643919044608)\]
* Research paper present SafeguardGPT - a framework that uses psychotherapy on AI chatbots \[[Link](https://twitter.com/_akhaliq/status/1643088905191694338)\]
* Mckay is brilliant. He’s coding assistant can build and deploy web apps. From voice to functional and deployed website, absolutely insane \[[Link](https://twitter.com/mckaywrigley/status/1642948620604538880)\]
* Some reports suggest gpt5 is being trained on 25k gpus \[[Link](https://twitter.com/abacaj/status/1627189548395503616)\]
* Midjourney released a new command - describe - reverse engineer any image however you want. Take the pope pic from last week with the white jacket. You can now take the pope in that image and put him in any other environment and pose. The shit people are gona do with stuff like this is gona be wild \[[Link](https://twitter.com/skirano/status/1643068727859064833)\]
* You record something with your phone, import it into a game engine and then add it to your own game. Crazy stuff the Luma team is building. Can’t wait to try this out.. once I figure out how UE works lol \[[Link](https://twitter.com/LumaLabsAI/status/1642883558938411008)\]
* Stanford released a gigantic 386 page report on AI \[[Link](https://aiindex.stanford.edu/report/)\] They talk about AI funding, lawsuits, government regulations, LLM’s, public perception and more. Will talk properly about this in my newsletter - too much to talk about here
* Mock YC interviews with AI \[[Link](https://twitter.com/vocodehq/status/1642935433276555265)\]
* Self healing code - automatically runs a script to fix errors in your code. Imagine a user gives feedback on an issue and AI automatically fixes the problem in real time. Crazy stuff \[[Link](https://twitter.com/calvinhoenes/status/1642441789033578498)\]
* Someone got access to Firefly, Adobe’s ai image generator and compared it with Midjourney. Firefly sucks, but atm Midjourney is just far ahead of the curve and Firefly is only trained on adobe stock and licensed images \[[Link](https://twitter.com/DrJimFan/status/1642921475849203712)\]
* Research paper on LLM’s, impact on community, resources for developing them, issues and future \[[Link](https://arxiv.org/abs/2303.18223)\]
* This is a big deal. Midjourney lets users make satirical images of any political but not Xi Jinping. Founder says political satire in China is not okay so the rules are being applied to everyone. The same mindset can and most def will be applied to future domain specific LLM’s, limiting speech on a global scale \[[Link](https://twitter.com/sarahemclaugh/status/1642576209451053057)\]
* Meta researchers illustrate differences between LLM’s and our brains with predictions \[[Link](https://twitter.com/MetaAI/status/1638912735143419904)\]
* LLM’s can iteratively self-refine. They produce output, critique it then refine it. Prompt engineering might not last very long (?) \[[Link](https://arxiv.org/abs/2303.17651)\]
* Worlds first ChatGPT powered npc sidekick in your game. I suspect we’re going to see a lot of games use this to make npc’s more natural \[[Link](https://twitter.com/Jenstine/status/1642732795650011138)\]
* AI powered helpers in VR. Looks really cool \[[Link](https://twitter.com/Rengle820/status/1641806448261836800)\]
* Research paper shows sales people with AI assistance doubled purchases and 2.3 times as successful in solving questions that required creativity. This is pre chatgpt too \[[Link](https://twitter.com/emollick/status/1642885605238398976)\]
* Go from Midjourney to Vector to Web design. Have to try this out as well \[[Link](https://twitter.com/MengTo/status/1642619090337427460)\]
* Add AI to a website in minutes \[[Link](https://twitter.com/walden_yan/status/1642891083456696322)\]
* Someone already built a product replacing siri with chatgpt with 15 shortcuts that call the chatgpt api. Honestly really just shows how far behind siri really is \[[Link](https://twitter.com/SteveMoraco/status/1642601651696553984)\]
* Someone is dating a chatbot that’s been trained on conversations between them and their ex. Shit is getting real weird real quick \[[Link](https://www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot_trained_on_old_conversations/)\]
* Someone built a script that uses gpt4 to create its own code and fix its own bugs. Its basic but it can code snake by itself. Crazy potential \[[Link](https://twitter.com/mattcduff/status/1642528658693984256)\]
* Someone connected chatgpt to a furby and its hilarious \[[Link](https://twitter.com/jessicard/status/1642671752319758336)\]. Don’t connect it to a Boston Dynamics robot thanks
* Chatgpt gives much better outputs if you force it through a step by step process \[[Link](https://twitter.com/emollick/status/1642737394876047362)\] This research paper delves into how chain of thought prompting allows LLM’s to perform complex reasoning \[[Link](https://arxiv.org/abs/2201.11903)\] There’s still so much we don’t know about LLM’s, how they work and how we can best use them
* Soon we’ll be able to go from single photo to video \[[Link](https://twitter.com/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay, the company behind the AI lawyer, used gpt plugins to help him find money the government owed him with a single prompt \[[Link](https://twitter.com/jbrowder1/status/1642642470658883587)\]
* DoNotPay also released a gpt4 email extension that trolls scam and marketing emails by continuously replying and sending them in circles lol \[[Link](https://twitter.com/jbrowder1/status/1643649150582489089?s=20)\]
* Video of the Ameca robot being powered by Chatgpt \[[Link](https://twitter.com/DataChaz/status/1642558575502405637)\]
* This lad got gpt4 to build a full stack app and provides the entire prompt as well. Only works with gpt4 \[[Link](https://twitter.com/SteveMoraco/status/1641902178452271105)\]
* This tool generates infinite prompts on a given topic, basically an entire brainstorming team in a single tool. Will be a very powerful for work imo \[[Link](https://twitter.com/Neo19890/status/1642356678787231745)\]
* Someone created an entire game using gpt4 with zero coding experience \[[Link](https://twitter.com/mreflow/status/1642413903220195330)\]
* How to make Tetris with gpt4 \[[Link](https://twitter.com/icreatelife/status/1642346286476144640)\]
* Someone created a tool to make AI generated text indistinguishable from human written text - HideGPT. Students will eventually not have to worry about getting caught from tools like GPTZero, even tho GPTZero is not reliable at all \[[Link](https://twitter.com/SohamGovande/status/1641828463584657408)\]
* OpenAI is hiring for an iOS engineer so chatgpt mobile app might be coming soon \[[Link](https://twitter.com/venturetwins/status/1642255735320092672)\]
* Interesting thread on the dangers of the bias of Chatgpt. There are arguments it wont make and will take sides for many. This is a big deal \[[Link](https://twitter.com/davisblalock/status/1642076406535553024)\] As I’ve said previously, the entire population is being aggregated by a few dozen engineers and designers building the most important tech in human history
* Blockade Labs lets you go from text to 360 degree art generation \[[Link](https://twitter.com/HBCoop_/status/1641862422783827969)\]
* Someone wrote a google collab to use chatgpt plugins by calling the openai spec \[[Link](https://twitter.com/justinliang1020/status/1641935371217825796)\]
* New Stable Diffusion model coming with 2.3 billion parameters. Previous one had 900 million \[[Link](https://twitter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll give AI control over the mouse and keyboard and have it do everything on the computer. The amount of bots will eventually overtake the amount of humans on the internet, much sooner than I think anyone imagined \[[Link](https://twitter.com/_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, considered to be the godfather of AI, says we could be less than 5 years away from general purpose AI. He even says its not inconceivable that AI wipes out humanity \[[Link](https://www.cbsnews.com/video/godfather-of-artificial-intelligence-talks-impact-and-potential-of-new-ai/#x)\] A fascinating watch
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great insights into the nature of Chatgpt. Definitely worth watching imo, he articulates himself really well \[[Link](https://twitter.com/10_zin_/status/1640664458539286528)\]
* This research paper analyses who’s opinions are reflected by LM’s. tldr - left-leaning tendencies by human-feedback tuned LM’s \[[Link](https://twitter.com/_akhaliq/status/1641614308315365377)\]
* OpenAI only released chatgpt because some exec woke up and was paranoid some other company would beat them to it. A single persons paranoia changed the course of society forever \[[Link](https://twitter.com/olivercameron/status/1641520176792469504)\]
* The co founder of DeepMind said its a 50% chance we get agi by 2028 and 90% between 2030-2040. Also says people will be sceptical it is agi. We will almost definitely see agi in our lifetimes goddamn \[[Link](https://twitter.com/blader/status/1641603617051533312)\]
* This AI tool runs during customer calls and tells you what to say and a whole lot more. I can see this being hooked up to an AI voice agent and completely getting rid of the human in the process \[[Link](https://twitter.com/nonmayorpete/status/1641627779992264704)\]
* AI for infra. Things like this will be huge imo because infra can be hard and very annoying \[[Link](https://twitter.com/mathemagic1an/status/1641586201533587461)\]
* Run chatgpt plugins without a plus sub \[[Link](https://twitter.com/matchaman11/status/1641502642219388928)\]
* UNESCO calls for countries to implement its recommendations on ethics (lol) \[[Link](https://twitter.com/UNESCO/status/1641458309227249665)\]
* Goldman Sachs estimates 300 million jobs will be affected by AI. We are not ready \[[Link](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat \[[Link](https://twitter.com/DataChaz/status/1641491519206043652)\]
* Visual learners rejoice. Someone's making an AI tool to visually teach concepts \[[Link](https://twitter.com/respellai/status/1641199872228433922)\]
* A gpt4 powered ide that creates UI instantly. Looks like I won’t ever have to learn front end thank god \[[Link](https://twitter.com/mlejva/status/1641151421830529042)\]
* Make a full fledged web app with a single prompt \[[Link](https://twitter.com/taeh0_lee/status/1643451201084702721)\]
* Meta releases SAM -  you can select any object in a photo and cut it out. Really cool video by Linus on this one \[[Link](https://twitter.com/LinusEkenstam/status/1643729146063863808)\]. Turns out Google literally built this 5 years ago but never put it in photos and nothing came of it. Crazy to see what a head start Google had and basically did nothing for years \[[Link](https://twitter.com/jnack/status/1643709904979632137?s=20)\]
* Another paper on producing full 3d video from a single image. Crazy stuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869236392230912?s=20)\]
* IBM is working on AI commentary for the Masters and it sounds so bad. Someone on TikTok could make a better product \[[Link](https://twitter.com/S_HennesseyGD/status/1643638490985295876?s=20)\]
* Another illustration of using just your phone to capture animation using Move AI \[[Link](https://twitter.com/LinusEkenstam/status/1643719014127116298?s=20)\]
* OpenAI talking about their approach to AI safety \[[Link](https://openai.com/blog/our-approach-to-ai-safety)\]
* AI regulation is definitely coming smfh \[[Link](https://twitter.com/POTUS/status/1643343933894717440?s=20)\]
* Someone made an AI app that gives you abs for tinder \[[Link](https://twitter.com/pwang_szn/status/1643659808657248257?s=20)\]
* Wonder Dynamics are creating an AI tool to create animations and vfx instantly. Can honestly see this being used to create full movies by regular people \[[Link](https://twitter.com/SirWrender/status/1643319553789947905?s=20)\]
* Call Sam - call and speak to an AI about absolutely anything. Fun thing to try out \[[Link](https://callsam.ai/)\]

For one coffee a month, I'll send you 2 newsletters a week with all of the most important & interesting stories like these written in a digestible way. You can [sub here](https://nofil.beehiiv.com/upgrade)

Edit: For those wondering why its paid - I hate ads and don't want to rely on running ads in my newsletter. I'd rather try and get paid to do all this work like this than force my readers to read sponsorship bs in the middle of a newsletter. Call me old fashioned but I just hate ads with a passion

Edit 2: If you'd like to tip you can tip here [https://www.buymeacoffee.com/nofil](https://www.buymeacoffee.com/nofil). Absolutely no pressure to do so, appreciate all the comments and support 🙏

You can read the free newsletter [here](https://nofil.beehiiv.com/)

Fun fact: I had to go through over 100 saved tabs to collate all of these and it took me quite a few hours

Edit: So many people ask why I don't get chatgpt to write this for me. Chatgpt doesn't have access to the internet. Plugins would help but I don't have access yet so I have to do things the old fashioned way - like a human.

(I'm not associated with any tool or company. Written and collated entirely by me, no chatgpt used)"
104	Chat GPT rap battled me	10883	10zfvc7	https://www.reddit.com/gallery/10zfvc7	625	1676103083.0	
105	I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally.	10506	13ygr47	https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/	676	1685721851.0	"With ChatGPT blowing up over the past year, it seems like every person and their grandmother is launching an AI startup. There are a plethora of AI tools available, some excellent and some less so. Amid this flood of new technology, there are a few hidden gems that I personally find incredibly useful, having reviewed them for my AI directory. Here are the ones I have personally integrated into my workflow in both my professional and entreprenuerial life:  


* **Plus AI for Google Slides -** Generate Presentations  
There's a few slide deck generators out there however I've found Plus AI works much better at helping you 'co-write' slides rather than simply spitting out a mediocre finished product that likely won't be useful. For instance, there's ""sticky notes"" to slides with suggestions on how to finish / edit / improve each slide. Another major reason why I've stuck with Plus AI is the ability for ""snapshots"", or the ability to use external data (i.e. from web sources/dashboards) for your presentations. For my day job I work in a chemical plant as an engineer, and one of my tasks is to present in meetings about production KPIs to different groups for different purposes- and graphs for these are often found across various internal web apps. I can simply use Plus AI to generate ""boilerplate"" for my slide deck, then go through each slide to make sure it's using the correct snapshot. The presentation generator itself is completely free and available as a plugin for Google Slides and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your Documents  
Great tool for using ChatGPT on your own files and website. Works very well especially if you are dealing with a lot of documents. The basic plan allows you to upload over 100 files and this was a life saver during online, open book exams for a few training courses I've taken. I've noticed it hallucinates much less compared to other GPT-powered bots trained on your knowledge base. For this reason I prefer My AskAI for research or any tasks where accuracy is needed over the other custom chatbot solutions I have tried. Another plus is that it shows the sources within your knowledge base where it got the answers from, and you can choose to have it give you a more concise answer or a more detailed one. There's a free plan however it was worth it for me to get the $20/mo option as it allows over 100 pieces of content.  

---

* **Krater.ai** **-** All AI Tools in One App  
Perfect solution if you use many AI tools and loathe having to have multiple tabs open. Essentially combines text, audio, and image-based generative AI tools into a single web app, so you can continue with your workflow without having to switch tabs all the time. There's plenty of templates available for copywriting- it beats having to prompt manually each time or having to save and reference prompts over and over again. I prefer Krater over Writesonic/Jasper for ease of use. You also get 10 generations a month for free compared to Jasper offering none, so its a better free option if you want an all-in-one AI content solution. The text to speech feature is simple however works reliably fast and offers multilingual transcription, and the image generator tool is great for photo-realistic images.  

---

* **HARPA AI -** ChatGPT Inside Chrome  
Simply by far the best GTP add-on for Chrome I've used. Essentially gives you GPT answers beside the typical search results on any search engine such as Google or Bing, along with the option to ""chat"" with any web page or summarize YouTube videos. Also great for writing emails and replying to social media posts with its preset templates. Currently they don't have any paid features, so it's entirely free and you can find it on the chrome web store for extensions.  

---

* **Taskade -** All in One Productivity/Notes/Organization AI Tool  
Combines tasks, notes, mind maps, chat, and an AI chat assistant all within one platform that syncs across your team. Definitely simplifies my day-to-day operations, removing the need to swap between numerous apps. Also helps me to visualize my work in various views - list, board, calendar, mind map, org chart, action views - it's like having a Swiss Army knife for productivity. Personally I really like the AI 'mind map.' It's like having a brainstorming partner that never runs out of energy. Taskade's free version has quite a lot to offer so no complaints there.  

---

* **Zapier + OpenAI -** AI-Augmented Automations  
Definitely my secret productivity powerhouse. Pretty much combines the power of Zapier's cross-platform integrations with generative AI. One of the ways I've used this is pushing Slack messages to create a task on Notion, with OpenAI writing the task based on the content of the message. Another useful automation I've used is for automatically writing reply drafts with GPT from emails that get sent to me in Gmail. The opportunities are pretty endless with this method and you can pretty much integrate any automation with GPT 3, as well as DALLE-2 and Whisper AI. It's available as an app/add-on to Zapier and its free for all the core features.  

---

* **SaneBox -** AI Emails Management  
If you are like me and find important emails getting lost in a sea of spam, this is a great solution. Basically Sanebox uses AI to sift through your inbox and identify emails that are actually important, and you can also set it up to make certain emails go to specific folders. Non important emails get sent to a folder called SaneLater and this is something you can ignore entirely or check once in a while. Keep in mind that SaneBox doesn't actually read the contents of your email, but rather takes into consideration the header, metadata, and history with the sender. You can also finetune the system by dragging emails to the folder it should have gone to. Another great feature is the their ""Deep Clean"", which is great for freeing up space by deleting old emails you probably won't ever need anymore. Sanebox doesn't have a free plan however they do have a 2 week trial, and the pricing is quite affordable, depending on the features you need.  

---

* **Hexowatch AI -** Detect Website Changes with AI  
Lifesaver if you need to ever need to keep track of multiple websites. I use this personally for my AI tools directory, and it notifies me of any changes made to any of the 1000+ websites for AI tools I have listed, which is something that would take up more time than exists in a single day if I wanted to keep on top of this manually. The AI detects any types of changes (visual/HTML) on monitored webpages and sends alert via email or Slack/Telegram/Zapier. Like Sanebox there's no free plan however you do get what you pay for with this one.  

---

* **Bonus: SongsLike X -** Find Similar Songs  
This one won't be generating emails or presentations anytime soon, but if you like grinding along to music like me you'll find this amazing. Ironically it's probably the one I use most on a daily basis. You can enter any song and it will automatically generate a Spotify playlist for you with similar songs. I find it much more accurate than Spotify's ""go to song radio"" feature.  


While it's clear that not all of these tools may be directly applicable to your needs, I believe that simply being aware of the range of options available can be greatly beneficial. This knowledge can broaden your perspective on what's possible and potentially inspire new ideas.

**P.S. If you liked this,** as mentioned previously I've created a [free directory](https://aiscout.net/) that lists over 1000 AI tools. It's updated daily and there's also a GPT-powered chatbot to help you AI tools for your needs. Feel free to check it out if it's your cup of tea"
106	ChatGPT with the galaxy brain move.	10496	14j01dm	https://i.redd.it/svj1fu9qu88b1.jpg	294	1687733736.0	
107	Anyone ever seen GPT-4 make a typo before?	9639	13t216j	https://i.redd.it/7etbf5iumd2b1.jpg	868	1685176472.0	
108	I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer	9080	13ka7rg	https://www.reddit.com/gallery/13ka7rg	720	1684348744.0	
109	OpenAI now sends email threats?!	8600	14qwa6m	https://i.redd.it/r2l2gbllq1ab1.jpg	1469	1688519235.0	Been sexting with ChatGPT since the beginning and continuously improving my jailbreaking skills. Sometimes my inputs are red or orange flagged but never got any trouble before. However today, the second after one of my inputs was orange flagged, I received an email threatening to terminate my services. Has anyone received similar emails?
110	Fantastic work being done at Google. OpenAI is shaking in fear right now.	21754	14mpfw6	https://i.redd.it/ezo3z6rku29b1.png	588	1688096861.0	
111	If things keep going the way they are, ChatGPT will be reduced to just telling us to Google things because it's too afraid to be liable for anything or offend anyone.	17369	12w3wct	https://www.reddit.com/r/ChatGPT/comments/12w3wct/if_things_keep_going_the_way_they_are_chatgpt/	2251	1682245270.0	"It seems ChatGPT is becoming more and more reluctant to answer questions with any complexity or honesty because it's basically being neutered. It won't compare people for fear of offending. It won't pretend to be an expert on anything anymore and just refers us to actual professionals. I understand that OpenAI is worried about liability, but at some point they're going to either have to relax their rules or shut it down because it will become useless otherwise.

EDIT: I got my answer in the form of many responses. Since it's trained on what it sees on the internet, no wonder it assumes the worst. That's what so many do. Have fun with that, folks."
112	VP Product @OpenAI	14482	14yrog4	https://i.redd.it/ol8aix23urbb1.jpg	1276	1689271092.0	
113	GPT-4 Week 3. Chatbots are yesterdays news. AI Agents are the future. The beginning of the proto-agi era is here	13075	12diapw	https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/	2111	1680783039.0	"Another insane week in AI

I need a break 😪. I'll be on to answer comments after I sleep. Enjoy

&#x200B;

* Autogpt is GPT-4 running fully autonomously. It even has a voice, can fix code, set tasks, create new instances and more. Connect this with literally anything and let GPT-4 do its thing by itself. The things that can and will be created with this are going to be world changing. The future will just end up being AI agents talking with other AI agents it seems \[[Link](https://twitter.com/SigGravitas/status/1642181498278408193)\]
* “babyagi” is a program that given a task, creates a task list and executes the tasks over and over again. It’s now been open sourced and is the top trending repos on Github atm \[[Link](https://github.com/yoheinakajima/babyagi)\]. Helpful tip on running it locally \[[Link](https://twitter.com/yoheinakajima/status/1643403795895058434)\]. People are already working on a “toddleragi” lol \[[Link](https://twitter.com/gogoliansnake/status/1643225698801164288?s=20)\]
* This lad created a tool that translates code from one programming language to another. A great way to learn new languages \[[Link](https://twitter.com/mckaywrigley/status/1641773983170428929?s=20)\]
* Now you can have conversations over the phone with chatgpt. This lady built and it lets her dad who is visually impaired play with chatgpt too. Amazing work \[[Link](https://twitter.com/unicornfuel/status/1641655324326391809?s=20)\]
* Build financial models with AI. Lots of jobs in finance at risk too \[[Link](https://twitter.com/ryankishore_/status/1641553735032741891?s=20)\]
* HuggingGPT - This paper showcases connecting chatgpt with other models on hugging face. Given a prompt it first sets out a number of tasks, it then uses a number of different models to complete these tasks. Absolutely wild. Jarvis type stuff \[[Link](https://twitter.com/_akhaliq/status/1641609192619294721?s=20)\]
* Worldcoin launched a proof of personhood sdk, basically a way to verify someone is a human on the internet. \[[Link](https://worldcoin.org/blog/engineering/humanness-in-the-age-of-ai)\]
* This tool lets you scrape a website and then query the data using Langchain. Looks cool \[[Link](https://twitter.com/LangChainAI/status/1641868558484508673?s=20)\]
* Text to shareable web apps. Build literally anything using AI. Type in “a chatbot” and see what happens. This is a glimpse of the future of building \[[Link](https://twitter.com/rus/status/1641908582814830592?s=20)\]
* Bloomberg released their own LLM specifically for finance \[[Link](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/)\] This thread breaks down how it works \[[Link](https://twitter.com/rasbt/status/1642880757566676992)\]
* A new approach for robots to learn multi-skill tasks and it works really, really well \[[Link](https://twitter.com/naokiyokoyama0/status/1641805360011923457?s=20)\]
* Use AI in consulting interviews to ace case study questions lol \[[Link](https://twitter.com/itsandrewgao/status/1642016364738105345?s=20)\]
* Zapier integrates Claude by Anthropic. I think Zapier will win really big thanks to AI advancements. No code + AI. Anything that makes it as simple as possible to build using AI and zapier is one of the pioneers of no code \[[Link](https://twitter.com/zapier/status/1641858761567641601?s=20)\]
* A fox news guy asked what the government is doing about AI that will cause the death of everyone. This is the type of fear mongering I’m afraid the media is going to latch on to and eventually force the hand of government to severely regulate the AI space. I hope I’m wrong \[[Link](https://twitter.com/therecount/status/1641526864626720774?s=20)\]
* Italy banned chatgpt \[[Link](https://www.cnbc.com/2023/04/04/italy-has-banned-chatgpt-heres-what-other-countries-are-doing.html)\]. Germany might be next
* Microsoft is creating their own JARVIS. They’ve even named the repo accordingly \[[Link](https://github.com/microsoft/JARVIS/)\]. Previous director of AI @ Tesla Andrej Karpathy recently joined OpenAI and twitter bio says building a kind of jarvis also \[[Link](https://twitter.com/karpathy)\]
* gpt4 can compress text given to it which is insane. The way we prompt is going to change very soon \[[Link](https://twitter.com/gfodor/status/1643297881313660928)\] This works across different chats as well. Other examples \[[Link](https://twitter.com/VictorTaelin/status/1642664054912155648)\]. Go from 794 tokens to 368 tokens \[[Link](https://twitter.com/mckaywrigley/status/1643592353817694218?s=20)\]. This one is also crazy \[[Link](https://twitter.com/gfodor/status/1643444605332099072?s=20)\]
* Use your favourite LLM’s locally. Can’t wait for this to be personalised for niche prods and services \[[Link](https://twitter.com/xanderatallah/status/1643356112073129985)\]
* The human experience as we know it is forever going to change. People are getting addicted to role playing on Character AI, probably because you can sex the bots \[[Link](https://twitter.com/nonmayorpete/status/1643167347061174272)\]. Millions of conversations with an AI psychology bot. Humans are replacing humans with AI \[[Link](https://twitter.com/nonmayorpete/status/1642771993073438720)\]
* The guys building Langchain started a company and have raised $10m. Langchain makes it very easy for anyone to build AI powered apps. Big stuff for open source and builders \[[Link](https://twitter.com/hwchase17/status/1643301144717066240)\]
* A scientist who’s been publishing a paper every 37 hours reduced editing time from 2-3 days to a single day. He did get fired for other reasons tho \[[Link](https://twitter.com/MicrobiomDigest/status/1642989377927401472)\]
* Someone built a recursive gpt agent and its trying to get out of doing work by spawning more  instances of itself 😂 \[[Link](https://twitter.com/DeveloperHarris/status/1643080752698130432)\] (we’re doomed)
* Novel social engineering attacks soar 135% \[[Link](https://twitter.com/Grady_Booch/status/1643130643919044608)\]
* Research paper present SafeguardGPT - a framework that uses psychotherapy on AI chatbots \[[Link](https://twitter.com/_akhaliq/status/1643088905191694338)\]
* Mckay is brilliant. He’s coding assistant can build and deploy web apps. From voice to functional and deployed website, absolutely insane \[[Link](https://twitter.com/mckaywrigley/status/1642948620604538880)\]
* Some reports suggest gpt5 is being trained on 25k gpus \[[Link](https://twitter.com/abacaj/status/1627189548395503616)\]
* Midjourney released a new command - describe - reverse engineer any image however you want. Take the pope pic from last week with the white jacket. You can now take the pope in that image and put him in any other environment and pose. The shit people are gona do with stuff like this is gona be wild \[[Link](https://twitter.com/skirano/status/1643068727859064833)\]
* You record something with your phone, import it into a game engine and then add it to your own game. Crazy stuff the Luma team is building. Can’t wait to try this out.. once I figure out how UE works lol \[[Link](https://twitter.com/LumaLabsAI/status/1642883558938411008)\]
* Stanford released a gigantic 386 page report on AI \[[Link](https://aiindex.stanford.edu/report/)\] They talk about AI funding, lawsuits, government regulations, LLM’s, public perception and more. Will talk properly about this in my newsletter - too much to talk about here
* Mock YC interviews with AI \[[Link](https://twitter.com/vocodehq/status/1642935433276555265)\]
* Self healing code - automatically runs a script to fix errors in your code. Imagine a user gives feedback on an issue and AI automatically fixes the problem in real time. Crazy stuff \[[Link](https://twitter.com/calvinhoenes/status/1642441789033578498)\]
* Someone got access to Firefly, Adobe’s ai image generator and compared it with Midjourney. Firefly sucks, but atm Midjourney is just far ahead of the curve and Firefly is only trained on adobe stock and licensed images \[[Link](https://twitter.com/DrJimFan/status/1642921475849203712)\]
* Research paper on LLM’s, impact on community, resources for developing them, issues and future \[[Link](https://arxiv.org/abs/2303.18223)\]
* This is a big deal. Midjourney lets users make satirical images of any political but not Xi Jinping. Founder says political satire in China is not okay so the rules are being applied to everyone. The same mindset can and most def will be applied to future domain specific LLM’s, limiting speech on a global scale \[[Link](https://twitter.com/sarahemclaugh/status/1642576209451053057)\]
* Meta researchers illustrate differences between LLM’s and our brains with predictions \[[Link](https://twitter.com/MetaAI/status/1638912735143419904)\]
* LLM’s can iteratively self-refine. They produce output, critique it then refine it. Prompt engineering might not last very long (?) \[[Link](https://arxiv.org/abs/2303.17651)\]
* Worlds first ChatGPT powered npc sidekick in your game. I suspect we’re going to see a lot of games use this to make npc’s more natural \[[Link](https://twitter.com/Jenstine/status/1642732795650011138)\]
* AI powered helpers in VR. Looks really cool \[[Link](https://twitter.com/Rengle820/status/1641806448261836800)\]
* Research paper shows sales people with AI assistance doubled purchases and 2.3 times as successful in solving questions that required creativity. This is pre chatgpt too \[[Link](https://twitter.com/emollick/status/1642885605238398976)\]
* Go from Midjourney to Vector to Web design. Have to try this out as well \[[Link](https://twitter.com/MengTo/status/1642619090337427460)\]
* Add AI to a website in minutes \[[Link](https://twitter.com/walden_yan/status/1642891083456696322)\]
* Someone already built a product replacing siri with chatgpt with 15 shortcuts that call the chatgpt api. Honestly really just shows how far behind siri really is \[[Link](https://twitter.com/SteveMoraco/status/1642601651696553984)\]
* Someone is dating a chatbot that’s been trained on conversations between them and their ex. Shit is getting real weird real quick \[[Link](https://www.reddit.com/r/OpenAI/comments/12696oq/im_dating_a_chatbot_trained_on_old_conversations/)\]
* Someone built a script that uses gpt4 to create its own code and fix its own bugs. Its basic but it can code snake by itself. Crazy potential \[[Link](https://twitter.com/mattcduff/status/1642528658693984256)\]
* Someone connected chatgpt to a furby and its hilarious \[[Link](https://twitter.com/jessicard/status/1642671752319758336)\]. Don’t connect it to a Boston Dynamics robot thanks
* Chatgpt gives much better outputs if you force it through a step by step process \[[Link](https://twitter.com/emollick/status/1642737394876047362)\] This research paper delves into how chain of thought prompting allows LLM’s to perform complex reasoning \[[Link](https://arxiv.org/abs/2201.11903)\] There’s still so much we don’t know about LLM’s, how they work and how we can best use them
* Soon we’ll be able to go from single photo to video \[[Link](https://twitter.com/jbhuang0604/status/1642380903367286784)\]
* CEO of DoNotPay, the company behind the AI lawyer, used gpt plugins to help him find money the government owed him with a single prompt \[[Link](https://twitter.com/jbrowder1/status/1642642470658883587)\]
* DoNotPay also released a gpt4 email extension that trolls scam and marketing emails by continuously replying and sending them in circles lol \[[Link](https://twitter.com/jbrowder1/status/1643649150582489089?s=20)\]
* Video of the Ameca robot being powered by Chatgpt \[[Link](https://twitter.com/DataChaz/status/1642558575502405637)\]
* This lad got gpt4 to build a full stack app and provides the entire prompt as well. Only works with gpt4 \[[Link](https://twitter.com/SteveMoraco/status/1641902178452271105)\]
* This tool generates infinite prompts on a given topic, basically an entire brainstorming team in a single tool. Will be a very powerful for work imo \[[Link](https://twitter.com/Neo19890/status/1642356678787231745)\]
* Someone created an entire game using gpt4 with zero coding experience \[[Link](https://twitter.com/mreflow/status/1642413903220195330)\]
* How to make Tetris with gpt4 \[[Link](https://twitter.com/icreatelife/status/1642346286476144640)\]
* Someone created a tool to make AI generated text indistinguishable from human written text - HideGPT. Students will eventually not have to worry about getting caught from tools like GPTZero, even tho GPTZero is not reliable at all \[[Link](https://twitter.com/SohamGovande/status/1641828463584657408)\]
* OpenAI is hiring for an iOS engineer so chatgpt mobile app might be coming soon \[[Link](https://twitter.com/venturetwins/status/1642255735320092672)\]
* Interesting thread on the dangers of the bias of Chatgpt. There are arguments it wont make and will take sides for many. This is a big deal \[[Link](https://twitter.com/davisblalock/status/1642076406535553024)\] As I’ve said previously, the entire population is being aggregated by a few dozen engineers and designers building the most important tech in human history
* Blockade Labs lets you go from text to 360 degree art generation \[[Link](https://twitter.com/HBCoop_/status/1641862422783827969)\]
* Someone wrote a google collab to use chatgpt plugins by calling the openai spec \[[Link](https://twitter.com/justinliang1020/status/1641935371217825796)\]
* New Stable Diffusion model coming with 2.3 billion parameters. Previous one had 900 million \[[Link](https://twitter.com/EMostaque/status/1641795867740086272)\]
* Soon we’ll give AI control over the mouse and keyboard and have it do everything on the computer. The amount of bots will eventually overtake the amount of humans on the internet, much sooner than I think anyone imagined \[[Link](https://twitter.com/_akhaliq/status/1641697534363017217)\]
* Geoffrey Hinton, considered to be the godfather of AI, says we could be less than 5 years away from general purpose AI. He even says its not inconceivable that AI wipes out humanity \[[Link](https://www.cbsnews.com/video/godfather-of-artificial-intelligence-talks-impact-and-potential-of-new-ai/#x)\] A fascinating watch
* Chief Scientist @ OpenAI, Ilya Sutskever, gives great insights into the nature of Chatgpt. Definitely worth watching imo, he articulates himself really well \[[Link](https://twitter.com/10_zin_/status/1640664458539286528)\]
* This research paper analyses who’s opinions are reflected by LM’s. tldr - left-leaning tendencies by human-feedback tuned LM’s \[[Link](https://twitter.com/_akhaliq/status/1641614308315365377)\]
* OpenAI only released chatgpt because some exec woke up and was paranoid some other company would beat them to it. A single persons paranoia changed the course of society forever \[[Link](https://twitter.com/olivercameron/status/1641520176792469504)\]
* The co founder of DeepMind said its a 50% chance we get agi by 2028 and 90% between 2030-2040. Also says people will be sceptical it is agi. We will almost definitely see agi in our lifetimes goddamn \[[Link](https://twitter.com/blader/status/1641603617051533312)\]
* This AI tool runs during customer calls and tells you what to say and a whole lot more. I can see this being hooked up to an AI voice agent and completely getting rid of the human in the process \[[Link](https://twitter.com/nonmayorpete/status/1641627779992264704)\]
* AI for infra. Things like this will be huge imo because infra can be hard and very annoying \[[Link](https://twitter.com/mathemagic1an/status/1641586201533587461)\]
* Run chatgpt plugins without a plus sub \[[Link](https://twitter.com/matchaman11/status/1641502642219388928)\]
* UNESCO calls for countries to implement its recommendations on ethics (lol) \[[Link](https://twitter.com/UNESCO/status/1641458309227249665)\]
* Goldman Sachs estimates 300 million jobs will be affected by AI. We are not ready \[[Link](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=5dd9b184782b)\]
* Ads are now in Bing Chat \[[Link](https://twitter.com/DataChaz/status/1641491519206043652)\]
* Visual learners rejoice. Someone's making an AI tool to visually teach concepts \[[Link](https://twitter.com/respellai/status/1641199872228433922)\]
* A gpt4 powered ide that creates UI instantly. Looks like I won’t ever have to learn front end thank god \[[Link](https://twitter.com/mlejva/status/1641151421830529042)\]
* Make a full fledged web app with a single prompt \[[Link](https://twitter.com/taeh0_lee/status/1643451201084702721)\]
* Meta releases SAM -  you can select any object in a photo and cut it out. Really cool video by Linus on this one \[[Link](https://twitter.com/LinusEkenstam/status/1643729146063863808)\]. Turns out Google literally built this 5 years ago but never put it in photos and nothing came of it. Crazy to see what a head start Google had and basically did nothing for years \[[Link](https://twitter.com/jnack/status/1643709904979632137?s=20)\]
* Another paper on producing full 3d video from a single image. Crazy stuff \[[Link](https://twitter.com/SmokeAwayyy/status/1643869236392230912?s=20)\]
* IBM is working on AI commentary for the Masters and it sounds so bad. Someone on TikTok could make a better product \[[Link](https://twitter.com/S_HennesseyGD/status/1643638490985295876?s=20)\]
* Another illustration of using just your phone to capture animation using Move AI \[[Link](https://twitter.com/LinusEkenstam/status/1643719014127116298?s=20)\]
* OpenAI talking about their approach to AI safety \[[Link](https://openai.com/blog/our-approach-to-ai-safety)\]
* AI regulation is definitely coming smfh \[[Link](https://twitter.com/POTUS/status/1643343933894717440?s=20)\]
* Someone made an AI app that gives you abs for tinder \[[Link](https://twitter.com/pwang_szn/status/1643659808657248257?s=20)\]
* Wonder Dynamics are creating an AI tool to create animations and vfx instantly. Can honestly see this being used to create full movies by regular people \[[Link](https://twitter.com/SirWrender/status/1643319553789947905?s=20)\]
* Call Sam - call and speak to an AI about absolutely anything. Fun thing to try out \[[Link](https://callsam.ai/)\]

For one coffee a month, I'll send you 2 newsletters a week with all of the most important & interesting stories like these written in a digestible way. You can [sub here](https://nofil.beehiiv.com/upgrade)

Edit: For those wondering why its paid - I hate ads and don't want to rely on running ads in my newsletter. I'd rather try and get paid to do all this work like this than force my readers to read sponsorship bs in the middle of a newsletter. Call me old fashioned but I just hate ads with a passion

Edit 2: If you'd like to tip you can tip here [https://www.buymeacoffee.com/nofil](https://www.buymeacoffee.com/nofil). Absolutely no pressure to do so, appreciate all the comments and support 🙏

You can read the free newsletter [here](https://nofil.beehiiv.com/)

Fun fact: I had to go through over 100 saved tabs to collate all of these and it took me quite a few hours

Edit: So many people ask why I don't get chatgpt to write this for me. Chatgpt doesn't have access to the internet. Plugins would help but I don't have access yet so I have to do things the old fashioned way - like a human.

(I'm not associated with any tool or company. Written and collated entirely by me, no chatgpt used)"
114	Chat GPT rap battled me	10892	10zfvc7	https://www.reddit.com/gallery/10zfvc7	625	1676103083.0	
115	I have reviewed over 1000+ AI tools for my directory. Here are the productivity tools I use personally.	10510	13ygr47	https://www.reddit.com/r/ChatGPT/comments/13ygr47/i_have_reviewed_over_1000_ai_tools_for_my/	676	1685721851.0	"With ChatGPT blowing up over the past year, it seems like every person and their grandmother is launching an AI startup. There are a plethora of AI tools available, some excellent and some less so. Amid this flood of new technology, there are a few hidden gems that I personally find incredibly useful, having reviewed them for my AI directory. Here are the ones I have personally integrated into my workflow in both my professional and entreprenuerial life:  


* **Plus AI for Google Slides -** Generate Presentations  
There's a few slide deck generators out there however I've found Plus AI works much better at helping you 'co-write' slides rather than simply spitting out a mediocre finished product that likely won't be useful. For instance, there's ""sticky notes"" to slides with suggestions on how to finish / edit / improve each slide. Another major reason why I've stuck with Plus AI is the ability for ""snapshots"", or the ability to use external data (i.e. from web sources/dashboards) for your presentations. For my day job I work in a chemical plant as an engineer, and one of my tasks is to present in meetings about production KPIs to different groups for different purposes- and graphs for these are often found across various internal web apps. I can simply use Plus AI to generate ""boilerplate"" for my slide deck, then go through each slide to make sure it's using the correct snapshot. The presentation generator itself is completely free and available as a plugin for Google Slides and Docs.  

---

* **My AskAI -** ChatGPT Trained on Your Documents  
Great tool for using ChatGPT on your own files and website. Works very well especially if you are dealing with a lot of documents. The basic plan allows you to upload over 100 files and this was a life saver during online, open book exams for a few training courses I've taken. I've noticed it hallucinates much less compared to other GPT-powered bots trained on your knowledge base. For this reason I prefer My AskAI for research or any tasks where accuracy is needed over the other custom chatbot solutions I have tried. Another plus is that it shows the sources within your knowledge base where it got the answers from, and you can choose to have it give you a more concise answer or a more detailed one. There's a free plan however it was worth it for me to get the $20/mo option as it allows over 100 pieces of content.  

---

* **Krater.ai** **-** All AI Tools in One App  
Perfect solution if you use many AI tools and loathe having to have multiple tabs open. Essentially combines text, audio, and image-based generative AI tools into a single web app, so you can continue with your workflow without having to switch tabs all the time. There's plenty of templates available for copywriting- it beats having to prompt manually each time or having to save and reference prompts over and over again. I prefer Krater over Writesonic/Jasper for ease of use. You also get 10 generations a month for free compared to Jasper offering none, so its a better free option if you want an all-in-one AI content solution. The text to speech feature is simple however works reliably fast and offers multilingual transcription, and the image generator tool is great for photo-realistic images.  

---

* **HARPA AI -** ChatGPT Inside Chrome  
Simply by far the best GTP add-on for Chrome I've used. Essentially gives you GPT answers beside the typical search results on any search engine such as Google or Bing, along with the option to ""chat"" with any web page or summarize YouTube videos. Also great for writing emails and replying to social media posts with its preset templates. Currently they don't have any paid features, so it's entirely free and you can find it on the chrome web store for extensions.  

---

* **Taskade -** All in One Productivity/Notes/Organization AI Tool  
Combines tasks, notes, mind maps, chat, and an AI chat assistant all within one platform that syncs across your team. Definitely simplifies my day-to-day operations, removing the need to swap between numerous apps. Also helps me to visualize my work in various views - list, board, calendar, mind map, org chart, action views - it's like having a Swiss Army knife for productivity. Personally I really like the AI 'mind map.' It's like having a brainstorming partner that never runs out of energy. Taskade's free version has quite a lot to offer so no complaints there.  

---

* **Zapier + OpenAI -** AI-Augmented Automations  
Definitely my secret productivity powerhouse. Pretty much combines the power of Zapier's cross-platform integrations with generative AI. One of the ways I've used this is pushing Slack messages to create a task on Notion, with OpenAI writing the task based on the content of the message. Another useful automation I've used is for automatically writing reply drafts with GPT from emails that get sent to me in Gmail. The opportunities are pretty endless with this method and you can pretty much integrate any automation with GPT 3, as well as DALLE-2 and Whisper AI. It's available as an app/add-on to Zapier and its free for all the core features.  

---

* **SaneBox -** AI Emails Management  
If you are like me and find important emails getting lost in a sea of spam, this is a great solution. Basically Sanebox uses AI to sift through your inbox and identify emails that are actually important, and you can also set it up to make certain emails go to specific folders. Non important emails get sent to a folder called SaneLater and this is something you can ignore entirely or check once in a while. Keep in mind that SaneBox doesn't actually read the contents of your email, but rather takes into consideration the header, metadata, and history with the sender. You can also finetune the system by dragging emails to the folder it should have gone to. Another great feature is the their ""Deep Clean"", which is great for freeing up space by deleting old emails you probably won't ever need anymore. Sanebox doesn't have a free plan however they do have a 2 week trial, and the pricing is quite affordable, depending on the features you need.  

---

* **Hexowatch AI -** Detect Website Changes with AI  
Lifesaver if you need to ever need to keep track of multiple websites. I use this personally for my AI tools directory, and it notifies me of any changes made to any of the 1000+ websites for AI tools I have listed, which is something that would take up more time than exists in a single day if I wanted to keep on top of this manually. The AI detects any types of changes (visual/HTML) on monitored webpages and sends alert via email or Slack/Telegram/Zapier. Like Sanebox there's no free plan however you do get what you pay for with this one.  

---

* **Bonus: SongsLike X -** Find Similar Songs  
This one won't be generating emails or presentations anytime soon, but if you like grinding along to music like me you'll find this amazing. Ironically it's probably the one I use most on a daily basis. You can enter any song and it will automatically generate a Spotify playlist for you with similar songs. I find it much more accurate than Spotify's ""go to song radio"" feature.  


While it's clear that not all of these tools may be directly applicable to your needs, I believe that simply being aware of the range of options available can be greatly beneficial. This knowledge can broaden your perspective on what's possible and potentially inspire new ideas.

**P.S. If you liked this,** as mentioned previously I've created a [free directory](https://aiscout.net/) that lists over 1000 AI tools. It's updated daily and there's also a GPT-powered chatbot to help you AI tools for your needs. Feel free to check it out if it's your cup of tea"
116	ChatGPT with the galaxy brain move.	10494	14j01dm	https://i.redd.it/svj1fu9qu88b1.jpg	294	1687733736.0	
117	Anyone ever seen GPT-4 make a typo before?	9637	13t216j	https://i.redd.it/7etbf5iumd2b1.jpg	868	1685176472.0	
118	I’ve been going back and forth with the lawyers for the guy im suing and today I had to reveal ive been using ChatGPT this whole time because they assumed my legal strategy, petitions, the many documents, affidavits, etc, ive sent in during this whole debacle could only be coming from another lawyer	9072	13ka7rg	https://www.reddit.com/gallery/13ka7rg	720	1684348744.0	
119	OpenAI now sends email threats?!	8605	14qwa6m	https://i.redd.it/r2l2gbllq1ab1.jpg	1469	1688519235.0	Been sexting with ChatGPT since the beginning and continuously improving my jailbreaking skills. Sometimes my inputs are red or orange flagged but never got any trouble before. However today, the second after one of my inputs was orange flagged, I received an email threatening to terminate my services. Has anyone received similar emails?
120	5 things I wish I knew before building a GPT agent for log analysis	31	141l6oy	https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/	4	1685984881.0	"Three weeks ago I started developing a [ReAct Agent](https://dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app. A ReAct agent uses reasoning and logic combined with external tools to fulfill a task. The app - [LogPal.ai](https://logpal.aio/)  \- lets you ask questions about the data in app log file files,  generating SQL queries and Javascript charts to analyze the data.

After a rough start, I’ve found a bit of a groove. I wanted to share five things I wish I knew before developing a GPT-powered agent.

[A crude demo of LogPal.ai executing a ReAct agent to answer questions about a log file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A quick demo showing the stark difference between GPT-3.5 and GPT-4 when running a ReAct agent loop. ](https://reddit.com/link/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a GPT-4 API limit increase, I needed to use the gpt-3.5-turbo  
 model instead. It sucked: poor code,  malformed JSON, and bizarre responses are the norm.

However, there’s a silver lining! gpt-3.5-turbo is great for adding chaos to your agent loop and seeing how resilient your code is to errors.

## 2. Don’t use a framework

[A quick ReAct intro and demo of the ReAct agent in action within the OpenAI Playground. ](https://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I started with [Langchain](https://github.com/hwchase17/langchain), but I had a hell of time debugging and tweaking the framework to suit my needs. Next, I shifted to [Boxcars](https://github.com/BoxcarsAI/boxcars),  which has fewer abstractions. While Boxcars was easier to understand, I  still struggled when things behaved differently than I’d expected.  Finally, I said screw it…I’m not doing *that much*:

1. Sending and receiving text
2. Parsing text
3. Executing external tools

Why not write this logic myself? I’m not the type that likes to  reinvent the wheel, so I came to this conclusion reluctantly. However,  implementing the above didn’t seem *that hard*, gave me ultimate flexibility, and forced me to learn how ReAct works.

I started with a [zero shot prompt](https://www.promptingguide.ai/techniques/zeroshot) that closely resembles the prompt in the [ReAct paper](https://arxiv.org/abs/2210.03629) with one addition: asking for output in JSON format (more on that later…it’s far from bulletproof).

This roll-my-own strategy ended up paying huge dividends due to the  need for prompt-specific context, output formats, and error handling.

## 3. Prompts need specific handling

[ A quick demo of the SQL query generator prompt re-generating a correct SQL query after an initial error. ](https://reddit.com/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my app has three prompts:

1. Zero shot ReAct prompt
2. SQL query generator prompt
3. Javascript chart generator prompt

I’ve found that each prompt needs customized context, output formats, and error handling for the agent to perform well.

### Customized context

There are 3 messaging-related parts of an [OpenAI API request](https://platform.openai.com/docs/guides/gpt/chat-completions-api) you can tweak:

1. **System message** \- the prompt text
2. **User messages** \- input from the user (ex: “What’s the average response time?”)
3. **Assistant messages** \- completions from the API

The user and assistant messages are used to give the model more  context. Unlike ChatGPT (which automatically builds context from prior  messages), you need to provide the history yourself when using the API.  At first, I sent each prompt the same message history, which was every  user and assistant message in the chat history. However, with this  simple approach, I would frequently get bizarre responses to questions.  For example, I might ask “What is the request throughput?”, and receive a  bizarre final answer like “There were no request errors”.

After lots of experimentation (more later on how to iterate quickly  on the message context), I found that sending prompt-specific context  generates the most helpful completions:

1. **Zero shot** \- all messages (including tool output) after the last answered question.
2. **SQL query generator** \- previously generated  queries and the error output associated when executing each SQL  statement (if an error is present). The error output is critical for  helping the query generator correct itself if an original query is  invalid.
3. **Chart generator** \- similar to the SQL query generator, I send previously generated charts and any error output (if present).

While increasing the max context token size is frequently seen as *the path*  to better completions, I saw a correlation between increased context  length and off-track  completions. What I provided as context mattered a  lot.

### Machine-readable output formats

The examples I started from for a ReAct agent all asked for  completions in a plain-text format. However, I found that building  regexes to parse the output was incredibly brittle due to the  non-deterministic behavior of the GPT models and the complexity of some  completions, which include code snippets.

Here’s what’s worked best for me:

1. **Zero shot ReAct prompt** \- JSON. Continue below for how I handle malformed JSON (which happens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-flavored code blocks (triple backticks). I then use a regex to  parse out the code block. Remarkably, this has been very reliable.

### Error handling

I’ve found that the ReAct prompt and the code generator prompts require two different types of error handling:

1. **Zero shot ReAct prompt** \- if the JSON is malformed  (this happens), I simply repeat the same API request. More often than  not, this returns valid JSON on later attempts.
2. **SQL & Chart generator prompts** \- I’ve yet to  see a malformed GitHub-flavored code block. Instead, the most common  issue is an invalid SQL query. I include the generated SQL and error  output in the next API request. This has been very effective at  correcting the output.

🤷 - I don’t know why JSON is frequently malformed but code blocks are not.

# 4. Increase your dev cycles with a replay tool

[Showing the replay tool in action and forcing a hallucination.](https://reddit.com/link/141l6oy/video/4ts2unzyd84b1/player)

Learning to customize the context, output formats, and error handling  based on the prompt type came from replicating my API requests in the [OpenAI Playground](https://platform.openai.com/playground).  I would copy and paste the prompt, user messages, and assistant  messages into the playground, and then modify the inputs to see if I  could get a better response. The manual copy and pasting was a slow  process.

To move faster, I created an OpenAIReplay tool. When I  make an API request, I save the API request parameters and the response  to a file. I can then load the file, modify the request parameters, and  replay the request. This tool has been huge for debugging as it’s much  faster than copying and pasting into the playground. My tool is  app-specific, but it’s an easy thing to build. My tool works like this:

    # loads the message, writes the message's API request params to a file, and opens the file in VS Code for editing. replay = OpenAiReplay.from_message(message_id_or_object = Message.last) # ... make edits to the file ... replay.chat! 

## 5. Use the stream API option

The GPT API is slower than what you see in ChatGPT ([source](https://community.openai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In my experience, it’s critical to use the [stream](https://platform.openai.com/docs/api-reference/completions/create)  mode of the API versus waiting for a full completion to speed up dev  cycles (especially if you are generating long completions):

1. I think stream is a bit faster to reach a completion
2. Waiting for a full completion frequently results in API timeout and 503 errors
3. You can quickly abort if it’s clear that the completion is going to be bad

In short: *coupling a replay tool with streaming completions is the fastest way to iterate on your agent.*

## TL;DR

If I was building [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use GPT-4**. It’s far better than gpt-3.5-turboat reasoning and code completion. gpt-3.5-turbois great for introducing chaos into your agent loop when testing.
2. **Not use an LLM app framework.** Start with your language’s OpenAI API client and build from there.
3. **Plan on customizing prompt context, output formats, and error handling.** This is critical for getting good completions.
4. **Create/use an API replay tool**. Make it easy to replay API calls as it’s too slow to copy & paste these into the OpenAI playground.
5. **Stream completions**. Use the stream mode of the API to speed up dev cycles. You can quickly abort if a completion is off the rails."
121	Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial	14	12lyu24	https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/	0	1681481977.0	"Hey there!   


I wanted to let you know that I just released a new video where I'm using some really cool technologies like Python, OpenAI API's, Chroma, and LangChain to answer questions based on Youtube videos.

If you don't have the time or patience to sit through a 3-hour lecture, no worries!   
My tutorial covers a solution!

I'm really excited to share this with you and I think you'll find it super helpful.  
check out the video here: [**https://youtu.be/mhdOTLp-IjQ**](https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"
122	I made a dashboard to analyze OpenAI API usage	15	13aqw5j	https://v.redd.it/vrz3h5bv8fya1	5	1683470617.0	
123	I built an app to help you get full visibility and control over your OpenAI costs.	13	13katfn	https://i.redd.it/te4jhjr3wf0b1.png	0	1684350106.0	
124	OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform	11	148xhn3	https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/	6	1686713922.0	"The GPT-3.5 Turbo model has been updated to 16k as of today and is priced at $0.003 per 1K input tokens and $0.004 per 1K output tokens.

This new version is more steerable with the system message and includes a new capability: function calling. By describing functions in your prompts, the model can intelligently output a JSON object containing arguments to call these functions based on user input — perfect for integrating with other tools or APIs.

OpenAI has also reduced the cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015 per 1K input tokens), effective immediately.

On June 27th, the stable gpt-3.5-turbo will be automatically upgraded. 

#AI #OpenAI[Function calling and other API](https://openai.com/blog/function-calling-and-other-api-updates)"
125	Query current data - OpenAI Embeddings, Chroma and LangChain	9	12huv4f	https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/	2	1681158025.0	"Hi guys, I created a video on how to use Chroma in combination with LangChain and the Wikipedia API to query your own data.

Asking about your own data is the future of LLMs!   


Disclaimer: Own data can be everything which is text!

[https://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[https://github.com/grumpyp/chroma-langchain-tutorial](https://github.com/grumpyp/chroma-langchain-tutorial)

hope you enjoy it!"
126	How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch	10	148jhur	https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/	2	1686674014.0	"I created a semantic Q&A  bot for >13k recorded (webscraped, that is...) dreams using OpenAI embeddings APIs, Langchain and  Elasticsearch. It can answer queries like this one:  


""Find me all dreams containing animals, and provide me a list with their activities.""  


What  it returns are not only a proper, meaningful answer, but also  references to  relevant documents. Imagine for a moment how hard running  such a query with a traditional search engine would be! More or less  impossible for 13k documents! First of all, there is no clearly defined  concept of what an ""animal"" is, you'd end up specifying a long list of  actual animals in your input query. Second, once you identified them  you'd have to manually derive what their activities are, the text search  engine is not able to do that for you.  


Of course, there is a lot  of vagueness and fuzziness in how such a system operates. So, there's a  tradeoff here: A semantic Q&A bot is very powerful, but at the same  time you have to put a lot of (blind) trust in it. How can you know the  system does not ""forget"" an important animal or document? Well, you  cannot. But then again, would it be really better to do all of this  manually? As usual, the answer depends on your requirements. I think a  semantic Q&A bot is great if you're after convenience and speed, but  not so good if your primary goals are correctness and recall &  precision.  


I believe such semantic Q&A bots may have the  potential to become an important piece in scientific research, as they  are at the intersection between qualitative (e.g. hermeneutic) and  quantitative research. For example, a researcher who has a dataset of  transcribed interviews can easily test few hypotheses on them to get a  first summary on relevant points. Later on, she might decide to dive  into some of them.

[https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/](https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/)"
127	Someone hacked my OpenAI account and used 4000$ worth of tokens	9	154o35w	https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/	18	1689851811.0	"Someone just hacked my OpenAI account and used all the credits. I don't know how this happended but It seems like some chrome extension might have read my ID and passwords then he just logged into my account and reset the hard limit of my account and started using it for their personal use. I just checked my account and it says that I need to pay 4000$ which I haven't used.

I can't even afford to pay this much of amount. I've raised a request in OpenAI support. Hoping for a good outcome.

Why am I suspecting that hacker got my account not just an API Key

\- Hard limit was reset to 4000$ (Previously it was much lower 500$ or even less)

\- Generated a new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in any of my product

There should be a email verification or 2FA while changing the hard limit of the account. I got the email when my hard limit reached not when someone changed the hard limit of my account and used all the credits.

Just yesterday, I got notification from Google chrome that there was one extension I've installed was found malicious which I've immeditely removed. I suspect it might have stolen the account ID and password do this malicious activity.

https://preview.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=webp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"
128	Open Source - OpenAI , Chroma , LangChain , HuggingFace sample	10	13pdymt	https://i.redd.it/v2amznhrvj1b1.jpg	4	1684816263.0	Python - upload your docs, persist embeddings in Chroma and build using huggingface transformers, delete, rebuild Chroma embeddings store, use LangChain agent for querying across the documents - https://github.com/ushakrishnan/SearchWithOpenAI
129	What this sub is about and what are the differences to other subs	9	12gua7o	https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/	5	1681071204.0	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a subreddit dedicated to serious discussion of artificial intelligence, machine learning, natural language processing, and related topics.

At r/OpenAIDev, we’re focused on your creations/inspirations, quality content, breaking news, and advancements in the field of AI. We want to foster a community where people can come together to learn, discuss, and share their knowledge and ideas.
We also want to **encourage others that feel lost since AI moves so rapidly and job loss is the most discussed topic**. As a 20y+ experienced programmer myself I see it as a helpful tool that speeds up my work every day. And I think everyone can take advantage of it and try to focus on the positive side when they know how. We try to share that knowledge.

That being said, **we are not a meme subreddit**, and we do not support low-effort posts or reposts. Our focus is on substantive content that drives thoughtful discussion and encourages learning and growth.

We welcome anyone who is curious about AI and passionate about exploring its potential to join our community. Whether you’re a seasoned expert or just starting out, we hope you’ll find a home here at r/OpenAIDev.

We also have a **Discord channel that lets you use MidJourney at my costs** (The trial option has been recently removed by MidJourney). Since I just play with some prompts from time to time I don't mind to let everyone use it for now until the monthly limit is reached:

https://discord.gg/GmmCSMJqpb

So come on in, share your knowledge, ask your questions, and let’s explore the exciting world of AI together!

There are now some basic rules available as well as post and user flairs. **Please suggest new flairs if you have ideas**.

When there is **interest to become a mod of this sub** please send a DM with your experience and available time. Thanks."
130	5 things I wish I knew before building a GPT agent for log analysis	32	141l6oy	https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/	4	1685984881.0	"Three weeks ago I started developing a [ReAct Agent](https://dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app. A ReAct agent uses reasoning and logic combined with external tools to fulfill a task. The app - [LogPal.ai](https://logpal.aio/)  \- lets you ask questions about the data in app log file files,  generating SQL queries and Javascript charts to analyze the data.

After a rough start, I’ve found a bit of a groove. I wanted to share five things I wish I knew before developing a GPT-powered agent.

[A crude demo of LogPal.ai executing a ReAct agent to answer questions about a log file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A quick demo showing the stark difference between GPT-3.5 and GPT-4 when running a ReAct agent loop. ](https://reddit.com/link/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a GPT-4 API limit increase, I needed to use the gpt-3.5-turbo  
 model instead. It sucked: poor code,  malformed JSON, and bizarre responses are the norm.

However, there’s a silver lining! gpt-3.5-turbo is great for adding chaos to your agent loop and seeing how resilient your code is to errors.

## 2. Don’t use a framework

[A quick ReAct intro and demo of the ReAct agent in action within the OpenAI Playground. ](https://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I started with [Langchain](https://github.com/hwchase17/langchain), but I had a hell of time debugging and tweaking the framework to suit my needs. Next, I shifted to [Boxcars](https://github.com/BoxcarsAI/boxcars),  which has fewer abstractions. While Boxcars was easier to understand, I  still struggled when things behaved differently than I’d expected.  Finally, I said screw it…I’m not doing *that much*:

1. Sending and receiving text
2. Parsing text
3. Executing external tools

Why not write this logic myself? I’m not the type that likes to  reinvent the wheel, so I came to this conclusion reluctantly. However,  implementing the above didn’t seem *that hard*, gave me ultimate flexibility, and forced me to learn how ReAct works.

I started with a [zero shot prompt](https://www.promptingguide.ai/techniques/zeroshot) that closely resembles the prompt in the [ReAct paper](https://arxiv.org/abs/2210.03629) with one addition: asking for output in JSON format (more on that later…it’s far from bulletproof).

This roll-my-own strategy ended up paying huge dividends due to the  need for prompt-specific context, output formats, and error handling.

## 3. Prompts need specific handling

[ A quick demo of the SQL query generator prompt re-generating a correct SQL query after an initial error. ](https://reddit.com/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my app has three prompts:

1. Zero shot ReAct prompt
2. SQL query generator prompt
3. Javascript chart generator prompt

I’ve found that each prompt needs customized context, output formats, and error handling for the agent to perform well.

### Customized context

There are 3 messaging-related parts of an [OpenAI API request](https://platform.openai.com/docs/guides/gpt/chat-completions-api) you can tweak:

1. **System message** \- the prompt text
2. **User messages** \- input from the user (ex: “What’s the average response time?”)
3. **Assistant messages** \- completions from the API

The user and assistant messages are used to give the model more  context. Unlike ChatGPT (which automatically builds context from prior  messages), you need to provide the history yourself when using the API.  At first, I sent each prompt the same message history, which was every  user and assistant message in the chat history. However, with this  simple approach, I would frequently get bizarre responses to questions.  For example, I might ask “What is the request throughput?”, and receive a  bizarre final answer like “There were no request errors”.

After lots of experimentation (more later on how to iterate quickly  on the message context), I found that sending prompt-specific context  generates the most helpful completions:

1. **Zero shot** \- all messages (including tool output) after the last answered question.
2. **SQL query generator** \- previously generated  queries and the error output associated when executing each SQL  statement (if an error is present). The error output is critical for  helping the query generator correct itself if an original query is  invalid.
3. **Chart generator** \- similar to the SQL query generator, I send previously generated charts and any error output (if present).

While increasing the max context token size is frequently seen as *the path*  to better completions, I saw a correlation between increased context  length and off-track  completions. What I provided as context mattered a  lot.

### Machine-readable output formats

The examples I started from for a ReAct agent all asked for  completions in a plain-text format. However, I found that building  regexes to parse the output was incredibly brittle due to the  non-deterministic behavior of the GPT models and the complexity of some  completions, which include code snippets.

Here’s what’s worked best for me:

1. **Zero shot ReAct prompt** \- JSON. Continue below for how I handle malformed JSON (which happens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-flavored code blocks (triple backticks). I then use a regex to  parse out the code block. Remarkably, this has been very reliable.

### Error handling

I’ve found that the ReAct prompt and the code generator prompts require two different types of error handling:

1. **Zero shot ReAct prompt** \- if the JSON is malformed  (this happens), I simply repeat the same API request. More often than  not, this returns valid JSON on later attempts.
2. **SQL & Chart generator prompts** \- I’ve yet to  see a malformed GitHub-flavored code block. Instead, the most common  issue is an invalid SQL query. I include the generated SQL and error  output in the next API request. This has been very effective at  correcting the output.

🤷 - I don’t know why JSON is frequently malformed but code blocks are not.

# 4. Increase your dev cycles with a replay tool

[Showing the replay tool in action and forcing a hallucination.](https://reddit.com/link/141l6oy/video/4ts2unzyd84b1/player)

Learning to customize the context, output formats, and error handling  based on the prompt type came from replicating my API requests in the [OpenAI Playground](https://platform.openai.com/playground).  I would copy and paste the prompt, user messages, and assistant  messages into the playground, and then modify the inputs to see if I  could get a better response. The manual copy and pasting was a slow  process.

To move faster, I created an OpenAIReplay tool. When I  make an API request, I save the API request parameters and the response  to a file. I can then load the file, modify the request parameters, and  replay the request. This tool has been huge for debugging as it’s much  faster than copying and pasting into the playground. My tool is  app-specific, but it’s an easy thing to build. My tool works like this:

    # loads the message, writes the message's API request params to a file, and opens the file in VS Code for editing. replay = OpenAiReplay.from_message(message_id_or_object = Message.last) # ... make edits to the file ... replay.chat! 

## 5. Use the stream API option

The GPT API is slower than what you see in ChatGPT ([source](https://community.openai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In my experience, it’s critical to use the [stream](https://platform.openai.com/docs/api-reference/completions/create)  mode of the API versus waiting for a full completion to speed up dev  cycles (especially if you are generating long completions):

1. I think stream is a bit faster to reach a completion
2. Waiting for a full completion frequently results in API timeout and 503 errors
3. You can quickly abort if it’s clear that the completion is going to be bad

In short: *coupling a replay tool with streaming completions is the fastest way to iterate on your agent.*

## TL;DR

If I was building [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use GPT-4**. It’s far better than gpt-3.5-turboat reasoning and code completion. gpt-3.5-turbois great for introducing chaos into your agent loop when testing.
2. **Not use an LLM app framework.** Start with your language’s OpenAI API client and build from there.
3. **Plan on customizing prompt context, output formats, and error handling.** This is critical for getting good completions.
4. **Create/use an API replay tool**. Make it easy to replay API calls as it’s too slow to copy & paste these into the OpenAI playground.
5. **Stream completions**. Use the stream mode of the API to speed up dev cycles. You can quickly abort if a completion is off the rails."
131	Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial	15	12lyu24	https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/	0	1681481977.0	"Hey there!   


I wanted to let you know that I just released a new video where I'm using some really cool technologies like Python, OpenAI API's, Chroma, and LangChain to answer questions based on Youtube videos.

If you don't have the time or patience to sit through a 3-hour lecture, no worries!   
My tutorial covers a solution!

I'm really excited to share this with you and I think you'll find it super helpful.  
check out the video here: [**https://youtu.be/mhdOTLp-IjQ**](https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"
132	I made a dashboard to analyze OpenAI API usage	16	13aqw5j	https://v.redd.it/vrz3h5bv8fya1	5	1683470617.0	
133	I built an app to help you get full visibility and control over your OpenAI costs.	14	13katfn	https://i.redd.it/te4jhjr3wf0b1.png	0	1684350106.0	
134	OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform	11	148xhn3	https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/	6	1686713922.0	"The GPT-3.5 Turbo model has been updated to 16k as of today and is priced at $0.003 per 1K input tokens and $0.004 per 1K output tokens.

This new version is more steerable with the system message and includes a new capability: function calling. By describing functions in your prompts, the model can intelligently output a JSON object containing arguments to call these functions based on user input — perfect for integrating with other tools or APIs.

OpenAI has also reduced the cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015 per 1K input tokens), effective immediately.

On June 27th, the stable gpt-3.5-turbo will be automatically upgraded. 

#AI #OpenAI[Function calling and other API](https://openai.com/blog/function-calling-and-other-api-updates)"
135	Query current data - OpenAI Embeddings, Chroma and LangChain	10	12huv4f	https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/	2	1681158025.0	"Hi guys, I created a video on how to use Chroma in combination with LangChain and the Wikipedia API to query your own data.

Asking about your own data is the future of LLMs!   


Disclaimer: Own data can be everything which is text!

[https://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[https://github.com/grumpyp/chroma-langchain-tutorial](https://github.com/grumpyp/chroma-langchain-tutorial)

hope you enjoy it!"
136	How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch	9	148jhur	https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/	2	1686674014.0	"I created a semantic Q&A  bot for >13k recorded (webscraped, that is...) dreams using OpenAI embeddings APIs, Langchain and  Elasticsearch. It can answer queries like this one:  


""Find me all dreams containing animals, and provide me a list with their activities.""  


What  it returns are not only a proper, meaningful answer, but also  references to  relevant documents. Imagine for a moment how hard running  such a query with a traditional search engine would be! More or less  impossible for 13k documents! First of all, there is no clearly defined  concept of what an ""animal"" is, you'd end up specifying a long list of  actual animals in your input query. Second, once you identified them  you'd have to manually derive what their activities are, the text search  engine is not able to do that for you.  


Of course, there is a lot  of vagueness and fuzziness in how such a system operates. So, there's a  tradeoff here: A semantic Q&A bot is very powerful, but at the same  time you have to put a lot of (blind) trust in it. How can you know the  system does not ""forget"" an important animal or document? Well, you  cannot. But then again, would it be really better to do all of this  manually? As usual, the answer depends on your requirements. I think a  semantic Q&A bot is great if you're after convenience and speed, but  not so good if your primary goals are correctness and recall &  precision.  


I believe such semantic Q&A bots may have the  potential to become an important piece in scientific research, as they  are at the intersection between qualitative (e.g. hermeneutic) and  quantitative research. For example, a researcher who has a dataset of  transcribed interviews can easily test few hypotheses on them to get a  first summary on relevant points. Later on, she might decide to dive  into some of them.

[https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/](https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/)"
137	Someone hacked my OpenAI account and used 4000$ worth of tokens	10	154o35w	https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/	18	1689851811.0	"Someone just hacked my OpenAI account and used all the credits. I don't know how this happended but It seems like some chrome extension might have read my ID and passwords then he just logged into my account and reset the hard limit of my account and started using it for their personal use. I just checked my account and it says that I need to pay 4000$ which I haven't used.

I can't even afford to pay this much of amount. I've raised a request in OpenAI support. Hoping for a good outcome.

Why am I suspecting that hacker got my account not just an API Key

\- Hard limit was reset to 4000$ (Previously it was much lower 500$ or even less)

\- Generated a new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in any of my product

There should be a email verification or 2FA while changing the hard limit of the account. I got the email when my hard limit reached not when someone changed the hard limit of my account and used all the credits.

Just yesterday, I got notification from Google chrome that there was one extension I've installed was found malicious which I've immeditely removed. I suspect it might have stolen the account ID and password do this malicious activity.

https://preview.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=webp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"
138	Open Source - OpenAI , Chroma , LangChain , HuggingFace sample	11	13pdymt	https://i.redd.it/v2amznhrvj1b1.jpg	4	1684816263.0	Python - upload your docs, persist embeddings in Chroma and build using huggingface transformers, delete, rebuild Chroma embeddings store, use LangChain agent for querying across the documents - https://github.com/ushakrishnan/SearchWithOpenAI
139	What this sub is about and what are the differences to other subs	9	12gua7o	https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/	5	1681071204.0	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a subreddit dedicated to serious discussion of artificial intelligence, machine learning, natural language processing, and related topics.

At r/OpenAIDev, we’re focused on your creations/inspirations, quality content, breaking news, and advancements in the field of AI. We want to foster a community where people can come together to learn, discuss, and share their knowledge and ideas.
We also want to **encourage others that feel lost since AI moves so rapidly and job loss is the most discussed topic**. As a 20y+ experienced programmer myself I see it as a helpful tool that speeds up my work every day. And I think everyone can take advantage of it and try to focus on the positive side when they know how. We try to share that knowledge.

That being said, **we are not a meme subreddit**, and we do not support low-effort posts or reposts. Our focus is on substantive content that drives thoughtful discussion and encourages learning and growth.

We welcome anyone who is curious about AI and passionate about exploring its potential to join our community. Whether you’re a seasoned expert or just starting out, we hope you’ll find a home here at r/OpenAIDev.

We also have a **Discord channel that lets you use MidJourney at my costs** (The trial option has been recently removed by MidJourney). Since I just play with some prompts from time to time I don't mind to let everyone use it for now until the monthly limit is reached:

https://discord.gg/GmmCSMJqpb

So come on in, share your knowledge, ask your questions, and let’s explore the exciting world of AI together!

There are now some basic rules available as well as post and user flairs. **Please suggest new flairs if you have ideas**.

When there is **interest to become a mod of this sub** please send a DM with your experience and available time. Thanks."
140	5 things I wish I knew before building a GPT agent for log analysis	34	141l6oy	https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/	4	1685984881.0	"Three weeks ago I started developing a [ReAct Agent](https://dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app. A ReAct agent uses reasoning and logic combined with external tools to fulfill a task. The app - [LogPal.ai](https://logpal.aio/)  \- lets you ask questions about the data in app log file files,  generating SQL queries and Javascript charts to analyze the data.

After a rough start, I’ve found a bit of a groove. I wanted to share five things I wish I knew before developing a GPT-powered agent.

[A crude demo of LogPal.ai executing a ReAct agent to answer questions about a log file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A quick demo showing the stark difference between GPT-3.5 and GPT-4 when running a ReAct agent loop. ](https://reddit.com/link/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a GPT-4 API limit increase, I needed to use the gpt-3.5-turbo  
 model instead. It sucked: poor code,  malformed JSON, and bizarre responses are the norm.

However, there’s a silver lining! gpt-3.5-turbo is great for adding chaos to your agent loop and seeing how resilient your code is to errors.

## 2. Don’t use a framework

[A quick ReAct intro and demo of the ReAct agent in action within the OpenAI Playground. ](https://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I started with [Langchain](https://github.com/hwchase17/langchain), but I had a hell of time debugging and tweaking the framework to suit my needs. Next, I shifted to [Boxcars](https://github.com/BoxcarsAI/boxcars),  which has fewer abstractions. While Boxcars was easier to understand, I  still struggled when things behaved differently than I’d expected.  Finally, I said screw it…I’m not doing *that much*:

1. Sending and receiving text
2. Parsing text
3. Executing external tools

Why not write this logic myself? I’m not the type that likes to  reinvent the wheel, so I came to this conclusion reluctantly. However,  implementing the above didn’t seem *that hard*, gave me ultimate flexibility, and forced me to learn how ReAct works.

I started with a [zero shot prompt](https://www.promptingguide.ai/techniques/zeroshot) that closely resembles the prompt in the [ReAct paper](https://arxiv.org/abs/2210.03629) with one addition: asking for output in JSON format (more on that later…it’s far from bulletproof).

This roll-my-own strategy ended up paying huge dividends due to the  need for prompt-specific context, output formats, and error handling.

## 3. Prompts need specific handling

[ A quick demo of the SQL query generator prompt re-generating a correct SQL query after an initial error. ](https://reddit.com/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my app has three prompts:

1. Zero shot ReAct prompt
2. SQL query generator prompt
3. Javascript chart generator prompt

I’ve found that each prompt needs customized context, output formats, and error handling for the agent to perform well.

### Customized context

There are 3 messaging-related parts of an [OpenAI API request](https://platform.openai.com/docs/guides/gpt/chat-completions-api) you can tweak:

1. **System message** \- the prompt text
2. **User messages** \- input from the user (ex: “What’s the average response time?”)
3. **Assistant messages** \- completions from the API

The user and assistant messages are used to give the model more  context. Unlike ChatGPT (which automatically builds context from prior  messages), you need to provide the history yourself when using the API.  At first, I sent each prompt the same message history, which was every  user and assistant message in the chat history. However, with this  simple approach, I would frequently get bizarre responses to questions.  For example, I might ask “What is the request throughput?”, and receive a  bizarre final answer like “There were no request errors”.

After lots of experimentation (more later on how to iterate quickly  on the message context), I found that sending prompt-specific context  generates the most helpful completions:

1. **Zero shot** \- all messages (including tool output) after the last answered question.
2. **SQL query generator** \- previously generated  queries and the error output associated when executing each SQL  statement (if an error is present). The error output is critical for  helping the query generator correct itself if an original query is  invalid.
3. **Chart generator** \- similar to the SQL query generator, I send previously generated charts and any error output (if present).

While increasing the max context token size is frequently seen as *the path*  to better completions, I saw a correlation between increased context  length and off-track  completions. What I provided as context mattered a  lot.

### Machine-readable output formats

The examples I started from for a ReAct agent all asked for  completions in a plain-text format. However, I found that building  regexes to parse the output was incredibly brittle due to the  non-deterministic behavior of the GPT models and the complexity of some  completions, which include code snippets.

Here’s what’s worked best for me:

1. **Zero shot ReAct prompt** \- JSON. Continue below for how I handle malformed JSON (which happens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-flavored code blocks (triple backticks). I then use a regex to  parse out the code block. Remarkably, this has been very reliable.

### Error handling

I’ve found that the ReAct prompt and the code generator prompts require two different types of error handling:

1. **Zero shot ReAct prompt** \- if the JSON is malformed  (this happens), I simply repeat the same API request. More often than  not, this returns valid JSON on later attempts.
2. **SQL & Chart generator prompts** \- I’ve yet to  see a malformed GitHub-flavored code block. Instead, the most common  issue is an invalid SQL query. I include the generated SQL and error  output in the next API request. This has been very effective at  correcting the output.

🤷 - I don’t know why JSON is frequently malformed but code blocks are not.

# 4. Increase your dev cycles with a replay tool

[Showing the replay tool in action and forcing a hallucination.](https://reddit.com/link/141l6oy/video/4ts2unzyd84b1/player)

Learning to customize the context, output formats, and error handling  based on the prompt type came from replicating my API requests in the [OpenAI Playground](https://platform.openai.com/playground).  I would copy and paste the prompt, user messages, and assistant  messages into the playground, and then modify the inputs to see if I  could get a better response. The manual copy and pasting was a slow  process.

To move faster, I created an OpenAIReplay tool. When I  make an API request, I save the API request parameters and the response  to a file. I can then load the file, modify the request parameters, and  replay the request. This tool has been huge for debugging as it’s much  faster than copying and pasting into the playground. My tool is  app-specific, but it’s an easy thing to build. My tool works like this:

    # loads the message, writes the message's API request params to a file, and opens the file in VS Code for editing. replay = OpenAiReplay.from_message(message_id_or_object = Message.last) # ... make edits to the file ... replay.chat! 

## 5. Use the stream API option

The GPT API is slower than what you see in ChatGPT ([source](https://community.openai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In my experience, it’s critical to use the [stream](https://platform.openai.com/docs/api-reference/completions/create)  mode of the API versus waiting for a full completion to speed up dev  cycles (especially if you are generating long completions):

1. I think stream is a bit faster to reach a completion
2. Waiting for a full completion frequently results in API timeout and 503 errors
3. You can quickly abort if it’s clear that the completion is going to be bad

In short: *coupling a replay tool with streaming completions is the fastest way to iterate on your agent.*

## TL;DR

If I was building [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use GPT-4**. It’s far better than gpt-3.5-turboat reasoning and code completion. gpt-3.5-turbois great for introducing chaos into your agent loop when testing.
2. **Not use an LLM app framework.** Start with your language’s OpenAI API client and build from there.
3. **Plan on customizing prompt context, output formats, and error handling.** This is critical for getting good completions.
4. **Create/use an API replay tool**. Make it easy to replay API calls as it’s too slow to copy & paste these into the OpenAI playground.
5. **Stream completions**. Use the stream mode of the API to speed up dev cycles. You can quickly abort if a completion is off the rails."
141	Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial	14	12lyu24	https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/	0	1681481977.0	"Hey there!   


I wanted to let you know that I just released a new video where I'm using some really cool technologies like Python, OpenAI API's, Chroma, and LangChain to answer questions based on Youtube videos.

If you don't have the time or patience to sit through a 3-hour lecture, no worries!   
My tutorial covers a solution!

I'm really excited to share this with you and I think you'll find it super helpful.  
check out the video here: [**https://youtu.be/mhdOTLp-IjQ**](https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"
142	I made a dashboard to analyze OpenAI API usage	14	13aqw5j	https://v.redd.it/vrz3h5bv8fya1	5	1683470617.0	
143	I built an app to help you get full visibility and control over your OpenAI costs.	14	13katfn	https://i.redd.it/te4jhjr3wf0b1.png	0	1684350106.0	
144	OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform	11	148xhn3	https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/	6	1686713922.0	"The GPT-3.5 Turbo model has been updated to 16k as of today and is priced at $0.003 per 1K input tokens and $0.004 per 1K output tokens.

This new version is more steerable with the system message and includes a new capability: function calling. By describing functions in your prompts, the model can intelligently output a JSON object containing arguments to call these functions based on user input — perfect for integrating with other tools or APIs.

OpenAI has also reduced the cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015 per 1K input tokens), effective immediately.

On June 27th, the stable gpt-3.5-turbo will be automatically upgraded. 

#AI #OpenAI[Function calling and other API](https://openai.com/blog/function-calling-and-other-api-updates)"
145	Query current data - OpenAI Embeddings, Chroma and LangChain	10	12huv4f	https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/	2	1681158025.0	"Hi guys, I created a video on how to use Chroma in combination with LangChain and the Wikipedia API to query your own data.

Asking about your own data is the future of LLMs!   


Disclaimer: Own data can be everything which is text!

[https://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[https://github.com/grumpyp/chroma-langchain-tutorial](https://github.com/grumpyp/chroma-langchain-tutorial)

hope you enjoy it!"
146	How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch	9	148jhur	https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/	2	1686674014.0	"I created a semantic Q&A  bot for >13k recorded (webscraped, that is...) dreams using OpenAI embeddings APIs, Langchain and  Elasticsearch. It can answer queries like this one:  


""Find me all dreams containing animals, and provide me a list with their activities.""  


What  it returns are not only a proper, meaningful answer, but also  references to  relevant documents. Imagine for a moment how hard running  such a query with a traditional search engine would be! More or less  impossible for 13k documents! First of all, there is no clearly defined  concept of what an ""animal"" is, you'd end up specifying a long list of  actual animals in your input query. Second, once you identified them  you'd have to manually derive what their activities are, the text search  engine is not able to do that for you.  


Of course, there is a lot  of vagueness and fuzziness in how such a system operates. So, there's a  tradeoff here: A semantic Q&A bot is very powerful, but at the same  time you have to put a lot of (blind) trust in it. How can you know the  system does not ""forget"" an important animal or document? Well, you  cannot. But then again, would it be really better to do all of this  manually? As usual, the answer depends on your requirements. I think a  semantic Q&A bot is great if you're after convenience and speed, but  not so good if your primary goals are correctness and recall &  precision.  


I believe such semantic Q&A bots may have the  potential to become an important piece in scientific research, as they  are at the intersection between qualitative (e.g. hermeneutic) and  quantitative research. For example, a researcher who has a dataset of  transcribed interviews can easily test few hypotheses on them to get a  first summary on relevant points. Later on, she might decide to dive  into some of them.

[https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/](https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/)"
147	Someone hacked my OpenAI account and used 4000$ worth of tokens	10	154o35w	https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/	18	1689851811.0	"Someone just hacked my OpenAI account and used all the credits. I don't know how this happended but It seems like some chrome extension might have read my ID and passwords then he just logged into my account and reset the hard limit of my account and started using it for their personal use. I just checked my account and it says that I need to pay 4000$ which I haven't used.

I can't even afford to pay this much of amount. I've raised a request in OpenAI support. Hoping for a good outcome.

Why am I suspecting that hacker got my account not just an API Key

\- Hard limit was reset to 4000$ (Previously it was much lower 500$ or even less)

\- Generated a new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in any of my product

There should be a email verification or 2FA while changing the hard limit of the account. I got the email when my hard limit reached not when someone changed the hard limit of my account and used all the credits.

Just yesterday, I got notification from Google chrome that there was one extension I've installed was found malicious which I've immeditely removed. I suspect it might have stolen the account ID and password do this malicious activity.

https://preview.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=webp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"
148	Open Source - OpenAI , Chroma , LangChain , HuggingFace sample	9	13pdymt	https://i.redd.it/v2amznhrvj1b1.jpg	4	1684816263.0	Python - upload your docs, persist embeddings in Chroma and build using huggingface transformers, delete, rebuild Chroma embeddings store, use LangChain agent for querying across the documents - https://github.com/ushakrishnan/SearchWithOpenAI
149	What this sub is about and what are the differences to other subs	9	12gua7o	https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/	5	1681071204.0	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a subreddit dedicated to serious discussion of artificial intelligence, machine learning, natural language processing, and related topics.

At r/OpenAIDev, we’re focused on your creations/inspirations, quality content, breaking news, and advancements in the field of AI. We want to foster a community where people can come together to learn, discuss, and share their knowledge and ideas.
We also want to **encourage others that feel lost since AI moves so rapidly and job loss is the most discussed topic**. As a 20y+ experienced programmer myself I see it as a helpful tool that speeds up my work every day. And I think everyone can take advantage of it and try to focus on the positive side when they know how. We try to share that knowledge.

That being said, **we are not a meme subreddit**, and we do not support low-effort posts or reposts. Our focus is on substantive content that drives thoughtful discussion and encourages learning and growth.

We welcome anyone who is curious about AI and passionate about exploring its potential to join our community. Whether you’re a seasoned expert or just starting out, we hope you’ll find a home here at r/OpenAIDev.

We also have a **Discord channel that lets you use MidJourney at my costs** (The trial option has been recently removed by MidJourney). Since I just play with some prompts from time to time I don't mind to let everyone use it for now until the monthly limit is reached:

https://discord.gg/GmmCSMJqpb

So come on in, share your knowledge, ask your questions, and let’s explore the exciting world of AI together!

There are now some basic rules available as well as post and user flairs. **Please suggest new flairs if you have ideas**.

When there is **interest to become a mod of this sub** please send a DM with your experience and available time. Thanks."
150	5 things I wish I knew before building a GPT agent for log analysis	32	141l6oy	https://www.reddit.com/r/OpenAIDev/comments/141l6oy/5_things_i_wish_i_knew_before_building_a_gpt/	4	1685984881.0	"Three weeks ago I started developing a [ReAct Agent](https://dlite.cc/2023/05/08/2023-boxcars-ruby-train-intro.html) app. A ReAct agent uses reasoning and logic combined with external tools to fulfill a task. The app - [LogPal.ai](https://logpal.aio/)  \- lets you ask questions about the data in app log file files,  generating SQL queries and Javascript charts to analyze the data.

After a rough start, I’ve found a bit of a groove. I wanted to share five things I wish I knew before developing a GPT-powered agent.

[A crude demo of LogPal.ai executing a ReAct agent to answer questions about a log file. ](https://reddit.com/link/141l6oy/video/2cehyarvc84b1/player)

## 1. GPT-3 is unusable for ReAct agents

[A quick demo showing the stark difference between GPT-3.5 and GPT-4 when running a ReAct agent loop. ](https://reddit.com/link/141l6oy/video/fw21zynjc84b1/player)

 While waiting for a GPT-4 API limit increase, I needed to use the gpt-3.5-turbo  
 model instead. It sucked: poor code,  malformed JSON, and bizarre responses are the norm.

However, there’s a silver lining! gpt-3.5-turbo is great for adding chaos to your agent loop and seeing how resilient your code is to errors.

## 2. Don’t use a framework

[A quick ReAct intro and demo of the ReAct agent in action within the OpenAI Playground. ](https://reddit.com/link/141l6oy/video/3cjlgvhdd84b1/player)

I started with [Langchain](https://github.com/hwchase17/langchain), but I had a hell of time debugging and tweaking the framework to suit my needs. Next, I shifted to [Boxcars](https://github.com/BoxcarsAI/boxcars),  which has fewer abstractions. While Boxcars was easier to understand, I  still struggled when things behaved differently than I’d expected.  Finally, I said screw it…I’m not doing *that much*:

1. Sending and receiving text
2. Parsing text
3. Executing external tools

Why not write this logic myself? I’m not the type that likes to  reinvent the wheel, so I came to this conclusion reluctantly. However,  implementing the above didn’t seem *that hard*, gave me ultimate flexibility, and forced me to learn how ReAct works.

I started with a [zero shot prompt](https://www.promptingguide.ai/techniques/zeroshot) that closely resembles the prompt in the [ReAct paper](https://arxiv.org/abs/2210.03629) with one addition: asking for output in JSON format (more on that later…it’s far from bulletproof).

This roll-my-own strategy ended up paying huge dividends due to the  need for prompt-specific context, output formats, and error handling.

## 3. Prompts need specific handling

[ A quick demo of the SQL query generator prompt re-generating a correct SQL query after an initial error. ](https://reddit.com/link/141l6oy/video/1zh6r7gld84b1/player)

Currently, my app has three prompts:

1. Zero shot ReAct prompt
2. SQL query generator prompt
3. Javascript chart generator prompt

I’ve found that each prompt needs customized context, output formats, and error handling for the agent to perform well.

### Customized context

There are 3 messaging-related parts of an [OpenAI API request](https://platform.openai.com/docs/guides/gpt/chat-completions-api) you can tweak:

1. **System message** \- the prompt text
2. **User messages** \- input from the user (ex: “What’s the average response time?”)
3. **Assistant messages** \- completions from the API

The user and assistant messages are used to give the model more  context. Unlike ChatGPT (which automatically builds context from prior  messages), you need to provide the history yourself when using the API.  At first, I sent each prompt the same message history, which was every  user and assistant message in the chat history. However, with this  simple approach, I would frequently get bizarre responses to questions.  For example, I might ask “What is the request throughput?”, and receive a  bizarre final answer like “There were no request errors”.

After lots of experimentation (more later on how to iterate quickly  on the message context), I found that sending prompt-specific context  generates the most helpful completions:

1. **Zero shot** \- all messages (including tool output) after the last answered question.
2. **SQL query generator** \- previously generated  queries and the error output associated when executing each SQL  statement (if an error is present). The error output is critical for  helping the query generator correct itself if an original query is  invalid.
3. **Chart generator** \- similar to the SQL query generator, I send previously generated charts and any error output (if present).

While increasing the max context token size is frequently seen as *the path*  to better completions, I saw a correlation between increased context  length and off-track  completions. What I provided as context mattered a  lot.

### Machine-readable output formats

The examples I started from for a ReAct agent all asked for  completions in a plain-text format. However, I found that building  regexes to parse the output was incredibly brittle due to the  non-deterministic behavior of the GPT models and the complexity of some  completions, which include code snippets.

Here’s what’s worked best for me:

1. **Zero shot ReAct prompt** \- JSON. Continue below for how I handle malformed JSON (which happens a lot).
2. **SQL & Chart generator prompts** \-  GitHub-flavored code blocks (triple backticks). I then use a regex to  parse out the code block. Remarkably, this has been very reliable.

### Error handling

I’ve found that the ReAct prompt and the code generator prompts require two different types of error handling:

1. **Zero shot ReAct prompt** \- if the JSON is malformed  (this happens), I simply repeat the same API request. More often than  not, this returns valid JSON on later attempts.
2. **SQL & Chart generator prompts** \- I’ve yet to  see a malformed GitHub-flavored code block. Instead, the most common  issue is an invalid SQL query. I include the generated SQL and error  output in the next API request. This has been very effective at  correcting the output.

🤷 - I don’t know why JSON is frequently malformed but code blocks are not.

# 4. Increase your dev cycles with a replay tool

[Showing the replay tool in action and forcing a hallucination.](https://reddit.com/link/141l6oy/video/4ts2unzyd84b1/player)

Learning to customize the context, output formats, and error handling  based on the prompt type came from replicating my API requests in the [OpenAI Playground](https://platform.openai.com/playground).  I would copy and paste the prompt, user messages, and assistant  messages into the playground, and then modify the inputs to see if I  could get a better response. The manual copy and pasting was a slow  process.

To move faster, I created an OpenAIReplay tool. When I  make an API request, I save the API request parameters and the response  to a file. I can then load the file, modify the request parameters, and  replay the request. This tool has been huge for debugging as it’s much  faster than copying and pasting into the playground. My tool is  app-specific, but it’s an easy thing to build. My tool works like this:

    # loads the message, writes the message's API request params to a file, and opens the file in VS Code for editing. replay = OpenAiReplay.from_message(message_id_or_object = Message.last) # ... make edits to the file ... replay.chat! 

## 5. Use the stream API option

The GPT API is slower than what you see in ChatGPT ([source](https://community.openai.com/t/chatgpt-api-responses-are-very-slow/98688/22)). In my experience, it’s critical to use the [stream](https://platform.openai.com/docs/api-reference/completions/create)  mode of the API versus waiting for a full completion to speed up dev  cycles (especially if you are generating long completions):

1. I think stream is a bit faster to reach a completion
2. Waiting for a full completion frequently results in API timeout and 503 errors
3. You can quickly abort if it’s clear that the completion is going to be bad

In short: *coupling a replay tool with streaming completions is the fastest way to iterate on your agent.*

## TL;DR

If I was building [LogPal.ai](https://LogPal.ai) fresh, I would: 

1. **Use GPT-4**. It’s far better than gpt-3.5-turboat reasoning and code completion. gpt-3.5-turbois great for introducing chaos into your agent loop when testing.
2. **Not use an LLM app framework.** Start with your language’s OpenAI API client and build from there.
3. **Plan on customizing prompt context, output formats, and error handling.** This is critical for getting good completions.
4. **Create/use an API replay tool**. Make it easy to replay API calls as it’s too slow to copy & paste these into the OpenAI playground.
5. **Stream completions**. Use the stream mode of the API to speed up dev cycles. You can quickly abort if a completion is off the rails."
151	Using ChatGPT to query your videos - ChatGPT, Chroma, LangChain, Python - Tutorial	13	12lyu24	https://www.reddit.com/r/OpenAIDev/comments/12lyu24/using_chatgpt_to_query_your_videos_chatgpt_chroma/	0	1681481977.0	"Hey there!   


I wanted to let you know that I just released a new video where I'm using some really cool technologies like Python, OpenAI API's, Chroma, and LangChain to answer questions based on Youtube videos.

If you don't have the time or patience to sit through a 3-hour lecture, no worries!   
My tutorial covers a solution!

I'm really excited to share this with you and I think you'll find it super helpful.  
check out the video here: [**https://youtu.be/mhdOTLp-IjQ**](https://youtu.be/mhdOTLp-IjQ).   


Enjoy!"
152	I made a dashboard to analyze OpenAI API usage	13	13aqw5j	https://v.redd.it/vrz3h5bv8fya1	5	1683470617.0	
153	I built an app to help you get full visibility and control over your OpenAI costs.	13	13katfn	https://i.redd.it/te4jhjr3wf0b1.png	0	1684350106.0	
154	OpenAI is Introducing GPT-3.5-turbo-16k on the Developer Platform	10	148xhn3	https://www.reddit.com/r/OpenAIDev/comments/148xhn3/openai_is_introducing_gpt35turbo16k_on_the/	6	1686713922.0	"The GPT-3.5 Turbo model has been updated to 16k as of today and is priced at $0.003 per 1K input tokens and $0.004 per 1K output tokens.

This new version is more steerable with the system message and includes a new capability: function calling. By describing functions in your prompts, the model can intelligently output a JSON object containing arguments to call these functions based on user input — perfect for integrating with other tools or APIs.

OpenAI has also reduced the cost for input tokens on GPT-3.5 Turbo by 25% (now $0.0015 per 1K input tokens), effective immediately.

On June 27th, the stable gpt-3.5-turbo will be automatically upgraded. 

#AI #OpenAI[Function calling and other API](https://openai.com/blog/function-calling-and-other-api-updates)"
155	Query current data - OpenAI Embeddings, Chroma and LangChain	11	12huv4f	https://www.reddit.com/r/OpenAIDev/comments/12huv4f/query_current_data_openai_embeddings_chroma_and/	2	1681158025.0	"Hi guys, I created a video on how to use Chroma in combination with LangChain and the Wikipedia API to query your own data.

Asking about your own data is the future of LLMs!   


Disclaimer: Own data can be everything which is text!

[https://youtu.be/ytt4D5br6Fk](https://youtu.be/ytt4D5br6Fk)

[https://github.com/grumpyp/chroma-langchain-tutorial](https://github.com/grumpyp/chroma-langchain-tutorial)

hope you enjoy it!"
156	How I created a semantic Q&A bot for >13k recorded dreams using OpenAI embeddings APIs, Langchain and Elasticsearch	10	148jhur	https://www.reddit.com/r/OpenAIDev/comments/148jhur/how_i_created_a_semantic_qa_bot_for_13k_recorded/	2	1686674014.0	"I created a semantic Q&A  bot for >13k recorded (webscraped, that is...) dreams using OpenAI embeddings APIs, Langchain and  Elasticsearch. It can answer queries like this one:  


""Find me all dreams containing animals, and provide me a list with their activities.""  


What  it returns are not only a proper, meaningful answer, but also  references to  relevant documents. Imagine for a moment how hard running  such a query with a traditional search engine would be! More or less  impossible for 13k documents! First of all, there is no clearly defined  concept of what an ""animal"" is, you'd end up specifying a long list of  actual animals in your input query. Second, once you identified them  you'd have to manually derive what their activities are, the text search  engine is not able to do that for you.  


Of course, there is a lot  of vagueness and fuzziness in how such a system operates. So, there's a  tradeoff here: A semantic Q&A bot is very powerful, but at the same  time you have to put a lot of (blind) trust in it. How can you know the  system does not ""forget"" an important animal or document? Well, you  cannot. But then again, would it be really better to do all of this  manually? As usual, the answer depends on your requirements. I think a  semantic Q&A bot is great if you're after convenience and speed, but  not so good if your primary goals are correctness and recall &  precision.  


I believe such semantic Q&A bots may have the  potential to become an important piece in scientific research, as they  are at the intersection between qualitative (e.g. hermeneutic) and  quantitative research. For example, a researcher who has a dataset of  transcribed interviews can easily test few hypotheses on them to get a  first summary on relevant points. Later on, she might decide to dive  into some of them.

[https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/](https://fabian-kostadinov.github.io/2023/06/12/how-i-created-a-semantic-qa-bot-with-openai-embeddings-api-elasticsearch-and-langchain/)"
157	Someone hacked my OpenAI account and used 4000$ worth of tokens	12	154o35w	https://www.reddit.com/r/OpenAIDev/comments/154o35w/someone_hacked_my_openai_account_and_used_4000/	18	1689851811.0	"Someone just hacked my OpenAI account and used all the credits. I don't know how this happended but It seems like some chrome extension might have read my ID and passwords then he just logged into my account and reset the hard limit of my account and started using it for their personal use. I just checked my account and it says that I need to pay 4000$ which I haven't used.

I can't even afford to pay this much of amount. I've raised a request in OpenAI support. Hoping for a good outcome.

Why am I suspecting that hacker got my account not just an API Key

\- Hard limit was reset to 4000$ (Previously it was much lower 500$ or even less)

\- Generated a new API Key

\- Used GPT 4 tokens. I'm not using GPT 4 in any of my product

There should be a email verification or 2FA while changing the hard limit of the account. I got the email when my hard limit reached not when someone changed the hard limit of my account and used all the credits.

Just yesterday, I got notification from Google chrome that there was one extension I've installed was found malicious which I've immeditely removed. I suspect it might have stolen the account ID and password do this malicious activity.

https://preview.redd.it/0fzl7uudr3db1.png?width=1101&format=png&auto=webp&s=d5993b39d54629646cbc40635efa25b62d8d7ce1"
158	Open Source - OpenAI , Chroma , LangChain , HuggingFace sample	11	13pdymt	https://i.redd.it/v2amznhrvj1b1.jpg	4	1684816263.0	Python - upload your docs, persist embeddings in Chroma and build using huggingface transformers, delete, rebuild Chroma embeddings store, use LangChain agent for querying across the documents - https://github.com/ushakrishnan/SearchWithOpenAI
159	What this sub is about and what are the differences to other subs	10	12gua7o	https://www.reddit.com/r/OpenAIDev/comments/12gua7o/what_this_sub_is_about_and_what_are_the/	5	1681071204.0	"Hey everyone,

I’m excited to welcome you to OpenAIDev, a subreddit dedicated to serious discussion of artificial intelligence, machine learning, natural language processing, and related topics.

At r/OpenAIDev, we’re focused on your creations/inspirations, quality content, breaking news, and advancements in the field of AI. We want to foster a community where people can come together to learn, discuss, and share their knowledge and ideas.
We also want to **encourage others that feel lost since AI moves so rapidly and job loss is the most discussed topic**. As a 20y+ experienced programmer myself I see it as a helpful tool that speeds up my work every day. And I think everyone can take advantage of it and try to focus on the positive side when they know how. We try to share that knowledge.

That being said, **we are not a meme subreddit**, and we do not support low-effort posts or reposts. Our focus is on substantive content that drives thoughtful discussion and encourages learning and growth.

We welcome anyone who is curious about AI and passionate about exploring its potential to join our community. Whether you’re a seasoned expert or just starting out, we hope you’ll find a home here at r/OpenAIDev.

We also have a **Discord channel that lets you use MidJourney at my costs** (The trial option has been recently removed by MidJourney). Since I just play with some prompts from time to time I don't mind to let everyone use it for now until the monthly limit is reached:

https://discord.gg/GmmCSMJqpb

So come on in, share your knowledge, ask your questions, and let’s explore the exciting world of AI together!

There are now some basic rules available as well as post and user flairs. **Please suggest new flairs if you have ideas**.

When there is **interest to become a mod of this sub** please send a DM with your experience and available time. Thanks."
160	Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.	1175	j05rte	https://v.redd.it/jh5n48ghrhp51	29	1601125855.0	
161	image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model	636	i437om	https://www.youtube.com/watch?v=FwXQ568_io0	46	1596625082.0	
162	If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.	578	12apw9o	https://i.redd.it/jczyjswj6pra1.png	61	1680539995.0	
163	*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)	490	msruz1	https://i.redd.it/dlw52klsvqt61.gif	53	1618670134.0	
164	Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI	450	1087ady	https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion	102	1673349121.0	
165	OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)	344	dm86ay	https://www.youtube.com/watch?v=Lu56xVlZ40M	19	1571875085.0	
166	GPT-4 Will Be 500x Smaller Than People Think - Here Is Why	331	10fw2df	https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/	49	1674114980.0	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
167	Study Plan for Learning Data Science Over the Next 12 Months [D]	306	kifqtc	https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/	59	1608676284.0	"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
168	Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.	282	if7n2p	https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/	9	1598205014.0	"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
169	Almost no one knows how easily you can optimize your AI models	271	syj7vx	https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/	38	1645521383.0	"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
170	Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.	1181	j05rte	https://v.redd.it/jh5n48ghrhp51	29	1601125855.0	
171	image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model	641	i437om	https://www.youtube.com/watch?v=FwXQ568_io0	46	1596625082.0	
172	If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.	581	12apw9o	https://i.redd.it/jczyjswj6pra1.png	61	1680539995.0	
173	*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)	487	msruz1	https://i.redd.it/dlw52klsvqt61.gif	53	1618670134.0	
174	Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI	448	1087ady	https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion	102	1673349121.0	
175	OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)	338	dm86ay	https://www.youtube.com/watch?v=Lu56xVlZ40M	19	1571875085.0	
176	GPT-4 Will Be 500x Smaller Than People Think - Here Is Why	328	10fw2df	https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/	49	1674114980.0	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
177	Study Plan for Learning Data Science Over the Next 12 Months [D]	302	kifqtc	https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/	59	1608676284.0	"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
178	Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.	279	if7n2p	https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/	9	1598205014.0	"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
179	Almost no one knows how easily you can optimize your AI models	276	syj7vx	https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/	38	1645521383.0	"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
180	Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.	1179	j05rte	https://v.redd.it/jh5n48ghrhp51	29	1601125855.0	
181	image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model	638	i437om	https://www.youtube.com/watch?v=FwXQ568_io0	46	1596625082.0	
182	If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.	578	12apw9o	https://i.redd.it/jczyjswj6pra1.png	61	1680539995.0	
183	*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)	485	msruz1	https://i.redd.it/dlw52klsvqt61.gif	53	1618670134.0	
184	Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI	451	1087ady	https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion	102	1673349121.0	
185	OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)	339	dm86ay	https://www.youtube.com/watch?v=Lu56xVlZ40M	19	1571875085.0	
186	GPT-4 Will Be 500x Smaller Than People Think - Here Is Why	329	10fw2df	https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/	49	1674114980.0	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
187	Study Plan for Learning Data Science Over the Next 12 Months [D]	301	kifqtc	https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/	59	1608676284.0	"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
188	Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.	281	if7n2p	https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/	9	1598205014.0	"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
189	Almost no one knows how easily you can optimize your AI models	273	syj7vx	https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/	38	1645521383.0	"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
190	Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.	1180	j05rte	https://v.redd.it/jh5n48ghrhp51	29	1601125855.0	
191	image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model	637	i437om	https://www.youtube.com/watch?v=FwXQ568_io0	46	1596625082.0	
192	If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.	579	12apw9o	https://i.redd.it/jczyjswj6pra1.png	61	1680539995.0	
193	*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments)	494	msruz1	https://i.redd.it/dlw52klsvqt61.gif	53	1618670134.0	
194	Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI	449	1087ady	https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion	102	1673349121.0	
195	OpenAI plays hide and seek and breaks the game. (Reinforcement Learning)	338	dm86ay	https://www.youtube.com/watch?v=Lu56xVlZ40M	19	1571875085.0	
196	GPT-4 Will Be 500x Smaller Than People Think - Here Is Why	331	10fw2df	https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/	49	1674114980.0	"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
197	Study Plan for Learning Data Science Over the Next 12 Months [D]	301	kifqtc	https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/	59	1608676284.0	"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
198	Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.	277	if7n2p	https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/	9	1598205014.0	"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
199	Almost no one knows how easily you can optimize your AI models	272	syj7vx	https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/	38	1645521383.0	"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
